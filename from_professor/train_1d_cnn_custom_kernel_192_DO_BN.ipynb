{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO_BN(conv_num=1):\n",
    "    kernel_size = 64\n",
    "    filter_size = 64\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3*kernel_size, filters=filter_size, strides=1, \n",
    "                      padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        target_kernel_size = 3 * (kernel_size//(2**(i+1)))\n",
    "        model.add(Conv1D (kernel_size=target_kernel_size if target_kernel_size != 0 else 3, \n",
    "                          filters=filter_size*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())    \n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,496\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,867,152\n",
      "Trainable params: 5,866,896\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,422,736\n",
      "Trainable params: 2,422,352\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 1,307,920\n",
      "Trainable params: 1,307,408\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,204,112\n",
      "Trainable params: 1,203,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,032,720\n",
      "Trainable params: 1,031,696\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 992,400\n",
      "Trainable params: 991,120\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 1,013,520\n",
      "Trainable params: 1,011,984\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,106,960\n",
      "Trainable params: 1,104,912\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5344 - acc: 0.3449\n",
      "Epoch 00001: val_loss improved from inf to 1.80659, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_1_conv_checkpoint/001-1.8066.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 2.5342 - acc: 0.3450 - val_loss: 1.8066 - val_acc: 0.4363\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1939 - acc: 0.6544\n",
      "Epoch 00002: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.1939 - acc: 0.6544 - val_loss: 2.0064 - val_acc: 0.4542\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8410 - acc: 0.7610\n",
      "Epoch 00003: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.8409 - acc: 0.7611 - val_loss: 2.0560 - val_acc: 0.4771\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6320 - acc: 0.8278\n",
      "Epoch 00004: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.6320 - acc: 0.8278 - val_loss: 2.4162 - val_acc: 0.4601\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5439 - acc: 0.8535\n",
      "Epoch 00005: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.5438 - acc: 0.8535 - val_loss: 2.7001 - val_acc: 0.4498\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5037 - acc: 0.8708\n",
      "Epoch 00006: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.5037 - acc: 0.8707 - val_loss: 2.9209 - val_acc: 0.4472\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8808\n",
      "Epoch 00007: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4591 - acc: 0.8808 - val_loss: 3.0733 - val_acc: 0.4717\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3774 - acc: 0.9034\n",
      "Epoch 00008: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3774 - acc: 0.9034 - val_loss: 3.2150 - val_acc: 0.4526\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3740 - acc: 0.9083\n",
      "Epoch 00009: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3740 - acc: 0.9082 - val_loss: 3.3207 - val_acc: 0.4640\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3387 - acc: 0.9190\n",
      "Epoch 00010: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3387 - acc: 0.9190 - val_loss: 3.3691 - val_acc: 0.4666\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3102 - acc: 0.9297\n",
      "Epoch 00011: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3101 - acc: 0.9297 - val_loss: 3.6109 - val_acc: 0.4682\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3289 - acc: 0.9252\n",
      "Epoch 00012: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3289 - acc: 0.9252 - val_loss: 4.0678 - val_acc: 0.4442\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3052 - acc: 0.9313\n",
      "Epoch 00013: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3052 - acc: 0.9313 - val_loss: 4.3603 - val_acc: 0.4468\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3176 - acc: 0.9320\n",
      "Epoch 00014: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3176 - acc: 0.9320 - val_loss: 4.1810 - val_acc: 0.4552\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2692 - acc: 0.9456\n",
      "Epoch 00015: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2692 - acc: 0.9456 - val_loss: 4.1735 - val_acc: 0.4696\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2684 - acc: 0.9434\n",
      "Epoch 00016: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2684 - acc: 0.9434 - val_loss: 4.2643 - val_acc: 0.4712\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2572 - acc: 0.9474\n",
      "Epoch 00017: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2572 - acc: 0.9474 - val_loss: 4.3914 - val_acc: 0.4612\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2469 - acc: 0.9493\n",
      "Epoch 00018: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2468 - acc: 0.9493 - val_loss: 4.4665 - val_acc: 0.4608\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2673 - acc: 0.9480\n",
      "Epoch 00019: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2672 - acc: 0.9480 - val_loss: 4.5345 - val_acc: 0.4531\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2655 - acc: 0.9491\n",
      "Epoch 00020: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2655 - acc: 0.9491 - val_loss: 4.8732 - val_acc: 0.4437\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2259 - acc: 0.9548\n",
      "Epoch 00021: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2258 - acc: 0.9548 - val_loss: 4.6585 - val_acc: 0.4624\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2363 - acc: 0.9570\n",
      "Epoch 00022: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2363 - acc: 0.9570 - val_loss: 4.8914 - val_acc: 0.4701\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2357 - acc: 0.9555\n",
      "Epoch 00023: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2365 - acc: 0.9554 - val_loss: 4.9210 - val_acc: 0.4521\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2759 - acc: 0.9483\n",
      "Epoch 00024: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2759 - acc: 0.9483 - val_loss: 4.9896 - val_acc: 0.4603\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1992 - acc: 0.9635\n",
      "Epoch 00025: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1992 - acc: 0.9635 - val_loss: 4.9374 - val_acc: 0.4610\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2105 - acc: 0.9614\n",
      "Epoch 00026: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2105 - acc: 0.9614 - val_loss: 5.1360 - val_acc: 0.4573\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.9582\n",
      "Epoch 00027: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2360 - acc: 0.9582 - val_loss: 5.0692 - val_acc: 0.4673\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1980 - acc: 0.9643\n",
      "Epoch 00028: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1979 - acc: 0.9643 - val_loss: 5.0449 - val_acc: 0.4731\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1778 - acc: 0.9688\n",
      "Epoch 00029: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1778 - acc: 0.9688 - val_loss: 5.3205 - val_acc: 0.4454\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.9581\n",
      "Epoch 00030: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2560 - acc: 0.9581 - val_loss: 5.1587 - val_acc: 0.4654\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2439 - acc: 0.9589\n",
      "Epoch 00031: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2438 - acc: 0.9589 - val_loss: 5.3810 - val_acc: 0.4591\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2231 - acc: 0.9621\n",
      "Epoch 00032: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2231 - acc: 0.9622 - val_loss: 5.3562 - val_acc: 0.4677\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2315 - acc: 0.9627\n",
      "Epoch 00033: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2315 - acc: 0.9627 - val_loss: 5.5760 - val_acc: 0.4617\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1881 - acc: 0.9674\n",
      "Epoch 00034: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1881 - acc: 0.9674 - val_loss: 5.3634 - val_acc: 0.4719\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1962 - acc: 0.9667\n",
      "Epoch 00035: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1962 - acc: 0.9667 - val_loss: 5.7229 - val_acc: 0.4589\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1882 - acc: 0.9691\n",
      "Epoch 00036: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1882 - acc: 0.9691 - val_loss: 5.6895 - val_acc: 0.4603\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1882 - acc: 0.9690\n",
      "Epoch 00037: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1882 - acc: 0.9690 - val_loss: 5.6504 - val_acc: 0.4619\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1827 - acc: 0.9695\n",
      "Epoch 00038: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1826 - acc: 0.9695 - val_loss: 5.6900 - val_acc: 0.4696\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9674\n",
      "Epoch 00039: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1984 - acc: 0.9674 - val_loss: 5.8925 - val_acc: 0.4477\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2352 - acc: 0.9641\n",
      "Epoch 00040: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2352 - acc: 0.9641 - val_loss: 5.8026 - val_acc: 0.4538\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1862 - acc: 0.9696\n",
      "Epoch 00041: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1863 - acc: 0.9696 - val_loss: 5.8412 - val_acc: 0.4563\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1905 - acc: 0.9692\n",
      "Epoch 00042: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1905 - acc: 0.9692 - val_loss: 5.7409 - val_acc: 0.4684\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1642 - acc: 0.9739\n",
      "Epoch 00043: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1642 - acc: 0.9739 - val_loss: 5.7565 - val_acc: 0.4647\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1883 - acc: 0.9704\n",
      "Epoch 00044: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1883 - acc: 0.9704 - val_loss: 6.0957 - val_acc: 0.4503\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9737\n",
      "Epoch 00045: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1724 - acc: 0.9737 - val_loss: 5.9838 - val_acc: 0.4507\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1697 - acc: 0.9737\n",
      "Epoch 00046: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1697 - acc: 0.9736 - val_loss: 6.3764 - val_acc: 0.4321\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2163 - acc: 0.9668\n",
      "Epoch 00047: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2162 - acc: 0.9668 - val_loss: 6.2758 - val_acc: 0.4419\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1973 - acc: 0.9712\n",
      "Epoch 00048: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1973 - acc: 0.9712 - val_loss: 5.9786 - val_acc: 0.4654\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1815 - acc: 0.9729\n",
      "Epoch 00049: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1814 - acc: 0.9729 - val_loss: 6.1912 - val_acc: 0.4603\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1655 - acc: 0.9757\n",
      "Epoch 00050: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1659 - acc: 0.9756 - val_loss: 6.2223 - val_acc: 0.4542\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1709 - acc: 0.9746\n",
      "Epoch 00051: val_loss did not improve from 1.80659\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1709 - acc: 0.9746 - val_loss: 6.0957 - val_acc: 0.4608\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEKCAYAAAARnO4WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl8VNX5+PHPmclkJpOdEPYlIFTZw1oUd1u/CEpditRi61Zpa6tS64I76lfr0n5d0FbRWlFxoVh/bih1YVHrFhStCoooSEIgCSRhJpnMen5/nJnJHkLIZDKT5/163dedzNy599zJzHPPPffc5yitNUIIIZKfJd4FEEII0TUk4AshRA8hAV8IIXoICfhCCNFDSMAXQogeQgK+EEL0EBLwhRCih5CAL4QQPYQEfCGE6CFS4l2Ahnr37q0LCgriXQwhhEgYGzZsqNBa57dn2W4V8AsKCigqKop3MYQQImEopba3d1lp0hFCiB5CAr4QQvQQEvCFEKKH6FZt+C3x+/0UFxdTV1cX76IkJIfDwaBBg7DZbPEuihAizrp9wC8uLiYzM5OCggKUUvEuTkLRWrNnzx6Ki4sZNmxYvIsjhIizbt+kU1dXR15engT7DlBKkZeXJ2dHQgggAQI+IMH+IMhnJ4SISIiAL4QQMbd8OWzYEO9SxJQE/P2oqqrir3/9a4feO2vWLKqqqtq9/OLFi/nzn//coW0JIQ7C+vVw9tkwZQr89KewaVO8SxQTEvD3o62AHwgE2nzvqlWryMnJiUWxhBCd6ZZboG9fuOEGWL0axo6F88+H7e2+iTUhSMDfj0WLFrF161YKCwu54oorWLt2LUcddRRz5sxh9OjRAJx66qlMnjyZMWPGsHTp0uh7CwoKqKioYNu2bYwaNYoLL7yQMWPGcOKJJ+LxeNrc7saNG5k+fTrjx4/ntNNOo7KyEoD77ruP0aNHM378eH72s58BsG7dOgoLCyksLGTixIm4XK4YfRpCJKH334c33oDLL4ebboJvv4WFC+Gpp+AHP4BLL4W9e+Ndyk6htNbxLkPUlClTdNNcOps2bWLUqFEAbNmyELd7Y6duMyOjkJEj72n19W3btnHyySfz+eefA7B27Vpmz57N559/Hu3quHfvXnr16oXH42Hq1KmsW7eOvLy8aG4gt9vNiBEjKCoqorCwkDPPPJM5c+Zw9tlnN9rW4sWLycjI4PLLL2f8+PEsWbKEY445hhtuuIF9+/Zxzz33MGDAAL777jvsdjtVVVXk5ORwyimnsGjRImbMmIHb7cbhcJCSUt/jtuFnKIRo4uSTTdDftg0yMuqf37HD1PwffRSOPRZefx26YScIpdQGrfWU9iwrNfwOmDZtWqN+7ffddx8TJkxg+vTp7Nixgy1btjR7z7BhwygsLARg8uTJbNu2rdX1V1dXU1VVxTHHHAPAOeecw/r16wEYP3488+fP58knn4wG9RkzZnDZZZdx3333UVVV1SjYCyHa8PHH8Mor8Ic/NA72AIMHw9KlcP/98Oab8NhjB77+mhqzjSefhGuuMevaT1NwLCVUZGirJt6V0tPTo4/Xrl3LG2+8wXvvvYfT6eTYY49tsd+73W6PPrZarftt0mnNK6+8wvr163nppZe49dZb+e9//8uiRYuYPXs2q1atYsaMGaxevZrDDjusQ+sXokf53/+FnBz4/e9bX2bBAtO8c9llcNJJ0K9f2+tcvtws/+WX5qwhwmqFYBCWLYN//MNcJ+hiUsPfj8zMzDbbxKurq8nNzcXpdLJ582bef//9g95mdnY2ubm5vP322wA88cQTHHPMMYRCIXbs2MFxxx3HHXfcQXV1NW63m61btzJu3Diuuuoqpk6dyubNmw+6DEIkvf/+F55/Hi65BLKzW1/OYoGHHwaPxyzbliefNL19tmyBww83TUIrV5rg7/HAihXmQvCkSeZg4/d37j7tR0LV8OMhLy+PGTNmMHbsWE466SRmz57d6PWZM2fy4IMPMmrUKA499FCmT5/eKdtdtmwZv/nNb6itrWX48OH84x//IBgMcvbZZ1NdXY3WmksuuYScnByuv/561qxZg8ViYcyYMZx00kmdUgYhktptt5lmnEsv3f+yhx5qevBcey288AL85CfNl1m9Gs47D44/HlatggZn9VFz55rrAZdcAtdfD//6l6ntT5hw0LvTLlrrbjNNnjxZN/Xll182e04cGPkMRY9TW6v1bbdp3dp3f/NmrZXS+qqr2r9On0/rCRO0HjBA66qqxq999JHW6enm9erq9q3vuee07tNH65QUrW+80ay/A4Ai3c4YG9MmHaVUjlJqpVJqs1Jqk1Lq8FhuTwghALjjDnORdPx40/ZeXd349dtuA4fDvNZeNhs88gjs2gVXXln//DffwKxZkJ8Pr74KWVntW9/pp5umnnnzTE2/C3pMxroN/17gNa31YcAEIDlvXxNCdB8lJXDnnXDKKaaJ5Z57TH/6Rx+FUMj0s1++HH79a+jT58DWPWWK6dGzdCmsW2eC///8jwnWq1dD//4Htr68PNPu/+67kJp6YO/tgJi14SulsoGjgXMBtNY+wBer7QkhBGBq9qEQ3HcfFBSYwH7xxXDBBfDgg6YmnpICV1zRsfXffLO52PurX0Fmpgn6a9aYg0pHZWZ2/L0HIJY1/GFAOfAPpdQnSqlHlFLpTRdSSi1QShUppYrKy8tjWBwhRNIrKoLHHzd3yhYUmOcmTzY16CeegOJic0H1ggtgwICObcPpNDX8b74xPX1WroRp0zptF2IplgE/BZgE/E1rPRGoARY1XUhrvVRrPUVrPSU/Pz+GxRFCJDWt4Y9/NDX4a65p/JpSprvkV1+ZLpa33npw2zrhBPjb30xNP4F6xcWyW2YxUKy1/iD890paCPhCiCQWCJjJ4Yj9tp5/3mS9fPDB1i+cZmaappjO8JvfdM56ulDMavha613ADqXUoeGnTgC+jNX2upOMprdo7+d5IZJSbS386EfmwuiVV0Jpaey25fWabYwZY5prRIti3UvnYmC5UuozoBC4LcbbE0J0B16v6Xa4fj3MmAF/+Uv9BdRvvmm+vNam98yKFaY3TW3tgW3v/vth61azHckl1aqYBnyt9cZw+/x4rfWpWuvKWG4vFhYtWsQDDzwQ/TsySInb7eaEE05g0qRJjBs3jhdeeKHd69Rac8UVVzB27FjGjRvHs88+C0BpaSlHH300hYWFjB07lrfffptgMMi5554bXfbuu+/u9H0UolMFAjB/vumm+PDDpm/6V1+ZLpKPPWbuWv3Zz0zXyKuvhh//2HRPPOQQ0yf9ggvM47/+FXzt6NhXUWFSGJx0kukiKVqVUOmRWbgQNnZuemQKC00/3VZ88sknLFy4kHXr1gEwevRoVq9eTf/+/amtrSUrK4uKigqmT5/Oli1bUEqRkZGB2+1utq7I88899xwPPvggr732GhUVFUydOpUPPviAp556irq6Oq699lqCwSC1tbV8/fXXLFq0iNdffx0gmhL5QEh6ZNFlQiETsB97DO6+2/xmGyothXvvNcHc5TK18fHjTU+aKVPM5HLBddfBO+/AsGEmR/3Pf26Sj7Xk97837faffQbhMSp6kgNJjyznPvsxceJEysrK2LlzJ+Xl5eTm5jJ48GD8fj/XXHMN69evx2KxUFJSwu7du+m3v0x6wDvvvMNZZ52F1Wqlb9++HHPMMXz00UdMnTqV888/H7/fz6mnnkphYSHDhw/n22+/5eKLL2b27NmceOKJXbDXQnSA1ibAP/aYCdJNgz2YG5Nuv93U7L/7Dg47rOULuuvXmzOEa66BX/7SvOeyy0xvm/Ly+qmiwiy3YEGPDPYHKrECfhs18ViaO3cuK1euZNeuXcybNw+A5cuXU15ezoYNG7DZbBQUFLSYFvlAHH300axfv55XXnmFc889l8suu4xf/vKXfPrpp6xevZoHH3yQFStW8Oijj3bGbomeLhQyd416PDBuXP2Ul9ex9V1/PSxZYrpGXn9928tmZ5uz69YoBTNnwoknmrQD113XuHeNw2G6X+bnmzFob765Y2XuYRIr4MfJvHnzuPDCC6moqIg27VRXV9OnTx9sNhtr1qxh+wGMfXnUUUfx0EMPcc4557B3717Wr1/PXXfdxfbt2xk0aBAXXnghXq+Xjz/+mFmzZpGamsoZZ5zBoYce2myULCE67J//NHejZmaatvaI/v1NrvaJE00Ty9SpMHRo89GegkHTNv/RR2aAkCeegAsvhLvu6ryRoSwWE9BPPdXkncnKMkE+vdk9nKIdJOC3w5gxY3C5XAwcOJD+4VwZ8+fP55RTTmHcuHFMmTLlgAYcOe2003jvvfeYMGECSinuvPNO+vXrx7Jly7jrrruw2WxkZGTw+OOPU1JSwnnnnUcoFALgT3/6U0z2UfQwfr+pNY8bB598Art3m7tGG053312frz0vr76N3es1QX7DBohcq8rIgIsuMgeQWAwDGGnrFwclsS7aig6Rz1A089BD5sahl14yY7q2xOs1gb+oyAT4oiL44gtz8bSw0NT8I9Ohh7Z+UVXElFy0FaKn0nr/NezaWnNRdcYMaDKgTyN2e32tPnJXqcdjAnsXZHYUnU+GOBQiWaxZY9q3ly5te7klS0z3yNtvP/Dml7Q0CfYJTAK+EMngyy/htNPMQB+//a3JK9OSykoT6GfPhiOP7NoyiriTgC9Eotu1y4y4lJZmbj6aNg3OOgvefrv5snfcYQ4Kt0mWk55IAr4QicztNhddy8vh5Zdh1ChzIbagAObMgc8/r1+2pMTc5Tp/vvR46aEk4AuRqAIBU5P/5BN49lmTngCgd29z92lamrl56fvvzfO33GL6zt90U/zKLOJKAv5+VFVV8de//rVD7501axZVVVWdXCIhML1xLr3U1Orvv79518qhQ+G110xempkz4YMPzADcv/41DB8enzKLuJNumfsRCfgXXXRRs9cCgQApbaRiXbVqVSyLJpLdO++YnDM5OSaJWMPp1VdNArIrrjAXaVsyfjy88ILJIHnkkSYdwXXXde0+iG5Favj7sWjRIrZu3UphYSFXXHEFa9eu5aijjmLOnDmMDidrOvXUU5k8eTJjxoxhaYMucQUFBVRUVLBt2zZGjRrFhRdeyJgxYzjxxBPxeDzNtvXSSy/xwx/+kIkTJ/KjH/2I3bt3A+B2uznvvPMYN24c48eP57nnngPgtddeY9KkSUyYMIETTjihCz4N0WW++sq0wX/3nWmSeewxkzzstNPMTU9XXw1z55oeN2059liThjgYNAeHvn27ovSim0qoO23jkB2Zbdu2cfLJJ/N5+OLX2rVrmT17Np9//jnDhg0DYO/evfTq1QuPx8PUqVNZt24deXl5FBQUUFRUhNvtZsSIERQVFVFYWMiZZ57JnDlzmuXFqaysJCcnB6UUjzzyCJs2beIvf/kLV111FV6vl3vCBa2srCQQCDBp0iTWr1/PsGHDomVoidxp2038/e9mcI9//AN+8IPWlysvh+nTzQXZ9983NXqtYe9ecwD47jtz89S8ee0fOnDnTpMjJxZpD0RcyZ22MTZt2rRosAe47777eD7c73nHjh1s2bKFvCYZB4cNG0ZhODvg5MmT2bZtW7P1FhcXM2/ePEpLS/H5fNFtvPHGGzzzzDPR5XJzc3nppZc4+uijo8u0FuxFN/HFF/C735l0BdOnmwyQxx7bfLm6OvjJT0yAXrvWBHswgTovrz6nzYEaMOBgSi+SREIF/DhlR24mvUGmvrVr1/LGG2/w3nvv4XQ6OfbYY1tMk2y326OPrVZri006F198MZdddhlz5sxh7dq1LF68OCblF13M54OzzzaZHl98Ec4/34zy9NBD5nFEKATnnAPvvQcrV8IPfxi/MoukJG34+5GZmYnL5Wr19erqanJzc3E6nWzevJn333+/w9uqrq5m4MCBACxbtiz6/I9//ONGwyxWVlYyffp01q9fz3fffQeYZiXRTS1ebNoiH37Y1O7/8x847jgzMtSVV5pAD+aC6ooVcOedcMYZcS2ySE4S8PcjLy+PGTNmMHbsWK644opmr8+cOZNAIMCoUaNYtGgR06dP7/C2Fi9ezNy5c5k8eTK9e/eOPn/ddddRWVnJ2LFjmTBhAmvWrCE/P5+lS5dy+umnM2HChOjALKKbefddc3frBReYphowvW5WrTK9a+66ywT3JUvgT38y3SYvvzy+ZRZJK6Eu2oqOkc/wIEV+Iwd6wdPlMr0CtIZPPzUDjTRd75IlZtSpUMh0n3z5ZZP7XYh2OpCLtlLDF6ItlZWmLX3QIDN0X1FR/QFgfy67zPSoefzx5sEezAHkkktMkD/vPNOcI8FexFBMA75SaptS6r9KqY1KqaL9v0OIbsTlgpNOMu3v48eb2nhksI8bb4TNm1t/74svmjtbr7pq/1kpTzrJdNfMyurc8gvRRFdUJ47TWld0wXaE6Dy1tSZdQVGR6TFz6qmmtv+vf8FTT5m8NDffbJKUDR9efwdsQQH062fGdp0wQfLWiG5Fzh+FaKquzgT4d94xwf3UU83zubnm4usFF5h+8itWwIcfmmabV14xaYoj7HYzsLcMFiK6kVgHfA38WymlgYe01vsZikeIGKurg7feqr+Bqek4rD6fSVnw+uvmjtjWej8NGGBu/W7I44Ht280BID8fxo6NzT4I0UGxDvhHaq1LlFJ9gNeVUpu11usbLqCUWgAsABgyZEiMiyN6pFDIDAby5JPwz3+aAUDAdI884QQ48UQzDRpkcsW//LJJTHbuuQe2nbQ0OOwwMwnRDcU04GutS8LzMqXU88A0YH2TZZYCS8F0y4xlebpKRkYGbrc73sXo2erqTDqDlStN8rAdOyA9HU4/3eSQd7ng3/82eePDyejo3RsqKuD//q/1DJRCJLCYBXylVDpg0Vq7wo9PBG6O1fZED/bxx/DRRybD5ObNZtq2zXSftFpN//bbbzc3PjVIi8GZZ5plvvrKBP+1a+FHP4IWUmELkQxi2S2zL/COUupT4EPgFa31azHcXkwsWrSoUVqDxYsX8+c//xm3280JJ5zApEmTGDduHC+88MJ+19VaGuWW0hy3lhI56ZWWmv7uZWXtW375cjPS029+Y3LTlJaaMV1vuMFccN2501xQ/fnPGwf7CKVME8wll5geOBLsRRJLqDttF762kI27Ojc/cmG/Qu6Z2XpWtk8++YSFCxeybt06AEaPHs3q1avp378/tbW1ZGVlUVFRwfTp09myZQtKqVabdFpKoxwKhVpMc9xSSuTc3NwO7WNC3Wl71lnwzDPmguqaNZCR0fqyH30ERx1l8tMsWwaDB4NF7iUUPYukR+5EEydOpKysjJ07d1JeXk5ubi6DBw/G7/dzzTXXsH79eiwWCyUlJezevZt+/fq1uq6W0iiXl5e3mOa4pZTISe+990ywnznTNLGceaYZsclma77szp2mu2T//qadvkHuISFEyxIq4LdVE4+luXPnsnLlSnbt2hVNUrZ8+XLKy8vZsGEDNpuNgoKCFtMiR7Q3jXKPFQqZnDL9+5ueNE89ZRKJ/eY35o7Vhnls6urMyE/V1eYgIcFeiHaR8992mDdvHs888wwrV65k7ty5gEll3KdPH2w2G2vWrGH79u1trqO1NMqtpTluKSVyUnv2WTPQ9q23mmacBQtMO/yjj5r0whFam7tYP/zQdLMcNy5uRRYi0UjAb4cxY8bgcrkYOHAg/fv3B2D+/PkUFRUxbtw4Hn/8cQ7bT9/r1tIot5bmuKWUyEnL4zE5ZyZONAOARCxebAYIuflmiFzk/vOfTaC/5Zb6O2CFEO2SUBdtRcd0+8/w1lvN4B9r1jQf9s/vN4H9tddM750//9m07T/9tIzPKgSSHlkkkl27zMAfp57a8hivNpvJWTN5shkspLDQNPNIsBfigEnAF/F13XUmf81dd7W+THq66Ut/+eUm7bDT2XXlEyKJJEQvHa01Smp0HdKdmuya+fRTU1v/wx9gxIi2l83Pb/ugIITYr25fw3c4HOzZs6d7B65uSmvNnj17cDgc8S5Kc1qbEaF69TK1fCFEzHX7Gv6gQYMoLi6mvLw83kVJSA6Hg0GDBsW7GPUCAZN6eNkyk6Z4yRKTZ14IEXPdPuDbbLboXagiQWld32/+2WehvNykJr7kEnNzlRCiS3T7gC8SWEmJGURk2TL45htwOOCUU0zO+ZkzzahQQoguIwFfdK5AwPSoeeQRWLXKpEw4/ni49lqTi14G6hYibiTgi86xcyfcfz889phJUdy/PyxaZMZ/HT483qUTQiABv+f47DPo29dMnUlr02SzcKEZRWrWLJPrZtYsSJGvlxDdifwie4JNm2DqVNOX/fXXobPSLBQXmyRnr74KRx4Jf/87/OAHnbNuIUSn6/b98MVBCgZNs0pGhnl89NGwYcPBrVNrE9zHjIF16+Dee81cgr0Q3ZoE/GS3ZInJGX/vvfD22yZNwXHHwfr1+39vS777Dk46CX71K5Pd8rPPTPdKGWlKiG5PfqXJbOtWuOYa054+f75JX/DOOzBwoBnYe9Wq9q9r0yY491xTi3/nHXOB9q234JBDYlZ8IUTnkoCfrCIDhdhsZnDvSC6iQYNM7X70aPjJT8yNUG0pKoIzzjDNNytWwO9+B5s3m7nU6oVIKHLRNlk9/LDJL//QQybIN5Sfb2rnp5xiBg1//nmT3sDprJ8cDnMx9vXXITvb9KO/5BLzXiFEQpKAn4x27DCphI8/3tTyW5KdbQYVWbDANNHU1tZPkUR1ffvCHXeYcWXlhikhEp4E/GSjtQnQwaCp5beVVtrpNPltmr7f64WaGhPkbbbYllcI0WViHvCVUlagCCjRWp8c6+31eMuXm4uxd9/dsTtclTLNOd0xpbIQ4qB0xVW3S4FNXbAdUVNj7ng9/HC4+OJ4l0YI0c3ENOArpQYBs4FHYrkdEfbUU7BnD9x5J1it8S6NEKKbiXUN/x7gSiAU4+0IreGBB2DCBJgxI96lEUJ0QzEL+Eqpk4EyrXWb9/ErpRYopYqUUkUyqtVBePddM0bs737X9oVaIUSPFcsa/gxgjlJqG/AMcLxS6smmC2mtl2qtp2itp+RLH++Oe+AB09Xy5z+Pd0mEEN1UzAK+1vpqrfUgrXUB8DPgLa312bHaXo+2axc89xycd57JlSOEEC2Qe+OTwcMPg98PF10U75IIIbqxLrnxSmu9FljbFdvqcfx+kz7hxBNh5Mh4l0YI0Y3JnbaJ7oUXzGDhf/tbvEsihOjmpEkn0T3wAAwdalIgCyFEGyTgJ7IvvoC1a+G3v5UbrYQQ+yUBP5H99a9gt5shDIUQYj8k4Ceqffvg8cdh3jzo3TvepRFCJAAJ+Inq8cfB7TZ31gohRDtIwE9EoZBpzpk6FaZNi3dphBAJQrplJqJbbjGDij/9dLxLIoRIIFLDTzQvvwyLF8M555j2eyGEaCcJ+IlkyxY4+2yYNMncaCVZMYUQB0ACfqJwu+G00yAlBf71L0hLi3eJhBAJpl0BXyl1qVIqSxl/V0p9rJQ6MdaFE2Fam772mzbBM8+YO2uFEOIAtbeGf77Weh9wIpAL/AK4PWalEo395S+wYgX86U/wox/FuzRCiATV3oAfaSyeBTyhtf6iwXMilt56C666Cn76U7jiiniXRgiRwNrbLXODUurfwDDgaqVUJjJObezs3Qvr18OaNfDEE3DYYfDoo3KRVghxUNob8C8ACoFvtda1SqlewHmxK1YPEwzCq6/Cm2+aZGiffmra7dPS4Oij4f77ITMz3qUUQiS49gb8w4GNWusapdTZwCTg3tgVq4fQGl57Da68Ej7/3CRCO+IIuOkmOO44cxdtamq8SymESBLtDfh/AyYopSYAfwQeAR4HjolVwZLexo2mTf6NN+CQQ+DZZ2HOHHA44l0yIUSSau9F24DWWgM/Ae7XWj8ASBtDRxQXw7nnmpunPv4Y7r0XvvwSzjxTgr0QIqbaW8N3KaWuxnTHPEopZQFssStWEtIaliwxPW60NrX7q6+GnJx4l0wI0UO0t4Y/D/Bi+uPvAgYBd8WsVMlm715zl+yll8IJJ8BXX8Edd0iwF0J0qXYF/HCQXw5kK6VOBuq01o/HtGTJ4j//gYkTYdUquPtueOkluVNWCBEX7U2tcCbwITAXOBP4QCn101gWLOGFQqYWf/TRJv/Nf/4DCxdKX3ohRNy0tw3/WmCq1roMQCmVD7wBrGztDUopB7AesIe3s1JrfePBFTdBlJfDL34Bq1ebi7FLl0J2drxLJYTo4dob8C2RYB+2h/2fHXiB47XWbqWUDXhHKfWq1vr9jhQ0YRQVwemnQ1kZPPggLFggtXohRLfQ3oD/mlJqNRAZYmkesKqtN4S7cbrDf9rCk+5IIRPGsmXw619D376mCWfSpHiXSAghotp70fYKYCkwPjwt1Vpftb/3KaWsSqmNQBnwutb6g4MpbLfl98PFF5v+9TNmwIYNEuyFEN1Ou8e01Vo/Bzx3ICvXWgeBQqVUDvC8Umqs1vrzhssopRYACwCGDBlyIKvvHnbvhrlz4e234Y9/hNtvNxdphRCim2kzMimlXLTcDKMwrTZZ7dmI1rpKKbUGmAl83uS1pZizB6ZMmZJYTT4bN8LJJ5t+9k89BWedFe8SCSFEq9oM+FrrDqdPCPfk8YeDfRrwY+COjq6v29m+HWbONMnN3nsPJkyId4mEEKJNsWx76A8sU0pZMdcKVmitX47h9rpOVRXMmgVer8lZP2pUvEskhBD7FbOAr7X+DJgYq/XHjc8HZ5wBW7bAv/8twV4IkTDk6uKB0Nr0q3/rLXj8cTj22HiXSAgh2q29ydMEwC23mL72N91k7qQVQogEIgG/vR5/HG68Ec45B66/Pt6lEUKIAyYBvz3WrYNf/QqOP97kxZFUCUKIBCQBf3+qqmD+fBg+HJ57TsaYFUIkLLlouz8LF8KuXfD++zJgiRAioUkNvy0vvmgu0l59NUyZEu/SCCHEQZGA35o9e0zmy/Hj5SKtECIpJHyTjtYh9u37EJutF07nDzpvxRdfDBUV8Oqr0m4vhEgKSVHD//TT49i586HOW+Fzz8HTT8MNN0BhYeetVwgh4ijhA76YSUvBAAAdmElEQVRSFtLSRuDxfNM5Kywvh9/+FiZPhkWLOmedQgjRDSR8wAfCAX/Lwa9IaxPsq6vhscfAZjv4dQohRDeRJAF/JB7PVsx4KwdhxQrTnHPTTTB2bOcUTgghuokkCfgj0NqH11vc8ZV4PHDZZab75eWXd17hhBCim0j4XjpgavgAHs83OBxDO7aS+++HnTvNxVoZolAIkYSSpIZvAn5tbQfb8auq4E9/gpNOgqOP7sSSCSFE95EUAd9uH4DF4uj4hdu77oLKSrjtts4tmBBCdCNJEfAPqmtmaSncc48ZgFz63AshklhSBHw4iK6Z//u/ZtjCm2/u/EIJIUQ3kkQBvwNdM7duNfntL7wQRoyIXeGEEKIbSKKA34GumTfcYG6ukuRoQogeIIkCfn3XzHb59FN46imT775//xiWTAghuockCvimSabdXTOvvRZyc+HKK2NYKiGE6D5iFvCVUoOVUmuUUl8qpb5QSl0aq20B2O0Dw10z21HDf/tteOUVkxxNRrESQvQQsbylNAD8UWv9sVIqE9iglHpda/1lLDamlAWH45CWe+poDZs3w5tvwltvmWnAAPj972NRFCGE6JZiFvC11qVAafixSym1CRgIxCTgAzidI6mt/ar+iVdfheXLTYAvLTXPDR0KZ5wBF10ETmesiiKEEN1OlySNUUoVABOBD2K5nbS0EezZswqtg6gnn4JzzoH8fDjhBDj+eDMNHx7LIgghRLcV84CvlMoAngMWaq33tfD6AmABwJAhQw5qW2lpI9Hah//ppaSe+3sT4F9+GRyOg1qvEEIkg5j20lFK2TDBfrnW+l8tLaO1Xqq1nqK1npKfn39Q20tLG0Gv98B2zsVw+OHwwgsS7IUQIiyWvXQU8Hdgk9b6/2K1nYbS39/N2BvBP2aQ6YWTnt4VmxVCiIQQyxr+DOAXwPFKqY3haVbMtvbOO9h++is8gxTFD8+G7OyYbUoIIRJRLHvpvAOoWK2/kaIimDULNWgQX92jsDkOYuQrIYRIUol/p+2ePfA//wN5efDmm6QOHtWxNMlCCJHkEj/g5+WZAUzefBMGDQqnSd6K1qF4l0wIIbqV5Bi89fzzow9N10wvXm8xDsfBdfMUQohkkvg1/CYiSdQ6PNyhEEIkqSQM+Ac5oLkQQiSppAv4B5Q1UwghepCkC/htZs0UQogeLOkCPkQGNJcavhBCNJSUAd/pHCldM4UQoomkDPhmQHPvgQ1oLoQQSS5JA35kQHNpxxdCiIgkDfiRvvjSji+EEBFJGfDt9kEoZZe++EII0UBSBnylLKSlHSI1fCGEaCApAz6YdnxpwxdCiHpJHPAla6YQQjSUtAHf6RwpXTOFEKKBpA34kjVTCCEaS+KAH+mLLxduhRACkjjg13fN/DreRRFCiG4haQO+UhaysqZTVvYswWBtvIsjhBBxl7QBH2DYsJvw+UooKVkS76IIIUTcJXXAz8k5hl69ZrN9+5/w+/fEuzhCCBFXMQv4SqlHlVJlSqnPY7WN9hg+/HaCQRfbt98Wz2IIIUTcxbKG/xgwM4brb5eMjLH063cOJSX3U1e3Pd7FEUKIuIlZwNdarwf2xmr9B6Kg4CaUsvDdd9fHuyhCCBE3KfEugFJqAbAAYMiQITHZhsMxmIEDL2HHjrsYPPiPZGRMiMl2ROxpDcFg80kpsFjAajXzyGS1mtdaEwzCnj1QUWEmv7/+fZF1Wa2QktJ4stnMXGuoq2t58vmaT1pDVpaZsrPrH6en1+9fKGTmkSkQMOUKBBpPDZeJvFdrs6zX2/K2I5+FUvVTKFT/OQYC9Y/3939oun2o/9waTk0/s8iklClnXZ2ZRya/v359Dcurdf2+RPbP6zVltlrN+iPbiMwj+xT5/CLz1tjtkJbWfIps2+9v/JkGAubzazg1/F42/H8Fg+b1yHe14TwnB+69t+3PvDPEPeBrrZcCSwGmTJmi97N4hw0ZsojS0of59ttFjB//aqw2E1N+P+zbZyaXy3xRUlMbTzab+XI1DDwej5kHg81/qFpDTQ3s3dt42rPH/JgaBr/IFClLwx+A32+mhl/6yFzrxl/wyBT5EUcCXGQeDNb/+CPBIDIPHWBqJIsFnE7zo43M09LMPldUQGVl44AlEkNqqgnODb/zDYO631//f216EIgcbJrS2nzHPB7znW4Pm63xd7phRSMlpfEBL1L5aPjbi3zne/fuvM+mLXEP+F3FZstl6NBr2br1cior3yI39/gu27bXCzt2wPffQ2lpfe2vYS3F660P5tXVjeeRx3V1sS9rSgr06mUmh6NxbSUSwKH+hxaZRx43rRm3FtgjU9OaTuQHY7eb7Ucmu91MkR9Ow8kSbpiMlLHhQcfrhdpa8yOura1/nJ5ufmT5+Wbeuzfk5TXe59Zqaw1r22AOIA3L2rC8TQ/IWpuDddP/cU1N41p35PNQquWA1XC/I8tFHke21XD7Nlv9Mk0P+E0DVGRqLSi2dJYQ+R+3dPbV9Mwk8hlq3fizikyRsjY8c4loui9tiXy/OiIYNN+TyGSxNP9f7u/ssTvqMQEfYMCA31FcfB9bt17J5MkfotSBfxtCIVMD3r3bTBUV5gccqXVHHu/dawL899/Drl37X6/F0vg0Pzsb+vaFkSMbn/pHXsvIaHyK23Cy2eoDT8NglBL+bzf9oTqd9UE+MzPxvsSJJj8/3iXoGToa7MEE84wMMyWTmAV8pdTTwLFAb6VUMXCj1vrvsdpee1itDoYNu4XNm8+hvPyf9Okzr9kydXWwbRt8+y1s3Wrm335rAvfu3VBW1nb7ptNpgmZODgwZArNnm/nQoWY+YIAJwpHaV2Se0qMOvUKIeIhZmNFanxWrdR+Mvn3nU1x8N19/fRHp6eNITx/Njh3wzDPw9NOwcWPjU0inE4YPNwF70iRT62449e5dXwPPyJDALYTovnpceFLKypgxz7FmzSksXvwE7713I+++6wBg2jS44QYYMcIE+UMOgT59pIlDCJEcelzA37IFrr12OM8//zmBgGLYsC0sXjyA+fPTGTEi3qUTQojY6TEBf88euOUWeOAB027+hz8o5szZQDB4JBkZYykoeAvIjHcxhRAiZpI6eRqYbnl/+YtpplmyBM4/H775Bu68E448cjJjxqzA5fqEL744nVDIG+/iCiFEzCR1wH/lFRg1Ci6/HA4/HD77DB56CPr1q1+md+9TOOywv1NZ+QabNv0Crfdzi6EQQiSopG3S+fprOP1004/93/+GH/+49WX79TsHv7+CrVsv58svYdiw23A6pUFfCJFckjLgaw0XXWT6u7/xRuMafWsGD/4jwaCH7dv/l/LyleTnn8HgwVeQlTUt9gUWQogukJRNOk89BW++Cbff3r5gH1FQcB3Tp29jyJCrqax8g48//iGffHIse/asQkvCFSFEglPdKZBNmTJFFxUVHdQ6KivhsMNg2DD4z386fnt1IOCitPQRiov/D6+3GLt9KNnZR5CZOZWsrGlkZEzEanUeVFmFEOJgKaU2aK2ntGfZpGvSueYak99m9eqDy6WRkpLJ4MF/YODA31NW9gwVFf+P6uq3KSt7OryElYyMcWRmTiM7+0iys2fgcAxDyV1aQohuKqkC/vvvm144CxdCYSF4/B6K9xWzvXo731d/z/aq7dHHGk2f9D70Te9rpoy+9EnvQ29nbzJTM8myZ5FlzyLTnkm/fr+gX79fAOD1luJyfcS+fR/icn1EWdmzfF+ylDIvlAd6Uc0wyoO51OpsBuWMZkDmAPpn9GdA5gAGZA4gz5mH2+emqq6K6rpqM/dW4/K68If8BEIBgqGgmesgwVCQoA4S0qFGk9aavhl9KcgpYFjOMIbmDMVpa/8Zh9Yab9AbLcue2j3s8eyhorYi+rjGVxPdXsMyWJU1+tlk2bOin1eaLQ2Fih70Io+tyorT5mw2paemk2pNbbOcHr+HXe5dlLpL2e3ejdvnptZfS42/hlp/LbX+WuoCdeQ6cumb0Zd+Gf2iU9/0voR0iBp/DTW+mui81l9LIBRAo9FaR+cAFmXBZrVhs9gazf1BPy6fi33efbi8rujjyPabTvYUOyNyRzAybyQje41kZN5IMlLrM3HVBerY6drJTtdOSvaVsNezF3uKHUeKg7SUNDO3pWGz2Kj11+L2uanx15i5rwZPwEOqNRVHiqPRlGpNpdZfyz7vvmhZ93n34fa5cdqc5Kbl0iutF7mO8DwtlxRLSrPvV0tTMGS+A96gN/rZR6YaXw2OFAeDswczOGswQ7KHMDh7cKN9bvjd8wV9eIPeRt/1yHffG/RSVVcVnSo9lVTVVeH2uUmxpDT7/9hT7OQ6cunt7E2eM4+8tDzynHn7/W51hC/oo3hfMduqtrG9ajveoBe71Y49xd5sHvk/NpwAPAEPdYE6PH4PnoAHj98DwHHDjuv08jaV8E06WmvuePcOdu7bxRPP76LWuouho3dRVruLam91o2UVigGZAxiSPQSrxUpZTRm73bubLddUWkoaTpuTFEsKVovVzJWZewIedrp2EtL1idqtCjJSYJ8fuvLT7ZPeh6HZQ3GkOBr9gCKPPX5Po+DXsMxNWZWV9NR0rMqKRVkaTf6QH5fXhTd48Pct2Cw2Mu2ZZKRmkJlq5vYUO2U1ZZS6Svf7v4n84N0+90GXpaNsFhuOFEc0YDtSHNT4aih1lzZarl9GP/LS8tjl3sUez54uKZtFWaKfa62/lqq6KnQMvpV2qx1f0Nds3TmOHHIcOc0OiB2hUAdU9nRbOlaLNXpQBxMvlFLkpeXRP7M//TPCU2Z/+mX0IxgK4vK5Gh3UXT4XJftK2F69nZJ9JTH5/Pqm92XX5e1Iq9uCA2nSSfiAD5Bzew5er6auoh+jh/ZjbEG/aM19cLapbQzNHsrArIEtHvXrAnXR4L/Xszf6j25YQ6rx10SDZ8NgmmpNpSCnIFrTHpY7jF62AFV7X2b7jiWU7vuG6lAeOv3H1KVOxOUPkpGaQY4jh2xHNtn2bHIcOWTaM0m1pkYPJFaLFauyNppHAm7ki7/LvYttVdsaTdurt+MP+psdmKwWK44UB+m2dNJt6WSkZpCeah5nO7JN7SgtL1pLyrZn77d5yhf0NfphePyeRj+syOPIwaZpzTxSW3X5XLh97ui8LlBHvjM/+kOMzPum9yXLntXoLMFmtUXLUlZTxi73rui0270bi7JE97Ph3GYx71NKRc9EFIqgDuIP+vGH/I3mNqstejbT8MzGaXNitVhb/HzcPjff7P2GLXu2sGWvmSo9lfTP6M/ArIEMzBzIgMwBDMwaSF5aHv6QH48/XPsL1wJ9QV+0zBmpGdH/nSPFgT/kbxZIvQEv6anp0bMup83Z6P8Y0iGq66rZ69lLZV0lez17CelQs4O6QjX6zjWc7FZ79AzNaXOSlpKG1WLFH/Sz07WTHft28H319+yo3sGOfTvY593X6Myl4dlI00qU1WIl1ZpKriM3erDITTOP01LS0GgCoUCj/01doI69nr3s8exhT234LNWzh0pPZbRSE/n/Rj6DCk8Fpa7S6NnjXk/z0VgjlZBMeyb9M/pTkFPA0OyhZp4zlKHZ5qzaG/SaM5aAF2/QG51H/ieR/2ldoA6NbnQGl5aSRpotjXRbOlMHTm3z99aaHhfwt3xXx8RxDo47Dl58sfskO9M6xN69/6akZAl7965CKRu9es0iNTUfpWzhKQWlbFgsDpzOw8jIKMTpHIlSLQcRIUTn8wa87K7ZTYolhczUTNJT07F0YLyMeOhxF22v+qODUMikTuguwR5AKQt5eTPJy5tJbe0WSkoeYM+eF3G56tDaj9YBQiF/+HH9mGoWSxrp6WPJyJhAevoE0tNHkZb2A+z2gW0O2qK1Jhh0Y7U65YAhxAGwp9gZkh2bMbW7k4Sv4VdWwhFHwLnnwlVXxaZcXSEU8lJTs4mamk9xuz/F7d6I2/0pgUD9qabF4iQtbSRO5w9ISzuEYLAWn68Un68Ur3cnPt8uQqFalErBbh+Mw1GAwzEUh6MAu30oSlkIBCoJBKrw+808EKgiNbUfOTnHkpNzLHb7Ady4IISIux7XpBMZbNtmi0Gh4khrjc+3k9rar6mt/QqP52tqa7/G4/kaj+dbrFYnqan9sdsHkJraPzz1JRCooq5uO3V126ir24bPV0rTy8dWaxYpKTmkpGRTV7eNYNAFgNN5GDk5x5GTcxxO56GAgmjPGzNZLHZSUrKxWrOxWDp2khgM1uH3V4TXawmfkVhQyoLFYsdqTe/4B9cKrTV1dd/idm/E6TyM9PQxnb4NIbpaj2vSsdvjXYLYUEphtw/Ebh9Ibm7jLltah9o9Jm8o5KWubgdKKVJScrFasxoF6lAogNv9CVVVa6iqWsvu3U+wc+ff2rVui8VJSkp29ACQkpIVPpjUz8GCz7cTr7cEr7cYr7eEQKDtXioOxyFkZU0lMzMyTWp2EAiF/ASDLoJBV4Okd/UHNq0D1NR8icv1ES5XES5XEYFAZfT1rKwjGDDg1+Tnz8VqTWvX/jYUCOwDFCkpHU+r7fXuYteuv1NVtRarNSN8EI5MuaSk5Ia/A4Ow2wfG5EAYD6FQAK19cvNiF0uKGr7oXKGQH7f7Y7ze4nD/9PpJa43WXgKB6ugUDDZ87CIQ2EcwuC86B43N1icatCIBzGbLB1Q4WIfQOgQECQRcuN2f4HJ9hNe7I1wqC2lpI4FQdL2hkKdd+6NUCunp48IHjilkZEyguvptdu5cisfzNSkpOfTt+0sGDPg1TucogsEaAoGqRvvl8+3E4/mWurpv8Xi+xePZGj1opaWNJDNzMhkZk8PzidhsOa2WR2tNVdVadu78GxUVz6N1gIyMiWgdiDazRc64mkpJyQl/dn3R2kcwWEMwWEMoFJl7SU8fQ1bWEWRnH0FW1hE4HIPa9TnFSjBYR03Nf3G7P8bl+gS3+xNqaj4jFPKRmTmZnJzjyc09juzsI7vVAU3rIG73p1RXvwvQ7GzaanXEuYRGj2vSEd2X1iaQd7Tpx+fbzb59H+FyfURNzedYLKnNziCs1kyUarh+FZ07nSNJT5/Q4o/TBN51lJY+RHn5c2jtB6xAaymyrTgcQ0lLOwSHYzhpacMJhXy43RtwuTY0ODiB3T44eoBLTR0YPdD5fLvZufMhPJ6vSEnpRb9+5zFgwAKczh802lIoFCAYrMbv39PozMjMi/H7d6OUHas1A6s1PTxloJQVl+sTXK4PowdEu30wWVnTsVgcDQ4QtdG5UilYLOlYrU6s1vToY6VabiNVyorF4sBisWOxOFDKjsViR2sfPl8Zfn85fn85Pp+Ze70l0c/Uas0mM3MiGRkTsVjSqKpah8v1AVoHUMpGZuY0MjOnYCoXvnCnBh+hkA+lLOHPfwQOxyGkpR0S7cigdQifb3e4GfM76uq24fXuJCUlE5stH5utD6mp+eHH+Vgs9nAPOWv4u2MFNG73Rqqq1lFdvZ7q6nfDFZaWpaTkkJraL7pOmy0/vI0+4b97N9hmbyyW5l3CtQ4RCnnROtDhM0UJ+EIcIJ+vnN27l+P3V0SbqOqbqbJJTe2L3T6kzQOXz1cersVuoLZ2czhAl+DzlRAM1t8YlpV1OAMG/Jb8/J92qCmpPcxZ2qfs2/cfqqv/g8v1EaCxWJwNDhDpWCxpaB0gGKyNniVEptYOfKZ3mZdQqC58kKxnsaSFA1+faBC02weTmTmJjIyJOBwFze7vCATc7Nv3LpWVa6iqeouami+xWGwolRruspyKUqloHcDr3Y7Wgeh7lbKTmtoPn28XWje+ETAlJYdg0N1o+fZyOkeRk3MM2dlHk519FBaLvUHniPqOEn5/WYODWxl+/x6g5RsaTVNqWvgA5kVrX7Rsqan9OOKI0hbftz8S8IXoZgKBfXi9JShlbVabT2SRGmoo5MViscW8SSYUCuD17sDj2Upd3VY8nm/wekux2weEe6UNi/ZOs1qdaK0JBKobnHWU4fdXRIOtmYLReXr6aLKzjyQ1tU+Hyqd1EL+/Mrq9+oNBBX5/OaGQJ3x2YQ+fIaWilOkEMXDgbzu0zW4T8JVSM4F7MedLj2itb29reQn4QghxYA4k4MfsVjJl+tk9AJwEjAbOUkqNjtX2hBBCtC2W9w5PA77RWn+rzW2kzwA/ieH2hBBCtCGWAX8gsKPB38Xh54QQQsRB3LMDKaUWKKWKlFJF5eXl8S6OEEIkrVgG/BJgcIO/B4Wfa0RrvVRrPUVrPSU/Pz+GxRFCiJ4tlgH/I2CkUmqYUioV+BnwYgy3J4QQog0xy6WjtQ4opX4PrMZ0y3xUa/1FrLYnhBCibTFNnqa1XgWsiuU2hBBCtE+3utNWKVUObO/g23sDFZ1YnEQg+5z8etr+guzzgRqqtW7XBdBuFfAPhlKqqL13myUL2efk19P2F2SfYynu3TKFEEJ0DQn4QgjRQyRTwF8a7wLEgexz8utp+wuyzzGTNG34Qggh2pZMNXwhhBBtSPiAr5SaqZT6Sin1jVJqUbzLEwtKqUeVUmVKqc8bPNdLKfW6UmpLeJ4bzzJ2NqXUYKXUGqXUl0qpL5RSl4afT9r9Vko5lFIfKqU+De/zTeHnhymlPgh/x58N37meNJRSVqXUJ0qpl8N/J/X+Aiiltiml/quU2qiUKgo/F/PvdkIH/B6Uc/8xYGaT5xYBb2qtRwJvhv9OJgHgj1rr0cB04Hfh/20y77cXOF5rPQEoBGYqpaYDdwB3a61HAJXABXEsYyxcCmxq8Hey72/EcVrrwgbdMWP+3U7ogE8PybmvtV4P7G3y9E+AZeHHy4BTu7RQMaa1LtVafxx+7MIEhIEk8X5rIzL4rS08aeB4YGX4+aTaZ6XUIGA28Ej4b0US7+9+xPy7negBvyfn3O+rtY6MerwL6BvPwsSSUqoAmAh8QJLvd7h5YyNQBrwObAWqdP1I3Mn2Hb8HuJL6kb/zSO79jdDAv5VSG5RSC8LPxfy7HdNcOqJraK21Uiopu1sppTKA54CFWut9pgJoJON+a62DQKFSKgd4HjgszkWKGaXUyUCZ1nqDUurYeJenix2ptS5RSvUBXldKbW74Yqy+24lew29Xzv0ktVsp1R8gPC+Lc3k6nVLKhgn2y7XW/wo/nfT7DaC1rgLWAIcDOUqpSOUsmb7jM4A5SqltmObY44F7Sd79jdJal4TnZZgD+zS64Lud6AG/J+fcfxE4J/z4HOCFOJal04Xbcv8ObNJa/1+Dl5J2v5VS+eGaPUqpNODHmGsXa4CfhhdLmn3WWl+ttR6ktS7A/Hbf0lrPJ0n3N0Ipla6Uyow8Bk4EPqcLvtsJf+OVUmoWph0wknP/1jgXqdMppZ4GjsVk1NsN3Aj8P2AFMASTYfRMrXXTC7sJSyl1JPA28F/q23evwbTjJ+V+K6XGYy7WWTGVsRVa65uVUsMxNeBewCfA2Vprb/xK2vnCTTqXa61PTvb9De/f8+E/U4CntNa3KqXyiPF3O+EDvhBCiPZJ9CYdIYQQ7SQBXwgheggJ+EII0UNIwBdCiB5CAr4QQvQQEvCF6ARKqWMj2R6F6K4k4AshRA8hAV/0KEqps8M55zcqpR4KJytzK6XuDuegf1MplR9etlAp9b5S6jOl1POR/ORKqRFKqTfCees/VkodEl59hlJqpVJqs1JquWqY+EeIbkACvugxlFKjgHnADK11IRAE5gPpQJHWegywDnMnM8DjwFVa6/GYO34jzy8HHgjnrT8CiGQ4nAgsxIzNMByTK0aIbkOyZYqe5ARgMvBRuPKdhklQFQKeDS/zJPAvpVQ2kKO1Xhd+fhnwz3AOlIFa6+cBtNZ1AOH1fai1Lg7/vREoAN6J/W4J0T4S8EVPooBlWuurGz2p1PVNlutovpGG+V6CyO9LdDPSpCN6kjeBn4ZzkEfGEB2K+R1EsjP+HHhHa10NVCqljgo//wtgXXj0rWKl1KnhddiVUs4u3QshOkhqIKLH0Fp/qZS6DjPSkAXwA78DaoBp4dfKMO38YFLUPhgO6N8C54Wf/wXwkFLq5vA65nbhbgjRYZItU/R4Sim31joj3uUQItakSUcIIXoIqeELIUQPITV8IYToISTgCyFEDyEBXwgheggJ+EII0UNIwBdCiB5CAr4QQvQQ/x+LsLl/pg1+LAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 512us/sample - loss: 1.8823 - acc: 0.3907\n",
      "Loss: 1.8822607367457136 Accuracy: 0.3906542\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.5889 - acc: 0.3103\n",
      "Epoch 00001: val_loss improved from inf to 3.40631, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_2_conv_checkpoint/001-3.4063.hdf5\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 3.5888 - acc: 0.3103 - val_loss: 3.4063 - val_acc: 0.2991\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6419 - acc: 0.5039\n",
      "Epoch 00002: val_loss improved from 3.40631 to 2.54833, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_2_conv_checkpoint/002-2.5483.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 2.6419 - acc: 0.5039 - val_loss: 2.5483 - val_acc: 0.5274\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2871 - acc: 0.5959\n",
      "Epoch 00003: val_loss improved from 2.54833 to 2.27234, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_2_conv_checkpoint/003-2.2723.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 2.2872 - acc: 0.5959 - val_loss: 2.2723 - val_acc: 0.5996\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0813 - acc: 0.6516\n",
      "Epoch 00004: val_loss did not improve from 2.27234\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 2.0813 - acc: 0.6516 - val_loss: 2.8497 - val_acc: 0.5206\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9131 - acc: 0.6978\n",
      "Epoch 00005: val_loss did not improve from 2.27234\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 1.9129 - acc: 0.6978 - val_loss: 2.8954 - val_acc: 0.5171\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8173 - acc: 0.7263\n",
      "Epoch 00006: val_loss did not improve from 2.27234\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 1.8173 - acc: 0.7263 - val_loss: 2.5355 - val_acc: 0.5877\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6866 - acc: 0.7629\n",
      "Epoch 00007: val_loss did not improve from 2.27234\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 1.6865 - acc: 0.7629 - val_loss: 2.7083 - val_acc: 0.5893\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6366 - acc: 0.7785\n",
      "Epoch 00008: val_loss did not improve from 2.27234\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 1.6368 - acc: 0.7785 - val_loss: 2.6758 - val_acc: 0.6038\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5071 - acc: 0.8039\n",
      "Epoch 00009: val_loss did not improve from 2.27234\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 1.5075 - acc: 0.8038 - val_loss: 2.8497 - val_acc: 0.5381\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9192 - acc: 0.8052\n",
      "Epoch 00010: val_loss did not improve from 2.27234\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.9192 - acc: 0.8052 - val_loss: 2.7363 - val_acc: 0.4976\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5102 - acc: 0.8576\n",
      "Epoch 00011: val_loss improved from 2.27234 to 2.20850, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_2_conv_checkpoint/011-2.2085.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.5102 - acc: 0.8576 - val_loss: 2.2085 - val_acc: 0.5749\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4307 - acc: 0.8725\n",
      "Epoch 00012: val_loss improved from 2.20850 to 2.01717, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_2_conv_checkpoint/012-2.0172.hdf5\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.4308 - acc: 0.8725 - val_loss: 2.0172 - val_acc: 0.5812\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3515 - acc: 0.8949\n",
      "Epoch 00013: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.3517 - acc: 0.8949 - val_loss: 2.0573 - val_acc: 0.6056\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3061 - acc: 0.9092\n",
      "Epoch 00014: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.3061 - acc: 0.9091 - val_loss: 2.1223 - val_acc: 0.6117\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2714 - acc: 0.9173\n",
      "Epoch 00015: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2714 - acc: 0.9173 - val_loss: 2.4790 - val_acc: 0.6003\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2468 - acc: 0.9262\n",
      "Epoch 00016: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2468 - acc: 0.9262 - val_loss: 2.2591 - val_acc: 0.6075\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2190 - acc: 0.9336\n",
      "Epoch 00017: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2190 - acc: 0.9336 - val_loss: 2.3188 - val_acc: 0.6105\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2246 - acc: 0.9345\n",
      "Epoch 00018: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2247 - acc: 0.9345 - val_loss: 2.3532 - val_acc: 0.5968\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2195 - acc: 0.9353\n",
      "Epoch 00019: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.2194 - acc: 0.9353 - val_loss: 2.9261 - val_acc: 0.5705\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1734 - acc: 0.9494\n",
      "Epoch 00020: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1733 - acc: 0.9494 - val_loss: 2.5533 - val_acc: 0.5947\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1681 - acc: 0.9498\n",
      "Epoch 00021: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1682 - acc: 0.9498 - val_loss: 2.4843 - val_acc: 0.6224\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9481\n",
      "Epoch 00022: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1793 - acc: 0.9481 - val_loss: 2.3509 - val_acc: 0.6271\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1626 - acc: 0.9527\n",
      "Epoch 00023: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1627 - acc: 0.9527 - val_loss: 2.5671 - val_acc: 0.6112\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1675 - acc: 0.9535\n",
      "Epoch 00024: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1674 - acc: 0.9535 - val_loss: 2.4415 - val_acc: 0.6287\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9661\n",
      "Epoch 00025: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 0.1159 - acc: 0.9661 - val_loss: 2.5023 - val_acc: 0.6261\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9680\n",
      "Epoch 00026: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1115 - acc: 0.9680 - val_loss: 2.4504 - val_acc: 0.6278\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9606\n",
      "Epoch 00027: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1395 - acc: 0.9606 - val_loss: 2.4352 - val_acc: 0.6345\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9692\n",
      "Epoch 00028: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1097 - acc: 0.9692 - val_loss: 2.5039 - val_acc: 0.6224\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9621\n",
      "Epoch 00029: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1335 - acc: 0.9621 - val_loss: 2.7127 - val_acc: 0.6117\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9702\n",
      "Epoch 00030: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1105 - acc: 0.9702 - val_loss: 2.4977 - val_acc: 0.6334\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9725\n",
      "Epoch 00031: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.1011 - acc: 0.9725 - val_loss: 2.5108 - val_acc: 0.6352\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9707\n",
      "Epoch 00032: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.1053 - acc: 0.9707 - val_loss: 2.9320 - val_acc: 0.5970\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9732\n",
      "Epoch 00033: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0985 - acc: 0.9732 - val_loss: 2.3450 - val_acc: 0.6548\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9715\n",
      "Epoch 00034: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.1053 - acc: 0.9715 - val_loss: 2.7833 - val_acc: 0.6171\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9761\n",
      "Epoch 00035: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0891 - acc: 0.9761 - val_loss: 2.4943 - val_acc: 0.6438\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9742\n",
      "Epoch 00036: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.1065 - acc: 0.9742 - val_loss: 2.7003 - val_acc: 0.6240\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9692\n",
      "Epoch 00037: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.1153 - acc: 0.9692 - val_loss: 2.3994 - val_acc: 0.6529\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9786\n",
      "Epoch 00038: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0803 - acc: 0.9786 - val_loss: 2.4537 - val_acc: 0.6597\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9805\n",
      "Epoch 00039: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0781 - acc: 0.9805 - val_loss: 2.3605 - val_acc: 0.6515\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9806\n",
      "Epoch 00040: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0772 - acc: 0.9806 - val_loss: 2.5754 - val_acc: 0.6539\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9826\n",
      "Epoch 00041: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0659 - acc: 0.9826 - val_loss: 2.4738 - val_acc: 0.6375\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9798\n",
      "Epoch 00042: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0775 - acc: 0.9798 - val_loss: 3.0688 - val_acc: 0.6117\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9798\n",
      "Epoch 00043: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0784 - acc: 0.9798 - val_loss: 2.6546 - val_acc: 0.6338\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9813\n",
      "Epoch 00044: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0756 - acc: 0.9813 - val_loss: 2.5637 - val_acc: 0.6401\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9772\n",
      "Epoch 00045: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0876 - acc: 0.9772 - val_loss: 2.4507 - val_acc: 0.6557\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9825\n",
      "Epoch 00046: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0748 - acc: 0.9824 - val_loss: 2.5327 - val_acc: 0.6389\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9825\n",
      "Epoch 00047: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0685 - acc: 0.9825 - val_loss: 2.3964 - val_acc: 0.6688\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9873\n",
      "Epoch 00048: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0550 - acc: 0.9873 - val_loss: 2.5295 - val_acc: 0.6471\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9859\n",
      "Epoch 00049: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0586 - acc: 0.9859 - val_loss: 2.6114 - val_acc: 0.6480\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9824\n",
      "Epoch 00050: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0696 - acc: 0.9824 - val_loss: 2.6006 - val_acc: 0.6462\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9861\n",
      "Epoch 00051: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0555 - acc: 0.9861 - val_loss: 2.4102 - val_acc: 0.6518\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9870\n",
      "Epoch 00052: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0549 - acc: 0.9870 - val_loss: 2.6399 - val_acc: 0.6424\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9818\n",
      "Epoch 00053: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0759 - acc: 0.9818 - val_loss: 2.5844 - val_acc: 0.6431\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9890\n",
      "Epoch 00054: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0524 - acc: 0.9890 - val_loss: 2.4874 - val_acc: 0.6553\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9852\n",
      "Epoch 00055: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0601 - acc: 0.9852 - val_loss: 2.8018 - val_acc: 0.6236\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9868\n",
      "Epoch 00056: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0560 - acc: 0.9868 - val_loss: 2.8525 - val_acc: 0.6394\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9864\n",
      "Epoch 00057: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0598 - acc: 0.9864 - val_loss: 2.8843 - val_acc: 0.6159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9873\n",
      "Epoch 00058: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0542 - acc: 0.9873 - val_loss: 2.5175 - val_acc: 0.6564\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9906\n",
      "Epoch 00059: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0438 - acc: 0.9906 - val_loss: 2.7313 - val_acc: 0.6306\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9875\n",
      "Epoch 00060: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0552 - acc: 0.9875 - val_loss: 2.6527 - val_acc: 0.6401\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9826\n",
      "Epoch 00061: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 175s 5ms/sample - loss: 0.0730 - acc: 0.9826 - val_loss: 2.5812 - val_acc: 0.6450\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9875\n",
      "Epoch 00062: val_loss did not improve from 2.01717\n",
      "36805/36805 [==============================] - 174s 5ms/sample - loss: 0.0544 - acc: 0.9875 - val_loss: 2.5746 - val_acc: 0.6513\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 2.1421 - acc: 0.5566\n",
      "Loss: 2.142140926329394 Accuracy: 0.55659395\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1844 - acc: 0.3616\n",
      "Epoch 00001: val_loss improved from inf to 1.83084, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_3_conv_checkpoint/001-1.8308.hdf5\n",
      "36805/36805 [==============================] - 206s 6ms/sample - loss: 2.1846 - acc: 0.3617 - val_loss: 1.8308 - val_acc: 0.4167\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3555 - acc: 0.5821\n",
      "Epoch 00002: val_loss improved from 1.83084 to 1.23952, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_3_conv_checkpoint/002-1.2395.hdf5\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 1.3556 - acc: 0.5821 - val_loss: 1.2395 - val_acc: 0.6040\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0765 - acc: 0.6675\n",
      "Epoch 00003: val_loss did not improve from 1.23952\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 1.0763 - acc: 0.6675 - val_loss: 1.3879 - val_acc: 0.6056\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9368 - acc: 0.7126\n",
      "Epoch 00004: val_loss improved from 1.23952 to 1.01154, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_3_conv_checkpoint/004-1.0115.hdf5\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.9367 - acc: 0.7126 - val_loss: 1.0115 - val_acc: 0.7088\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8256 - acc: 0.7485\n",
      "Epoch 00005: val_loss did not improve from 1.01154\n",
      "36805/36805 [==============================] - 202s 6ms/sample - loss: 0.8256 - acc: 0.7485 - val_loss: 1.0554 - val_acc: 0.7023\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7395 - acc: 0.7757\n",
      "Epoch 00006: val_loss improved from 1.01154 to 0.84745, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_3_conv_checkpoint/006-0.8474.hdf5\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.7398 - acc: 0.7756 - val_loss: 0.8474 - val_acc: 0.7538\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6531 - acc: 0.8011\n",
      "Epoch 00007: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.6531 - acc: 0.8010 - val_loss: 0.9813 - val_acc: 0.7144\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5781 - acc: 0.8231\n",
      "Epoch 00008: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.5780 - acc: 0.8231 - val_loss: 0.9227 - val_acc: 0.7419\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5011 - acc: 0.8438\n",
      "Epoch 00009: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.5012 - acc: 0.8437 - val_loss: 0.9332 - val_acc: 0.7491\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.8567\n",
      "Epoch 00010: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.4601 - acc: 0.8566 - val_loss: 0.9998 - val_acc: 0.7331\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3919 - acc: 0.8766\n",
      "Epoch 00011: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.3918 - acc: 0.8766 - val_loss: 0.9707 - val_acc: 0.7570\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3464 - acc: 0.8895\n",
      "Epoch 00012: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.3464 - acc: 0.8894 - val_loss: 0.8775 - val_acc: 0.7708\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3274 - acc: 0.8971\n",
      "Epoch 00013: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 203s 6ms/sample - loss: 0.3274 - acc: 0.8971 - val_loss: 1.6554 - val_acc: 0.6594\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2978 - acc: 0.9067\n",
      "Epoch 00014: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.2977 - acc: 0.9068 - val_loss: 0.9973 - val_acc: 0.7577\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2538 - acc: 0.9188\n",
      "Epoch 00015: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.2539 - acc: 0.9188 - val_loss: 1.2426 - val_acc: 0.7265\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2414 - acc: 0.9236\n",
      "Epoch 00016: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.2414 - acc: 0.9236 - val_loss: 0.9720 - val_acc: 0.7792\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2233 - acc: 0.9298\n",
      "Epoch 00017: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.2232 - acc: 0.9298 - val_loss: 1.2417 - val_acc: 0.7242\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1808 - acc: 0.9417\n",
      "Epoch 00018: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1808 - acc: 0.9417 - val_loss: 1.3630 - val_acc: 0.7237\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9417\n",
      "Epoch 00019: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1830 - acc: 0.9416 - val_loss: 1.1445 - val_acc: 0.7703\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1836 - acc: 0.9417\n",
      "Epoch 00020: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1837 - acc: 0.9417 - val_loss: 1.0226 - val_acc: 0.7880\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9452\n",
      "Epoch 00021: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1690 - acc: 0.9453 - val_loss: 1.3017 - val_acc: 0.7491\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9552\n",
      "Epoch 00022: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1389 - acc: 0.9552 - val_loss: 1.1812 - val_acc: 0.7587\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1477 - acc: 0.9533\n",
      "Epoch 00023: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1480 - acc: 0.9532 - val_loss: 1.2233 - val_acc: 0.7650\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1726 - acc: 0.9445\n",
      "Epoch 00024: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1727 - acc: 0.9445 - val_loss: 1.0085 - val_acc: 0.7918\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1185 - acc: 0.9630\n",
      "Epoch 00025: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1185 - acc: 0.9630 - val_loss: 1.1190 - val_acc: 0.7843\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9657\n",
      "Epoch 00026: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1115 - acc: 0.9656 - val_loss: 1.3823 - val_acc: 0.7556\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9598\n",
      "Epoch 00027: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1283 - acc: 0.9598 - val_loss: 1.1184 - val_acc: 0.7885\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9669\n",
      "Epoch 00028: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1069 - acc: 0.9669 - val_loss: 1.1393 - val_acc: 0.7941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9681\n",
      "Epoch 00029: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1041 - acc: 0.9681 - val_loss: 1.1350 - val_acc: 0.7936\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9670\n",
      "Epoch 00030: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1037 - acc: 0.9670 - val_loss: 1.1561 - val_acc: 0.7927\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9699\n",
      "Epoch 00031: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1008 - acc: 0.9699 - val_loss: 1.6398 - val_acc: 0.7277\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9669\n",
      "Epoch 00032: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1037 - acc: 0.9669 - val_loss: 1.0642 - val_acc: 0.8015\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9690\n",
      "Epoch 00033: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1003 - acc: 0.9689 - val_loss: 1.3302 - val_acc: 0.7729\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9714\n",
      "Epoch 00034: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0947 - acc: 0.9714 - val_loss: 1.0864 - val_acc: 0.8032\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9731\n",
      "Epoch 00035: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0911 - acc: 0.9730 - val_loss: 1.2264 - val_acc: 0.7757\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9666\n",
      "Epoch 00036: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.1140 - acc: 0.9666 - val_loss: 0.9941 - val_acc: 0.8116\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9787\n",
      "Epoch 00037: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0711 - acc: 0.9787 - val_loss: 1.1820 - val_acc: 0.7992\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9750\n",
      "Epoch 00038: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0860 - acc: 0.9750 - val_loss: 1.1459 - val_acc: 0.7959\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9774\n",
      "Epoch 00039: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0748 - acc: 0.9774 - val_loss: 1.1253 - val_acc: 0.8055\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9767\n",
      "Epoch 00040: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 201s 5ms/sample - loss: 0.0778 - acc: 0.9767 - val_loss: 1.1252 - val_acc: 0.8027\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9796\n",
      "Epoch 00041: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0694 - acc: 0.9796 - val_loss: 1.3284 - val_acc: 0.7768\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9749\n",
      "Epoch 00042: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0870 - acc: 0.9749 - val_loss: 1.2695 - val_acc: 0.7866\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9768\n",
      "Epoch 00043: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0809 - acc: 0.9768 - val_loss: 1.1210 - val_acc: 0.8085\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9804\n",
      "Epoch 00044: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0647 - acc: 0.9804 - val_loss: 1.0606 - val_acc: 0.8176\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9821\n",
      "Epoch 00045: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0616 - acc: 0.9821 - val_loss: 1.1893 - val_acc: 0.8092\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9796\n",
      "Epoch 00046: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0722 - acc: 0.9796 - val_loss: 1.3813 - val_acc: 0.7785\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9795\n",
      "Epoch 00047: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0709 - acc: 0.9795 - val_loss: 1.5419 - val_acc: 0.7468\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9801\n",
      "Epoch 00048: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0686 - acc: 0.9801 - val_loss: 1.1123 - val_acc: 0.8160\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9811\n",
      "Epoch 00049: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0659 - acc: 0.9811 - val_loss: 1.2158 - val_acc: 0.7922\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9848\n",
      "Epoch 00050: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0540 - acc: 0.9848 - val_loss: 1.2465 - val_acc: 0.8004\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9848\n",
      "Epoch 00051: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0543 - acc: 0.9847 - val_loss: 1.2202 - val_acc: 0.7973\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9804\n",
      "Epoch 00052: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0704 - acc: 0.9804 - val_loss: 1.2888 - val_acc: 0.7906\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9847\n",
      "Epoch 00053: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0550 - acc: 0.9847 - val_loss: 1.2846 - val_acc: 0.8013\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9851\n",
      "Epoch 00054: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0535 - acc: 0.9850 - val_loss: 1.1890 - val_acc: 0.8092\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9814\n",
      "Epoch 00055: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0629 - acc: 0.9814 - val_loss: 1.2067 - val_acc: 0.7976\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9864\n",
      "Epoch 00056: val_loss did not improve from 0.84745\n",
      "36805/36805 [==============================] - 202s 5ms/sample - loss: 0.0509 - acc: 0.9864 - val_loss: 1.2229 - val_acc: 0.8034\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.9862 - acc: 0.7117\n",
      "Loss: 0.98616148430239 Accuracy: 0.7117342\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0423 - acc: 0.3760\n",
      "Epoch 00001: val_loss improved from inf to 1.67544, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_4_conv_checkpoint/001-1.6754.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 2.0422 - acc: 0.3760 - val_loss: 1.6754 - val_acc: 0.4633\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2073 - acc: 0.6219\n",
      "Epoch 00002: val_loss improved from 1.67544 to 0.99712, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_4_conv_checkpoint/002-0.9971.hdf5\n",
      "36805/36805 [==============================] - 210s 6ms/sample - loss: 1.2073 - acc: 0.6219 - val_loss: 0.9971 - val_acc: 0.6958\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9657 - acc: 0.7040\n",
      "Epoch 00003: val_loss improved from 0.99712 to 0.82472, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_4_conv_checkpoint/003-0.8247.hdf5\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.9656 - acc: 0.7040 - val_loss: 0.8247 - val_acc: 0.7454\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7985 - acc: 0.7574\n",
      "Epoch 00004: val_loss did not improve from 0.82472\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.7986 - acc: 0.7574 - val_loss: 0.8483 - val_acc: 0.7442\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6985 - acc: 0.7901\n",
      "Epoch 00005: val_loss improved from 0.82472 to 0.73496, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_4_conv_checkpoint/005-0.7350.hdf5\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.6987 - acc: 0.7900 - val_loss: 0.7350 - val_acc: 0.7801\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6181 - acc: 0.8156\n",
      "Epoch 00006: val_loss improved from 0.73496 to 0.68258, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_4_conv_checkpoint/006-0.6826.hdf5\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.6181 - acc: 0.8156 - val_loss: 0.6826 - val_acc: 0.8018\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5482 - acc: 0.8365\n",
      "Epoch 00007: val_loss did not improve from 0.68258\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 0.5482 - acc: 0.8365 - val_loss: 0.8524 - val_acc: 0.7522\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4980 - acc: 0.8509\n",
      "Epoch 00008: val_loss did not improve from 0.68258\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.4980 - acc: 0.8509 - val_loss: 0.7534 - val_acc: 0.7885\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4540 - acc: 0.8636\n",
      "Epoch 00009: val_loss improved from 0.68258 to 0.64895, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_4_conv_checkpoint/009-0.6489.hdf5\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.4540 - acc: 0.8636 - val_loss: 0.6489 - val_acc: 0.8078\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4202 - acc: 0.8729\n",
      "Epoch 00010: val_loss did not improve from 0.64895\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.4206 - acc: 0.8728 - val_loss: 0.9212 - val_acc: 0.7552\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4054 - acc: 0.8768\n",
      "Epoch 00011: val_loss did not improve from 0.64895\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.4054 - acc: 0.8768 - val_loss: 0.6496 - val_acc: 0.8164\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3640 - acc: 0.8872\n",
      "Epoch 00012: val_loss improved from 0.64895 to 0.50468, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_4_conv_checkpoint/012-0.5047.hdf5\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.3640 - acc: 0.8872 - val_loss: 0.5047 - val_acc: 0.8696\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3391 - acc: 0.8964\n",
      "Epoch 00013: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.3393 - acc: 0.8964 - val_loss: 0.6071 - val_acc: 0.8272\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3307 - acc: 0.9000\n",
      "Epoch 00014: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.3306 - acc: 0.9000 - val_loss: 0.6429 - val_acc: 0.8348\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2986 - acc: 0.9070\n",
      "Epoch 00015: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.2986 - acc: 0.9070 - val_loss: 0.6797 - val_acc: 0.8199\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2805 - acc: 0.9134\n",
      "Epoch 00016: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.2806 - acc: 0.9133 - val_loss: 0.6112 - val_acc: 0.8453\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2727 - acc: 0.9147\n",
      "Epoch 00017: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.2727 - acc: 0.9147 - val_loss: 0.5782 - val_acc: 0.8453\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2509 - acc: 0.9208\n",
      "Epoch 00018: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.2509 - acc: 0.9208 - val_loss: 0.5718 - val_acc: 0.8549\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2512 - acc: 0.9190\n",
      "Epoch 00019: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.2512 - acc: 0.9190 - val_loss: 0.9155 - val_acc: 0.7890\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2205 - acc: 0.9292\n",
      "Epoch 00020: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.2211 - acc: 0.9292 - val_loss: 1.0221 - val_acc: 0.7652\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2362 - acc: 0.9236\n",
      "Epoch 00021: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.2362 - acc: 0.9236 - val_loss: 0.6383 - val_acc: 0.8388\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9364\n",
      "Epoch 00022: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.2005 - acc: 0.9364 - val_loss: 0.6219 - val_acc: 0.8560\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9393\n",
      "Epoch 00023: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1894 - acc: 0.9393 - val_loss: 0.6582 - val_acc: 0.8311\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1858 - acc: 0.9404\n",
      "Epoch 00024: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1860 - acc: 0.9403 - val_loss: 0.6194 - val_acc: 0.8644\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2029 - acc: 0.9348\n",
      "Epoch 00025: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.2029 - acc: 0.9348 - val_loss: 0.6217 - val_acc: 0.8642\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1693 - acc: 0.9450\n",
      "Epoch 00026: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1692 - acc: 0.9450 - val_loss: 0.5703 - val_acc: 0.8698\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1573 - acc: 0.9485\n",
      "Epoch 00027: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1573 - acc: 0.9485 - val_loss: 0.5212 - val_acc: 0.8807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1675 - acc: 0.9465\n",
      "Epoch 00028: val_loss did not improve from 0.50468\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1676 - acc: 0.9464 - val_loss: 0.7336 - val_acc: 0.8376\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1544 - acc: 0.9483\n",
      "Epoch 00029: val_loss improved from 0.50468 to 0.49733, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_4_conv_checkpoint/029-0.4973.hdf5\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1544 - acc: 0.9483 - val_loss: 0.4973 - val_acc: 0.8919\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9512\n",
      "Epoch 00030: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1492 - acc: 0.9512 - val_loss: 0.6223 - val_acc: 0.8649\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9518\n",
      "Epoch 00031: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1501 - acc: 0.9518 - val_loss: 0.5058 - val_acc: 0.8884\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9569\n",
      "Epoch 00032: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1304 - acc: 0.9569 - val_loss: 0.6512 - val_acc: 0.8623\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9585\n",
      "Epoch 00033: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1297 - acc: 0.9585 - val_loss: 1.2822 - val_acc: 0.7605\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9571\n",
      "Epoch 00034: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1292 - acc: 0.9571 - val_loss: 0.7004 - val_acc: 0.8528\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9605\n",
      "Epoch 00035: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1206 - acc: 0.9605 - val_loss: 0.7564 - val_acc: 0.8383\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9593\n",
      "Epoch 00036: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1255 - acc: 0.9594 - val_loss: 0.6881 - val_acc: 0.8551\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9634\n",
      "Epoch 00037: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1103 - acc: 0.9634 - val_loss: 0.5612 - val_acc: 0.8807\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9643\n",
      "Epoch 00038: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1102 - acc: 0.9644 - val_loss: 0.6837 - val_acc: 0.8621\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9635\n",
      "Epoch 00039: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1091 - acc: 0.9635 - val_loss: 0.7857 - val_acc: 0.8463\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9662\n",
      "Epoch 00040: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1036 - acc: 0.9662 - val_loss: 0.6259 - val_acc: 0.8675\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9657\n",
      "Epoch 00041: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1053 - acc: 0.9656 - val_loss: 0.7041 - val_acc: 0.8609\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9682\n",
      "Epoch 00042: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0974 - acc: 0.9681 - val_loss: 0.7077 - val_acc: 0.8612\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9667\n",
      "Epoch 00043: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.1050 - acc: 0.9667 - val_loss: 0.5526 - val_acc: 0.8880\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9716\n",
      "Epoch 00044: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0882 - acc: 0.9716 - val_loss: 0.6521 - val_acc: 0.8751\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9682\n",
      "Epoch 00045: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0987 - acc: 0.9682 - val_loss: 0.6139 - val_acc: 0.8812\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9706\n",
      "Epoch 00046: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0898 - acc: 0.9706 - val_loss: 0.6464 - val_acc: 0.8791\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9730\n",
      "Epoch 00047: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0814 - acc: 0.9730 - val_loss: 0.7270 - val_acc: 0.8710\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9732\n",
      "Epoch 00048: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0869 - acc: 0.9732 - val_loss: 1.2468 - val_acc: 0.7934\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9691\n",
      "Epoch 00049: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0936 - acc: 0.9691 - val_loss: 0.6095 - val_acc: 0.8814\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9745\n",
      "Epoch 00050: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0783 - acc: 0.9745 - val_loss: 0.6396 - val_acc: 0.8831\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9737\n",
      "Epoch 00051: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0801 - acc: 0.9737 - val_loss: 0.6890 - val_acc: 0.8714\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9753\n",
      "Epoch 00052: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0763 - acc: 0.9753 - val_loss: 0.6154 - val_acc: 0.8840\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9749\n",
      "Epoch 00053: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0803 - acc: 0.9749 - val_loss: 0.6680 - val_acc: 0.8737\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9766\n",
      "Epoch 00054: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0732 - acc: 0.9766 - val_loss: 0.6750 - val_acc: 0.8754\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9785\n",
      "Epoch 00055: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0661 - acc: 0.9785 - val_loss: 0.6760 - val_acc: 0.8805\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9782\n",
      "Epoch 00056: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0697 - acc: 0.9782 - val_loss: 0.6895 - val_acc: 0.8705\n",
      "Epoch 57/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9769\n",
      "Epoch 00057: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0722 - acc: 0.9769 - val_loss: 0.8519 - val_acc: 0.8491\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9781\n",
      "Epoch 00058: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0688 - acc: 0.9781 - val_loss: 0.6606 - val_acc: 0.8849\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9780\n",
      "Epoch 00059: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0673 - acc: 0.9780 - val_loss: 0.8110 - val_acc: 0.8553\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9774\n",
      "Epoch 00060: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0703 - acc: 0.9774 - val_loss: 0.6268 - val_acc: 0.8854\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9759\n",
      "Epoch 00061: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0759 - acc: 0.9759 - val_loss: 0.6805 - val_acc: 0.8772\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9780\n",
      "Epoch 00062: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0699 - acc: 0.9780 - val_loss: 0.6619 - val_acc: 0.8873\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9822\n",
      "Epoch 00063: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0561 - acc: 0.9822 - val_loss: 0.7459 - val_acc: 0.8689\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9801\n",
      "Epoch 00064: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 210s 6ms/sample - loss: 0.0631 - acc: 0.9800 - val_loss: 0.6186 - val_acc: 0.8835\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9751\n",
      "Epoch 00065: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0822 - acc: 0.9751 - val_loss: 1.2051 - val_acc: 0.8104\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9812\n",
      "Epoch 00066: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0620 - acc: 0.9812 - val_loss: 0.5779 - val_acc: 0.8945\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9843\n",
      "Epoch 00067: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0519 - acc: 0.9843 - val_loss: 0.7733 - val_acc: 0.8635\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9826\n",
      "Epoch 00068: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0560 - acc: 0.9826 - val_loss: 0.6605 - val_acc: 0.8838\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9804\n",
      "Epoch 00069: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0629 - acc: 0.9804 - val_loss: 0.7782 - val_acc: 0.8605\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9820\n",
      "Epoch 00070: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0573 - acc: 0.9820 - val_loss: 0.6445 - val_acc: 0.8852\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9839\n",
      "Epoch 00071: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0511 - acc: 0.9839 - val_loss: 1.0517 - val_acc: 0.8137\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9810\n",
      "Epoch 00072: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0614 - acc: 0.9809 - val_loss: 0.6667 - val_acc: 0.8852\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9772\n",
      "Epoch 00073: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 210s 6ms/sample - loss: 0.0757 - acc: 0.9772 - val_loss: 0.6424 - val_acc: 0.8786\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9865\n",
      "Epoch 00074: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0436 - acc: 0.9865 - val_loss: 0.6175 - val_acc: 0.8901\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9837\n",
      "Epoch 00075: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0506 - acc: 0.9837 - val_loss: 0.6961 - val_acc: 0.8847\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9839\n",
      "Epoch 00076: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0560 - acc: 0.9839 - val_loss: 0.6638 - val_acc: 0.8877\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9849\n",
      "Epoch 00077: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0502 - acc: 0.9849 - val_loss: 0.6032 - val_acc: 0.8910\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9855\n",
      "Epoch 00078: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0478 - acc: 0.9855 - val_loss: 0.6400 - val_acc: 0.8896\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9811\n",
      "Epoch 00079: val_loss did not improve from 0.49733\n",
      "36805/36805 [==============================] - 211s 6ms/sample - loss: 0.0639 - acc: 0.9811 - val_loss: 0.6992 - val_acc: 0.8854\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.5687 - acc: 0.8656\n",
      "Loss: 0.5686791763622565 Accuracy: 0.86562824\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9975 - acc: 0.3943\n",
      "Epoch 00001: val_loss improved from inf to 1.83088, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_5_conv_checkpoint/001-1.8309.hdf5\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 1.9975 - acc: 0.3942 - val_loss: 1.8309 - val_acc: 0.4354\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2218 - acc: 0.6184\n",
      "Epoch 00002: val_loss improved from 1.83088 to 1.14771, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_5_conv_checkpoint/002-1.1477.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 1.2219 - acc: 0.6183 - val_loss: 1.1477 - val_acc: 0.6564\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9254 - acc: 0.7143\n",
      "Epoch 00003: val_loss improved from 1.14771 to 0.92174, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_5_conv_checkpoint/003-0.9217.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.9255 - acc: 0.7143 - val_loss: 0.9217 - val_acc: 0.7167\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7632 - acc: 0.7697\n",
      "Epoch 00004: val_loss improved from 0.92174 to 0.79879, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_5_conv_checkpoint/004-0.7988.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.7632 - acc: 0.7697 - val_loss: 0.7988 - val_acc: 0.7727\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6455 - acc: 0.8080\n",
      "Epoch 00005: val_loss did not improve from 0.79879\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.6456 - acc: 0.8080 - val_loss: 0.8363 - val_acc: 0.7617\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5672 - acc: 0.8299\n",
      "Epoch 00006: val_loss did not improve from 0.79879\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.5673 - acc: 0.8298 - val_loss: 0.8781 - val_acc: 0.7594\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5202 - acc: 0.8445\n",
      "Epoch 00007: val_loss did not improve from 0.79879\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.5206 - acc: 0.8445 - val_loss: 1.0981 - val_acc: 0.7072\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4618 - acc: 0.8602\n",
      "Epoch 00008: val_loss improved from 0.79879 to 0.52416, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_5_conv_checkpoint/008-0.5242.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.4618 - acc: 0.8602 - val_loss: 0.5242 - val_acc: 0.8570\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4124 - acc: 0.8739\n",
      "Epoch 00009: val_loss did not improve from 0.52416\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.4124 - acc: 0.8739 - val_loss: 0.6273 - val_acc: 0.8379\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3764 - acc: 0.8856\n",
      "Epoch 00010: val_loss improved from 0.52416 to 0.50210, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_5_conv_checkpoint/010-0.5021.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.3763 - acc: 0.8856 - val_loss: 0.5021 - val_acc: 0.8721\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3516 - acc: 0.8937\n",
      "Epoch 00011: val_loss improved from 0.50210 to 0.45241, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_5_conv_checkpoint/011-0.4524.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.3517 - acc: 0.8937 - val_loss: 0.4524 - val_acc: 0.8838\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3319 - acc: 0.8970\n",
      "Epoch 00012: val_loss did not improve from 0.45241\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.3323 - acc: 0.8970 - val_loss: 0.6366 - val_acc: 0.8279\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3120 - acc: 0.9040\n",
      "Epoch 00013: val_loss did not improve from 0.45241\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.3121 - acc: 0.9040 - val_loss: 0.5436 - val_acc: 0.8630\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2824 - acc: 0.9117\n",
      "Epoch 00014: val_loss did not improve from 0.45241\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.2825 - acc: 0.9116 - val_loss: 0.4737 - val_acc: 0.8777\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2721 - acc: 0.9145\n",
      "Epoch 00015: val_loss did not improve from 0.45241\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.2720 - acc: 0.9145 - val_loss: 0.7932 - val_acc: 0.8085\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2490 - acc: 0.9215\n",
      "Epoch 00016: val_loss improved from 0.45241 to 0.40825, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_5_conv_checkpoint/016-0.4083.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.2490 - acc: 0.9215 - val_loss: 0.4083 - val_acc: 0.8952\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2313 - acc: 0.9266\n",
      "Epoch 00017: val_loss did not improve from 0.40825\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.2314 - acc: 0.9266 - val_loss: 0.4694 - val_acc: 0.8854\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2314 - acc: 0.9263\n",
      "Epoch 00018: val_loss did not improve from 0.40825\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.2313 - acc: 0.9263 - val_loss: 0.5384 - val_acc: 0.8642\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2024 - acc: 0.9355\n",
      "Epoch 00019: val_loss did not improve from 0.40825\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.2024 - acc: 0.9355 - val_loss: 0.4642 - val_acc: 0.8891\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9365\n",
      "Epoch 00020: val_loss did not improve from 0.40825\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1962 - acc: 0.9365 - val_loss: 0.4207 - val_acc: 0.8973\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1912 - acc: 0.9386\n",
      "Epoch 00021: val_loss did not improve from 0.40825\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1913 - acc: 0.9386 - val_loss: 0.4408 - val_acc: 0.8910\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1791 - acc: 0.9409\n",
      "Epoch 00022: val_loss did not improve from 0.40825\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1792 - acc: 0.9409 - val_loss: 0.4615 - val_acc: 0.8842\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1687 - acc: 0.9455\n",
      "Epoch 00023: val_loss did not improve from 0.40825\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1691 - acc: 0.9455 - val_loss: 0.5686 - val_acc: 0.8672\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1798 - acc: 0.9413\n",
      "Epoch 00024: val_loss did not improve from 0.40825\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1798 - acc: 0.9413 - val_loss: 0.5078 - val_acc: 0.8742\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9517\n",
      "Epoch 00025: val_loss did not improve from 0.40825\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1497 - acc: 0.9516 - val_loss: 0.4650 - val_acc: 0.8833\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1475 - acc: 0.9510\n",
      "Epoch 00026: val_loss did not improve from 0.40825\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1475 - acc: 0.9510 - val_loss: 0.4301 - val_acc: 0.8910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9540\n",
      "Epoch 00027: val_loss improved from 0.40825 to 0.39379, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_5_conv_checkpoint/027-0.3938.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1420 - acc: 0.9540 - val_loss: 0.3938 - val_acc: 0.9092\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9467\n",
      "Epoch 00028: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1579 - acc: 0.9466 - val_loss: 0.4665 - val_acc: 0.8919\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9547\n",
      "Epoch 00029: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1406 - acc: 0.9547 - val_loss: 0.4198 - val_acc: 0.8975\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9588\n",
      "Epoch 00030: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1268 - acc: 0.9587 - val_loss: 0.4898 - val_acc: 0.8875\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1398 - acc: 0.9538\n",
      "Epoch 00031: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1398 - acc: 0.9538 - val_loss: 0.4203 - val_acc: 0.9012\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9626\n",
      "Epoch 00032: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1127 - acc: 0.9626 - val_loss: 0.5564 - val_acc: 0.8770\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9645\n",
      "Epoch 00033: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1089 - acc: 0.9645 - val_loss: 0.4983 - val_acc: 0.8928\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9646\n",
      "Epoch 00034: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1046 - acc: 0.9646 - val_loss: 0.6298 - val_acc: 0.8586\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9641\n",
      "Epoch 00035: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1088 - acc: 0.9641 - val_loss: 0.4173 - val_acc: 0.9071\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9638\n",
      "Epoch 00036: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1116 - acc: 0.9638 - val_loss: 0.4329 - val_acc: 0.8996\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9681\n",
      "Epoch 00037: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0956 - acc: 0.9681 - val_loss: 1.1852 - val_acc: 0.7859\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9660\n",
      "Epoch 00038: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.1002 - acc: 0.9660 - val_loss: 0.4699 - val_acc: 0.8970\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9698\n",
      "Epoch 00039: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0892 - acc: 0.9698 - val_loss: 0.8458 - val_acc: 0.8491\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9724\n",
      "Epoch 00040: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0837 - acc: 0.9723 - val_loss: 0.6516 - val_acc: 0.8647\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9698\n",
      "Epoch 00041: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0915 - acc: 0.9698 - val_loss: 0.4035 - val_acc: 0.9106\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9731\n",
      "Epoch 00042: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0813 - acc: 0.9731 - val_loss: 0.4836 - val_acc: 0.9036\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9722\n",
      "Epoch 00043: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0837 - acc: 0.9722 - val_loss: 0.5114 - val_acc: 0.9071\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9676\n",
      "Epoch 00044: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0984 - acc: 0.9676 - val_loss: 0.5424 - val_acc: 0.8796\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9750\n",
      "Epoch 00045: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0752 - acc: 0.9750 - val_loss: 0.4141 - val_acc: 0.9154\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9760\n",
      "Epoch 00046: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0696 - acc: 0.9760 - val_loss: 0.4873 - val_acc: 0.9010\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9746\n",
      "Epoch 00047: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0764 - acc: 0.9747 - val_loss: 0.4914 - val_acc: 0.8940\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9758\n",
      "Epoch 00048: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0744 - acc: 0.9757 - val_loss: 0.6051 - val_acc: 0.8754\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9762\n",
      "Epoch 00049: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0731 - acc: 0.9762 - val_loss: 0.4690 - val_acc: 0.9059\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9783\n",
      "Epoch 00050: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0654 - acc: 0.9782 - val_loss: 0.7419 - val_acc: 0.8640\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9765\n",
      "Epoch 00051: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0734 - acc: 0.9765 - val_loss: 0.4443 - val_acc: 0.9117\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9769\n",
      "Epoch 00052: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0708 - acc: 0.9769 - val_loss: 0.4282 - val_acc: 0.9096\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9782\n",
      "Epoch 00053: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0678 - acc: 0.9782 - val_loss: 0.5153 - val_acc: 0.9008\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9773\n",
      "Epoch 00054: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0680 - acc: 0.9773 - val_loss: 0.4367 - val_acc: 0.9185\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9798\n",
      "Epoch 00055: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0602 - acc: 0.9798 - val_loss: 0.4943 - val_acc: 0.9045\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9812\n",
      "Epoch 00056: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0560 - acc: 0.9811 - val_loss: 0.5316 - val_acc: 0.8959\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9789\n",
      "Epoch 00057: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0665 - acc: 0.9789 - val_loss: 0.6750 - val_acc: 0.8593\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9838\n",
      "Epoch 00058: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0504 - acc: 0.9838 - val_loss: 0.4992 - val_acc: 0.8998\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9817\n",
      "Epoch 00059: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0529 - acc: 0.9817 - val_loss: 0.4959 - val_acc: 0.9047\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9783\n",
      "Epoch 00060: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0651 - acc: 0.9783 - val_loss: 0.4864 - val_acc: 0.9103\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9809\n",
      "Epoch 00061: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0582 - acc: 0.9809 - val_loss: 0.7847 - val_acc: 0.8640\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9828\n",
      "Epoch 00062: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0542 - acc: 0.9828 - val_loss: 0.5163 - val_acc: 0.8994\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9834\n",
      "Epoch 00063: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0507 - acc: 0.9834 - val_loss: 0.7682 - val_acc: 0.8689\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9838\n",
      "Epoch 00064: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0506 - acc: 0.9838 - val_loss: 0.4919 - val_acc: 0.8952\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9837\n",
      "Epoch 00065: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0498 - acc: 0.9837 - val_loss: 0.4450 - val_acc: 0.9143\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9845\n",
      "Epoch 00066: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0468 - acc: 0.9845 - val_loss: 1.2242 - val_acc: 0.7932\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9847\n",
      "Epoch 00067: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0472 - acc: 0.9847 - val_loss: 0.6212 - val_acc: 0.8905\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9830\n",
      "Epoch 00068: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0505 - acc: 0.9830 - val_loss: 0.8334 - val_acc: 0.8493\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9848\n",
      "Epoch 00069: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0467 - acc: 0.9848 - val_loss: 0.4059 - val_acc: 0.9231\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9853\n",
      "Epoch 00070: val_loss did not improve from 0.39379\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0470 - acc: 0.9853 - val_loss: 0.7120 - val_acc: 0.8791\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9836\n",
      "Epoch 00071: val_loss improved from 0.39379 to 0.38432, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_5_conv_checkpoint/071-0.3843.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0499 - acc: 0.9836 - val_loss: 0.3843 - val_acc: 0.9255\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9862\n",
      "Epoch 00072: val_loss did not improve from 0.38432\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0448 - acc: 0.9863 - val_loss: 0.5443 - val_acc: 0.8980\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9866\n",
      "Epoch 00073: val_loss did not improve from 0.38432\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0418 - acc: 0.9866 - val_loss: 0.4451 - val_acc: 0.9161\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9843\n",
      "Epoch 00074: val_loss did not improve from 0.38432\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0467 - acc: 0.9843 - val_loss: 0.4984 - val_acc: 0.9040\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9857\n",
      "Epoch 00075: val_loss did not improve from 0.38432\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0447 - acc: 0.9857 - val_loss: 0.5436 - val_acc: 0.9008\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9864\n",
      "Epoch 00076: val_loss did not improve from 0.38432\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0415 - acc: 0.9864 - val_loss: 0.5602 - val_acc: 0.9017\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9838\n",
      "Epoch 00077: val_loss did not improve from 0.38432\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0503 - acc: 0.9837 - val_loss: 0.4809 - val_acc: 0.9140\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9816\n",
      "Epoch 00078: val_loss did not improve from 0.38432\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0544 - acc: 0.9816 - val_loss: 0.4828 - val_acc: 0.9036\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9850\n",
      "Epoch 00079: val_loss did not improve from 0.38432\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0453 - acc: 0.9850 - val_loss: 0.7003 - val_acc: 0.8826\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9853\n",
      "Epoch 00080: val_loss did not improve from 0.38432\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0439 - acc: 0.9853 - val_loss: 0.5430 - val_acc: 0.8998\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9899\n",
      "Epoch 00081: val_loss did not improve from 0.38432\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0322 - acc: 0.9898 - val_loss: 0.4654 - val_acc: 0.9145\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9815\n",
      "Epoch 00082: val_loss improved from 0.38432 to 0.36958, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_5_conv_checkpoint/082-0.3696.hdf5\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0592 - acc: 0.9815 - val_loss: 0.3696 - val_acc: 0.9331\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9910\n",
      "Epoch 00083: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0291 - acc: 0.9910 - val_loss: 0.4033 - val_acc: 0.9308\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9890\n",
      "Epoch 00084: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0335 - acc: 0.9890 - val_loss: 0.3944 - val_acc: 0.9276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9883\n",
      "Epoch 00085: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0363 - acc: 0.9883 - val_loss: 0.4586 - val_acc: 0.9234\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9883\n",
      "Epoch 00086: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0382 - acc: 0.9883 - val_loss: 0.5477 - val_acc: 0.9068\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9883\n",
      "Epoch 00087: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0368 - acc: 0.9883 - val_loss: 0.5430 - val_acc: 0.9068\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9882\n",
      "Epoch 00088: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0361 - acc: 0.9882 - val_loss: 0.4232 - val_acc: 0.9199\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9892\n",
      "Epoch 00089: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0350 - acc: 0.9892 - val_loss: 0.4833 - val_acc: 0.9164\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9899\n",
      "Epoch 00090: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0304 - acc: 0.9899 - val_loss: 0.4815 - val_acc: 0.9122\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9881\n",
      "Epoch 00091: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0376 - acc: 0.9881 - val_loss: 0.4343 - val_acc: 0.9175\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9893\n",
      "Epoch 00092: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0319 - acc: 0.9893 - val_loss: 1.1573 - val_acc: 0.8248\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9894\n",
      "Epoch 00093: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0338 - acc: 0.9894 - val_loss: 0.5468 - val_acc: 0.9068\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9901\n",
      "Epoch 00094: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0314 - acc: 0.9901 - val_loss: 0.4083 - val_acc: 0.9299\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9899\n",
      "Epoch 00095: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0324 - acc: 0.9899 - val_loss: 0.5274 - val_acc: 0.9113\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9880\n",
      "Epoch 00096: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0373 - acc: 0.9880 - val_loss: 0.5143 - val_acc: 0.9159\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9910\n",
      "Epoch 00097: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0284 - acc: 0.9910 - val_loss: 0.6459 - val_acc: 0.8940\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9897\n",
      "Epoch 00098: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0334 - acc: 0.9897 - val_loss: 0.5015 - val_acc: 0.9157\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9904\n",
      "Epoch 00099: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0314 - acc: 0.9903 - val_loss: 0.6507 - val_acc: 0.8898\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9891\n",
      "Epoch 00100: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0330 - acc: 0.9891 - val_loss: 0.4570 - val_acc: 0.9192\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9895\n",
      "Epoch 00101: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0332 - acc: 0.9895 - val_loss: 0.5072 - val_acc: 0.9150\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9913\n",
      "Epoch 00102: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0276 - acc: 0.9913 - val_loss: 0.4181 - val_acc: 0.9266\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9902\n",
      "Epoch 00103: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0307 - acc: 0.9902 - val_loss: 0.5570 - val_acc: 0.9080\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9902\n",
      "Epoch 00104: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0303 - acc: 0.9902 - val_loss: 0.7883 - val_acc: 0.8737\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9886\n",
      "Epoch 00105: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0337 - acc: 0.9886 - val_loss: 0.4320 - val_acc: 0.9269\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9918\n",
      "Epoch 00106: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0264 - acc: 0.9917 - val_loss: 0.5263 - val_acc: 0.9145\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9893\n",
      "Epoch 00107: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0333 - acc: 0.9893 - val_loss: 0.4085 - val_acc: 0.9294\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9923\n",
      "Epoch 00108: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0260 - acc: 0.9923 - val_loss: 0.9981 - val_acc: 0.8535\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9895\n",
      "Epoch 00109: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0343 - acc: 0.9895 - val_loss: 0.6798 - val_acc: 0.8963\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9930\n",
      "Epoch 00110: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0242 - acc: 0.9930 - val_loss: 0.4287 - val_acc: 0.9236\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9906\n",
      "Epoch 00111: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0298 - acc: 0.9906 - val_loss: 3.0167 - val_acc: 0.6685\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9920\n",
      "Epoch 00112: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0266 - acc: 0.9920 - val_loss: 0.5858 - val_acc: 0.9022\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9906\n",
      "Epoch 00113: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0297 - acc: 0.9906 - val_loss: 0.5947 - val_acc: 0.9071\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9912\n",
      "Epoch 00114: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0304 - acc: 0.9912 - val_loss: 0.7591 - val_acc: 0.8842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9921\n",
      "Epoch 00115: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0257 - acc: 0.9921 - val_loss: 0.4649 - val_acc: 0.9231\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9923\n",
      "Epoch 00116: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0249 - acc: 0.9922 - val_loss: 0.4568 - val_acc: 0.9189\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9890\n",
      "Epoch 00117: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0356 - acc: 0.9890 - val_loss: 0.4193 - val_acc: 0.9317\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9907\n",
      "Epoch 00118: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0298 - acc: 0.9907 - val_loss: 0.5734 - val_acc: 0.9094\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9927\n",
      "Epoch 00119: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0237 - acc: 0.9927 - val_loss: 0.6106 - val_acc: 0.9012\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9931\n",
      "Epoch 00120: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0223 - acc: 0.9931 - val_loss: 0.4045 - val_acc: 0.9278\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9919\n",
      "Epoch 00121: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0266 - acc: 0.9919 - val_loss: 0.4951 - val_acc: 0.9187\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9914\n",
      "Epoch 00122: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0266 - acc: 0.9914 - val_loss: 0.6551 - val_acc: 0.8954\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9921\n",
      "Epoch 00123: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0246 - acc: 0.9920 - val_loss: 0.4916 - val_acc: 0.9213\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9894\n",
      "Epoch 00124: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0335 - acc: 0.9894 - val_loss: 0.4303 - val_acc: 0.9301\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9919\n",
      "Epoch 00125: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0283 - acc: 0.9919 - val_loss: 0.4609 - val_acc: 0.9194\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9926\n",
      "Epoch 00126: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0235 - acc: 0.9926 - val_loss: 1.2804 - val_acc: 0.8286\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9942\n",
      "Epoch 00127: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0196 - acc: 0.9942 - val_loss: 0.5511 - val_acc: 0.9089\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9891\n",
      "Epoch 00128: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0353 - acc: 0.9891 - val_loss: 0.5502 - val_acc: 0.9071\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9937\n",
      "Epoch 00129: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0203 - acc: 0.9937 - val_loss: 0.4686 - val_acc: 0.9250\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9922\n",
      "Epoch 00130: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0250 - acc: 0.9922 - val_loss: 0.4490 - val_acc: 0.9257\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9929\n",
      "Epoch 00131: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 215s 6ms/sample - loss: 0.0223 - acc: 0.9929 - val_loss: 0.4921 - val_acc: 0.9180\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9910\n",
      "Epoch 00132: val_loss did not improve from 0.36958\n",
      "36805/36805 [==============================] - 214s 6ms/sample - loss: 0.0298 - acc: 0.9909 - val_loss: 2.3636 - val_acc: 0.7144\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4731 - acc: 0.9094\n",
      "Loss: 0.4730949756233863 Accuracy: 0.90944964\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2091 - acc: 0.3247\n",
      "Epoch 00001: val_loss improved from inf to 1.65103, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_6_conv_checkpoint/001-1.6510.hdf5\n",
      "36805/36805 [==============================] - 225s 6ms/sample - loss: 2.2090 - acc: 0.3247 - val_loss: 1.6510 - val_acc: 0.4789\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2965 - acc: 0.5862\n",
      "Epoch 00002: val_loss improved from 1.65103 to 0.98329, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_6_conv_checkpoint/002-0.9833.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 1.2965 - acc: 0.5863 - val_loss: 0.9833 - val_acc: 0.7018\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9594 - acc: 0.7023\n",
      "Epoch 00003: val_loss improved from 0.98329 to 0.75948, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_6_conv_checkpoint/003-0.7595.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.9594 - acc: 0.7023 - val_loss: 0.7595 - val_acc: 0.7675\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7515 - acc: 0.7739\n",
      "Epoch 00004: val_loss improved from 0.75948 to 0.63121, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_6_conv_checkpoint/004-0.6312.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.7515 - acc: 0.7740 - val_loss: 0.6312 - val_acc: 0.8064\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6368 - acc: 0.8088\n",
      "Epoch 00005: val_loss improved from 0.63121 to 0.52944, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_6_conv_checkpoint/005-0.5294.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.6368 - acc: 0.8088 - val_loss: 0.5294 - val_acc: 0.8512\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5472 - acc: 0.8345\n",
      "Epoch 00006: val_loss did not improve from 0.52944\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.5472 - acc: 0.8345 - val_loss: 0.8716 - val_acc: 0.7526\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4878 - acc: 0.8525\n",
      "Epoch 00007: val_loss improved from 0.52944 to 0.41258, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_6_conv_checkpoint/007-0.4126.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.4879 - acc: 0.8525 - val_loss: 0.4126 - val_acc: 0.8849\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4352 - acc: 0.8685\n",
      "Epoch 00008: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.4351 - acc: 0.8685 - val_loss: 0.6183 - val_acc: 0.8272\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3931 - acc: 0.8799\n",
      "Epoch 00009: val_loss improved from 0.41258 to 0.35153, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_6_conv_checkpoint/009-0.3515.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.3931 - acc: 0.8799 - val_loss: 0.3515 - val_acc: 0.9017\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3685 - acc: 0.8876\n",
      "Epoch 00010: val_loss did not improve from 0.35153\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.3685 - acc: 0.8877 - val_loss: 0.3547 - val_acc: 0.9024\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3337 - acc: 0.8993\n",
      "Epoch 00011: val_loss did not improve from 0.35153\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.3338 - acc: 0.8993 - val_loss: 0.4068 - val_acc: 0.8782\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3237 - acc: 0.8989\n",
      "Epoch 00012: val_loss improved from 0.35153 to 0.31407, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_6_conv_checkpoint/012-0.3141.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.3237 - acc: 0.8989 - val_loss: 0.3141 - val_acc: 0.9085\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2797 - acc: 0.9140\n",
      "Epoch 00013: val_loss did not improve from 0.31407\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.2797 - acc: 0.9140 - val_loss: 0.4424 - val_acc: 0.8796\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2691 - acc: 0.9169\n",
      "Epoch 00014: val_loss did not improve from 0.31407\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.2692 - acc: 0.9168 - val_loss: 0.3355 - val_acc: 0.9054\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2525 - acc: 0.9217\n",
      "Epoch 00015: val_loss did not improve from 0.31407\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.2525 - acc: 0.9216 - val_loss: 0.5261 - val_acc: 0.8570\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2441 - acc: 0.9248\n",
      "Epoch 00016: val_loss did not improve from 0.31407\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.2442 - acc: 0.9248 - val_loss: 0.5039 - val_acc: 0.8598\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2265 - acc: 0.9288\n",
      "Epoch 00017: val_loss did not improve from 0.31407\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.2265 - acc: 0.9288 - val_loss: 0.3591 - val_acc: 0.9005\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2129 - acc: 0.9323\n",
      "Epoch 00018: val_loss improved from 0.31407 to 0.30425, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_6_conv_checkpoint/018-0.3042.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.2129 - acc: 0.9323 - val_loss: 0.3042 - val_acc: 0.9106\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9368\n",
      "Epoch 00019: val_loss did not improve from 0.30425\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1966 - acc: 0.9368 - val_loss: 0.5894 - val_acc: 0.8539\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1913 - acc: 0.9400\n",
      "Epoch 00020: val_loss did not improve from 0.30425\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1913 - acc: 0.9400 - val_loss: 0.3179 - val_acc: 0.9248\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9438\n",
      "Epoch 00021: val_loss did not improve from 0.30425\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1762 - acc: 0.9438 - val_loss: 0.3891 - val_acc: 0.8994\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1698 - acc: 0.9463\n",
      "Epoch 00022: val_loss did not improve from 0.30425\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1698 - acc: 0.9463 - val_loss: 0.3481 - val_acc: 0.9068\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9493\n",
      "Epoch 00023: val_loss improved from 0.30425 to 0.27401, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_6_conv_checkpoint/023-0.2740.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1595 - acc: 0.9493 - val_loss: 0.2740 - val_acc: 0.9348\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1610 - acc: 0.9483\n",
      "Epoch 00024: val_loss did not improve from 0.27401\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1611 - acc: 0.9483 - val_loss: 0.3716 - val_acc: 0.9003\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1568 - acc: 0.9509\n",
      "Epoch 00025: val_loss did not improve from 0.27401\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1568 - acc: 0.9509 - val_loss: 0.3109 - val_acc: 0.9224\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9558\n",
      "Epoch 00026: val_loss did not improve from 0.27401\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1400 - acc: 0.9558 - val_loss: 0.2777 - val_acc: 0.9317\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1347 - acc: 0.9567\n",
      "Epoch 00027: val_loss improved from 0.27401 to 0.26942, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_6_conv_checkpoint/027-0.2694.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1348 - acc: 0.9567 - val_loss: 0.2694 - val_acc: 0.9355\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9563\n",
      "Epoch 00028: val_loss did not improve from 0.26942\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1358 - acc: 0.9563 - val_loss: 0.3011 - val_acc: 0.9266\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9596\n",
      "Epoch 00029: val_loss did not improve from 0.26942\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1235 - acc: 0.9596 - val_loss: 0.2812 - val_acc: 0.9231\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9605\n",
      "Epoch 00030: val_loss did not improve from 0.26942\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1187 - acc: 0.9605 - val_loss: 0.4957 - val_acc: 0.8765\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9578\n",
      "Epoch 00031: val_loss did not improve from 0.26942\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1308 - acc: 0.9578 - val_loss: 0.3843 - val_acc: 0.9045\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9629\n",
      "Epoch 00032: val_loss did not improve from 0.26942\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1139 - acc: 0.9629 - val_loss: 0.3725 - val_acc: 0.9113\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9630\n",
      "Epoch 00033: val_loss did not improve from 0.26942\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1100 - acc: 0.9630 - val_loss: 0.2844 - val_acc: 0.9331\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9665\n",
      "Epoch 00034: val_loss did not improve from 0.26942\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1062 - acc: 0.9665 - val_loss: 0.2725 - val_acc: 0.9350\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9641\n",
      "Epoch 00035: val_loss improved from 0.26942 to 0.24382, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_6_conv_checkpoint/035-0.2438.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1076 - acc: 0.9641 - val_loss: 0.2438 - val_acc: 0.9443\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9692\n",
      "Epoch 00036: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0949 - acc: 0.9692 - val_loss: 0.3554 - val_acc: 0.9175\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9666\n",
      "Epoch 00037: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1015 - acc: 0.9666 - val_loss: 0.2897 - val_acc: 0.9311\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9690\n",
      "Epoch 00038: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0971 - acc: 0.9690 - val_loss: 0.4655 - val_acc: 0.8791\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9708\n",
      "Epoch 00039: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0918 - acc: 0.9707 - val_loss: 0.5664 - val_acc: 0.8665\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9661\n",
      "Epoch 00040: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1049 - acc: 0.9661 - val_loss: 0.2621 - val_acc: 0.9399\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9737\n",
      "Epoch 00041: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0792 - acc: 0.9738 - val_loss: 0.3665 - val_acc: 0.9124\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9743\n",
      "Epoch 00042: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0777 - acc: 0.9743 - val_loss: 0.2766 - val_acc: 0.9390\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9730\n",
      "Epoch 00043: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0808 - acc: 0.9730 - val_loss: 0.2685 - val_acc: 0.9425\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9713\n",
      "Epoch 00044: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0867 - acc: 0.9713 - val_loss: 0.4735 - val_acc: 0.8800\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9755\n",
      "Epoch 00045: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0738 - acc: 0.9755 - val_loss: 0.2961 - val_acc: 0.9220\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9765\n",
      "Epoch 00046: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0733 - acc: 0.9764 - val_loss: 0.4220 - val_acc: 0.9059\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9742\n",
      "Epoch 00047: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0790 - acc: 0.9742 - val_loss: 0.2804 - val_acc: 0.9350\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9772\n",
      "Epoch 00048: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0694 - acc: 0.9772 - val_loss: 0.5555 - val_acc: 0.8747\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9774\n",
      "Epoch 00049: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0677 - acc: 0.9774 - val_loss: 0.3014 - val_acc: 0.9373\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9766\n",
      "Epoch 00050: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0717 - acc: 0.9766 - val_loss: 0.6653 - val_acc: 0.8532\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9767\n",
      "Epoch 00051: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0732 - acc: 0.9767 - val_loss: 0.3128 - val_acc: 0.9266\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9803\n",
      "Epoch 00052: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0609 - acc: 0.9803 - val_loss: 0.5777 - val_acc: 0.8772\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9801\n",
      "Epoch 00053: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0597 - acc: 0.9801 - val_loss: 0.4210 - val_acc: 0.9103\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9781\n",
      "Epoch 00054: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0663 - acc: 0.9781 - val_loss: 0.5538 - val_acc: 0.8868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9793\n",
      "Epoch 00055: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0607 - acc: 0.9793 - val_loss: 0.5438 - val_acc: 0.8924\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9811\n",
      "Epoch 00056: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0578 - acc: 0.9811 - val_loss: 0.3270 - val_acc: 0.9283\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9814\n",
      "Epoch 00057: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0593 - acc: 0.9813 - val_loss: 0.3813 - val_acc: 0.9108\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9802\n",
      "Epoch 00058: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0610 - acc: 0.9802 - val_loss: 0.3177 - val_acc: 0.9271\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9830\n",
      "Epoch 00059: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0532 - acc: 0.9830 - val_loss: 0.3240 - val_acc: 0.9306\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9797\n",
      "Epoch 00060: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0618 - acc: 0.9796 - val_loss: 0.3189 - val_acc: 0.9276\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9817\n",
      "Epoch 00061: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0560 - acc: 0.9817 - val_loss: 0.5799 - val_acc: 0.8800\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9816\n",
      "Epoch 00062: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0549 - acc: 0.9816 - val_loss: 0.3491 - val_acc: 0.9213\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9853\n",
      "Epoch 00063: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0459 - acc: 0.9853 - val_loss: 0.7713 - val_acc: 0.8605\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9837\n",
      "Epoch 00064: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0482 - acc: 0.9837 - val_loss: 1.3135 - val_acc: 0.7885\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9824\n",
      "Epoch 00065: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0534 - acc: 0.9824 - val_loss: 0.3037 - val_acc: 0.9387\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9849\n",
      "Epoch 00066: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0475 - acc: 0.9849 - val_loss: 0.4115 - val_acc: 0.9129\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9855\n",
      "Epoch 00067: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0449 - acc: 0.9855 - val_loss: 1.3695 - val_acc: 0.7848\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9827\n",
      "Epoch 00068: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0538 - acc: 0.9827 - val_loss: 0.5210 - val_acc: 0.8931\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9868\n",
      "Epoch 00069: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0431 - acc: 0.9868 - val_loss: 0.3237 - val_acc: 0.9387\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9850\n",
      "Epoch 00070: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0453 - acc: 0.9850 - val_loss: 0.2693 - val_acc: 0.9453\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9860\n",
      "Epoch 00071: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0426 - acc: 0.9860 - val_loss: 0.4740 - val_acc: 0.9057\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9873\n",
      "Epoch 00072: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0400 - acc: 0.9873 - val_loss: 0.5944 - val_acc: 0.8898\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9841\n",
      "Epoch 00073: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0468 - acc: 0.9841 - val_loss: 0.2804 - val_acc: 0.9418\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9848\n",
      "Epoch 00074: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0459 - acc: 0.9848 - val_loss: 0.4064 - val_acc: 0.9147\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9853\n",
      "Epoch 00075: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0432 - acc: 0.9853 - val_loss: 0.3295 - val_acc: 0.9315\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9878\n",
      "Epoch 00076: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0396 - acc: 0.9878 - val_loss: 0.6501 - val_acc: 0.8805\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9874\n",
      "Epoch 00077: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0391 - acc: 0.9874 - val_loss: 0.4179 - val_acc: 0.9210\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9888\n",
      "Epoch 00078: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0354 - acc: 0.9888 - val_loss: 0.8922 - val_acc: 0.8437\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9844\n",
      "Epoch 00079: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0488 - acc: 0.9843 - val_loss: 0.4549 - val_acc: 0.9182\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9868\n",
      "Epoch 00080: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0409 - acc: 0.9868 - val_loss: 0.2982 - val_acc: 0.9448\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9890\n",
      "Epoch 00081: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0345 - acc: 0.9890 - val_loss: 0.9045 - val_acc: 0.8316\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9884\n",
      "Epoch 00082: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0371 - acc: 0.9884 - val_loss: 0.5647 - val_acc: 0.8912\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9890\n",
      "Epoch 00083: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0354 - acc: 0.9889 - val_loss: 0.2926 - val_acc: 0.9418\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9854\n",
      "Epoch 00084: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0448 - acc: 0.9854 - val_loss: 0.4753 - val_acc: 0.9047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9858\n",
      "Epoch 00085: val_loss did not improve from 0.24382\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0425 - acc: 0.9858 - val_loss: 0.5061 - val_acc: 0.9099\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3006 - acc: 0.9202\n",
      "Loss: 0.3006058562334205 Accuracy: 0.9202492\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4963 - acc: 0.2515\n",
      "Epoch 00001: val_loss improved from inf to 1.91124, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/001-1.9112.hdf5\n",
      "36805/36805 [==============================] - 230s 6ms/sample - loss: 2.4963 - acc: 0.2515 - val_loss: 1.9112 - val_acc: 0.3811\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5269 - acc: 0.5076\n",
      "Epoch 00002: val_loss improved from 1.91124 to 1.15478, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/002-1.1548.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 1.5270 - acc: 0.5076 - val_loss: 1.1548 - val_acc: 0.6380\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1000 - acc: 0.6522\n",
      "Epoch 00003: val_loss improved from 1.15478 to 0.86941, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/003-0.8694.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 1.1004 - acc: 0.6522 - val_loss: 0.8694 - val_acc: 0.7433\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8650 - acc: 0.7347\n",
      "Epoch 00004: val_loss improved from 0.86941 to 0.61293, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/004-0.6129.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.8649 - acc: 0.7348 - val_loss: 0.6129 - val_acc: 0.8283\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6867 - acc: 0.7909\n",
      "Epoch 00005: val_loss did not improve from 0.61293\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.6868 - acc: 0.7909 - val_loss: 0.8487 - val_acc: 0.7673\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5791 - acc: 0.8262\n",
      "Epoch 00006: val_loss improved from 0.61293 to 0.45135, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/006-0.4514.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.5791 - acc: 0.8262 - val_loss: 0.4514 - val_acc: 0.8733\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4965 - acc: 0.8498\n",
      "Epoch 00007: val_loss did not improve from 0.45135\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.4964 - acc: 0.8498 - val_loss: 0.6502 - val_acc: 0.8258\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4511 - acc: 0.8621\n",
      "Epoch 00008: val_loss improved from 0.45135 to 0.43541, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/008-0.4354.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.4510 - acc: 0.8621 - val_loss: 0.4354 - val_acc: 0.8696\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4053 - acc: 0.8775\n",
      "Epoch 00009: val_loss improved from 0.43541 to 0.38459, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/009-0.3846.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.4053 - acc: 0.8775 - val_loss: 0.3846 - val_acc: 0.8833\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3640 - acc: 0.8904\n",
      "Epoch 00010: val_loss improved from 0.38459 to 0.29173, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/010-0.2917.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.3640 - acc: 0.8904 - val_loss: 0.2917 - val_acc: 0.9173\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3264 - acc: 0.9006\n",
      "Epoch 00011: val_loss did not improve from 0.29173\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.3264 - acc: 0.9006 - val_loss: 0.3911 - val_acc: 0.8903\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3030 - acc: 0.9068\n",
      "Epoch 00012: val_loss did not improve from 0.29173\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.3030 - acc: 0.9068 - val_loss: 0.3032 - val_acc: 0.9171\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2842 - acc: 0.9129\n",
      "Epoch 00013: val_loss did not improve from 0.29173\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.2841 - acc: 0.9129 - val_loss: 0.3566 - val_acc: 0.9094\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2585 - acc: 0.9198\n",
      "Epoch 00014: val_loss improved from 0.29173 to 0.25407, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/014-0.2541.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.2586 - acc: 0.9198 - val_loss: 0.2541 - val_acc: 0.9304\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2460 - acc: 0.9240\n",
      "Epoch 00015: val_loss did not improve from 0.25407\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.2464 - acc: 0.9239 - val_loss: 0.2757 - val_acc: 0.9217\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2350 - acc: 0.9281\n",
      "Epoch 00016: val_loss did not improve from 0.25407\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.2349 - acc: 0.9281 - val_loss: 0.2813 - val_acc: 0.9259\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2149 - acc: 0.9347\n",
      "Epoch 00017: val_loss did not improve from 0.25407\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.2149 - acc: 0.9347 - val_loss: 0.9487 - val_acc: 0.7761\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9327\n",
      "Epoch 00018: val_loss did not improve from 0.25407\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.2133 - acc: 0.9327 - val_loss: 0.5820 - val_acc: 0.8400\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1933 - acc: 0.9404\n",
      "Epoch 00019: val_loss did not improve from 0.25407\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1933 - acc: 0.9404 - val_loss: 0.2580 - val_acc: 0.9243\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1871 - acc: 0.9402\n",
      "Epoch 00020: val_loss improved from 0.25407 to 0.22392, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/020-0.2239.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1871 - acc: 0.9402 - val_loss: 0.2239 - val_acc: 0.9387\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1784 - acc: 0.9455\n",
      "Epoch 00021: val_loss improved from 0.22392 to 0.21331, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/021-0.2133.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1785 - acc: 0.9455 - val_loss: 0.2133 - val_acc: 0.9385\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1692 - acc: 0.9466\n",
      "Epoch 00022: val_loss did not improve from 0.21331\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1692 - acc: 0.9466 - val_loss: 0.2298 - val_acc: 0.9362\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9520\n",
      "Epoch 00023: val_loss improved from 0.21331 to 0.20916, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/023-0.2092.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1547 - acc: 0.9520 - val_loss: 0.2092 - val_acc: 0.9446\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9539\n",
      "Epoch 00024: val_loss did not improve from 0.20916\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1468 - acc: 0.9539 - val_loss: 0.2663 - val_acc: 0.9252\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9552\n",
      "Epoch 00025: val_loss did not improve from 0.20916\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1420 - acc: 0.9552 - val_loss: 0.9255 - val_acc: 0.7771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9550\n",
      "Epoch 00026: val_loss did not improve from 0.20916\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1362 - acc: 0.9550 - val_loss: 0.5443 - val_acc: 0.8565\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9594\n",
      "Epoch 00027: val_loss improved from 0.20916 to 0.18264, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/027-0.1826.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1279 - acc: 0.9594 - val_loss: 0.1826 - val_acc: 0.9546\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1318 - acc: 0.9579\n",
      "Epoch 00028: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1318 - acc: 0.9579 - val_loss: 0.2670 - val_acc: 0.9290\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9638\n",
      "Epoch 00029: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1151 - acc: 0.9638 - val_loss: 0.2317 - val_acc: 0.9415\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9630\n",
      "Epoch 00030: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1146 - acc: 0.9630 - val_loss: 0.3008 - val_acc: 0.9213\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9624\n",
      "Epoch 00031: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.1164 - acc: 0.9623 - val_loss: 0.2227 - val_acc: 0.9425\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9618\n",
      "Epoch 00032: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1194 - acc: 0.9618 - val_loss: 0.2628 - val_acc: 0.9306\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9660\n",
      "Epoch 00033: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.1059 - acc: 0.9660 - val_loss: 1.6101 - val_acc: 0.7174\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9685\n",
      "Epoch 00034: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0980 - acc: 0.9685 - val_loss: 0.2184 - val_acc: 0.9450\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9706\n",
      "Epoch 00035: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0928 - acc: 0.9706 - val_loss: 0.2116 - val_acc: 0.9427\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9705\n",
      "Epoch 00036: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0912 - acc: 0.9705 - val_loss: 0.2579 - val_acc: 0.9329\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9694\n",
      "Epoch 00037: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0917 - acc: 0.9693 - val_loss: 0.1952 - val_acc: 0.9483\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9706\n",
      "Epoch 00038: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0891 - acc: 0.9705 - val_loss: 0.3629 - val_acc: 0.9050\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9696\n",
      "Epoch 00039: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0926 - acc: 0.9695 - val_loss: 0.2352 - val_acc: 0.9401\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9723\n",
      "Epoch 00040: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0846 - acc: 0.9723 - val_loss: 0.1953 - val_acc: 0.9532\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9758\n",
      "Epoch 00041: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0741 - acc: 0.9758 - val_loss: 0.2217 - val_acc: 0.9450\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9725\n",
      "Epoch 00042: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0828 - acc: 0.9725 - val_loss: 0.2283 - val_acc: 0.9415\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9764\n",
      "Epoch 00043: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0722 - acc: 0.9764 - val_loss: 0.1883 - val_acc: 0.9476\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9787\n",
      "Epoch 00044: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0663 - acc: 0.9787 - val_loss: 0.2819 - val_acc: 0.9257\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9780\n",
      "Epoch 00045: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0675 - acc: 0.9780 - val_loss: 0.3137 - val_acc: 0.9164\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9775\n",
      "Epoch 00046: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0705 - acc: 0.9775 - val_loss: 0.2460 - val_acc: 0.9355\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9787\n",
      "Epoch 00047: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0659 - acc: 0.9787 - val_loss: 0.4084 - val_acc: 0.8915\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9795\n",
      "Epoch 00048: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0650 - acc: 0.9795 - val_loss: 0.2713 - val_acc: 0.9355\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9799\n",
      "Epoch 00049: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0610 - acc: 0.9799 - val_loss: 0.3713 - val_acc: 0.9106\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9813\n",
      "Epoch 00050: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0581 - acc: 0.9813 - val_loss: 0.1954 - val_acc: 0.9488\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9808\n",
      "Epoch 00051: val_loss did not improve from 0.18264\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0589 - acc: 0.9808 - val_loss: 0.3029 - val_acc: 0.9234\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9801\n",
      "Epoch 00052: val_loss improved from 0.18264 to 0.17970, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/052-0.1797.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0597 - acc: 0.9801 - val_loss: 0.1797 - val_acc: 0.9529\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9838\n",
      "Epoch 00053: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0515 - acc: 0.9838 - val_loss: 0.9938 - val_acc: 0.7983\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9821\n",
      "Epoch 00054: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0539 - acc: 0.9821 - val_loss: 0.2338 - val_acc: 0.9488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9820\n",
      "Epoch 00055: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0549 - acc: 0.9820 - val_loss: 0.2154 - val_acc: 0.9434\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9822\n",
      "Epoch 00056: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0548 - acc: 0.9822 - val_loss: 0.4080 - val_acc: 0.9015\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9827\n",
      "Epoch 00057: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0533 - acc: 0.9827 - val_loss: 2.1289 - val_acc: 0.7088\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9837\n",
      "Epoch 00058: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0494 - acc: 0.9838 - val_loss: 0.1885 - val_acc: 0.9518\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9858\n",
      "Epoch 00059: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0456 - acc: 0.9858 - val_loss: 0.2063 - val_acc: 0.9539\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9821\n",
      "Epoch 00060: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0539 - acc: 0.9821 - val_loss: 0.2625 - val_acc: 0.9399\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9854\n",
      "Epoch 00061: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0458 - acc: 0.9854 - val_loss: 0.2143 - val_acc: 0.9520\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9853\n",
      "Epoch 00062: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0449 - acc: 0.9853 - val_loss: 0.2082 - val_acc: 0.9478\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9859\n",
      "Epoch 00063: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0428 - acc: 0.9859 - val_loss: 0.2556 - val_acc: 0.9429\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9861\n",
      "Epoch 00064: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0427 - acc: 0.9861 - val_loss: 0.6618 - val_acc: 0.8500\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9816\n",
      "Epoch 00065: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0594 - acc: 0.9816 - val_loss: 0.2121 - val_acc: 0.9497\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9878\n",
      "Epoch 00066: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0390 - acc: 0.9878 - val_loss: 0.1804 - val_acc: 0.9567\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9880\n",
      "Epoch 00067: val_loss did not improve from 0.17970\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0376 - acc: 0.9880 - val_loss: 0.2495 - val_acc: 0.9420\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9869\n",
      "Epoch 00068: val_loss improved from 0.17970 to 0.17434, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/068-0.1743.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0402 - acc: 0.9869 - val_loss: 0.1743 - val_acc: 0.9567\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9863\n",
      "Epoch 00069: val_loss did not improve from 0.17434\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0436 - acc: 0.9863 - val_loss: 0.1882 - val_acc: 0.9529\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9875\n",
      "Epoch 00070: val_loss did not improve from 0.17434\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0386 - acc: 0.9875 - val_loss: 0.2427 - val_acc: 0.9397\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9888\n",
      "Epoch 00071: val_loss did not improve from 0.17434\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0360 - acc: 0.9888 - val_loss: 0.2024 - val_acc: 0.9546\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9889\n",
      "Epoch 00072: val_loss did not improve from 0.17434\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0359 - acc: 0.9889 - val_loss: 0.1892 - val_acc: 0.9588\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9879\n",
      "Epoch 00073: val_loss did not improve from 0.17434\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0379 - acc: 0.9879 - val_loss: 0.2154 - val_acc: 0.9483\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9896\n",
      "Epoch 00074: val_loss did not improve from 0.17434\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0325 - acc: 0.9896 - val_loss: 0.2259 - val_acc: 0.9492\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9860\n",
      "Epoch 00075: val_loss did not improve from 0.17434\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0450 - acc: 0.9860 - val_loss: 0.1899 - val_acc: 0.9518\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9900\n",
      "Epoch 00076: val_loss improved from 0.17434 to 0.17364, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/076-0.1736.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0335 - acc: 0.9900 - val_loss: 0.1736 - val_acc: 0.9597\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9901\n",
      "Epoch 00077: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0310 - acc: 0.9901 - val_loss: 0.1944 - val_acc: 0.9560\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9905\n",
      "Epoch 00078: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0294 - acc: 0.9905 - val_loss: 0.1987 - val_acc: 0.9553\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9896\n",
      "Epoch 00079: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0338 - acc: 0.9896 - val_loss: 0.2816 - val_acc: 0.9376\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9845\n",
      "Epoch 00080: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0479 - acc: 0.9845 - val_loss: 0.2508 - val_acc: 0.9406\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9869\n",
      "Epoch 00081: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0402 - acc: 0.9869 - val_loss: 0.2208 - val_acc: 0.9478\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9923\n",
      "Epoch 00082: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0251 - acc: 0.9923 - val_loss: 0.2108 - val_acc: 0.9532\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9902\n",
      "Epoch 00083: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0309 - acc: 0.9901 - val_loss: 0.2731 - val_acc: 0.9446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9879\n",
      "Epoch 00084: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0365 - acc: 0.9879 - val_loss: 0.1857 - val_acc: 0.9590\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9911\n",
      "Epoch 00085: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0274 - acc: 0.9910 - val_loss: 0.3022 - val_acc: 0.9329\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9835\n",
      "Epoch 00086: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0504 - acc: 0.9835 - val_loss: 0.4995 - val_acc: 0.8954\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9894\n",
      "Epoch 00087: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0342 - acc: 0.9894 - val_loss: 0.1828 - val_acc: 0.9595\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9932\n",
      "Epoch 00088: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0230 - acc: 0.9931 - val_loss: 0.1820 - val_acc: 0.9581\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9909\n",
      "Epoch 00089: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0298 - acc: 0.9909 - val_loss: 0.4205 - val_acc: 0.9166\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9908\n",
      "Epoch 00090: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0275 - acc: 0.9908 - val_loss: 0.2208 - val_acc: 0.9527\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9904\n",
      "Epoch 00091: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0292 - acc: 0.9904 - val_loss: 0.3065 - val_acc: 0.9327\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9925\n",
      "Epoch 00092: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0238 - acc: 0.9925 - val_loss: 0.2420 - val_acc: 0.9490\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9919\n",
      "Epoch 00093: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0261 - acc: 0.9919 - val_loss: 0.2313 - val_acc: 0.9502\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9910\n",
      "Epoch 00094: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0275 - acc: 0.9910 - val_loss: 0.4338 - val_acc: 0.9087\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9907\n",
      "Epoch 00095: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0279 - acc: 0.9907 - val_loss: 0.3160 - val_acc: 0.9334\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9893\n",
      "Epoch 00096: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0313 - acc: 0.9893 - val_loss: 0.5175 - val_acc: 0.8982\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9908\n",
      "Epoch 00097: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0285 - acc: 0.9908 - val_loss: 0.2123 - val_acc: 0.9518\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9927\n",
      "Epoch 00098: val_loss did not improve from 0.17364\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0224 - acc: 0.9926 - val_loss: 0.2249 - val_acc: 0.9476\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9876\n",
      "Epoch 00099: val_loss improved from 0.17364 to 0.16406, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_7_conv_checkpoint/099-0.1641.hdf5\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0375 - acc: 0.9876 - val_loss: 0.1641 - val_acc: 0.9653\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9933\n",
      "Epoch 00100: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0202 - acc: 0.9933 - val_loss: 0.2144 - val_acc: 0.9490\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9934\n",
      "Epoch 00101: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0209 - acc: 0.9934 - val_loss: 0.2707 - val_acc: 0.9418\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9931\n",
      "Epoch 00102: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0206 - acc: 0.9931 - val_loss: 0.2293 - val_acc: 0.9548\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9892\n",
      "Epoch 00103: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0353 - acc: 0.9891 - val_loss: 0.2921 - val_acc: 0.9404\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9909\n",
      "Epoch 00104: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0286 - acc: 0.9909 - val_loss: 0.5048 - val_acc: 0.9059\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9937\n",
      "Epoch 00105: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0197 - acc: 0.9937 - val_loss: 0.2580 - val_acc: 0.9485\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9902\n",
      "Epoch 00106: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0302 - acc: 0.9902 - val_loss: 0.2187 - val_acc: 0.9515\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9945\n",
      "Epoch 00107: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0184 - acc: 0.9945 - val_loss: 0.3051 - val_acc: 0.9366\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9925\n",
      "Epoch 00108: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0231 - acc: 0.9925 - val_loss: 0.8544 - val_acc: 0.8437\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9928\n",
      "Epoch 00109: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0236 - acc: 0.9928 - val_loss: 0.2854 - val_acc: 0.9422\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9909\n",
      "Epoch 00110: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0290 - acc: 0.9909 - val_loss: 0.2197 - val_acc: 0.9553\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9913\n",
      "Epoch 00111: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0268 - acc: 0.9913 - val_loss: 0.2757 - val_acc: 0.9401\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9906\n",
      "Epoch 00112: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0294 - acc: 0.9906 - val_loss: 0.2854 - val_acc: 0.9336\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9952\n",
      "Epoch 00113: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0155 - acc: 0.9952 - val_loss: 0.1934 - val_acc: 0.9571\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9945\n",
      "Epoch 00114: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0177 - acc: 0.9945 - val_loss: 0.2117 - val_acc: 0.9557\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9944\n",
      "Epoch 00115: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0180 - acc: 0.9943 - val_loss: 0.1864 - val_acc: 0.9611\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 00116: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0255 - acc: 0.9917 - val_loss: 0.2949 - val_acc: 0.9355\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9925\n",
      "Epoch 00117: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0235 - acc: 0.9925 - val_loss: 0.2432 - val_acc: 0.9548\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9938\n",
      "Epoch 00118: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0191 - acc: 0.9938 - val_loss: 0.2275 - val_acc: 0.9539\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9944\n",
      "Epoch 00119: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0186 - acc: 0.9944 - val_loss: 0.3315 - val_acc: 0.9334\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9938\n",
      "Epoch 00120: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0196 - acc: 0.9938 - val_loss: 0.2504 - val_acc: 0.9509\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9909\n",
      "Epoch 00121: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0283 - acc: 0.9909 - val_loss: 0.4638 - val_acc: 0.9085\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9948\n",
      "Epoch 00122: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0177 - acc: 0.9948 - val_loss: 0.3533 - val_acc: 0.9252\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9944\n",
      "Epoch 00123: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0167 - acc: 0.9944 - val_loss: 0.3488 - val_acc: 0.9376\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9949\n",
      "Epoch 00124: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0163 - acc: 0.9949 - val_loss: 0.2307 - val_acc: 0.9567\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9915\n",
      "Epoch 00125: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0271 - acc: 0.9914 - val_loss: 0.2071 - val_acc: 0.9602\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9924\n",
      "Epoch 00126: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0232 - acc: 0.9924 - val_loss: 0.1815 - val_acc: 0.9606\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9920\n",
      "Epoch 00127: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0247 - acc: 0.9920 - val_loss: 0.3080 - val_acc: 0.9352\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9959\n",
      "Epoch 00128: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0140 - acc: 0.9959 - val_loss: 0.2624 - val_acc: 0.9418\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9954\n",
      "Epoch 00129: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0148 - acc: 0.9954 - val_loss: 0.6524 - val_acc: 0.8933\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9917\n",
      "Epoch 00130: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0279 - acc: 0.9917 - val_loss: 0.4996 - val_acc: 0.9073\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9954\n",
      "Epoch 00131: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0146 - acc: 0.9954 - val_loss: 0.2042 - val_acc: 0.9574\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9942\n",
      "Epoch 00132: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0179 - acc: 0.9942 - val_loss: 0.2925 - val_acc: 0.9481\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9958\n",
      "Epoch 00133: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0139 - acc: 0.9958 - val_loss: 0.2833 - val_acc: 0.9497\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9908\n",
      "Epoch 00134: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0284 - acc: 0.9908 - val_loss: 0.4208 - val_acc: 0.9231\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9961\n",
      "Epoch 00135: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0138 - acc: 0.9961 - val_loss: 0.2312 - val_acc: 0.9576\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9918\n",
      "Epoch 00136: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0271 - acc: 0.9918 - val_loss: 0.2300 - val_acc: 0.9578\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9958\n",
      "Epoch 00137: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0144 - acc: 0.9958 - val_loss: 0.2108 - val_acc: 0.9571\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9943\n",
      "Epoch 00138: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0180 - acc: 0.9943 - val_loss: 2.5159 - val_acc: 0.6783\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9956\n",
      "Epoch 00139: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0140 - acc: 0.9956 - val_loss: 0.2112 - val_acc: 0.9567\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9959\n",
      "Epoch 00140: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0132 - acc: 0.9959 - val_loss: 0.2140 - val_acc: 0.9585\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9943\n",
      "Epoch 00141: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0182 - acc: 0.9943 - val_loss: 0.2370 - val_acc: 0.9520\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9949\n",
      "Epoch 00142: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0160 - acc: 0.9949 - val_loss: 0.3716 - val_acc: 0.9338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9953\n",
      "Epoch 00143: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0151 - acc: 0.9953 - val_loss: 0.3541 - val_acc: 0.9313\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9948\n",
      "Epoch 00144: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0159 - acc: 0.9948 - val_loss: 0.2624 - val_acc: 0.9509\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 00145: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0125 - acc: 0.9961 - val_loss: 0.2015 - val_acc: 0.9611\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9931\n",
      "Epoch 00146: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0209 - acc: 0.9930 - val_loss: 0.2640 - val_acc: 0.9471\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9898\n",
      "Epoch 00147: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0309 - acc: 0.9898 - val_loss: 0.1943 - val_acc: 0.9583\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9964\n",
      "Epoch 00148: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0122 - acc: 0.9964 - val_loss: 0.2860 - val_acc: 0.9420\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9927\n",
      "Epoch 00149: val_loss did not improve from 0.16406\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0236 - acc: 0.9927 - val_loss: 0.2043 - val_acc: 0.9602\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2022 - acc: 0.9524\n",
      "Loss: 0.20219213401169545 Accuracy: 0.95244026\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4420 - acc: 0.2751\n",
      "Epoch 00001: val_loss improved from inf to 1.62449, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/001-1.6245.hdf5\n",
      "36805/36805 [==============================] - 234s 6ms/sample - loss: 2.4420 - acc: 0.2751 - val_loss: 1.6245 - val_acc: 0.5146\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5122 - acc: 0.5144\n",
      "Epoch 00002: val_loss improved from 1.62449 to 1.00303, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/002-1.0030.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 1.5124 - acc: 0.5144 - val_loss: 1.0030 - val_acc: 0.6988\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0991 - acc: 0.6459\n",
      "Epoch 00003: val_loss improved from 1.00303 to 0.80757, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/003-0.8076.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 1.0991 - acc: 0.6459 - val_loss: 0.8076 - val_acc: 0.7543\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8179 - acc: 0.7473\n",
      "Epoch 00004: val_loss improved from 0.80757 to 0.57935, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/004-0.5793.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.8179 - acc: 0.7473 - val_loss: 0.5793 - val_acc: 0.8258\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6468 - acc: 0.7995\n",
      "Epoch 00005: val_loss improved from 0.57935 to 0.55895, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/005-0.5590.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.6467 - acc: 0.7996 - val_loss: 0.5590 - val_acc: 0.8367\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5220 - acc: 0.8415\n",
      "Epoch 00006: val_loss improved from 0.55895 to 0.48739, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/006-0.4874.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.5221 - acc: 0.8415 - val_loss: 0.4874 - val_acc: 0.8565\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8623\n",
      "Epoch 00007: val_loss improved from 0.48739 to 0.33006, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/007-0.3301.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.4466 - acc: 0.8623 - val_loss: 0.3301 - val_acc: 0.9068\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3880 - acc: 0.8819\n",
      "Epoch 00008: val_loss did not improve from 0.33006\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.3880 - acc: 0.8819 - val_loss: 0.4669 - val_acc: 0.8609\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3380 - acc: 0.8966\n",
      "Epoch 00009: val_loss improved from 0.33006 to 0.23368, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/009-0.2337.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.3380 - acc: 0.8966 - val_loss: 0.2337 - val_acc: 0.9345\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3087 - acc: 0.9049\n",
      "Epoch 00010: val_loss did not improve from 0.23368\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.3088 - acc: 0.9049 - val_loss: 0.2595 - val_acc: 0.9238\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.9115\n",
      "Epoch 00011: val_loss improved from 0.23368 to 0.20106, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/011-0.2011.hdf5\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.2884 - acc: 0.9115 - val_loss: 0.2011 - val_acc: 0.9429\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2554 - acc: 0.9209\n",
      "Epoch 00012: val_loss did not improve from 0.20106\n",
      "36805/36805 [==============================] - 222s 6ms/sample - loss: 0.2555 - acc: 0.9209 - val_loss: 0.2579 - val_acc: 0.9210\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2494 - acc: 0.9229\n",
      "Epoch 00013: val_loss did not improve from 0.20106\n",
      "36805/36805 [==============================] - 224s 6ms/sample - loss: 0.2494 - acc: 0.9229 - val_loss: 0.2440 - val_acc: 0.9352\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9308\n",
      "Epoch 00014: val_loss did not improve from 0.20106\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.2256 - acc: 0.9308 - val_loss: 0.2259 - val_acc: 0.9378\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2059 - acc: 0.9370\n",
      "Epoch 00015: val_loss improved from 0.20106 to 0.19724, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/015-0.1972.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.2059 - acc: 0.9370 - val_loss: 0.1972 - val_acc: 0.9464\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1928 - acc: 0.9415\n",
      "Epoch 00016: val_loss did not improve from 0.19724\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.1930 - acc: 0.9415 - val_loss: 0.2940 - val_acc: 0.9166\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9411\n",
      "Epoch 00017: val_loss did not improve from 0.19724\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.1893 - acc: 0.9411 - val_loss: 0.2440 - val_acc: 0.9255\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1717 - acc: 0.9469\n",
      "Epoch 00018: val_loss did not improve from 0.19724\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.1717 - acc: 0.9469 - val_loss: 0.2170 - val_acc: 0.9378\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1633 - acc: 0.9486\n",
      "Epoch 00019: val_loss improved from 0.19724 to 0.18863, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/019-0.1886.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.1633 - acc: 0.9486 - val_loss: 0.1886 - val_acc: 0.9450\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1526 - acc: 0.9533\n",
      "Epoch 00020: val_loss did not improve from 0.18863\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.1526 - acc: 0.9532 - val_loss: 0.2020 - val_acc: 0.9467\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1443 - acc: 0.9561\n",
      "Epoch 00021: val_loss improved from 0.18863 to 0.16428, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/021-0.1643.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.1443 - acc: 0.9560 - val_loss: 0.1643 - val_acc: 0.9569\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9554\n",
      "Epoch 00022: val_loss did not improve from 0.16428\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.1388 - acc: 0.9554 - val_loss: 0.1644 - val_acc: 0.9546\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9590\n",
      "Epoch 00023: val_loss improved from 0.16428 to 0.15265, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/023-0.1526.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.1303 - acc: 0.9591 - val_loss: 0.1526 - val_acc: 0.9564\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9602\n",
      "Epoch 00024: val_loss improved from 0.15265 to 0.14544, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/024-0.1454.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.1268 - acc: 0.9602 - val_loss: 0.1454 - val_acc: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9588\n",
      "Epoch 00025: val_loss did not improve from 0.14544\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.1288 - acc: 0.9588 - val_loss: 0.1921 - val_acc: 0.9413\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9650\n",
      "Epoch 00026: val_loss improved from 0.14544 to 0.14435, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/026-0.1444.hdf5\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.1142 - acc: 0.9650 - val_loss: 0.1444 - val_acc: 0.9592\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9658\n",
      "Epoch 00027: val_loss improved from 0.14435 to 0.13530, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/027-0.1353.hdf5\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.1068 - acc: 0.9658 - val_loss: 0.1353 - val_acc: 0.9599\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9670\n",
      "Epoch 00028: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.1045 - acc: 0.9670 - val_loss: 0.2252 - val_acc: 0.9385\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9684\n",
      "Epoch 00029: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0979 - acc: 0.9684 - val_loss: 0.2092 - val_acc: 0.9383\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9682\n",
      "Epoch 00030: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.1007 - acc: 0.9682 - val_loss: 0.4385 - val_acc: 0.8796\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9701\n",
      "Epoch 00031: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0949 - acc: 0.9701 - val_loss: 0.1511 - val_acc: 0.9553\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9742\n",
      "Epoch 00032: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0840 - acc: 0.9742 - val_loss: 0.1772 - val_acc: 0.9464\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9743\n",
      "Epoch 00033: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0834 - acc: 0.9742 - val_loss: 0.2177 - val_acc: 0.9387\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9727\n",
      "Epoch 00034: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0873 - acc: 0.9726 - val_loss: 0.1812 - val_acc: 0.9488\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9708\n",
      "Epoch 00035: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0920 - acc: 0.9708 - val_loss: 0.1710 - val_acc: 0.9504\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9760\n",
      "Epoch 00036: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0762 - acc: 0.9760 - val_loss: 0.2067 - val_acc: 0.9455\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9778\n",
      "Epoch 00037: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0706 - acc: 0.9778 - val_loss: 0.1433 - val_acc: 0.9595\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9788\n",
      "Epoch 00038: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0667 - acc: 0.9788 - val_loss: 0.1678 - val_acc: 0.9504\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9789\n",
      "Epoch 00039: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0684 - acc: 0.9789 - val_loss: 0.1430 - val_acc: 0.9585\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9770\n",
      "Epoch 00040: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0717 - acc: 0.9770 - val_loss: 0.2119 - val_acc: 0.9469\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9795\n",
      "Epoch 00041: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0672 - acc: 0.9795 - val_loss: 0.1603 - val_acc: 0.9520\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9763\n",
      "Epoch 00042: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0758 - acc: 0.9763 - val_loss: 0.2607 - val_acc: 0.9299\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9826\n",
      "Epoch 00043: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0569 - acc: 0.9825 - val_loss: 0.1603 - val_acc: 0.9541\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9811\n",
      "Epoch 00044: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0605 - acc: 0.9811 - val_loss: 0.1845 - val_acc: 0.9502\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9830\n",
      "Epoch 00045: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0564 - acc: 0.9830 - val_loss: 0.1435 - val_acc: 0.9597\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9835\n",
      "Epoch 00046: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0521 - acc: 0.9835 - val_loss: 0.1448 - val_acc: 0.9602\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9833\n",
      "Epoch 00047: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0527 - acc: 0.9832 - val_loss: 0.2183 - val_acc: 0.9434\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9780\n",
      "Epoch 00048: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0694 - acc: 0.9780 - val_loss: 0.1690 - val_acc: 0.9550\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9851\n",
      "Epoch 00049: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0482 - acc: 0.9851 - val_loss: 0.2254 - val_acc: 0.9404\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9863\n",
      "Epoch 00050: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0462 - acc: 0.9863 - val_loss: 0.2007 - val_acc: 0.9471\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9862\n",
      "Epoch 00051: val_loss did not improve from 0.13530\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0457 - acc: 0.9862 - val_loss: 0.1969 - val_acc: 0.9448\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9860\n",
      "Epoch 00052: val_loss improved from 0.13530 to 0.13506, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_8_conv_checkpoint/052-0.1351.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0463 - acc: 0.9860 - val_loss: 0.1351 - val_acc: 0.9634\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9857\n",
      "Epoch 00053: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0463 - acc: 0.9857 - val_loss: 0.1959 - val_acc: 0.9476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9856\n",
      "Epoch 00054: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0459 - acc: 0.9856 - val_loss: 0.1673 - val_acc: 0.9529\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9881\n",
      "Epoch 00055: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0389 - acc: 0.9881 - val_loss: 0.1667 - val_acc: 0.9560\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9864\n",
      "Epoch 00056: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0452 - acc: 0.9864 - val_loss: 0.1559 - val_acc: 0.9585\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9888\n",
      "Epoch 00057: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0367 - acc: 0.9888 - val_loss: 0.1460 - val_acc: 0.9653\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9876\n",
      "Epoch 00058: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0410 - acc: 0.9876 - val_loss: 0.2484 - val_acc: 0.9338\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9868\n",
      "Epoch 00059: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0410 - acc: 0.9868 - val_loss: 0.1654 - val_acc: 0.9623\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9860\n",
      "Epoch 00060: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0446 - acc: 0.9860 - val_loss: 0.2030 - val_acc: 0.9513\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9839\n",
      "Epoch 00061: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0510 - acc: 0.9839 - val_loss: 0.1388 - val_acc: 0.9658\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9898\n",
      "Epoch 00062: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0335 - acc: 0.9898 - val_loss: 0.2371 - val_acc: 0.9448\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9904\n",
      "Epoch 00063: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0311 - acc: 0.9904 - val_loss: 0.1525 - val_acc: 0.9646\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9859\n",
      "Epoch 00064: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0448 - acc: 0.9859 - val_loss: 0.1651 - val_acc: 0.9611\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9909\n",
      "Epoch 00065: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0300 - acc: 0.9909 - val_loss: 0.3993 - val_acc: 0.8987\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9904\n",
      "Epoch 00066: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0311 - acc: 0.9904 - val_loss: 0.1898 - val_acc: 0.9541\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9892\n",
      "Epoch 00067: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0345 - acc: 0.9892 - val_loss: 0.1557 - val_acc: 0.9627\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9912\n",
      "Epoch 00068: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 218s 6ms/sample - loss: 0.0287 - acc: 0.9912 - val_loss: 0.1827 - val_acc: 0.9560\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9907\n",
      "Epoch 00069: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0326 - acc: 0.9907 - val_loss: 0.5958 - val_acc: 0.8584\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9906\n",
      "Epoch 00070: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0299 - acc: 0.9906 - val_loss: 0.1560 - val_acc: 0.9625\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9911\n",
      "Epoch 00071: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0283 - acc: 0.9911 - val_loss: 0.5241 - val_acc: 0.8782\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9907\n",
      "Epoch 00072: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0296 - acc: 0.9907 - val_loss: 0.1578 - val_acc: 0.9576\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9901\n",
      "Epoch 00073: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0292 - acc: 0.9901 - val_loss: 0.1978 - val_acc: 0.9483\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9916\n",
      "Epoch 00074: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0275 - acc: 0.9916 - val_loss: 0.1721 - val_acc: 0.9581\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9926\n",
      "Epoch 00075: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0248 - acc: 0.9926 - val_loss: 0.2444 - val_acc: 0.9359\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9921\n",
      "Epoch 00076: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0267 - acc: 0.9921 - val_loss: 0.2005 - val_acc: 0.9481\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9905\n",
      "Epoch 00077: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0307 - acc: 0.9905 - val_loss: 0.2691 - val_acc: 0.9357\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9926\n",
      "Epoch 00078: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0251 - acc: 0.9926 - val_loss: 0.1714 - val_acc: 0.9576\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9929\n",
      "Epoch 00079: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0245 - acc: 0.9929 - val_loss: 0.1690 - val_acc: 0.9588\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9931\n",
      "Epoch 00080: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0234 - acc: 0.9931 - val_loss: 0.1560 - val_acc: 0.9611\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9922\n",
      "Epoch 00081: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0250 - acc: 0.9922 - val_loss: 0.1370 - val_acc: 0.9658\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9917\n",
      "Epoch 00082: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0265 - acc: 0.9917 - val_loss: 0.1757 - val_acc: 0.9597\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9930\n",
      "Epoch 00083: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0231 - acc: 0.9930 - val_loss: 0.1366 - val_acc: 0.9667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9939\n",
      "Epoch 00084: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0200 - acc: 0.9939 - val_loss: 0.2362 - val_acc: 0.9478\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9924\n",
      "Epoch 00085: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0255 - acc: 0.9924 - val_loss: 0.1714 - val_acc: 0.9588\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9931\n",
      "Epoch 00086: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0212 - acc: 0.9931 - val_loss: 0.1645 - val_acc: 0.9632\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9937\n",
      "Epoch 00087: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0213 - acc: 0.9937 - val_loss: 0.1822 - val_acc: 0.9562\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9925\n",
      "Epoch 00088: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0225 - acc: 0.9925 - val_loss: 0.2715 - val_acc: 0.9434\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9939\n",
      "Epoch 00089: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0195 - acc: 0.9939 - val_loss: 0.2417 - val_acc: 0.9469\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9912\n",
      "Epoch 00090: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0289 - acc: 0.9912 - val_loss: 0.1931 - val_acc: 0.9574\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9944\n",
      "Epoch 00091: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0180 - acc: 0.9944 - val_loss: 0.3208 - val_acc: 0.9352\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9939\n",
      "Epoch 00092: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0203 - acc: 0.9939 - val_loss: 0.4852 - val_acc: 0.8938\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9905\n",
      "Epoch 00093: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0300 - acc: 0.9905 - val_loss: 0.1538 - val_acc: 0.9641\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9958\n",
      "Epoch 00094: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0151 - acc: 0.9958 - val_loss: 0.2257 - val_acc: 0.9499\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9939\n",
      "Epoch 00095: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0204 - acc: 0.9939 - val_loss: 0.2394 - val_acc: 0.9443\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9942\n",
      "Epoch 00096: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0186 - acc: 0.9942 - val_loss: 1.0912 - val_acc: 0.8064\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9938\n",
      "Epoch 00097: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0202 - acc: 0.9938 - val_loss: 0.1871 - val_acc: 0.9574\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9918\n",
      "Epoch 00098: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0281 - acc: 0.9918 - val_loss: 0.1696 - val_acc: 0.9602\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9945\n",
      "Epoch 00099: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0179 - acc: 0.9945 - val_loss: 0.1529 - val_acc: 0.9655\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9946\n",
      "Epoch 00100: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0179 - acc: 0.9946 - val_loss: 0.1716 - val_acc: 0.9609\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9948\n",
      "Epoch 00101: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0163 - acc: 0.9948 - val_loss: 0.1482 - val_acc: 0.9644\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9935\n",
      "Epoch 00102: val_loss did not improve from 0.13506\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0196 - acc: 0.9934 - val_loss: 0.2187 - val_acc: 0.9562\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.1747 - acc: 0.9535\n",
      "Loss: 0.17465961022633258 Accuracy: 0.9534787\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1932 - acc: 0.3682\n",
      "Epoch 00001: val_loss improved from inf to 1.21442, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/001-1.2144.hdf5\n",
      "36805/36805 [==============================] - 236s 6ms/sample - loss: 2.1933 - acc: 0.3682 - val_loss: 1.2144 - val_acc: 0.6105\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1202 - acc: 0.6475\n",
      "Epoch 00002: val_loss improved from 1.21442 to 0.85236, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/002-0.8524.hdf5\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 1.1203 - acc: 0.6475 - val_loss: 0.8524 - val_acc: 0.7333\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7649 - acc: 0.7618\n",
      "Epoch 00003: val_loss improved from 0.85236 to 0.50437, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/003-0.5044.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.7649 - acc: 0.7618 - val_loss: 0.5044 - val_acc: 0.8395\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5536 - acc: 0.8288\n",
      "Epoch 00004: val_loss improved from 0.50437 to 0.37636, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/004-0.3764.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.5537 - acc: 0.8287 - val_loss: 0.3764 - val_acc: 0.8840\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4373 - acc: 0.8646\n",
      "Epoch 00005: val_loss improved from 0.37636 to 0.25844, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/005-0.2584.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.4372 - acc: 0.8647 - val_loss: 0.2584 - val_acc: 0.9203\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3706 - acc: 0.8862\n",
      "Epoch 00006: val_loss improved from 0.25844 to 0.23420, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/006-0.2342.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.3706 - acc: 0.8862 - val_loss: 0.2342 - val_acc: 0.9317\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3194 - acc: 0.9032\n",
      "Epoch 00007: val_loss improved from 0.23420 to 0.22933, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/007-0.2293.hdf5\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.3194 - acc: 0.9032 - val_loss: 0.2293 - val_acc: 0.9345\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2804 - acc: 0.9135\n",
      "Epoch 00008: val_loss did not improve from 0.22933\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.2804 - acc: 0.9135 - val_loss: 0.2551 - val_acc: 0.9234\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2473 - acc: 0.9235\n",
      "Epoch 00009: val_loss did not improve from 0.22933\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.2476 - acc: 0.9234 - val_loss: 0.3123 - val_acc: 0.9089\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2386 - acc: 0.9270\n",
      "Epoch 00010: val_loss improved from 0.22933 to 0.20170, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/010-0.2017.hdf5\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.2387 - acc: 0.9270 - val_loss: 0.2017 - val_acc: 0.9420\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2097 - acc: 0.9353\n",
      "Epoch 00011: val_loss improved from 0.20170 to 0.16737, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/011-0.1674.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.2099 - acc: 0.9352 - val_loss: 0.1674 - val_acc: 0.9490\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1979 - acc: 0.9381\n",
      "Epoch 00012: val_loss did not improve from 0.16737\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.1980 - acc: 0.9381 - val_loss: 0.1772 - val_acc: 0.9478\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1744 - acc: 0.9454\n",
      "Epoch 00013: val_loss did not improve from 0.16737\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.1745 - acc: 0.9454 - val_loss: 0.3637 - val_acc: 0.8994\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1675 - acc: 0.9477\n",
      "Epoch 00014: val_loss improved from 0.16737 to 0.14103, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/014-0.1410.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1675 - acc: 0.9477 - val_loss: 0.1410 - val_acc: 0.9592\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9526\n",
      "Epoch 00015: val_loss did not improve from 0.14103\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.1556 - acc: 0.9526 - val_loss: 0.1867 - val_acc: 0.9434\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9546\n",
      "Epoch 00016: val_loss did not improve from 0.14103\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.1459 - acc: 0.9546 - val_loss: 0.1554 - val_acc: 0.9546\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1270 - acc: 0.9612\n",
      "Epoch 00017: val_loss improved from 0.14103 to 0.13516, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/017-0.1352.hdf5\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.1270 - acc: 0.9612 - val_loss: 0.1352 - val_acc: 0.9581\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9630\n",
      "Epoch 00018: val_loss did not improve from 0.13516\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1193 - acc: 0.9630 - val_loss: 0.1494 - val_acc: 0.9525\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9629\n",
      "Epoch 00019: val_loss did not improve from 0.13516\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1177 - acc: 0.9629 - val_loss: 0.1613 - val_acc: 0.9536\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9674\n",
      "Epoch 00020: val_loss did not improve from 0.13516\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1066 - acc: 0.9673 - val_loss: 0.1930 - val_acc: 0.9406\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9672\n",
      "Epoch 00021: val_loss did not improve from 0.13516\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.1046 - acc: 0.9672 - val_loss: 0.2104 - val_acc: 0.9362\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9720\n",
      "Epoch 00022: val_loss improved from 0.13516 to 0.12162, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/022-0.1216.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0902 - acc: 0.9719 - val_loss: 0.1216 - val_acc: 0.9641\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9702\n",
      "Epoch 00023: val_loss did not improve from 0.12162\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0943 - acc: 0.9702 - val_loss: 0.1276 - val_acc: 0.9613\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9740\n",
      "Epoch 00024: val_loss did not improve from 0.12162\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0847 - acc: 0.9740 - val_loss: 0.1673 - val_acc: 0.9518\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9764\n",
      "Epoch 00025: val_loss did not improve from 0.12162\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0766 - acc: 0.9764 - val_loss: 0.1567 - val_acc: 0.9504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9758\n",
      "Epoch 00026: val_loss did not improve from 0.12162\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0775 - acc: 0.9757 - val_loss: 0.1517 - val_acc: 0.9567\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9765\n",
      "Epoch 00027: val_loss did not improve from 0.12162\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0755 - acc: 0.9765 - val_loss: 0.1894 - val_acc: 0.9457\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9783\n",
      "Epoch 00028: val_loss improved from 0.12162 to 0.11698, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/028-0.1170.hdf5\n",
      "36805/36805 [==============================] - 217s 6ms/sample - loss: 0.0694 - acc: 0.9783 - val_loss: 0.1170 - val_acc: 0.9634\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9805\n",
      "Epoch 00029: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0637 - acc: 0.9805 - val_loss: 0.1558 - val_acc: 0.9541\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9826\n",
      "Epoch 00030: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0572 - acc: 0.9826 - val_loss: 0.1660 - val_acc: 0.9578\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9824\n",
      "Epoch 00031: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0562 - acc: 0.9824 - val_loss: 0.1357 - val_acc: 0.9620\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9797\n",
      "Epoch 00032: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0647 - acc: 0.9796 - val_loss: 0.1404 - val_acc: 0.9581\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9826\n",
      "Epoch 00033: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0564 - acc: 0.9825 - val_loss: 0.1985 - val_acc: 0.9476\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9820\n",
      "Epoch 00034: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0561 - acc: 0.9820 - val_loss: 0.1441 - val_acc: 0.9592\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9860\n",
      "Epoch 00035: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0458 - acc: 0.9860 - val_loss: 0.1205 - val_acc: 0.9662\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9867\n",
      "Epoch 00036: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0437 - acc: 0.9867 - val_loss: 0.1760 - val_acc: 0.9539\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9866\n",
      "Epoch 00037: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0433 - acc: 0.9866 - val_loss: 0.1686 - val_acc: 0.9490\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9865\n",
      "Epoch 00038: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0443 - acc: 0.9865 - val_loss: 0.2025 - val_acc: 0.9502\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9871\n",
      "Epoch 00039: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0425 - acc: 0.9871 - val_loss: 0.1350 - val_acc: 0.9592\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9885\n",
      "Epoch 00040: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0381 - acc: 0.9885 - val_loss: 0.1417 - val_acc: 0.9623\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9869\n",
      "Epoch 00041: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0409 - acc: 0.9869 - val_loss: 0.1413 - val_acc: 0.9630\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9888\n",
      "Epoch 00042: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0372 - acc: 0.9888 - val_loss: 0.1188 - val_acc: 0.9704\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9906\n",
      "Epoch 00043: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0326 - acc: 0.9906 - val_loss: 0.1598 - val_acc: 0.9539\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9890\n",
      "Epoch 00044: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0360 - acc: 0.9890 - val_loss: 0.2563 - val_acc: 0.9364\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9909\n",
      "Epoch 00045: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0316 - acc: 0.9909 - val_loss: 0.1623 - val_acc: 0.9609\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9905\n",
      "Epoch 00046: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0309 - acc: 0.9905 - val_loss: 0.1225 - val_acc: 0.9667\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9907\n",
      "Epoch 00047: val_loss did not improve from 0.11698\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0301 - acc: 0.9907 - val_loss: 0.1589 - val_acc: 0.9592\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9905\n",
      "Epoch 00048: val_loss improved from 0.11698 to 0.11243, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/048-0.1124.hdf5\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0313 - acc: 0.9905 - val_loss: 0.1124 - val_acc: 0.9709\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9895\n",
      "Epoch 00049: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0318 - acc: 0.9895 - val_loss: 0.1478 - val_acc: 0.9618\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9936\n",
      "Epoch 00050: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0230 - acc: 0.9936 - val_loss: 0.1533 - val_acc: 0.9599\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9890\n",
      "Epoch 00051: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0338 - acc: 0.9890 - val_loss: 0.1466 - val_acc: 0.9606\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9921\n",
      "Epoch 00052: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0264 - acc: 0.9921 - val_loss: 0.1671 - val_acc: 0.9625\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9924\n",
      "Epoch 00053: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0252 - acc: 0.9924 - val_loss: 0.1406 - val_acc: 0.9662\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9929\n",
      "Epoch 00054: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0228 - acc: 0.9929 - val_loss: 0.2029 - val_acc: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9923\n",
      "Epoch 00055: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0244 - acc: 0.9923 - val_loss: 0.1289 - val_acc: 0.9658\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9928\n",
      "Epoch 00056: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0242 - acc: 0.9928 - val_loss: 0.1313 - val_acc: 0.9644\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9940\n",
      "Epoch 00057: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0204 - acc: 0.9940 - val_loss: 0.1636 - val_acc: 0.9627\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9908\n",
      "Epoch 00058: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0295 - acc: 0.9908 - val_loss: 0.1236 - val_acc: 0.9686\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9948\n",
      "Epoch 00059: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0178 - acc: 0.9948 - val_loss: 0.1140 - val_acc: 0.9711\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9929\n",
      "Epoch 00060: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0238 - acc: 0.9929 - val_loss: 0.2018 - val_acc: 0.9499\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9943\n",
      "Epoch 00061: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0183 - acc: 0.9943 - val_loss: 0.1802 - val_acc: 0.9567\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9933\n",
      "Epoch 00062: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0219 - acc: 0.9933 - val_loss: 0.1442 - val_acc: 0.9644\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9910\n",
      "Epoch 00063: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0289 - acc: 0.9910 - val_loss: 0.1352 - val_acc: 0.9662\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9953\n",
      "Epoch 00064: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0153 - acc: 0.9953 - val_loss: 0.1877 - val_acc: 0.9588\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9883\n",
      "Epoch 00065: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0381 - acc: 0.9883 - val_loss: 0.1361 - val_acc: 0.9665\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9966\n",
      "Epoch 00066: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0129 - acc: 0.9966 - val_loss: 0.1408 - val_acc: 0.9639\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9964\n",
      "Epoch 00067: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0130 - acc: 0.9964 - val_loss: 0.1209 - val_acc: 0.9686\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9942\n",
      "Epoch 00068: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0196 - acc: 0.9942 - val_loss: 0.1479 - val_acc: 0.9660\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9968\n",
      "Epoch 00069: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0124 - acc: 0.9968 - val_loss: 0.2323 - val_acc: 0.9478\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9915\n",
      "Epoch 00070: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0269 - acc: 0.9915 - val_loss: 0.1583 - val_acc: 0.9613\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9954\n",
      "Epoch 00071: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0152 - acc: 0.9953 - val_loss: 0.1153 - val_acc: 0.9718\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9940\n",
      "Epoch 00072: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0199 - acc: 0.9940 - val_loss: 0.1493 - val_acc: 0.9662\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9956\n",
      "Epoch 00073: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0152 - acc: 0.9956 - val_loss: 0.1556 - val_acc: 0.9623\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9958\n",
      "Epoch 00074: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0141 - acc: 0.9958 - val_loss: 0.1400 - val_acc: 0.9695\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9956\n",
      "Epoch 00075: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0150 - acc: 0.9955 - val_loss: 0.1940 - val_acc: 0.9576\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9926\n",
      "Epoch 00076: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0255 - acc: 0.9926 - val_loss: 0.1815 - val_acc: 0.9611\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9961\n",
      "Epoch 00077: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0137 - acc: 0.9961 - val_loss: 0.1766 - val_acc: 0.9604\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9941\n",
      "Epoch 00078: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0183 - acc: 0.9941 - val_loss: 0.1614 - val_acc: 0.9655\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9960\n",
      "Epoch 00079: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0137 - acc: 0.9960 - val_loss: 0.1576 - val_acc: 0.9660\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9954\n",
      "Epoch 00080: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0151 - acc: 0.9954 - val_loss: 0.1480 - val_acc: 0.9634\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9971\n",
      "Epoch 00081: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0106 - acc: 0.9971 - val_loss: 0.1726 - val_acc: 0.9618\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9946\n",
      "Epoch 00082: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0172 - acc: 0.9946 - val_loss: 0.2042 - val_acc: 0.9525\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9956\n",
      "Epoch 00083: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0145 - acc: 0.9956 - val_loss: 0.1728 - val_acc: 0.9602\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9950\n",
      "Epoch 00084: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0159 - acc: 0.9950 - val_loss: 0.2032 - val_acc: 0.9641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9961\n",
      "Epoch 00085: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0123 - acc: 0.9961 - val_loss: 0.1677 - val_acc: 0.9653\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9965\n",
      "Epoch 00086: val_loss did not improve from 0.11243\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0118 - acc: 0.9965 - val_loss: 0.1470 - val_acc: 0.9634\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9950\n",
      "Epoch 00087: val_loss improved from 0.11243 to 0.10146, saving model to model/checkpoint/1D_CNN_custom_kernel_192_DO_BN_9_conv_checkpoint/087-0.1015.hdf5\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0169 - acc: 0.9950 - val_loss: 0.1015 - val_acc: 0.9755\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9966\n",
      "Epoch 00088: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0114 - acc: 0.9966 - val_loss: 0.1716 - val_acc: 0.9609\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9959\n",
      "Epoch 00089: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0144 - acc: 0.9959 - val_loss: 0.2062 - val_acc: 0.9585\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9967\n",
      "Epoch 00090: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0108 - acc: 0.9967 - val_loss: 0.3152 - val_acc: 0.9343\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9958\n",
      "Epoch 00091: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0141 - acc: 0.9957 - val_loss: 0.1690 - val_acc: 0.9662\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9951\n",
      "Epoch 00092: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0166 - acc: 0.9951 - val_loss: 0.1441 - val_acc: 0.9665\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9974\n",
      "Epoch 00093: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0102 - acc: 0.9973 - val_loss: 0.1311 - val_acc: 0.9669\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9929\n",
      "Epoch 00094: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0236 - acc: 0.9929 - val_loss: 0.1644 - val_acc: 0.9646\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9972\n",
      "Epoch 00095: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0094 - acc: 0.9972 - val_loss: 0.1297 - val_acc: 0.9693\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9977\n",
      "Epoch 00096: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0078 - acc: 0.9977 - val_loss: 0.1442 - val_acc: 0.9695\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9974\n",
      "Epoch 00097: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0090 - acc: 0.9974 - val_loss: 0.2031 - val_acc: 0.9520\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9967\n",
      "Epoch 00098: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0105 - acc: 0.9967 - val_loss: 0.1855 - val_acc: 0.9576\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9974\n",
      "Epoch 00099: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0093 - acc: 0.9974 - val_loss: 0.1429 - val_acc: 0.9662\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9960\n",
      "Epoch 00100: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0132 - acc: 0.9960 - val_loss: 0.2486 - val_acc: 0.9467\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9955\n",
      "Epoch 00101: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0149 - acc: 0.9955 - val_loss: 0.4123 - val_acc: 0.9154\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9973\n",
      "Epoch 00102: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0092 - acc: 0.9973 - val_loss: 0.1373 - val_acc: 0.9700\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9975\n",
      "Epoch 00103: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0089 - acc: 0.9975 - val_loss: 0.1888 - val_acc: 0.9616\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9962\n",
      "Epoch 00104: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 216s 6ms/sample - loss: 0.0120 - acc: 0.9962 - val_loss: 0.1721 - val_acc: 0.9632\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9971\n",
      "Epoch 00105: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 219s 6ms/sample - loss: 0.0094 - acc: 0.9971 - val_loss: 0.1904 - val_acc: 0.9611\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9966\n",
      "Epoch 00106: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0102 - acc: 0.9966 - val_loss: 0.1339 - val_acc: 0.9683\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9957\n",
      "Epoch 00107: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0142 - acc: 0.9957 - val_loss: 0.1396 - val_acc: 0.9709\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9977\n",
      "Epoch 00108: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0078 - acc: 0.9977 - val_loss: 0.1380 - val_acc: 0.9711\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9968\n",
      "Epoch 00109: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0100 - acc: 0.9967 - val_loss: 0.1678 - val_acc: 0.9639\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9943\n",
      "Epoch 00110: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0187 - acc: 0.9943 - val_loss: 0.1389 - val_acc: 0.9723\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9974\n",
      "Epoch 00111: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0084 - acc: 0.9974 - val_loss: 0.1655 - val_acc: 0.9706\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9982\n",
      "Epoch 00112: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0061 - acc: 0.9981 - val_loss: 0.1497 - val_acc: 0.9697\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9951\n",
      "Epoch 00113: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0158 - acc: 0.9951 - val_loss: 0.1694 - val_acc: 0.9655\n",
      "Epoch 114/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9976\n",
      "Epoch 00114: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0077 - acc: 0.9976 - val_loss: 0.1576 - val_acc: 0.9669\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9977\n",
      "Epoch 00115: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0077 - acc: 0.9977 - val_loss: 0.1463 - val_acc: 0.9695\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9977\n",
      "Epoch 00116: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0084 - acc: 0.9977 - val_loss: 0.1743 - val_acc: 0.9639\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9979\n",
      "Epoch 00117: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0076 - acc: 0.9979 - val_loss: 0.1703 - val_acc: 0.9611\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9945\n",
      "Epoch 00118: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0183 - acc: 0.9945 - val_loss: 0.2215 - val_acc: 0.9564\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9972\n",
      "Epoch 00119: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0087 - acc: 0.9972 - val_loss: 0.1754 - val_acc: 0.9634\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9964\n",
      "Epoch 00120: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0124 - acc: 0.9964 - val_loss: 0.1796 - val_acc: 0.9634\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9977\n",
      "Epoch 00121: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0064 - acc: 0.9977 - val_loss: 0.2049 - val_acc: 0.9604\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9982\n",
      "Epoch 00122: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0064 - acc: 0.9982 - val_loss: 0.1493 - val_acc: 0.9651\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9957\n",
      "Epoch 00123: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0145 - acc: 0.9957 - val_loss: 0.1932 - val_acc: 0.9606\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9982\n",
      "Epoch 00124: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0063 - acc: 0.9982 - val_loss: 0.1310 - val_acc: 0.9730\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9980\n",
      "Epoch 00125: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0071 - acc: 0.9980 - val_loss: 0.2033 - val_acc: 0.9597\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9985\n",
      "Epoch 00126: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0052 - acc: 0.9985 - val_loss: 0.2103 - val_acc: 0.9585\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9977\n",
      "Epoch 00127: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0073 - acc: 0.9977 - val_loss: 0.1410 - val_acc: 0.9700\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9953\n",
      "Epoch 00128: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 222s 6ms/sample - loss: 0.0140 - acc: 0.9953 - val_loss: 0.1560 - val_acc: 0.9700\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9974\n",
      "Epoch 00129: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0081 - acc: 0.9974 - val_loss: 0.1598 - val_acc: 0.9641\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9958\n",
      "Epoch 00130: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0129 - acc: 0.9958 - val_loss: 0.1237 - val_acc: 0.9730\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9979\n",
      "Epoch 00131: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0068 - acc: 0.9979 - val_loss: 0.1679 - val_acc: 0.9637\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9982\n",
      "Epoch 00132: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0065 - acc: 0.9982 - val_loss: 0.1581 - val_acc: 0.9688\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9976\n",
      "Epoch 00133: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0076 - acc: 0.9976 - val_loss: 0.1569 - val_acc: 0.9711\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9975\n",
      "Epoch 00134: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0087 - acc: 0.9975 - val_loss: 0.2386 - val_acc: 0.9522\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9985\n",
      "Epoch 00135: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 220s 6ms/sample - loss: 0.0051 - acc: 0.9985 - val_loss: 0.1462 - val_acc: 0.9679\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9971\n",
      "Epoch 00136: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0090 - acc: 0.9971 - val_loss: 0.1747 - val_acc: 0.9651\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9977\n",
      "Epoch 00137: val_loss did not improve from 0.10146\n",
      "36805/36805 [==============================] - 221s 6ms/sample - loss: 0.0075 - acc: 0.9977 - val_loss: 0.1431 - val_acc: 0.9704\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.1531 - acc: 0.9641\n",
      "Loss: 0.1531310552408264 Accuracy: 0.9640706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_kernel_192_DO_BN'\n",
    "\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,496\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 646us/sample - loss: 1.8823 - acc: 0.3907\n",
      "Loss: 1.8822607367457136 Accuracy: 0.3906542\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,867,152\n",
      "Trainable params: 5,866,896\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.1421 - acc: 0.5566\n",
      "Loss: 2.142140926329394 Accuracy: 0.55659395\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,422,736\n",
      "Trainable params: 2,422,352\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.9862 - acc: 0.7117\n",
      "Loss: 0.98616148430239 Accuracy: 0.7117342\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 1,307,920\n",
      "Trainable params: 1,307,408\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.5687 - acc: 0.8656\n",
      "Loss: 0.5686791763622565 Accuracy: 0.86562824\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,204,112\n",
      "Trainable params: 1,203,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.4731 - acc: 0.9094\n",
      "Loss: 0.4730949756233863 Accuracy: 0.90944964\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,032,720\n",
      "Trainable params: 1,031,696\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.3006 - acc: 0.9202\n",
      "Loss: 0.3006058562334205 Accuracy: 0.9202492\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 992,400\n",
      "Trainable params: 991,120\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.2022 - acc: 0.9524\n",
      "Loss: 0.20219213401169545 Accuracy: 0.95244026\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 1,013,520\n",
      "Trainable params: 1,011,984\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.1747 - acc: 0.9535\n",
      "Loss: 0.17465961022633258 Accuracy: 0.9534787\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,106,960\n",
      "Trainable params: 1,104,912\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.1531 - acc: 0.9641\n",
      "Loss: 0.1531310552408264 Accuracy: 0.9640706\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_kernel_192_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,496\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 841us/sample - loss: 6.3623 - acc: 0.4380\n",
      "Loss: 6.362338397559842 Accuracy: 0.43800622\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,867,152\n",
      "Trainable params: 5,866,896\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.7828 - acc: 0.6291\n",
      "Loss: 2.7827801266687064 Accuracy: 0.6290758\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,422,736\n",
      "Trainable params: 2,422,352\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 1.4128 - acc: 0.7776\n",
      "Loss: 1.4127883540507047 Accuracy: 0.77757007\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 1,307,920\n",
      "Trainable params: 1,307,408\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.8243 - acc: 0.8623\n",
      "Loss: 0.8242827140901196 Accuracy: 0.8623053\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 1,204,112\n",
      "Trainable params: 1,203,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 2.7719 - acc: 0.6910\n",
      "Loss: 2.7719070205312155 Accuracy: 0.6909657\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 1,032,720\n",
      "Trainable params: 1,031,696\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.6033 - acc: 0.8920\n",
      "Loss: 0.6033457358662708 Accuracy: 0.89200413\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 992,400\n",
      "Trainable params: 991,120\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.2601 - acc: 0.9464\n",
      "Loss: 0.26006958857333423 Accuracy: 0.94641745\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 1,013,520\n",
      "Trainable params: 1,011,984\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2212 - acc: 0.9516\n",
      "Loss: 0.22122878167751175 Accuracy: 0.95160955\n",
      "\n",
      "1D_CNN_custom_kernel_192_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         393280    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          196672    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          98368     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          98432     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 1,106,960\n",
      "Trainable params: 1,104,912\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2167 - acc: 0.9570\n",
      "Loss: 0.2167260921670236 Accuracy: 0.9570094\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
