{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO_075_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.75))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO_075_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.1732 - acc: 0.2170\n",
      "Epoch 00001: val_loss improved from inf to 2.31064, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_1_conv_checkpoint/001-2.3106.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 3.1731 - acc: 0.2169 - val_loss: 2.3106 - val_acc: 0.2453\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6976 - acc: 0.4808\n",
      "Epoch 00002: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.6975 - acc: 0.4809 - val_loss: 2.5730 - val_acc: 0.2902\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2834 - acc: 0.6030\n",
      "Epoch 00003: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.2834 - acc: 0.6030 - val_loss: 2.8633 - val_acc: 0.2821\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0546 - acc: 0.6730\n",
      "Epoch 00004: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.0545 - acc: 0.6731 - val_loss: 2.5589 - val_acc: 0.3277\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8917 - acc: 0.7218\n",
      "Epoch 00005: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.8917 - acc: 0.7218 - val_loss: 3.1290 - val_acc: 0.2753\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7672 - acc: 0.7605\n",
      "Epoch 00006: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.7672 - acc: 0.7604 - val_loss: 3.4657 - val_acc: 0.2481\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6742 - acc: 0.7920\n",
      "Epoch 00007: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.6742 - acc: 0.7919 - val_loss: 3.3805 - val_acc: 0.2860\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5963 - acc: 0.8155\n",
      "Epoch 00008: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.5964 - acc: 0.8155 - val_loss: 3.3242 - val_acc: 0.3100\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5298 - acc: 0.8363\n",
      "Epoch 00009: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.5299 - acc: 0.8363 - val_loss: 4.4532 - val_acc: 0.2662\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4729 - acc: 0.8536\n",
      "Epoch 00010: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4729 - acc: 0.8536 - val_loss: 3.5694 - val_acc: 0.3000\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4447 - acc: 0.8630\n",
      "Epoch 00011: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4448 - acc: 0.8630 - val_loss: 3.7089 - val_acc: 0.3075\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4005 - acc: 0.8787\n",
      "Epoch 00012: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4005 - acc: 0.8787 - val_loss: 3.6830 - val_acc: 0.3093\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3699 - acc: 0.8851\n",
      "Epoch 00013: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3701 - acc: 0.8851 - val_loss: 3.8096 - val_acc: 0.3082\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3455 - acc: 0.8954\n",
      "Epoch 00014: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3454 - acc: 0.8954 - val_loss: 3.9050 - val_acc: 0.3240\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3124 - acc: 0.9055\n",
      "Epoch 00015: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3125 - acc: 0.9055 - val_loss: 4.2174 - val_acc: 0.2937\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2984 - acc: 0.9114\n",
      "Epoch 00016: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2984 - acc: 0.9114 - val_loss: 4.9081 - val_acc: 0.2690\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2847 - acc: 0.9159\n",
      "Epoch 00017: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2848 - acc: 0.9159 - val_loss: 4.3901 - val_acc: 0.2996\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2589 - acc: 0.9236\n",
      "Epoch 00018: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2589 - acc: 0.9236 - val_loss: 4.3630 - val_acc: 0.2923\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2559 - acc: 0.9236\n",
      "Epoch 00019: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2559 - acc: 0.9237 - val_loss: 4.3727 - val_acc: 0.3065\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2453 - acc: 0.9280\n",
      "Epoch 00020: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2452 - acc: 0.9280 - val_loss: 5.7827 - val_acc: 0.2427\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2227 - acc: 0.9352\n",
      "Epoch 00021: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2227 - acc: 0.9352 - val_loss: 4.7406 - val_acc: 0.3077\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2260 - acc: 0.9342\n",
      "Epoch 00022: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2260 - acc: 0.9342 - val_loss: 5.4907 - val_acc: 0.2639\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2099 - acc: 0.9388\n",
      "Epoch 00023: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2100 - acc: 0.9388 - val_loss: 4.8536 - val_acc: 0.3086\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1987 - acc: 0.9420\n",
      "Epoch 00024: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1987 - acc: 0.9420 - val_loss: 4.9474 - val_acc: 0.3051\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1925 - acc: 0.9463\n",
      "Epoch 00025: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1927 - acc: 0.9463 - val_loss: 4.9321 - val_acc: 0.3105\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1917 - acc: 0.9461\n",
      "Epoch 00026: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1917 - acc: 0.9461 - val_loss: 5.2240 - val_acc: 0.3024\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1764 - acc: 0.9504\n",
      "Epoch 00027: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1764 - acc: 0.9504 - val_loss: 5.6665 - val_acc: 0.2900\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1731 - acc: 0.9501\n",
      "Epoch 00028: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1731 - acc: 0.9501 - val_loss: 5.2620 - val_acc: 0.2833\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9544\n",
      "Epoch 00029: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1691 - acc: 0.9544 - val_loss: 5.4253 - val_acc: 0.2914\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1570 - acc: 0.9554\n",
      "Epoch 00030: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1569 - acc: 0.9554 - val_loss: 5.5089 - val_acc: 0.2975\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1615 - acc: 0.9548\n",
      "Epoch 00031: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1615 - acc: 0.9548 - val_loss: 5.5001 - val_acc: 0.2972\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9562\n",
      "Epoch 00032: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1598 - acc: 0.9562 - val_loss: 5.6625 - val_acc: 0.2977\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9565\n",
      "Epoch 00033: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1579 - acc: 0.9565 - val_loss: 5.2475 - val_acc: 0.3098\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9574\n",
      "Epoch 00034: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1594 - acc: 0.9574 - val_loss: 5.5725 - val_acc: 0.2805\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9620\n",
      "Epoch 00035: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1392 - acc: 0.9620 - val_loss: 5.3217 - val_acc: 0.2919\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9615\n",
      "Epoch 00036: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1421 - acc: 0.9615 - val_loss: 5.7237 - val_acc: 0.2912\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9636\n",
      "Epoch 00037: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1383 - acc: 0.9636 - val_loss: 5.2149 - val_acc: 0.3145\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9646\n",
      "Epoch 00038: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1351 - acc: 0.9646 - val_loss: 5.3167 - val_acc: 0.2986\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9619\n",
      "Epoch 00039: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1408 - acc: 0.9619 - val_loss: 5.3572 - val_acc: 0.3170\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9673\n",
      "Epoch 00040: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1232 - acc: 0.9673 - val_loss: 5.3855 - val_acc: 0.3217\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9651\n",
      "Epoch 00041: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1307 - acc: 0.9651 - val_loss: 6.7552 - val_acc: 0.2867\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9645\n",
      "Epoch 00042: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1299 - acc: 0.9645 - val_loss: 5.8605 - val_acc: 0.2940\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9686\n",
      "Epoch 00043: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1202 - acc: 0.9686 - val_loss: 6.1469 - val_acc: 0.3005\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.9673\n",
      "Epoch 00044: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1228 - acc: 0.9673 - val_loss: 5.5260 - val_acc: 0.3105\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9684\n",
      "Epoch 00045: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1241 - acc: 0.9684 - val_loss: 6.1482 - val_acc: 0.2912\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9690\n",
      "Epoch 00046: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1194 - acc: 0.9690 - val_loss: 5.9744 - val_acc: 0.3012\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9711\n",
      "Epoch 00047: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1111 - acc: 0.9711 - val_loss: 6.1490 - val_acc: 0.2877\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9688\n",
      "Epoch 00048: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1182 - acc: 0.9688 - val_loss: 5.8104 - val_acc: 0.3105\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9699\n",
      "Epoch 00049: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1126 - acc: 0.9699 - val_loss: 6.1009 - val_acc: 0.3054\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9710\n",
      "Epoch 00050: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1140 - acc: 0.9710 - val_loss: 6.2995 - val_acc: 0.3049\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9737\n",
      "Epoch 00051: val_loss did not improve from 2.31064\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1038 - acc: 0.9737 - val_loss: 6.3214 - val_acc: 0.2916\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 434us/sample - loss: 2.3570 - acc: 0.2318\n",
      "Loss: 2.3570385051045957 Accuracy: 0.2317757\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3508 - acc: 0.2392\n",
      "Epoch 00001: val_loss improved from inf to 2.69378, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_2_conv_checkpoint/001-2.6938.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 3.3510 - acc: 0.2392 - val_loss: 2.6938 - val_acc: 0.2569\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3447 - acc: 0.3797\n",
      "Epoch 00002: val_loss improved from 2.69378 to 2.25107, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_2_conv_checkpoint/002-2.2511.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.3448 - acc: 0.3796 - val_loss: 2.2511 - val_acc: 0.3874\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0210 - acc: 0.4557\n",
      "Epoch 00003: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 2.0211 - acc: 0.4557 - val_loss: 2.3662 - val_acc: 0.3697\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8050 - acc: 0.5032\n",
      "Epoch 00004: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.8051 - acc: 0.5032 - val_loss: 2.3420 - val_acc: 0.3876\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5882 - acc: 0.5576\n",
      "Epoch 00005: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.5883 - acc: 0.5576 - val_loss: 2.6684 - val_acc: 0.3816\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4025 - acc: 0.6008\n",
      "Epoch 00006: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.4024 - acc: 0.6008 - val_loss: 2.3158 - val_acc: 0.4354\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2828 - acc: 0.6359\n",
      "Epoch 00007: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.2827 - acc: 0.6359 - val_loss: 2.5698 - val_acc: 0.4146\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1559 - acc: 0.6661\n",
      "Epoch 00008: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.1559 - acc: 0.6661 - val_loss: 2.5093 - val_acc: 0.4279\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0569 - acc: 0.6912\n",
      "Epoch 00009: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.0568 - acc: 0.6912 - val_loss: 2.4576 - val_acc: 0.4437\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9657 - acc: 0.7203\n",
      "Epoch 00010: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.9658 - acc: 0.7203 - val_loss: 2.7590 - val_acc: 0.4430\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8522 - acc: 0.7500\n",
      "Epoch 00011: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.8524 - acc: 0.7500 - val_loss: 3.1933 - val_acc: 0.3990\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8058 - acc: 0.7623\n",
      "Epoch 00012: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.8057 - acc: 0.7623 - val_loss: 3.2688 - val_acc: 0.3701\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7524 - acc: 0.7785\n",
      "Epoch 00013: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.7524 - acc: 0.7784 - val_loss: 2.8582 - val_acc: 0.4545\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6893 - acc: 0.7940\n",
      "Epoch 00014: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.6892 - acc: 0.7940 - val_loss: 2.7004 - val_acc: 0.4559\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6231 - acc: 0.8135\n",
      "Epoch 00015: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.6234 - acc: 0.8135 - val_loss: 3.0543 - val_acc: 0.4323\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5865 - acc: 0.8228\n",
      "Epoch 00016: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.5866 - acc: 0.8227 - val_loss: 2.7535 - val_acc: 0.4752\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5629 - acc: 0.8317\n",
      "Epoch 00017: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.5629 - acc: 0.8317 - val_loss: 3.2328 - val_acc: 0.4009\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5190 - acc: 0.8454\n",
      "Epoch 00018: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.5190 - acc: 0.8454 - val_loss: 3.1426 - val_acc: 0.4351\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4898 - acc: 0.8530\n",
      "Epoch 00019: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.4899 - acc: 0.8530 - val_loss: 3.0732 - val_acc: 0.4421\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4534 - acc: 0.8626\n",
      "Epoch 00020: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.4536 - acc: 0.8625 - val_loss: 2.9256 - val_acc: 0.4407\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4325 - acc: 0.8691\n",
      "Epoch 00021: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.4325 - acc: 0.8691 - val_loss: 2.8685 - val_acc: 0.4719\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4066 - acc: 0.8779\n",
      "Epoch 00022: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.4068 - acc: 0.8779 - val_loss: 2.9750 - val_acc: 0.4712\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3848 - acc: 0.8814\n",
      "Epoch 00023: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3847 - acc: 0.8814 - val_loss: 4.2504 - val_acc: 0.3694\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3769 - acc: 0.8864\n",
      "Epoch 00024: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3768 - acc: 0.8864 - val_loss: 3.5913 - val_acc: 0.4097\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3406 - acc: 0.8971\n",
      "Epoch 00025: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3407 - acc: 0.8971 - val_loss: 3.1983 - val_acc: 0.4475\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3333 - acc: 0.8992\n",
      "Epoch 00026: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3334 - acc: 0.8991 - val_loss: 3.3949 - val_acc: 0.4486\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3116 - acc: 0.9061\n",
      "Epoch 00027: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3116 - acc: 0.9062 - val_loss: 2.8803 - val_acc: 0.4840\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3000 - acc: 0.9090\n",
      "Epoch 00028: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3002 - acc: 0.9090 - val_loss: 4.0161 - val_acc: 0.4151\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3004 - acc: 0.9098\n",
      "Epoch 00029: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3006 - acc: 0.9098 - val_loss: 3.3433 - val_acc: 0.4428\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2762 - acc: 0.9160\n",
      "Epoch 00030: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2762 - acc: 0.9160 - val_loss: 3.1137 - val_acc: 0.4621\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2697 - acc: 0.9172\n",
      "Epoch 00031: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2697 - acc: 0.9172 - val_loss: 3.2268 - val_acc: 0.4694\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2531 - acc: 0.9238\n",
      "Epoch 00032: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2531 - acc: 0.9238 - val_loss: 3.2724 - val_acc: 0.4705\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2438 - acc: 0.9273\n",
      "Epoch 00033: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2437 - acc: 0.9273 - val_loss: 3.3414 - val_acc: 0.4496\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2416 - acc: 0.9282\n",
      "Epoch 00034: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2416 - acc: 0.9282 - val_loss: 3.1006 - val_acc: 0.4722\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2170 - acc: 0.9346\n",
      "Epoch 00035: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2171 - acc: 0.9345 - val_loss: 3.4323 - val_acc: 0.4500\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2258 - acc: 0.9322\n",
      "Epoch 00036: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2259 - acc: 0.9322 - val_loss: 3.5340 - val_acc: 0.4505\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2162 - acc: 0.9368\n",
      "Epoch 00037: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2163 - acc: 0.9368 - val_loss: 3.3407 - val_acc: 0.4850\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1962 - acc: 0.9410\n",
      "Epoch 00038: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1962 - acc: 0.9410 - val_loss: 3.2304 - val_acc: 0.4645\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9413\n",
      "Epoch 00039: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2021 - acc: 0.9413 - val_loss: 3.4119 - val_acc: 0.4649\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2013 - acc: 0.9401\n",
      "Epoch 00040: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2013 - acc: 0.9401 - val_loss: 3.1150 - val_acc: 0.4743\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1875 - acc: 0.9446\n",
      "Epoch 00041: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1875 - acc: 0.9447 - val_loss: 3.6899 - val_acc: 0.4479\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1835 - acc: 0.9463\n",
      "Epoch 00042: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1834 - acc: 0.9463 - val_loss: 3.0942 - val_acc: 0.4924\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9512\n",
      "Epoch 00043: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1677 - acc: 0.9512 - val_loss: 3.4227 - val_acc: 0.4831\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9506\n",
      "Epoch 00044: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1677 - acc: 0.9506 - val_loss: 4.0045 - val_acc: 0.4305\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9541\n",
      "Epoch 00045: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1583 - acc: 0.9541 - val_loss: 3.2552 - val_acc: 0.4584\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9519\n",
      "Epoch 00046: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1633 - acc: 0.9519 - val_loss: 3.2235 - val_acc: 0.4719\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9556\n",
      "Epoch 00047: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1548 - acc: 0.9556 - val_loss: 3.2636 - val_acc: 0.4745\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9552\n",
      "Epoch 00048: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1515 - acc: 0.9552 - val_loss: 3.1015 - val_acc: 0.4847\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1454 - acc: 0.9583\n",
      "Epoch 00049: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1456 - acc: 0.9583 - val_loss: 3.3626 - val_acc: 0.4663\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1488 - acc: 0.9578\n",
      "Epoch 00050: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1489 - acc: 0.9578 - val_loss: 3.3585 - val_acc: 0.4475\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1429 - acc: 0.9592\n",
      "Epoch 00051: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1429 - acc: 0.9592 - val_loss: 3.8733 - val_acc: 0.4286\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9615\n",
      "Epoch 00052: val_loss did not improve from 2.25107\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1337 - acc: 0.9615 - val_loss: 3.1347 - val_acc: 0.4992\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 718us/sample - loss: 2.3558 - acc: 0.3616\n",
      "Loss: 2.3557704696526534 Accuracy: 0.3615784\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7274 - acc: 0.2832\n",
      "Epoch 00001: val_loss improved from inf to 1.91350, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_3_conv_checkpoint/001-1.9135.hdf5\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 2.7272 - acc: 0.2832 - val_loss: 1.9135 - val_acc: 0.3811\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9395 - acc: 0.4385\n",
      "Epoch 00002: val_loss improved from 1.91350 to 1.53119, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_3_conv_checkpoint/002-1.5312.hdf5\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 1.9395 - acc: 0.4384 - val_loss: 1.5312 - val_acc: 0.5181\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6506 - acc: 0.5111\n",
      "Epoch 00003: val_loss improved from 1.53119 to 1.43303, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_3_conv_checkpoint/003-1.4330.hdf5\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 1.6506 - acc: 0.5111 - val_loss: 1.4330 - val_acc: 0.5726\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4668 - acc: 0.5649\n",
      "Epoch 00004: val_loss did not improve from 1.43303\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 1.4670 - acc: 0.5649 - val_loss: 1.4380 - val_acc: 0.5614\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3202 - acc: 0.6009\n",
      "Epoch 00005: val_loss improved from 1.43303 to 1.35862, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_3_conv_checkpoint/005-1.3586.hdf5\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 1.3201 - acc: 0.6009 - val_loss: 1.3586 - val_acc: 0.5970\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1972 - acc: 0.6335\n",
      "Epoch 00006: val_loss improved from 1.35862 to 1.26691, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_3_conv_checkpoint/006-1.2669.hdf5\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 1.1972 - acc: 0.6335 - val_loss: 1.2669 - val_acc: 0.6229\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1261 - acc: 0.6526\n",
      "Epoch 00007: val_loss did not improve from 1.26691\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 1.1263 - acc: 0.6526 - val_loss: 1.4665 - val_acc: 0.5849\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0349 - acc: 0.6789\n",
      "Epoch 00008: val_loss did not improve from 1.26691\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 1.0351 - acc: 0.6789 - val_loss: 1.5188 - val_acc: 0.5740\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9520 - acc: 0.7024\n",
      "Epoch 00009: val_loss did not improve from 1.26691\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.9519 - acc: 0.7024 - val_loss: 1.6412 - val_acc: 0.5597\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9065 - acc: 0.7179\n",
      "Epoch 00010: val_loss did not improve from 1.26691\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.9066 - acc: 0.7178 - val_loss: 1.3297 - val_acc: 0.6159\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8388 - acc: 0.7342\n",
      "Epoch 00011: val_loss did not improve from 1.26691\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.8388 - acc: 0.7342 - val_loss: 1.3287 - val_acc: 0.6324\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7962 - acc: 0.7464\n",
      "Epoch 00012: val_loss did not improve from 1.26691\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.7963 - acc: 0.7463 - val_loss: 1.4282 - val_acc: 0.6105\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7452 - acc: 0.7614\n",
      "Epoch 00013: val_loss did not improve from 1.26691\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.7455 - acc: 0.7613 - val_loss: 1.3124 - val_acc: 0.6490\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7041 - acc: 0.7736\n",
      "Epoch 00014: val_loss did not improve from 1.26691\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.7040 - acc: 0.7736 - val_loss: 1.3145 - val_acc: 0.6443\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6600 - acc: 0.7901\n",
      "Epoch 00015: val_loss did not improve from 1.26691\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.6601 - acc: 0.7901 - val_loss: 1.3169 - val_acc: 0.6427\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6309 - acc: 0.7954\n",
      "Epoch 00016: val_loss did not improve from 1.26691\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.6310 - acc: 0.7954 - val_loss: 1.3077 - val_acc: 0.6520\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6062 - acc: 0.8060\n",
      "Epoch 00017: val_loss did not improve from 1.26691\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.6063 - acc: 0.8060 - val_loss: 1.3133 - val_acc: 0.6625\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5805 - acc: 0.8127\n",
      "Epoch 00018: val_loss improved from 1.26691 to 1.26514, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_3_conv_checkpoint/018-1.2651.hdf5\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.5805 - acc: 0.8127 - val_loss: 1.2651 - val_acc: 0.6718\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5434 - acc: 0.8235\n",
      "Epoch 00019: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.5433 - acc: 0.8235 - val_loss: 1.4180 - val_acc: 0.6478\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5308 - acc: 0.8270\n",
      "Epoch 00020: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.5309 - acc: 0.8270 - val_loss: 1.5697 - val_acc: 0.6096\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5000 - acc: 0.8364\n",
      "Epoch 00021: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.5000 - acc: 0.8364 - val_loss: 1.4361 - val_acc: 0.6518\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4862 - acc: 0.8409\n",
      "Epoch 00022: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.4868 - acc: 0.8408 - val_loss: 1.8577 - val_acc: 0.5716\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4706 - acc: 0.8445\n",
      "Epoch 00023: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.4708 - acc: 0.8445 - val_loss: 1.5055 - val_acc: 0.6378\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4521 - acc: 0.8511\n",
      "Epoch 00024: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.4521 - acc: 0.8512 - val_loss: 1.5735 - val_acc: 0.6313\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4245 - acc: 0.8621\n",
      "Epoch 00025: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.4245 - acc: 0.8621 - val_loss: 1.5369 - val_acc: 0.6287\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4121 - acc: 0.8636\n",
      "Epoch 00026: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.4121 - acc: 0.8636 - val_loss: 1.3209 - val_acc: 0.6734\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3991 - acc: 0.8688\n",
      "Epoch 00027: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.3991 - acc: 0.8688 - val_loss: 1.3786 - val_acc: 0.6541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3880 - acc: 0.8737\n",
      "Epoch 00028: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.3881 - acc: 0.8737 - val_loss: 1.4471 - val_acc: 0.6629\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3748 - acc: 0.8769\n",
      "Epoch 00029: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.3749 - acc: 0.8768 - val_loss: 1.3971 - val_acc: 0.6734\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3545 - acc: 0.8834\n",
      "Epoch 00030: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.3545 - acc: 0.8834 - val_loss: 1.5819 - val_acc: 0.6366\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3555 - acc: 0.8831\n",
      "Epoch 00031: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.3555 - acc: 0.8831 - val_loss: 1.3635 - val_acc: 0.6739\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3406 - acc: 0.8876\n",
      "Epoch 00032: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.3406 - acc: 0.8876 - val_loss: 1.4469 - val_acc: 0.6639\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3298 - acc: 0.8894\n",
      "Epoch 00033: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.3299 - acc: 0.8894 - val_loss: 1.4250 - val_acc: 0.6690\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3191 - acc: 0.8937\n",
      "Epoch 00034: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.3191 - acc: 0.8937 - val_loss: 1.4779 - val_acc: 0.6587\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3065 - acc: 0.8992\n",
      "Epoch 00035: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.3065 - acc: 0.8992 - val_loss: 1.3687 - val_acc: 0.6755\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3020 - acc: 0.8995\n",
      "Epoch 00036: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.3021 - acc: 0.8994 - val_loss: 1.7942 - val_acc: 0.6131\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2936 - acc: 0.9024\n",
      "Epoch 00037: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2936 - acc: 0.9025 - val_loss: 1.3111 - val_acc: 0.6930\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2892 - acc: 0.9052\n",
      "Epoch 00038: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2892 - acc: 0.9052 - val_loss: 1.4337 - val_acc: 0.6751\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2751 - acc: 0.9107\n",
      "Epoch 00039: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2751 - acc: 0.9106 - val_loss: 1.7421 - val_acc: 0.6336\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2762 - acc: 0.9097\n",
      "Epoch 00040: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2762 - acc: 0.9097 - val_loss: 1.5236 - val_acc: 0.6590\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2634 - acc: 0.9126\n",
      "Epoch 00041: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2634 - acc: 0.9126 - val_loss: 1.3989 - val_acc: 0.6851\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2564 - acc: 0.9161\n",
      "Epoch 00042: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2566 - acc: 0.9161 - val_loss: 1.4076 - val_acc: 0.6802\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2492 - acc: 0.9182\n",
      "Epoch 00043: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2494 - acc: 0.9182 - val_loss: 1.8347 - val_acc: 0.6240\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2517 - acc: 0.9176\n",
      "Epoch 00044: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2517 - acc: 0.9176 - val_loss: 1.4558 - val_acc: 0.6611\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.9208\n",
      "Epoch 00045: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2401 - acc: 0.9208 - val_loss: 1.4314 - val_acc: 0.6774\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2260 - acc: 0.9251\n",
      "Epoch 00046: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2260 - acc: 0.9251 - val_loss: 1.7868 - val_acc: 0.6245\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2197 - acc: 0.9293\n",
      "Epoch 00047: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2197 - acc: 0.9293 - val_loss: 1.4407 - val_acc: 0.6748\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2272 - acc: 0.9248\n",
      "Epoch 00048: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2272 - acc: 0.9248 - val_loss: 1.3974 - val_acc: 0.6911\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9307\n",
      "Epoch 00049: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2106 - acc: 0.9307 - val_loss: 1.6569 - val_acc: 0.6441\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2188 - acc: 0.9287\n",
      "Epoch 00050: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2187 - acc: 0.9287 - val_loss: 1.4429 - val_acc: 0.6893\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9334\n",
      "Epoch 00051: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2061 - acc: 0.9334 - val_loss: 1.7995 - val_acc: 0.6434\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2013 - acc: 0.9339\n",
      "Epoch 00052: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2013 - acc: 0.9339 - val_loss: 1.5220 - val_acc: 0.6776\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1955 - acc: 0.9367\n",
      "Epoch 00053: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1957 - acc: 0.9366 - val_loss: 1.3446 - val_acc: 0.6946\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2008 - acc: 0.9352\n",
      "Epoch 00054: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.2008 - acc: 0.9352 - val_loss: 1.3778 - val_acc: 0.6960\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1916 - acc: 0.9394\n",
      "Epoch 00055: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1917 - acc: 0.9394 - val_loss: 1.4412 - val_acc: 0.6909\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1916 - acc: 0.9382\n",
      "Epoch 00056: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1917 - acc: 0.9382 - val_loss: 1.3691 - val_acc: 0.7053\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1815 - acc: 0.9407\n",
      "Epoch 00057: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1824 - acc: 0.9406 - val_loss: 1.3353 - val_acc: 0.6993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9364\n",
      "Epoch 00058: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1935 - acc: 0.9364 - val_loss: 1.3210 - val_acc: 0.7074\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9428\n",
      "Epoch 00059: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1748 - acc: 0.9428 - val_loss: 1.4388 - val_acc: 0.6797\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1732 - acc: 0.9453\n",
      "Epoch 00060: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1732 - acc: 0.9453 - val_loss: 1.8509 - val_acc: 0.6215\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1734 - acc: 0.9438\n",
      "Epoch 00061: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1734 - acc: 0.9438 - val_loss: 1.7555 - val_acc: 0.6401\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1631 - acc: 0.9470\n",
      "Epoch 00062: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1631 - acc: 0.9470 - val_loss: 1.2772 - val_acc: 0.7167\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9465\n",
      "Epoch 00063: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1674 - acc: 0.9466 - val_loss: 1.3437 - val_acc: 0.7149\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9489\n",
      "Epoch 00064: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1620 - acc: 0.9489 - val_loss: 1.4879 - val_acc: 0.6881\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1652 - acc: 0.9480\n",
      "Epoch 00065: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1653 - acc: 0.9480 - val_loss: 1.4189 - val_acc: 0.7079\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9507\n",
      "Epoch 00066: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1546 - acc: 0.9507 - val_loss: 1.3841 - val_acc: 0.7011\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9499\n",
      "Epoch 00067: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1566 - acc: 0.9499 - val_loss: 1.6136 - val_acc: 0.6748\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9518\n",
      "Epoch 00068: val_loss did not improve from 1.26514\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 0.1510 - acc: 0.9518 - val_loss: 1.3767 - val_acc: 0.7130\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 807us/sample - loss: 1.4029 - acc: 0.6309\n",
      "Loss: 1.4029251341755393 Accuracy: 0.63094497\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.8424 - acc: 0.2676\n",
      "Epoch 00001: val_loss improved from inf to 1.81628, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/001-1.8163.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 2.8426 - acc: 0.2675 - val_loss: 1.8163 - val_acc: 0.3981\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8526 - acc: 0.4559\n",
      "Epoch 00002: val_loss improved from 1.81628 to 1.27767, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/002-1.2777.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.8526 - acc: 0.4558 - val_loss: 1.2777 - val_acc: 0.6215\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5449 - acc: 0.5392\n",
      "Epoch 00003: val_loss improved from 1.27767 to 1.13862, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/003-1.1386.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.5449 - acc: 0.5392 - val_loss: 1.1386 - val_acc: 0.6573\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3573 - acc: 0.5887\n",
      "Epoch 00004: val_loss improved from 1.13862 to 1.02460, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/004-1.0246.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.3574 - acc: 0.5886 - val_loss: 1.0246 - val_acc: 0.6879\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2268 - acc: 0.6283\n",
      "Epoch 00005: val_loss improved from 1.02460 to 0.97361, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/005-0.9736.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.2269 - acc: 0.6283 - val_loss: 0.9736 - val_acc: 0.7121\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1491 - acc: 0.6479\n",
      "Epoch 00006: val_loss did not improve from 0.97361\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 1.1490 - acc: 0.6480 - val_loss: 1.0106 - val_acc: 0.6951\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0641 - acc: 0.6725\n",
      "Epoch 00007: val_loss did not improve from 0.97361\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.0641 - acc: 0.6725 - val_loss: 1.0114 - val_acc: 0.6932\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9924 - acc: 0.6958\n",
      "Epoch 00008: val_loss improved from 0.97361 to 0.89493, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/008-0.8949.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.9923 - acc: 0.6959 - val_loss: 0.8949 - val_acc: 0.7321\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9385 - acc: 0.7114\n",
      "Epoch 00009: val_loss did not improve from 0.89493\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.9384 - acc: 0.7114 - val_loss: 0.9123 - val_acc: 0.7328\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9029 - acc: 0.7211\n",
      "Epoch 00010: val_loss did not improve from 0.89493\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.9029 - acc: 0.7212 - val_loss: 0.9753 - val_acc: 0.7042\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8474 - acc: 0.7360\n",
      "Epoch 00011: val_loss improved from 0.89493 to 0.83441, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/011-0.8344.hdf5\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.8476 - acc: 0.7360 - val_loss: 0.8344 - val_acc: 0.7519\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8185 - acc: 0.7435\n",
      "Epoch 00012: val_loss did not improve from 0.83441\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.8186 - acc: 0.7435 - val_loss: 0.8725 - val_acc: 0.7426\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7848 - acc: 0.7546\n",
      "Epoch 00013: val_loss did not improve from 0.83441\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.7847 - acc: 0.7546 - val_loss: 0.8816 - val_acc: 0.7361\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7533 - acc: 0.7639\n",
      "Epoch 00014: val_loss improved from 0.83441 to 0.79126, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/014-0.7913.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.7532 - acc: 0.7639 - val_loss: 0.7913 - val_acc: 0.7687\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7315 - acc: 0.7743\n",
      "Epoch 00015: val_loss did not improve from 0.79126\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.7316 - acc: 0.7743 - val_loss: 0.8593 - val_acc: 0.7531\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6962 - acc: 0.7802\n",
      "Epoch 00016: val_loss did not improve from 0.79126\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.6963 - acc: 0.7802 - val_loss: 0.7922 - val_acc: 0.7633\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6676 - acc: 0.7914\n",
      "Epoch 00017: val_loss did not improve from 0.79126\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.6677 - acc: 0.7914 - val_loss: 0.7962 - val_acc: 0.7678\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6481 - acc: 0.7965\n",
      "Epoch 00018: val_loss did not improve from 0.79126\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.6481 - acc: 0.7965 - val_loss: 0.8481 - val_acc: 0.7577\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6300 - acc: 0.7987\n",
      "Epoch 00019: val_loss did not improve from 0.79126\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.6301 - acc: 0.7987 - val_loss: 0.9626 - val_acc: 0.7191\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6117 - acc: 0.8066\n",
      "Epoch 00020: val_loss did not improve from 0.79126\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.6116 - acc: 0.8065 - val_loss: 0.8365 - val_acc: 0.7524\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5972 - acc: 0.8098\n",
      "Epoch 00021: val_loss improved from 0.79126 to 0.78675, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/021-0.7868.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5973 - acc: 0.8098 - val_loss: 0.7868 - val_acc: 0.7743\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5803 - acc: 0.8158\n",
      "Epoch 00022: val_loss improved from 0.78675 to 0.78200, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/022-0.7820.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5803 - acc: 0.8158 - val_loss: 0.7820 - val_acc: 0.7768\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5540 - acc: 0.8224\n",
      "Epoch 00023: val_loss improved from 0.78200 to 0.77763, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/023-0.7776.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5540 - acc: 0.8224 - val_loss: 0.7776 - val_acc: 0.7813\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5432 - acc: 0.8267\n",
      "Epoch 00024: val_loss did not improve from 0.77763\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5432 - acc: 0.8267 - val_loss: 0.7938 - val_acc: 0.7734\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5235 - acc: 0.8339\n",
      "Epoch 00025: val_loss did not improve from 0.77763\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5238 - acc: 0.8338 - val_loss: 0.9025 - val_acc: 0.7403\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5165 - acc: 0.8357\n",
      "Epoch 00026: val_loss did not improve from 0.77763\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5165 - acc: 0.8356 - val_loss: 0.9720 - val_acc: 0.7307\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5048 - acc: 0.8394\n",
      "Epoch 00027: val_loss improved from 0.77763 to 0.75888, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/027-0.7589.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5048 - acc: 0.8394 - val_loss: 0.7589 - val_acc: 0.7897\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4819 - acc: 0.8458\n",
      "Epoch 00028: val_loss did not improve from 0.75888\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4820 - acc: 0.8458 - val_loss: 0.7841 - val_acc: 0.7747\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4671 - acc: 0.8498\n",
      "Epoch 00029: val_loss improved from 0.75888 to 0.74806, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/029-0.7481.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4670 - acc: 0.8499 - val_loss: 0.7481 - val_acc: 0.7999\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4652 - acc: 0.8497\n",
      "Epoch 00030: val_loss did not improve from 0.74806\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4652 - acc: 0.8497 - val_loss: 0.7952 - val_acc: 0.7743\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4492 - acc: 0.8549\n",
      "Epoch 00031: val_loss improved from 0.74806 to 0.73621, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/031-0.7362.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4492 - acc: 0.8549 - val_loss: 0.7362 - val_acc: 0.7964\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4425 - acc: 0.8573\n",
      "Epoch 00032: val_loss did not improve from 0.73621\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4425 - acc: 0.8573 - val_loss: 0.7990 - val_acc: 0.7848\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4322 - acc: 0.8612\n",
      "Epoch 00033: val_loss improved from 0.73621 to 0.73171, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/033-0.7317.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4322 - acc: 0.8612 - val_loss: 0.7317 - val_acc: 0.7976\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4275 - acc: 0.8623\n",
      "Epoch 00034: val_loss did not improve from 0.73171\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4275 - acc: 0.8623 - val_loss: 0.9212 - val_acc: 0.7487\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4105 - acc: 0.8668\n",
      "Epoch 00035: val_loss did not improve from 0.73171\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.4105 - acc: 0.8668 - val_loss: 0.8271 - val_acc: 0.7824\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4074 - acc: 0.8675\n",
      "Epoch 00036: val_loss improved from 0.73171 to 0.68591, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_4_conv_checkpoint/036-0.6859.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4074 - acc: 0.8675 - val_loss: 0.6859 - val_acc: 0.8169\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3948 - acc: 0.8702\n",
      "Epoch 00037: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.3949 - acc: 0.8702 - val_loss: 0.8603 - val_acc: 0.7626\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3904 - acc: 0.8735\n",
      "Epoch 00038: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.3907 - acc: 0.8734 - val_loss: 0.7765 - val_acc: 0.7878\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3783 - acc: 0.8770\n",
      "Epoch 00039: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.3784 - acc: 0.8770 - val_loss: 0.7313 - val_acc: 0.8067\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3727 - acc: 0.8775\n",
      "Epoch 00040: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.3726 - acc: 0.8775 - val_loss: 0.7501 - val_acc: 0.7978\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3720 - acc: 0.8790\n",
      "Epoch 00041: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.3720 - acc: 0.8790 - val_loss: 0.8409 - val_acc: 0.7747\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3586 - acc: 0.8832\n",
      "Epoch 00042: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.3587 - acc: 0.8832 - val_loss: 0.8736 - val_acc: 0.7675\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3530 - acc: 0.8837\n",
      "Epoch 00043: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.3530 - acc: 0.8837 - val_loss: 0.7969 - val_acc: 0.7945\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3520 - acc: 0.8846\n",
      "Epoch 00044: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.3520 - acc: 0.8846 - val_loss: 0.7583 - val_acc: 0.7997\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3398 - acc: 0.8901\n",
      "Epoch 00045: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3398 - acc: 0.8901 - val_loss: 0.8746 - val_acc: 0.7766\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3338 - acc: 0.8907\n",
      "Epoch 00046: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3338 - acc: 0.8907 - val_loss: 0.7438 - val_acc: 0.8067\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3333 - acc: 0.8913\n",
      "Epoch 00047: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3333 - acc: 0.8913 - val_loss: 0.7649 - val_acc: 0.7906\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3236 - acc: 0.8954\n",
      "Epoch 00048: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3236 - acc: 0.8954 - val_loss: 0.7404 - val_acc: 0.8018\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3203 - acc: 0.8961\n",
      "Epoch 00049: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3203 - acc: 0.8962 - val_loss: 0.7891 - val_acc: 0.7869\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3124 - acc: 0.8965\n",
      "Epoch 00050: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.3124 - acc: 0.8965 - val_loss: 0.7622 - val_acc: 0.7992\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3089 - acc: 0.8979\n",
      "Epoch 00051: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3090 - acc: 0.8979 - val_loss: 0.7370 - val_acc: 0.8130\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3076 - acc: 0.9000\n",
      "Epoch 00052: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3076 - acc: 0.9000 - val_loss: 0.7516 - val_acc: 0.8036\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2981 - acc: 0.9017\n",
      "Epoch 00053: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2982 - acc: 0.9017 - val_loss: 0.8155 - val_acc: 0.7810\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2930 - acc: 0.9043\n",
      "Epoch 00054: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2930 - acc: 0.9043 - val_loss: 0.7223 - val_acc: 0.8104\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2932 - acc: 0.9033\n",
      "Epoch 00055: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2932 - acc: 0.9033 - val_loss: 0.7096 - val_acc: 0.8169\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2878 - acc: 0.9049\n",
      "Epoch 00056: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2878 - acc: 0.9049 - val_loss: 0.7756 - val_acc: 0.7973\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2832 - acc: 0.9088\n",
      "Epoch 00057: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2833 - acc: 0.9088 - val_loss: 0.7772 - val_acc: 0.7962\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2744 - acc: 0.9105\n",
      "Epoch 00058: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2744 - acc: 0.9105 - val_loss: 0.8331 - val_acc: 0.7894\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2732 - acc: 0.9121\n",
      "Epoch 00059: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2731 - acc: 0.9122 - val_loss: 0.7894 - val_acc: 0.8057\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2702 - acc: 0.9117\n",
      "Epoch 00060: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2702 - acc: 0.9117 - val_loss: 0.7445 - val_acc: 0.8034\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2686 - acc: 0.9133\n",
      "Epoch 00061: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2685 - acc: 0.9133 - val_loss: 0.7561 - val_acc: 0.8046\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2597 - acc: 0.9140\n",
      "Epoch 00062: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2597 - acc: 0.9140 - val_loss: 0.8472 - val_acc: 0.7761\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2573 - acc: 0.9133\n",
      "Epoch 00063: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2573 - acc: 0.9133 - val_loss: 0.7381 - val_acc: 0.8192\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2531 - acc: 0.9167\n",
      "Epoch 00064: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2531 - acc: 0.9168 - val_loss: 1.1206 - val_acc: 0.7324\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2495 - acc: 0.9186\n",
      "Epoch 00065: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2495 - acc: 0.9186 - val_loss: 0.7236 - val_acc: 0.8181\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2490 - acc: 0.9173\n",
      "Epoch 00066: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2490 - acc: 0.9173 - val_loss: 0.7407 - val_acc: 0.8137\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2443 - acc: 0.9198\n",
      "Epoch 00067: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2444 - acc: 0.9197 - val_loss: 1.0187 - val_acc: 0.7496\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2472 - acc: 0.9203\n",
      "Epoch 00068: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2472 - acc: 0.9203 - val_loss: 0.7515 - val_acc: 0.8104\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2369 - acc: 0.9217\n",
      "Epoch 00069: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2370 - acc: 0.9217 - val_loss: 0.7926 - val_acc: 0.8029\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2370 - acc: 0.9232\n",
      "Epoch 00070: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2371 - acc: 0.9231 - val_loss: 0.8568 - val_acc: 0.7841\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.9221\n",
      "Epoch 00071: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2360 - acc: 0.9221 - val_loss: 0.7220 - val_acc: 0.8216\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.9254\n",
      "Epoch 00072: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2299 - acc: 0.9254 - val_loss: 0.7177 - val_acc: 0.8192\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2303 - acc: 0.9249\n",
      "Epoch 00073: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2303 - acc: 0.9249 - val_loss: 0.7360 - val_acc: 0.8150\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2265 - acc: 0.9251\n",
      "Epoch 00074: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2265 - acc: 0.9251 - val_loss: 0.7451 - val_acc: 0.8164\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2244 - acc: 0.9266\n",
      "Epoch 00075: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2244 - acc: 0.9266 - val_loss: 0.7755 - val_acc: 0.8036\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9282\n",
      "Epoch 00076: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2195 - acc: 0.9282 - val_loss: 0.7833 - val_acc: 0.8095\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2206 - acc: 0.9283\n",
      "Epoch 00077: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2207 - acc: 0.9283 - val_loss: 0.7870 - val_acc: 0.8067\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2121 - acc: 0.9298\n",
      "Epoch 00078: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2122 - acc: 0.9298 - val_loss: 0.8474 - val_acc: 0.7992\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2105 - acc: 0.9309\n",
      "Epoch 00079: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2106 - acc: 0.9309 - val_loss: 0.8130 - val_acc: 0.7990\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2166 - acc: 0.9294\n",
      "Epoch 00080: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2168 - acc: 0.9293 - val_loss: 0.7523 - val_acc: 0.8120\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9316\n",
      "Epoch 00081: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2116 - acc: 0.9316 - val_loss: 0.7662 - val_acc: 0.8134\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2038 - acc: 0.9337\n",
      "Epoch 00082: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2038 - acc: 0.9337 - val_loss: 1.0718 - val_acc: 0.7384\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2004 - acc: 0.9351\n",
      "Epoch 00083: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2004 - acc: 0.9351 - val_loss: 0.7513 - val_acc: 0.8155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2058 - acc: 0.9325\n",
      "Epoch 00084: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2058 - acc: 0.9325 - val_loss: 0.7793 - val_acc: 0.7999\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2019 - acc: 0.9338\n",
      "Epoch 00085: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2019 - acc: 0.9338 - val_loss: 0.7154 - val_acc: 0.8272\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9326\n",
      "Epoch 00086: val_loss did not improve from 0.68591\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2036 - acc: 0.9326 - val_loss: 0.8051 - val_acc: 0.8088\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 844us/sample - loss: 0.8081 - acc: 0.7718\n",
      "Loss: 0.8080774210447587 Accuracy: 0.7717549\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.8994 - acc: 0.2595\n",
      "Epoch 00001: val_loss improved from inf to 2.04151, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/001-2.0415.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 2.8996 - acc: 0.2595 - val_loss: 2.0415 - val_acc: 0.3240\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7718 - acc: 0.4809\n",
      "Epoch 00002: val_loss improved from 2.04151 to 1.16538, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/002-1.1654.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.7717 - acc: 0.4809 - val_loss: 1.1654 - val_acc: 0.6553\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4172 - acc: 0.5760\n",
      "Epoch 00003: val_loss improved from 1.16538 to 1.00635, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/003-1.0064.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.4171 - acc: 0.5760 - val_loss: 1.0064 - val_acc: 0.6904\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2503 - acc: 0.6257\n",
      "Epoch 00004: val_loss improved from 1.00635 to 0.97513, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/004-0.9751.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.2505 - acc: 0.6256 - val_loss: 0.9751 - val_acc: 0.7088\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1131 - acc: 0.6672\n",
      "Epoch 00005: val_loss improved from 0.97513 to 0.85641, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/005-0.8564.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.1132 - acc: 0.6672 - val_loss: 0.8564 - val_acc: 0.7503\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0259 - acc: 0.6926\n",
      "Epoch 00006: val_loss improved from 0.85641 to 0.84669, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/006-0.8467.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.0258 - acc: 0.6926 - val_loss: 0.8467 - val_acc: 0.7563\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9472 - acc: 0.7159\n",
      "Epoch 00007: val_loss improved from 0.84669 to 0.74886, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/007-0.7489.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.9473 - acc: 0.7159 - val_loss: 0.7489 - val_acc: 0.7815\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8905 - acc: 0.7314\n",
      "Epoch 00008: val_loss did not improve from 0.74886\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.8906 - acc: 0.7314 - val_loss: 1.0399 - val_acc: 0.6888\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8442 - acc: 0.7457\n",
      "Epoch 00009: val_loss did not improve from 0.74886\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.8442 - acc: 0.7456 - val_loss: 0.8440 - val_acc: 0.7498\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8061 - acc: 0.7543\n",
      "Epoch 00010: val_loss did not improve from 0.74886\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.8062 - acc: 0.7543 - val_loss: 0.8250 - val_acc: 0.7519\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7701 - acc: 0.7668\n",
      "Epoch 00011: val_loss did not improve from 0.74886\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.7701 - acc: 0.7667 - val_loss: 0.9473 - val_acc: 0.7228\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7384 - acc: 0.7763\n",
      "Epoch 00012: val_loss did not improve from 0.74886\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.7384 - acc: 0.7763 - val_loss: 0.8479 - val_acc: 0.7508\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7109 - acc: 0.7846\n",
      "Epoch 00013: val_loss improved from 0.74886 to 0.70230, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/013-0.7023.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.7109 - acc: 0.7846 - val_loss: 0.7023 - val_acc: 0.7983\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6799 - acc: 0.7935\n",
      "Epoch 00014: val_loss improved from 0.70230 to 0.68367, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/014-0.6837.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6799 - acc: 0.7935 - val_loss: 0.6837 - val_acc: 0.8078\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6651 - acc: 0.7989\n",
      "Epoch 00015: val_loss did not improve from 0.68367\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6651 - acc: 0.7989 - val_loss: 0.7153 - val_acc: 0.7862\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6407 - acc: 0.8046\n",
      "Epoch 00016: val_loss improved from 0.68367 to 0.65050, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/016-0.6505.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6409 - acc: 0.8046 - val_loss: 0.6505 - val_acc: 0.8202\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6189 - acc: 0.8129\n",
      "Epoch 00017: val_loss did not improve from 0.65050\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6189 - acc: 0.8129 - val_loss: 0.6708 - val_acc: 0.8102\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6043 - acc: 0.8156\n",
      "Epoch 00018: val_loss improved from 0.65050 to 0.63195, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/018-0.6320.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6043 - acc: 0.8156 - val_loss: 0.6320 - val_acc: 0.8192\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5834 - acc: 0.8207\n",
      "Epoch 00019: val_loss improved from 0.63195 to 0.58377, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/019-0.5838.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5834 - acc: 0.8207 - val_loss: 0.5838 - val_acc: 0.8388\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5676 - acc: 0.8268\n",
      "Epoch 00020: val_loss improved from 0.58377 to 0.57689, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/020-0.5769.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5676 - acc: 0.8268 - val_loss: 0.5769 - val_acc: 0.8458\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5535 - acc: 0.8287\n",
      "Epoch 00021: val_loss did not improve from 0.57689\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5534 - acc: 0.8287 - val_loss: 0.5785 - val_acc: 0.8411\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5471 - acc: 0.8324\n",
      "Epoch 00022: val_loss improved from 0.57689 to 0.56496, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/022-0.5650.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5472 - acc: 0.8324 - val_loss: 0.5650 - val_acc: 0.8479\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5302 - acc: 0.8379\n",
      "Epoch 00023: val_loss did not improve from 0.56496\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5304 - acc: 0.8378 - val_loss: 0.6034 - val_acc: 0.8272\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5174 - acc: 0.8400\n",
      "Epoch 00024: val_loss did not improve from 0.56496\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5175 - acc: 0.8399 - val_loss: 0.6268 - val_acc: 0.8202\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5093 - acc: 0.8427\n",
      "Epoch 00025: val_loss did not improve from 0.56496\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5092 - acc: 0.8427 - val_loss: 0.6134 - val_acc: 0.8246\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4965 - acc: 0.8466\n",
      "Epoch 00026: val_loss did not improve from 0.56496\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4965 - acc: 0.8466 - val_loss: 0.7134 - val_acc: 0.8053\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4820 - acc: 0.8514\n",
      "Epoch 00027: val_loss did not improve from 0.56496\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4821 - acc: 0.8513 - val_loss: 0.5888 - val_acc: 0.8323\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4724 - acc: 0.8548\n",
      "Epoch 00028: val_loss did not improve from 0.56496\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4727 - acc: 0.8548 - val_loss: 0.5750 - val_acc: 0.8376\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4638 - acc: 0.8522\n",
      "Epoch 00029: val_loss did not improve from 0.56496\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4639 - acc: 0.8521 - val_loss: 0.6146 - val_acc: 0.8251\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4560 - acc: 0.8592\n",
      "Epoch 00030: val_loss improved from 0.56496 to 0.54963, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/030-0.5496.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4560 - acc: 0.8591 - val_loss: 0.5496 - val_acc: 0.8472\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4369 - acc: 0.8640\n",
      "Epoch 00031: val_loss improved from 0.54963 to 0.54665, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/031-0.5467.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4369 - acc: 0.8639 - val_loss: 0.5467 - val_acc: 0.8479\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4391 - acc: 0.8631\n",
      "Epoch 00032: val_loss did not improve from 0.54665\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4393 - acc: 0.8631 - val_loss: 0.5626 - val_acc: 0.8465\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4228 - acc: 0.8690\n",
      "Epoch 00033: val_loss improved from 0.54665 to 0.53868, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/033-0.5387.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4228 - acc: 0.8690 - val_loss: 0.5387 - val_acc: 0.8526\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4123 - acc: 0.8710\n",
      "Epoch 00034: val_loss did not improve from 0.53868\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4123 - acc: 0.8710 - val_loss: 0.6050 - val_acc: 0.8295\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4096 - acc: 0.8714\n",
      "Epoch 00035: val_loss did not improve from 0.53868\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4096 - acc: 0.8713 - val_loss: 0.5493 - val_acc: 0.8477\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3989 - acc: 0.8734\n",
      "Epoch 00036: val_loss did not improve from 0.53868\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3991 - acc: 0.8734 - val_loss: 0.5755 - val_acc: 0.8477\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3998 - acc: 0.8740\n",
      "Epoch 00037: val_loss did not improve from 0.53868\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3998 - acc: 0.8740 - val_loss: 0.5911 - val_acc: 0.8423\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3840 - acc: 0.8782\n",
      "Epoch 00038: val_loss did not improve from 0.53868\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3839 - acc: 0.8782 - val_loss: 0.5629 - val_acc: 0.8458\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3758 - acc: 0.8813\n",
      "Epoch 00039: val_loss improved from 0.53868 to 0.52284, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/039-0.5228.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3758 - acc: 0.8812 - val_loss: 0.5228 - val_acc: 0.8553\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3685 - acc: 0.8828\n",
      "Epoch 00040: val_loss did not improve from 0.52284\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3685 - acc: 0.8828 - val_loss: 0.5826 - val_acc: 0.8435\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3642 - acc: 0.8842\n",
      "Epoch 00041: val_loss did not improve from 0.52284\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3644 - acc: 0.8842 - val_loss: 0.5299 - val_acc: 0.8553\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3560 - acc: 0.8870\n",
      "Epoch 00042: val_loss did not improve from 0.52284\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3561 - acc: 0.8870 - val_loss: 0.5497 - val_acc: 0.8486\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3547 - acc: 0.8871\n",
      "Epoch 00043: val_loss did not improve from 0.52284\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3548 - acc: 0.8871 - val_loss: 0.5304 - val_acc: 0.8535\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3405 - acc: 0.8905\n",
      "Epoch 00044: val_loss improved from 0.52284 to 0.49577, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/044-0.4958.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3405 - acc: 0.8905 - val_loss: 0.4958 - val_acc: 0.8637\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3351 - acc: 0.8935\n",
      "Epoch 00045: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3351 - acc: 0.8935 - val_loss: 0.5283 - val_acc: 0.8563\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3281 - acc: 0.8955\n",
      "Epoch 00046: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3281 - acc: 0.8955 - val_loss: 0.5354 - val_acc: 0.8532\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.8934\n",
      "Epoch 00047: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3315 - acc: 0.8934 - val_loss: 0.5465 - val_acc: 0.8512\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3159 - acc: 0.9004\n",
      "Epoch 00048: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3160 - acc: 0.9003 - val_loss: 0.5438 - val_acc: 0.8598\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3108 - acc: 0.8995\n",
      "Epoch 00049: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3108 - acc: 0.8995 - val_loss: 0.5389 - val_acc: 0.8577\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3064 - acc: 0.9013\n",
      "Epoch 00050: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3065 - acc: 0.9013 - val_loss: 0.5435 - val_acc: 0.8553\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3067 - acc: 0.9023\n",
      "Epoch 00051: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3068 - acc: 0.9023 - val_loss: 0.5741 - val_acc: 0.8491\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2902 - acc: 0.9058\n",
      "Epoch 00052: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2902 - acc: 0.9057 - val_loss: 0.5192 - val_acc: 0.8637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2880 - acc: 0.9062\n",
      "Epoch 00053: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2881 - acc: 0.9062 - val_loss: 0.5259 - val_acc: 0.8628\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2922 - acc: 0.9057\n",
      "Epoch 00054: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2922 - acc: 0.9056 - val_loss: 0.5020 - val_acc: 0.8630\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2823 - acc: 0.9088\n",
      "Epoch 00055: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2824 - acc: 0.9088 - val_loss: 0.5586 - val_acc: 0.8495\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2791 - acc: 0.9108\n",
      "Epoch 00056: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2791 - acc: 0.9108 - val_loss: 0.5109 - val_acc: 0.8651\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2704 - acc: 0.9120\n",
      "Epoch 00057: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2704 - acc: 0.9120 - val_loss: 0.5239 - val_acc: 0.8744\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2691 - acc: 0.9115\n",
      "Epoch 00058: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2691 - acc: 0.9115 - val_loss: 0.5011 - val_acc: 0.8700\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2668 - acc: 0.9133\n",
      "Epoch 00059: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2668 - acc: 0.9133 - val_loss: 0.5421 - val_acc: 0.8526\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2590 - acc: 0.9151\n",
      "Epoch 00060: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2593 - acc: 0.9151 - val_loss: 0.5381 - val_acc: 0.8647\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2647 - acc: 0.9157\n",
      "Epoch 00061: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2648 - acc: 0.9156 - val_loss: 0.5428 - val_acc: 0.8598\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2572 - acc: 0.9179\n",
      "Epoch 00062: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2571 - acc: 0.9179 - val_loss: 0.4967 - val_acc: 0.8761\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2464 - acc: 0.9209\n",
      "Epoch 00063: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2464 - acc: 0.9209 - val_loss: 0.5274 - val_acc: 0.8705\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2450 - acc: 0.9207\n",
      "Epoch 00064: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2450 - acc: 0.9207 - val_loss: 0.5388 - val_acc: 0.8630\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2461 - acc: 0.9209\n",
      "Epoch 00065: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2461 - acc: 0.9209 - val_loss: 0.5402 - val_acc: 0.8577\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2346 - acc: 0.9251\n",
      "Epoch 00066: val_loss did not improve from 0.49577\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2346 - acc: 0.9251 - val_loss: 0.5818 - val_acc: 0.8467\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2400 - acc: 0.9217\n",
      "Epoch 00067: val_loss improved from 0.49577 to 0.48977, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_5_conv_checkpoint/067-0.4898.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2399 - acc: 0.9217 - val_loss: 0.4898 - val_acc: 0.8763\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2318 - acc: 0.9258\n",
      "Epoch 00068: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2318 - acc: 0.9258 - val_loss: 0.5812 - val_acc: 0.8616\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2320 - acc: 0.9243\n",
      "Epoch 00069: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2320 - acc: 0.9244 - val_loss: 0.5124 - val_acc: 0.8733\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2276 - acc: 0.9257\n",
      "Epoch 00070: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2276 - acc: 0.9257 - val_loss: 0.5093 - val_acc: 0.8749\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2243 - acc: 0.9271\n",
      "Epoch 00071: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2243 - acc: 0.9271 - val_loss: 0.5588 - val_acc: 0.8647\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2235 - acc: 0.9279\n",
      "Epoch 00072: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2235 - acc: 0.9279 - val_loss: 0.4908 - val_acc: 0.8763\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9298\n",
      "Epoch 00073: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2200 - acc: 0.9298 - val_loss: 0.5522 - val_acc: 0.8714\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9331\n",
      "Epoch 00074: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2078 - acc: 0.9331 - val_loss: 0.5304 - val_acc: 0.8696\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2154 - acc: 0.9308\n",
      "Epoch 00075: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2154 - acc: 0.9308 - val_loss: 0.5671 - val_acc: 0.8556\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.9308\n",
      "Epoch 00076: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2102 - acc: 0.9308 - val_loss: 0.5074 - val_acc: 0.8768\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2091 - acc: 0.9314\n",
      "Epoch 00077: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2091 - acc: 0.9314 - val_loss: 0.5323 - val_acc: 0.8696\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9319\n",
      "Epoch 00078: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2090 - acc: 0.9319 - val_loss: 0.5379 - val_acc: 0.8654\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2027 - acc: 0.9345\n",
      "Epoch 00079: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2027 - acc: 0.9345 - val_loss: 0.5236 - val_acc: 0.8670\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9372\n",
      "Epoch 00080: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1959 - acc: 0.9372 - val_loss: 0.5180 - val_acc: 0.8724\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9366\n",
      "Epoch 00081: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1958 - acc: 0.9366 - val_loss: 0.4981 - val_acc: 0.8779\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1940 - acc: 0.9364\n",
      "Epoch 00082: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1940 - acc: 0.9364 - val_loss: 0.6073 - val_acc: 0.8560\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1915 - acc: 0.9378\n",
      "Epoch 00083: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1915 - acc: 0.9378 - val_loss: 0.5212 - val_acc: 0.8682\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1840 - acc: 0.9414\n",
      "Epoch 00084: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1840 - acc: 0.9414 - val_loss: 0.5101 - val_acc: 0.8765\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1899 - acc: 0.9382\n",
      "Epoch 00085: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1899 - acc: 0.9382 - val_loss: 0.5304 - val_acc: 0.8712\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1928 - acc: 0.9365\n",
      "Epoch 00086: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1928 - acc: 0.9365 - val_loss: 0.5279 - val_acc: 0.8784\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1783 - acc: 0.9424\n",
      "Epoch 00087: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1782 - acc: 0.9424 - val_loss: 0.5471 - val_acc: 0.8675\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1832 - acc: 0.9410\n",
      "Epoch 00088: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1833 - acc: 0.9410 - val_loss: 0.5126 - val_acc: 0.8810\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1844 - acc: 0.9401\n",
      "Epoch 00089: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1844 - acc: 0.9401 - val_loss: 0.5648 - val_acc: 0.8621\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1798 - acc: 0.9422\n",
      "Epoch 00090: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1797 - acc: 0.9422 - val_loss: 0.5203 - val_acc: 0.8735\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1726 - acc: 0.9433\n",
      "Epoch 00091: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1726 - acc: 0.9433 - val_loss: 0.5461 - val_acc: 0.8730\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1730 - acc: 0.9439\n",
      "Epoch 00092: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1732 - acc: 0.9439 - val_loss: 0.5655 - val_acc: 0.8654\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9437\n",
      "Epoch 00093: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1755 - acc: 0.9437 - val_loss: 0.5464 - val_acc: 0.8672\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9459\n",
      "Epoch 00094: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1685 - acc: 0.9458 - val_loss: 0.5246 - val_acc: 0.8807\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1785 - acc: 0.9418\n",
      "Epoch 00095: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1785 - acc: 0.9418 - val_loss: 0.5032 - val_acc: 0.8805\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1686 - acc: 0.9457\n",
      "Epoch 00096: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1686 - acc: 0.9457 - val_loss: 0.5034 - val_acc: 0.8770\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9456\n",
      "Epoch 00097: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1693 - acc: 0.9455 - val_loss: 0.5356 - val_acc: 0.8719\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9452\n",
      "Epoch 00098: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1678 - acc: 0.9452 - val_loss: 0.6065 - val_acc: 0.8579\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1621 - acc: 0.9486\n",
      "Epoch 00099: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1621 - acc: 0.9485 - val_loss: 0.5154 - val_acc: 0.8751\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1640 - acc: 0.9473\n",
      "Epoch 00100: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1644 - acc: 0.9472 - val_loss: 0.5548 - val_acc: 0.8614\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9482\n",
      "Epoch 00101: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1596 - acc: 0.9482 - val_loss: 0.5620 - val_acc: 0.8665\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1585 - acc: 0.9498\n",
      "Epoch 00102: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1585 - acc: 0.9498 - val_loss: 0.5315 - val_acc: 0.8744\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9491\n",
      "Epoch 00103: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1596 - acc: 0.9491 - val_loss: 0.5156 - val_acc: 0.8784\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9499\n",
      "Epoch 00104: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1543 - acc: 0.9500 - val_loss: 0.5173 - val_acc: 0.8796\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9535\n",
      "Epoch 00105: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1510 - acc: 0.9535 - val_loss: 0.5629 - val_acc: 0.8670\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1545 - acc: 0.9501\n",
      "Epoch 00106: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1546 - acc: 0.9500 - val_loss: 0.5040 - val_acc: 0.8838\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1539 - acc: 0.9515\n",
      "Epoch 00107: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1540 - acc: 0.9515 - val_loss: 0.5692 - val_acc: 0.8635\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9532\n",
      "Epoch 00108: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1455 - acc: 0.9532 - val_loss: 0.5349 - val_acc: 0.8763\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1470 - acc: 0.9526\n",
      "Epoch 00109: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1473 - acc: 0.9526 - val_loss: 0.5046 - val_acc: 0.8775\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1612 - acc: 0.9468\n",
      "Epoch 00110: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1615 - acc: 0.9468 - val_loss: 0.5036 - val_acc: 0.8805\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1460 - acc: 0.9534\n",
      "Epoch 00111: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1461 - acc: 0.9534 - val_loss: 0.5761 - val_acc: 0.8724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9513\n",
      "Epoch 00112: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1494 - acc: 0.9513 - val_loss: 0.5026 - val_acc: 0.8819\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9545\n",
      "Epoch 00113: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1429 - acc: 0.9545 - val_loss: 0.7789 - val_acc: 0.8262\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1528 - acc: 0.9514\n",
      "Epoch 00114: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1528 - acc: 0.9514 - val_loss: 0.5023 - val_acc: 0.8826\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9551\n",
      "Epoch 00115: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1422 - acc: 0.9551 - val_loss: 0.4961 - val_acc: 0.8854\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9531\n",
      "Epoch 00116: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1443 - acc: 0.9531 - val_loss: 0.5147 - val_acc: 0.8784\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9518\n",
      "Epoch 00117: val_loss did not improve from 0.48977\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1480 - acc: 0.9518 - val_loss: 0.5214 - val_acc: 0.8772\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 886us/sample - loss: 0.6022 - acc: 0.8355\n",
      "Loss: 0.6022437252359598 Accuracy: 0.835514\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.8975 - acc: 0.2145\n",
      "Epoch 00001: val_loss improved from inf to 1.76617, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/001-1.7662.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 2.8976 - acc: 0.2145 - val_loss: 1.7662 - val_acc: 0.4181\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7847 - acc: 0.4515\n",
      "Epoch 00002: val_loss improved from 1.76617 to 1.09709, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/002-1.0971.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.7846 - acc: 0.4515 - val_loss: 1.0971 - val_acc: 0.6613\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3918 - acc: 0.5612\n",
      "Epoch 00003: val_loss improved from 1.09709 to 0.94141, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/003-0.9414.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.3919 - acc: 0.5613 - val_loss: 0.9414 - val_acc: 0.7119\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1861 - acc: 0.6301\n",
      "Epoch 00004: val_loss improved from 0.94141 to 0.82257, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/004-0.8226.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.1860 - acc: 0.6301 - val_loss: 0.8226 - val_acc: 0.7524\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0289 - acc: 0.6789\n",
      "Epoch 00005: val_loss improved from 0.82257 to 0.81724, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/005-0.8172.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.0291 - acc: 0.6789 - val_loss: 0.8172 - val_acc: 0.7601\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9410 - acc: 0.7100\n",
      "Epoch 00006: val_loss improved from 0.81724 to 0.75065, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/006-0.7506.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9410 - acc: 0.7099 - val_loss: 0.7506 - val_acc: 0.7757\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8609 - acc: 0.7370\n",
      "Epoch 00007: val_loss did not improve from 0.75065\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8608 - acc: 0.7371 - val_loss: 0.7534 - val_acc: 0.7901\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7979 - acc: 0.7575\n",
      "Epoch 00008: val_loss improved from 0.75065 to 0.69587, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/008-0.6959.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7978 - acc: 0.7575 - val_loss: 0.6959 - val_acc: 0.8043\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7364 - acc: 0.7758\n",
      "Epoch 00009: val_loss improved from 0.69587 to 0.61663, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/009-0.6166.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7366 - acc: 0.7757 - val_loss: 0.6166 - val_acc: 0.8330\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6924 - acc: 0.7896\n",
      "Epoch 00010: val_loss improved from 0.61663 to 0.54508, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/010-0.5451.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6925 - acc: 0.7895 - val_loss: 0.5451 - val_acc: 0.8479\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6566 - acc: 0.8025\n",
      "Epoch 00011: val_loss did not improve from 0.54508\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6568 - acc: 0.8025 - val_loss: 0.7397 - val_acc: 0.7864\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6288 - acc: 0.8114\n",
      "Epoch 00012: val_loss improved from 0.54508 to 0.49968, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/012-0.4997.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6288 - acc: 0.8114 - val_loss: 0.4997 - val_acc: 0.8654\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5911 - acc: 0.8218\n",
      "Epoch 00013: val_loss improved from 0.49968 to 0.48253, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/013-0.4825.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5911 - acc: 0.8218 - val_loss: 0.4825 - val_acc: 0.8644\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5676 - acc: 0.8295\n",
      "Epoch 00014: val_loss improved from 0.48253 to 0.48121, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/014-0.4812.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5676 - acc: 0.8295 - val_loss: 0.4812 - val_acc: 0.8747\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5471 - acc: 0.8369\n",
      "Epoch 00015: val_loss did not improve from 0.48121\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5472 - acc: 0.8368 - val_loss: 0.4831 - val_acc: 0.8682\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5312 - acc: 0.8422\n",
      "Epoch 00016: val_loss did not improve from 0.48121\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5315 - acc: 0.8421 - val_loss: 0.5000 - val_acc: 0.8605\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5103 - acc: 0.8467\n",
      "Epoch 00017: val_loss did not improve from 0.48121\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5103 - acc: 0.8467 - val_loss: 0.4948 - val_acc: 0.8700\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4916 - acc: 0.8527\n",
      "Epoch 00018: val_loss improved from 0.48121 to 0.45484, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/018-0.4548.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4917 - acc: 0.8527 - val_loss: 0.4548 - val_acc: 0.8754\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4792 - acc: 0.8545\n",
      "Epoch 00019: val_loss improved from 0.45484 to 0.39662, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/019-0.3966.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4793 - acc: 0.8545 - val_loss: 0.3966 - val_acc: 0.8928\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4627 - acc: 0.8599\n",
      "Epoch 00020: val_loss did not improve from 0.39662\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4626 - acc: 0.8600 - val_loss: 0.4844 - val_acc: 0.8721\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4449 - acc: 0.8651\n",
      "Epoch 00021: val_loss improved from 0.39662 to 0.39563, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/021-0.3956.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4448 - acc: 0.8651 - val_loss: 0.3956 - val_acc: 0.8963\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4308 - acc: 0.8687\n",
      "Epoch 00022: val_loss did not improve from 0.39563\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4310 - acc: 0.8687 - val_loss: 0.4002 - val_acc: 0.8982\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4191 - acc: 0.8728\n",
      "Epoch 00023: val_loss improved from 0.39563 to 0.39413, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/023-0.3941.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4191 - acc: 0.8728 - val_loss: 0.3941 - val_acc: 0.8887\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4072 - acc: 0.8760\n",
      "Epoch 00024: val_loss did not improve from 0.39413\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4073 - acc: 0.8760 - val_loss: 0.5042 - val_acc: 0.8661\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3977 - acc: 0.8801\n",
      "Epoch 00025: val_loss did not improve from 0.39413\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3977 - acc: 0.8801 - val_loss: 0.3942 - val_acc: 0.8924\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3939 - acc: 0.8810\n",
      "Epoch 00026: val_loss improved from 0.39413 to 0.38309, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/026-0.3831.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3938 - acc: 0.8810 - val_loss: 0.3831 - val_acc: 0.8973\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3763 - acc: 0.8879\n",
      "Epoch 00027: val_loss improved from 0.38309 to 0.36846, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/027-0.3685.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3762 - acc: 0.8879 - val_loss: 0.3685 - val_acc: 0.8998\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3709 - acc: 0.8860\n",
      "Epoch 00028: val_loss did not improve from 0.36846\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3709 - acc: 0.8860 - val_loss: 0.4301 - val_acc: 0.8887\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3641 - acc: 0.8881\n",
      "Epoch 00029: val_loss did not improve from 0.36846\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3642 - acc: 0.8881 - val_loss: 0.3780 - val_acc: 0.9036\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3525 - acc: 0.8922\n",
      "Epoch 00030: val_loss did not improve from 0.36846\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3525 - acc: 0.8922 - val_loss: 0.4003 - val_acc: 0.8835\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3461 - acc: 0.8937\n",
      "Epoch 00031: val_loss did not improve from 0.36846\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3461 - acc: 0.8937 - val_loss: 0.4097 - val_acc: 0.8935\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3424 - acc: 0.8946\n",
      "Epoch 00032: val_loss did not improve from 0.36846\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3423 - acc: 0.8946 - val_loss: 0.4340 - val_acc: 0.8854\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3270 - acc: 0.8989\n",
      "Epoch 00033: val_loss improved from 0.36846 to 0.35546, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/033-0.3555.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3272 - acc: 0.8988 - val_loss: 0.3555 - val_acc: 0.9073\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3362 - acc: 0.8944\n",
      "Epoch 00034: val_loss did not improve from 0.35546\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3362 - acc: 0.8944 - val_loss: 0.3985 - val_acc: 0.8956\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3150 - acc: 0.9018\n",
      "Epoch 00035: val_loss did not improve from 0.35546\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3150 - acc: 0.9018 - val_loss: 0.4126 - val_acc: 0.8849\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3175 - acc: 0.9008\n",
      "Epoch 00036: val_loss did not improve from 0.35546\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3175 - acc: 0.9008 - val_loss: 0.3572 - val_acc: 0.9110\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3044 - acc: 0.9048\n",
      "Epoch 00037: val_loss did not improve from 0.35546\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3044 - acc: 0.9048 - val_loss: 0.3994 - val_acc: 0.8956\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3009 - acc: 0.9069\n",
      "Epoch 00038: val_loss did not improve from 0.35546\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3010 - acc: 0.9069 - val_loss: 0.3644 - val_acc: 0.9078\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2999 - acc: 0.9068\n",
      "Epoch 00039: val_loss did not improve from 0.35546\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2999 - acc: 0.9068 - val_loss: 0.3597 - val_acc: 0.9005\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2821 - acc: 0.9117\n",
      "Epoch 00040: val_loss did not improve from 0.35546\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2820 - acc: 0.9117 - val_loss: 0.3668 - val_acc: 0.9089\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2898 - acc: 0.9076\n",
      "Epoch 00041: val_loss did not improve from 0.35546\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2898 - acc: 0.9076 - val_loss: 0.3836 - val_acc: 0.9059\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2834 - acc: 0.9094\n",
      "Epoch 00042: val_loss did not improve from 0.35546\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2833 - acc: 0.9094 - val_loss: 0.3630 - val_acc: 0.9003\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2725 - acc: 0.9146\n",
      "Epoch 00043: val_loss did not improve from 0.35546\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2725 - acc: 0.9147 - val_loss: 0.3703 - val_acc: 0.9050\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2648 - acc: 0.9162\n",
      "Epoch 00044: val_loss did not improve from 0.35546\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2648 - acc: 0.9163 - val_loss: 0.4202 - val_acc: 0.8884\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2631 - acc: 0.9157\n",
      "Epoch 00045: val_loss improved from 0.35546 to 0.35537, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/045-0.3554.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2631 - acc: 0.9157 - val_loss: 0.3554 - val_acc: 0.9050\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.9187\n",
      "Epoch 00046: val_loss did not improve from 0.35537\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2560 - acc: 0.9187 - val_loss: 0.3950 - val_acc: 0.8952\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2629 - acc: 0.9180\n",
      "Epoch 00047: val_loss improved from 0.35537 to 0.33358, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/047-0.3336.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2629 - acc: 0.9181 - val_loss: 0.3336 - val_acc: 0.9057\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2543 - acc: 0.9192\n",
      "Epoch 00048: val_loss did not improve from 0.33358\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2543 - acc: 0.9192 - val_loss: 0.4017 - val_acc: 0.8898\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2482 - acc: 0.9205\n",
      "Epoch 00049: val_loss did not improve from 0.33358\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2484 - acc: 0.9205 - val_loss: 0.3658 - val_acc: 0.9040\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2518 - acc: 0.9205\n",
      "Epoch 00050: val_loss did not improve from 0.33358\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2518 - acc: 0.9204 - val_loss: 0.4186 - val_acc: 0.9001\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2374 - acc: 0.9243\n",
      "Epoch 00051: val_loss did not improve from 0.33358\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2374 - acc: 0.9244 - val_loss: 0.3505 - val_acc: 0.9012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2390 - acc: 0.9244\n",
      "Epoch 00052: val_loss did not improve from 0.33358\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2389 - acc: 0.9244 - val_loss: 0.3604 - val_acc: 0.9106\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2304 - acc: 0.9273\n",
      "Epoch 00053: val_loss did not improve from 0.33358\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2303 - acc: 0.9273 - val_loss: 0.3538 - val_acc: 0.9092\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9275\n",
      "Epoch 00054: val_loss did not improve from 0.33358\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2240 - acc: 0.9275 - val_loss: 0.3760 - val_acc: 0.9015\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2248 - acc: 0.9276\n",
      "Epoch 00055: val_loss did not improve from 0.33358\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2248 - acc: 0.9276 - val_loss: 0.3815 - val_acc: 0.9094\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2266 - acc: 0.9278\n",
      "Epoch 00056: val_loss did not improve from 0.33358\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2265 - acc: 0.9278 - val_loss: 0.3780 - val_acc: 0.9092\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2142 - acc: 0.9302\n",
      "Epoch 00057: val_loss did not improve from 0.33358\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2142 - acc: 0.9302 - val_loss: 0.3424 - val_acc: 0.9143\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2157 - acc: 0.9312\n",
      "Epoch 00058: val_loss improved from 0.33358 to 0.32222, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/058-0.3222.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2158 - acc: 0.9312 - val_loss: 0.3222 - val_acc: 0.9185\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2150 - acc: 0.9308\n",
      "Epoch 00059: val_loss did not improve from 0.32222\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2151 - acc: 0.9308 - val_loss: 0.3386 - val_acc: 0.9168\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2092 - acc: 0.9332\n",
      "Epoch 00060: val_loss did not improve from 0.32222\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2093 - acc: 0.9332 - val_loss: 0.3598 - val_acc: 0.9157\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9331\n",
      "Epoch 00061: val_loss did not improve from 0.32222\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2061 - acc: 0.9331 - val_loss: 0.3365 - val_acc: 0.9082\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2054 - acc: 0.9344\n",
      "Epoch 00062: val_loss did not improve from 0.32222\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2054 - acc: 0.9344 - val_loss: 0.3383 - val_acc: 0.9227\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2067 - acc: 0.9339\n",
      "Epoch 00063: val_loss did not improve from 0.32222\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2067 - acc: 0.9339 - val_loss: 0.3442 - val_acc: 0.9145\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1946 - acc: 0.9373\n",
      "Epoch 00064: val_loss did not improve from 0.32222\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1948 - acc: 0.9372 - val_loss: 0.3543 - val_acc: 0.9075\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1987 - acc: 0.9353\n",
      "Epoch 00065: val_loss improved from 0.32222 to 0.31095, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/065-0.3110.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1987 - acc: 0.9353 - val_loss: 0.3110 - val_acc: 0.9154\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1917 - acc: 0.9384\n",
      "Epoch 00066: val_loss did not improve from 0.31095\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1917 - acc: 0.9384 - val_loss: 0.3334 - val_acc: 0.9147\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1900 - acc: 0.9380\n",
      "Epoch 00067: val_loss improved from 0.31095 to 0.30027, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_6_conv_checkpoint/067-0.3003.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1900 - acc: 0.9380 - val_loss: 0.3003 - val_acc: 0.9196\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1875 - acc: 0.9386\n",
      "Epoch 00068: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1875 - acc: 0.9385 - val_loss: 0.3246 - val_acc: 0.9208\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1875 - acc: 0.9395\n",
      "Epoch 00069: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1874 - acc: 0.9395 - val_loss: 0.3363 - val_acc: 0.9154\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1787 - acc: 0.9421\n",
      "Epoch 00070: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1786 - acc: 0.9421 - val_loss: 0.3806 - val_acc: 0.9057\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9411\n",
      "Epoch 00071: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1790 - acc: 0.9411 - val_loss: 0.3370 - val_acc: 0.9122\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1738 - acc: 0.9450\n",
      "Epoch 00072: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1739 - acc: 0.9450 - val_loss: 0.3145 - val_acc: 0.9178\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1746 - acc: 0.9433\n",
      "Epoch 00073: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1746 - acc: 0.9433 - val_loss: 0.3311 - val_acc: 0.9189\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1767 - acc: 0.9415\n",
      "Epoch 00074: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1768 - acc: 0.9415 - val_loss: 0.4060 - val_acc: 0.9005\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9438\n",
      "Epoch 00075: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1716 - acc: 0.9438 - val_loss: 0.3723 - val_acc: 0.9078\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9453\n",
      "Epoch 00076: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1680 - acc: 0.9453 - val_loss: 0.4290 - val_acc: 0.8940\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1740 - acc: 0.9437\n",
      "Epoch 00077: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1740 - acc: 0.9437 - val_loss: 0.3169 - val_acc: 0.9234\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1625 - acc: 0.9480\n",
      "Epoch 00078: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1625 - acc: 0.9480 - val_loss: 0.3290 - val_acc: 0.9147\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1633 - acc: 0.9461\n",
      "Epoch 00079: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1634 - acc: 0.9460 - val_loss: 0.3339 - val_acc: 0.9136\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9472\n",
      "Epoch 00080: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1634 - acc: 0.9472 - val_loss: 0.3559 - val_acc: 0.9194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9478\n",
      "Epoch 00081: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1599 - acc: 0.9478 - val_loss: 0.3571 - val_acc: 0.9171\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9491\n",
      "Epoch 00082: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1579 - acc: 0.9491 - val_loss: 0.3448 - val_acc: 0.9133\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9488\n",
      "Epoch 00083: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1566 - acc: 0.9488 - val_loss: 0.3252 - val_acc: 0.9175\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1521 - acc: 0.9500\n",
      "Epoch 00084: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1521 - acc: 0.9500 - val_loss: 0.3493 - val_acc: 0.9217\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9499\n",
      "Epoch 00085: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1521 - acc: 0.9499 - val_loss: 0.3339 - val_acc: 0.9138\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9526\n",
      "Epoch 00086: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1415 - acc: 0.9526 - val_loss: 0.3353 - val_acc: 0.9150\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9495\n",
      "Epoch 00087: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1497 - acc: 0.9495 - val_loss: 0.3631 - val_acc: 0.9103\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9521\n",
      "Epoch 00088: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1490 - acc: 0.9520 - val_loss: 0.3349 - val_acc: 0.9215\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9520\n",
      "Epoch 00089: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1463 - acc: 0.9520 - val_loss: 0.3359 - val_acc: 0.9173\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.9526\n",
      "Epoch 00090: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1431 - acc: 0.9525 - val_loss: 0.3452 - val_acc: 0.9238\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9504\n",
      "Epoch 00091: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1467 - acc: 0.9504 - val_loss: 0.3520 - val_acc: 0.9113\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1365 - acc: 0.9556\n",
      "Epoch 00092: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1365 - acc: 0.9556 - val_loss: 0.3194 - val_acc: 0.9222\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1365 - acc: 0.9548\n",
      "Epoch 00093: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1366 - acc: 0.9548 - val_loss: 0.3449 - val_acc: 0.9136\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9553\n",
      "Epoch 00094: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1394 - acc: 0.9553 - val_loss: 0.3511 - val_acc: 0.9150\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9541\n",
      "Epoch 00095: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1386 - acc: 0.9541 - val_loss: 0.3244 - val_acc: 0.9229\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9560\n",
      "Epoch 00096: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1353 - acc: 0.9560 - val_loss: 0.3487 - val_acc: 0.9203\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1316 - acc: 0.9588\n",
      "Epoch 00097: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1316 - acc: 0.9588 - val_loss: 0.3218 - val_acc: 0.9192\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9582\n",
      "Epoch 00098: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1254 - acc: 0.9582 - val_loss: 0.3399 - val_acc: 0.9231\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1268 - acc: 0.9583\n",
      "Epoch 00099: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1268 - acc: 0.9583 - val_loss: 0.3835 - val_acc: 0.9138\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9568\n",
      "Epoch 00100: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1305 - acc: 0.9568 - val_loss: 0.3460 - val_acc: 0.9231\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9586\n",
      "Epoch 00101: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1256 - acc: 0.9586 - val_loss: 0.3345 - val_acc: 0.9236\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9577\n",
      "Epoch 00102: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1277 - acc: 0.9577 - val_loss: 0.3140 - val_acc: 0.9231\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9588\n",
      "Epoch 00103: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1239 - acc: 0.9588 - val_loss: 0.3771 - val_acc: 0.9099\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9579\n",
      "Epoch 00104: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1275 - acc: 0.9579 - val_loss: 0.3490 - val_acc: 0.9215\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9599\n",
      "Epoch 00105: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1240 - acc: 0.9598 - val_loss: 0.3441 - val_acc: 0.9236\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9588\n",
      "Epoch 00106: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1227 - acc: 0.9588 - val_loss: 0.3846 - val_acc: 0.9050\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9620\n",
      "Epoch 00107: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1139 - acc: 0.9620 - val_loss: 0.4195 - val_acc: 0.9099\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9568\n",
      "Epoch 00108: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1293 - acc: 0.9568 - val_loss: 0.3435 - val_acc: 0.9187\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9607\n",
      "Epoch 00109: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1191 - acc: 0.9607 - val_loss: 0.3293 - val_acc: 0.9227\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9622\n",
      "Epoch 00110: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1157 - acc: 0.9622 - val_loss: 0.4054 - val_acc: 0.9054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9619\n",
      "Epoch 00111: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1176 - acc: 0.9619 - val_loss: 0.4345 - val_acc: 0.9078\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9618\n",
      "Epoch 00112: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1158 - acc: 0.9618 - val_loss: 0.3263 - val_acc: 0.9196\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9630\n",
      "Epoch 00113: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1113 - acc: 0.9630 - val_loss: 0.3785 - val_acc: 0.9133\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9640\n",
      "Epoch 00114: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1113 - acc: 0.9640 - val_loss: 0.3266 - val_acc: 0.9264\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9622\n",
      "Epoch 00115: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1126 - acc: 0.9622 - val_loss: 0.3042 - val_acc: 0.9257\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9640\n",
      "Epoch 00116: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1094 - acc: 0.9640 - val_loss: 0.3593 - val_acc: 0.9208\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9637\n",
      "Epoch 00117: val_loss did not improve from 0.30027\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1117 - acc: 0.9637 - val_loss: 0.3282 - val_acc: 0.9248\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 941us/sample - loss: 0.3867 - acc: 0.8933\n",
      "Loss: 0.38665750389406117 Accuracy: 0.8932503\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.1795 - acc: 0.1709\n",
      "Epoch 00001: val_loss improved from inf to 1.98156, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/001-1.9816.hdf5\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 3.1795 - acc: 0.1709 - val_loss: 1.9816 - val_acc: 0.3590\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0280 - acc: 0.3683\n",
      "Epoch 00002: val_loss improved from 1.98156 to 1.27779, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/002-1.2778.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 2.0281 - acc: 0.3683 - val_loss: 1.2778 - val_acc: 0.6082\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5489 - acc: 0.5013\n",
      "Epoch 00003: val_loss improved from 1.27779 to 1.02626, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/003-1.0263.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.5489 - acc: 0.5013 - val_loss: 1.0263 - val_acc: 0.7086\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2589 - acc: 0.5982\n",
      "Epoch 00004: val_loss improved from 1.02626 to 0.82671, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/004-0.8267.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.2588 - acc: 0.5983 - val_loss: 0.8267 - val_acc: 0.7671\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0664 - acc: 0.6661\n",
      "Epoch 00005: val_loss improved from 0.82671 to 0.68546, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/005-0.6855.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.0664 - acc: 0.6661 - val_loss: 0.6855 - val_acc: 0.8106\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9261 - acc: 0.7135\n",
      "Epoch 00006: val_loss improved from 0.68546 to 0.63311, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/006-0.6331.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9261 - acc: 0.7134 - val_loss: 0.6331 - val_acc: 0.8176\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8168 - acc: 0.7493\n",
      "Epoch 00007: val_loss improved from 0.63311 to 0.57065, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/007-0.5707.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8168 - acc: 0.7493 - val_loss: 0.5707 - val_acc: 0.8456\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7274 - acc: 0.7784\n",
      "Epoch 00008: val_loss improved from 0.57065 to 0.53807, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/008-0.5381.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.7275 - acc: 0.7783 - val_loss: 0.5381 - val_acc: 0.8519\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6595 - acc: 0.7989\n",
      "Epoch 00009: val_loss improved from 0.53807 to 0.47517, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/009-0.4752.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6595 - acc: 0.7989 - val_loss: 0.4752 - val_acc: 0.8633\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6086 - acc: 0.8153\n",
      "Epoch 00010: val_loss improved from 0.47517 to 0.43714, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/010-0.4371.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6086 - acc: 0.8153 - val_loss: 0.4371 - val_acc: 0.8793\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5555 - acc: 0.8332\n",
      "Epoch 00011: val_loss improved from 0.43714 to 0.40233, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/011-0.4023.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5554 - acc: 0.8332 - val_loss: 0.4023 - val_acc: 0.8905\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5203 - acc: 0.8423\n",
      "Epoch 00012: val_loss did not improve from 0.40233\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5203 - acc: 0.8423 - val_loss: 0.4056 - val_acc: 0.8963\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4931 - acc: 0.8514\n",
      "Epoch 00013: val_loss did not improve from 0.40233\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4932 - acc: 0.8514 - val_loss: 0.4273 - val_acc: 0.8782\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4562 - acc: 0.8611\n",
      "Epoch 00014: val_loss improved from 0.40233 to 0.36217, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/014-0.3622.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4561 - acc: 0.8612 - val_loss: 0.3622 - val_acc: 0.8891\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4296 - acc: 0.8701\n",
      "Epoch 00015: val_loss improved from 0.36217 to 0.31128, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/015-0.3113.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4296 - acc: 0.8701 - val_loss: 0.3113 - val_acc: 0.9113\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4114 - acc: 0.8767\n",
      "Epoch 00016: val_loss did not improve from 0.31128\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4115 - acc: 0.8767 - val_loss: 0.4248 - val_acc: 0.8744\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3867 - acc: 0.8823\n",
      "Epoch 00017: val_loss improved from 0.31128 to 0.31125, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/017-0.3112.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3868 - acc: 0.8822 - val_loss: 0.3112 - val_acc: 0.9133\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3718 - acc: 0.8871\n",
      "Epoch 00018: val_loss did not improve from 0.31125\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3721 - acc: 0.8871 - val_loss: 0.4215 - val_acc: 0.8786\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3684 - acc: 0.8876\n",
      "Epoch 00019: val_loss improved from 0.31125 to 0.29132, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/019-0.2913.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3683 - acc: 0.8876 - val_loss: 0.2913 - val_acc: 0.9192\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3377 - acc: 0.8968\n",
      "Epoch 00020: val_loss did not improve from 0.29132\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3377 - acc: 0.8968 - val_loss: 0.3162 - val_acc: 0.9133\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3318 - acc: 0.8990\n",
      "Epoch 00021: val_loss did not improve from 0.29132\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3318 - acc: 0.8990 - val_loss: 0.3141 - val_acc: 0.9129\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3207 - acc: 0.9009\n",
      "Epoch 00022: val_loss improved from 0.29132 to 0.27658, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/022-0.2766.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3207 - acc: 0.9009 - val_loss: 0.2766 - val_acc: 0.9255\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3086 - acc: 0.9055\n",
      "Epoch 00023: val_loss improved from 0.27658 to 0.27554, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/023-0.2755.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3086 - acc: 0.9055 - val_loss: 0.2755 - val_acc: 0.9194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2957 - acc: 0.9079\n",
      "Epoch 00024: val_loss improved from 0.27554 to 0.25567, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/024-0.2557.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2957 - acc: 0.9079 - val_loss: 0.2557 - val_acc: 0.9313\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.9105\n",
      "Epoch 00025: val_loss did not improve from 0.25567\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2885 - acc: 0.9104 - val_loss: 0.3343 - val_acc: 0.9119\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2848 - acc: 0.9126\n",
      "Epoch 00026: val_loss did not improve from 0.25567\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2848 - acc: 0.9126 - val_loss: 0.2779 - val_acc: 0.9234\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2694 - acc: 0.9157\n",
      "Epoch 00027: val_loss did not improve from 0.25567\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2695 - acc: 0.9157 - val_loss: 0.2776 - val_acc: 0.9234\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2711 - acc: 0.9172\n",
      "Epoch 00028: val_loss did not improve from 0.25567\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2711 - acc: 0.9172 - val_loss: 0.2595 - val_acc: 0.9271\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2558 - acc: 0.9197\n",
      "Epoch 00029: val_loss improved from 0.25567 to 0.23524, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/029-0.2352.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2558 - acc: 0.9197 - val_loss: 0.2352 - val_acc: 0.9357\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2459 - acc: 0.9238\n",
      "Epoch 00030: val_loss did not improve from 0.23524\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2460 - acc: 0.9238 - val_loss: 0.3426 - val_acc: 0.9064\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2329 - acc: 0.9276\n",
      "Epoch 00031: val_loss did not improve from 0.23524\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2330 - acc: 0.9276 - val_loss: 0.2721 - val_acc: 0.9301\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2424 - acc: 0.9242\n",
      "Epoch 00032: val_loss improved from 0.23524 to 0.21724, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/032-0.2172.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2424 - acc: 0.9241 - val_loss: 0.2172 - val_acc: 0.9446\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2209 - acc: 0.9305\n",
      "Epoch 00033: val_loss did not improve from 0.21724\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2209 - acc: 0.9306 - val_loss: 0.2321 - val_acc: 0.9371\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2165 - acc: 0.9313\n",
      "Epoch 00034: val_loss did not improve from 0.21724\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2167 - acc: 0.9313 - val_loss: 0.3045 - val_acc: 0.9252\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2218 - acc: 0.9305\n",
      "Epoch 00035: val_loss did not improve from 0.21724\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2218 - acc: 0.9304 - val_loss: 0.2755 - val_acc: 0.9273\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2130 - acc: 0.9332\n",
      "Epoch 00036: val_loss did not improve from 0.21724\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2131 - acc: 0.9331 - val_loss: 0.2804 - val_acc: 0.9257\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2065 - acc: 0.9358\n",
      "Epoch 00037: val_loss did not improve from 0.21724\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2066 - acc: 0.9357 - val_loss: 0.2507 - val_acc: 0.9343\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9365\n",
      "Epoch 00038: val_loss did not improve from 0.21724\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1995 - acc: 0.9365 - val_loss: 0.2489 - val_acc: 0.9352\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1946 - acc: 0.9386\n",
      "Epoch 00039: val_loss did not improve from 0.21724\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1946 - acc: 0.9386 - val_loss: 0.2236 - val_acc: 0.9408\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1925 - acc: 0.9387\n",
      "Epoch 00040: val_loss did not improve from 0.21724\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1927 - acc: 0.9387 - val_loss: 0.2270 - val_acc: 0.9448\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9384\n",
      "Epoch 00041: val_loss did not improve from 0.21724\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1957 - acc: 0.9384 - val_loss: 0.2275 - val_acc: 0.9369\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1872 - acc: 0.9408\n",
      "Epoch 00042: val_loss did not improve from 0.21724\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1872 - acc: 0.9408 - val_loss: 0.2501 - val_acc: 0.9383\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1787 - acc: 0.9426\n",
      "Epoch 00043: val_loss did not improve from 0.21724\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1787 - acc: 0.9426 - val_loss: 0.2208 - val_acc: 0.9404\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1712 - acc: 0.9458\n",
      "Epoch 00044: val_loss improved from 0.21724 to 0.19780, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/044-0.1978.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1711 - acc: 0.9458 - val_loss: 0.1978 - val_acc: 0.9481\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1736 - acc: 0.9439\n",
      "Epoch 00045: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1736 - acc: 0.9439 - val_loss: 0.2261 - val_acc: 0.9425\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9460\n",
      "Epoch 00046: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1679 - acc: 0.9459 - val_loss: 0.2197 - val_acc: 0.9455\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1686 - acc: 0.9458\n",
      "Epoch 00047: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1686 - acc: 0.9458 - val_loss: 0.2123 - val_acc: 0.9394\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1553 - acc: 0.9496\n",
      "Epoch 00048: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1553 - acc: 0.9496 - val_loss: 0.2114 - val_acc: 0.9464\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9495\n",
      "Epoch 00049: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1583 - acc: 0.9495 - val_loss: 0.2210 - val_acc: 0.9450\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9510\n",
      "Epoch 00050: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1516 - acc: 0.9510 - val_loss: 0.2880 - val_acc: 0.9271\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1524 - acc: 0.9510\n",
      "Epoch 00051: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1524 - acc: 0.9509 - val_loss: 0.2321 - val_acc: 0.9362\n",
      "Epoch 52/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1471 - acc: 0.9526\n",
      "Epoch 00052: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1471 - acc: 0.9526 - val_loss: 0.2619 - val_acc: 0.9334\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1418 - acc: 0.9545\n",
      "Epoch 00053: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1417 - acc: 0.9545 - val_loss: 0.2327 - val_acc: 0.9415\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.9535\n",
      "Epoch 00054: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1430 - acc: 0.9535 - val_loss: 0.2290 - val_acc: 0.9436\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9550\n",
      "Epoch 00055: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1382 - acc: 0.9550 - val_loss: 0.2265 - val_acc: 0.9453\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9543\n",
      "Epoch 00056: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1449 - acc: 0.9544 - val_loss: 0.2384 - val_acc: 0.9385\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9557\n",
      "Epoch 00057: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1336 - acc: 0.9557 - val_loss: 0.2248 - val_acc: 0.9413\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9573\n",
      "Epoch 00058: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1302 - acc: 0.9572 - val_loss: 0.2126 - val_acc: 0.9490\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9583\n",
      "Epoch 00059: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1283 - acc: 0.9583 - val_loss: 0.2337 - val_acc: 0.9392\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1275 - acc: 0.9578\n",
      "Epoch 00060: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1275 - acc: 0.9578 - val_loss: 0.2365 - val_acc: 0.9439\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9588\n",
      "Epoch 00061: val_loss did not improve from 0.19780\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1251 - acc: 0.9588 - val_loss: 0.2089 - val_acc: 0.9511\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9584\n",
      "Epoch 00062: val_loss improved from 0.19780 to 0.19454, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_7_conv_checkpoint/062-0.1945.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1302 - acc: 0.9584 - val_loss: 0.1945 - val_acc: 0.9495\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9609\n",
      "Epoch 00063: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1196 - acc: 0.9609 - val_loss: 0.3048 - val_acc: 0.9290\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9611\n",
      "Epoch 00064: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1175 - acc: 0.9611 - val_loss: 0.2339 - val_acc: 0.9432\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9630\n",
      "Epoch 00065: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1146 - acc: 0.9630 - val_loss: 0.2377 - val_acc: 0.9436\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9611\n",
      "Epoch 00066: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1182 - acc: 0.9611 - val_loss: 0.2339 - val_acc: 0.9380\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9627\n",
      "Epoch 00067: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1121 - acc: 0.9627 - val_loss: 0.2422 - val_acc: 0.9420\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9608\n",
      "Epoch 00068: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1186 - acc: 0.9608 - val_loss: 0.2137 - val_acc: 0.9453\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9627\n",
      "Epoch 00069: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1103 - acc: 0.9627 - val_loss: 0.2238 - val_acc: 0.9497\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9667\n",
      "Epoch 00070: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1005 - acc: 0.9667 - val_loss: 0.2348 - val_acc: 0.9422\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9662\n",
      "Epoch 00071: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1059 - acc: 0.9662 - val_loss: 0.2337 - val_acc: 0.9373\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9646\n",
      "Epoch 00072: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1081 - acc: 0.9646 - val_loss: 0.2882 - val_acc: 0.9266\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9667\n",
      "Epoch 00073: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0996 - acc: 0.9667 - val_loss: 0.2423 - val_acc: 0.9415\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9666\n",
      "Epoch 00074: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1011 - acc: 0.9666 - val_loss: 0.2209 - val_acc: 0.9499\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0998 - acc: 0.9677\n",
      "Epoch 00075: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0998 - acc: 0.9677 - val_loss: 0.2316 - val_acc: 0.9495\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9696\n",
      "Epoch 00076: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0945 - acc: 0.9696 - val_loss: 0.2482 - val_acc: 0.9406\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9684\n",
      "Epoch 00077: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0993 - acc: 0.9683 - val_loss: 0.3301 - val_acc: 0.9245\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9627\n",
      "Epoch 00078: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1116 - acc: 0.9627 - val_loss: 0.2377 - val_acc: 0.9373\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9718\n",
      "Epoch 00079: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0891 - acc: 0.9718 - val_loss: 0.2137 - val_acc: 0.9539\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9711\n",
      "Epoch 00080: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0903 - acc: 0.9711 - val_loss: 0.2885 - val_acc: 0.9327\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9706\n",
      "Epoch 00081: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0912 - acc: 0.9706 - val_loss: 0.2142 - val_acc: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9713\n",
      "Epoch 00082: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0878 - acc: 0.9713 - val_loss: 0.2713 - val_acc: 0.9432\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9701\n",
      "Epoch 00083: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0915 - acc: 0.9701 - val_loss: 0.2357 - val_acc: 0.9446\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9720\n",
      "Epoch 00084: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0861 - acc: 0.9720 - val_loss: 0.2450 - val_acc: 0.9397\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9705\n",
      "Epoch 00085: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0898 - acc: 0.9705 - val_loss: 0.2078 - val_acc: 0.9513\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9736\n",
      "Epoch 00086: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0810 - acc: 0.9736 - val_loss: 0.2588 - val_acc: 0.9366\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9714\n",
      "Epoch 00087: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0889 - acc: 0.9714 - val_loss: 0.2263 - val_acc: 0.9504\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9718\n",
      "Epoch 00088: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0853 - acc: 0.9718 - val_loss: 0.3408 - val_acc: 0.9245\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9729\n",
      "Epoch 00089: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0823 - acc: 0.9729 - val_loss: 0.2230 - val_acc: 0.9476\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9743\n",
      "Epoch 00090: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0783 - acc: 0.9743 - val_loss: 0.2281 - val_acc: 0.9439\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9742\n",
      "Epoch 00091: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0783 - acc: 0.9742 - val_loss: 0.2168 - val_acc: 0.9513\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9761\n",
      "Epoch 00092: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0730 - acc: 0.9761 - val_loss: 0.2332 - val_acc: 0.9499\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9759\n",
      "Epoch 00093: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0752 - acc: 0.9758 - val_loss: 0.2390 - val_acc: 0.9420\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9717\n",
      "Epoch 00094: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0872 - acc: 0.9717 - val_loss: 0.2176 - val_acc: 0.9462\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9762\n",
      "Epoch 00095: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0719 - acc: 0.9762 - val_loss: 0.2897 - val_acc: 0.9373\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9756\n",
      "Epoch 00096: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0740 - acc: 0.9756 - val_loss: 0.2294 - val_acc: 0.9436\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9756\n",
      "Epoch 00097: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0744 - acc: 0.9756 - val_loss: 0.2463 - val_acc: 0.9457\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9757\n",
      "Epoch 00098: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0736 - acc: 0.9757 - val_loss: 0.2127 - val_acc: 0.9488\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9760\n",
      "Epoch 00099: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0722 - acc: 0.9760 - val_loss: 0.2063 - val_acc: 0.9515\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9772\n",
      "Epoch 00100: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0676 - acc: 0.9772 - val_loss: 0.2556 - val_acc: 0.9446\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9769\n",
      "Epoch 00101: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0691 - acc: 0.9769 - val_loss: 0.2507 - val_acc: 0.9427\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9774\n",
      "Epoch 00102: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0673 - acc: 0.9774 - val_loss: 0.2474 - val_acc: 0.9478\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9776\n",
      "Epoch 00103: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0668 - acc: 0.9776 - val_loss: 0.2644 - val_acc: 0.9350\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9790\n",
      "Epoch 00104: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0645 - acc: 0.9790 - val_loss: 0.2165 - val_acc: 0.9529\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9776\n",
      "Epoch 00105: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0671 - acc: 0.9775 - val_loss: 0.2341 - val_acc: 0.9499\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9773\n",
      "Epoch 00106: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0692 - acc: 0.9773 - val_loss: 0.2458 - val_acc: 0.9457\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9788\n",
      "Epoch 00107: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0651 - acc: 0.9788 - val_loss: 0.2331 - val_acc: 0.9432\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9811\n",
      "Epoch 00108: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0582 - acc: 0.9811 - val_loss: 0.2113 - val_acc: 0.9532\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9785\n",
      "Epoch 00109: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0650 - acc: 0.9785 - val_loss: 0.2449 - val_acc: 0.9441\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9798\n",
      "Epoch 00110: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0624 - acc: 0.9798 - val_loss: 0.2561 - val_acc: 0.9397\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9789\n",
      "Epoch 00111: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0635 - acc: 0.9789 - val_loss: 0.3016 - val_acc: 0.9341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9782\n",
      "Epoch 00112: val_loss did not improve from 0.19454\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0692 - acc: 0.9781 - val_loss: 0.2516 - val_acc: 0.9450\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3XecVNX5+PHPmbazvdPLLk3aAtJEUUFRY+8EY4smsf2MiTExsUSjMflGjfpVEkswdo0llqgRRU1A8CuogPQi3V1YtrfZnZ36/P44Wyi7sMAOC+zzfr3mtTO3nHvuMJznnnLPNSKCUkopBeDo6AwopZQ6dGhQUEop1USDglJKqSYaFJRSSjXRoKCUUqqJBgWllFJNNCgopZRqokFBKaVUEw0KSimlmrg6OgP7KisrS3Jycjo6G0opdVhZtGhRqYhk7227wy4o5OTksHDhwo7OhlJKHVaMMVvasp02HymllGqiQUEppVQTDQpKKaWaHHZ9Ci0JhUIUFBRQX1/f0Vk5bHm9Xnr16oXb7e7orCilOtARERQKCgpITk4mJycHY0xHZ+ewIyKUlZVRUFBAbm5uR2dHKdWBjojmo/r6ejIzMzUg7CdjDJmZmVrTUkodGUEB0IBwgPT7U0rBERQU9iYS8RMIbCUaDXV0VpRS6pDVaYJCNFpPMFiISPsHhcrKSp544on92vfMM8+ksrKyzdvfc889PPTQQ/t1LKWU2ptOExSMaTzVaLunvaegEA6H97jvzJkzSUtLa/c8KaXU/ug0QaHxVEXaPyjcdtttbNiwgVGjRnHrrbcyZ84cTjjhBM4991yGDh0KwPnnn8+YMWMYNmwYM2bMaNo3JyeH0tJSNm/ezJAhQ7jmmmsYNmwYp512Gn6/f4/HXbJkCRMmTGDEiBFccMEFVFRUADB9+nSGDh3KiBEjuOSSSwD47LPPGDVqFKNGjeLoo4+mpqam3b8HpdTh74gYkrqjdetuxudb0sKaCJFIHQ5HPMbs22knJY1i4MBHW11///33s2LFCpYsscedM2cOixcvZsWKFU1DPJ999lkyMjLw+/2MGzeOiy66iMzMzF3yvo5XX32Vp59+mu9///u89dZbXH755a0e98orr+Qvf/kLkyZN4u677+bee+/l0Ucf5f7772fTpk3ExcU1NU099NBDPP7440ycOBGfz4fX692n70Ap1Tl0oprCwR1dM378+J3G/E+fPp2RI0cyYcIE8vPzWbdu3W775ObmMmrUKADGjBnD5s2bW02/qqqKyspKJk2aBMAPf/hD5s6dC8CIESO47LLLePnll3G5bACcOHEit9xyC9OnT6eysrJpuVJK7eiIKxlau6KPRuuprV2B15uD250V83wkJiY2vZ8zZw6ffvop8+fPJyEhgcmTJ7d4T0BcXFzTe6fTudfmo9Z88MEHzJ07l/fff58//vGPLF++nNtuu42zzjqLmTNnMnHiRGbNmsXgwYP3K32l1JGrE9UUGvsUpN1TTk5O3mMbfVVVFenp6SQkJLBmzRoWLFhwwMdMTU0lPT2defPmAfDSSy8xadIkotEo+fn5nHTSSTzwwANUVVXh8/nYsGEDeXl5/OY3v2HcuHGsWbPmgPOglDryHHE1hdbFbvRRZmYmEydOZPjw4ZxxxhmcddZZO60//fTTeeqppxgyZAhHHXUUEyZMaJfjvvDCC1x//fXU1dXRr18/nnvuOSKRCJdffjlVVVWICD/72c9IS0vjrrvuYvbs2TgcDoYNG8YZZ5zRLnlQSh1ZTCyunAGMMV5gLhCHDT5visjvdtkmDngRGAOUAdNEZPOe0h07dqzs+pCd1atXM2TIkD3mRySKz7cYj6cncXHd9/FsOoe2fI9KqcOTMWaRiIzd23axbD4KACeLyEhgFHC6MWbXS+QfAxUiMgD4X+CB2GWnsaO5/WsKSil1pIhZUBDL1/DR3fDatVpyHvBCw/s3gSkmRpPw2GQdMblPQSmljhQx7Wg2xjiNMUuAYuATEflyl016AvkAIhIGqoBMYsTe1axBQSmlWhPToCAiEREZBfQCxhtjhu9POsaYa40xC40xC0tKSg4gR1pTUEqpPTkoQ1JFpBKYDZy+y6qtQG8AY28zTsV2OO+6/wwRGSsiY7Ozs/c7H1pTUEqpPYtZUDDGZBtj0hrexwOnArsOjn8P+GHD+4uB/0qshkMBWlNQSqk9i2VNoTsw2xizDPga26fwb2PM740x5zZs8wyQaYxZD9wC3BbD/BxSNYWkpKR9Wq6UUgdDzG5eE5FlwNEtLL97h/f1wNRY5WF3DkQiB+9wSil1mOlE01yAPd3YTJ39+OOPN31ufBCOz+djypQpjB49mry8PN599902pyki3HrrrQwfPpy8vDxef/11AAoLCznxxBMZNWoUw4cPZ968eUQiEa666qqmbf/3f/+33c9RKdU5HHnTXNx8MyxpaepsiIvWg0TAmdji+laNGgWPtj519rRp07j55pu58cYbAXjjjTeYNWsWXq+Xd955h5SUFEpLS5kwYQLnnntum56H/Pbbb7NkyRKWLl1KaWkp48aN48QTT+Qf//gH3/ve97jzzjuJRCLU1dWxZMkStm7dyooVKwD26UluSim1oyMvKOxV+/djH3300RQXF7Nt2zZKSkpIT0+nd+/ehEIh7rjjDubOnYvD4WDr1q0UFRXRrVu3vab5+eef84Mf/ACn00nXrl2ZNGkSX3/9NePGjeNHP/oRoVCI888/n1GjRtGvXz82btzITTfdxFlnncVpp53W7ueolOocjrygsIcr+lD9d4RCZSQn79bVccCmTp3Km2++yfbt25k2bRoAr7zyCiUlJSxatAi3201OTk6LU2bvixNPPJG5c+fywQcfcNVVV3HLLbdw5ZVXsnTpUmbNmsVTTz3FG2+8wbPPPtsep6WU6mS0T6GdTJs2jddee40333yTqVNt33lVVRVdunTB7XYze/ZstmzZ0ub0TjjhBF5//XUikQglJSXMnTuX8ePHs2XLFrp27co111zDT37yExYvXkxpaSnRaJSLLrqIP/zhDyxevDgm56iUOvIdeTWFPbBDUgURaVO7/r4YNmwYNTU19OzZk+7d7Sysl112Geeccw55eXmMHTt2nx5qc8EFFzB//nxGjhyJMYYHH3yQbt268cILL/DnP/8Zt9tNUlISL774Ilu3buXqq68mGrUB709/+lO7nptSqvOI2dTZsbK/U2cDBALbCQYLSEo6GmOcscriYUunzlbqyHUoTJ19yLE1BfSuZqWUakWnCgr6TAWllNqzThUUtKaglFJ71qmCQiyf06yUUkeCThUUmmsKh1fnulJKHSydKihoTUEppfasUwWFWPUpVFZW8sQTT+zXvmeeeabOVaSUOmR0qqAQq5rCnoJCOBze474zZ84kLS2tXfOjlFL7q1MFhVjVFG677TY2bNjAqFGjuPXWW5kzZw4nnHAC5557LkOHDgXg/PPPZ8yYMQwbNowZM2Y07ZuTk0NpaSmbN29myJAhXHPNNQwbNozTTjsNv9+/27Hef/99jjnmGI4++mhOOeUUioqKAPD5fFx99dXk5eUxYsQI3nrrLQA++ugjRo8ezciRI5kyZUq7nrdS6shzxE1zsYeZswE3kchROBxx7MssF3uZOZv777+fFStWsKThwHPmzGHx4sWsWLGC3NxcAJ599lkyMjLw+/2MGzeOiy66iMzMzJ3SWbduHa+++ipPP/003//+93nrrbe4/PLLd9rm+OOPZ8GCBRhj+Pvf/86DDz7Iww8/zH333UdqairLly8HoKKigpKSEq655hrmzp1Lbm4u5eXlbT9ppVSndMQFhT2zkUCEfQoK+2P8+PFNAQFg+vTpvPPOOwDk5+ezbt263YJCbm4uo0aNAmDMmDFs3rx5t3QLCgqYNm0ahYWFBIPBpmN8+umnvPbaa03bpaen8/7773PiiSc2bZORkdGu56iUOvIccUFhT1f0IuDzrcXj6UFcXI+Y5iMxsflBPnPmzOHTTz9l/vz5JCQkMHny5Ban0I6Li2t673Q6W2w+uummm7jllls499xzmTNnDvfcc09M8q+U6pw6WZ+CAUy79ykkJydTU1PT6vqqqirS09NJSEhgzZo1LFiwYL+PVVVVRc+ePQF44YUXmpafeuqpOz0StKKiggkTJjB37lw2bdoEoM1HSqm96lRBwWr/ZypkZmYyceJEhg8fzq233rrb+tNPP51wOMyQIUO47bbbmDBhwn4f65577mHq1KmMGTOGrKyspuW//e1vqaioYPjw4YwcOZLZs2eTnZ3NjBkzuPDCCxk5cmTTw3+UUqo1nWrqbACfbykuVypeb04Mcnd406mzlTpy6dTZrXLohHhKKdWKmAUFY0xvY8xsY8wqY8xKY8zPW9hmsjGmyhizpOF1d6zy03zM2D2SUymlDnexHH0UBn4pIouNMcnAImPMJyKyapft5onI2THMxy60pqCUUq2JWU1BRApFZHHD+xpgNdAzVsdrK60pKKVU6w5Kn4IxJgc4GviyhdXHGmOWGmM+NMYMa2X/a40xC40xC0tKSg4wN1pTUEqp1sQ8KBhjkoC3gJtFpHqX1YuBviIyEvgL8K+W0hCRGSIyVkTGZmdnH2B+tKaglFKtiWlQMMa4sQHhFRF5e9f1IlItIr6G9zMBtzEma9ft2tehUVNISkrq6CwopdRuYjn6yADPAKtF5JFWtunWsB3GmPEN+SmLVZ7scRzA4XVvhlJKHSyxrClMBK4ATt5hyOmZxpjrjTHXN2xzMbDCGLMUmA5cIjG/m86BSKRdU7ztttt2mmLinnvu4aGHHsLn8zFlyhRGjx5NXl4e77777l7Tam2K7ZamwG5tumyllNpfR9wdzTd/dDNLtrc6dzbRaACRIE5ncpuPOarbKB49vfWZ9r755htuvvlmPvvsMwCGDh3KrFmz6N69O3V1daSkpFBaWsqECRNYt24dxhiSkpLw+Xy7pVVeXr7TFNufffYZ0WiU0aNH7zQFdkZGBr/5zW8IBAI82jALYEVFBenp6W0+r13pHc1KHbnaekfzETdL6t61/5zZRx99NMXFxWzbto2SkhLS09Pp3bs3oVCIO+64g7lz5+JwONi6dStFRUV069at1bRammK7pKSkxSmwW5ouWymlDsQRFxT2dEUPEAxuJxAoIClpFMa03+lPnTqVN998k+3btzdNPPfKK69QUlLCokWLcLvd5OTktDhldqO2TrGtlFKx0innPoL2fyTntGnTeO2113jzzTeZOnUqYKe57tKlC263m9mzZ7Nly5Y9ptHaFNutTYHd0nTZSil1IDpdUGh8TnN7j0AaNmwYNTU19OzZk+7duwNw2WWXsXDhQvLy8njxxRcZPHjwHtNobYrt1qbAbmm6bKWUOhBHXEfz3oRC5dTXbyQhYRhOZ3wssnjY0o5mpY5cOnV2qxpPueNvYFNKqUNNpwsKjc1Hh8JdzUopdag5YoJC25vBtKbQksOtGVEpFRtHRFDwer2UlZW1qWDTmsLuRISysjK8Xm9HZ0Up1cGOiPsUevXqRUFBAW2ZVjsaDREMluJ2C06nTkrXyOv10qtXr47OhlKqgx0RQcHtdjfd7bs39fUFLFgwkkGD/kaPHtfGOGdKKXV4OSKaj/aF05kAQDTq7+CcKKXUoafTBQWHwwaFSKSug3OilFKHnk4YFOIAozUFpZRqQacLCsYYHI54rSkopVQLOl1QAHA44olGNSgopdSuOmVQcDoTtPlIKaVa0CmDgsORoM1HSinVgk4ZFJxObT5SSqmWdMqgYGsK2nyklFK76pRBwfYpaE1BKaV21SmDgh19pDUFpZTaVcyCgjGmtzFmtjFmlTFmpTHm5y1sY4wx040x640xy4wxo2OVnx1pR7NSSrUslhPihYFfishiY0wysMgY84mIrNphmzOAgQ2vY4AnG/7GlHY0K6VUy2JWUxCRQhFZ3PC+BlgN9Nxls/OAF8VaAKQZY7rHKk+NnM4UwuGqWB9GKaUOOwelT8EYkwMcDXy5y6qeQP4OnwvYPXC0O4+nK5FIjY5AUkqpXcQ8KBhjkoC3gJtFpHo/07jWGLPQGLOwLQ/SadGCBXDppVBYiMfTFYBgsGj/0lJKqSNUTIOCMcaNDQiviMjbLWyyFei9w+deDct2IiIzRGSsiIzNzs7ev8wUFcGrr8L27bjdNiiEQhoUlFJqR7EcfWSAZ4DVIvJIK5u9B1zZMAppAlAlIoUxyVBqqv1bWak1BaWUakUsRx9NBK4AlhtjljQsuwPoAyAiTwEzgTOB9UAdcHXMcpOWZv9WVuLx9Ac0KCil1K5iFhRE5HPA7GUbAW6MVR52skNQcLu7ABAMbj8oh1ZKqcNF57mjubH5qKoKp9OLy5WmNQWllNpF5wkKKSn2b2UlAG53V+1oVkqpXXSeoOB02sDQEBQ8nq5aU1BKqV10nqAAtl+hyt7JrEFBKaV217mCQmqq1hSUUmoPOldQSEvbqU8hEqkiEqnv4EwppdSho9MGhcYb2EKh4o7MkVJKHVI6X1Bo6lPoBui9CkoptaPOFRR26VMAvatZKaV21LmCQmNNIRrVoKCUUi3ofEEhGgWfT2dKVUqpFnS+oABNU104nSlaU1BKqR20KSgYY35ujElpmOL6GWPMYmPMabHOXLvbYfps0HsVlFJqV22tKfyo4alppwHp2Cmx749ZrmJlh5lSQYOCUkrtqq1BoXEK7DOBl0RkJXuZFvuQtEtQ0EnxlFJqZ20NCouMMR9jg8IsY0wyEI1dtmJkh+mzwd6roPcpKKVUs7Y+ZOfHwChgo4jUGWMyiOVT0mKlheajcLiSaDSAwxHXgRlTSqlDQ1trCscCa0Wk0hhzOfBboCp22YqRFjqaAYJBnepCKaWg7UHhSaDOGDMS+CWwAXgxZrmKFY8HEhL0rmallGpFW4NCuOF5yucBfxWRx4Hk2GUrhlJTm/oU9AY2pZTaWVv7FGqMMbdjh6KeYIxxAO7YZSuGWpgpVWsKSilltbWmMA0IYO9X2A70Av4cs1zFkgYFpZRqVZuCQkMgeAVINcacDdSLyOHXpwA7BQWnMwGnM0mHpSqlVIO2TnPxfeArYCrwfeBLY8zFe9nnWWNMsTFmRSvrJxtjqowxSxped+9r5vfLDn0KAB5Pd4LBwoNyaKWUOtS1tU/hTmCciBQDGGOygU+BN/ewz/PAX9nzKKV5InJ2G/PQPnaoKQDExw/A7193ULOglFKHqrb2KTgaA0KDsr3tKyJzgfL9zVjMNAYFEQDi4wdRV/ct0vBZKaU6s7YGhY+MMbOMMVcZY64CPgBmtsPxjzXGLDXGfGiMGdYO6e1dWhqEQuD3A5CQMIhotI5gcNtBObxSSh3K2tR8JCK3GmMuAiY2LJohIu8c4LEXA31FxGeMORP4FzCwpQ2NMdcC1wL06dPnwI664/xHCQnExw8CoK7uW+Lieh5Y2kopdZhr80N2ROQtEbml4XWgAQERqRYRX8P7mYDbGJPVyrYzRGSsiIzNzs4+sAPvMv9RQoINCn7/tweWrlJKHQH2WFMwxtQALTW2G0BEJGV/D2yM6QYUiYgYY8ZjA1TZ/qbXZrsEhbi4Xjgc8dTVrY35oZVS6lC3x6AgIvs9lYUx5lVgMpBljCkAfkfDXdAi8hRwMXCDMSYM+IFL5GD09u4yKZ4xDuLjB1JXpzUFpZRq65DUfSYiP9jL+r9ih6weXDs8p7lRQsIgfL6lBz0rSil1qGlzn8IRY5fmI7DDUv3+jUSjoQ7KlFJKHRo0KAAJCUcBEerrN3VMnpRS6hDR+YKC1wtu9241BUA7m5VSnV7nCwrG2NrCLn0KoMNSlVKq8wUF2G3+I7c7A5crU0cgKaU6PQ0KDRISBmlNQSnV6XXOoJCa2kJQOEprCkqpTq9zBoVd+hTAdjYHg9sIh2s6KFNKKdXxOmdQSE+Hsp1n1GjubNZnKyilOq/OGRQGDIDiYh2WqpRSu+icQWH4cPt35cqmRQkJR2FMHDU1CzsoU0op1fE6d1BY0fz4aIfDQ3LyWKqrv+igTCmlVMfrnEGhd29ITobly3danJp6HDU1i4lE6jsoY0op1bE6Z1AwxtYWdqgpAKSkHIdIEJ9vcQdlTCmlOlbnDArQHBR2eIRDauqxAFRXz++oXCmlVIfq3EGhrAyKipoWeTxd8Xr7UVWl/QpKqc6pcwcFaKEJ6Viqq7/gYDwETimlDjUaFHYJCqmpxxEMbqe+fksHZEoppTpW5w0KXbpAdnaLNQVAh6YqpTqlzhsUoMURSImJeTgcidqvoJTqlDQorFwJ0WjTIofDRUrKMToCSSnVKWlQ8Pngu+92WpySciw+31LCYV8HZUwppTqGBgXYrQkpLW0yEKGy8r8HPUtKKdWRYhYUjDHPGmOKjTErWllvjDHTjTHrjTHLjDGjY5WXVg0bZv/uFhROxOlMobT03YOeJaWU6kixrCk8D5y+h/VnAAMbXtcCT8YwLy1LTbXzIC1bttNih8NDZuaZlJW9j0jkoGdLKaU6SsyCgojMBcr3sMl5wItiLQDSjDHdY5WfVo0bB199tdvizMzzCIVKqK5ecNCzpJRSHcXVgcfuCeTv8LmgYVnhrhsaY67F1ibo06dP++bimGPg7behpMTet9AgM/MMjHFTWvouqakT2/eYSqnDhgiEQvavMeBwQCTS/Gqc/CAchvp6+3I4ID4evF773hi7XX09+P1QWwvV1Xaci9ttnxCcnNycRjgMLpdd1/hyuSAlBZKSYnu+HRkU2kxEZgAzAMaOHdu+809MmGD/fvUVnHVW02KXK5W0tMmUlr5L//4PtushldobETtSOhSyBUhtrS1cEhLsKxSyhUsoZD8nJoLT2bxtaamd1qukxKbjcNiCxeu12wPU1NhCKRy2hZYxEAxCIGALpsa0olGIi7P7du0KubnQrRusWgVffw3r19v0XS6bh8aXiE07ErHH9njsdrW1UFdn020sOGtrobzcFpTx8baAjI+3aUQi9jwDgeaX32//gs13ONyc33DYHsfphIwM6N7dFrrFxbBtm308e+N6h2P3773xFY3atBqPcyj49a/hgQdie4yODApbgd47fO7VsOzgGjPG/joWLNgpKABkZZ3HunU/pbZ2DYmJgw961tTeVfqr2FxWSP/sXiTH2UsoEfDVRpCoA2MMIraQ3F4UJb+kArcjjjhnPBJx4vfbArDxVhURW+DU1TUXMo0Fo8djC7emK8KA4DAGV8P/osbC1O+HmmAN5WYtpro34utKKNRcEIkJ4/NsoDZhFVFnLc5oAs5oItHNE6kpS8K3XyOhBeJqIHkbJBVCIBVKhkA4vm37pmyFLivAEYaoE4JJUDQCj6TidNrz2m06MEcI15APyRj0LembroDark1BIOgqw+EQPJFMnA7TVLhGozaAJSTY76NGtlOV+n8kBwfSw5VHdrbB74fNNeupq6ogsXIcTmdzUDFJxSRnROnhzMIb56TOVUBV3AoC7kJy4rwkeLykOnqQGcnDEU6ktBQKt0cpKq+ne7cERo+2ASIabb7KF4SQ+Ak6Kgg4Kgg4yhveV+I0Tnq4h9DDMxivM5FotLHGIAScZYQdPjIcfXE4DE4nEFfN0vAb1EYq8UQycIczSKQrSdKdFEdXUhLiiY8Hl7eeYuciNoW+JN6k0oPxpAaGEudx4vXaABsO22DY+AqGIgweXg8k7s8PpM06Mii8B/zUGPMacAxQJSK7NR3FXGIi5OXBl1/utioz81zWrfspZWXvHtZBQUSoClSR5k1r8z7FtcUs2rYIt9PNlNwpGGOa1lXWV/Le2vf456p/Mj9/PrnpuQzLymNQytFM7HYqfROPwuEwTVXe2lr7OOzKSigur2dl6XK2+rYQjIQIhAOUB4soCW2iPLqZWkchfkcRYVNLemQImeGRxId64Q/W4w/V44/UEsRHwFFBfdJqoinNc1SZumwIJiHecvBWQX0qlA+A6l6Q+h1krQG3v/kkywbAouvgm6sh7IXui23BGI6H+jQwERw9l+LssYRo0laEGqLiA28dJNeBieD05eCqGIyp64bDWw3pFYT7bCSYuKnpMImB/qTWjyToqMDvLsDv2ULUEdztO4+LZHB06GeMdV9BgXMeq3iTYpYhJoyYCAmOdDLoR1K0D2FHLXVmOz4poiZSSq2UEWbnS1oHDnon9adXUg5d43vTI74fw5In0s8zgYiEWFT7HrOL32BJ6XzKAyUt/g5yMgcxqe8krhhxJeO7TaRga5SZyxbw0ZZ3WFD3EuXBYoqBmjF3c+2YaxmYMZA3Vr3BvC3zEAS3w01WQhYRieAP+THGkJ7ck+6pvSmsKWRjsX3QVRkQl3kUI3NPZt5381hVbEcEnjXwLB47/TE8Tg/3zLmH55c+T1RsBI93xeMP+1vMt8GQm55LoHeAotoiwtEwlWm5JPYYizexK+sr1rO+fD3FtcX4gr6mNFsVgRRXConeRLwuL0W1RdQF6ux3lJbD2QPPJhQN8fKyl6kN1baajCfgIbUulapAFcHIzr+BeFc8fVL70CO5B71SepGTmUNuWi4V9RXM3jybuVvm8qvIrziJu/ac1wNkYjUbqDHmVWAykAUUAb8D3AAi8pSxpcxfsSOU6oCrRWSvD0geO3asLFzYzs9RvuEG+Mc/oKJit/rkwoVjcDg8jB59aNzh/GXBl1QHqumX3o8+qX1wO90AlNWV8dH6j/hw/YdUB6oZkDGAPql9WFG8go83fEx+dT4n5ZzELcfewsm5J/NF/hf8d9N/KawptE0RgSjldRWU+osp8hdQEmiutB0VuZCjtz1JWZGXFSl/Znu/hxGXn7j6PmRVT6EiUkBd8nJI2m53qOptC2KPD9y1EHVDKN5ehWatAWd49xOry8JZk4OrrgcOf1cIxxHOWEk4a6kt5CNuHFEvrmgiLkkiTlLI5Ch6efLIjutFWbCAkvAmglJHijuDZHca9Y5ySqPrqZJ8unj60D91CH3T+hCRMPWROhaWf8qSinm4HR4iEm6xYHAYB4OzBpOblktyXDKJ7kQS3YkkuBMwxrCxYiNrStdQXFtMmjeNNG8avVN7M6LLCAZnDWZz5Wa+KPiClcUryUrIomdKT/r0b/rfAAAgAElEQVSm9mVo9lCGZQ8jzZuGP+xnu287j3/9OO+tfa/p2H1S+zCp7yQ8Tg8O46DMX8amik18V/UdSZ4kuiV1o0tiF7ISsshKyCI7IZseyT3ontydcn85K4pXsLJkJd9VfUd+VT7bfdsRpCm9+nA9vVN6c2q/UxndfTQjuo4g3h1PJBqhor6CxYWL+WrrV3y68VNqQ7XkpuVSHaimzF+Gy+HinEHncPWoqxmQMYAHv3iQl5a+REQiDM0eytShU0n3prPdt52SuhJcDhfxrngiEqGguoD86nxS41I5pd8pnNj3RJYXLef1la/z+Xefc1zv47hg8AUEIgHum3sfoUgIsFf0N4y9gUGZgyiuLaY6UM3AjIEM7zKc3qm9CUaC+EN+NlduZmnRUlaWrCTBnUD3pO4kuBNYVrSMr7d9TVldGQMyBjAwcyDdk7qT5EkiyZNEujedjPgM0uPTSfemk+ZNIxAJsLpkNatLV1NaV0ptsBZ/2E+XxC70Te2Ly+Fi1oZZfLrxUwThkuGXcMPYGxiSNYRyfzll/jK2+7ZTWFNIcW0xVYEqquqrSPIkMbHPRI7tdSxVgSq+2voViwsXU1BdwLaabeRX51NQXdD0mxyYMZDJOZO5ZPglnJx78n6VHcaYRSIydq/bHW5TRMckKDz/PFx9tZ3yYujQnVZ9992DbNz4G8aPX0NCwlHtelgR4aP1H/HnL/7Mybknc+cJd2KMISpR7vzPnby64lWeP/95JudMBuCR+Y/wy49/uVMaLocLh3EQioQQhHRPFqmubmzzbyAofuIklR71pxBfexQbk1+kPq4AxIARiLjA191+BqhPh9ou4OsG20fCtrHQ8ys4+bc4Qqk4HBCOK6FvzTRyt/+CSP54an2GnBwYNAjium1iffRj1oQ+oS5ahYck3JKIcYXA5cfpEoZk5jG2+xgGdxlAotdLvMdN74xs0hOTW/2OohLF6XC263ffaFnRMl5Y8gJJniTG9xzPiK4jCEfDVNRXICIMzR5KvLstTTDtY3nRcmZtmMWkvpMY22PsTjW0A1VZX8nn333OZ5s/IxwNc/HQizm297E4zJ4HIfqCPt5e/Tavr3ydzPhMzh50Nqf1P223mmd+VT61oVoGZ7VfrXpbzTbunXMvxhjuOOEO+qS280CTduIP+YlIhCRP+/UChyIh8qvz8bq89EjuccDpaVDYF2vWwJAh8OyzNjjsIBgsYv78XvTs+XMGDHhor0mFIiEWblvI7M2zWVWyig0VG9ju2873+n+PG8fdSF7XPIp8RczePJvpX05nfsF80rxpVNZX8oPhP+BvZ/+N/zfz//HyspdJ92ZQHaji2r6PUOwr5a3S+xiXOJUB5f+PbzZtYnPVFupDQSACwWTYcJotyMUBCCQWExfNJC3FRXIypKSFqO//JuGM5fSKHk8/1wlkJSeTmWk75JKSmjsiU1Js22t6OmyPrOS6D64h3h3P/VPuZ1zPce37/SulYk6Dwr6IRm2pOG0a/O1vu61eseJiqqo+49hjC3A44nZbH46G+Wj9R7y49EU+XP8hvqDtKeyb2pf+Gf1JiUvhw3UfEogE6J3Sm/xqOxK3Z3JPbp94F2McV/PIgkf4Z/ntuCIphJ3VxH/xR/yf/RQuuAIGNzQpLP4xvP833C4nI0faPvLsbDtSIymp+ZWRAb16QY8ezSNNlFKdmwaFffW979kxfEuW7LaqvHwWy5adztChr9GlyzREhG0125izeQ7/2fQfZq6bSVFtEVkJWVw05CJO6XcKk3Mmk5WQ1ZRGWV0Zz3zzLLO/XUBa7XjC609i0xejWb7URbChv8kx/E0cZ9zCUYX3cELSj8jJgZ69onzBI3i8Ia4behtOp6FPH3tFr5RSbaVBYV/97nfwhz/YQcy73B0iEuWTeTm8+B2sqevCuvJ1VAeqAciIz2BK7hQuy7uMMwaegcfpadqvrMyO4/7qq+a/xcV2XWKivZm68ZWXB/362WF3SinV3toaFA6Lm9cOimOOsc1ICxfC5Mk7rXp37Xtct6CSUn8NJ+X04coRVzIwcyATe09kVLdRO3WCVlXBSy/BjBmw3I62wxjbZXHmmTYAHHecnaDVpd++UuoQo8VSowkT7HDU//6X0vHD+etXf2V58XJWlaxiTeka8rKH8Pshazhl6ET699/5lkIR+OILeO45eO01Oy5/3Dj4059srBk71rb7K6XUoU6DQqOMDJg4kZKP3ubk7u+wqmQVAzIGMCRrCNeNuY4bx93It2suY9u2J+nT5zbc7nT8fjtgafp0+PZb2yQ0bZq97WHsXitpSil16NGgsIOSc05myqZ72VDm5ZMrPtntJpG+fe+kpOSfbNz4JO++ewcPP2z7CI45xgaHqVNjP1mVUkrFkgaFBjWBGk7xvMa6DPh3wo9bvGswKWkkRUU38+Mfn8/GjXDaaXDHHXDiibbfQCmlDned+3GcDUSE6z+4nhVV6/jX//Viyodrd9smGoXf/x4uu+wRqqrSePbZN5k1CyZN0oCglDpyaE0BeG7Jc/xj+T+476T7+F5tDTzyiB1GlJoK2CmGr7gC3n0XLr3UcP31N+FwfE4kciZOp94dppQ6cnT6msLK4pX8dOZPmZI7hduPvx3OO8/OWfvhhwBs2QITJ8L778Ojj8LLL0Ne3s2EQsXk5z/cwblXSqn21amDgojww3/9kOS4ZF6+8GV7v8Exx9i5I957j8JCOOkk+O47mDkTfv5z21SUlnYC2dnfZ8uWP1BXt3tTk1JKHa46dVD4bMtnLCpcxP+c/D90S+pmFzqdcM45VH7wf5z+vSjFxfDxx3YWjB0NGPAYTmcCa9dei+xtLnallDpMdOqgMP3L6WTGZ3Jp3qU7LfdPvZJzq19i9coo77wtjB+/+75xcd3o3/8hqqrmUlj47EHKsVJKxVanDQqbKzfz7tp3uW7MdbvNl3/nx5OYx4m8FL2MU1c91moa3br9iNTUSWzY8Cv8/g2xzrJSSsVcpw0Kj3/1OAbDDeNu2Gn511/DY4/BDdcL0y4Mwy9/CR991GIaxhgGD34GY5wsX342oVDlwci6UkrFTKcMCrXBWv7+zd+5aOhF9Erp1bQ8FIKf/AS6d4c/3W/gxRft9KU/+AFs3dpiWvHx/Rk+/G38/g2sXHkx0WjoYJ2GUkq1u04ZFF5e9jKV9ZX8/Jif77T8oYdg2TJ4/PGGWxQSE+Gf/4Rg0D6RLdpyh3Ja2iSOOuppKiv/w7p1N3K4TUeulFKNOmVQ+Hjjx/RP78+xvY5tWrZ1K9x7L1x8sb1VocnAgfDww/DJJ/DEE62m2a3bD+nT5w4KC59m27bWt1NKqUNZpwwKK4pXMKrbqJ0eiv7Xv9rmowcfbGGH666DM86AX//aPs+5Fbm595GZeQ7r1v2ciorZMci5UkrFVqcLCv6Qn/Xl6xneZXjTMp8PnnoKLroIcnNb2MkYeOYZ+8DjyZPhP/9pMW1jHAwZ8jIJCYNYuXIqfv/G2JyEUkrFSEyDgjHmdGPMWmPMemPMbS2sv8oYU2KMWdLw+kks8wOwunQ1UYmS1yWvadnzz0NlJdxyyx527N4dPvvMPnfh1FNtW1MksttmLlcKw4e/C0T55pvjqapa0O7noJRSsRKzoGCMcQKPA2cAQ4EfGGOGtrDp6yIyquH191jlp9HyIvuMzMaaQiRi5zQ69lj78LU9GjbMPmj58svhnnvstKktSEgYyKhRc3E44lmyZBKFhc+14xkopVTsxLKmMB5YLyIbRSQIvAact5d9Ym5F8QrinHH0z+gP2InuNmzYSy1hR0lJ8MILNjD88Y82SLS42XDGjPmatLQTWbv2R6xcOY1AoLCdzkIppWIjlkGhJ5C/w+eChmW7usgYs8wY86YxpncM8wPA8uLlDM0eisthZw1/9FHbj3DBBfuQiDHwl7/YJqUrrwS/v8XN3O4M8vI+JCfn95SWvstXXw1h27YZOmRVKXXI6uiO5veBHBEZAXwCvNDSRsaYa40xC40xC0tKSg7ogCuKVzQ1HW3darsJfvQjOw/ePklLs50Ra9fC7be3upnD4SIn5y7GjVtGcvIYvv32OtauvUZvclNKHZJiGRS2Ajte+fdqWNZERMpEJNDw8e/AmJYSEpEZIjJWRMZmZ2fvd4Yq/BVsrdna1Mn89tt2+cUX72eCU6bAz35m58X44x9hDzWAhIRBjBz5KX373sX27c+wbNkZOi2GUuqQE8ug8DUw0BiTa4zxAJcA7+24gTGm+w4fzwVWxzA/rCheATR3Mr/1FgwdCoMHH0Cif/6z7V/47W/t/QzhcKubGmPIzf09gwe/QFXVXBYtGk1Z2YcHcHCllGpfMQsKIhIGfgrMwhb2b4jISmPM740x5zZs9jNjzEpjzFLgZ8BVscoP2P4EgLyueRQVwbx5B1BLaOTx2DmS7rgDnn4azjnHjm9tSSgEW7fSrduVjBo1G4cjjuXLz2TFiot1llWl1CEhpn0KIjJTRAaJSH8R+WPDsrtF5L2G97eLyDARGSkiJ4lI67cLt4MVxStIjUulZ3JP/vUvO5XRRRe1Q8LG2OajGTPg009h/HhYtap5fSgEzz4LRx0FOTnw9dekpk5k7Nil5Ob+kfLyD/jyy4Gs/deJRJMTkHnzdk7/gQfg7rvbIaNKKbVn5nAbCTN27FhZuHDhfu17wnMnADDv6nmcdhps2gTffmvL9Hbz+ee2+lFbC6ecAmVlsH49FBbC2LH2b2oqLF4McXEABALb2LZtBnG3/Zkeb9RR/r1MXG/MJCVlPFRX21FOkQiUlEBycjtmVinVWRhjFonI2L1t19Gjjw4aEbEjj7KHU1YG//2vrSW0a0AAOP54WLgQJk60wcDhgBNOgH//297T8Pe/21rEvfc27RIX14PcnnfQ/T/xiMOQNruMZXOOYeXKS6h95i6oq4NAwN5UoZRSMeTq6AwcLFtrtlJZX0le1zzee89eeB9wf0JrevVq9cE8nH66HQP7wAP25ohx4+zy99/HlJXB//wP5o47GPzNaaxOn0nvv9VQ28+Jx+cm8NydlB63juzsaSQmHkjvuFJKtazT1BR2HHn00UfQsyeMaXEA7EHw8MO2Sejyy6Giwi577jmbqV//GkaNIuv9Mo5L+ISUtVB9ySjKJieQMHcz+avuYdGioyko+KveBKeUanedJiike9O5NO9S8rrksWCBbd1p96ajtkpLg1dftZ0aF18MW7bAhx/CD39o76K7+mpYtAjnr26DuDi6//Jjut30Lo4gHFv2JGlpJ7F+/U0sW3Y6W7c+SXn5x9TX5+/9uGDvvt7D9N+t+tWv4E9/2vf91JGjoy5CnnjC3iiqDg4ROaxeY8aMkQOxdasIiDzyyAEl0z5eeMFmpndv+/fbb+3y0lIRj8cuu+wyuywSEenRQ+SCCyQajUpBwV/ly9cSZf4/kM//hcz5FJk/P1dWr/6xbN/+DwkESlo+5sUXizidIp991vZ8btokYoyIwyGyaNEBnbI6TNXWivTvL3LXXQf3uFVVIvHxIhkZIoHAwT32EQZYKG0oYztNTaHRl1/av3udEfVguPJKuPNOyM+3ndEDB9rlmZnNj3/7ScNs4g6H7Rn/8EPMokX0vHYm4y+pZcKlMPF8OP6SJLp824vS0rdYvfpSvviiC4sWjWfTpnuoqVmESBTmz4c337RpTZsG27e3LZ9PP22rVRkZcMMNLU4ZvpMFC+xzTdW+8/ttLXJv3/HB9pe/2Jkj//d/obz84B33jTfsd1JeDjNnHrzjHioqK6G09OAesy2R41B6HWhN4de/FnG7Rfz+A0qm/UQiIg89JLJ48c7LV60SuecekWi0edncubb2ACIpKSL33Sfy7LMijz0mctRRIh6PRF95WaqqvpRNm+6VRYuOldmzjcyejXw+r4v4RqZJKDtRit69VaLxHgkdf7QE64r3nL9gUKRbN5GzzxZ5+WV77CefbH37zZvtlZ3TKXLHHSL19fv/3RwsX34pUlbW0bmwHnjAfsd/+UvsjrFpk8jXX7d9+4oKkfR0kZEjbd7uu6/l7davF1mxol2y2OS44+xvu1s3kQsuOPD01q8X+fe/Dzydg2HzZtuK0LWr/Tc7QLSxptDhhfy+vg40KJxwgsgxxxxQEh0nEhE54wyRa68VKSraeV1ZmT05EDnvPJErrxS59loJvvaMFBY8L/mPTRIBWfsrl8yejay63QaX6oFIzfgsqZ88QuruuU7Kvn1NSks/lHDYZ9N9802b5vvv2wB18skiqaki27e3nMcLLxRJSLDNXiAyZIgNKCNHigwbJvLuuzH9ivbZ/Pm2aWzMmI6/UohGRQYObA76hYXtf4zt20V69hRxudpeON5xh83TN9+InHmmSFaWbU7akc9n001Pt82fjSIRkS++EAmF9j2va9bY4z7wgMgvf2mv5nZMe18FAiKDB9s0Z83a/3QOhm3bRAYMsP/X0tLs/6OKigNKUoNCC4JBexH785/vdxKHtvp6keuuswVLTo79Dwr2x9W7t8jQoRIN1ovfny/V1YvFd9dVUje2p1SNcEtNfxskIm5k2+nIl6/Gy8qVl0lg0kiJ9u4pEg7bY6xZY/s7TjuteVmjWbPs8f7nf+znDz4QycuzAeHss0WGD7frr75apLLyoH41LaqvFxk61LZXg8g119jl0ajI88+L/PCHIt99d/DyM3u2zcdvf2u/40svbd/0g0F74RAfb/9dvF57zD0pLLRB/pJL7OfG2upf/7rzdnfdZZc7HCI33NC8/L777PJTTtl7bayy0nb2lTT0h91+u61xbtsmsnSpTefxx/fplHfSWAvr2tW+dr2w2pM1a+zve9UqkZqa5uXBoMhbb9lged55InV1+58/ERtEFy+2F1CJifai5b//tQHx5JMPqF9Fg0ILFi2yZ/zqq/udxOElHLZX+uPG2ROfObPFzaLRsFRWfiGV//eM1P/4QokmxEnE7ZBt59nO7o1XIwsWHCVr114vpaX/lsiMJ0RAan9+oeTnPyaBwHZbwA4aZANSa01GgYDInXfaggNE4uJsgXzJJSJbtrR+HqGQyDPP2AL8wgvb7wr6d7+z+fj3v20BBLYp77zz7Htj7BX7c8/t3Iy3q+Ji22yyp21EbAFSXLxzobKjyy6zV4a1tSJ3323z8MknzemvWSNSXm4LjnXrRN54wzbl+XytHzMSac7Xz35m03zlFVvwDh0qkpQk8tFHu+c9EBB5+23bfON0Ng+CiEbtsr597fmI2KYNr9cGsZtusv++S5bYwszhEJkwwQa5AQPsspdesnl56qnm4waDIqeeavPXs6cdCNGzp8hZZzXnaeTItlXzQyGRjRttAGv8rvPzbSF77rk2wMTF2QuVujrbLHrppa3XnObNs9s3Nt2CDay9e4tkZtrP3bvb38v55+98sRQI2MB7xx32d/7kky1faGzebNc3puf12u+q0Ysv2uUHcEWrQaEFjz9uz7gdmucOL9GoLVjaqqBA5OqrJWqMRJ1Oyf/ydlm27Gz57LNEmT0bmTPHJVvPsv85Vv4WWXGfR3yTckRAIjP/3XDIqASD5eLzrZRQqHrn9L/6SuTee20Hz49+ZP8DxMfbq81nnxV58EFbSN96q8gtt9hgAyIjRthtMzJsZN+1IPviC/uf7pNPbJCJRFo/x2XL7NVX49V4OCwyZUpzsHr4YVvwnniiXdavn73KvvBCkR//WOQXv7B5Gz26uaDo3dsWip980hwY8/NtAZiW1rxdYqLIo4/uXHiUldnj3nij/VxXZ4+5Y0HU+DJm58/9+jVf8ft8tjC5+26b38ZRbI1/f/GL5mNu3drcXHXCCSLvvWeD7xVXiGRn2+U9etjCe0fvv2/XHXOMLTCnTrW1ifx8G7QyM+26rl1tc01Njcj//Z9Ily7NeW7Mz9VX24Lz+uvt5zvvtKOcGrf75z+bj/vww3bZY4/ZGsgvfiHyj3/YJrHSUpHp00XGjrVBrHH/zExbc73gAvvb2bjRpvXYY3Z9QkJzId94/B3/XdassTXuQYNEPv3UBtT77xf51a9ErrrKNtP++992n8Y0r73WBsXrrxdJTrbLnE4bOBrzdeyxIh9+aH/DH31kf9PJyTbNF19s+cLnySeb878fNCi04IorbH/V3i7oVIOlS20B1yAc9ktZ2Ueyfv2t8t26P0tozNCmH3kgzdYoZs9GPv88S+bOTZLZs2l4GfnyyyGycuVlsmnTfVJU9IbU1CyVcLihDX/zZluw7FjQOZ22kExIEBk1SuSdd+w/3OrVtsABkZNOElmwwA5bbCxUdnwlJYmMH2+bgX76U1uI/OQnthnLGNs2vmOwLC4WuflmkeXLm5dFIiJPPGHzN3myvbru0cMW7G63DRp/+IPI00/bGobX21zYnHiiLfxcLlsL+P3vbcF1+ul2m/Hj7RVxJNJcoHzzTfOxFy+2gXL6dBsEX37ZNq/ceac93sKFIv/5T3Mhmpdnj9XYjDNunA1cd98t8pvf2FrQrm37fr/t1O7Zs/l7y84WmTbNNv+11hfwwgv2e2jc5/e/b1735JPNBe2O32VBgT2HpUttuo01tQED7N9f/9puV1Vlr5qHDt251llY2BxMGoN34/vG8z76aHtV/swz9jdzxhnN29x7b3Na0aj9zVx6qf0Oa2vtBUpjgLz/fpHXXxfJzbXBbMOGVv+b7OS225qP5/XaoPGvf9mmsWjUNj89+KCtaUHzb3H48ObaWIy0NSh0qgnxBg2CYcPgnXfaOVOd1bZtdqjilCn4j+lNRc0cAoFCgsFCHI54vN4+eDxd8fs3UFOzEJ9vCYHAjjfZOYiP74fX2x+vtzeJxYk4nCmY7C6YpCTCkSpCoXIcjjiSkkaTnDwaj6eLfWbFU0/BffdBcbG9GbC6Gn7xC7jxRnsz4Nq1do6pFSvszXp+v52tNi7OTkx47LF2WO6BPExDZPc7IGtrYc4cO83JvHn2OL/5jZ0dd8f9Xn0Vbr7ZTnLYo4cdgtq7N3z99b7no67OzqX19dd2rPXxx8Nxx9nvpa0CATvDb24uDBnStjs76+rgkUfs5I6vvALx8XZ5JAL/7//BGWfA+efvOY0XX7TDrs85B/75Tztcek82bGj+rjwe+OYb+M9/7NDNSy6BkSN33+frr+25/eIX4PXuOf1nnrEzEm/bZj/Hx9vHMzZOR7M3InYKG6/XDjnPyGh5u2DQ3pD34IP2TtonnoDExLYdYz+1dUK8ThMUSkshOxvuv9/+H1UdIxKpxe9fT23taurq7Ku+fhP19fmEQkUt7GGA5t+ox9OT5OQxJCePJlEGkvrcV7iXbCTym5sJjxmEw+HG7e6C6bDb1fdBTY2d5PCf/4SPP7b3g1x6aUfn6uArLrb35uzzM3FjqLoa1q2DLl1sADoCaFDYxQcfwNln24u4SZPaP1/qwEWjISIRH5GID5EQLlcaLlcqkYiPmppv8PkWUVOzGJ9vMXV1a9kxWOzI4UjA683B6UzAPuvJkJp6AllZ55KaejyRSG1DDcRLXFzPwyOAKHWA2hoUOs0sqb17w0032ZYDdWhyONw4HOm43ek7LXe5UklPn0x6+uSmZeGwj7q61dTWLqe+/jtcrmSczhSi0fqGmscmotEAxriIRv0UFs5g69bpLRwzkYSEQTidiUSjQUDweHrg9fbF681pePVtSlskiMuVTlxcTxwOD6FQBXV1a4lG/aSkjMfpjG0TgFKx1mlqCqpzi0Rqqaj4FJ9vSUMNJJ1IpJa6urX4/WuJRoMY4wYgGNxKff1mIhHfHlI0OJ0pRCJVzUuMm5SUY0lKGonbnYXbnYXTmYzTmYjTmYgxboxx43B4cblSGvavJRDYQiCwjfj4gSQnj8HhcMf421CdkdYUlNqB05lIVtZ5ZGWd16btRYRwuJz6+i1NAcLhiG+oHZQRCOQTCpUSF9eXhISjMMZFZeUcKir+w/btL+4ULPaFw5FISso4XK5MnM4kXK5kXK4MXK50REKEQiWEQuV4PF2Jjx+A251Nff3mpsCWlDSSpKSjSUoahdMZv1952JtoNEx9/Sbi4/tjTKebPu2Ip0FBqRYYY3C7M3G7M0lOHt2mfTIzz2h6H42GCIfLCYdriEZriURqEQkRjYaIRuuJRKoJh6twOhOIi+uLx9OV2tqVVFV9Rk3NIurqVhOJ+AiHq3apjcThdqcTDJYAzZPmOZ3JGOOisHBGw3auhhFb44hEfNTXbyYQKCASqSYSqcHhSCQ5+WiSkkbjcqUSjfqbmtscDi9OZxJxcb3xevtijIdAoIBAYAuVlZ9RUfEJ4XAliYkjyc29j8zMs7Vf5giizUdKHeJEIoTDVRjjxulMwhhDNBoiEPiOYLAYrzcXj6crAIFAPjU1i6mp+ZKqqvn4fItwudLwenOIi+uF05mKy5VMOFxJTc031NYuRyQIGByOOETCDZ3zLfN4upORcTqJicPZuvUJ6us34PX2x+HwIhIkGg0iEkQkhNOZjNudhcuVSjhcSTBYTDRa3xBschpqXSUNNa7eJCePJSHhKPz+Dfh8SwkGtzc0w2U3BOgMXK4MPJ4ueDzdcLuzMcaOWHI44nG50ncKTiJCXd0qystnUVu7ioyM08jMPCdmNahDnY4+UkrtVTQaAqShv8MWqDYI1RAIfEd9/WZEQsTF9SIurhceT4+m7aLRENu3P09Z2fsNNYw4jPHgcHgwxk0kUkMoVEo4XInLlY7b3QWHw0MgkI/fvwmREB5PF1yuDOrrN1FXt4bGEWVeby5xcb0IhcoJhYoJhcqA6B7PxeFIxOvti8MRRyTiIxQqJxwuA2xNKhKpwelMJjl5fENtraYhgEUQiWKMs6HPx4PD4W0INCl4PD2bBhZEIn5EAhjjwelMxOGIb9jPiTFxDQMekhEJEQ5XNdT0fA3HCuF2d8Hj6Y7X24eEhKNwuVIREQKBrdTXb2zob0rD4UhoqFkGCIVKqa/fSAKrlWYAAAf5SURBVH39JpKTjyEz8/T9+rfWoKCUOqyEwzX4/RuIj++Hy5Wy0zqRaEOQsUEiGCwiFCpBxAaKSMTXEMS2NNRSknA6U0hOHktGxveIi+tJZeVnFBW9Qm3tiob1STgc3oZ+EUdDcLAFsUiAaLSecLiSQGAr4XDFDrnZ+d6Zttt9P4+nW9Mw7Lbs36fP7fTr98f9OPYh0tFsjDkdeAxwAn8Xkft3WR8HvAiMAcqAaSKyOZZ5UkodmlyuZJKTR7W4zhgHLlcqLlcq8fG5+5V+evrJpKefvF/7RiJ1iIQbBhu4G/qG/ESj/oYmt0hT7SMcrsHhcDc01aU2jEBLwhgHoVApwWAh9fWbqatbQ13dWpzOZBIShhAf36+phhGJ1DbUuOJwudIa7vy3taBYi1lQMLax73HgVKAA+NoY856IrNphsx8DFSIywBhzCfAA/P/27i9GrrKM4/j3ZwtKWaWChWirtEijVmMLNqSKmoZ6IUooFyAqKCEx3GAEo1Ew/okkXpgYUaNBCKBFG0BL0cYQ/xVS5YLCQlGh1dig4pJC1whVNCh/fl6874zT7W67me3s7Jn5fZJm55w5O3nfPrvz7LznnOfh/F6NKSKiG/PmLdhvu9xTcwTwssm/YQrlfMjxjIysBKZ3Jdxs6+X1ZKcBu20/4nIm6xYO/F9YD2yojzcB65TLGCIi+qaXSWEx0Fn9bKzum/QYl0se9gHH9XBMERFxEI2480TSJZJGJY2Oj4/3ezgREQOrl0nhMaCzvOCSum/SYyTNB46hnHDej+3rbK+2vXrRokU9Gm5ERPQyKdwHLJe0TNKRwPuBLROO2QJcVB+fC9zppl0jGxExQHp29ZHt5yR9FPgZ5ZLUG20/LOkqSgegLcANwPck7Qb+TkkcERHRJz29T8H2HcAdE/Z9vuPxM8B5vRxDRERMXyNONEdExOxoXJkLSePAX7r89lcAfzuMw5lLMrdmytyaqYlzO9H2Ia/UaVxSmAlJo9Op/dFEmVszZW7NNMhzy/JRRES0JSlERETbsCWF6/o9gB7K3Jopc2umgZ3bUJ1TiIiIgxu2TwoREXEQQ5MUJL1b0h8k7ZZ0Rb/HMxOSXi3pLkk7JT0s6bK6/1hJv5D0x/r15f0eazckzZO0Q9JP6vYySdtr7G6tZVMaR9JCSZsk/V7SLklvHaCYfbz+LD4k6WZJL2lq3CTdKGmvpIc69k0aJxXfqHP8raRT+zfyw2MokkJHw58zgRXABySt6O+oZuQ54BO2VwBrgEvrfK4AttpeDmyt2010GbCrY/vLwNW2TwaepDRnaqKvAz+1/XpgJWWOjY+ZpMXAx4DVtt9EKWvTaprVxLh9F5jYCHmqOJ0JLK//LgGumaUx9sxQJAWm1/CnMWzvsf1AffxPypvLYvZvWrQBOKc/I+yepCXAe4Hr67aAMyhNmKC58zoGeCel3he2/2v7KQYgZtV84Kha7XgBsIeGxs32ryi12DpNFaf1wE0u7gEWSnrl7Iy0N4YlKUyn4U8jSVoKnAJsB06wvac+9ThwQp+GNRNfAz4FvFC3jwOeqk2YoLmxWwaMA9+pS2PXSzqaAYiZ7ceArwCPUpLBPuB+BiNuLVPFaeDeW4YlKQwkSSPAbcDltv/R+VwtQd6oS8sknQXstX1/v8fSA/OBU4FrbJ8C/IsJS0VNjBlAXV9fT0l8rwKO5sDll4HR1DhN17Akhek0/GkUSUdQEsJG25vr7idaH13r1739Gl+XTgfOlvRnyhLfGZR1+IV1WQKaG7sxYMz29rq9iZIkmh4zgHcBf7I9bvtZYDMlloMQt5ap4jRw7y3DkhSm0/CnMeo6+w3ALttf7Xiqs2nRRcCPZ3tsM2H7SttLbC+lxOhO2xcAd1GaMEED5wVg+3Hgr5JeV3etA3bS8JhVjwJrJC2oP5utuTU+bh2mitMW4MP1KqQ1wL6OZaZGGpqb1yS9h7Je3Wr486U+D6lrkt4O/Br4Hf9fe/8M5bzCD4DXUCrJvs/2xBNmjSBpLfBJ22dJOonyyeFYYAdwoe3/9HN83ZC0inIC/UjgEeBiyh9mjY+ZpC8C51OujNsBfISytt64uEm6GVhLqYT6BPAF4EdMEqeaBL9JWS77N3Cx7dF+jPtwGZqkEBERhzYsy0cRETENSQoREdGWpBAREW1JChER0ZakEBERbUkKEbNI0tpW9deIuShJISIi2pIUIiYh6UJJ90p6UNK1tcfD05Kurn0DtkpaVI9dJemeWk//9o5a+ydL+qWk30h6QNJr68uPdPRV2FhvgIqYE5IUIiaQ9AbK3bmn214FPA9cQCn0Nmr7jcA2yp2uADcBn7b9Zspd5q39G4Fv2V4JvI1SQRRKVdvLKb09TqLUCYqYE+Yf+pCIobMOeAtwX/0j/ihKAbQXgFvrMd8HNtc+CQttb6v7NwA/lPRSYLHt2wFsPwNQX+9e22N1+0FgKXB376cVcWhJChEHErDB9pX77ZQ+N+G4bmvEdNb/eZ78HsYckuWjiANtBc6VdDy0+/OeSPl9aVX9/CBwt+19wJOS3lH3fwjYVjvijUk6p77GiyUtmNVZRHQhf6FETGB7p6TPAj+X9CLgWeBSSmOc0+pzeynnHaCUUv52fdNvVT+FkiCulXRVfY3zZnEaEV1JldSIaZL0tO2Rfo8jopeyfBQREW35pBAREW35pBAREW1JChER0ZakEBERbUkKERHRlqQQERFtSQoREdH2P9fmPhXH7G1eAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 991us/sample - loss: 0.2401 - acc: 0.9354\n",
      "Loss: 0.24014565102670918 Accuracy: 0.9354102\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.2123 - acc: 0.1758\n",
      "Epoch 00001: val_loss improved from inf to 1.88975, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/001-1.8898.hdf5\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 3.2124 - acc: 0.1758 - val_loss: 1.8898 - val_acc: 0.4512\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0172 - acc: 0.3753\n",
      "Epoch 00002: val_loss improved from 1.88975 to 1.10019, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/002-1.1002.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 2.0173 - acc: 0.3753 - val_loss: 1.1002 - val_acc: 0.6862\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4823 - acc: 0.5297\n",
      "Epoch 00003: val_loss improved from 1.10019 to 0.76450, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/003-0.7645.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.4822 - acc: 0.5298 - val_loss: 0.7645 - val_acc: 0.7817\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1489 - acc: 0.6408\n",
      "Epoch 00004: val_loss improved from 0.76450 to 0.57525, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/004-0.5753.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.1488 - acc: 0.6408 - val_loss: 0.5753 - val_acc: 0.8439\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9239 - acc: 0.7117\n",
      "Epoch 00005: val_loss improved from 0.57525 to 0.52831, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/005-0.5283.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.9240 - acc: 0.7116 - val_loss: 0.5283 - val_acc: 0.8423\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7704 - acc: 0.7612\n",
      "Epoch 00006: val_loss improved from 0.52831 to 0.39521, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/006-0.3952.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.7706 - acc: 0.7611 - val_loss: 0.3952 - val_acc: 0.8891\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6483 - acc: 0.7989\n",
      "Epoch 00007: val_loss improved from 0.39521 to 0.39274, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/007-0.3927.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.6484 - acc: 0.7989 - val_loss: 0.3927 - val_acc: 0.8915\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5641 - acc: 0.8246\n",
      "Epoch 00008: val_loss improved from 0.39274 to 0.33782, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/008-0.3378.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5644 - acc: 0.8245 - val_loss: 0.3378 - val_acc: 0.9031\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5038 - acc: 0.8433\n",
      "Epoch 00009: val_loss did not improve from 0.33782\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5040 - acc: 0.8432 - val_loss: 0.4758 - val_acc: 0.8595\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4532 - acc: 0.8604\n",
      "Epoch 00010: val_loss improved from 0.33782 to 0.24177, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/010-0.2418.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4532 - acc: 0.8604 - val_loss: 0.2418 - val_acc: 0.9315\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4148 - acc: 0.8738\n",
      "Epoch 00011: val_loss improved from 0.24177 to 0.22618, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/011-0.2262.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4148 - acc: 0.8738 - val_loss: 0.2262 - val_acc: 0.9338\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3845 - acc: 0.8814\n",
      "Epoch 00012: val_loss did not improve from 0.22618\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3847 - acc: 0.8813 - val_loss: 0.2625 - val_acc: 0.9224\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3550 - acc: 0.8901\n",
      "Epoch 00013: val_loss did not improve from 0.22618\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3550 - acc: 0.8901 - val_loss: 0.2319 - val_acc: 0.9322\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3291 - acc: 0.8997\n",
      "Epoch 00014: val_loss improved from 0.22618 to 0.22048, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/014-0.2205.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3292 - acc: 0.8997 - val_loss: 0.2205 - val_acc: 0.9385\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3146 - acc: 0.9033\n",
      "Epoch 00015: val_loss improved from 0.22048 to 0.21327, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/015-0.2133.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3146 - acc: 0.9033 - val_loss: 0.2133 - val_acc: 0.9392\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2928 - acc: 0.9114\n",
      "Epoch 00016: val_loss improved from 0.21327 to 0.20572, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/016-0.2057.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2928 - acc: 0.9114 - val_loss: 0.2057 - val_acc: 0.9408\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2725 - acc: 0.9155\n",
      "Epoch 00017: val_loss improved from 0.20572 to 0.18904, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/017-0.1890.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2727 - acc: 0.9154 - val_loss: 0.1890 - val_acc: 0.9443\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2643 - acc: 0.9173\n",
      "Epoch 00018: val_loss improved from 0.18904 to 0.18509, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/018-0.1851.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2643 - acc: 0.9173 - val_loss: 0.1851 - val_acc: 0.9457\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2431 - acc: 0.9260\n",
      "Epoch 00019: val_loss improved from 0.18509 to 0.16280, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/019-0.1628.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2430 - acc: 0.9260 - val_loss: 0.1628 - val_acc: 0.9515\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2282 - acc: 0.9275\n",
      "Epoch 00020: val_loss did not improve from 0.16280\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2283 - acc: 0.9275 - val_loss: 0.1659 - val_acc: 0.9532\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2297 - acc: 0.9272\n",
      "Epoch 00021: val_loss did not improve from 0.16280\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2298 - acc: 0.9272 - val_loss: 0.1642 - val_acc: 0.9509\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2124 - acc: 0.9336\n",
      "Epoch 00022: val_loss did not improve from 0.16280\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2125 - acc: 0.9336 - val_loss: 0.2108 - val_acc: 0.9369\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2031 - acc: 0.9365\n",
      "Epoch 00023: val_loss did not improve from 0.16280\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2032 - acc: 0.9364 - val_loss: 0.1828 - val_acc: 0.9467\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9384\n",
      "Epoch 00024: val_loss did not improve from 0.16280\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1961 - acc: 0.9384 - val_loss: 0.2132 - val_acc: 0.9362\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1902 - acc: 0.9403\n",
      "Epoch 00025: val_loss improved from 0.16280 to 0.15219, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/025-0.1522.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1902 - acc: 0.9403 - val_loss: 0.1522 - val_acc: 0.9543\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1798 - acc: 0.9445\n",
      "Epoch 00026: val_loss did not improve from 0.15219\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1799 - acc: 0.9445 - val_loss: 0.1529 - val_acc: 0.9539\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1757 - acc: 0.9442\n",
      "Epoch 00027: val_loss did not improve from 0.15219\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1758 - acc: 0.9441 - val_loss: 0.1536 - val_acc: 0.9569\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1706 - acc: 0.9462\n",
      "Epoch 00028: val_loss did not improve from 0.15219\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1707 - acc: 0.9461 - val_loss: 0.1794 - val_acc: 0.9515\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9474\n",
      "Epoch 00029: val_loss did not improve from 0.15219\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1672 - acc: 0.9474 - val_loss: 0.1571 - val_acc: 0.9536\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9536\n",
      "Epoch 00030: val_loss did not improve from 0.15219\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1506 - acc: 0.9536 - val_loss: 0.1650 - val_acc: 0.9548\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9534\n",
      "Epoch 00031: val_loss did not improve from 0.15219\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1499 - acc: 0.9534 - val_loss: 0.1701 - val_acc: 0.9492\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9515\n",
      "Epoch 00032: val_loss did not improve from 0.15219\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1536 - acc: 0.9515 - val_loss: 0.1564 - val_acc: 0.9578\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9545\n",
      "Epoch 00033: val_loss did not improve from 0.15219\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1462 - acc: 0.9545 - val_loss: 0.1584 - val_acc: 0.9515\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9570\n",
      "Epoch 00034: val_loss did not improve from 0.15219\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1367 - acc: 0.9570 - val_loss: 0.1568 - val_acc: 0.9529\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9610\n",
      "Epoch 00035: val_loss did not improve from 0.15219\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1269 - acc: 0.9610 - val_loss: 0.2551 - val_acc: 0.9373\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9561\n",
      "Epoch 00036: val_loss did not improve from 0.15219\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1379 - acc: 0.9561 - val_loss: 0.1637 - val_acc: 0.9567\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9614\n",
      "Epoch 00037: val_loss improved from 0.15219 to 0.14317, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/037-0.1432.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1206 - acc: 0.9614 - val_loss: 0.1432 - val_acc: 0.9604\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9628\n",
      "Epoch 00038: val_loss improved from 0.14317 to 0.12670, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_8_conv_checkpoint/038-0.1267.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1173 - acc: 0.9628 - val_loss: 0.1267 - val_acc: 0.9627\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9640\n",
      "Epoch 00039: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1122 - acc: 0.9640 - val_loss: 0.1626 - val_acc: 0.9562\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9643\n",
      "Epoch 00040: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1094 - acc: 0.9643 - val_loss: 0.1700 - val_acc: 0.9504\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9654\n",
      "Epoch 00041: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1081 - acc: 0.9654 - val_loss: 0.1387 - val_acc: 0.9599\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9677\n",
      "Epoch 00042: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1031 - acc: 0.9677 - val_loss: 0.1675 - val_acc: 0.9522\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9658\n",
      "Epoch 00043: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1039 - acc: 0.9658 - val_loss: 0.1374 - val_acc: 0.9639\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9679\n",
      "Epoch 00044: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1000 - acc: 0.9679 - val_loss: 0.1390 - val_acc: 0.9602\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9680\n",
      "Epoch 00045: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0983 - acc: 0.9680 - val_loss: 0.1738 - val_acc: 0.9504\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9670\n",
      "Epoch 00046: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0990 - acc: 0.9670 - val_loss: 0.1558 - val_acc: 0.9578\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9702\n",
      "Epoch 00047: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0920 - acc: 0.9701 - val_loss: 0.1712 - val_acc: 0.9539\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9679\n",
      "Epoch 00048: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1033 - acc: 0.9679 - val_loss: 0.1590 - val_acc: 0.9592\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9734\n",
      "Epoch 00049: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0832 - acc: 0.9734 - val_loss: 0.1408 - val_acc: 0.9648\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9743\n",
      "Epoch 00050: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0807 - acc: 0.9742 - val_loss: 0.1606 - val_acc: 0.9555\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9729\n",
      "Epoch 00051: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0834 - acc: 0.9729 - val_loss: 0.1512 - val_acc: 0.9557\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9748\n",
      "Epoch 00052: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0777 - acc: 0.9747 - val_loss: 0.1873 - val_acc: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9724\n",
      "Epoch 00053: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0846 - acc: 0.9724 - val_loss: 0.1922 - val_acc: 0.9515\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9760\n",
      "Epoch 00054: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0742 - acc: 0.9760 - val_loss: 0.1449 - val_acc: 0.9625\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9775\n",
      "Epoch 00055: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0719 - acc: 0.9775 - val_loss: 0.1836 - val_acc: 0.9539\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9785\n",
      "Epoch 00056: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0687 - acc: 0.9785 - val_loss: 0.1598 - val_acc: 0.9595\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9753\n",
      "Epoch 00057: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0755 - acc: 0.9753 - val_loss: 0.1548 - val_acc: 0.9623\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9788\n",
      "Epoch 00058: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0652 - acc: 0.9788 - val_loss: 0.1937 - val_acc: 0.9502\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9770\n",
      "Epoch 00059: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0732 - acc: 0.9770 - val_loss: 0.2345 - val_acc: 0.9369\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9765\n",
      "Epoch 00060: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0699 - acc: 0.9765 - val_loss: 0.1430 - val_acc: 0.9620\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9801\n",
      "Epoch 00061: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0612 - acc: 0.9801 - val_loss: 0.1692 - val_acc: 0.9532\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9787\n",
      "Epoch 00062: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0641 - acc: 0.9787 - val_loss: 0.1570 - val_acc: 0.9595\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9794\n",
      "Epoch 00063: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0615 - acc: 0.9794 - val_loss: 0.1369 - val_acc: 0.9616\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9780\n",
      "Epoch 00064: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0686 - acc: 0.9780 - val_loss: 0.1493 - val_acc: 0.9597\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9814\n",
      "Epoch 00065: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0583 - acc: 0.9813 - val_loss: 0.1364 - val_acc: 0.9648\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9811\n",
      "Epoch 00066: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0583 - acc: 0.9810 - val_loss: 0.1565 - val_acc: 0.9634\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9807\n",
      "Epoch 00067: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0584 - acc: 0.9807 - val_loss: 0.1379 - val_acc: 0.9669\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9842\n",
      "Epoch 00068: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0515 - acc: 0.9842 - val_loss: 0.1627 - val_acc: 0.9581\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9828\n",
      "Epoch 00069: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0524 - acc: 0.9827 - val_loss: 0.1595 - val_acc: 0.9557\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9817\n",
      "Epoch 00070: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0575 - acc: 0.9817 - val_loss: 0.1659 - val_acc: 0.9576\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9851\n",
      "Epoch 00071: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0489 - acc: 0.9851 - val_loss: 0.1383 - val_acc: 0.9637\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9839\n",
      "Epoch 00072: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0500 - acc: 0.9838 - val_loss: 0.1617 - val_acc: 0.9548\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9822\n",
      "Epoch 00073: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0551 - acc: 0.9822 - val_loss: 0.1971 - val_acc: 0.9522\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9808\n",
      "Epoch 00074: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0601 - acc: 0.9808 - val_loss: 0.1394 - val_acc: 0.9634\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9871\n",
      "Epoch 00075: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0425 - acc: 0.9871 - val_loss: 0.1642 - val_acc: 0.9613\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9820\n",
      "Epoch 00076: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0549 - acc: 0.9819 - val_loss: 0.1766 - val_acc: 0.9602\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9855\n",
      "Epoch 00077: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0441 - acc: 0.9855 - val_loss: 0.1625 - val_acc: 0.9597\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9875\n",
      "Epoch 00078: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0395 - acc: 0.9875 - val_loss: 0.1781 - val_acc: 0.9590\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9861\n",
      "Epoch 00079: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0438 - acc: 0.9861 - val_loss: 0.2081 - val_acc: 0.9585\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9872\n",
      "Epoch 00080: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0405 - acc: 0.9872 - val_loss: 0.1551 - val_acc: 0.9623\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9873\n",
      "Epoch 00081: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0423 - acc: 0.9873 - val_loss: 0.1637 - val_acc: 0.9616\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9870\n",
      "Epoch 00082: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0403 - acc: 0.9870 - val_loss: 0.2124 - val_acc: 0.9483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9868\n",
      "Epoch 00083: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0403 - acc: 0.9868 - val_loss: 0.2218 - val_acc: 0.9534\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9854\n",
      "Epoch 00084: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0465 - acc: 0.9854 - val_loss: 0.1755 - val_acc: 0.9604\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9887\n",
      "Epoch 00085: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0366 - acc: 0.9887 - val_loss: 0.1614 - val_acc: 0.9620\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9880\n",
      "Epoch 00086: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0373 - acc: 0.9880 - val_loss: 0.2255 - val_acc: 0.9483\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9873\n",
      "Epoch 00087: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0389 - acc: 0.9873 - val_loss: 0.2035 - val_acc: 0.9546\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9832\n",
      "Epoch 00088: val_loss did not improve from 0.12670\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0531 - acc: 0.9832 - val_loss: 0.1608 - val_acc: 0.9588\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8XVW5+P/POnPmOU2ajkChc9MJCrVQBZmtIJaCICAK4gWFL4j2InpRrz9BcUJQrAgCF5lBQMsg2tKiZWhLofM8JWnTJM2cnPn5/bFOpjZJ0zanaXKe9+u1X8nZ4zo7O/vZa9hrGRFBKaWUAnD0dQKUUkodPzQoKKWUaqVBQSmlVCsNCkoppVppUFBKKdVKg4JSSqlWGhSUUkq10qCglFKqlQYFpZRSrVx9nYDDlZubKyNGjOjrZCilVL+yYsWKShHJO9R6/S4ojBgxguXLl/d1MpRSql8xxuzsyXpafKSUUqqVBgWllFKtNCgopZRq1e/qFDoTCoUoKSnB7/f3dVL6LZ/Px5AhQ3C73X2dFKVUHxoQQaGkpIS0tDRGjBiBMaavk9PviAhVVVWUlJQwcuTIvk6OUqoPDYjiI7/fT05OjgaEI2SMIScnR3NaSqmBERQADQhHSc+fUgoGUFA4lEikmUCglGg01NdJUUqp41bCBIVo1E8wuAeR3g8KNTU1/O53vzuibS+88EJqamp6vP4999zD/ffff0THUkqpQ0mYoGCM/aoi0V7fd3dBIRwOd7vtwoULyczM7PU0KaXUkUiYoADO2M9Ir+95/vz5bN26leLiYu68804WL17MrFmzmDNnDmPHjgXgkksuYerUqYwbN44FCxa0bjtixAgqKyvZsWMHY8aM4YYbbmDcuHGce+65NDc3d3vcVatWMWPGDCZOnMill15KdXU1AA888ABjx45l4sSJXHHFFQC88847FBcXU1xczOTJk6mvr+/186CU6v8GRJPU9jZvvo2GhlWdLIkSiTTicCRhzOF97dTUYkaN+nWXy++9917WrFnDqlX2uIsXL2blypWsWbOmtYnno48+SnZ2Ns3NzUyfPp3LLruMnJycA9K+maeffpo//vGPXH755bz44otcffXVXR73mmuu4be//S1nnXUWP/jBD/jhD3/Ir3/9a+699162b9+O1+ttLZq6//77eeihh5g5cyYNDQ34fL7DOgdKqcSQQDmFFnJMjnLqqad2aPP/wAMPMGnSJGbMmMHu3bvZvHnzQduMHDmS4uJiAKZOncqOHTu63H9tbS01NTWcddZZAFx77bUsWbIEgIkTJ3LVVVfxf//3f7hcNgDOnDmT22+/nQceeICamprW+Uop1d6AuzN09UQfjYZobPwYr3cYHk9+3NORkpLS+vvixYt5++23WbZsGcnJycyePbvTdwK8Xm/r706n85DFR135+9//zpIlS3jttdf4yU9+wurVq5k/fz4XXXQRCxcuZObMmbz55puMHj36iPavlBq4EianEM+K5rS0tG7L6Gtra8nKyiI5OZkNGzbw3nvvHfUxMzIyyMrKYunSpQA8+eSTnHXWWUSjUXbv3s2nP/1p7rvvPmpra2loaGDr1q1MmDCB7373u0yfPp0NGzYcdRqUUgPPgMspdK0l/vV+RXNOTg4zZ85k/PjxXHDBBVx00UUdlp9//vk8/PDDjBkzhlNOOYUZM2b0ynEff/xxbrrpJpqamjjhhBN47LHHiEQiXH311dTW1iIifOtb3yIzM5Pvf//7LFq0CIfDwbhx47jgggt6JQ1KqYHFiBybMvbeMm3aNDlwkJ3169czZsyYQ25bX78StzsPn29ovJLXr/X0PCql+h9jzAoRmXao9RKm+AjAGCfxyCkopdRAEbegYIzxGWM+MMZ8bIxZa4z5YSfreI0xzxpjthhj3jfGjIhXeixHXOoUlFJqoIhnTiEAfEZEJgHFwPnGmAML078KVIvIScCvgPvimB6McSKiOQWllOpK3IKCWA2xj+7YdGAFxueBx2O/vwCcbeLYXadtgaQ5BaWU6kpc6xSMMU5jzCpgH/APEXn/gFWKgN0AIhIGaoGcA9bBGHOjMWa5MWZ5RUXFUaTIqcVHSinVjbgGBRGJiEgxMAQ41Rgz/gj3s0BEponItLy8vCNOj80paPGRUkp15Zi0PhKRGmARcP4Bi0qBoQDGdkiUAVTFLyXHT04hNTX1sOYrpdSxEM/WR3nGmMzY70nAZ4EDX6N9Fbg29vsXgX9JHF+cMMahFc1KKdWNeOYUCoFFxphPgA+xdQp/M8b8yBgzJ7bOn4AcY8wW4HZgfhzT01rR3NtxZ/78+Tz00EOtn1sGwmloaODss89mypQpTJgwgVdeeaXH+xQR7rzzTsaPH8+ECRN49tlnAdizZw9nnnkmxcXFjB8/nqVLlxKJRLjuuuta1/3Vr37Vq99PKZU44tbNhYh8AkzuZP4P2v3uB+b26oFvuw1WddZ1NrijQZwSAGfa4e2zuBh+3XXX2fPmzeO2227j5ptvBuC5557jzTffxOfz8fLLL5Oenk5lZSUzZsxgzpw5PRoP+aWXXmLVqlV8/PHHVFZWMn36dM4880z+8pe/cN555/G9732PSCRCU1MTq1atorS0lDVr1gAc1khuSinVXgL1fQQYYo1iJfahd0yePJl9+/ZRVlZGRUUFWVlZDB06lFAoxF133cWSJUtwOByUlpZSXl5OQUHBIff57rvvcuWVV+J0Ohk0aBBnnXUWH374IdOnT+f6668nFApxySWXUFxczAknnMC2bdv45je/yUUXXcS5557ba99NKZVYBl5Q6OaJPhysJBDYQUrKBIzD2+V6R2Lu3Lm88MIL7N27l3nz5gHw1FNPUVFRwYoVK3C73YwYMaLTLrMPx5lnnsmSJUv4+9//znXXXcftt9/ONddcw8cff8ybb77Jww8/zHPPPcejjz7aG19LKZVgEqzvo/h1nz1v3jyeeeYZXnjhBebOtSVitbW15Ofn43a7WbRoETt37uzx/mbNmsWzzz5LJBKhoqKCJUuWcOqpp7Jz504GDRrEDTfcwNe+9jVWrlxJZWUl0WiUyy67jP/93/9l5cqVvf79lFKJYeDlFLphO8SDeLyrMG7cOOrr6ykqKqKwsBCAq666is997nNMmDCBadOmHdagNpdeeinLli1j0qRJGGP42c9+RkFBAY8//jg///nPcbvdpKam8sQTT1BaWspXvvIVolEb7H7605/2+vdTSiWGhOo6Oxyup7l5I0lJJ+Nypccrif2Wdp2t1MClXWd3Ip7FR0opNRAkVFCA+BUfKaXUQJBQQUFzCkop1b0ECwqaU1BKqe4kVFBo+bqaU1BKqc4lVFCw3Utop3hKKdWVhAoKEJ/R12pqavjd7353RNteeOGF2leRUuq4kXBBwY6p0Ls5he6CQjgc7nbbhQsXkpmZ2avpUUqpI5VwQSEeOYX58+ezdetWiouLufPOO1m8eDGzZs1izpw5jB07FoBLLrmEqVOnMm7cOBYsWNC67YgRI6isrGTHjh2MGTOGG264gXHjxnHuuefS3Nx80LFee+01TjvtNCZPnsw555xDeXk5AA0NDXzlK19hwoQJTJw4kRdffBGAN954gylTpjBp0iTOPvvsXv3eSqmBZ8B1c9FNz9kARCIjMQYchxEOD9FzNvfeey9r1qxhVezAixcvZuXKlaxZs4aRI0cC8Oijj5KdnU1zczPTp0/nsssuIyen43DUmzdv5umnn+aPf/wjl19+OS+++CJXX311h3U+9alP8d5772GM4ZFHHuFnP/sZv/jFL/jxj39MRkYGq1evBqC6upqKigpuuOEGlixZwsiRI9m/f3/Pv7RSKiENuKBwKMbQ64PsdObUU09tDQgADzzwAC+//DIAu3fvZvPmzQcFhZEjR1JcXAzA1KlT2bFjx0H7LSkpYd68eezZs4dgMNh6jLfffptnnnmmdb2srCxee+01zjzzzNZ1srOze/U7KqUGngEXFLp7ogdobi4jGg2QkjIurulISUlp/X3x4sW8/fbbLFu2jOTkZGbPnt1pF9peb1t33k6ns9Pio29+85vcfvvtzJkzh8WLF3PPPffEJf1KqcSUcHUK8ahoTktLo76+vsvltbW1ZGVlkZyczIYNG3jvvfeO+Fi1tbUUFRUB8Pjjj7fO/+xnP9thSNDq6mpmzJjBkiVL2L59O4AWHymlDinhgkI8KppzcnKYOXMm48eP58477zxo+fnnn084HGbMmDHMnz+fGTNmHPGx7rnnHubOncvUqVPJzc1tnX/33XdTXV3N+PHjmTRpEosWLSIvL48FCxbwhS98gUmTJrUO/qOUUl1JqK6zAfz+EkKhctLSpsYjef2adp2t1MClXWd3weYU5JhUNiulVH+TgEFBO8VTSqmuxC0oGGOGGmMWGWPWGWPWGmNu7WSd2caYWmPMqtj0g3ilp412iqeUUl2JZ5PUMHCHiKw0xqQBK4wx/xCRdQest1RELo5jOjpoG1NBcwpKKXWguOUURGSPiKyM/V4PrAeK4nW8nmspPtKcglJKHeiY1CkYY0YAk4H3O1l8ujHmY2PM68aY+L5Rho6+ppRS3Yl7UDDGpAIvAreJSN0Bi1cCw0VkEvBb4K9d7ONGY8xyY8zyioqKo0yPzSn0dfFRampqnx5fKaU6E9egYIxxYwPCUyLy0oHLRaRORBpivy8E3MaY3E7WWyAi00RkWl5e3lGmquUra05BKaUOFM/WRwb4E7BeRH7ZxToFsfUwxpwaS09VvNJkj9P7OYX58+d36GLinnvu4f7776ehoYGzzz6bKVOmMGHCBF555ZVD7qurLrY76wK7q+6ylVLqSMWz9dFM4MvAamNMS2fWdwHDAETkYeCLwDeMMWGgGbhCjvKtstveuI1Ve7vpOxshEmnA4fBijKdH+ywuKObX53fd0968efO47bbbuPnmmwF47rnnePPNN/H5fLz88sukp6dTWVnJjBkzmDNnTmxY0M511sV2NBrttAvszrrLVkqpoxG3oCAi7wJd3/3sOg8CD8YrDZ0zsWPbbrR7w+TJk9m3bx9lZWVUVFSQlZXF0KFDCYVC3HXXXSxZsgSHw0FpaSnl5eUUFBR0ua/OutiuqKjotAvszrrLVkqpozHwus7u5om+RX39CtzuQfh8Q3rtuHPnzuWFF15g7969rR3PPfXUU1RUVLBixQrcbjcjRozotMvsFj3tYlsppeIl4bq5sJz0dkXzvHnzeOaZZ3jhhReYO3cuYLu5zs/Px+12s2jRInbu3NntPrrqYrurLrA76y5bKaWORkIGBWMcvd4kddy4cdTX11NUVERhYSEAV111FcuXL2fChAk88cQTjB49utt9dNXFdlddYHfWXbZSSh2NhOs6G6CxcQ0ORxJJSSf2dvL6Ne06W6mBS7vO7lbvj76mlFIDQUIGBVt8pC+vKaXUgQZMUDi8YjAnOp5CR/2tGFEpFR8DIij4fD6qqqp6fGPTnEJHIkJVVRU+n6+vk6KU6mMD4j2FIUOGUFJSQk87ywuFqohGm/B6B8TX7xU+n48hQ3rvvQ2lVP80IO6Kbre79W3fntiy5duUlT3MmWc2xDFVSinV/wyI4qPD5XSmEo02ahGSUkodIGGDAkAk0tTHKVFKqeNLggcFLT5SSqn2NCgopZRqpUFBKaVUKw0KSimlWmlQUEop1UqDglJKqVYaFJRSSrXSoKCUUqpVggeF+j5OiVJKHV8SMig4HF7AqTkFpZQ6QNyCgjFmqDFmkTFmnTFmrTHm1k7WMcaYB4wxW4wxnxhjpsQrPQccF6czVYOCUkodIJ69pIaBO0RkpTEmDVhhjPmHiKxrt84FwKjYdBrw+9jPuNOgoJRSB4tbTkFE9ojIytjv9cB6oOiA1T4PPCHWe0CmMaYwXmlqz+VKIxKpOxaHUkqpfuOY1CkYY0YAk4H3D1hUBOxu97mEgwNHXLjdgwgG9x6LQymlVL8R96BgjEkFXgRuE5EjejQ3xtxojFlujFne09HVDsXrLSIQKO2VfSml1EAR16BgjHFjA8JTIvJSJ6uUAkPbfR4Sm9eBiCwQkWkiMi0vL69X0maDQpkOWK+UUu3Es/WRAf4ErBeRX3ax2qvANbFWSDOAWhHZE680tef1FiESIBSqOhaHU0qpfiGerY9mAl8GVhtjVsXm3QUMAxCRh4GFwIXAFqAJ+Eoc09OBx2OrLoLBUjye3GN1WKWUOq7FLSiIyLuAOcQ6AtwcrzR0x+sdDEAgUEZq6qS+SIJSSh13EueN5ro6+Ogj8PsBW3wEaGWzUkq1kzhB4fXXYcoU2LYNAI/Hvg4RDGpQUEqpFokTFLKz7c/9+wFwODy43fmaU1BKqXYSNiiAvquglFIHSrygUNXWBFWDglJKdZQ4QSEnx/5sl1PweIq0TkEppdpJnKCQlgZO50HFR6FQJdFooA8TppRSx4/ECQrG2CKkA4IC2HcVlFJKJVJQABsU2tUpeDwtL7BpEZJSSkGiBYWcnE5zClqvoJRSVmIFBS0+UkqpbvUoKBhjbjXGpMd6M/2TMWalMebceCeu1x0QFFyuLBwOnxYfKaVUTE9zCtfHBsg5F8jC9n56b9xSFS8H1CkYY7RZqlJKtdPToNDS2+mFwJMispZD9IB6XMrOhoYGCAZbZ+kLbEop1aanQWGFMeYtbFB40xiTBkTjl6w4aXmBrbq6dZYGBaWUatPT8RS+ChQD20SkyRiTzTEcEKfXtO//aNAgoC0oiAh2sDillEpcPc0pnA5sFJEaY8zVwN1AbfySFSeddIrn8dhhOcPh/V1spJRSiaOnQeH3QJMxZhJwB7AVeCJuqYqXLjrFA32BTSmloOdBIRwbOvPzwIMi8hCQFr9kxUknneK1DcupQUEppXpap1BvjPlvbFPUWcYYB+COX7LipIviI9CgoJRS0POcwjwggH1fYS8wBPh53FIVL+npnfSUanMKwaC+1ayUUj0KCrFA8BSQYYy5GPCLSP+rUzAGsrI61CnYYTnzNKeglFL0vJuLy4EPgLnA5cD7xpgvHmKbR40x+4wxa7pYPtsYU2uMWRWbfnC4iT8iB3R1AfquglJKtehpncL3gOkisg/AGJMHvA280M02fwYepPtWSktF5OIepqF3HNBTKugIbEop1aKndQqOloAQU3WobUVkCXD8Nf7XnIJSSnWpp0HhDWPMm8aY64wx1wF/Bxb2wvFPN8Z8bIx53Rgzrhf2d2gHdIoHLcNyVuiwnEqphNej4iMRudMYcxkwMzZrgYi8fJTHXgkMF5EGY8yFwF+BUZ2taIy5EbgRYNiwYUd31C5yCgCBwB6SkkYc3f6VUqof6/EgOyLyoojcHpuONiAgInUi0hD7fSHgNsbkdrHuAhGZJiLT8vLyju7A2dlQXw+hUOssn+8EAJqbNx3dvpVSqp/rNigYY+qNMXWdTPXGmLqjObAxpsDEeqAzxpwaS0tV91v1gk56Sk1JsSVXjY1r4354pZQ6nnVbfCQiR9yVhTHmaWA2kGuMKQH+h9hb0CLyMPBF4BvGmDDQDFwR60ojvtq/1ZyfD4DHk4/bnatBQSmV8HraJPWwiciVh1j+ILbJ6rHVSad4AMnJ42hq0qCglEpsPa5TGDA66f8IICVlPI2N6zgWmRWllDpeJV5Q6KSnVLD1CpFIHYFASR8kSimljg+JFxS6zCloZbNSSiVeUEhPB4fjoDqFtqDQaVdNSimVEBIvKDgctqfUA3IKbncObvcgrWxWSiW0xAsK0OlbzdBS2axBQSmVuBIzKHTSUyrYIiTbAinaB4lSSqm+l5hBoZNO8cAGhWi0Eb9/Vx8kSiml+l7iBoUucgqA1isopRKWBoV2kpO1BZJSKrElZlDIyYG6ug49pQK43Zl4PIO1slkplbASMyi0vMBWU3PQIm2BpJRKZIkdFLqobG5qWq8tkJRSCSmxg0IXlc3RaDN+//ZjnCillOp7GhQO0FbZrEVISqnEk5hBoYueUgFSUsYCGhSUUokpMYNCN3UKLlc6Xu8wGhs/OcaJUkqpvpeYQSEjA4zpNKcAkJ5+OrW17+qAO0qphJOYQaGLnlJbZGbOJhAowe/fdowTppRSfSsxgwLYeoWKik4XZWbOBqCmZvGxS49SSh0HEjconHgibN7c6aLk5FNwuwdpUFBKJZzEDQpjx8KGDRCJHLTIGENm5mxqahZrvYJSKqHELSgYYx41xuwzxnTau5yxHjDGbDHGfGKMmRKvtHRq3Djw+2Fb5/UGWq+glEpE8cwp/Bk4v5vlFwCjYtONwO/jmJaDjbMvqbG28/cRtF5BKZWI4hYURGQJ0HnzHuvzwBNivQdkGmMK45Weg4y1L6l1FRS0XkEplYhcfXjsImB3u88lsXl7jsnR09Jg2LAug8KB9QrGmGOSLKXU8SMcti3YHZ08Pou0TS2MaZsOJRqFhgZoarL7dzrt5HJ1/L2zY8dTXwaFHjPG3IgtYmLYsGG9t+Nx47oMCmCLkCoqnsXv30ZS0om9d1yl2hGB6mr7gn0oZG9ELTcjj8dOTicEArYazO+3N4vkZEhJsb/X1dl91NTYm0wgAMGg/RkOt+3X54P0dDv5fHa7mhqorbU3Mp/PTi3HdDjs/Kamtv03Nraly+u13yESsZNI2zKPB5qb7b5ra+0NsOWG2bLflp+RSNt6LT3at+zf4wG3235Pt9umpWW95mY7r/0xfT67XcvUsv3+/bB7N5SU2O1zc6GgAPLz7fFratrORXOzncJhmxan0+7L5bLnsuV8dqd9cHA6O36f5mZ77g/VjsUY+0pVTo7tiOG66+Cmm474UuuRvgwKpcDQdp+HxOYdREQWAAsApk2b1nvNgcaNg3/9y/51XQefivb1ChoUeiYYCVIfqCcQCZCbnIvH6Tmi/USiEXbV7sLlcFGYVojLYf8+waC9uTQ22n/g6mr7z97UZP9x8vMhNauRndUlbN1Tza591ZTX1NIYaqQp1EhzpAlXOJ2UyDCSgkNJDg3FE81CogYReyn4Q0Eq2Ui9lGHqh0H1SAKNPnCGiGSvoTn7Q/zJW8GfjvgziTZm4aofia9+PM5wGhB72vMEiabtJhCA5qpsGqoyaG5y4E1rwJOzB1fmXuplD9WRMiK+PeBpgKqToWIcVIwFfyYgYAQiboh4uz5h7kYY9AkUrIJwElSeAlWnQHMWeOshdQ+k7QFftT2Otx7EwN7JsGdy1/t2BuGUV8ERhsrRmP0nk+JJJiR+At4SSC8Bby24m8HdBM4QhL0QSoKwD7z1ODP24s0ux5lagwl7IOJBIh7E2UzUU0PEU4NxhklOHkWmZzS5uWPwRfKJBpIJNKfQ2Owh1OgnGPUTlGZcGftwDSvBMaGEVG8Dyf5RJDWOxls3mqg/Db/fXhd+PzQ79lGftoLm9FV4UwNkTUli1Owk0nxJNNZ7qK91s6najdPjIjXHQUGqgxOTHPi8TnweJz6vEyNOQiEH4aCTcDRC2FVNyFVN2FmDOMI4cOI0LrySQREzyJKTWq8nsDf+SATqgjVUhndQHd0F3jo8yX7cSQFSvF5GOM8g34whGjVEIm0PBs3+KHuqayivq2JfQxX7JR844Yj+p3qqL4PCq8AtxphngNOAWhE5NkVHLcaNs49S27bByScftLh9vUJh4VePadI6E5Uo4WiYQDiAP+wnEAlQH6inxl9Djb+GukAdgUiAYCRIIBygqrmK0rpSyhrKKG8oxx/2t27ncrhIdieT4k4hKymLM4acwVkjzuK0otNwGAebqjaxZt8aSutLGZ07muKCYgpTC6lorOTFdX/lpXUv8V7Zv4mKYMQB4iAofkLi75DmFJNDminEiIugNBGUJsLiJyxBIoSImiAmmIajaTDOxsE4IilEMrYSTt+MOAOxL+7ANBUi9YPAhO2NyhmE6hNhy3mw9TyoHgkn/w3GPwujFoIr0PWJdMQmd+xzKAlH42AcjYVIUhWRQZvtTbCFGLzBwYRcVUSdse8XdXVcJyYpMBxfaAjN7hL8nt1g2sblMOLAiZca03zQdk48eBw+mqN1XSY7zZlLnmcY+d6hOHDRFGqiKdxIXbiC8shGhIPHAPE6vQQi3ZwLwO1wMzG/mNMGn8G0/E9RnP0pJOzhLxv/wBMbf0uFv/2/pcHty6TBX93tPtuLAFGXj3RfJuFomGAkSDAcIMmdRKYvk0xfJgCbq5awLdTI4bT3MxiEtufEJFcSqZ5UUj2pBCNBSus7Pmfua//BC+Qe4gAtu3bTdr10tx4wKHUQM4fNxOP0sLdhL+UN5ZTVl1EbqD14u2BsAnKTc/nUsE/hNE5K6kooqSthb2QvkbwI5Nl1PjPqu8C9h0j00THxaodvjHkamI097eXA/xA7rSLysLGF9A9iWyg1AV8RkeWH2u+0adNk+fJDrtYzH3wAp50GL70El17a6Spr115BXd2/mTFj11HVK7y8/mUW71hMY6iRxlAjIsLEQROZNngaUwunEo6GWb1vNWv2rWF9xXp21+1md91uSupKqA/UE5GD36foibzkPAYlDybVDMJDMi58OMRLRCIEoo34o43sD+5lZ/NqBMER9QJC1BE8eGdNOfZJ0xG1N+Et59snQhO1U9gHgXQIpkHEA8kV9uk0dU9seRKEbBpSkzykpXjISHWDt45GRxlNjj0ETR3JwRNIaRqNt+FknK4okZQSQsm7Cbn34XG58bq8eFwuyqKrKAmsA8BhHEQlSparkMmeyzkpaTpFuVkMz89iWH4G2ampZKakkJmcTGOkhpL63eyq3cWu2l2U1ZdRWl9KWX0ZWb4sxuWNY3z+eIrSi9hdu5ut1VvZVr2N7KRspg+ezvSi6ZyYdSLBSJBqfzX7m/ezZf8W1uxbw+p9qymtK2VYxjBOyDqBkZkjcRgH+5v3U+2vpinURH5KPgWpBRSkFlCYWsjgtMFkJ9lOGvc17mNdxTrWVayjIdiAMQaDIRAJUFpXyq46m+aoRDsE9UmDJjGlcArFBcUEI0E2VG5gY+VG9jbsJT8ln8FpgylMKyQ7KZs0T1rrTXN52XLeL32fZSXL+LD0Q5rDNmC5HW5C0RCfPeGz/L8Z/4+i9CI2VG5gQ+UG9jbsZXDaYIakD2Fo+lCykrJIciUb80hlAAAgAElEQVSR5E7C7XATiARaH0BSPakMShlEujf9kP8/IkJpfSkbKjewv3k/jcFGmkJNBCIBfC4fSa4kfC4feSl5FKUVUZRehM/lY1v1NtZXrG/driHYQEOoAYOhuKCYqYVTmVw4mVRPKoFwgKZQE83hZkKRkA1QkSBRibZOEYkQiUZaf7bMi0oUh3GQ6cskOymbTF8mLoeLSDRCOBpmX+M+/r3737y7613+s/s/GGMYlDKo9W89InMEIzJHMDxjOJm+THwuH16Xl1p/LUt3LeWdne/w713/xuVwMTRjKEPThzI4bTC5ybnkJOWQk5zD6NzRnJB1ZDkFY8wKEZl2yPX628tZvRoUGhpshfOPfwx3393pKqWlD7N58zeYPn09KSmjj+gwr29+nYv+chEpnhTSvekku5OJRCNsr+l8IJ/c5FyGZwxnSPoQhqQPIcObgdPhxGmcuBwuPE4voWYfNZVegg1pRBozCdVnEqxPI9TsI+j3EGz2UL4jk80bvFRW9iCRvmocI5eSMnYJST4n2aEJ5MsEsj2DCaZvoC55FTXeT8hwFlDsuYyRSZNISTFkZ9tim5wcW14qYivQWsqnk5Ls5PPZcl2ns2eVcD21u3Y3b219i01Vm7hg1AXMGjYLp8PZewdIIMFIkJV7VvLurnfZU7+H64qvY8KgCX2dLNVLNCj01IgRcPrp8PTTnS4OBMpYtmwow4d/j5Ejf9RhWSQaoaKpghVlK/iw7EM+2vsRpxWdxndnfrf1xrS9ejtTF0xlWMYw/vPV/5DsTm7dvsZfw8o9K1lRtgKP08OEQRMYnz+eLE8+W7bAmjW2HnzPnrZKvn37YOtWG88O5PPZyseWm3BhIYweDaecAiecYCslWyq6HI62lhNOJxQV2Uq3TqpWlFIDQE+Dgt4CDtECyesdTFbWOZSXP0ly3n/xlVeu572S91qztS0MhuGZw3l146ss3rGYv1z2F1LcKVz23GUIwouXv9ghIESj0LQ/E0/pZ8jf+hk2bYKHNtieN7ZssRWqYG/e+fmQmWmnIUPgrLNg1Cg46ST7OTvbTj5f3M6SUipBaFAYNw7efrvLFkgABQXX8PcPr+byBZOpaK7h2knXkuHNIMWTQoY3g+KCYqYUTiHNm8YjKx/hloW3MOUPtnz3o70f8bcr/8Ygz4m89RYsWQJLl8KHH9pmaS2cTnuTHz0aPvc5m6zx4+3npKRjdC6UUglPg8K4cfaxfOtWW84ChKNhav21rRVBy/Z7uGUVpLrrWHLdEqYXTe9yd1+b8jUmF0zmi89/kdc2vcaFyT/gwVsv4gv/sodxOmHKFLjxRtvg6cQTbdHO8OG2WEcppfqSBoX2fSCdcgp7G/Yy+8+z2Vi1seNqWTn8aKyfKQXju93dzp2w6PmpZP91BTuq/8nC9V/gpBPhm9+E886z1RepqfH6MkopdXQ0KIwZY3+uXUvdRedwwVMXsLtuN/edcx8Ggz/sJ8WTwrwTR7N53UVUVr7CoEFXdNhFNAqvvgq//KUtGgKYMiWb/+/quVxyiS0C0l4ylFL9gQaFlBQYOZLAuk+49NlLWbNvDa9e8SoXjLqgw2oiUXZ5h1Je/mRrUAgG4bHH4Be/sOP1jBgBP/0pzJ1ri4WUUqq/0aAARMeO4ZqUt/jX9joev+TxgwICgDEOBg26il27fk4gsJcNGwq47jpYtQqmTYNnn4UvfEGbdCql+rfEHXmtnQcm+XluaB0/+8xPuWbSNV2uN2jQlwmHDXffvZXp06GszL4M/cEHcPnlGhCUUv1fwt/GyhvK+R/vMs7bDN++5OAcQnuNjWO5/faVrF49gSuuiPLb3zrIPVTfKUop1Y8kfE7hv//53zSbML95Hcybb3a53ubNtuXQli1j+P735/HAA3/VgKCUGnASOih8UPoBj616jNtm3MYpQ4vhb3/rdL333rMBoa7Ovud24YXL2bXrPvpbFyFKKXUoCRsUohLlloW3UJBawN1n3g0XXwz//rftnL+dd96BT3/adjGxbBmccYaLoUPvoL7+A2prl/ZR6pVSKj4SNij8edWf+bDsQ352zs9I96bboBCNwhtvtK6za5dtXjpihA0IJ51k5xcUXIfbncvu3T/vm8QrpVScJGxQ+Om7P+W0otO4euLVdsb06ZCX11qE5PfDZZfZn3/9q13UwulMpqjoFqqq/kZjY9ed6SmlVH+TkEGhrL6MLfu3cPm4y9sG/nA44KKL4PXXkVCY//ovWL4cnnyytUukDgYPvhmHI4ndu+8/tolXSqk4SsigsHSnrQs4c/iZHRdcfDHU1PCH+dt57DH4/vfh85/vfB8eTy6FhV+lvPwpmpu3xjnFSil1bCRmUNi1lFRPKsUFxR0XnHsula4Cvv3bYZx3HtxzT/f7GTr0uzgcSWzY8FVEDh4fVyml+puEDApLdi7h9CGn43Ic8O5eWho/H/JrmkJufvUrW6LUHZ9vCCed9Ctqa9+htPSh+CVYKaWOkYQLCtXN1azZt4ZZw2YdtGzfPniw7At8ib8wxtOzIqGCgq+QnX0B27bN12IkpVS/l3BB4d+7/40gB9cnAD/7GfjDLn7Aj7p8ke1AxhhOPnkBxrjZsOF6LUZSSvVrCRcUlu5citvh5tSiUzvM37sXfvc7uPpqw8nFKfCDH3R4Z6E7thjp19TWLmH37l/GI9lKKXVMxDUoGGPON8ZsNMZsMcbM72T5dcaYCmPMqtj0tXimB2wl8/Si6SS5Ow58fN99dnyE738feOUVGDnSNlF94AHoQXcWBQXXkpv7BbZt+w7l5U/HKfVKKRVfcQsKxhgn8BBwATAWuNIYM7aTVZ8VkeLY9Ei80gPQFGriw7IPD6pPKCuD3/8errkm9tbysGHw7rswZw7ceit84xv2beduGGMYM+b/yMg4kw0brqGq6u9x/CZKKRUf8cwpnApsEZFtIhIEngG6aPV/bLxf8j7haPig+oQ//QkCAfje99rNTE2FF1+EO+6AP/wBXnvtkPt3OpOYMOFVUlImsnbtF6mp0b6RlFL9SzyDQhGwu93nkti8A11mjPnEGPOCMWZoHNPD0l1LMRjOGHpG6zwR+9by7NmdDKHpcMC998KQIfBQz5qculzpTJz4Bj7fCFavvlgDg1KqX+nriubXgBEiMhH4B/B4ZysZY240xiw3xiyvqKg44oMt3bWUiYMmkunLbJ33wQd2rIQvf7mLjVwuuOkm+Mc/YMOGHh3H48lj4sR/kNyUx8cff5aKir8ecZqVUupYimdQKAXaP/kPic1rJSJVIhKIfXwEmNrZjkRkgYhME5Fpee17pjsMoUiIZbuXHVSf8MQT4PPBF7/YzcY33AAeT49zCwC+l5cy5eKdZNeMZu3ayygrW3BE6VZKqWMpnkHhQ2CUMWakMcYDXAG82n4FY0xhu49zgPXxSsxHez+iMdTYoT4hGIRnnrH9G6Wnd7Nxfj7Mmwd//rMdaacnfvMbTDjMuD1fJTv7PDZt+jpbt36HaDRw6G2VUqqPxC0oiEgYuAV4E3uzf05E1hpjfmSMmRNb7VvGmLXGmI+BbwHXxSs95Q3lFKYWMmt4W07h9dftmDpdFh21d8st0NBgKyAO5aOP4P33AXC8+z7jx79CYeHX2b3756xYcSoNDZ8c4bdQSqn4Mv1tSMlp06bJ8uXLj2hbEWnrKhtbZLRkCZSWgtvdgx2ceirU18O6ddBuPwf5+tdt8Jg5EzZtgp07AaisfI2NG28gHN7PiBH3MHToHTgc3iP6LkopdTiMMStEZNqh1uvriuZjqn1AqK62rUyvvLKHAQFsbmHDBnj+efsKdEPDwe8v1NXBU0/BFVfY9xx27WoNCrm5n2P69DXk5l7C9u3f44MPRlNe/pR2jaGUOm4kVFBo7/nnbZ3CNdccxkaXX26HYJs3DwoLIS0NcnJsy6QW//d/0NhoWyydGau/WNrWLNXjyWXs2GeZOPENXK5M1q+/muXLp1BV9Tr9LdemlBp4Eqr4qL2zzoKKCli7tvuSoIOsWQMrVtgbf2OjLSbatAlefhnOPx8mTbJZj+XLbS4iJ8cGkwUHtz4SibJv37Ns3343fv82MjJmccIJPyUjY+ZRfz+llGqvp8VHrkOtMBBVV9teLO666zADAsD48XZqcf318NnPwiWXwJ13wurVNgAYA04nfOpTHXIK7RnjYNCgK8nLu4w9ex5h584f89FHnyI7+yKGD7+LjIwzOt1OKaXiJSGLj/7xD/sQf8EFvbCznBz45z9tDuEnP7FFSlde2bZ81ixbD7FvX5e7cDg8FBX9F6edtoWRI39KXd0yPvpoJitXzqSy8hWtc1BKHTMJGRTeeAMyM21jol6RlWUjzec/D3ffbftNatFSr/Duu4fcjdOZwvDh8zn99F2cdNIDBINlrFlzCf/5TwFr186jrOwPNDdv66VEK6XUwRKuTkEEiopsqc5zz/ViwroSDNoI9PWvw69+dVibRqNhKitfpqrqNaqr/0kwWAZAevoZFBZ+lby8y3G5Ug+xF6WU0jqFLq1eDXv29FLRUU94PHDaafaFiMPkcLjIz59Lfv5cRITm5k1UVr7Knj1/YuPGr7Jly63k5V3OoEFXkZl5Fra3cqWUOnIJFxRaBlM777xjeNAzz4T//V/7DkO3/Wl0zRhDcvIpDBt2J0OHfpu6uv+wZ88jVFQ8x969j+LxFJGfP5eUlEkkJ59MUtLJeDy5vfxFlFIDXUIGhYkTYfDgY3jQWbNszfZ//mObrba3bp1ttZSaCj/6EZxyyiF3Z4whI2MmGRkzGTXqIaqqXqO8/ClKSx9CJNS6XnLyWAoKrmPQoC/j9Rb09rc6fjQ22pzY+ecfQXMypVR7CVXRXF9v63sPvC/H3emn2y64//AHWLnSBohg0AaB4mJ47z1YuBDGjbOjvO3d2+NdO53J5OfPY8KEV5k1q5FTT93EhAl/58QT78flymTbtu+wbNkQPvnkIkpKHqSxcf3Ae0nuttvgwgvtm+Tq6In0vONHNeAkVEXzK6/Y1wn+9S/49Kd7OWGH8vWvt73Alp9vm65u3Wqbr/7mN/Yf8Uc/soHD4bDBYto0mDrVBouRI+3b1If5JNzYuIHy8sfZt+9Z/P7tAHg8g/F6hxCNBhAJYIybrKxzyMmZQ0bGp3A4+lEG8qOP7DlyuWwrsA0b7E91ZPbsgWuvte/WLF9urz115CorbWkAtLVE7IoI/PrXkJ0Nc+dCcnKvJqWnFc0JFRS+8Q37AvL+/bb+95jbu9c2XX3zTdi2zb49d/HFHdfZvNkGj+XL7ZvT9fVty1JSbHA44YS2afp0OzkPXcnc3LyN6up/UlPzL0KhahwOLw6Hl3C4hpqadyAUZORffLizTsB/3fkk5RWTnDyGpKQTcK3egfnxj2HGDPjud3v5xBwhERvd1661/ZacfTbceKMdcFsdvoUL4brrbJ9eHo8tZ33nHS2Sa7Fypf2fvP767v/fqqvtzWbRoo7vJ910EzzwQNedrd19t33XCWzd45e+ZLeZNKlXkt/ToICI9Ktp6tSpciSiUZERI0TmzDmizftGJCKyYYPIq6+K/OY3IrfdJvL5z4tMmCCSnCxib4sieXki114r8tRTIosWiXz8scju3SLhcI8PFSrfIYFZ41v3GchAttyIfPAosvdsOy/iNiIg5f89Q7Zvv0fKyh6V2toPJRxuitsp6NYLL9j0/v739vOtt4oYI/Lee32TnmNl1y6RN94QeeIJkfvvF/ntb0UCgSPfX1OTPXdgr621a0UeecR+fuyxXkv2MRMMivz85yIXXiiyZ8/R72/zZpF589r+3770JXuMzmzbJjJ6tIjHI3Lddfbv8/rrIt/5jt129myRioqDt/vDH+zyr31N5J13RL78ZRGfz17PP/zhYf0vdwVYLj24x/b5Tf5wpyMNChs2dLx/9HvRqEhZmchf/mIv0qystou2ZRoyROR//kdk587u97VunciJJ9oL+fHHRZYtk+h557XuJ+JzS9XXp8napefJ/k9niICs+29k0aKWySHvvz9GPv74Alm79irZtOlbsn37D6W09GGpWvxr8V9/qQRvv0ECa5ZJJNLFzSsaFamqEikttb8fSnOzyMiR9iYWCtl5tbUigweLFBe3zeupSMTeQLr6Z++pqiqRv/1NZP/+g5c1NIisWXPkx/D77d/T7T74b33WWSKVlR2PdcstIkOH2hv+pk2d73PlSpGxY+0+brnFnlcRez7OOEMkN7fjfqNRG0SOV++/LzJpkv0+Tqf9bvv2db7u/v32hv2jH4ksWGDPUcu1V1sr8vLLIl/5iojLZR/Cvvc9uy6IXHzxwefhvfdE8vPt/+LixQcf78knRbxee90+84xIebmd//e/27RecEHH63b/fhscQOTcc7v+Hj3U06CQMMVHzzwDV10FW7bYEpgBJxyG9euhqsqWj+3bB3/9K7z1ls3+n3GGrauoq7OTiB2H1OezRVbJyXb9009v2+f778PixXD11faNPwC/Hy66CHnnHYJ/+S1109NoqvuExro1hPxlhAP7Cfur8e5sYOjzkPM+RLzgCIGJQvVk2H9WEmn+EaSVZ+AtDeIoLbfpDcVaThUVEZ01k8jMqTgKh+L0R6G5GQIB8Hptmpctg9/9Dt5+2xYbtXj+edsB4Ze/DLfeClOmdF388dZb8OCD9qLYvt1+txNOgHvvtYNtGGPP6xNPwC9+YZus/eQnnb8KL2LLJu+4w5Yju1y2aOuSS2wR4Ftv2VYOwaBN/9SptijunHPgM5/pWJ65bRu88II9/rhxdiotha99zf6Nr77aFisUFNj6qVdfha9+FYYMgb/9DWpqbPe/mzfD7Nnw73/bc3v++fZcDRpkpw8+gB/+0NZVPfbYwe20V6+GyZNtccnvf28r5e69Fz78EEaNsu/fzJhh93viiT2/VqNRWxeUlwfDhnVc9skn8PDDUFtri1AyMmxRTWmp7Ya+rMye/+99r2NLvU2b4Je/tEWvhYX275qVZRsgjBplKxJzcux19vDD8PTTnY+5Xlho07R8OUQitlXgNdfYop3C2ECRv/893HyzPbc33QQbN9rppZfs3+T117tuRfj++3DZZfb7gP3b7thh13/nnY69IYC9rh55BL75TcjNhWefteO0HAEtPupEdfURb9p/bd8ucvfdIqeearOuc+aIXHWVfQKZO1fkc58TufLKQ+cm2qurE5k27eCn1QOmaH6u+O/+hlRtelr2rfqt1Hz3cxIcanM0UQfSVIDsn4LsvcAju69Kkm3fTJWtt6ZJ+Wcc4s/pft8CEr3sCwenLRqV8H99TaIej11vzBiRn/xEZPXqtqfAioq2J7ChQ0UuvVTkjjtEfvELm/MAkdNPt0V2J51kP0+ebIvpQOSyy0SWLxfZuFHkk09sdn/27LbtXnlFZP58kVGj2tI7caLIt79tc2K3326fwr1euywz06bnvvvs9l1952HDRBYu7Pxv8p//2KfU1FQRh8Ou+69/2WVlZbYIYvDgg/d5+eUdcwIH+va37Xonntj2c/58kUsuESkoaNvPjBkiDz5oz8eTT4rcfLO95s47zz5d//OfIqtWidx1l8jw4W3bnXaaLep54QWRz3zGzktKssfJy7O5V4fD5nrPOMMWnyYl2WKVK6+0RWjnnGO3c7ttbqe2ti39b71lz/OUKSLXX992zs85x14X//ynvZ43brRFOFdeKTJzpk3nO+90XSz35JP26b793+aLX2x7+u9OMGhzFT/9qT0/p51m/0bd+egjey3++MeH3n8X0JyCiqv9++2TcShkn+RaJpfL/szMtJXoPl/H7aJR2LULKSigIbSOqqqFBIN7gQgiEQBcrkxczky8pSGidVX4zV6aKaM5spNQYwmOIJgQ+Ef4SE4bR2rqBDyeQhob11Bfv4JgsAxPYzLDPziFvDca8XywyR57+HD7pPzqq/Zpev58+8TZPo2RiB2L++67bcOASZNsq7DPfc5WwP7iF3ZqaOj4vTIz4b777NO8I9bSW8Q+raeltT1ltuf324YHL71kn8Krq23l7pe+ZAdpSkuzLVfWroWmJrvvtLSu/yY7d9pcxCmn2DRmZHRcLmJzLeXldnK57NN+dxXJDQ02V5OWBt/5jn3KbalkFbFPuc8/b5sDf9JumNnUVNt6rrLSpr/lPuNw2F6Fr7jCnt/nn7cVuGBzOrfcAjfcYFvgtIhG284p2Kf9X/7S5gYaG+12N91kc0sFnbyPs3ChzbG5XLYi/dZbe/Q+0CFt3myPP2qUbQQSb/X19jiOI3uTQFsfqQEpHK6nqWk9jY1rYtNqGhpWEwrtIzl5NGlpU0lJmYTfv43KylcJBkvxVNhirNz3XGSujNA8KpnSH0wiOvYkPJ58nM60dlMSxnhwNEVwb63EMe10PL5C3O48HA63fZoq3wNvvInD7WkrzjrtNFsccqRCIXuTHDq0905WbxHpWQuk1avtDX7yZFss0hI8ampscd+ePXDRRbboqr1t22zz7NmzD2MYRGxR6bp1be8BdWfLFhto2gebBKNBQSWUaDR80PsVIkJ9/Qpqa98lHK4mHK4lHKomFK4iFConGCwnFKogGvX38CgOoK0bc4cjBbc7G5crC6czFYfDh8ORFAsekdbJ7c7G5xuBzzcCpzONhoaPqa9fTkPDKny+4QwadDX5+Vfg9XaSm1Cql2hQUKqHotEwkUg9kUg90aifaDSISJBIpIlQqCIWPMqJRkMY44p1PCiEwzWEQvsJh6uJRBpj2/oRCcbWcWKMg1CokkBgNyJhAIxxk5IygdTUYhoaPqahYQXgID19Bm53Hk5nCk5nCiJhIpEGIpF6RMJ4PAV4PIPxeAqJRBoIBHbi9+8kHK4lOXkMqamTSE2dhMczOLaP5Fiw8nb4vuGw3TYcriM5eQxud+YB5yNIKFSF05mK05naYWxz1X9pL6lK9ZDD4cLhyMLtjt+b0NFomGCwLHYDP7nDjbqxcQP79j1FdfUi/P7tsQDTiDGu1hszOGlu3kIgUIZIEAC3Oz+W+0hl//43KC9/vNNjG+PB5crA6UwnHK4hHK7qsNzrHUZq6kSi0SDNzVvw+3cCkdhSBy5XOl7vMJKTR5OcPBqvdyjRaBPhcB2RSP0B6TSxYLUDv38nLld2LFhNJCnpFIxpueVIh5/GuPH5huFyHVAP0uEcBggGK2ydUw+6jI9Gw+2CegXJySfj8w0/5HbHMxGJe5DWnIJS/YiIEA7vx+FIxulM6rAsENhLY+MnhEKVRCJNRKNNRCINsZt3LeFwLS5XBl7vcHy+4TidqTQ2rqWx8WMaGlbjdCaRlHQSSUknxXIjjUQidYTDNTQ3b6epaUOsq5S2IjRjPLEGApF287yx4rLhhEL7aGxc1xrIDsXlysTrHY7TmYRIOJZbaiIU2kc4XNO6nsdTRHLyKfh8wxCJIhJCJEQotL81ZxcKVdEWfKzU1Mnk5l5CaupkGhpWUVf3HvX1H+JyZZCaOpnU1CmkpIzH4xmE252H252LSJBQqDJ2XhtxOtNwuTJaA1g02hzLIYbbFSEmtQuAdp1AoJRAoIRAoBS3OzcWKE/utluZUGg/NTVLqKlZRE3NIgoKrmXo0Dt6dC4PdFzkFIwx5wO/AZzAIyJy7wHLvcATwFSgCpgnIjvimSal+jNjDG53TqfLvN6Cw+4NNzf3c4e1vn1aL48VT6XhcHhiTRmDRCINsTqUXIxxtNsmFAso22j/ENr2xGuIRpvx+3fh9+8kENhJNBqMFdW5cDh8eDz5uN2D8HjyCYUqaWraSFPTRqqr346t58YYFy5XFsnJJ+PxzIqtPyh2g8+hru5DKiv/yo4d92CDhSE5eSw5ORcTDtdRX7+ciornD+t8HC1jPLHci7SrhwrGiiIDRKPNADgcPtLTZ+L1xr8hQtxyCsYWqm4CPguUAB8CV4rIunbr/BcwUURuMsZcAVwqIvO626/mFJRSRyMYLKepaSOpqZMOKq4KhappatpIKFQRmypxOLy43bm4XDk4nSlEIvW20UK4FmMcsdyBD2OcRKN+IpHm2M28fY7Ki9dbhNc7BI+nkFConIaGT2hsXI3fvxNjHLGchROHw4PD4cUYL253NhkZs0hPP/WguqHDdTzkFE4FtojItliCngE+D6xrt87ngXtiv78APGiMMdLfyrSUUv1GS+6hM253FhkZM+KeBq+3gNTU3unorrfFczyFImB3u88lsXmdriO2aUYtcFDe2BhzozFmuTFmeUVFRZySq5RSql8MsiMiC0RkmohMyzuaF4SUUkp1K55BoRRoXysyJDav03WMLVDLwFY4K6WU6gPxDAofAqOMMSONMR7gCuDVA9Z5Fbg29vsXgX9pfYJSSvWduFU0i0jYGHML8Ca2SeqjIrLWGPMjbG99rwJ/Ap40xmwB9mMDh1JKqT4S1/cURGQhsPCAeT9o97sfmBvPNCillOq5flHRrJRS6tjQoKCUUqpVv+v7yBhTAew8ws1zgcpeTM5Aoeelc3peOqfnpXPH+3kZLiKHbNPf74LC0TDGLO/Ja96JRs9L5/S8dE7PS+cGynnR4iOllFKtNCgopZRqlWhBYUFfJ+A4peelc3peOqfnpXMD4rwkVJ2CUkqp7iVaTkEppVQ3EiYoGGPON8ZsNMZsMcbM7+v09BVjzFBjzCJjzDpjzFpjzK2x+dnGmH8YYzbHfsZvwOLjmDHGaYz5yBjzt9jnkcaY92PXzbOxfrwSijEm0xjzgjFmgzFmvTHmdL1ewBjz/2L/Q2uMMU8bY3wD4XpJiKAQGwXuIeACYCxwpTFmbN+mqs+EgTtEZCwwA7g5di7mA/8UkVHAP2OfE9GtwPp2n+8DfiUiJwHVwFf7JFV96zfAGyIyGpiEPT8Jfb0YY4qAbwHTRGQ8tn+3KxgA10tCBAXajQIndgTxllHgEo6I7BGRlbHf67H/4EXY8/F4bLXHgUv6JoV9x+ti/tUAAAPeSURBVBgzBLgIeCT22QCfwY4KCAl4XowxGcCZ2M4rEZGgiNSg1wvYvuOSYt3+JwN7GADXS6IEhZ6MApdwjDEjgMnA+8AgEdkTW7QX6Hy8woHt18B3aBtcNweoiY0KCIl53YwEKoDHYsVqjxhjUkjw60VESoH7gV3YYFALrGAAXC+JEhTUAYwxqcCLwG0iUtd+WWxMi4RqlmaMuRjYJyIr+jotxxkXMAX4vYhMBho5oKgoQa+XLGxuaSQwGEgBzu/TRPWSRAkKPRkFLmEYY9zYgPCUiLwUm11ujCmMLS8E9vVV+vrITGCOMWYHtnjxM9iy9MxY8QAk5nVTApSIyPuxzy9gg0SiXy/nANtFpEJEQsBL2Guo318viRIUejIKXEKIlZP/CVgvIr9st6j9KHjXAq8c67T1JRH5bxEZIiIjsNfHv0TkKmARdlRASMzzshfYbYw5JTbrbGDd/9/e/YNIdUVxHP/+JEQUAxIwjRCD2ohgFgQJakCwE4sUSQQ1hWCXxiIQIooYSG0luKWihQraixZLLIIJ/omQMpWVRSRgYRA9Ke6d57orrCy4szLfTzd37jzeG+6b8959c89hwscLbdroiySr+zk1+l7e+/EyMYvXkuyjzRmPqsD9MuZdGosku4FfgYe8mjs/TnuucAX4lJaF9tuq+mcsOzlmSfYAP1TV/iQbaXcOHwP3gMNV9d8492+pJZmiPXz/EPgbOEK7oJzo8ZLkNHCA9o++e8BR2jOE93q8TExQkCQtbFKmjyRJb8GgIEkaGBQkSQODgiRpYFCQJA0MCtISSrJnlIFVWo4MCpKkgUFBeoMkh5PcSXI/yXSvs/A0yZmeQ/9WknW971SS35L8meT6qLZAks1JbiZ5kORukk1982tm1Se41FfESsuCQUGaI8kW2krVXVU1BbwADtGSnv1RVVuBGeBU/8gF4Meq2kZbKT5qvwScrarPgZ20bJrQMtMeo9X22EjLmSMtCx8s3EWaOHuB7cDv/SJ+FS3h20vgcu9zEbjW6w2sraqZ3n4euJrkI2B9VV0HqKpnAH17d6rqUX99H/gMuP3uD0tamEFBmi/A+ar66bXG5OScfovNETM7F84LPA+1jDh9JM13C/g6yScw1K/eQDtfRhkwDwK3q+pf4EmSL3v7d8BMr2r3KMlXfRsrk6xe0qOQFsErFGmOqvoryQngRpIVwHPge1qBmR39vce05w7QUiSf6z/6oyyi0ALEdJKf+za+WcLDkBbFLKnSW0rytKrWjHs/pHfJ6SNJ0sA7BUnSwDsFSdLAoCBJGhgUJEkDg4IkaWBQkCQNDAqSpMH/u8z31fCSEfUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1735 - acc: 0.9493\n",
      "Loss: 0.17354647725325384 Accuracy: 0.949325\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.9782 - acc: 0.2824\n",
      "Epoch 00001: val_loss improved from inf to 1.41508, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/001-1.4151.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 2.9780 - acc: 0.2825 - val_loss: 1.4151 - val_acc: 0.5763\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4162 - acc: 0.5791\n",
      "Epoch 00002: val_loss improved from 1.41508 to 0.57773, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/002-0.5777.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 1.4164 - acc: 0.5791 - val_loss: 0.5777 - val_acc: 0.8314\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9133 - acc: 0.7229\n",
      "Epoch 00003: val_loss improved from 0.57773 to 0.44605, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/003-0.4461.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.9133 - acc: 0.7229 - val_loss: 0.4461 - val_acc: 0.8686\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6766 - acc: 0.7960\n",
      "Epoch 00004: val_loss improved from 0.44605 to 0.34030, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/004-0.3403.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6765 - acc: 0.7960 - val_loss: 0.3403 - val_acc: 0.9059\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5481 - acc: 0.8333\n",
      "Epoch 00005: val_loss improved from 0.34030 to 0.29890, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/005-0.2989.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.5480 - acc: 0.8333 - val_loss: 0.2989 - val_acc: 0.9119\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4588 - acc: 0.8584\n",
      "Epoch 00006: val_loss did not improve from 0.29890\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4588 - acc: 0.8584 - val_loss: 0.3051 - val_acc: 0.9147\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3978 - acc: 0.8794\n",
      "Epoch 00007: val_loss improved from 0.29890 to 0.24047, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/007-0.2405.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3979 - acc: 0.8794 - val_loss: 0.2405 - val_acc: 0.9278\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3522 - acc: 0.8901\n",
      "Epoch 00008: val_loss improved from 0.24047 to 0.22693, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/008-0.2269.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3522 - acc: 0.8901 - val_loss: 0.2269 - val_acc: 0.9378\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3149 - acc: 0.9055\n",
      "Epoch 00009: val_loss improved from 0.22693 to 0.20736, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/009-0.2074.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3148 - acc: 0.9055 - val_loss: 0.2074 - val_acc: 0.9453\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2789 - acc: 0.9151\n",
      "Epoch 00010: val_loss improved from 0.20736 to 0.18483, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/010-0.1848.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2789 - acc: 0.9151 - val_loss: 0.1848 - val_acc: 0.9481\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2532 - acc: 0.9218\n",
      "Epoch 00011: val_loss improved from 0.18483 to 0.16508, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/011-0.1651.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2533 - acc: 0.9217 - val_loss: 0.1651 - val_acc: 0.9532\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2383 - acc: 0.9262\n",
      "Epoch 00012: val_loss improved from 0.16508 to 0.15542, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/012-0.1554.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2383 - acc: 0.9263 - val_loss: 0.1554 - val_acc: 0.9548\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2161 - acc: 0.9326\n",
      "Epoch 00013: val_loss did not improve from 0.15542\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2162 - acc: 0.9325 - val_loss: 0.1576 - val_acc: 0.9532\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2048 - acc: 0.9375\n",
      "Epoch 00014: val_loss improved from 0.15542 to 0.14726, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/014-0.1473.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2048 - acc: 0.9375 - val_loss: 0.1473 - val_acc: 0.9569\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1860 - acc: 0.9427\n",
      "Epoch 00015: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1860 - acc: 0.9427 - val_loss: 0.1493 - val_acc: 0.9555\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9476\n",
      "Epoch 00016: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1690 - acc: 0.9476 - val_loss: 0.1612 - val_acc: 0.9550\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9488\n",
      "Epoch 00017: val_loss did not improve from 0.14726\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1664 - acc: 0.9488 - val_loss: 0.1878 - val_acc: 0.9427\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9523\n",
      "Epoch 00018: val_loss improved from 0.14726 to 0.13175, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/018-0.1318.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1500 - acc: 0.9522 - val_loss: 0.1318 - val_acc: 0.9590\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1391 - acc: 0.9571\n",
      "Epoch 00019: val_loss did not improve from 0.13175\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1392 - acc: 0.9571 - val_loss: 0.1349 - val_acc: 0.9592\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9598\n",
      "Epoch 00020: val_loss did not improve from 0.13175\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1312 - acc: 0.9598 - val_loss: 0.1512 - val_acc: 0.9555\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9610\n",
      "Epoch 00021: val_loss did not improve from 0.13175\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1259 - acc: 0.9610 - val_loss: 0.1395 - val_acc: 0.9581\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9629\n",
      "Epoch 00022: val_loss improved from 0.13175 to 0.12917, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/022-0.1292.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1172 - acc: 0.9629 - val_loss: 0.1292 - val_acc: 0.9602\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9658\n",
      "Epoch 00023: val_loss did not improve from 0.12917\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1107 - acc: 0.9658 - val_loss: 0.1499 - val_acc: 0.9546\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9674\n",
      "Epoch 00024: val_loss improved from 0.12917 to 0.12600, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/024-0.1260.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1037 - acc: 0.9674 - val_loss: 0.1260 - val_acc: 0.9646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0998 - acc: 0.9683\n",
      "Epoch 00025: val_loss improved from 0.12600 to 0.12544, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/025-0.1254.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0998 - acc: 0.9683 - val_loss: 0.1254 - val_acc: 0.9630\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9692\n",
      "Epoch 00026: val_loss did not improve from 0.12544\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0966 - acc: 0.9692 - val_loss: 0.1343 - val_acc: 0.9611\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9737\n",
      "Epoch 00027: val_loss improved from 0.12544 to 0.10666, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_BN_9_conv_checkpoint/027-0.1067.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0870 - acc: 0.9737 - val_loss: 0.1067 - val_acc: 0.9681\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9730\n",
      "Epoch 00028: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0838 - acc: 0.9730 - val_loss: 0.1412 - val_acc: 0.9592\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9754\n",
      "Epoch 00029: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0790 - acc: 0.9754 - val_loss: 0.1438 - val_acc: 0.9585\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9759\n",
      "Epoch 00030: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0756 - acc: 0.9759 - val_loss: 0.1155 - val_acc: 0.9669\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9776\n",
      "Epoch 00031: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0724 - acc: 0.9776 - val_loss: 0.1478 - val_acc: 0.9583\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9774\n",
      "Epoch 00032: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0691 - acc: 0.9773 - val_loss: 0.1382 - val_acc: 0.9604\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9770\n",
      "Epoch 00033: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0732 - acc: 0.9770 - val_loss: 0.1189 - val_acc: 0.9632\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9816\n",
      "Epoch 00034: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0602 - acc: 0.9816 - val_loss: 0.1441 - val_acc: 0.9639\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9813\n",
      "Epoch 00035: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0608 - acc: 0.9813 - val_loss: 0.1404 - val_acc: 0.9571\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9818\n",
      "Epoch 00036: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0562 - acc: 0.9818 - val_loss: 0.1274 - val_acc: 0.9655\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9827\n",
      "Epoch 00037: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0549 - acc: 0.9827 - val_loss: 0.1298 - val_acc: 0.9651\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9789\n",
      "Epoch 00038: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0654 - acc: 0.9789 - val_loss: 0.1171 - val_acc: 0.9641\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9863\n",
      "Epoch 00039: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0455 - acc: 0.9863 - val_loss: 0.1193 - val_acc: 0.9639\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9826\n",
      "Epoch 00040: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0544 - acc: 0.9826 - val_loss: 0.1266 - val_acc: 0.9690\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9862\n",
      "Epoch 00041: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0455 - acc: 0.9862 - val_loss: 0.1191 - val_acc: 0.9686\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9851\n",
      "Epoch 00042: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0462 - acc: 0.9851 - val_loss: 0.1285 - val_acc: 0.9651\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9860\n",
      "Epoch 00043: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0443 - acc: 0.9860 - val_loss: 0.1133 - val_acc: 0.9667\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9843\n",
      "Epoch 00044: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0510 - acc: 0.9842 - val_loss: 0.1483 - val_acc: 0.9618\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9837\n",
      "Epoch 00045: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0523 - acc: 0.9838 - val_loss: 0.1404 - val_acc: 0.9627\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9879\n",
      "Epoch 00046: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0375 - acc: 0.9879 - val_loss: 0.1352 - val_acc: 0.9641\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9892\n",
      "Epoch 00047: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0365 - acc: 0.9892 - val_loss: 0.1221 - val_acc: 0.9688\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9874\n",
      "Epoch 00048: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0383 - acc: 0.9874 - val_loss: 0.1729 - val_acc: 0.9571\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9887\n",
      "Epoch 00049: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0378 - acc: 0.9887 - val_loss: 0.1215 - val_acc: 0.9695\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9892\n",
      "Epoch 00050: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0343 - acc: 0.9892 - val_loss: 0.1077 - val_acc: 0.9695\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9904\n",
      "Epoch 00051: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0319 - acc: 0.9904 - val_loss: 0.1328 - val_acc: 0.9674\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9856\n",
      "Epoch 00052: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0460 - acc: 0.9855 - val_loss: 0.1411 - val_acc: 0.9667\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9839\n",
      "Epoch 00053: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0502 - acc: 0.9838 - val_loss: 0.1395 - val_acc: 0.9651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9893\n",
      "Epoch 00054: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0340 - acc: 0.9893 - val_loss: 0.1323 - val_acc: 0.9641\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9920\n",
      "Epoch 00055: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0267 - acc: 0.9920 - val_loss: 0.1334 - val_acc: 0.9674\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9918\n",
      "Epoch 00056: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0268 - acc: 0.9917 - val_loss: 0.1670 - val_acc: 0.9611\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9886\n",
      "Epoch 00057: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0359 - acc: 0.9886 - val_loss: 0.1495 - val_acc: 0.9634\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9909\n",
      "Epoch 00058: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0290 - acc: 0.9909 - val_loss: 0.1518 - val_acc: 0.9623\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9897\n",
      "Epoch 00059: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0327 - acc: 0.9897 - val_loss: 0.1434 - val_acc: 0.9651\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9918\n",
      "Epoch 00060: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0257 - acc: 0.9918 - val_loss: 0.1595 - val_acc: 0.9618\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9920\n",
      "Epoch 00061: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0257 - acc: 0.9920 - val_loss: 0.1510 - val_acc: 0.9634\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9912\n",
      "Epoch 00062: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0282 - acc: 0.9912 - val_loss: 0.1274 - val_acc: 0.9669\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9930\n",
      "Epoch 00063: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0231 - acc: 0.9930 - val_loss: 0.1309 - val_acc: 0.9688\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9904\n",
      "Epoch 00064: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0304 - acc: 0.9904 - val_loss: 0.1279 - val_acc: 0.9660\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9928\n",
      "Epoch 00065: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0240 - acc: 0.9927 - val_loss: 0.1767 - val_acc: 0.9567\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9878\n",
      "Epoch 00066: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0391 - acc: 0.9878 - val_loss: 0.1222 - val_acc: 0.9693\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9921\n",
      "Epoch 00067: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0247 - acc: 0.9921 - val_loss: 0.1568 - val_acc: 0.9625\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9940\n",
      "Epoch 00068: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0201 - acc: 0.9940 - val_loss: 0.1563 - val_acc: 0.9646\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9940\n",
      "Epoch 00069: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0204 - acc: 0.9939 - val_loss: 0.1683 - val_acc: 0.9618\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9894\n",
      "Epoch 00070: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0349 - acc: 0.9894 - val_loss: 0.1388 - val_acc: 0.9658\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9948\n",
      "Epoch 00071: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0176 - acc: 0.9948 - val_loss: 0.1332 - val_acc: 0.9674\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9940\n",
      "Epoch 00072: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0188 - acc: 0.9940 - val_loss: 0.1805 - val_acc: 0.9595\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9944\n",
      "Epoch 00073: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0189 - acc: 0.9944 - val_loss: 0.1457 - val_acc: 0.9655\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9932\n",
      "Epoch 00074: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0211 - acc: 0.9931 - val_loss: 0.1495 - val_acc: 0.9637\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9921\n",
      "Epoch 00075: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0262 - acc: 0.9921 - val_loss: 0.1386 - val_acc: 0.9700\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9914\n",
      "Epoch 00076: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0282 - acc: 0.9914 - val_loss: 0.1324 - val_acc: 0.9693\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9954\n",
      "Epoch 00077: val_loss did not improve from 0.10666\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0159 - acc: 0.9954 - val_loss: 0.1920 - val_acc: 0.9602\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1693 - acc: 0.9470\n",
      "Loss: 0.16931005258979673 Accuracy: 0.9470405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    base = '1D_CNN_custom_DO_075_DO_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO_075_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 569us/sample - loss: 2.3570 - acc: 0.2318\n",
      "Loss: 2.3570385051045957 Accuracy: 0.2317757\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 879us/sample - loss: 2.3558 - acc: 0.3616\n",
      "Loss: 2.3557704696526534 Accuracy: 0.3615784\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 980us/sample - loss: 1.4029 - acc: 0.6309\n",
      "Loss: 1.4029251341755393 Accuracy: 0.63094497\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.8081 - acc: 0.7718\n",
      "Loss: 0.8080774210447587 Accuracy: 0.7717549\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.6022 - acc: 0.8355\n",
      "Loss: 0.6022437252359598 Accuracy: 0.835514\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.3867 - acc: 0.8933\n",
      "Loss: 0.38665750389406117 Accuracy: 0.8932503\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2401 - acc: 0.9354\n",
      "Loss: 0.24014565102670918 Accuracy: 0.9354102\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1735 - acc: 0.9493\n",
      "Loss: 0.17354647725325384 Accuracy: 0.949325\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1693 - acc: 0.9470\n",
      "Loss: 0.16931005258979673 Accuracy: 0.9470405\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_DO_075_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
