{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, \\\n",
    "                                    Flatten, Conv1D, MaxPooling1D, Dropout, \\\n",
    "                                    Concatenate, GlobalMaxPool1D, GlobalAvgPool1D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(conv_num=1):\n",
    "    filter_size = 32\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    layer_outputs = []\n",
    "    for i in range(conv_num):\n",
    "        x = Conv1D (kernel_size=5, filters=filter_size*(2**(i//4)), \n",
    "                          strides=1, padding='same')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling1D(pool_size=3, strides=3)(x)\n",
    "        layer_outputs.append(x)    \n",
    "    \n",
    "    x = Concatenate()([GlobalAvgPool1D()(output) for output in layer_outputs[-2:]])\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 16000, 32)    192         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16000, 32)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 5333, 32)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 5333, 32)     5152        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5333, 32)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1777, 32)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1777, 32)     5152        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1777, 32)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 592, 32)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 32)           0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 32)           0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64)           0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           1040        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 11,536\n",
      "Trainable params: 11,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 16000, 32)    192         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16000, 32)    0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 5333, 32)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 5333, 32)     5152        max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 5333, 32)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1777, 32)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1777, 32)     5152        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1777, 32)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 592, 32)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 592, 32)      5152        max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 592, 32)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 197, 32)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 32)           0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 32)           0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64)           0           global_average_pooling1d_2[0][0] \n",
      "                                                                 global_average_pooling1d_3[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           1040        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,688\n",
      "Trainable params: 16,688\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 16000, 32)    192         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16000, 32)    0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 5333, 32)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 5333, 32)     5152        max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5333, 32)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1777, 32)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1777, 32)     5152        max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1777, 32)     0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 592, 32)      0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 592, 32)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 197, 32)      0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 197, 64)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 65, 64)       0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 32)           0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 64)           0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 96)           0           global_average_pooling1d_4[0][0] \n",
      "                                                                 global_average_pooling1d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 96)           0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           1552        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,504\n",
      "Trainable params: 27,504\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 16000, 32)    192         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16000, 32)    0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 5333, 32)     0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 5333, 32)     0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1777, 32)     0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1777, 32)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 592, 32)      0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 592, 32)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 197, 32)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 197, 64)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 65, 64)       0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 65, 64)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 21, 64)       0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 64)           0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 64)           0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128)          0           global_average_pooling1d_6[0][0] \n",
      "                                                                 global_average_pooling1d_7[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 128)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           2064        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 48,560\n",
      "Trainable params: 48,560\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 16000, 32)    192         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16000, 32)    0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 5333, 32)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 5333, 32)     0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 1777, 32)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1777, 32)     0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 592, 32)      0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 592, 32)      0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 197, 32)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 197, 64)      0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 65, 64)       0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 65, 64)       0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 21, 64)       0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 21, 64)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 7, 64)        0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 64)           0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 64)           0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128)          0           global_average_pooling1d_8[0][0] \n",
      "                                                                 global_average_pooling1d_9[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           2064        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 69,104\n",
      "Trainable params: 69,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 16000, 32)    192         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16000, 32)    0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 5333, 32)     0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 5333, 32)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 1777, 32)     0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1777, 32)     0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 592, 32)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 592, 32)      0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 197, 32)      0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 197, 64)      0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 65, 64)       0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 65, 64)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 21, 64)       0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 21, 64)       0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 7, 64)        0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 7, 64)        20544       max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 64)        0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 2, 64)        0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 64)           0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 64)           0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 128)          0           global_average_pooling1d_10[0][0]\n",
      "                                                                 global_average_pooling1d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           2064        dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 89,648\n",
      "Trainable params: 89,648\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 9):\n",
    "    model = build_cnn(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.7429 - acc: 0.0823\n",
      "Epoch 00001: val_loss improved from inf to 2.70514, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/001-2.7051.hdf5\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 2.7427 - acc: 0.0824 - val_loss: 2.7051 - val_acc: 0.0825\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.6880 - acc: 0.1102\n",
      "Epoch 00002: val_loss improved from 2.70514 to 2.63207, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/002-2.6321.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 2.6880 - acc: 0.1101 - val_loss: 2.6321 - val_acc: 0.1463\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6140 - acc: 0.1560\n",
      "Epoch 00003: val_loss improved from 2.63207 to 2.52817, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/003-2.5282.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 2.6140 - acc: 0.1560 - val_loss: 2.5282 - val_acc: 0.2027\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5240 - acc: 0.1895\n",
      "Epoch 00004: val_loss improved from 2.52817 to 2.40672, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/004-2.4067.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 2.5240 - acc: 0.1895 - val_loss: 2.4067 - val_acc: 0.2518\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.4359 - acc: 0.2078\n",
      "Epoch 00005: val_loss improved from 2.40672 to 2.30087, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/005-2.3009.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 2.4358 - acc: 0.2078 - val_loss: 2.3009 - val_acc: 0.2898\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.3614 - acc: 0.2211\n",
      "Epoch 00006: val_loss improved from 2.30087 to 2.22002, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/006-2.2200.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 2.3614 - acc: 0.2211 - val_loss: 2.2200 - val_acc: 0.3191\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3035 - acc: 0.2390\n",
      "Epoch 00007: val_loss improved from 2.22002 to 2.15628, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/007-2.1563.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 2.3035 - acc: 0.2390 - val_loss: 2.1563 - val_acc: 0.3364\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2571 - acc: 0.2508\n",
      "Epoch 00008: val_loss improved from 2.15628 to 2.10018, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/008-2.1002.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 2.2572 - acc: 0.2508 - val_loss: 2.1002 - val_acc: 0.3454\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2171 - acc: 0.2618\n",
      "Epoch 00009: val_loss improved from 2.10018 to 2.06146, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/009-2.0615.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 2.2170 - acc: 0.2618 - val_loss: 2.0615 - val_acc: 0.3748\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1819 - acc: 0.2707\n",
      "Epoch 00010: val_loss improved from 2.06146 to 2.02348, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/010-2.0235.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 2.1820 - acc: 0.2707 - val_loss: 2.0235 - val_acc: 0.3783\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1466 - acc: 0.2843\n",
      "Epoch 00011: val_loss improved from 2.02348 to 1.98968, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/011-1.9897.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 2.1467 - acc: 0.2843 - val_loss: 1.9897 - val_acc: 0.3888\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1205 - acc: 0.2930\n",
      "Epoch 00012: val_loss improved from 1.98968 to 1.96188, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/012-1.9619.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 2.1206 - acc: 0.2929 - val_loss: 1.9619 - val_acc: 0.3965\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0979 - acc: 0.2982\n",
      "Epoch 00013: val_loss improved from 1.96188 to 1.93451, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/013-1.9345.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 2.0978 - acc: 0.2983 - val_loss: 1.9345 - val_acc: 0.4051\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0816 - acc: 0.3050\n",
      "Epoch 00014: val_loss improved from 1.93451 to 1.91397, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/014-1.9140.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 2.0816 - acc: 0.3050 - val_loss: 1.9140 - val_acc: 0.4158\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0535 - acc: 0.3144\n",
      "Epoch 00015: val_loss improved from 1.91397 to 1.88989, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/015-1.8899.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 2.0535 - acc: 0.3144 - val_loss: 1.8899 - val_acc: 0.4212\n",
      "Epoch 16/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.0359 - acc: 0.3241\n",
      "Epoch 00016: val_loss improved from 1.88989 to 1.87282, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/016-1.8728.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 2.0361 - acc: 0.3240 - val_loss: 1.8728 - val_acc: 0.4242\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0128 - acc: 0.3302\n",
      "Epoch 00017: val_loss improved from 1.87282 to 1.84954, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/017-1.8495.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 2.0128 - acc: 0.3301 - val_loss: 1.8495 - val_acc: 0.4412\n",
      "Epoch 18/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.9958 - acc: 0.3354\n",
      "Epoch 00018: val_loss improved from 1.84954 to 1.83146, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/018-1.8315.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.9961 - acc: 0.3353 - val_loss: 1.8315 - val_acc: 0.4384\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9773 - acc: 0.3414\n",
      "Epoch 00019: val_loss improved from 1.83146 to 1.81325, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/019-1.8133.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.9773 - acc: 0.3414 - val_loss: 1.8133 - val_acc: 0.4482\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9670 - acc: 0.3475\n",
      "Epoch 00020: val_loss improved from 1.81325 to 1.79599, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/020-1.7960.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.9669 - acc: 0.3475 - val_loss: 1.7960 - val_acc: 0.4542\n",
      "Epoch 21/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.9488 - acc: 0.3527\n",
      "Epoch 00021: val_loss improved from 1.79599 to 1.78415, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/021-1.7842.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.9489 - acc: 0.3527 - val_loss: 1.7842 - val_acc: 0.4561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.9322 - acc: 0.3605\n",
      "Epoch 00022: val_loss improved from 1.78415 to 1.76591, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/022-1.7659.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.9322 - acc: 0.3605 - val_loss: 1.7659 - val_acc: 0.4670\n",
      "Epoch 23/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.9214 - acc: 0.3611\n",
      "Epoch 00023: val_loss improved from 1.76591 to 1.75116, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/023-1.7512.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.9214 - acc: 0.3611 - val_loss: 1.7512 - val_acc: 0.4666\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9079 - acc: 0.3675\n",
      "Epoch 00024: val_loss improved from 1.75116 to 1.74002, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/024-1.7400.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.9079 - acc: 0.3675 - val_loss: 1.7400 - val_acc: 0.4708\n",
      "Epoch 25/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.8985 - acc: 0.3737\n",
      "Epoch 00025: val_loss improved from 1.74002 to 1.72618, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/025-1.7262.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.8984 - acc: 0.3736 - val_loss: 1.7262 - val_acc: 0.4757\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8832 - acc: 0.3795\n",
      "Epoch 00026: val_loss improved from 1.72618 to 1.71195, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/026-1.7119.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.8832 - acc: 0.3795 - val_loss: 1.7119 - val_acc: 0.4836\n",
      "Epoch 27/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.8723 - acc: 0.3804\n",
      "Epoch 00027: val_loss improved from 1.71195 to 1.69881, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/027-1.6988.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.8725 - acc: 0.3802 - val_loss: 1.6988 - val_acc: 0.4887\n",
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.8625 - acc: 0.3853\n",
      "Epoch 00028: val_loss improved from 1.69881 to 1.68699, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/028-1.6870.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.8626 - acc: 0.3854 - val_loss: 1.6870 - val_acc: 0.4962\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8554 - acc: 0.3859\n",
      "Epoch 00029: val_loss improved from 1.68699 to 1.67539, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/029-1.6754.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.8554 - acc: 0.3859 - val_loss: 1.6754 - val_acc: 0.4969\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8452 - acc: 0.3957\n",
      "Epoch 00030: val_loss improved from 1.67539 to 1.66443, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/030-1.6644.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.8452 - acc: 0.3957 - val_loss: 1.6644 - val_acc: 0.4980\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8276 - acc: 0.4017\n",
      "Epoch 00031: val_loss improved from 1.66443 to 1.65003, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/031-1.6500.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.8276 - acc: 0.4017 - val_loss: 1.6500 - val_acc: 0.5017\n",
      "Epoch 32/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.8213 - acc: 0.4028\n",
      "Epoch 00032: val_loss improved from 1.65003 to 1.63811, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/032-1.6381.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.8211 - acc: 0.4027 - val_loss: 1.6381 - val_acc: 0.5101\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8157 - acc: 0.4055\n",
      "Epoch 00033: val_loss improved from 1.63811 to 1.62768, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/033-1.6277.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.8157 - acc: 0.4055 - val_loss: 1.6277 - val_acc: 0.5118\n",
      "Epoch 34/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.8009 - acc: 0.4089\n",
      "Epoch 00034: val_loss improved from 1.62768 to 1.61348, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/034-1.6135.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.8010 - acc: 0.4089 - val_loss: 1.6135 - val_acc: 0.5178\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7908 - acc: 0.4150\n",
      "Epoch 00035: val_loss improved from 1.61348 to 1.60648, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/035-1.6065.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.7909 - acc: 0.4150 - val_loss: 1.6065 - val_acc: 0.5218\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7815 - acc: 0.4196\n",
      "Epoch 00036: val_loss improved from 1.60648 to 1.59224, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/036-1.5922.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.7815 - acc: 0.4195 - val_loss: 1.5922 - val_acc: 0.5278\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7802 - acc: 0.4167\n",
      "Epoch 00037: val_loss improved from 1.59224 to 1.58663, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/037-1.5866.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.7802 - acc: 0.4167 - val_loss: 1.5866 - val_acc: 0.5264\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7706 - acc: 0.4247\n",
      "Epoch 00038: val_loss improved from 1.58663 to 1.57637, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/038-1.5764.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.7703 - acc: 0.4248 - val_loss: 1.5764 - val_acc: 0.5351\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7618 - acc: 0.4286\n",
      "Epoch 00039: val_loss improved from 1.57637 to 1.56312, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/039-1.5631.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.7617 - acc: 0.4286 - val_loss: 1.5631 - val_acc: 0.5358\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7489 - acc: 0.4326\n",
      "Epoch 00040: val_loss improved from 1.56312 to 1.55302, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/040-1.5530.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.7489 - acc: 0.4327 - val_loss: 1.5530 - val_acc: 0.5360\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7435 - acc: 0.4330\n",
      "Epoch 00041: val_loss improved from 1.55302 to 1.54356, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/041-1.5436.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.7435 - acc: 0.4330 - val_loss: 1.5436 - val_acc: 0.5418\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7379 - acc: 0.4366\n",
      "Epoch 00042: val_loss improved from 1.54356 to 1.53787, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/042-1.5379.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.7380 - acc: 0.4366 - val_loss: 1.5379 - val_acc: 0.5486\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7289 - acc: 0.4388\n",
      "Epoch 00043: val_loss improved from 1.53787 to 1.52512, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/043-1.5251.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.7287 - acc: 0.4388 - val_loss: 1.5251 - val_acc: 0.5539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7181 - acc: 0.4416\n",
      "Epoch 00044: val_loss improved from 1.52512 to 1.51752, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/044-1.5175.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.7177 - acc: 0.4418 - val_loss: 1.5175 - val_acc: 0.5537\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7111 - acc: 0.4472\n",
      "Epoch 00045: val_loss improved from 1.51752 to 1.50527, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/045-1.5053.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.7112 - acc: 0.4472 - val_loss: 1.5053 - val_acc: 0.5584\n",
      "Epoch 46/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.7030 - acc: 0.4455\n",
      "Epoch 00046: val_loss improved from 1.50527 to 1.49792, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/046-1.4979.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.7028 - acc: 0.4456 - val_loss: 1.4979 - val_acc: 0.5560\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6944 - acc: 0.4499\n",
      "Epoch 00047: val_loss improved from 1.49792 to 1.48646, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/047-1.4865.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.6943 - acc: 0.4500 - val_loss: 1.4865 - val_acc: 0.5625\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6907 - acc: 0.4550\n",
      "Epoch 00048: val_loss improved from 1.48646 to 1.48194, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/048-1.4819.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.6907 - acc: 0.4550 - val_loss: 1.4819 - val_acc: 0.5628\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6881 - acc: 0.4564\n",
      "Epoch 00049: val_loss improved from 1.48194 to 1.47478, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/049-1.4748.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.6881 - acc: 0.4563 - val_loss: 1.4748 - val_acc: 0.5660\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6770 - acc: 0.4578\n",
      "Epoch 00050: val_loss improved from 1.47478 to 1.46470, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/050-1.4647.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.6769 - acc: 0.4578 - val_loss: 1.4647 - val_acc: 0.5656\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6732 - acc: 0.4569\n",
      "Epoch 00051: val_loss improved from 1.46470 to 1.45878, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/051-1.4588.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.6731 - acc: 0.4569 - val_loss: 1.4588 - val_acc: 0.5723\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6627 - acc: 0.4622\n",
      "Epoch 00052: val_loss improved from 1.45878 to 1.44845, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/052-1.4485.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.6627 - acc: 0.4622 - val_loss: 1.4485 - val_acc: 0.5735\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6527 - acc: 0.4657\n",
      "Epoch 00053: val_loss improved from 1.44845 to 1.44001, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/053-1.4400.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.6527 - acc: 0.4656 - val_loss: 1.4400 - val_acc: 0.5788\n",
      "Epoch 54/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6518 - acc: 0.4662\n",
      "Epoch 00054: val_loss improved from 1.44001 to 1.43599, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/054-1.4360.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.6520 - acc: 0.4661 - val_loss: 1.4360 - val_acc: 0.5800\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6437 - acc: 0.4671\n",
      "Epoch 00055: val_loss improved from 1.43599 to 1.42785, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/055-1.4279.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.6436 - acc: 0.4671 - val_loss: 1.4279 - val_acc: 0.5768\n",
      "Epoch 56/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6383 - acc: 0.4732\n",
      "Epoch 00056: val_loss improved from 1.42785 to 1.41967, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/056-1.4197.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.6389 - acc: 0.4731 - val_loss: 1.4197 - val_acc: 0.5802\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6336 - acc: 0.4728\n",
      "Epoch 00057: val_loss improved from 1.41967 to 1.41099, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/057-1.4110.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.6335 - acc: 0.4728 - val_loss: 1.4110 - val_acc: 0.5912\n",
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6293 - acc: 0.4794\n",
      "Epoch 00058: val_loss improved from 1.41099 to 1.40391, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/058-1.4039.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.6297 - acc: 0.4793 - val_loss: 1.4039 - val_acc: 0.5907\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6179 - acc: 0.4768\n",
      "Epoch 00059: val_loss improved from 1.40391 to 1.39536, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/059-1.3954.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.6178 - acc: 0.4769 - val_loss: 1.3954 - val_acc: 0.5893\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6110 - acc: 0.4791\n",
      "Epoch 00060: val_loss improved from 1.39536 to 1.39133, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/060-1.3913.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.6110 - acc: 0.4791 - val_loss: 1.3913 - val_acc: 0.5921\n",
      "Epoch 61/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6087 - acc: 0.4834\n",
      "Epoch 00061: val_loss improved from 1.39133 to 1.38540, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/061-1.3854.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.6083 - acc: 0.4835 - val_loss: 1.3854 - val_acc: 0.5912\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6058 - acc: 0.4842\n",
      "Epoch 00062: val_loss improved from 1.38540 to 1.37663, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/062-1.3766.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.6058 - acc: 0.4842 - val_loss: 1.3766 - val_acc: 0.5980\n",
      "Epoch 63/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5958 - acc: 0.4878\n",
      "Epoch 00063: val_loss improved from 1.37663 to 1.36769, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/063-1.3677.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.5967 - acc: 0.4876 - val_loss: 1.3677 - val_acc: 0.6010\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5900 - acc: 0.4901\n",
      "Epoch 00064: val_loss improved from 1.36769 to 1.36031, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/064-1.3603.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.5901 - acc: 0.4900 - val_loss: 1.3603 - val_acc: 0.6049\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5840 - acc: 0.4928\n",
      "Epoch 00065: val_loss did not improve from 1.36031\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.5840 - acc: 0.4928 - val_loss: 1.3672 - val_acc: 0.5956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5822 - acc: 0.4928\n",
      "Epoch 00066: val_loss improved from 1.36031 to 1.35372, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/066-1.3537.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.5825 - acc: 0.4928 - val_loss: 1.3537 - val_acc: 0.6024\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5740 - acc: 0.4944\n",
      "Epoch 00067: val_loss improved from 1.35372 to 1.34826, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/067-1.3483.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.5739 - acc: 0.4944 - val_loss: 1.3483 - val_acc: 0.6031\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5747 - acc: 0.4952\n",
      "Epoch 00068: val_loss improved from 1.34826 to 1.33894, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/068-1.3389.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.5747 - acc: 0.4953 - val_loss: 1.3389 - val_acc: 0.6115\n",
      "Epoch 69/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5660 - acc: 0.4983\n",
      "Epoch 00069: val_loss improved from 1.33894 to 1.33261, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/069-1.3326.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.5663 - acc: 0.4982 - val_loss: 1.3326 - val_acc: 0.6096\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5583 - acc: 0.4983\n",
      "Epoch 00070: val_loss improved from 1.33261 to 1.32831, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/070-1.3283.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.5582 - acc: 0.4983 - val_loss: 1.3283 - val_acc: 0.6157\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5521 - acc: 0.5021\n",
      "Epoch 00071: val_loss improved from 1.32831 to 1.31578, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/071-1.3158.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.5521 - acc: 0.5021 - val_loss: 1.3158 - val_acc: 0.6171\n",
      "Epoch 72/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5500 - acc: 0.5023\n",
      "Epoch 00072: val_loss improved from 1.31578 to 1.31513, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/072-1.3151.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.5498 - acc: 0.5024 - val_loss: 1.3151 - val_acc: 0.6201\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5490 - acc: 0.5024\n",
      "Epoch 00073: val_loss improved from 1.31513 to 1.31171, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/073-1.3117.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.5490 - acc: 0.5024 - val_loss: 1.3117 - val_acc: 0.6219\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5413 - acc: 0.5062\n",
      "Epoch 00074: val_loss improved from 1.31171 to 1.30566, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/074-1.3057.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.5413 - acc: 0.5062 - val_loss: 1.3057 - val_acc: 0.6231\n",
      "Epoch 75/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5459 - acc: 0.5063\n",
      "Epoch 00075: val_loss improved from 1.30566 to 1.30324, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/075-1.3032.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.5456 - acc: 0.5063 - val_loss: 1.3032 - val_acc: 0.6236\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5336 - acc: 0.5087\n",
      "Epoch 00076: val_loss improved from 1.30324 to 1.29495, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/076-1.2950.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.5336 - acc: 0.5087 - val_loss: 1.2950 - val_acc: 0.6247\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5329 - acc: 0.5078\n",
      "Epoch 00077: val_loss improved from 1.29495 to 1.29315, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/077-1.2931.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.5329 - acc: 0.5078 - val_loss: 1.2931 - val_acc: 0.6289\n",
      "Epoch 78/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5292 - acc: 0.5129\n",
      "Epoch 00078: val_loss improved from 1.29315 to 1.28446, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/078-1.2845.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.5290 - acc: 0.5129 - val_loss: 1.2845 - val_acc: 0.6327\n",
      "Epoch 79/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5277 - acc: 0.5127\n",
      "Epoch 00079: val_loss improved from 1.28446 to 1.28234, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/079-1.2823.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.5274 - acc: 0.5126 - val_loss: 1.2823 - val_acc: 0.6327\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5187 - acc: 0.5119\n",
      "Epoch 00080: val_loss improved from 1.28234 to 1.27879, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/080-1.2788.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.5187 - acc: 0.5119 - val_loss: 1.2788 - val_acc: 0.6282\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5120 - acc: 0.5151\n",
      "Epoch 00081: val_loss improved from 1.27879 to 1.27024, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/081-1.2702.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.5121 - acc: 0.5151 - val_loss: 1.2702 - val_acc: 0.6369\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5165 - acc: 0.5152\n",
      "Epoch 00082: val_loss improved from 1.27024 to 1.26167, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/082-1.2617.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.5166 - acc: 0.5151 - val_loss: 1.2617 - val_acc: 0.6396\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5060 - acc: 0.5203\n",
      "Epoch 00083: val_loss improved from 1.26167 to 1.25939, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/083-1.2594.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.5061 - acc: 0.5203 - val_loss: 1.2594 - val_acc: 0.6369\n",
      "Epoch 84/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5091 - acc: 0.5192\n",
      "Epoch 00084: val_loss improved from 1.25939 to 1.25581, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/084-1.2558.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.5089 - acc: 0.5194 - val_loss: 1.2558 - val_acc: 0.6399\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4991 - acc: 0.5184\n",
      "Epoch 00085: val_loss improved from 1.25581 to 1.24951, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/085-1.2495.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.4991 - acc: 0.5184 - val_loss: 1.2495 - val_acc: 0.6445\n",
      "Epoch 86/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4968 - acc: 0.5218\n",
      "Epoch 00086: val_loss improved from 1.24951 to 1.24298, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/086-1.2430.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.4966 - acc: 0.5219 - val_loss: 1.2430 - val_acc: 0.6462\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4947 - acc: 0.5199\n",
      "Epoch 00087: val_loss improved from 1.24298 to 1.24121, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/087-1.2412.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.4947 - acc: 0.5199 - val_loss: 1.2412 - val_acc: 0.6478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4891 - acc: 0.5223\n",
      "Epoch 00088: val_loss improved from 1.24121 to 1.23911, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/088-1.2391.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.4891 - acc: 0.5222 - val_loss: 1.2391 - val_acc: 0.6473\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4904 - acc: 0.5217\n",
      "Epoch 00089: val_loss improved from 1.23911 to 1.23419, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/089-1.2342.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.4904 - acc: 0.5218 - val_loss: 1.2342 - val_acc: 0.6508\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4792 - acc: 0.5283\n",
      "Epoch 00090: val_loss improved from 1.23419 to 1.22836, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/090-1.2284.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.4794 - acc: 0.5283 - val_loss: 1.2284 - val_acc: 0.6485\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4850 - acc: 0.5243\n",
      "Epoch 00091: val_loss improved from 1.22836 to 1.22646, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/091-1.2265.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.4850 - acc: 0.5242 - val_loss: 1.2265 - val_acc: 0.6513\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4786 - acc: 0.5308\n",
      "Epoch 00092: val_loss improved from 1.22646 to 1.22327, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/092-1.2233.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.4787 - acc: 0.5308 - val_loss: 1.2233 - val_acc: 0.6513\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4779 - acc: 0.5302\n",
      "Epoch 00093: val_loss improved from 1.22327 to 1.21905, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/093-1.2190.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.4779 - acc: 0.5302 - val_loss: 1.2190 - val_acc: 0.6546\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4707 - acc: 0.5310\n",
      "Epoch 00094: val_loss did not improve from 1.21905\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.4707 - acc: 0.5310 - val_loss: 1.2195 - val_acc: 0.6513\n",
      "Epoch 95/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4644 - acc: 0.5307\n",
      "Epoch 00095: val_loss improved from 1.21905 to 1.20944, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/095-1.2094.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.4640 - acc: 0.5307 - val_loss: 1.2094 - val_acc: 0.6576\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4631 - acc: 0.5321\n",
      "Epoch 00096: val_loss improved from 1.20944 to 1.20805, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/096-1.2080.hdf5\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 1.4631 - acc: 0.5322 - val_loss: 1.2080 - val_acc: 0.6571\n",
      "Epoch 97/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4682 - acc: 0.5351\n",
      "Epoch 00097: val_loss improved from 1.20805 to 1.20400, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/097-1.2040.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.4683 - acc: 0.5350 - val_loss: 1.2040 - val_acc: 0.6560\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4608 - acc: 0.5327\n",
      "Epoch 00098: val_loss did not improve from 1.20400\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.4608 - acc: 0.5327 - val_loss: 1.2071 - val_acc: 0.6562\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4541 - acc: 0.5365\n",
      "Epoch 00099: val_loss improved from 1.20400 to 1.19541, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/099-1.1954.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.4540 - acc: 0.5366 - val_loss: 1.1954 - val_acc: 0.6611\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4570 - acc: 0.5370\n",
      "Epoch 00100: val_loss did not improve from 1.19541\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.4569 - acc: 0.5370 - val_loss: 1.1962 - val_acc: 0.6620\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4594 - acc: 0.5371\n",
      "Epoch 00101: val_loss improved from 1.19541 to 1.19350, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/101-1.1935.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.4594 - acc: 0.5372 - val_loss: 1.1935 - val_acc: 0.6560\n",
      "Epoch 102/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4513 - acc: 0.5352\n",
      "Epoch 00102: val_loss improved from 1.19350 to 1.19189, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/102-1.1919.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.4513 - acc: 0.5353 - val_loss: 1.1919 - val_acc: 0.6569\n",
      "Epoch 103/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4454 - acc: 0.5389\n",
      "Epoch 00103: val_loss improved from 1.19189 to 1.18778, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/103-1.1878.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.4457 - acc: 0.5388 - val_loss: 1.1878 - val_acc: 0.6583\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4382 - acc: 0.5435\n",
      "Epoch 00104: val_loss improved from 1.18778 to 1.17727, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/104-1.1773.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.4382 - acc: 0.5434 - val_loss: 1.1773 - val_acc: 0.6662\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4399 - acc: 0.5391\n",
      "Epoch 00105: val_loss improved from 1.17727 to 1.17496, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/105-1.1750.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.4398 - acc: 0.5392 - val_loss: 1.1750 - val_acc: 0.6643\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4355 - acc: 0.5438\n",
      "Epoch 00106: val_loss improved from 1.17496 to 1.17033, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/106-1.1703.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.4354 - acc: 0.5438 - val_loss: 1.1703 - val_acc: 0.6678\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4402 - acc: 0.5420\n",
      "Epoch 00107: val_loss improved from 1.17033 to 1.16755, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/107-1.1675.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.4402 - acc: 0.5420 - val_loss: 1.1675 - val_acc: 0.6676\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4278 - acc: 0.5424\n",
      "Epoch 00108: val_loss did not improve from 1.16755\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.4277 - acc: 0.5424 - val_loss: 1.1677 - val_acc: 0.6639\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4311 - acc: 0.5458\n",
      "Epoch 00109: val_loss improved from 1.16755 to 1.16576, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/109-1.1658.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.4311 - acc: 0.5458 - val_loss: 1.1658 - val_acc: 0.6685\n",
      "Epoch 110/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4285 - acc: 0.5442\n",
      "Epoch 00110: val_loss improved from 1.16576 to 1.16248, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/110-1.1625.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.4284 - acc: 0.5441 - val_loss: 1.1625 - val_acc: 0.6643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4199 - acc: 0.5491\n",
      "Epoch 00111: val_loss improved from 1.16248 to 1.15572, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/111-1.1557.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.4199 - acc: 0.5491 - val_loss: 1.1557 - val_acc: 0.6688\n",
      "Epoch 112/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4194 - acc: 0.5468\n",
      "Epoch 00112: val_loss did not improve from 1.15572\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.4199 - acc: 0.5468 - val_loss: 1.1575 - val_acc: 0.6676\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4204 - acc: 0.5487\n",
      "Epoch 00113: val_loss improved from 1.15572 to 1.14814, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/113-1.1481.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.4205 - acc: 0.5487 - val_loss: 1.1481 - val_acc: 0.6755\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4200 - acc: 0.5471\n",
      "Epoch 00114: val_loss did not improve from 1.14814\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.4200 - acc: 0.5472 - val_loss: 1.1535 - val_acc: 0.6692\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4104 - acc: 0.5518\n",
      "Epoch 00115: val_loss improved from 1.14814 to 1.14530, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/115-1.1453.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.4104 - acc: 0.5518 - val_loss: 1.1453 - val_acc: 0.6711\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4144 - acc: 0.5505\n",
      "Epoch 00116: val_loss improved from 1.14530 to 1.13890, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/116-1.1389.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.4144 - acc: 0.5504 - val_loss: 1.1389 - val_acc: 0.6760\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4090 - acc: 0.5509\n",
      "Epoch 00117: val_loss did not improve from 1.13890\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.4089 - acc: 0.5509 - val_loss: 1.1404 - val_acc: 0.6732\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4024 - acc: 0.5495\n",
      "Epoch 00118: val_loss improved from 1.13890 to 1.13860, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/118-1.1386.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.4024 - acc: 0.5494 - val_loss: 1.1386 - val_acc: 0.6709\n",
      "Epoch 119/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4066 - acc: 0.5531\n",
      "Epoch 00119: val_loss improved from 1.13860 to 1.13421, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/119-1.1342.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.4065 - acc: 0.5530 - val_loss: 1.1342 - val_acc: 0.6727\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4058 - acc: 0.5522\n",
      "Epoch 00120: val_loss improved from 1.13421 to 1.13149, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/120-1.1315.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.4057 - acc: 0.5522 - val_loss: 1.1315 - val_acc: 0.6778\n",
      "Epoch 121/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4056 - acc: 0.5544\n",
      "Epoch 00121: val_loss did not improve from 1.13149\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.4055 - acc: 0.5545 - val_loss: 1.1323 - val_acc: 0.6788\n",
      "Epoch 122/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3942 - acc: 0.5559\n",
      "Epoch 00122: val_loss improved from 1.13149 to 1.13051, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/122-1.1305.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.3941 - acc: 0.5559 - val_loss: 1.1305 - val_acc: 0.6797\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3967 - acc: 0.5583\n",
      "Epoch 00123: val_loss improved from 1.13051 to 1.12022, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/123-1.1202.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3968 - acc: 0.5582 - val_loss: 1.1202 - val_acc: 0.6806\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3982 - acc: 0.5562\n",
      "Epoch 00124: val_loss improved from 1.12022 to 1.11881, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/124-1.1188.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3981 - acc: 0.5563 - val_loss: 1.1188 - val_acc: 0.6820\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3865 - acc: 0.5592\n",
      "Epoch 00125: val_loss did not improve from 1.11881\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3864 - acc: 0.5592 - val_loss: 1.1212 - val_acc: 0.6802\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3902 - acc: 0.5585\n",
      "Epoch 00126: val_loss improved from 1.11881 to 1.11711, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/126-1.1171.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.3902 - acc: 0.5585 - val_loss: 1.1171 - val_acc: 0.6818\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3891 - acc: 0.5579\n",
      "Epoch 00127: val_loss improved from 1.11711 to 1.11227, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/127-1.1123.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.3891 - acc: 0.5579 - val_loss: 1.1123 - val_acc: 0.6830\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3827 - acc: 0.5619\n",
      "Epoch 00128: val_loss did not improve from 1.11227\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.3827 - acc: 0.5619 - val_loss: 1.1126 - val_acc: 0.6830\n",
      "Epoch 129/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3882 - acc: 0.5582\n",
      "Epoch 00129: val_loss improved from 1.11227 to 1.10667, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/129-1.1067.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.3881 - acc: 0.5582 - val_loss: 1.1067 - val_acc: 0.6839\n",
      "Epoch 130/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3826 - acc: 0.5597\n",
      "Epoch 00130: val_loss improved from 1.10667 to 1.10438, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/130-1.1044.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.3824 - acc: 0.5597 - val_loss: 1.1044 - val_acc: 0.6848\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3780 - acc: 0.5633\n",
      "Epoch 00131: val_loss did not improve from 1.10438\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3781 - acc: 0.5633 - val_loss: 1.1077 - val_acc: 0.6823\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3724 - acc: 0.5639\n",
      "Epoch 00132: val_loss improved from 1.10438 to 1.09541, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/132-1.0954.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3725 - acc: 0.5638 - val_loss: 1.0954 - val_acc: 0.6860\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3760 - acc: 0.5661\n",
      "Epoch 00133: val_loss did not improve from 1.09541\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.3760 - acc: 0.5661 - val_loss: 1.0993 - val_acc: 0.6900\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3728 - acc: 0.5642\n",
      "Epoch 00134: val_loss improved from 1.09541 to 1.09216, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/134-1.0922.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.3727 - acc: 0.5643 - val_loss: 1.0922 - val_acc: 0.6890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3727 - acc: 0.5657\n",
      "Epoch 00135: val_loss improved from 1.09216 to 1.08983, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/135-1.0898.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.3729 - acc: 0.5657 - val_loss: 1.0898 - val_acc: 0.6895\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3721 - acc: 0.5665\n",
      "Epoch 00136: val_loss did not improve from 1.08983\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3720 - acc: 0.5666 - val_loss: 1.0936 - val_acc: 0.6886\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3595 - acc: 0.5680\n",
      "Epoch 00137: val_loss improved from 1.08983 to 1.08820, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/137-1.0882.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.3595 - acc: 0.5680 - val_loss: 1.0882 - val_acc: 0.6844\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3641 - acc: 0.5685\n",
      "Epoch 00138: val_loss did not improve from 1.08820\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.3640 - acc: 0.5685 - val_loss: 1.0900 - val_acc: 0.6895\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3688 - acc: 0.5652\n",
      "Epoch 00139: val_loss improved from 1.08820 to 1.08403, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/139-1.0840.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.3689 - acc: 0.5652 - val_loss: 1.0840 - val_acc: 0.6909\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3642 - acc: 0.5671\n",
      "Epoch 00140: val_loss improved from 1.08403 to 1.08272, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/140-1.0827.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.3642 - acc: 0.5671 - val_loss: 1.0827 - val_acc: 0.6921\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3624 - acc: 0.5663\n",
      "Epoch 00141: val_loss improved from 1.08272 to 1.08046, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/141-1.0805.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.3624 - acc: 0.5663 - val_loss: 1.0805 - val_acc: 0.6900\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3591 - acc: 0.5666\n",
      "Epoch 00142: val_loss improved from 1.08046 to 1.07679, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/142-1.0768.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3590 - acc: 0.5667 - val_loss: 1.0768 - val_acc: 0.6911\n",
      "Epoch 143/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3606 - acc: 0.5694\n",
      "Epoch 00143: val_loss did not improve from 1.07679\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.3606 - acc: 0.5692 - val_loss: 1.0774 - val_acc: 0.6883\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3549 - acc: 0.5690\n",
      "Epoch 00144: val_loss improved from 1.07679 to 1.07306, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/144-1.0731.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.3548 - acc: 0.5691 - val_loss: 1.0731 - val_acc: 0.6962\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3454 - acc: 0.5742\n",
      "Epoch 00145: val_loss improved from 1.07306 to 1.07118, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/145-1.0712.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.3453 - acc: 0.5742 - val_loss: 1.0712 - val_acc: 0.6916\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3519 - acc: 0.5710\n",
      "Epoch 00146: val_loss did not improve from 1.07118\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.3519 - acc: 0.5709 - val_loss: 1.0775 - val_acc: 0.6897\n",
      "Epoch 147/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3487 - acc: 0.5746\n",
      "Epoch 00147: val_loss improved from 1.07118 to 1.07002, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/147-1.0700.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.3489 - acc: 0.5746 - val_loss: 1.0700 - val_acc: 0.6946\n",
      "Epoch 148/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3472 - acc: 0.5720\n",
      "Epoch 00148: val_loss improved from 1.07002 to 1.06794, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/148-1.0679.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3469 - acc: 0.5721 - val_loss: 1.0679 - val_acc: 0.6937\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3416 - acc: 0.5749\n",
      "Epoch 00149: val_loss improved from 1.06794 to 1.06646, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/149-1.0665.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.3416 - acc: 0.5749 - val_loss: 1.0665 - val_acc: 0.6942\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3451 - acc: 0.5735\n",
      "Epoch 00150: val_loss improved from 1.06646 to 1.06248, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/150-1.0625.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.3451 - acc: 0.5734 - val_loss: 1.0625 - val_acc: 0.6949\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3402 - acc: 0.5736\n",
      "Epoch 00151: val_loss did not improve from 1.06248\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.3402 - acc: 0.5736 - val_loss: 1.0639 - val_acc: 0.6962\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3430 - acc: 0.5751\n",
      "Epoch 00152: val_loss improved from 1.06248 to 1.05582, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/152-1.0558.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3430 - acc: 0.5751 - val_loss: 1.0558 - val_acc: 0.6981\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3388 - acc: 0.5770\n",
      "Epoch 00153: val_loss did not improve from 1.05582\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.3388 - acc: 0.5770 - val_loss: 1.0684 - val_acc: 0.6904\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3400 - acc: 0.5772\n",
      "Epoch 00154: val_loss did not improve from 1.05582\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 1.3399 - acc: 0.5772 - val_loss: 1.0567 - val_acc: 0.6976\n",
      "Epoch 155/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3373 - acc: 0.5775\n",
      "Epoch 00155: val_loss did not improve from 1.05582\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.3374 - acc: 0.5774 - val_loss: 1.0562 - val_acc: 0.6972\n",
      "Epoch 156/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3399 - acc: 0.5769\n",
      "Epoch 00156: val_loss improved from 1.05582 to 1.05541, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/156-1.0554.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.3402 - acc: 0.5768 - val_loss: 1.0554 - val_acc: 0.6958\n",
      "Epoch 157/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3403 - acc: 0.5769\n",
      "Epoch 00157: val_loss improved from 1.05541 to 1.05068, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/157-1.0507.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3399 - acc: 0.5769 - val_loss: 1.0507 - val_acc: 0.6979\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3439 - acc: 0.5760\n",
      "Epoch 00158: val_loss did not improve from 1.05068\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.3440 - acc: 0.5760 - val_loss: 1.0511 - val_acc: 0.7000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3331 - acc: 0.5789\n",
      "Epoch 00159: val_loss improved from 1.05068 to 1.04384, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/159-1.0438.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3334 - acc: 0.5789 - val_loss: 1.0438 - val_acc: 0.6993\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3338 - acc: 0.5789\n",
      "Epoch 00160: val_loss did not improve from 1.04384\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.3338 - acc: 0.5790 - val_loss: 1.0450 - val_acc: 0.7021\n",
      "Epoch 161/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3213 - acc: 0.5816\n",
      "Epoch 00161: val_loss did not improve from 1.04384\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.3215 - acc: 0.5815 - val_loss: 1.0442 - val_acc: 0.7016\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3315 - acc: 0.5795\n",
      "Epoch 00162: val_loss improved from 1.04384 to 1.04282, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/162-1.0428.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.3315 - acc: 0.5795 - val_loss: 1.0428 - val_acc: 0.6997\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3286 - acc: 0.5809\n",
      "Epoch 00163: val_loss did not improve from 1.04282\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.3286 - acc: 0.5810 - val_loss: 1.0433 - val_acc: 0.7056\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3217 - acc: 0.5794\n",
      "Epoch 00164: val_loss improved from 1.04282 to 1.04257, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/164-1.0426.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.3216 - acc: 0.5795 - val_loss: 1.0426 - val_acc: 0.6983\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3195 - acc: 0.5845\n",
      "Epoch 00165: val_loss improved from 1.04257 to 1.03554, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/165-1.0355.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.3194 - acc: 0.5845 - val_loss: 1.0355 - val_acc: 0.7084\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3206 - acc: 0.5776\n",
      "Epoch 00166: val_loss did not improve from 1.03554\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3206 - acc: 0.5776 - val_loss: 1.0371 - val_acc: 0.7053\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3227 - acc: 0.5833\n",
      "Epoch 00167: val_loss improved from 1.03554 to 1.03272, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/167-1.0327.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.3227 - acc: 0.5833 - val_loss: 1.0327 - val_acc: 0.7056\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3203 - acc: 0.5814\n",
      "Epoch 00168: val_loss did not improve from 1.03272\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.3202 - acc: 0.5814 - val_loss: 1.0343 - val_acc: 0.7056\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3155 - acc: 0.5858\n",
      "Epoch 00169: val_loss improved from 1.03272 to 1.02881, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/169-1.0288.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.3156 - acc: 0.5858 - val_loss: 1.0288 - val_acc: 0.7044\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3100 - acc: 0.5824\n",
      "Epoch 00170: val_loss improved from 1.02881 to 1.02489, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/170-1.0249.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3099 - acc: 0.5824 - val_loss: 1.0249 - val_acc: 0.7088\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3185 - acc: 0.5839\n",
      "Epoch 00171: val_loss did not improve from 1.02489\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.3184 - acc: 0.5840 - val_loss: 1.0272 - val_acc: 0.7086\n",
      "Epoch 172/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3213 - acc: 0.5849\n",
      "Epoch 00172: val_loss did not improve from 1.02489\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.3217 - acc: 0.5848 - val_loss: 1.0296 - val_acc: 0.7037\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3071 - acc: 0.5848\n",
      "Epoch 00173: val_loss improved from 1.02489 to 1.02411, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/173-1.0241.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.3070 - acc: 0.5848 - val_loss: 1.0241 - val_acc: 0.7088\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3176 - acc: 0.5860\n",
      "Epoch 00174: val_loss did not improve from 1.02411\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.3175 - acc: 0.5860 - val_loss: 1.0274 - val_acc: 0.7084\n",
      "Epoch 175/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3065 - acc: 0.5867\n",
      "Epoch 00175: val_loss did not improve from 1.02411\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.3066 - acc: 0.5867 - val_loss: 1.0259 - val_acc: 0.7037\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3093 - acc: 0.5852\n",
      "Epoch 00176: val_loss improved from 1.02411 to 1.02234, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/176-1.0223.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.3093 - acc: 0.5852 - val_loss: 1.0223 - val_acc: 0.7079\n",
      "Epoch 177/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3042 - acc: 0.5888\n",
      "Epoch 00177: val_loss improved from 1.02234 to 1.01736, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/177-1.0174.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.3043 - acc: 0.5888 - val_loss: 1.0174 - val_acc: 0.7116\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3000 - acc: 0.5879\n",
      "Epoch 00178: val_loss improved from 1.01736 to 1.01357, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/178-1.0136.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2999 - acc: 0.5880 - val_loss: 1.0136 - val_acc: 0.7107\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3011 - acc: 0.5879\n",
      "Epoch 00179: val_loss improved from 1.01357 to 1.01120, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/179-1.0112.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3013 - acc: 0.5879 - val_loss: 1.0112 - val_acc: 0.7144\n",
      "Epoch 180/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3044 - acc: 0.5920\n",
      "Epoch 00180: val_loss did not improve from 1.01120\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.3042 - acc: 0.5921 - val_loss: 1.0160 - val_acc: 0.7086\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2964 - acc: 0.5911\n",
      "Epoch 00181: val_loss did not improve from 1.01120\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2965 - acc: 0.5911 - val_loss: 1.0122 - val_acc: 0.7142\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2989 - acc: 0.5930\n",
      "Epoch 00182: val_loss improved from 1.01120 to 1.00667, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/182-1.0067.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.2989 - acc: 0.5931 - val_loss: 1.0067 - val_acc: 0.7154\n",
      "Epoch 183/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2938 - acc: 0.5920\n",
      "Epoch 00183: val_loss improved from 1.00667 to 1.00528, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/183-1.0053.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2937 - acc: 0.5920 - val_loss: 1.0053 - val_acc: 0.7156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3000 - acc: 0.5891\n",
      "Epoch 00184: val_loss did not improve from 1.00528\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2997 - acc: 0.5892 - val_loss: 1.0086 - val_acc: 0.7135\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2860 - acc: 0.5933\n",
      "Epoch 00185: val_loss improved from 1.00528 to 1.00099, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/185-1.0010.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2859 - acc: 0.5933 - val_loss: 1.0010 - val_acc: 0.7174\n",
      "Epoch 186/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2912 - acc: 0.5921\n",
      "Epoch 00186: val_loss did not improve from 1.00099\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.2910 - acc: 0.5923 - val_loss: 1.0103 - val_acc: 0.7100\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2946 - acc: 0.5879\n",
      "Epoch 00187: val_loss improved from 1.00099 to 0.99962, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/187-0.9996.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2946 - acc: 0.5879 - val_loss: 0.9996 - val_acc: 0.7165\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2882 - acc: 0.5960\n",
      "Epoch 00188: val_loss did not improve from 0.99962\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2881 - acc: 0.5960 - val_loss: 1.0003 - val_acc: 0.7160\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2942 - acc: 0.5925\n",
      "Epoch 00189: val_loss did not improve from 0.99962\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2943 - acc: 0.5925 - val_loss: 0.9997 - val_acc: 0.7144\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2878 - acc: 0.5933\n",
      "Epoch 00190: val_loss improved from 0.99962 to 0.99847, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/190-0.9985.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2878 - acc: 0.5933 - val_loss: 0.9985 - val_acc: 0.7191\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2857 - acc: 0.5956\n",
      "Epoch 00191: val_loss improved from 0.99847 to 0.99818, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/191-0.9982.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2856 - acc: 0.5957 - val_loss: 0.9982 - val_acc: 0.7151\n",
      "Epoch 192/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2858 - acc: 0.5935\n",
      "Epoch 00192: val_loss improved from 0.99818 to 0.99659, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/192-0.9966.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2860 - acc: 0.5936 - val_loss: 0.9966 - val_acc: 0.7167\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2850 - acc: 0.5946\n",
      "Epoch 00193: val_loss improved from 0.99659 to 0.99582, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/193-0.9958.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2850 - acc: 0.5946 - val_loss: 0.9958 - val_acc: 0.7179\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2866 - acc: 0.5916\n",
      "Epoch 00194: val_loss did not improve from 0.99582\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2868 - acc: 0.5916 - val_loss: 0.9968 - val_acc: 0.7186\n",
      "Epoch 195/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2765 - acc: 0.5961\n",
      "Epoch 00195: val_loss improved from 0.99582 to 0.99220, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/195-0.9922.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2768 - acc: 0.5960 - val_loss: 0.9922 - val_acc: 0.7165\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2800 - acc: 0.5975\n",
      "Epoch 00196: val_loss improved from 0.99220 to 0.99170, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/196-0.9917.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2799 - acc: 0.5975 - val_loss: 0.9917 - val_acc: 0.7174\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2830 - acc: 0.5963\n",
      "Epoch 00197: val_loss improved from 0.99170 to 0.98851, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/197-0.9885.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2831 - acc: 0.5963 - val_loss: 0.9885 - val_acc: 0.7258\n",
      "Epoch 198/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2828 - acc: 0.5986\n",
      "Epoch 00198: val_loss did not improve from 0.98851\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2824 - acc: 0.5988 - val_loss: 0.9923 - val_acc: 0.7188\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2777 - acc: 0.5984\n",
      "Epoch 00199: val_loss improved from 0.98851 to 0.98195, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/199-0.9820.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.2776 - acc: 0.5984 - val_loss: 0.9820 - val_acc: 0.7226\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2733 - acc: 0.5984\n",
      "Epoch 00200: val_loss did not improve from 0.98195\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2733 - acc: 0.5984 - val_loss: 0.9831 - val_acc: 0.7219\n",
      "Epoch 201/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2794 - acc: 0.5977\n",
      "Epoch 00201: val_loss did not improve from 0.98195\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2794 - acc: 0.5977 - val_loss: 0.9837 - val_acc: 0.7228\n",
      "Epoch 202/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2709 - acc: 0.6004\n",
      "Epoch 00202: val_loss did not improve from 0.98195\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2704 - acc: 0.6005 - val_loss: 0.9840 - val_acc: 0.7230\n",
      "Epoch 203/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2713 - acc: 0.5996\n",
      "Epoch 00203: val_loss did not improve from 0.98195\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2713 - acc: 0.5998 - val_loss: 0.9847 - val_acc: 0.7209\n",
      "Epoch 204/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2730 - acc: 0.5976\n",
      "Epoch 00204: val_loss improved from 0.98195 to 0.97865, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/204-0.9786.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2729 - acc: 0.5978 - val_loss: 0.9786 - val_acc: 0.7244\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2665 - acc: 0.6007\n",
      "Epoch 00205: val_loss improved from 0.97865 to 0.97714, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/205-0.9771.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2664 - acc: 0.6007 - val_loss: 0.9771 - val_acc: 0.7202\n",
      "Epoch 206/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2683 - acc: 0.5993\n",
      "Epoch 00206: val_loss improved from 0.97714 to 0.97382, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/206-0.9738.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2684 - acc: 0.5994 - val_loss: 0.9738 - val_acc: 0.7235\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2725 - acc: 0.5994\n",
      "Epoch 00207: val_loss did not improve from 0.97382\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2724 - acc: 0.5994 - val_loss: 0.9778 - val_acc: 0.7219\n",
      "Epoch 208/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2678 - acc: 0.6027\n",
      "Epoch 00208: val_loss improved from 0.97382 to 0.97342, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/208-0.9734.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2676 - acc: 0.6027 - val_loss: 0.9734 - val_acc: 0.7247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2719 - acc: 0.5993\n",
      "Epoch 00209: val_loss did not improve from 0.97342\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.2721 - acc: 0.5993 - val_loss: 0.9762 - val_acc: 0.7247\n",
      "Epoch 210/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2666 - acc: 0.5991\n",
      "Epoch 00210: val_loss improved from 0.97342 to 0.97249, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/210-0.9725.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2661 - acc: 0.5992 - val_loss: 0.9725 - val_acc: 0.7237\n",
      "Epoch 211/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2634 - acc: 0.6006\n",
      "Epoch 00211: val_loss did not improve from 0.97249\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2633 - acc: 0.6006 - val_loss: 0.9737 - val_acc: 0.7263\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2641 - acc: 0.6030\n",
      "Epoch 00212: val_loss improved from 0.97249 to 0.97041, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/212-0.9704.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2641 - acc: 0.6030 - val_loss: 0.9704 - val_acc: 0.7282\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2587 - acc: 0.6039\n",
      "Epoch 00213: val_loss improved from 0.97041 to 0.96959, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/213-0.9696.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2587 - acc: 0.6039 - val_loss: 0.9696 - val_acc: 0.7272\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2660 - acc: 0.6019\n",
      "Epoch 00214: val_loss improved from 0.96959 to 0.96920, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/214-0.9692.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.2660 - acc: 0.6019 - val_loss: 0.9692 - val_acc: 0.7275\n",
      "Epoch 215/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2606 - acc: 0.6013\n",
      "Epoch 00215: val_loss did not improve from 0.96920\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2607 - acc: 0.6013 - val_loss: 0.9699 - val_acc: 0.7249\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2610 - acc: 0.6012\n",
      "Epoch 00216: val_loss did not improve from 0.96920\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2609 - acc: 0.6013 - val_loss: 0.9715 - val_acc: 0.7237\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2607 - acc: 0.6045\n",
      "Epoch 00217: val_loss improved from 0.96920 to 0.96372, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/217-0.9637.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2607 - acc: 0.6045 - val_loss: 0.9637 - val_acc: 0.7289\n",
      "Epoch 218/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2562 - acc: 0.6024\n",
      "Epoch 00218: val_loss did not improve from 0.96372\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2564 - acc: 0.6024 - val_loss: 0.9668 - val_acc: 0.7307\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2551 - acc: 0.6055\n",
      "Epoch 00219: val_loss improved from 0.96372 to 0.96027, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/219-0.9603.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2550 - acc: 0.6055 - val_loss: 0.9603 - val_acc: 0.7270\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2577 - acc: 0.6065\n",
      "Epoch 00220: val_loss improved from 0.96027 to 0.95963, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/220-0.9596.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.2576 - acc: 0.6065 - val_loss: 0.9596 - val_acc: 0.7305\n",
      "Epoch 221/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2602 - acc: 0.6043\n",
      "Epoch 00221: val_loss did not improve from 0.95963\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2601 - acc: 0.6043 - val_loss: 0.9639 - val_acc: 0.7284\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2571 - acc: 0.6065\n",
      "Epoch 00222: val_loss did not improve from 0.95963\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2571 - acc: 0.6065 - val_loss: 0.9637 - val_acc: 0.7279\n",
      "Epoch 223/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2551 - acc: 0.6058\n",
      "Epoch 00223: val_loss did not improve from 0.95963\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2551 - acc: 0.6059 - val_loss: 0.9604 - val_acc: 0.7272\n",
      "Epoch 224/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2525 - acc: 0.6101\n",
      "Epoch 00224: val_loss improved from 0.95963 to 0.95487, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/224-0.9549.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2523 - acc: 0.6100 - val_loss: 0.9549 - val_acc: 0.7317\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2550 - acc: 0.6080\n",
      "Epoch 00225: val_loss did not improve from 0.95487\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.2550 - acc: 0.6080 - val_loss: 0.9596 - val_acc: 0.7293\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2505 - acc: 0.6083\n",
      "Epoch 00226: val_loss did not improve from 0.95487\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2505 - acc: 0.6083 - val_loss: 0.9580 - val_acc: 0.7326\n",
      "Epoch 227/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2540 - acc: 0.6045\n",
      "Epoch 00227: val_loss did not improve from 0.95487\n",
      "36805/36805 [==============================] - 16s 429us/sample - loss: 1.2541 - acc: 0.6044 - val_loss: 0.9625 - val_acc: 0.7305\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2433 - acc: 0.6095\n",
      "Epoch 00228: val_loss did not improve from 0.95487\n",
      "36805/36805 [==============================] - 16s 429us/sample - loss: 1.2432 - acc: 0.6096 - val_loss: 0.9552 - val_acc: 0.7333\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2421 - acc: 0.6090\n",
      "Epoch 00229: val_loss improved from 0.95487 to 0.94939, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/229-0.9494.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.2421 - acc: 0.6091 - val_loss: 0.9494 - val_acc: 0.7321\n",
      "Epoch 230/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2457 - acc: 0.6083\n",
      "Epoch 00230: val_loss did not improve from 0.94939\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2458 - acc: 0.6082 - val_loss: 0.9614 - val_acc: 0.7300\n",
      "Epoch 231/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2402 - acc: 0.6105\n",
      "Epoch 00231: val_loss improved from 0.94939 to 0.94882, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/231-0.9488.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2403 - acc: 0.6104 - val_loss: 0.9488 - val_acc: 0.7368\n",
      "Epoch 232/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2463 - acc: 0.6099\n",
      "Epoch 00232: val_loss improved from 0.94882 to 0.94862, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/232-0.9486.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.2462 - acc: 0.6099 - val_loss: 0.9486 - val_acc: 0.7368\n",
      "Epoch 233/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2375 - acc: 0.6119\n",
      "Epoch 00233: val_loss improved from 0.94862 to 0.94712, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/233-0.9471.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.2377 - acc: 0.6119 - val_loss: 0.9471 - val_acc: 0.7352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2473 - acc: 0.6095\n",
      "Epoch 00234: val_loss did not improve from 0.94712\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2472 - acc: 0.6095 - val_loss: 0.9487 - val_acc: 0.7333\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2481 - acc: 0.6083\n",
      "Epoch 00235: val_loss improved from 0.94712 to 0.94604, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/235-0.9460.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2480 - acc: 0.6083 - val_loss: 0.9460 - val_acc: 0.7363\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2397 - acc: 0.6074\n",
      "Epoch 00236: val_loss did not improve from 0.94604\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2398 - acc: 0.6074 - val_loss: 0.9500 - val_acc: 0.7335\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2429 - acc: 0.6089\n",
      "Epoch 00237: val_loss improved from 0.94604 to 0.94194, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/237-0.9419.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.2428 - acc: 0.6089 - val_loss: 0.9419 - val_acc: 0.7354\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2373 - acc: 0.6117\n",
      "Epoch 00238: val_loss did not improve from 0.94194\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2372 - acc: 0.6118 - val_loss: 0.9461 - val_acc: 0.7370\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2372 - acc: 0.6098\n",
      "Epoch 00239: val_loss did not improve from 0.94194\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2371 - acc: 0.6099 - val_loss: 0.9469 - val_acc: 0.7333\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2446 - acc: 0.6101\n",
      "Epoch 00240: val_loss did not improve from 0.94194\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2447 - acc: 0.6100 - val_loss: 0.9447 - val_acc: 0.7356\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2343 - acc: 0.6126\n",
      "Epoch 00241: val_loss improved from 0.94194 to 0.93980, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/241-0.9398.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2343 - acc: 0.6126 - val_loss: 0.9398 - val_acc: 0.7363\n",
      "Epoch 242/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2401 - acc: 0.6098\n",
      "Epoch 00242: val_loss improved from 0.93980 to 0.93959, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/242-0.9396.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.2404 - acc: 0.6097 - val_loss: 0.9396 - val_acc: 0.7368\n",
      "Epoch 243/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2328 - acc: 0.6115\n",
      "Epoch 00243: val_loss did not improve from 0.93959\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2329 - acc: 0.6115 - val_loss: 0.9459 - val_acc: 0.7368\n",
      "Epoch 244/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2369 - acc: 0.6125\n",
      "Epoch 00244: val_loss improved from 0.93959 to 0.93932, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/244-0.9393.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2366 - acc: 0.6125 - val_loss: 0.9393 - val_acc: 0.7370\n",
      "Epoch 245/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2359 - acc: 0.6128\n",
      "Epoch 00245: val_loss improved from 0.93932 to 0.93660, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/245-0.9366.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2358 - acc: 0.6128 - val_loss: 0.9366 - val_acc: 0.7412\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2300 - acc: 0.6124\n",
      "Epoch 00246: val_loss did not improve from 0.93660\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2301 - acc: 0.6124 - val_loss: 0.9409 - val_acc: 0.7363\n",
      "Epoch 247/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2364 - acc: 0.6136\n",
      "Epoch 00247: val_loss did not improve from 0.93660\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.2364 - acc: 0.6136 - val_loss: 0.9400 - val_acc: 0.7358\n",
      "Epoch 248/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2269 - acc: 0.6141\n",
      "Epoch 00248: val_loss did not improve from 0.93660\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2269 - acc: 0.6141 - val_loss: 0.9455 - val_acc: 0.7340\n",
      "Epoch 249/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2303 - acc: 0.6179\n",
      "Epoch 00249: val_loss improved from 0.93660 to 0.93500, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/249-0.9350.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2304 - acc: 0.6179 - val_loss: 0.9350 - val_acc: 0.7384\n",
      "Epoch 250/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2338 - acc: 0.6116\n",
      "Epoch 00250: val_loss did not improve from 0.93500\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2340 - acc: 0.6115 - val_loss: 0.9370 - val_acc: 0.7382\n",
      "Epoch 251/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2326 - acc: 0.6130\n",
      "Epoch 00251: val_loss improved from 0.93500 to 0.93278, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/251-0.9328.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2325 - acc: 0.6131 - val_loss: 0.9328 - val_acc: 0.7393\n",
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2273 - acc: 0.6141\n",
      "Epoch 00252: val_loss did not improve from 0.93278\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2272 - acc: 0.6140 - val_loss: 0.9339 - val_acc: 0.7396\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2248 - acc: 0.6162\n",
      "Epoch 00253: val_loss did not improve from 0.93278\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2247 - acc: 0.6162 - val_loss: 0.9336 - val_acc: 0.7372\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2260 - acc: 0.6145\n",
      "Epoch 00254: val_loss did not improve from 0.93278\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2259 - acc: 0.6145 - val_loss: 0.9350 - val_acc: 0.7389\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2267 - acc: 0.6136\n",
      "Epoch 00255: val_loss improved from 0.93278 to 0.93180, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/255-0.9318.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.2266 - acc: 0.6136 - val_loss: 0.9318 - val_acc: 0.7400\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2298 - acc: 0.6148\n",
      "Epoch 00256: val_loss did not improve from 0.93180\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2297 - acc: 0.6149 - val_loss: 0.9328 - val_acc: 0.7410\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2258 - acc: 0.6142\n",
      "Epoch 00257: val_loss did not improve from 0.93180\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2259 - acc: 0.6142 - val_loss: 0.9342 - val_acc: 0.7370\n",
      "Epoch 258/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2252 - acc: 0.6151\n",
      "Epoch 00258: val_loss improved from 0.93180 to 0.92896, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/258-0.9290.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.2246 - acc: 0.6154 - val_loss: 0.9290 - val_acc: 0.7400\n",
      "Epoch 259/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2208 - acc: 0.6169\n",
      "Epoch 00259: val_loss improved from 0.92896 to 0.92501, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/259-0.9250.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2207 - acc: 0.6168 - val_loss: 0.9250 - val_acc: 0.7426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2203 - acc: 0.6159\n",
      "Epoch 00260: val_loss did not improve from 0.92501\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2205 - acc: 0.6158 - val_loss: 0.9257 - val_acc: 0.7393\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2192 - acc: 0.6184\n",
      "Epoch 00261: val_loss did not improve from 0.92501\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.2192 - acc: 0.6184 - val_loss: 0.9310 - val_acc: 0.7363\n",
      "Epoch 262/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2193 - acc: 0.6172\n",
      "Epoch 00262: val_loss did not improve from 0.92501\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.2196 - acc: 0.6172 - val_loss: 0.9290 - val_acc: 0.7398\n",
      "Epoch 263/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2203 - acc: 0.6166\n",
      "Epoch 00263: val_loss did not improve from 0.92501\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2203 - acc: 0.6166 - val_loss: 0.9301 - val_acc: 0.7389\n",
      "Epoch 264/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2175 - acc: 0.6181\n",
      "Epoch 00264: val_loss did not improve from 0.92501\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.2174 - acc: 0.6181 - val_loss: 0.9283 - val_acc: 0.7398\n",
      "Epoch 265/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2211 - acc: 0.6164\n",
      "Epoch 00265: val_loss improved from 0.92501 to 0.92199, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/265-0.9220.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2209 - acc: 0.6165 - val_loss: 0.9220 - val_acc: 0.7433\n",
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2192 - acc: 0.6201\n",
      "Epoch 00266: val_loss improved from 0.92199 to 0.92179, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/266-0.9218.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2193 - acc: 0.6201 - val_loss: 0.9218 - val_acc: 0.7414\n",
      "Epoch 267/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2164 - acc: 0.6197\n",
      "Epoch 00267: val_loss improved from 0.92179 to 0.92097, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/267-0.9210.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.2164 - acc: 0.6198 - val_loss: 0.9210 - val_acc: 0.7417\n",
      "Epoch 268/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2134 - acc: 0.6191\n",
      "Epoch 00268: val_loss improved from 0.92097 to 0.91974, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/268-0.9197.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2134 - acc: 0.6190 - val_loss: 0.9197 - val_acc: 0.7431\n",
      "Epoch 269/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2110 - acc: 0.6196\n",
      "Epoch 00269: val_loss improved from 0.91974 to 0.91758, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/269-0.9176.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2113 - acc: 0.6194 - val_loss: 0.9176 - val_acc: 0.7426\n",
      "Epoch 270/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2174 - acc: 0.6171\n",
      "Epoch 00270: val_loss did not improve from 0.91758\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2172 - acc: 0.6171 - val_loss: 0.9223 - val_acc: 0.7403\n",
      "Epoch 271/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2086 - acc: 0.6214\n",
      "Epoch 00271: val_loss did not improve from 0.91758\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2087 - acc: 0.6215 - val_loss: 0.9188 - val_acc: 0.7421\n",
      "Epoch 272/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2217 - acc: 0.6171\n",
      "Epoch 00272: val_loss did not improve from 0.91758\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2218 - acc: 0.6171 - val_loss: 0.9213 - val_acc: 0.7431\n",
      "Epoch 273/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2143 - acc: 0.6198\n",
      "Epoch 00273: val_loss did not improve from 0.91758\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2145 - acc: 0.6197 - val_loss: 0.9240 - val_acc: 0.7433\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2103 - acc: 0.6190\n",
      "Epoch 00274: val_loss did not improve from 0.91758\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.2103 - acc: 0.6190 - val_loss: 0.9190 - val_acc: 0.7414\n",
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2217 - acc: 0.6165\n",
      "Epoch 00275: val_loss improved from 0.91758 to 0.91279, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/275-0.9128.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2217 - acc: 0.6166 - val_loss: 0.9128 - val_acc: 0.7445\n",
      "Epoch 276/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2115 - acc: 0.6209\n",
      "Epoch 00276: val_loss improved from 0.91279 to 0.91176, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/276-0.9118.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2112 - acc: 0.6208 - val_loss: 0.9118 - val_acc: 0.7461\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2164 - acc: 0.6189\n",
      "Epoch 00277: val_loss did not improve from 0.91176\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.2163 - acc: 0.6190 - val_loss: 0.9195 - val_acc: 0.7419\n",
      "Epoch 278/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2086 - acc: 0.6240\n",
      "Epoch 00278: val_loss did not improve from 0.91176\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2085 - acc: 0.6239 - val_loss: 0.9128 - val_acc: 0.7442\n",
      "Epoch 279/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2149 - acc: 0.6171\n",
      "Epoch 00279: val_loss did not improve from 0.91176\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2151 - acc: 0.6170 - val_loss: 0.9181 - val_acc: 0.7461\n",
      "Epoch 280/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2039 - acc: 0.6248\n",
      "Epoch 00280: val_loss improved from 0.91176 to 0.91014, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/280-0.9101.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.2045 - acc: 0.6247 - val_loss: 0.9101 - val_acc: 0.7445\n",
      "Epoch 281/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2068 - acc: 0.6223\n",
      "Epoch 00281: val_loss improved from 0.91014 to 0.91004, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/281-0.9100.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2068 - acc: 0.6223 - val_loss: 0.9100 - val_acc: 0.7442\n",
      "Epoch 282/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2017 - acc: 0.6223\n",
      "Epoch 00282: val_loss improved from 0.91004 to 0.90712, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/282-0.9071.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2016 - acc: 0.6224 - val_loss: 0.9071 - val_acc: 0.7480\n",
      "Epoch 283/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2076 - acc: 0.6210\n",
      "Epoch 00283: val_loss did not improve from 0.90712\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2075 - acc: 0.6210 - val_loss: 0.9098 - val_acc: 0.7454\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2080 - acc: 0.6222\n",
      "Epoch 00284: val_loss did not improve from 0.90712\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2080 - acc: 0.6222 - val_loss: 0.9097 - val_acc: 0.7456\n",
      "Epoch 285/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2061 - acc: 0.6220\n",
      "Epoch 00285: val_loss did not improve from 0.90712\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2063 - acc: 0.6220 - val_loss: 0.9117 - val_acc: 0.7435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2056 - acc: 0.6237\n",
      "Epoch 00286: val_loss did not improve from 0.90712\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2056 - acc: 0.6238 - val_loss: 0.9096 - val_acc: 0.7470\n",
      "Epoch 287/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2072 - acc: 0.6226\n",
      "Epoch 00287: val_loss did not improve from 0.90712\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2073 - acc: 0.6227 - val_loss: 0.9109 - val_acc: 0.7447\n",
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2019 - acc: 0.6255\n",
      "Epoch 00288: val_loss did not improve from 0.90712\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2020 - acc: 0.6255 - val_loss: 0.9111 - val_acc: 0.7480\n",
      "Epoch 289/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2040 - acc: 0.6246\n",
      "Epoch 00289: val_loss improved from 0.90712 to 0.90041, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/289-0.9004.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2041 - acc: 0.6245 - val_loss: 0.9004 - val_acc: 0.7498\n",
      "Epoch 290/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2021 - acc: 0.6228\n",
      "Epoch 00290: val_loss did not improve from 0.90041\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2021 - acc: 0.6228 - val_loss: 0.9042 - val_acc: 0.7491\n",
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1972 - acc: 0.6225\n",
      "Epoch 00291: val_loss did not improve from 0.90041\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1973 - acc: 0.6225 - val_loss: 0.9054 - val_acc: 0.7459\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2013 - acc: 0.6236\n",
      "Epoch 00292: val_loss did not improve from 0.90041\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2012 - acc: 0.6236 - val_loss: 0.9096 - val_acc: 0.7459\n",
      "Epoch 293/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2013 - acc: 0.6224\n",
      "Epoch 00293: val_loss did not improve from 0.90041\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2014 - acc: 0.6225 - val_loss: 0.9026 - val_acc: 0.7477\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1984 - acc: 0.6217\n",
      "Epoch 00294: val_loss did not improve from 0.90041\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1983 - acc: 0.6217 - val_loss: 0.9011 - val_acc: 0.7480\n",
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2011 - acc: 0.6269\n",
      "Epoch 00295: val_loss did not improve from 0.90041\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2010 - acc: 0.6270 - val_loss: 0.9052 - val_acc: 0.7473\n",
      "Epoch 296/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1991 - acc: 0.6243\n",
      "Epoch 00296: val_loss improved from 0.90041 to 0.89976, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/296-0.8998.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1991 - acc: 0.6243 - val_loss: 0.8998 - val_acc: 0.7482\n",
      "Epoch 297/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1995 - acc: 0.6250\n",
      "Epoch 00297: val_loss did not improve from 0.89976\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1990 - acc: 0.6251 - val_loss: 0.9061 - val_acc: 0.7496\n",
      "Epoch 298/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2060 - acc: 0.6218\n",
      "Epoch 00298: val_loss did not improve from 0.89976\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2061 - acc: 0.6218 - val_loss: 0.9023 - val_acc: 0.7461\n",
      "Epoch 299/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2011 - acc: 0.6264\n",
      "Epoch 00299: val_loss did not improve from 0.89976\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2008 - acc: 0.6264 - val_loss: 0.9050 - val_acc: 0.7459\n",
      "Epoch 300/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1966 - acc: 0.6269\n",
      "Epoch 00300: val_loss did not improve from 0.89976\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1966 - acc: 0.6269 - val_loss: 0.9080 - val_acc: 0.7459\n",
      "Epoch 301/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1945 - acc: 0.6292\n",
      "Epoch 00301: val_loss improved from 0.89976 to 0.89429, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/301-0.8943.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1944 - acc: 0.6293 - val_loss: 0.8943 - val_acc: 0.7470\n",
      "Epoch 302/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2013 - acc: 0.6228\n",
      "Epoch 00302: val_loss did not improve from 0.89429\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2013 - acc: 0.6228 - val_loss: 0.8987 - val_acc: 0.7477\n",
      "Epoch 303/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1990 - acc: 0.6270\n",
      "Epoch 00303: val_loss did not improve from 0.89429\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1989 - acc: 0.6270 - val_loss: 0.8989 - val_acc: 0.7489\n",
      "Epoch 304/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1943 - acc: 0.6266\n",
      "Epoch 00304: val_loss did not improve from 0.89429\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1939 - acc: 0.6267 - val_loss: 0.9002 - val_acc: 0.7491\n",
      "Epoch 305/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1947 - acc: 0.6274\n",
      "Epoch 00305: val_loss did not improve from 0.89429\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1947 - acc: 0.6274 - val_loss: 0.9001 - val_acc: 0.7475\n",
      "Epoch 306/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1953 - acc: 0.6282\n",
      "Epoch 00306: val_loss did not improve from 0.89429\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1955 - acc: 0.6281 - val_loss: 0.9000 - val_acc: 0.7491\n",
      "Epoch 307/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1921 - acc: 0.6248\n",
      "Epoch 00307: val_loss did not improve from 0.89429\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1917 - acc: 0.6249 - val_loss: 0.9026 - val_acc: 0.7487\n",
      "Epoch 308/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1951 - acc: 0.6298\n",
      "Epoch 00308: val_loss did not improve from 0.89429\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1951 - acc: 0.6299 - val_loss: 0.8993 - val_acc: 0.7501\n",
      "Epoch 309/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1931 - acc: 0.6263\n",
      "Epoch 00309: val_loss improved from 0.89429 to 0.89252, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/309-0.8925.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1930 - acc: 0.6263 - val_loss: 0.8925 - val_acc: 0.7517\n",
      "Epoch 310/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1932 - acc: 0.6277\n",
      "Epoch 00310: val_loss did not improve from 0.89252\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1930 - acc: 0.6278 - val_loss: 0.8932 - val_acc: 0.7489\n",
      "Epoch 311/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1928 - acc: 0.6251\n",
      "Epoch 00311: val_loss improved from 0.89252 to 0.89146, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/311-0.8915.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1934 - acc: 0.6249 - val_loss: 0.8915 - val_acc: 0.7522\n",
      "Epoch 312/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1942 - acc: 0.6270\n",
      "Epoch 00312: val_loss did not improve from 0.89146\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.1941 - acc: 0.6271 - val_loss: 0.8960 - val_acc: 0.7501\n",
      "Epoch 313/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1885 - acc: 0.6305\n",
      "Epoch 00313: val_loss improved from 0.89146 to 0.88876, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/313-0.8888.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1887 - acc: 0.6304 - val_loss: 0.8888 - val_acc: 0.7533\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 314/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1895 - acc: 0.6280\n",
      "Epoch 00314: val_loss did not improve from 0.88876\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1896 - acc: 0.6280 - val_loss: 0.8904 - val_acc: 0.7510\n",
      "Epoch 315/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1771 - acc: 0.6317\n",
      "Epoch 00315: val_loss improved from 0.88876 to 0.88600, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/315-0.8860.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1771 - acc: 0.6317 - val_loss: 0.8860 - val_acc: 0.7515\n",
      "Epoch 316/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1887 - acc: 0.6264\n",
      "Epoch 00316: val_loss did not improve from 0.88600\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1886 - acc: 0.6264 - val_loss: 0.8940 - val_acc: 0.7482\n",
      "Epoch 317/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1906 - acc: 0.6252\n",
      "Epoch 00317: val_loss did not improve from 0.88600\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1907 - acc: 0.6250 - val_loss: 0.8887 - val_acc: 0.7512\n",
      "Epoch 318/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1862 - acc: 0.6277\n",
      "Epoch 00318: val_loss did not improve from 0.88600\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1863 - acc: 0.6277 - val_loss: 0.8893 - val_acc: 0.7487\n",
      "Epoch 319/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1857 - acc: 0.6298\n",
      "Epoch 00319: val_loss did not improve from 0.88600\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1860 - acc: 0.6298 - val_loss: 0.8898 - val_acc: 0.7524\n",
      "Epoch 320/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1845 - acc: 0.6322\n",
      "Epoch 00320: val_loss did not improve from 0.88600\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1844 - acc: 0.6321 - val_loss: 0.8894 - val_acc: 0.7501\n",
      "Epoch 321/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1885 - acc: 0.6292\n",
      "Epoch 00321: val_loss improved from 0.88600 to 0.88520, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/321-0.8852.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1884 - acc: 0.6293 - val_loss: 0.8852 - val_acc: 0.7496\n",
      "Epoch 322/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1883 - acc: 0.6312\n",
      "Epoch 00322: val_loss did not improve from 0.88520\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1882 - acc: 0.6312 - val_loss: 0.8884 - val_acc: 0.7517\n",
      "Epoch 323/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1869 - acc: 0.6296\n",
      "Epoch 00323: val_loss did not improve from 0.88520\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1869 - acc: 0.6296 - val_loss: 0.8947 - val_acc: 0.7501\n",
      "Epoch 324/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1855 - acc: 0.6307\n",
      "Epoch 00324: val_loss did not improve from 0.88520\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1854 - acc: 0.6307 - val_loss: 0.8982 - val_acc: 0.7489\n",
      "Epoch 325/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1903 - acc: 0.6289\n",
      "Epoch 00325: val_loss did not improve from 0.88520\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1910 - acc: 0.6289 - val_loss: 0.8909 - val_acc: 0.7512\n",
      "Epoch 326/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1804 - acc: 0.6344\n",
      "Epoch 00326: val_loss improved from 0.88520 to 0.88375, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/326-0.8837.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1802 - acc: 0.6345 - val_loss: 0.8837 - val_acc: 0.7501\n",
      "Epoch 327/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1854 - acc: 0.6294\n",
      "Epoch 00327: val_loss did not improve from 0.88375\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1853 - acc: 0.6294 - val_loss: 0.8901 - val_acc: 0.7489\n",
      "Epoch 328/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1843 - acc: 0.6328\n",
      "Epoch 00328: val_loss did not improve from 0.88375\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1845 - acc: 0.6327 - val_loss: 0.8856 - val_acc: 0.7526\n",
      "Epoch 329/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1846 - acc: 0.6308\n",
      "Epoch 00329: val_loss did not improve from 0.88375\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1846 - acc: 0.6309 - val_loss: 0.8855 - val_acc: 0.7510\n",
      "Epoch 330/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1833 - acc: 0.6288\n",
      "Epoch 00330: val_loss improved from 0.88375 to 0.88089, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/330-0.8809.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1833 - acc: 0.6288 - val_loss: 0.8809 - val_acc: 0.7524\n",
      "Epoch 331/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1802 - acc: 0.6329\n",
      "Epoch 00331: val_loss did not improve from 0.88089\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1804 - acc: 0.6328 - val_loss: 0.8854 - val_acc: 0.7517\n",
      "Epoch 332/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1808 - acc: 0.6303\n",
      "Epoch 00332: val_loss did not improve from 0.88089\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1807 - acc: 0.6304 - val_loss: 0.8891 - val_acc: 0.7536\n",
      "Epoch 333/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1816 - acc: 0.6306\n",
      "Epoch 00333: val_loss did not improve from 0.88089\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1815 - acc: 0.6306 - val_loss: 0.8865 - val_acc: 0.7526\n",
      "Epoch 334/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1872 - acc: 0.6297\n",
      "Epoch 00334: val_loss did not improve from 0.88089\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1872 - acc: 0.6297 - val_loss: 0.8833 - val_acc: 0.7540\n",
      "Epoch 335/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1782 - acc: 0.6285\n",
      "Epoch 00335: val_loss improved from 0.88089 to 0.87861, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/335-0.8786.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1781 - acc: 0.6286 - val_loss: 0.8786 - val_acc: 0.7552\n",
      "Epoch 336/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1790 - acc: 0.6322\n",
      "Epoch 00336: val_loss did not improve from 0.87861\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1790 - acc: 0.6323 - val_loss: 0.8816 - val_acc: 0.7552\n",
      "Epoch 337/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1768 - acc: 0.6325\n",
      "Epoch 00337: val_loss did not improve from 0.87861\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1768 - acc: 0.6325 - val_loss: 0.8842 - val_acc: 0.7515\n",
      "Epoch 338/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1720 - acc: 0.6315\n",
      "Epoch 00338: val_loss improved from 0.87861 to 0.87478, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/338-0.8748.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1720 - acc: 0.6315 - val_loss: 0.8748 - val_acc: 0.7552\n",
      "Epoch 339/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1736 - acc: 0.6343\n",
      "Epoch 00339: val_loss did not improve from 0.87478\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1734 - acc: 0.6342 - val_loss: 0.8817 - val_acc: 0.7547\n",
      "Epoch 340/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1781 - acc: 0.6345\n",
      "Epoch 00340: val_loss did not improve from 0.87478\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1780 - acc: 0.6346 - val_loss: 0.8855 - val_acc: 0.7545\n",
      "Epoch 341/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1765 - acc: 0.6342\n",
      "Epoch 00341: val_loss did not improve from 0.87478\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1764 - acc: 0.6342 - val_loss: 0.8816 - val_acc: 0.7552\n",
      "Epoch 342/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1687 - acc: 0.6347\n",
      "Epoch 00342: val_loss did not improve from 0.87478\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.1687 - acc: 0.6347 - val_loss: 0.8801 - val_acc: 0.7545\n",
      "Epoch 343/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1739 - acc: 0.6342\n",
      "Epoch 00343: val_loss did not improve from 0.87478\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1742 - acc: 0.6341 - val_loss: 0.8748 - val_acc: 0.7533\n",
      "Epoch 344/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1693 - acc: 0.6347\n",
      "Epoch 00344: val_loss did not improve from 0.87478\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1695 - acc: 0.6346 - val_loss: 0.8781 - val_acc: 0.7561\n",
      "Epoch 345/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1676 - acc: 0.6356\n",
      "Epoch 00345: val_loss did not improve from 0.87478\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1678 - acc: 0.6355 - val_loss: 0.8807 - val_acc: 0.7515\n",
      "Epoch 346/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1750 - acc: 0.6357\n",
      "Epoch 00346: val_loss did not improve from 0.87478\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1750 - acc: 0.6356 - val_loss: 0.8777 - val_acc: 0.7552\n",
      "Epoch 347/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1745 - acc: 0.6351\n",
      "Epoch 00347: val_loss improved from 0.87478 to 0.87277, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/347-0.8728.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1753 - acc: 0.6350 - val_loss: 0.8728 - val_acc: 0.7545\n",
      "Epoch 348/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1707 - acc: 0.6361\n",
      "Epoch 00348: val_loss improved from 0.87277 to 0.87262, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/348-0.8726.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1713 - acc: 0.6361 - val_loss: 0.8726 - val_acc: 0.7568\n",
      "Epoch 349/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1717 - acc: 0.6359\n",
      "Epoch 00349: val_loss did not improve from 0.87262\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1716 - acc: 0.6357 - val_loss: 0.8786 - val_acc: 0.7545\n",
      "Epoch 350/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1742 - acc: 0.6329\n",
      "Epoch 00350: val_loss did not improve from 0.87262\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1743 - acc: 0.6329 - val_loss: 0.8786 - val_acc: 0.7531\n",
      "Epoch 351/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1696 - acc: 0.6350\n",
      "Epoch 00351: val_loss did not improve from 0.87262\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1696 - acc: 0.6350 - val_loss: 0.8728 - val_acc: 0.7547\n",
      "Epoch 352/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1705 - acc: 0.6345\n",
      "Epoch 00352: val_loss did not improve from 0.87262\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1705 - acc: 0.6346 - val_loss: 0.8732 - val_acc: 0.7549\n",
      "Epoch 353/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1706 - acc: 0.6354\n",
      "Epoch 00353: val_loss did not improve from 0.87262\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1707 - acc: 0.6353 - val_loss: 0.8735 - val_acc: 0.7559\n",
      "Epoch 354/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1769 - acc: 0.6324\n",
      "Epoch 00354: val_loss did not improve from 0.87262\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1768 - acc: 0.6324 - val_loss: 0.8741 - val_acc: 0.7568\n",
      "Epoch 355/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1690 - acc: 0.6362\n",
      "Epoch 00355: val_loss did not improve from 0.87262\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1687 - acc: 0.6361 - val_loss: 0.8727 - val_acc: 0.7529\n",
      "Epoch 356/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1642 - acc: 0.6381\n",
      "Epoch 00356: val_loss improved from 0.87262 to 0.86962, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/356-0.8696.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1641 - acc: 0.6381 - val_loss: 0.8696 - val_acc: 0.7566\n",
      "Epoch 357/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1729 - acc: 0.6356\n",
      "Epoch 00357: val_loss did not improve from 0.86962\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1727 - acc: 0.6357 - val_loss: 0.8733 - val_acc: 0.7543\n",
      "Epoch 358/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1691 - acc: 0.6335\n",
      "Epoch 00358: val_loss improved from 0.86962 to 0.86943, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/358-0.8694.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1686 - acc: 0.6337 - val_loss: 0.8694 - val_acc: 0.7552\n",
      "Epoch 359/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1662 - acc: 0.6384\n",
      "Epoch 00359: val_loss improved from 0.86943 to 0.86708, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/359-0.8671.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1662 - acc: 0.6383 - val_loss: 0.8671 - val_acc: 0.7538\n",
      "Epoch 360/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1633 - acc: 0.6386\n",
      "Epoch 00360: val_loss did not improve from 0.86708\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1639 - acc: 0.6383 - val_loss: 0.8741 - val_acc: 0.7573\n",
      "Epoch 361/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1695 - acc: 0.6338\n",
      "Epoch 00361: val_loss did not improve from 0.86708\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1695 - acc: 0.6338 - val_loss: 0.8736 - val_acc: 0.7524\n",
      "Epoch 362/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1676 - acc: 0.6361\n",
      "Epoch 00362: val_loss did not improve from 0.86708\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1675 - acc: 0.6361 - val_loss: 0.8724 - val_acc: 0.7559\n",
      "Epoch 363/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1679 - acc: 0.6365\n",
      "Epoch 00363: val_loss did not improve from 0.86708\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1680 - acc: 0.6365 - val_loss: 0.8712 - val_acc: 0.7559\n",
      "Epoch 364/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1584 - acc: 0.6364\n",
      "Epoch 00364: val_loss improved from 0.86708 to 0.86625, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/364-0.8662.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1584 - acc: 0.6364 - val_loss: 0.8662 - val_acc: 0.7554\n",
      "Epoch 365/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1666 - acc: 0.6371\n",
      "Epoch 00365: val_loss did not improve from 0.86625\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1664 - acc: 0.6372 - val_loss: 0.8699 - val_acc: 0.7540\n",
      "Epoch 366/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1661 - acc: 0.6371\n",
      "Epoch 00366: val_loss did not improve from 0.86625\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1661 - acc: 0.6371 - val_loss: 0.8680 - val_acc: 0.7561\n",
      "Epoch 367/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1656 - acc: 0.6359\n",
      "Epoch 00367: val_loss did not improve from 0.86625\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1656 - acc: 0.6359 - val_loss: 0.8714 - val_acc: 0.7552\n",
      "Epoch 368/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1650 - acc: 0.6378\n",
      "Epoch 00368: val_loss improved from 0.86625 to 0.86481, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/368-0.8648.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1650 - acc: 0.6378 - val_loss: 0.8648 - val_acc: 0.7598\n",
      "Epoch 369/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1549 - acc: 0.6390\n",
      "Epoch 00369: val_loss improved from 0.86481 to 0.86292, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/369-0.8629.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1548 - acc: 0.6391 - val_loss: 0.8629 - val_acc: 0.7582\n",
      "Epoch 370/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1656 - acc: 0.6375\n",
      "Epoch 00370: val_loss did not improve from 0.86292\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1656 - acc: 0.6375 - val_loss: 0.8659 - val_acc: 0.7584\n",
      "Epoch 371/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1537 - acc: 0.6396\n",
      "Epoch 00371: val_loss did not improve from 0.86292\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1538 - acc: 0.6396 - val_loss: 0.8654 - val_acc: 0.7584\n",
      "Epoch 372/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1653 - acc: 0.6378\n",
      "Epoch 00372: val_loss did not improve from 0.86292\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1653 - acc: 0.6378 - val_loss: 0.8637 - val_acc: 0.7575\n",
      "Epoch 373/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1608 - acc: 0.6379\n",
      "Epoch 00373: val_loss did not improve from 0.86292\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1607 - acc: 0.6378 - val_loss: 0.8634 - val_acc: 0.7566\n",
      "Epoch 374/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1631 - acc: 0.6380\n",
      "Epoch 00374: val_loss did not improve from 0.86292\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1631 - acc: 0.6380 - val_loss: 0.8690 - val_acc: 0.7577\n",
      "Epoch 375/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1542 - acc: 0.6382\n",
      "Epoch 00375: val_loss improved from 0.86292 to 0.86122, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/375-0.8612.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1543 - acc: 0.6381 - val_loss: 0.8612 - val_acc: 0.7584\n",
      "Epoch 376/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1594 - acc: 0.6378\n",
      "Epoch 00376: val_loss did not improve from 0.86122\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1594 - acc: 0.6377 - val_loss: 0.8672 - val_acc: 0.7603\n",
      "Epoch 377/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1677 - acc: 0.6367\n",
      "Epoch 00377: val_loss improved from 0.86122 to 0.86085, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/377-0.8608.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1677 - acc: 0.6367 - val_loss: 0.8608 - val_acc: 0.7591\n",
      "Epoch 378/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1604 - acc: 0.6362\n",
      "Epoch 00378: val_loss did not improve from 0.86085\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1605 - acc: 0.6361 - val_loss: 0.8644 - val_acc: 0.7594\n",
      "Epoch 379/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1586 - acc: 0.6411\n",
      "Epoch 00379: val_loss did not improve from 0.86085\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1585 - acc: 0.6411 - val_loss: 0.8690 - val_acc: 0.7563\n",
      "Epoch 380/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1595 - acc: 0.6394\n",
      "Epoch 00380: val_loss did not improve from 0.86085\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1598 - acc: 0.6392 - val_loss: 0.8627 - val_acc: 0.7608\n",
      "Epoch 381/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1550 - acc: 0.6392\n",
      "Epoch 00381: val_loss did not improve from 0.86085\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1549 - acc: 0.6392 - val_loss: 0.8626 - val_acc: 0.7584\n",
      "Epoch 382/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1628 - acc: 0.6396\n",
      "Epoch 00382: val_loss did not improve from 0.86085\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1626 - acc: 0.6398 - val_loss: 0.8625 - val_acc: 0.7605\n",
      "Epoch 383/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1604 - acc: 0.6370\n",
      "Epoch 00383: val_loss improved from 0.86085 to 0.85833, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/383-0.8583.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1604 - acc: 0.6370 - val_loss: 0.8583 - val_acc: 0.7608\n",
      "Epoch 384/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1560 - acc: 0.6403\n",
      "Epoch 00384: val_loss did not improve from 0.85833\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1561 - acc: 0.6403 - val_loss: 0.8610 - val_acc: 0.7601\n",
      "Epoch 385/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1613 - acc: 0.6360\n",
      "Epoch 00385: val_loss did not improve from 0.85833\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1612 - acc: 0.6360 - val_loss: 0.8607 - val_acc: 0.7612\n",
      "Epoch 386/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1555 - acc: 0.6403\n",
      "Epoch 00386: val_loss did not improve from 0.85833\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1554 - acc: 0.6403 - val_loss: 0.8679 - val_acc: 0.7554\n",
      "Epoch 387/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1580 - acc: 0.6393\n",
      "Epoch 00387: val_loss did not improve from 0.85833\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1581 - acc: 0.6393 - val_loss: 0.8614 - val_acc: 0.7566\n",
      "Epoch 388/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1571 - acc: 0.6424\n",
      "Epoch 00388: val_loss improved from 0.85833 to 0.85344, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/388-0.8534.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1571 - acc: 0.6424 - val_loss: 0.8534 - val_acc: 0.7612\n",
      "Epoch 389/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1569 - acc: 0.6378\n",
      "Epoch 00389: val_loss did not improve from 0.85344\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1571 - acc: 0.6379 - val_loss: 0.8712 - val_acc: 0.7596\n",
      "Epoch 390/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1607 - acc: 0.6371\n",
      "Epoch 00390: val_loss did not improve from 0.85344\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1607 - acc: 0.6371 - val_loss: 0.8565 - val_acc: 0.7626\n",
      "Epoch 391/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1509 - acc: 0.6412\n",
      "Epoch 00391: val_loss did not improve from 0.85344\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1510 - acc: 0.6412 - val_loss: 0.8560 - val_acc: 0.7624\n",
      "Epoch 392/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1535 - acc: 0.6395\n",
      "Epoch 00392: val_loss did not improve from 0.85344\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1534 - acc: 0.6397 - val_loss: 0.8621 - val_acc: 0.7612\n",
      "Epoch 393/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1516 - acc: 0.6408\n",
      "Epoch 00393: val_loss did not improve from 0.85344\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1515 - acc: 0.6408 - val_loss: 0.8579 - val_acc: 0.7610\n",
      "Epoch 394/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1582 - acc: 0.6404\n",
      "Epoch 00394: val_loss did not improve from 0.85344\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1582 - acc: 0.6403 - val_loss: 0.8586 - val_acc: 0.7617\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1563 - acc: 0.6395\n",
      "Epoch 00395: val_loss did not improve from 0.85344\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1563 - acc: 0.6395 - val_loss: 0.8583 - val_acc: 0.7619\n",
      "Epoch 396/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1488 - acc: 0.6410\n",
      "Epoch 00396: val_loss did not improve from 0.85344\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1488 - acc: 0.6411 - val_loss: 0.8549 - val_acc: 0.7608\n",
      "Epoch 397/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1586 - acc: 0.6405\n",
      "Epoch 00397: val_loss did not improve from 0.85344\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1591 - acc: 0.6405 - val_loss: 0.8585 - val_acc: 0.7608\n",
      "Epoch 398/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1561 - acc: 0.6410\n",
      "Epoch 00398: val_loss did not improve from 0.85344\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1560 - acc: 0.6410 - val_loss: 0.8579 - val_acc: 0.7610\n",
      "Epoch 399/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1497 - acc: 0.6420\n",
      "Epoch 00399: val_loss improved from 0.85344 to 0.85159, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/399-0.8516.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1496 - acc: 0.6421 - val_loss: 0.8516 - val_acc: 0.7624\n",
      "Epoch 400/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1570 - acc: 0.6396\n",
      "Epoch 00400: val_loss did not improve from 0.85159\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1570 - acc: 0.6396 - val_loss: 0.8544 - val_acc: 0.7584\n",
      "Epoch 401/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1513 - acc: 0.6443\n",
      "Epoch 00401: val_loss did not improve from 0.85159\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1513 - acc: 0.6443 - val_loss: 0.8553 - val_acc: 0.7645\n",
      "Epoch 402/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1458 - acc: 0.6412\n",
      "Epoch 00402: val_loss did not improve from 0.85159\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1465 - acc: 0.6413 - val_loss: 0.8601 - val_acc: 0.7622\n",
      "Epoch 403/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1514 - acc: 0.6435\n",
      "Epoch 00403: val_loss did not improve from 0.85159\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1514 - acc: 0.6436 - val_loss: 0.8529 - val_acc: 0.7633\n",
      "Epoch 404/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1558 - acc: 0.6396\n",
      "Epoch 00404: val_loss did not improve from 0.85159\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1558 - acc: 0.6396 - val_loss: 0.8560 - val_acc: 0.7577\n",
      "Epoch 405/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1533 - acc: 0.6419\n",
      "Epoch 00405: val_loss did not improve from 0.85159\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1530 - acc: 0.6420 - val_loss: 0.8541 - val_acc: 0.7615\n",
      "Epoch 406/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1546 - acc: 0.6414\n",
      "Epoch 00406: val_loss did not improve from 0.85159\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1546 - acc: 0.6414 - val_loss: 0.8574 - val_acc: 0.7603\n",
      "Epoch 407/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1495 - acc: 0.6417\n",
      "Epoch 00407: val_loss did not improve from 0.85159\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1495 - acc: 0.6418 - val_loss: 0.8564 - val_acc: 0.7624\n",
      "Epoch 408/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1468 - acc: 0.6414\n",
      "Epoch 00408: val_loss did not improve from 0.85159\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1475 - acc: 0.6411 - val_loss: 0.8580 - val_acc: 0.7619\n",
      "Epoch 409/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1479 - acc: 0.6451\n",
      "Epoch 00409: val_loss did not improve from 0.85159\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1479 - acc: 0.6451 - val_loss: 0.8555 - val_acc: 0.7603\n",
      "Epoch 410/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1496 - acc: 0.6433\n",
      "Epoch 00410: val_loss did not improve from 0.85159\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1494 - acc: 0.6434 - val_loss: 0.8520 - val_acc: 0.7654\n",
      "Epoch 411/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1460 - acc: 0.6423\n",
      "Epoch 00411: val_loss improved from 0.85159 to 0.85136, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/411-0.8514.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1461 - acc: 0.6422 - val_loss: 0.8514 - val_acc: 0.7633\n",
      "Epoch 412/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1471 - acc: 0.6421\n",
      "Epoch 00412: val_loss improved from 0.85136 to 0.84911, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/412-0.8491.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1473 - acc: 0.6420 - val_loss: 0.8491 - val_acc: 0.7643\n",
      "Epoch 413/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1493 - acc: 0.6426\n",
      "Epoch 00413: val_loss did not improve from 0.84911\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1498 - acc: 0.6427 - val_loss: 0.8507 - val_acc: 0.7619\n",
      "Epoch 414/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1481 - acc: 0.6445\n",
      "Epoch 00414: val_loss did not improve from 0.84911\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1481 - acc: 0.6445 - val_loss: 0.8493 - val_acc: 0.7624\n",
      "Epoch 415/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1471 - acc: 0.6423\n",
      "Epoch 00415: val_loss improved from 0.84911 to 0.84867, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/415-0.8487.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1471 - acc: 0.6423 - val_loss: 0.8487 - val_acc: 0.7650\n",
      "Epoch 416/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1468 - acc: 0.6426\n",
      "Epoch 00416: val_loss did not improve from 0.84867\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1474 - acc: 0.6426 - val_loss: 0.8488 - val_acc: 0.7631\n",
      "Epoch 417/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1490 - acc: 0.6422\n",
      "Epoch 00417: val_loss did not improve from 0.84867\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1490 - acc: 0.6422 - val_loss: 0.8492 - val_acc: 0.7640\n",
      "Epoch 418/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1459 - acc: 0.6438\n",
      "Epoch 00418: val_loss did not improve from 0.84867\n",
      "36805/36805 [==============================] - 16s 430us/sample - loss: 1.1457 - acc: 0.6438 - val_loss: 0.8548 - val_acc: 0.7601\n",
      "Epoch 419/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1450 - acc: 0.6417\n",
      "Epoch 00419: val_loss improved from 0.84867 to 0.84825, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/419-0.8483.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1450 - acc: 0.6417 - val_loss: 0.8483 - val_acc: 0.7640\n",
      "Epoch 420/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1510 - acc: 0.6408\n",
      "Epoch 00420: val_loss improved from 0.84825 to 0.84805, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/420-0.8481.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1513 - acc: 0.6408 - val_loss: 0.8481 - val_acc: 0.7650\n",
      "Epoch 421/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1453 - acc: 0.6446\n",
      "Epoch 00421: val_loss improved from 0.84805 to 0.84257, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/421-0.8426.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1452 - acc: 0.6447 - val_loss: 0.8426 - val_acc: 0.7661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 422/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1459 - acc: 0.6448\n",
      "Epoch 00422: val_loss did not improve from 0.84257\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1459 - acc: 0.6447 - val_loss: 0.8479 - val_acc: 0.7631\n",
      "Epoch 423/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1397 - acc: 0.6441\n",
      "Epoch 00423: val_loss did not improve from 0.84257\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1400 - acc: 0.6440 - val_loss: 0.8460 - val_acc: 0.7647\n",
      "Epoch 424/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1456 - acc: 0.6467\n",
      "Epoch 00424: val_loss did not improve from 0.84257\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1455 - acc: 0.6467 - val_loss: 0.8478 - val_acc: 0.7645\n",
      "Epoch 425/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1459 - acc: 0.6411\n",
      "Epoch 00425: val_loss did not improve from 0.84257\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1457 - acc: 0.6412 - val_loss: 0.8507 - val_acc: 0.7645\n",
      "Epoch 426/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1519 - acc: 0.6432\n",
      "Epoch 00426: val_loss did not improve from 0.84257\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1519 - acc: 0.6433 - val_loss: 0.8462 - val_acc: 0.7636\n",
      "Epoch 427/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1427 - acc: 0.6441\n",
      "Epoch 00427: val_loss did not improve from 0.84257\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1426 - acc: 0.6441 - val_loss: 0.8450 - val_acc: 0.7624\n",
      "Epoch 428/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1442 - acc: 0.6418\n",
      "Epoch 00428: val_loss did not improve from 0.84257\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1443 - acc: 0.6418 - val_loss: 0.8457 - val_acc: 0.7645\n",
      "Epoch 429/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1419 - acc: 0.6464\n",
      "Epoch 00429: val_loss improved from 0.84257 to 0.84170, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/429-0.8417.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1419 - acc: 0.6464 - val_loss: 0.8417 - val_acc: 0.7652\n",
      "Epoch 430/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1380 - acc: 0.6475\n",
      "Epoch 00430: val_loss did not improve from 0.84170\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1379 - acc: 0.6477 - val_loss: 0.8451 - val_acc: 0.7643\n",
      "Epoch 431/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1439 - acc: 0.6418\n",
      "Epoch 00431: val_loss did not improve from 0.84170\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1436 - acc: 0.6418 - val_loss: 0.8426 - val_acc: 0.7645\n",
      "Epoch 432/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1442 - acc: 0.6440\n",
      "Epoch 00432: val_loss did not improve from 0.84170\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1443 - acc: 0.6439 - val_loss: 0.8513 - val_acc: 0.7629\n",
      "Epoch 433/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1406 - acc: 0.6415\n",
      "Epoch 00433: val_loss did not improve from 0.84170\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1407 - acc: 0.6416 - val_loss: 0.8477 - val_acc: 0.7654\n",
      "Epoch 434/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1437 - acc: 0.6442\n",
      "Epoch 00434: val_loss did not improve from 0.84170\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1438 - acc: 0.6442 - val_loss: 0.8425 - val_acc: 0.7650\n",
      "Epoch 435/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1425 - acc: 0.6441\n",
      "Epoch 00435: val_loss improved from 0.84170 to 0.84013, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/435-0.8401.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1425 - acc: 0.6441 - val_loss: 0.8401 - val_acc: 0.7652\n",
      "Epoch 436/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1424 - acc: 0.6463\n",
      "Epoch 00436: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1425 - acc: 0.6463 - val_loss: 0.8428 - val_acc: 0.7654\n",
      "Epoch 437/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1408 - acc: 0.6454\n",
      "Epoch 00437: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1408 - acc: 0.6454 - val_loss: 0.8402 - val_acc: 0.7668\n",
      "Epoch 438/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1386 - acc: 0.6462\n",
      "Epoch 00438: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1388 - acc: 0.6462 - val_loss: 0.8510 - val_acc: 0.7603\n",
      "Epoch 439/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1428 - acc: 0.6426\n",
      "Epoch 00439: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1423 - acc: 0.6427 - val_loss: 0.8453 - val_acc: 0.7643\n",
      "Epoch 440/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1430 - acc: 0.6460\n",
      "Epoch 00440: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1436 - acc: 0.6458 - val_loss: 0.8405 - val_acc: 0.7661\n",
      "Epoch 441/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1372 - acc: 0.6440\n",
      "Epoch 00441: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1372 - acc: 0.6441 - val_loss: 0.8429 - val_acc: 0.7608\n",
      "Epoch 442/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1420 - acc: 0.6456\n",
      "Epoch 00442: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1419 - acc: 0.6456 - val_loss: 0.8453 - val_acc: 0.7643\n",
      "Epoch 443/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1390 - acc: 0.6463\n",
      "Epoch 00443: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1401 - acc: 0.6462 - val_loss: 0.8433 - val_acc: 0.7647\n",
      "Epoch 444/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1420 - acc: 0.6454\n",
      "Epoch 00444: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1420 - acc: 0.6455 - val_loss: 0.8470 - val_acc: 0.7659\n",
      "Epoch 445/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1376 - acc: 0.6442\n",
      "Epoch 00445: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1375 - acc: 0.6442 - val_loss: 0.8466 - val_acc: 0.7654\n",
      "Epoch 446/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1356 - acc: 0.6451\n",
      "Epoch 00446: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1356 - acc: 0.6450 - val_loss: 0.8470 - val_acc: 0.7692\n",
      "Epoch 447/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1397 - acc: 0.6468\n",
      "Epoch 00447: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1397 - acc: 0.6468 - val_loss: 0.8405 - val_acc: 0.7664\n",
      "Epoch 448/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1409 - acc: 0.6435\n",
      "Epoch 00448: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1407 - acc: 0.6434 - val_loss: 0.8488 - val_acc: 0.7671\n",
      "Epoch 449/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1349 - acc: 0.6482\n",
      "Epoch 00449: val_loss did not improve from 0.84013\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1349 - acc: 0.6482 - val_loss: 0.8472 - val_acc: 0.7619\n",
      "Epoch 450/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1350 - acc: 0.6474\n",
      "Epoch 00450: val_loss improved from 0.84013 to 0.83899, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/450-0.8390.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1349 - acc: 0.6474 - val_loss: 0.8390 - val_acc: 0.7631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 451/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1386 - acc: 0.6469\n",
      "Epoch 00451: val_loss did not improve from 0.83899\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1387 - acc: 0.6468 - val_loss: 0.8403 - val_acc: 0.7692\n",
      "Epoch 452/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1308 - acc: 0.6496\n",
      "Epoch 00452: val_loss did not improve from 0.83899\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1308 - acc: 0.6496 - val_loss: 0.8449 - val_acc: 0.7647\n",
      "Epoch 453/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1353 - acc: 0.6479\n",
      "Epoch 00453: val_loss improved from 0.83899 to 0.83738, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/453-0.8374.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1354 - acc: 0.6479 - val_loss: 0.8374 - val_acc: 0.7666\n",
      "Epoch 454/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1356 - acc: 0.6451\n",
      "Epoch 00454: val_loss did not improve from 0.83738\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1357 - acc: 0.6451 - val_loss: 0.8403 - val_acc: 0.7678\n",
      "Epoch 455/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1327 - acc: 0.6494\n",
      "Epoch 00455: val_loss improved from 0.83738 to 0.83588, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/455-0.8359.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1327 - acc: 0.6494 - val_loss: 0.8359 - val_acc: 0.7650\n",
      "Epoch 456/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1298 - acc: 0.6474\n",
      "Epoch 00456: val_loss did not improve from 0.83588\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1298 - acc: 0.6474 - val_loss: 0.8376 - val_acc: 0.7685\n",
      "Epoch 457/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1354 - acc: 0.6484\n",
      "Epoch 00457: val_loss did not improve from 0.83588\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1354 - acc: 0.6484 - val_loss: 0.8376 - val_acc: 0.7652\n",
      "Epoch 458/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1311 - acc: 0.6477\n",
      "Epoch 00458: val_loss did not improve from 0.83588\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1313 - acc: 0.6476 - val_loss: 0.8375 - val_acc: 0.7657\n",
      "Epoch 459/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1435 - acc: 0.6452\n",
      "Epoch 00459: val_loss did not improve from 0.83588\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1436 - acc: 0.6452 - val_loss: 0.8402 - val_acc: 0.7678\n",
      "Epoch 460/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1282 - acc: 0.6490\n",
      "Epoch 00460: val_loss did not improve from 0.83588\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1281 - acc: 0.6490 - val_loss: 0.8397 - val_acc: 0.7654\n",
      "Epoch 461/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1282 - acc: 0.6472\n",
      "Epoch 00461: val_loss did not improve from 0.83588\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1281 - acc: 0.6473 - val_loss: 0.8380 - val_acc: 0.7657\n",
      "Epoch 462/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1335 - acc: 0.6481\n",
      "Epoch 00462: val_loss did not improve from 0.83588\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1335 - acc: 0.6481 - val_loss: 0.8377 - val_acc: 0.7694\n",
      "Epoch 463/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1291 - acc: 0.6455\n",
      "Epoch 00463: val_loss improved from 0.83588 to 0.83378, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/463-0.8338.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1291 - acc: 0.6455 - val_loss: 0.8338 - val_acc: 0.7701\n",
      "Epoch 464/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1399 - acc: 0.6463\n",
      "Epoch 00464: val_loss did not improve from 0.83378\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1401 - acc: 0.6463 - val_loss: 0.8374 - val_acc: 0.7671\n",
      "Epoch 465/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1307 - acc: 0.6488\n",
      "Epoch 00465: val_loss did not improve from 0.83378\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1307 - acc: 0.6487 - val_loss: 0.8365 - val_acc: 0.7699\n",
      "Epoch 466/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1310 - acc: 0.6490\n",
      "Epoch 00466: val_loss did not improve from 0.83378\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1307 - acc: 0.6491 - val_loss: 0.8350 - val_acc: 0.7675\n",
      "Epoch 467/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1269 - acc: 0.6507\n",
      "Epoch 00467: val_loss improved from 0.83378 to 0.83192, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/467-0.8319.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1269 - acc: 0.6507 - val_loss: 0.8319 - val_acc: 0.7675\n",
      "Epoch 468/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1311 - acc: 0.6447\n",
      "Epoch 00468: val_loss improved from 0.83192 to 0.83151, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/468-0.8315.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1306 - acc: 0.6447 - val_loss: 0.8315 - val_acc: 0.7673\n",
      "Epoch 469/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1334 - acc: 0.6489\n",
      "Epoch 00469: val_loss did not improve from 0.83151\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1334 - acc: 0.6489 - val_loss: 0.8337 - val_acc: 0.7675\n",
      "Epoch 470/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1338 - acc: 0.6463\n",
      "Epoch 00470: val_loss did not improve from 0.83151\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.1338 - acc: 0.6464 - val_loss: 0.8336 - val_acc: 0.7701\n",
      "Epoch 471/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1311 - acc: 0.6485\n",
      "Epoch 00471: val_loss did not improve from 0.83151\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1316 - acc: 0.6485 - val_loss: 0.8317 - val_acc: 0.7692\n",
      "Epoch 472/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1280 - acc: 0.6500\n",
      "Epoch 00472: val_loss did not improve from 0.83151\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1280 - acc: 0.6500 - val_loss: 0.8340 - val_acc: 0.7678\n",
      "Epoch 473/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1325 - acc: 0.6506\n",
      "Epoch 00473: val_loss improved from 0.83151 to 0.82920, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/473-0.8292.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1325 - acc: 0.6506 - val_loss: 0.8292 - val_acc: 0.7703\n",
      "Epoch 474/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1330 - acc: 0.6466\n",
      "Epoch 00474: val_loss did not improve from 0.82920\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1331 - acc: 0.6466 - val_loss: 0.8367 - val_acc: 0.7668\n",
      "Epoch 475/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1313 - acc: 0.6498\n",
      "Epoch 00475: val_loss did not improve from 0.82920\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1313 - acc: 0.6498 - val_loss: 0.8305 - val_acc: 0.7692\n",
      "Epoch 476/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1228 - acc: 0.6526\n",
      "Epoch 00476: val_loss improved from 0.82920 to 0.82728, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/476-0.8273.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.1228 - acc: 0.6526 - val_loss: 0.8273 - val_acc: 0.7680\n",
      "Epoch 477/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1250 - acc: 0.6513\n",
      "Epoch 00477: val_loss did not improve from 0.82728\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1250 - acc: 0.6513 - val_loss: 0.8317 - val_acc: 0.7673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1235 - acc: 0.6487\n",
      "Epoch 00478: val_loss did not improve from 0.82728\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1235 - acc: 0.6487 - val_loss: 0.8369 - val_acc: 0.7673\n",
      "Epoch 479/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1271 - acc: 0.6502\n",
      "Epoch 00479: val_loss did not improve from 0.82728\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1271 - acc: 0.6502 - val_loss: 0.8289 - val_acc: 0.7694\n",
      "Epoch 480/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1170 - acc: 0.6524\n",
      "Epoch 00480: val_loss did not improve from 0.82728\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1170 - acc: 0.6525 - val_loss: 0.8293 - val_acc: 0.7682\n",
      "Epoch 481/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1266 - acc: 0.6490\n",
      "Epoch 00481: val_loss did not improve from 0.82728\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1265 - acc: 0.6491 - val_loss: 0.8280 - val_acc: 0.7671\n",
      "Epoch 482/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1232 - acc: 0.6507\n",
      "Epoch 00482: val_loss did not improve from 0.82728\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1232 - acc: 0.6507 - val_loss: 0.8277 - val_acc: 0.7692\n",
      "Epoch 483/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1304 - acc: 0.6484\n",
      "Epoch 00483: val_loss did not improve from 0.82728\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1304 - acc: 0.6485 - val_loss: 0.8361 - val_acc: 0.7685\n",
      "Epoch 484/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1233 - acc: 0.6499\n",
      "Epoch 00484: val_loss improved from 0.82728 to 0.82599, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/484-0.8260.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1233 - acc: 0.6499 - val_loss: 0.8260 - val_acc: 0.7713\n",
      "Epoch 485/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1212 - acc: 0.6493\n",
      "Epoch 00485: val_loss did not improve from 0.82599\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1211 - acc: 0.6493 - val_loss: 0.8332 - val_acc: 0.7689\n",
      "Epoch 486/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1216 - acc: 0.6545\n",
      "Epoch 00486: val_loss did not improve from 0.82599\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1215 - acc: 0.6546 - val_loss: 0.8383 - val_acc: 0.7664\n",
      "Epoch 487/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1247 - acc: 0.6506\n",
      "Epoch 00487: val_loss did not improve from 0.82599\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1247 - acc: 0.6506 - val_loss: 0.8279 - val_acc: 0.7715\n",
      "Epoch 488/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1257 - acc: 0.6523\n",
      "Epoch 00488: val_loss did not improve from 0.82599\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1256 - acc: 0.6524 - val_loss: 0.8268 - val_acc: 0.7710\n",
      "Epoch 489/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1248 - acc: 0.6492\n",
      "Epoch 00489: val_loss did not improve from 0.82599\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1248 - acc: 0.6492 - val_loss: 0.8324 - val_acc: 0.7692\n",
      "Epoch 490/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1255 - acc: 0.6484\n",
      "Epoch 00490: val_loss did not improve from 0.82599\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1255 - acc: 0.6484 - val_loss: 0.8324 - val_acc: 0.7701\n",
      "Epoch 491/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1261 - acc: 0.6469\n",
      "Epoch 00491: val_loss improved from 0.82599 to 0.82402, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/491-0.8240.hdf5\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 1.1261 - acc: 0.6469 - val_loss: 0.8240 - val_acc: 0.7724\n",
      "Epoch 492/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1231 - acc: 0.6486\n",
      "Epoch 00492: val_loss did not improve from 0.82402\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1230 - acc: 0.6486 - val_loss: 0.8248 - val_acc: 0.7722\n",
      "Epoch 493/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1210 - acc: 0.6514\n",
      "Epoch 00493: val_loss did not improve from 0.82402\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1209 - acc: 0.6514 - val_loss: 0.8255 - val_acc: 0.7717\n",
      "Epoch 494/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1206 - acc: 0.6516\n",
      "Epoch 00494: val_loss did not improve from 0.82402\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1206 - acc: 0.6516 - val_loss: 0.8266 - val_acc: 0.7701\n",
      "Epoch 495/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1212 - acc: 0.6491\n",
      "Epoch 00495: val_loss did not improve from 0.82402\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1212 - acc: 0.6491 - val_loss: 0.8304 - val_acc: 0.7692\n",
      "Epoch 496/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1204 - acc: 0.6509\n",
      "Epoch 00496: val_loss did not improve from 0.82402\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1203 - acc: 0.6509 - val_loss: 0.8289 - val_acc: 0.7720\n",
      "Epoch 497/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1254 - acc: 0.6507\n",
      "Epoch 00497: val_loss did not improve from 0.82402\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1254 - acc: 0.6507 - val_loss: 0.8280 - val_acc: 0.7682\n",
      "Epoch 498/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1210 - acc: 0.6508\n",
      "Epoch 00498: val_loss did not improve from 0.82402\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1209 - acc: 0.6508 - val_loss: 0.8292 - val_acc: 0.7699\n",
      "Epoch 499/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1259 - acc: 0.6515\n",
      "Epoch 00499: val_loss improved from 0.82402 to 0.82380, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv_checkpoint/499-0.8238.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1259 - acc: 0.6515 - val_loss: 0.8238 - val_acc: 0.7692\n",
      "Epoch 500/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1193 - acc: 0.6539\n",
      "Epoch 00500: val_loss did not improve from 0.82380\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1192 - acc: 0.6540 - val_loss: 0.8291 - val_acc: 0.7720\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 287us/sample - loss: 0.8719 - acc: 0.7433\n",
      "Loss: 0.8719101119388053 Accuracy: 0.74330217\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7340 - acc: 0.0950\n",
      "Epoch 00001: val_loss improved from inf to 2.66969, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/001-2.6697.hdf5\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 2.7340 - acc: 0.0950 - val_loss: 2.6697 - val_acc: 0.1332\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6070 - acc: 0.1586\n",
      "Epoch 00002: val_loss improved from 2.66969 to 2.46063, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/002-2.4606.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 2.6070 - acc: 0.1586 - val_loss: 2.4606 - val_acc: 0.2285\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4114 - acc: 0.2129\n",
      "Epoch 00003: val_loss improved from 2.46063 to 2.23358, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/003-2.2336.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 2.4113 - acc: 0.2129 - val_loss: 2.2336 - val_acc: 0.3168\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2692 - acc: 0.2458\n",
      "Epoch 00004: val_loss improved from 2.23358 to 2.10799, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/004-2.1080.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 2.2693 - acc: 0.2458 - val_loss: 2.1080 - val_acc: 0.3599\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1795 - acc: 0.2716\n",
      "Epoch 00005: val_loss improved from 2.10799 to 2.02886, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/005-2.0289.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 2.1795 - acc: 0.2716 - val_loss: 2.0289 - val_acc: 0.3727\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1255 - acc: 0.2881\n",
      "Epoch 00006: val_loss improved from 2.02886 to 1.95521, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/006-1.9552.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 2.1256 - acc: 0.2881 - val_loss: 1.9552 - val_acc: 0.3995\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0685 - acc: 0.3070\n",
      "Epoch 00007: val_loss improved from 1.95521 to 1.89402, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/007-1.8940.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 2.0685 - acc: 0.3069 - val_loss: 1.8940 - val_acc: 0.4246\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0211 - acc: 0.3237\n",
      "Epoch 00008: val_loss improved from 1.89402 to 1.85325, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/008-1.8532.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 2.0211 - acc: 0.3237 - val_loss: 1.8532 - val_acc: 0.4365\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9857 - acc: 0.3291\n",
      "Epoch 00009: val_loss improved from 1.85325 to 1.81448, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/009-1.8145.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.9856 - acc: 0.3291 - val_loss: 1.8145 - val_acc: 0.4454\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9437 - acc: 0.3455\n",
      "Epoch 00010: val_loss improved from 1.81448 to 1.76620, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/010-1.7662.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 1.9437 - acc: 0.3455 - val_loss: 1.7662 - val_acc: 0.4647\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9092 - acc: 0.3570\n",
      "Epoch 00011: val_loss improved from 1.76620 to 1.72645, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/011-1.7265.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.9092 - acc: 0.3570 - val_loss: 1.7265 - val_acc: 0.4761\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8785 - acc: 0.3711\n",
      "Epoch 00012: val_loss improved from 1.72645 to 1.69383, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/012-1.6938.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.8785 - acc: 0.3711 - val_loss: 1.6938 - val_acc: 0.4889\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8430 - acc: 0.3823\n",
      "Epoch 00013: val_loss improved from 1.69383 to 1.65785, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/013-1.6579.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.8430 - acc: 0.3823 - val_loss: 1.6579 - val_acc: 0.4987\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8152 - acc: 0.3910\n",
      "Epoch 00014: val_loss improved from 1.65785 to 1.62543, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/014-1.6254.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.8152 - acc: 0.3909 - val_loss: 1.6254 - val_acc: 0.5080\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7865 - acc: 0.4058\n",
      "Epoch 00015: val_loss improved from 1.62543 to 1.59060, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/015-1.5906.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.7866 - acc: 0.4058 - val_loss: 1.5906 - val_acc: 0.5208\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7617 - acc: 0.4140\n",
      "Epoch 00016: val_loss improved from 1.59060 to 1.56408, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/016-1.5641.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.7617 - acc: 0.4141 - val_loss: 1.5641 - val_acc: 0.5325\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7359 - acc: 0.4211\n",
      "Epoch 00017: val_loss improved from 1.56408 to 1.53332, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/017-1.5333.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 1.7358 - acc: 0.4211 - val_loss: 1.5333 - val_acc: 0.5486\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7108 - acc: 0.4332\n",
      "Epoch 00018: val_loss improved from 1.53332 to 1.50500, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/018-1.5050.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.7109 - acc: 0.4331 - val_loss: 1.5050 - val_acc: 0.5558\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6892 - acc: 0.4420\n",
      "Epoch 00019: val_loss improved from 1.50500 to 1.47641, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/019-1.4764.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.6891 - acc: 0.4420 - val_loss: 1.4764 - val_acc: 0.5639\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6668 - acc: 0.4521\n",
      "Epoch 00020: val_loss improved from 1.47641 to 1.45548, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/020-1.4555.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 1.6667 - acc: 0.4521 - val_loss: 1.4555 - val_acc: 0.5730\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6470 - acc: 0.4574\n",
      "Epoch 00021: val_loss improved from 1.45548 to 1.43329, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/021-1.4333.hdf5\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.6470 - acc: 0.4574 - val_loss: 1.4333 - val_acc: 0.5823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6297 - acc: 0.4651\n",
      "Epoch 00022: val_loss improved from 1.43329 to 1.41107, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/022-1.4111.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.6299 - acc: 0.4650 - val_loss: 1.4111 - val_acc: 0.5833\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6157 - acc: 0.4718\n",
      "Epoch 00023: val_loss improved from 1.41107 to 1.39379, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/023-1.3938.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.6159 - acc: 0.4718 - val_loss: 1.3938 - val_acc: 0.5854\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5984 - acc: 0.4767\n",
      "Epoch 00024: val_loss improved from 1.39379 to 1.37207, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/024-1.3721.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.5983 - acc: 0.4767 - val_loss: 1.3721 - val_acc: 0.5945\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5768 - acc: 0.4859\n",
      "Epoch 00025: val_loss improved from 1.37207 to 1.35410, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/025-1.3541.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.5768 - acc: 0.4859 - val_loss: 1.3541 - val_acc: 0.6012\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5611 - acc: 0.4901\n",
      "Epoch 00026: val_loss improved from 1.35410 to 1.33776, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/026-1.3378.hdf5\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 1.5610 - acc: 0.4901 - val_loss: 1.3378 - val_acc: 0.6024\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5572 - acc: 0.4942\n",
      "Epoch 00027: val_loss improved from 1.33776 to 1.33014, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/027-1.3301.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.5572 - acc: 0.4942 - val_loss: 1.3301 - val_acc: 0.6096\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5433 - acc: 0.4970\n",
      "Epoch 00028: val_loss improved from 1.33014 to 1.31593, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/028-1.3159.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 1.5433 - acc: 0.4971 - val_loss: 1.3159 - val_acc: 0.6119\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5233 - acc: 0.5080\n",
      "Epoch 00029: val_loss improved from 1.31593 to 1.29569, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/029-1.2957.hdf5\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.5232 - acc: 0.5081 - val_loss: 1.2957 - val_acc: 0.6152\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5120 - acc: 0.5090\n",
      "Epoch 00030: val_loss improved from 1.29569 to 1.28333, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/030-1.2833.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.5121 - acc: 0.5089 - val_loss: 1.2833 - val_acc: 0.6219\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5014 - acc: 0.5135\n",
      "Epoch 00031: val_loss improved from 1.28333 to 1.27154, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/031-1.2715.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.5013 - acc: 0.5134 - val_loss: 1.2715 - val_acc: 0.6299\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4939 - acc: 0.5188\n",
      "Epoch 00032: val_loss improved from 1.27154 to 1.25882, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/032-1.2588.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 1.4939 - acc: 0.5187 - val_loss: 1.2588 - val_acc: 0.6310\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4838 - acc: 0.5206\n",
      "Epoch 00033: val_loss did not improve from 1.25882\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.4838 - acc: 0.5206 - val_loss: 1.2646 - val_acc: 0.6175\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4710 - acc: 0.5289\n",
      "Epoch 00034: val_loss improved from 1.25882 to 1.23183, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/034-1.2318.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.4710 - acc: 0.5289 - val_loss: 1.2318 - val_acc: 0.6362\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4563 - acc: 0.5269\n",
      "Epoch 00035: val_loss improved from 1.23183 to 1.22047, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/035-1.2205.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.4564 - acc: 0.5269 - val_loss: 1.2205 - val_acc: 0.6369\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4414 - acc: 0.5345\n",
      "Epoch 00036: val_loss improved from 1.22047 to 1.21339, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/036-1.2134.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.4414 - acc: 0.5345 - val_loss: 1.2134 - val_acc: 0.6417\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4349 - acc: 0.5405\n",
      "Epoch 00037: val_loss improved from 1.21339 to 1.20204, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/037-1.2020.hdf5\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.4353 - acc: 0.5404 - val_loss: 1.2020 - val_acc: 0.6399\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4271 - acc: 0.5386\n",
      "Epoch 00038: val_loss improved from 1.20204 to 1.19655, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/038-1.1966.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 1.4271 - acc: 0.5387 - val_loss: 1.1966 - val_acc: 0.6511\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4175 - acc: 0.5446\n",
      "Epoch 00039: val_loss improved from 1.19655 to 1.18130, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/039-1.1813.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.4175 - acc: 0.5447 - val_loss: 1.1813 - val_acc: 0.6473\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4088 - acc: 0.5507\n",
      "Epoch 00040: val_loss improved from 1.18130 to 1.16816, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/040-1.1682.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.4088 - acc: 0.5507 - val_loss: 1.1682 - val_acc: 0.6515\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4041 - acc: 0.5511\n",
      "Epoch 00041: val_loss improved from 1.16816 to 1.16119, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/041-1.1612.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 1.4041 - acc: 0.5511 - val_loss: 1.1612 - val_acc: 0.6555\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3977 - acc: 0.5492\n",
      "Epoch 00042: val_loss improved from 1.16119 to 1.15957, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/042-1.1596.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.3977 - acc: 0.5492 - val_loss: 1.1596 - val_acc: 0.6604\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3830 - acc: 0.5561\n",
      "Epoch 00043: val_loss improved from 1.15957 to 1.14625, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/043-1.1463.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.3829 - acc: 0.5561 - val_loss: 1.1463 - val_acc: 0.6597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3797 - acc: 0.5564\n",
      "Epoch 00044: val_loss improved from 1.14625 to 1.14433, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/044-1.1443.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.3797 - acc: 0.5564 - val_loss: 1.1443 - val_acc: 0.6555\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3706 - acc: 0.5610\n",
      "Epoch 00045: val_loss improved from 1.14433 to 1.13184, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/045-1.1318.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.3706 - acc: 0.5610 - val_loss: 1.1318 - val_acc: 0.6599\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3619 - acc: 0.5629\n",
      "Epoch 00046: val_loss improved from 1.13184 to 1.12756, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/046-1.1276.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.3619 - acc: 0.5629 - val_loss: 1.1276 - val_acc: 0.6634\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3522 - acc: 0.5667\n",
      "Epoch 00047: val_loss improved from 1.12756 to 1.11215, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/047-1.1121.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 1.3522 - acc: 0.5666 - val_loss: 1.1121 - val_acc: 0.6695\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3491 - acc: 0.5695\n",
      "Epoch 00048: val_loss improved from 1.11215 to 1.10891, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/048-1.1089.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.3491 - acc: 0.5695 - val_loss: 1.1089 - val_acc: 0.6683\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3392 - acc: 0.5712\n",
      "Epoch 00049: val_loss improved from 1.10891 to 1.09635, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/049-1.0964.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.3391 - acc: 0.5712 - val_loss: 1.0964 - val_acc: 0.6753\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3378 - acc: 0.5706\n",
      "Epoch 00050: val_loss improved from 1.09635 to 1.09190, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/050-1.0919.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 1.3377 - acc: 0.5706 - val_loss: 1.0919 - val_acc: 0.6769\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3354 - acc: 0.5738\n",
      "Epoch 00051: val_loss improved from 1.09190 to 1.08912, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/051-1.0891.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.3353 - acc: 0.5739 - val_loss: 1.0891 - val_acc: 0.6767\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3300 - acc: 0.5771\n",
      "Epoch 00052: val_loss improved from 1.08912 to 1.08236, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/052-1.0824.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.3300 - acc: 0.5771 - val_loss: 1.0824 - val_acc: 0.6765\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3183 - acc: 0.5759\n",
      "Epoch 00053: val_loss improved from 1.08236 to 1.07549, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/053-1.0755.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.3184 - acc: 0.5759 - val_loss: 1.0755 - val_acc: 0.6837\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3175 - acc: 0.5808\n",
      "Epoch 00054: val_loss improved from 1.07549 to 1.06985, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/054-1.0698.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.3175 - acc: 0.5808 - val_loss: 1.0698 - val_acc: 0.6816\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3061 - acc: 0.5852\n",
      "Epoch 00055: val_loss did not improve from 1.06985\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.3061 - acc: 0.5852 - val_loss: 1.0740 - val_acc: 0.6860\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3017 - acc: 0.5875\n",
      "Epoch 00056: val_loss improved from 1.06985 to 1.05420, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/056-1.0542.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.3017 - acc: 0.5875 - val_loss: 1.0542 - val_acc: 0.6921\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2989 - acc: 0.5858\n",
      "Epoch 00057: val_loss did not improve from 1.05420\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.2988 - acc: 0.5858 - val_loss: 1.0567 - val_acc: 0.6862\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2908 - acc: 0.5888\n",
      "Epoch 00058: val_loss improved from 1.05420 to 1.04443, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/058-1.0444.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.2907 - acc: 0.5889 - val_loss: 1.0444 - val_acc: 0.6867\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2761 - acc: 0.5930\n",
      "Epoch 00059: val_loss improved from 1.04443 to 1.04311, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/059-1.0431.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.2762 - acc: 0.5930 - val_loss: 1.0431 - val_acc: 0.6888\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2797 - acc: 0.5919\n",
      "Epoch 00060: val_loss improved from 1.04311 to 1.03332, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/060-1.0333.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.2798 - acc: 0.5919 - val_loss: 1.0333 - val_acc: 0.6965\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2769 - acc: 0.5916\n",
      "Epoch 00061: val_loss did not improve from 1.03332\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.2768 - acc: 0.5916 - val_loss: 1.0343 - val_acc: 0.6930\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2714 - acc: 0.5952\n",
      "Epoch 00062: val_loss improved from 1.03332 to 1.02794, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/062-1.0279.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 1.2714 - acc: 0.5952 - val_loss: 1.0279 - val_acc: 0.6951\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2674 - acc: 0.5953\n",
      "Epoch 00063: val_loss improved from 1.02794 to 1.01597, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/063-1.0160.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.2674 - acc: 0.5953 - val_loss: 1.0160 - val_acc: 0.6946\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2655 - acc: 0.5976\n",
      "Epoch 00064: val_loss did not improve from 1.01597\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.2655 - acc: 0.5976 - val_loss: 1.0195 - val_acc: 0.6983\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2615 - acc: 0.6021\n",
      "Epoch 00065: val_loss improved from 1.01597 to 1.01236, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/065-1.0124.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.2614 - acc: 0.6022 - val_loss: 1.0124 - val_acc: 0.7018\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2556 - acc: 0.5976\n",
      "Epoch 00066: val_loss improved from 1.01236 to 1.00869, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/066-1.0087.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.2556 - acc: 0.5976 - val_loss: 1.0087 - val_acc: 0.7053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2552 - acc: 0.6001\n",
      "Epoch 00067: val_loss improved from 1.00869 to 0.99824, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/067-0.9982.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.2552 - acc: 0.6001 - val_loss: 0.9982 - val_acc: 0.6988\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2472 - acc: 0.6052\n",
      "Epoch 00068: val_loss did not improve from 0.99824\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.2472 - acc: 0.6052 - val_loss: 1.0057 - val_acc: 0.7067\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2475 - acc: 0.6036\n",
      "Epoch 00069: val_loss improved from 0.99824 to 0.98733, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/069-0.9873.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.2476 - acc: 0.6036 - val_loss: 0.9873 - val_acc: 0.7084\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2441 - acc: 0.6064\n",
      "Epoch 00070: val_loss did not improve from 0.98733\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.2441 - acc: 0.6064 - val_loss: 0.9946 - val_acc: 0.7070\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2370 - acc: 0.6065\n",
      "Epoch 00071: val_loss did not improve from 0.98733\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.2370 - acc: 0.6065 - val_loss: 0.9932 - val_acc: 0.7025\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2339 - acc: 0.6113\n",
      "Epoch 00072: val_loss improved from 0.98733 to 0.97948, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/072-0.9795.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.2338 - acc: 0.6113 - val_loss: 0.9795 - val_acc: 0.7060\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2335 - acc: 0.6095\n",
      "Epoch 00073: val_loss improved from 0.97948 to 0.97819, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/073-0.9782.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 1.2337 - acc: 0.6094 - val_loss: 0.9782 - val_acc: 0.7093\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2279 - acc: 0.6091\n",
      "Epoch 00074: val_loss improved from 0.97819 to 0.96948, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/074-0.9695.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.2279 - acc: 0.6091 - val_loss: 0.9695 - val_acc: 0.7137\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2214 - acc: 0.6125\n",
      "Epoch 00075: val_loss improved from 0.96948 to 0.96748, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/075-0.9675.hdf5\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 1.2214 - acc: 0.6126 - val_loss: 0.9675 - val_acc: 0.7079\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2190 - acc: 0.6165\n",
      "Epoch 00076: val_loss improved from 0.96748 to 0.96117, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/076-0.9612.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.2189 - acc: 0.6165 - val_loss: 0.9612 - val_acc: 0.7154\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2141 - acc: 0.6161\n",
      "Epoch 00077: val_loss improved from 0.96117 to 0.95892, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/077-0.9589.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.2141 - acc: 0.6160 - val_loss: 0.9589 - val_acc: 0.7149\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2094 - acc: 0.6175\n",
      "Epoch 00078: val_loss improved from 0.95892 to 0.95847, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/078-0.9585.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.2093 - acc: 0.6175 - val_loss: 0.9585 - val_acc: 0.7174\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2146 - acc: 0.6165\n",
      "Epoch 00079: val_loss improved from 0.95847 to 0.94987, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/079-0.9499.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.2145 - acc: 0.6166 - val_loss: 0.9499 - val_acc: 0.7188\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2047 - acc: 0.6166\n",
      "Epoch 00080: val_loss improved from 0.94987 to 0.94834, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/080-0.9483.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 1.2047 - acc: 0.6166 - val_loss: 0.9483 - val_acc: 0.7170\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2085 - acc: 0.6216\n",
      "Epoch 00081: val_loss did not improve from 0.94834\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.2084 - acc: 0.6216 - val_loss: 0.9498 - val_acc: 0.7212\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1997 - acc: 0.6224\n",
      "Epoch 00082: val_loss improved from 0.94834 to 0.94667, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/082-0.9467.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.1997 - acc: 0.6224 - val_loss: 0.9467 - val_acc: 0.7163\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1944 - acc: 0.6230\n",
      "Epoch 00083: val_loss improved from 0.94667 to 0.94023, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/083-0.9402.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 1.1945 - acc: 0.6229 - val_loss: 0.9402 - val_acc: 0.7184\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1894 - acc: 0.6217\n",
      "Epoch 00084: val_loss did not improve from 0.94023\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.1894 - acc: 0.6218 - val_loss: 0.9421 - val_acc: 0.7167\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1963 - acc: 0.6230\n",
      "Epoch 00085: val_loss improved from 0.94023 to 0.93301, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/085-0.9330.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 1.1962 - acc: 0.6231 - val_loss: 0.9330 - val_acc: 0.7249\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1896 - acc: 0.6235\n",
      "Epoch 00086: val_loss did not improve from 0.93301\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.1896 - acc: 0.6235 - val_loss: 0.9332 - val_acc: 0.7256\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1822 - acc: 0.6278\n",
      "Epoch 00087: val_loss did not improve from 0.93301\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.1821 - acc: 0.6278 - val_loss: 0.9349 - val_acc: 0.7237\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1799 - acc: 0.6276\n",
      "Epoch 00088: val_loss did not improve from 0.93301\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.1799 - acc: 0.6277 - val_loss: 0.9340 - val_acc: 0.7195\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1791 - acc: 0.6281\n",
      "Epoch 00089: val_loss improved from 0.93301 to 0.92836, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/089-0.9284.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 1.1790 - acc: 0.6281 - val_loss: 0.9284 - val_acc: 0.7268\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1800 - acc: 0.6268\n",
      "Epoch 00090: val_loss improved from 0.92836 to 0.92209, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/090-0.9221.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 1.1801 - acc: 0.6268 - val_loss: 0.9221 - val_acc: 0.7277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1667 - acc: 0.6333\n",
      "Epoch 00091: val_loss improved from 0.92209 to 0.91373, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/091-0.9137.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.1667 - acc: 0.6333 - val_loss: 0.9137 - val_acc: 0.7293\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1739 - acc: 0.6285\n",
      "Epoch 00092: val_loss did not improve from 0.91373\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.1740 - acc: 0.6285 - val_loss: 0.9157 - val_acc: 0.7289\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1657 - acc: 0.6339\n",
      "Epoch 00093: val_loss did not improve from 0.91373\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.1657 - acc: 0.6339 - val_loss: 0.9229 - val_acc: 0.7284\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1586 - acc: 0.6354\n",
      "Epoch 00094: val_loss improved from 0.91373 to 0.91040, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/094-0.9104.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.1585 - acc: 0.6354 - val_loss: 0.9104 - val_acc: 0.7284\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1651 - acc: 0.6323\n",
      "Epoch 00095: val_loss improved from 0.91040 to 0.91022, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/095-0.9102.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 1.1651 - acc: 0.6323 - val_loss: 0.9102 - val_acc: 0.7328\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1565 - acc: 0.6354\n",
      "Epoch 00096: val_loss improved from 0.91022 to 0.90264, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/096-0.9026.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.1566 - acc: 0.6354 - val_loss: 0.9026 - val_acc: 0.7361\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1552 - acc: 0.6388\n",
      "Epoch 00097: val_loss did not improve from 0.90264\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.1552 - acc: 0.6387 - val_loss: 0.9035 - val_acc: 0.7365\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1527 - acc: 0.6402\n",
      "Epoch 00098: val_loss did not improve from 0.90264\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.1526 - acc: 0.6401 - val_loss: 0.9064 - val_acc: 0.7347\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1516 - acc: 0.6416\n",
      "Epoch 00099: val_loss improved from 0.90264 to 0.89327, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/099-0.8933.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.1515 - acc: 0.6416 - val_loss: 0.8933 - val_acc: 0.7342\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1498 - acc: 0.6411\n",
      "Epoch 00100: val_loss improved from 0.89327 to 0.89209, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/100-0.8921.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.1498 - acc: 0.6412 - val_loss: 0.8921 - val_acc: 0.7354\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1428 - acc: 0.6396\n",
      "Epoch 00101: val_loss did not improve from 0.89209\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.1427 - acc: 0.6396 - val_loss: 0.8927 - val_acc: 0.7382\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1435 - acc: 0.6436\n",
      "Epoch 00102: val_loss improved from 0.89209 to 0.88777, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/102-0.8878.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.1439 - acc: 0.6436 - val_loss: 0.8878 - val_acc: 0.7379\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1494 - acc: 0.6396\n",
      "Epoch 00103: val_loss did not improve from 0.88777\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.1494 - acc: 0.6396 - val_loss: 0.8879 - val_acc: 0.7377\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1332 - acc: 0.6466\n",
      "Epoch 00104: val_loss improved from 0.88777 to 0.87914, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/104-0.8791.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.1332 - acc: 0.6467 - val_loss: 0.8791 - val_acc: 0.7396\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1374 - acc: 0.6448\n",
      "Epoch 00105: val_loss did not improve from 0.87914\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.1373 - acc: 0.6448 - val_loss: 0.8850 - val_acc: 0.7349\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1414 - acc: 0.6424\n",
      "Epoch 00106: val_loss improved from 0.87914 to 0.87912, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/106-0.8791.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.1414 - acc: 0.6424 - val_loss: 0.8791 - val_acc: 0.7442\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1272 - acc: 0.6473\n",
      "Epoch 00107: val_loss improved from 0.87912 to 0.87346, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/107-0.8735.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.1271 - acc: 0.6474 - val_loss: 0.8735 - val_acc: 0.7447\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1369 - acc: 0.6475\n",
      "Epoch 00108: val_loss did not improve from 0.87346\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.1369 - acc: 0.6474 - val_loss: 0.8826 - val_acc: 0.7412\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1304 - acc: 0.6466\n",
      "Epoch 00109: val_loss improved from 0.87346 to 0.87232, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/109-0.8723.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.1303 - acc: 0.6467 - val_loss: 0.8723 - val_acc: 0.7452\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1241 - acc: 0.6516\n",
      "Epoch 00110: val_loss did not improve from 0.87232\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.1241 - acc: 0.6516 - val_loss: 0.8759 - val_acc: 0.7372\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1246 - acc: 0.6480\n",
      "Epoch 00111: val_loss improved from 0.87232 to 0.86669, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/111-0.8667.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 1.1246 - acc: 0.6480 - val_loss: 0.8667 - val_acc: 0.7452\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1215 - acc: 0.6490\n",
      "Epoch 00112: val_loss improved from 0.86669 to 0.86549, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/112-0.8655.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.1214 - acc: 0.6490 - val_loss: 0.8655 - val_acc: 0.7431\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1178 - acc: 0.6526\n",
      "Epoch 00113: val_loss did not improve from 0.86549\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 1.1179 - acc: 0.6526 - val_loss: 0.8736 - val_acc: 0.7405\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1209 - acc: 0.6496\n",
      "Epoch 00114: val_loss improved from 0.86549 to 0.86527, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/114-0.8653.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.1209 - acc: 0.6496 - val_loss: 0.8653 - val_acc: 0.7454\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1199 - acc: 0.6508\n",
      "Epoch 00115: val_loss improved from 0.86527 to 0.86516, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/115-0.8652.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.1200 - acc: 0.6508 - val_loss: 0.8652 - val_acc: 0.7452\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1102 - acc: 0.6536\n",
      "Epoch 00116: val_loss did not improve from 0.86516\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 1.1102 - acc: 0.6536 - val_loss: 0.8663 - val_acc: 0.7461\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1097 - acc: 0.6524\n",
      "Epoch 00117: val_loss improved from 0.86516 to 0.85123, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/117-0.8512.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.1096 - acc: 0.6524 - val_loss: 0.8512 - val_acc: 0.7501\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1103 - acc: 0.6546\n",
      "Epoch 00118: val_loss improved from 0.85123 to 0.84788, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/118-0.8479.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.1103 - acc: 0.6547 - val_loss: 0.8479 - val_acc: 0.7498\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1111 - acc: 0.6554\n",
      "Epoch 00119: val_loss did not improve from 0.84788\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.1111 - acc: 0.6555 - val_loss: 0.8607 - val_acc: 0.7452\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1041 - acc: 0.6549\n",
      "Epoch 00120: val_loss improved from 0.84788 to 0.84483, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/120-0.8448.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.1041 - acc: 0.6549 - val_loss: 0.8448 - val_acc: 0.7522\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1068 - acc: 0.6541\n",
      "Epoch 00121: val_loss did not improve from 0.84483\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 1.1069 - acc: 0.6540 - val_loss: 0.8509 - val_acc: 0.7470\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0991 - acc: 0.6569\n",
      "Epoch 00122: val_loss did not improve from 0.84483\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.0992 - acc: 0.6569 - val_loss: 0.8532 - val_acc: 0.7431\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1052 - acc: 0.6544\n",
      "Epoch 00123: val_loss improved from 0.84483 to 0.84400, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/123-0.8440.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.1052 - acc: 0.6544 - val_loss: 0.8440 - val_acc: 0.7512\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0915 - acc: 0.6604\n",
      "Epoch 00124: val_loss improved from 0.84400 to 0.84178, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/124-0.8418.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.0915 - acc: 0.6604 - val_loss: 0.8418 - val_acc: 0.7522\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1048 - acc: 0.6579\n",
      "Epoch 00125: val_loss did not improve from 0.84178\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.1048 - acc: 0.6579 - val_loss: 0.8457 - val_acc: 0.7515\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0977 - acc: 0.6590\n",
      "Epoch 00126: val_loss did not improve from 0.84178\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.0976 - acc: 0.6590 - val_loss: 0.8562 - val_acc: 0.7431\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1026 - acc: 0.6574\n",
      "Epoch 00127: val_loss did not improve from 0.84178\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1026 - acc: 0.6574 - val_loss: 0.8471 - val_acc: 0.7517\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0962 - acc: 0.6602\n",
      "Epoch 00128: val_loss improved from 0.84178 to 0.83761, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/128-0.8376.hdf5\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 1.0963 - acc: 0.6601 - val_loss: 0.8376 - val_acc: 0.7531\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0890 - acc: 0.6619\n",
      "Epoch 00129: val_loss did not improve from 0.83761\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.0891 - acc: 0.6619 - val_loss: 0.8431 - val_acc: 0.7531\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0937 - acc: 0.6613\n",
      "Epoch 00130: val_loss improved from 0.83761 to 0.83071, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/130-0.8307.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.0937 - acc: 0.6613 - val_loss: 0.8307 - val_acc: 0.7556\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0885 - acc: 0.6610\n",
      "Epoch 00131: val_loss did not improve from 0.83071\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.0884 - acc: 0.6610 - val_loss: 0.8329 - val_acc: 0.7556\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0862 - acc: 0.6629\n",
      "Epoch 00132: val_loss did not improve from 0.83071\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 1.0861 - acc: 0.6629 - val_loss: 0.8327 - val_acc: 0.7556\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0853 - acc: 0.6639\n",
      "Epoch 00133: val_loss did not improve from 0.83071\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.0852 - acc: 0.6639 - val_loss: 0.8308 - val_acc: 0.7570\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0773 - acc: 0.6641\n",
      "Epoch 00134: val_loss improved from 0.83071 to 0.82439, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/134-0.8244.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.0772 - acc: 0.6641 - val_loss: 0.8244 - val_acc: 0.7540\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0817 - acc: 0.6655\n",
      "Epoch 00135: val_loss did not improve from 0.82439\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.0818 - acc: 0.6655 - val_loss: 0.8295 - val_acc: 0.7547\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0876 - acc: 0.6616\n",
      "Epoch 00136: val_loss did not improve from 0.82439\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.0876 - acc: 0.6616 - val_loss: 0.8249 - val_acc: 0.7582\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0719 - acc: 0.6655\n",
      "Epoch 00137: val_loss did not improve from 0.82439\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 1.0718 - acc: 0.6656 - val_loss: 0.8330 - val_acc: 0.7519\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0751 - acc: 0.6677\n",
      "Epoch 00138: val_loss did not improve from 0.82439\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0751 - acc: 0.6677 - val_loss: 0.8291 - val_acc: 0.7575\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0795 - acc: 0.6637\n",
      "Epoch 00139: val_loss improved from 0.82439 to 0.81713, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/139-0.8171.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0794 - acc: 0.6637 - val_loss: 0.8171 - val_acc: 0.7608\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0765 - acc: 0.6649\n",
      "Epoch 00140: val_loss improved from 0.81713 to 0.81435, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/140-0.8143.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 1.0765 - acc: 0.6649 - val_loss: 0.8143 - val_acc: 0.7598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0750 - acc: 0.6653\n",
      "Epoch 00141: val_loss did not improve from 0.81435\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0748 - acc: 0.6654 - val_loss: 0.8146 - val_acc: 0.7584\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0697 - acc: 0.6660\n",
      "Epoch 00142: val_loss did not improve from 0.81435\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0697 - acc: 0.6660 - val_loss: 0.8171 - val_acc: 0.7624\n",
      "Epoch 143/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.0730 - acc: 0.6660\n",
      "Epoch 00143: val_loss did not improve from 0.81435\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0731 - acc: 0.6660 - val_loss: 0.8185 - val_acc: 0.7584\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0677 - acc: 0.6650\n",
      "Epoch 00144: val_loss did not improve from 0.81435\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0677 - acc: 0.6650 - val_loss: 0.8241 - val_acc: 0.7577\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0640 - acc: 0.6716\n",
      "Epoch 00145: val_loss improved from 0.81435 to 0.81263, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/145-0.8126.hdf5\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 1.0640 - acc: 0.6716 - val_loss: 0.8126 - val_acc: 0.7608\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0594 - acc: 0.6712\n",
      "Epoch 00146: val_loss did not improve from 0.81263\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 1.0593 - acc: 0.6712 - val_loss: 0.8155 - val_acc: 0.7608\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0633 - acc: 0.6671\n",
      "Epoch 00147: val_loss improved from 0.81263 to 0.81139, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/147-0.8114.hdf5\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 1.0633 - acc: 0.6672 - val_loss: 0.8114 - val_acc: 0.7622\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0661 - acc: 0.6684\n",
      "Epoch 00148: val_loss did not improve from 0.81139\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.0662 - acc: 0.6684 - val_loss: 0.8119 - val_acc: 0.7626\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0638 - acc: 0.6709\n",
      "Epoch 00149: val_loss improved from 0.81139 to 0.81045, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/149-0.8105.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.0638 - acc: 0.6709 - val_loss: 0.8105 - val_acc: 0.7608\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0612 - acc: 0.6712\n",
      "Epoch 00150: val_loss improved from 0.81045 to 0.80509, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/150-0.8051.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.0611 - acc: 0.6712 - val_loss: 0.8051 - val_acc: 0.7652\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0592 - acc: 0.6724\n",
      "Epoch 00151: val_loss did not improve from 0.80509\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.0592 - acc: 0.6724 - val_loss: 0.8064 - val_acc: 0.7605\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0597 - acc: 0.6690\n",
      "Epoch 00152: val_loss did not improve from 0.80509\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.0599 - acc: 0.6689 - val_loss: 0.8102 - val_acc: 0.7615\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0588 - acc: 0.6721\n",
      "Epoch 00153: val_loss improved from 0.80509 to 0.79672, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/153-0.7967.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.0587 - acc: 0.6722 - val_loss: 0.7967 - val_acc: 0.7673\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0531 - acc: 0.6727\n",
      "Epoch 00154: val_loss did not improve from 0.79672\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.0531 - acc: 0.6727 - val_loss: 0.8125 - val_acc: 0.7577\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0574 - acc: 0.6745\n",
      "Epoch 00155: val_loss did not improve from 0.79672\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.0574 - acc: 0.6744 - val_loss: 0.8179 - val_acc: 0.7596\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0501 - acc: 0.6737\n",
      "Epoch 00156: val_loss improved from 0.79672 to 0.79428, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/156-0.7943.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.0501 - acc: 0.6737 - val_loss: 0.7943 - val_acc: 0.7668\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0474 - acc: 0.6749\n",
      "Epoch 00157: val_loss did not improve from 0.79428\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.0474 - acc: 0.6749 - val_loss: 0.7948 - val_acc: 0.7664\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0471 - acc: 0.6744\n",
      "Epoch 00158: val_loss did not improve from 0.79428\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.0471 - acc: 0.6744 - val_loss: 0.8068 - val_acc: 0.7678\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0440 - acc: 0.6744\n",
      "Epoch 00159: val_loss improved from 0.79428 to 0.79352, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/159-0.7935.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.0439 - acc: 0.6744 - val_loss: 0.7935 - val_acc: 0.7671\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0444 - acc: 0.6763\n",
      "Epoch 00160: val_loss improved from 0.79352 to 0.79187, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/160-0.7919.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.0444 - acc: 0.6763 - val_loss: 0.7919 - val_acc: 0.7668\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0482 - acc: 0.6764\n",
      "Epoch 00161: val_loss did not improve from 0.79187\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.0482 - acc: 0.6764 - val_loss: 0.7942 - val_acc: 0.7673\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0382 - acc: 0.6763\n",
      "Epoch 00162: val_loss did not improve from 0.79187\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.0382 - acc: 0.6763 - val_loss: 0.7943 - val_acc: 0.7675\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0473 - acc: 0.6740\n",
      "Epoch 00163: val_loss did not improve from 0.79187\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.0474 - acc: 0.6739 - val_loss: 0.7935 - val_acc: 0.7680\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0476 - acc: 0.6747\n",
      "Epoch 00164: val_loss improved from 0.79187 to 0.78667, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/164-0.7867.hdf5\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 1.0476 - acc: 0.6747 - val_loss: 0.7867 - val_acc: 0.7713\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0420 - acc: 0.6759\n",
      "Epoch 00165: val_loss did not improve from 0.78667\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 1.0421 - acc: 0.6759 - val_loss: 0.7925 - val_acc: 0.7694\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0413 - acc: 0.6772\n",
      "Epoch 00166: val_loss did not improve from 0.78667\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 1.0413 - acc: 0.6772 - val_loss: 0.7896 - val_acc: 0.7722\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0394 - acc: 0.6788\n",
      "Epoch 00167: val_loss did not improve from 0.78667\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.0393 - acc: 0.6788 - val_loss: 0.7873 - val_acc: 0.7692\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0347 - acc: 0.6782\n",
      "Epoch 00168: val_loss improved from 0.78667 to 0.78356, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/168-0.7836.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.0347 - acc: 0.6783 - val_loss: 0.7836 - val_acc: 0.7689\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0411 - acc: 0.6784\n",
      "Epoch 00169: val_loss did not improve from 0.78356\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.0412 - acc: 0.6784 - val_loss: 0.7937 - val_acc: 0.7673\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0459 - acc: 0.6758\n",
      "Epoch 00170: val_loss improved from 0.78356 to 0.77791, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/170-0.7779.hdf5\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.0459 - acc: 0.6758 - val_loss: 0.7779 - val_acc: 0.7713\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0352 - acc: 0.6807\n",
      "Epoch 00171: val_loss did not improve from 0.77791\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 1.0352 - acc: 0.6807 - val_loss: 0.7835 - val_acc: 0.7699\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0402 - acc: 0.6758\n",
      "Epoch 00172: val_loss did not improve from 0.77791\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.0402 - acc: 0.6758 - val_loss: 0.7864 - val_acc: 0.7701\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0323 - acc: 0.6817\n",
      "Epoch 00173: val_loss improved from 0.77791 to 0.77664, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/173-0.7766.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.0324 - acc: 0.6817 - val_loss: 0.7766 - val_acc: 0.7701\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0393 - acc: 0.6787\n",
      "Epoch 00174: val_loss did not improve from 0.77664\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.0393 - acc: 0.6787 - val_loss: 0.7951 - val_acc: 0.7654\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0313 - acc: 0.6804\n",
      "Epoch 00175: val_loss improved from 0.77664 to 0.77470, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/175-0.7747.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.0313 - acc: 0.6804 - val_loss: 0.7747 - val_acc: 0.7741\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0366 - acc: 0.6780\n",
      "Epoch 00176: val_loss did not improve from 0.77470\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.0366 - acc: 0.6780 - val_loss: 0.7783 - val_acc: 0.7692\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0343 - acc: 0.6786\n",
      "Epoch 00177: val_loss did not improve from 0.77470\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 1.0343 - acc: 0.6786 - val_loss: 0.7806 - val_acc: 0.7713\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0297 - acc: 0.6806\n",
      "Epoch 00178: val_loss did not improve from 0.77470\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.0296 - acc: 0.6806 - val_loss: 0.7776 - val_acc: 0.7752\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0237 - acc: 0.6815\n",
      "Epoch 00179: val_loss improved from 0.77470 to 0.77240, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/179-0.7724.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.0238 - acc: 0.6815 - val_loss: 0.7724 - val_acc: 0.7720\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0242 - acc: 0.6799\n",
      "Epoch 00180: val_loss improved from 0.77240 to 0.76893, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/180-0.7689.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.0242 - acc: 0.6800 - val_loss: 0.7689 - val_acc: 0.7736\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0224 - acc: 0.6825\n",
      "Epoch 00181: val_loss did not improve from 0.76893\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 1.0224 - acc: 0.6825 - val_loss: 0.7704 - val_acc: 0.7768\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0255 - acc: 0.6814\n",
      "Epoch 00182: val_loss improved from 0.76893 to 0.76673, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/182-0.7667.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.0256 - acc: 0.6814 - val_loss: 0.7667 - val_acc: 0.7761\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0213 - acc: 0.6867\n",
      "Epoch 00183: val_loss did not improve from 0.76673\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 1.0214 - acc: 0.6866 - val_loss: 0.7740 - val_acc: 0.7741\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0231 - acc: 0.6844\n",
      "Epoch 00184: val_loss did not improve from 0.76673\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 1.0231 - acc: 0.6844 - val_loss: 0.7710 - val_acc: 0.7759\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0171 - acc: 0.6886\n",
      "Epoch 00185: val_loss improved from 0.76673 to 0.76106, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/185-0.7611.hdf5\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 1.0172 - acc: 0.6885 - val_loss: 0.7611 - val_acc: 0.7768\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0235 - acc: 0.6847\n",
      "Epoch 00186: val_loss did not improve from 0.76106\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 1.0235 - acc: 0.6847 - val_loss: 0.7698 - val_acc: 0.7745\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0114 - acc: 0.6862\n",
      "Epoch 00187: val_loss did not improve from 0.76106\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 1.0114 - acc: 0.6862 - val_loss: 0.7630 - val_acc: 0.7757\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0253 - acc: 0.6845\n",
      "Epoch 00188: val_loss did not improve from 0.76106\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 1.0254 - acc: 0.6844 - val_loss: 0.7808 - val_acc: 0.7727\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0160 - acc: 0.6850\n",
      "Epoch 00189: val_loss did not improve from 0.76106\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 1.0159 - acc: 0.6850 - val_loss: 0.7683 - val_acc: 0.7747\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0117 - acc: 0.6873\n",
      "Epoch 00190: val_loss improved from 0.76106 to 0.76062, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/190-0.7606.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 1.0119 - acc: 0.6872 - val_loss: 0.7606 - val_acc: 0.7731\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0130 - acc: 0.6855\n",
      "Epoch 00191: val_loss did not improve from 0.76062\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 1.0131 - acc: 0.6855 - val_loss: 0.7634 - val_acc: 0.7743\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0145 - acc: 0.6865\n",
      "Epoch 00192: val_loss did not improve from 0.76062\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.0144 - acc: 0.6866 - val_loss: 0.7611 - val_acc: 0.7768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0123 - acc: 0.6879\n",
      "Epoch 00193: val_loss did not improve from 0.76062\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 1.0123 - acc: 0.6879 - val_loss: 0.7628 - val_acc: 0.7768\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0183 - acc: 0.6865\n",
      "Epoch 00194: val_loss did not improve from 0.76062\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 1.0183 - acc: 0.6866 - val_loss: 0.7608 - val_acc: 0.7780\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0104 - acc: 0.6852\n",
      "Epoch 00195: val_loss improved from 0.76062 to 0.75684, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/195-0.7568.hdf5\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 1.0104 - acc: 0.6852 - val_loss: 0.7568 - val_acc: 0.7778\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0072 - acc: 0.6874\n",
      "Epoch 00196: val_loss did not improve from 0.75684\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 1.0072 - acc: 0.6874 - val_loss: 0.7642 - val_acc: 0.7761\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0055 - acc: 0.6924\n",
      "Epoch 00197: val_loss improved from 0.75684 to 0.75549, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/197-0.7555.hdf5\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.0055 - acc: 0.6925 - val_loss: 0.7555 - val_acc: 0.7808\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0046 - acc: 0.6893\n",
      "Epoch 00198: val_loss did not improve from 0.75549\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 1.0047 - acc: 0.6892 - val_loss: 0.7610 - val_acc: 0.7757\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0127 - acc: 0.6843\n",
      "Epoch 00199: val_loss did not improve from 0.75549\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 1.0127 - acc: 0.6842 - val_loss: 0.7580 - val_acc: 0.7799\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0098 - acc: 0.6874\n",
      "Epoch 00200: val_loss did not improve from 0.75549\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0098 - acc: 0.6874 - val_loss: 0.7587 - val_acc: 0.7778\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0117 - acc: 0.6863\n",
      "Epoch 00201: val_loss improved from 0.75549 to 0.75517, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/201-0.7552.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 1.0118 - acc: 0.6863 - val_loss: 0.7552 - val_acc: 0.7764\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0048 - acc: 0.6901\n",
      "Epoch 00202: val_loss did not improve from 0.75517\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 1.0049 - acc: 0.6901 - val_loss: 0.7663 - val_acc: 0.7731\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0143 - acc: 0.6870\n",
      "Epoch 00203: val_loss did not improve from 0.75517\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 1.0146 - acc: 0.6870 - val_loss: 0.7568 - val_acc: 0.7754\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0022 - acc: 0.6875\n",
      "Epoch 00204: val_loss improved from 0.75517 to 0.75439, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/204-0.7544.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.0021 - acc: 0.6875 - val_loss: 0.7544 - val_acc: 0.7801\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9994 - acc: 0.6913\n",
      "Epoch 00205: val_loss did not improve from 0.75439\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9995 - acc: 0.6913 - val_loss: 0.7601 - val_acc: 0.7761\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0051 - acc: 0.6897\n",
      "Epoch 00206: val_loss did not improve from 0.75439\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 1.0051 - acc: 0.6897 - val_loss: 0.7638 - val_acc: 0.7754\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0019 - acc: 0.6883\n",
      "Epoch 00207: val_loss improved from 0.75439 to 0.75280, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/207-0.7528.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.0019 - acc: 0.6883 - val_loss: 0.7528 - val_acc: 0.7778\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0071 - acc: 0.6890\n",
      "Epoch 00208: val_loss improved from 0.75280 to 0.74938, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/208-0.7494.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.0070 - acc: 0.6891 - val_loss: 0.7494 - val_acc: 0.7780\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0027 - acc: 0.6892\n",
      "Epoch 00209: val_loss did not improve from 0.74938\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 1.0031 - acc: 0.6892 - val_loss: 0.7534 - val_acc: 0.7782\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0016 - acc: 0.6912\n",
      "Epoch 00210: val_loss did not improve from 0.74938\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 1.0015 - acc: 0.6912 - val_loss: 0.7528 - val_acc: 0.7785\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9915 - acc: 0.6937\n",
      "Epoch 00211: val_loss did not improve from 0.74938\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.9916 - acc: 0.6937 - val_loss: 0.7558 - val_acc: 0.7759\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9981 - acc: 0.6911\n",
      "Epoch 00212: val_loss improved from 0.74938 to 0.74187, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/212-0.7419.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9980 - acc: 0.6912 - val_loss: 0.7419 - val_acc: 0.7834\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9948 - acc: 0.6934\n",
      "Epoch 00213: val_loss did not improve from 0.74187\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.9947 - acc: 0.6934 - val_loss: 0.7483 - val_acc: 0.7831\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9980 - acc: 0.6910\n",
      "Epoch 00214: val_loss improved from 0.74187 to 0.73947, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/214-0.7395.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9980 - acc: 0.6910 - val_loss: 0.7395 - val_acc: 0.7829\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9872 - acc: 0.6946\n",
      "Epoch 00215: val_loss did not improve from 0.73947\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.9871 - acc: 0.6946 - val_loss: 0.7493 - val_acc: 0.7785\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9957 - acc: 0.6938\n",
      "Epoch 00216: val_loss did not improve from 0.73947\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.9956 - acc: 0.6938 - val_loss: 0.7578 - val_acc: 0.7782\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9893 - acc: 0.6931\n",
      "Epoch 00217: val_loss did not improve from 0.73947\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9893 - acc: 0.6930 - val_loss: 0.7430 - val_acc: 0.7820\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9948 - acc: 0.6936\n",
      "Epoch 00218: val_loss did not improve from 0.73947\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.9947 - acc: 0.6936 - val_loss: 0.7463 - val_acc: 0.7815\n",
      "Epoch 219/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9848 - acc: 0.6966\n",
      "Epoch 00219: val_loss did not improve from 0.73947\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9844 - acc: 0.6967 - val_loss: 0.7486 - val_acc: 0.7785\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9882 - acc: 0.6960\n",
      "Epoch 00220: val_loss did not improve from 0.73947\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.9882 - acc: 0.6960 - val_loss: 0.7526 - val_acc: 0.7773\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9887 - acc: 0.6931\n",
      "Epoch 00221: val_loss improved from 0.73947 to 0.73674, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/221-0.7367.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9886 - acc: 0.6932 - val_loss: 0.7367 - val_acc: 0.7831\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9912 - acc: 0.6944\n",
      "Epoch 00222: val_loss did not improve from 0.73674\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.9912 - acc: 0.6944 - val_loss: 0.7442 - val_acc: 0.7778\n",
      "Epoch 223/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9830 - acc: 0.6965\n",
      "Epoch 00223: val_loss did not improve from 0.73674\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9831 - acc: 0.6965 - val_loss: 0.7438 - val_acc: 0.7836\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9854 - acc: 0.6940\n",
      "Epoch 00224: val_loss did not improve from 0.73674\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9854 - acc: 0.6940 - val_loss: 0.7410 - val_acc: 0.7808\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9861 - acc: 0.6955\n",
      "Epoch 00225: val_loss did not improve from 0.73674\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9862 - acc: 0.6955 - val_loss: 0.7412 - val_acc: 0.7817\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9949 - acc: 0.6918\n",
      "Epoch 00226: val_loss did not improve from 0.73674\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.9949 - acc: 0.6918 - val_loss: 0.7513 - val_acc: 0.7838\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9852 - acc: 0.6957\n",
      "Epoch 00227: val_loss improved from 0.73674 to 0.73094, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/227-0.7309.hdf5\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9851 - acc: 0.6957 - val_loss: 0.7309 - val_acc: 0.7831\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9883 - acc: 0.6955\n",
      "Epoch 00228: val_loss did not improve from 0.73094\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.9883 - acc: 0.6954 - val_loss: 0.7428 - val_acc: 0.7841\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9898 - acc: 0.6953\n",
      "Epoch 00229: val_loss did not improve from 0.73094\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.9897 - acc: 0.6953 - val_loss: 0.7435 - val_acc: 0.7780\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9836 - acc: 0.6979\n",
      "Epoch 00230: val_loss did not improve from 0.73094\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.9836 - acc: 0.6979 - val_loss: 0.7330 - val_acc: 0.7845\n",
      "Epoch 231/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9784 - acc: 0.6989\n",
      "Epoch 00231: val_loss did not improve from 0.73094\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.9784 - acc: 0.6989 - val_loss: 0.7398 - val_acc: 0.7820\n",
      "Epoch 232/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9728 - acc: 0.6960\n",
      "Epoch 00232: val_loss did not improve from 0.73094\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.9727 - acc: 0.6960 - val_loss: 0.7414 - val_acc: 0.7845\n",
      "Epoch 233/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9810 - acc: 0.6973\n",
      "Epoch 00233: val_loss did not improve from 0.73094\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9811 - acc: 0.6973 - val_loss: 0.7358 - val_acc: 0.7836\n",
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9785 - acc: 0.6986\n",
      "Epoch 00234: val_loss did not improve from 0.73094\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9786 - acc: 0.6986 - val_loss: 0.7333 - val_acc: 0.7859\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9797 - acc: 0.6988\n",
      "Epoch 00235: val_loss improved from 0.73094 to 0.72783, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/235-0.7278.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9797 - acc: 0.6988 - val_loss: 0.7278 - val_acc: 0.7883\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9794 - acc: 0.6971\n",
      "Epoch 00236: val_loss did not improve from 0.72783\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9795 - acc: 0.6971 - val_loss: 0.7318 - val_acc: 0.7836\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9767 - acc: 0.6995\n",
      "Epoch 00237: val_loss improved from 0.72783 to 0.72713, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/237-0.7271.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9767 - acc: 0.6995 - val_loss: 0.7271 - val_acc: 0.7862\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9838 - acc: 0.6969\n",
      "Epoch 00238: val_loss did not improve from 0.72713\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.9839 - acc: 0.6969 - val_loss: 0.7300 - val_acc: 0.7848\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9768 - acc: 0.6951\n",
      "Epoch 00239: val_loss did not improve from 0.72713\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9768 - acc: 0.6950 - val_loss: 0.7335 - val_acc: 0.7836\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9798 - acc: 0.6985\n",
      "Epoch 00240: val_loss improved from 0.72713 to 0.72542, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/240-0.7254.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9798 - acc: 0.6985 - val_loss: 0.7254 - val_acc: 0.7890\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9753 - acc: 0.6984\n",
      "Epoch 00241: val_loss did not improve from 0.72542\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9753 - acc: 0.6984 - val_loss: 0.7313 - val_acc: 0.7862\n",
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9770 - acc: 0.6996\n",
      "Epoch 00242: val_loss improved from 0.72542 to 0.72247, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/242-0.7225.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9769 - acc: 0.6996 - val_loss: 0.7225 - val_acc: 0.7843\n",
      "Epoch 243/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9733 - acc: 0.7005\n",
      "Epoch 00243: val_loss improved from 0.72247 to 0.72019, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/243-0.7202.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9733 - acc: 0.7005 - val_loss: 0.7202 - val_acc: 0.7869\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9702 - acc: 0.7032\n",
      "Epoch 00244: val_loss did not improve from 0.72019\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9702 - acc: 0.7032 - val_loss: 0.7234 - val_acc: 0.7864\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9710 - acc: 0.6981\n",
      "Epoch 00245: val_loss did not improve from 0.72019\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.9711 - acc: 0.6981 - val_loss: 0.7237 - val_acc: 0.7885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9703 - acc: 0.7011\n",
      "Epoch 00246: val_loss did not improve from 0.72019\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9703 - acc: 0.7011 - val_loss: 0.7257 - val_acc: 0.7892\n",
      "Epoch 247/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9768 - acc: 0.6988\n",
      "Epoch 00247: val_loss did not improve from 0.72019\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.9769 - acc: 0.6987 - val_loss: 0.7305 - val_acc: 0.7892\n",
      "Epoch 248/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9733 - acc: 0.6988\n",
      "Epoch 00248: val_loss improved from 0.72019 to 0.71819, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/248-0.7182.hdf5\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.9734 - acc: 0.6987 - val_loss: 0.7182 - val_acc: 0.7890\n",
      "Epoch 249/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9623 - acc: 0.7027\n",
      "Epoch 00249: val_loss did not improve from 0.71819\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9622 - acc: 0.7028 - val_loss: 0.7298 - val_acc: 0.7883\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9759 - acc: 0.6979\n",
      "Epoch 00250: val_loss did not improve from 0.71819\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.9759 - acc: 0.6979 - val_loss: 0.7270 - val_acc: 0.7855\n",
      "Epoch 251/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9718 - acc: 0.7016\n",
      "Epoch 00251: val_loss did not improve from 0.71819\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9721 - acc: 0.7015 - val_loss: 0.7382 - val_acc: 0.7906\n",
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9704 - acc: 0.7009\n",
      "Epoch 00252: val_loss did not improve from 0.71819\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9705 - acc: 0.7008 - val_loss: 0.7237 - val_acc: 0.7880\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9638 - acc: 0.7002\n",
      "Epoch 00253: val_loss improved from 0.71819 to 0.71604, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/253-0.7160.hdf5\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.9637 - acc: 0.7002 - val_loss: 0.7160 - val_acc: 0.7913\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9660 - acc: 0.7015\n",
      "Epoch 00254: val_loss did not improve from 0.71604\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.9660 - acc: 0.7016 - val_loss: 0.7178 - val_acc: 0.7897\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9651 - acc: 0.6978\n",
      "Epoch 00255: val_loss improved from 0.71604 to 0.71514, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/255-0.7151.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9651 - acc: 0.6978 - val_loss: 0.7151 - val_acc: 0.7908\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9677 - acc: 0.7014\n",
      "Epoch 00256: val_loss did not improve from 0.71514\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9676 - acc: 0.7014 - val_loss: 0.7238 - val_acc: 0.7885\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9666 - acc: 0.7027\n",
      "Epoch 00257: val_loss improved from 0.71514 to 0.71445, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/257-0.7144.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.9666 - acc: 0.7026 - val_loss: 0.7144 - val_acc: 0.7876\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9666 - acc: 0.7023\n",
      "Epoch 00258: val_loss did not improve from 0.71445\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9666 - acc: 0.7023 - val_loss: 0.7207 - val_acc: 0.7904\n",
      "Epoch 259/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9604 - acc: 0.7031\n",
      "Epoch 00259: val_loss did not improve from 0.71445\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.9605 - acc: 0.7030 - val_loss: 0.7159 - val_acc: 0.7899\n",
      "Epoch 260/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9574 - acc: 0.7050\n",
      "Epoch 00260: val_loss improved from 0.71445 to 0.71041, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/260-0.7104.hdf5\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.9575 - acc: 0.7050 - val_loss: 0.7104 - val_acc: 0.7913\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9651 - acc: 0.7031\n",
      "Epoch 00261: val_loss did not improve from 0.71041\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9650 - acc: 0.7031 - val_loss: 0.7163 - val_acc: 0.7915\n",
      "Epoch 262/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9683 - acc: 0.7020\n",
      "Epoch 00262: val_loss did not improve from 0.71041\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9684 - acc: 0.7019 - val_loss: 0.7164 - val_acc: 0.7904\n",
      "Epoch 263/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9597 - acc: 0.7038\n",
      "Epoch 00263: val_loss improved from 0.71041 to 0.71025, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/263-0.7102.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9598 - acc: 0.7038 - val_loss: 0.7102 - val_acc: 0.7918\n",
      "Epoch 264/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9559 - acc: 0.7041\n",
      "Epoch 00264: val_loss did not improve from 0.71025\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9558 - acc: 0.7041 - val_loss: 0.7205 - val_acc: 0.7918\n",
      "Epoch 265/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9624 - acc: 0.7034\n",
      "Epoch 00265: val_loss did not improve from 0.71025\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.9625 - acc: 0.7034 - val_loss: 0.7149 - val_acc: 0.7957\n",
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9599 - acc: 0.7059\n",
      "Epoch 00266: val_loss did not improve from 0.71025\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9600 - acc: 0.7058 - val_loss: 0.7128 - val_acc: 0.7890\n",
      "Epoch 267/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9557 - acc: 0.7073\n",
      "Epoch 00267: val_loss did not improve from 0.71025\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9557 - acc: 0.7073 - val_loss: 0.7145 - val_acc: 0.7941\n",
      "Epoch 268/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9542 - acc: 0.7037\n",
      "Epoch 00268: val_loss improved from 0.71025 to 0.70634, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/268-0.7063.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9542 - acc: 0.7037 - val_loss: 0.7063 - val_acc: 0.7922\n",
      "Epoch 269/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9595 - acc: 0.7048\n",
      "Epoch 00269: val_loss did not improve from 0.70634\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.9597 - acc: 0.7048 - val_loss: 0.7275 - val_acc: 0.7873\n",
      "Epoch 270/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9524 - acc: 0.7064\n",
      "Epoch 00270: val_loss did not improve from 0.70634\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9525 - acc: 0.7063 - val_loss: 0.7078 - val_acc: 0.7983\n",
      "Epoch 271/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9554 - acc: 0.7060\n",
      "Epoch 00271: val_loss did not improve from 0.70634\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9554 - acc: 0.7060 - val_loss: 0.7079 - val_acc: 0.7890\n",
      "Epoch 272/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9521 - acc: 0.7065\n",
      "Epoch 00272: val_loss improved from 0.70634 to 0.70515, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/272-0.7052.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9520 - acc: 0.7065 - val_loss: 0.7052 - val_acc: 0.7959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9611 - acc: 0.7033\n",
      "Epoch 00273: val_loss did not improve from 0.70515\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9614 - acc: 0.7033 - val_loss: 0.7116 - val_acc: 0.7955\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9625 - acc: 0.7030\n",
      "Epoch 00274: val_loss did not improve from 0.70515\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.9625 - acc: 0.7029 - val_loss: 0.7163 - val_acc: 0.7939\n",
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9484 - acc: 0.7059\n",
      "Epoch 00275: val_loss improved from 0.70515 to 0.70123, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/275-0.7012.hdf5\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.9484 - acc: 0.7059 - val_loss: 0.7012 - val_acc: 0.7952\n",
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9509 - acc: 0.7078\n",
      "Epoch 00276: val_loss did not improve from 0.70123\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.9509 - acc: 0.7078 - val_loss: 0.7121 - val_acc: 0.7964\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9546 - acc: 0.7059\n",
      "Epoch 00277: val_loss did not improve from 0.70123\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.9545 - acc: 0.7059 - val_loss: 0.7094 - val_acc: 0.7950\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9468 - acc: 0.7076\n",
      "Epoch 00278: val_loss did not improve from 0.70123\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.9468 - acc: 0.7076 - val_loss: 0.7094 - val_acc: 0.7945\n",
      "Epoch 279/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9536 - acc: 0.7061\n",
      "Epoch 00279: val_loss did not improve from 0.70123\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.9535 - acc: 0.7062 - val_loss: 0.7123 - val_acc: 0.7950\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9523 - acc: 0.7068\n",
      "Epoch 00280: val_loss did not improve from 0.70123\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.9523 - acc: 0.7068 - val_loss: 0.7016 - val_acc: 0.7936\n",
      "Epoch 281/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9550 - acc: 0.7039\n",
      "Epoch 00281: val_loss did not improve from 0.70123\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.9552 - acc: 0.7039 - val_loss: 0.7028 - val_acc: 0.7927\n",
      "Epoch 282/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9513 - acc: 0.7076\n",
      "Epoch 00282: val_loss did not improve from 0.70123\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.9513 - acc: 0.7076 - val_loss: 0.7019 - val_acc: 0.7969\n",
      "Epoch 283/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9509 - acc: 0.7050\n",
      "Epoch 00283: val_loss did not improve from 0.70123\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9509 - acc: 0.7050 - val_loss: 0.7197 - val_acc: 0.7890\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9510 - acc: 0.7048\n",
      "Epoch 00284: val_loss improved from 0.70123 to 0.70071, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/284-0.7007.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.9514 - acc: 0.7048 - val_loss: 0.7007 - val_acc: 0.7939\n",
      "Epoch 285/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9517 - acc: 0.7059\n",
      "Epoch 00285: val_loss improved from 0.70071 to 0.69475, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/285-0.6948.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.9517 - acc: 0.7059 - val_loss: 0.6948 - val_acc: 0.7969\n",
      "Epoch 286/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9495 - acc: 0.7085\n",
      "Epoch 00286: val_loss did not improve from 0.69475\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.9495 - acc: 0.7085 - val_loss: 0.7007 - val_acc: 0.7971\n",
      "Epoch 287/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9492 - acc: 0.7089\n",
      "Epoch 00287: val_loss did not improve from 0.69475\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.9493 - acc: 0.7088 - val_loss: 0.7016 - val_acc: 0.7941\n",
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9430 - acc: 0.7066\n",
      "Epoch 00288: val_loss did not improve from 0.69475\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.9430 - acc: 0.7066 - val_loss: 0.6986 - val_acc: 0.7983\n",
      "Epoch 289/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9449 - acc: 0.7096\n",
      "Epoch 00289: val_loss did not improve from 0.69475\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.9449 - acc: 0.7096 - val_loss: 0.7007 - val_acc: 0.7978\n",
      "Epoch 290/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9472 - acc: 0.7080\n",
      "Epoch 00290: val_loss did not improve from 0.69475\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.9472 - acc: 0.7080 - val_loss: 0.7046 - val_acc: 0.7983\n",
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9487 - acc: 0.7096\n",
      "Epoch 00291: val_loss did not improve from 0.69475\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.9487 - acc: 0.7096 - val_loss: 0.7034 - val_acc: 0.7985\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9463 - acc: 0.7090\n",
      "Epoch 00292: val_loss did not improve from 0.69475\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.9463 - acc: 0.7091 - val_loss: 0.7009 - val_acc: 0.7959\n",
      "Epoch 293/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.9475 - acc: 0.7074\n",
      "Epoch 00293: val_loss did not improve from 0.69475\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9473 - acc: 0.7075 - val_loss: 0.7026 - val_acc: 0.7966\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9449 - acc: 0.7084\n",
      "Epoch 00294: val_loss did not improve from 0.69475\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9448 - acc: 0.7084 - val_loss: 0.7143 - val_acc: 0.7925\n",
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9397 - acc: 0.7109\n",
      "Epoch 00295: val_loss improved from 0.69475 to 0.69207, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/295-0.6921.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.9398 - acc: 0.7109 - val_loss: 0.6921 - val_acc: 0.7966\n",
      "Epoch 296/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9464 - acc: 0.7077\n",
      "Epoch 00296: val_loss did not improve from 0.69207\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.9463 - acc: 0.7077 - val_loss: 0.7019 - val_acc: 0.7959\n",
      "Epoch 297/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9404 - acc: 0.7098\n",
      "Epoch 00297: val_loss did not improve from 0.69207\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9404 - acc: 0.7098 - val_loss: 0.6950 - val_acc: 0.7980\n",
      "Epoch 298/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9387 - acc: 0.7125\n",
      "Epoch 00298: val_loss did not improve from 0.69207\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9387 - acc: 0.7125 - val_loss: 0.6995 - val_acc: 0.7994\n",
      "Epoch 299/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9356 - acc: 0.7104\n",
      "Epoch 00299: val_loss did not improve from 0.69207\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9356 - acc: 0.7104 - val_loss: 0.6921 - val_acc: 0.7999\n",
      "Epoch 300/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9461 - acc: 0.7098\n",
      "Epoch 00300: val_loss did not improve from 0.69207\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.9463 - acc: 0.7098 - val_loss: 0.6972 - val_acc: 0.7973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9401 - acc: 0.7120\n",
      "Epoch 00301: val_loss improved from 0.69207 to 0.69198, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/301-0.6920.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.9402 - acc: 0.7120 - val_loss: 0.6920 - val_acc: 0.7990\n",
      "Epoch 302/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9379 - acc: 0.7112\n",
      "Epoch 00302: val_loss did not improve from 0.69198\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9379 - acc: 0.7112 - val_loss: 0.6934 - val_acc: 0.8013\n",
      "Epoch 303/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9365 - acc: 0.7115\n",
      "Epoch 00303: val_loss did not improve from 0.69198\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9365 - acc: 0.7115 - val_loss: 0.7043 - val_acc: 0.7957\n",
      "Epoch 304/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9342 - acc: 0.7114\n",
      "Epoch 00304: val_loss improved from 0.69198 to 0.68841, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/304-0.6884.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.9343 - acc: 0.7113 - val_loss: 0.6884 - val_acc: 0.8001\n",
      "Epoch 305/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9405 - acc: 0.7076\n",
      "Epoch 00305: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.9404 - acc: 0.7076 - val_loss: 0.6909 - val_acc: 0.8008\n",
      "Epoch 306/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9409 - acc: 0.7112\n",
      "Epoch 00306: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9409 - acc: 0.7112 - val_loss: 0.6894 - val_acc: 0.8032\n",
      "Epoch 307/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9372 - acc: 0.7132\n",
      "Epoch 00307: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9371 - acc: 0.7132 - val_loss: 0.6901 - val_acc: 0.8001\n",
      "Epoch 308/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9329 - acc: 0.7144\n",
      "Epoch 00308: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9329 - acc: 0.7144 - val_loss: 0.6944 - val_acc: 0.7985\n",
      "Epoch 309/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9368 - acc: 0.7096\n",
      "Epoch 00309: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9368 - acc: 0.7096 - val_loss: 0.6899 - val_acc: 0.8015\n",
      "Epoch 310/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9313 - acc: 0.7152\n",
      "Epoch 00310: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.9312 - acc: 0.7153 - val_loss: 0.6972 - val_acc: 0.7994\n",
      "Epoch 311/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9398 - acc: 0.7090\n",
      "Epoch 00311: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9398 - acc: 0.7090 - val_loss: 0.6993 - val_acc: 0.7992\n",
      "Epoch 312/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9352 - acc: 0.7135\n",
      "Epoch 00312: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.9352 - acc: 0.7135 - val_loss: 0.6963 - val_acc: 0.8001\n",
      "Epoch 313/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9326 - acc: 0.7135\n",
      "Epoch 00313: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.9326 - acc: 0.7135 - val_loss: 0.6890 - val_acc: 0.8025\n",
      "Epoch 314/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9345 - acc: 0.7140\n",
      "Epoch 00314: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.9345 - acc: 0.7140 - val_loss: 0.6908 - val_acc: 0.8032\n",
      "Epoch 315/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9324 - acc: 0.7124\n",
      "Epoch 00315: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.9324 - acc: 0.7125 - val_loss: 0.6900 - val_acc: 0.8013\n",
      "Epoch 316/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9310 - acc: 0.7140\n",
      "Epoch 00316: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.9310 - acc: 0.7140 - val_loss: 0.6893 - val_acc: 0.8022\n",
      "Epoch 317/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9385 - acc: 0.7107\n",
      "Epoch 00317: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.9385 - acc: 0.7107 - val_loss: 0.6921 - val_acc: 0.8022\n",
      "Epoch 318/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9318 - acc: 0.7149\n",
      "Epoch 00318: val_loss did not improve from 0.68841\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9320 - acc: 0.7148 - val_loss: 0.6913 - val_acc: 0.8020\n",
      "Epoch 319/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9305 - acc: 0.7142\n",
      "Epoch 00319: val_loss improved from 0.68841 to 0.68701, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/319-0.6870.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9305 - acc: 0.7142 - val_loss: 0.6870 - val_acc: 0.8043\n",
      "Epoch 320/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9354 - acc: 0.7111\n",
      "Epoch 00320: val_loss improved from 0.68701 to 0.68368, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/320-0.6837.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.9353 - acc: 0.7111 - val_loss: 0.6837 - val_acc: 0.8006\n",
      "Epoch 321/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9379 - acc: 0.7109\n",
      "Epoch 00321: val_loss did not improve from 0.68368\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9381 - acc: 0.7108 - val_loss: 0.6893 - val_acc: 0.7999\n",
      "Epoch 322/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9287 - acc: 0.7143\n",
      "Epoch 00322: val_loss improved from 0.68368 to 0.67762, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/322-0.6776.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.9287 - acc: 0.7143 - val_loss: 0.6776 - val_acc: 0.8060\n",
      "Epoch 323/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9247 - acc: 0.7152\n",
      "Epoch 00323: val_loss did not improve from 0.67762\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.9247 - acc: 0.7152 - val_loss: 0.6909 - val_acc: 0.7999\n",
      "Epoch 324/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9254 - acc: 0.7159\n",
      "Epoch 00324: val_loss did not improve from 0.67762\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9253 - acc: 0.7159 - val_loss: 0.6949 - val_acc: 0.8011\n",
      "Epoch 325/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9266 - acc: 0.7148\n",
      "Epoch 00325: val_loss did not improve from 0.67762\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9267 - acc: 0.7147 - val_loss: 0.7050 - val_acc: 0.7983\n",
      "Epoch 326/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9294 - acc: 0.7104\n",
      "Epoch 00326: val_loss did not improve from 0.67762\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.9296 - acc: 0.7104 - val_loss: 0.6816 - val_acc: 0.8050\n",
      "Epoch 327/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9242 - acc: 0.7137\n",
      "Epoch 00327: val_loss did not improve from 0.67762\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9241 - acc: 0.7138 - val_loss: 0.6794 - val_acc: 0.8074\n",
      "Epoch 328/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9262 - acc: 0.7186\n",
      "Epoch 00328: val_loss did not improve from 0.67762\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.9261 - acc: 0.7186 - val_loss: 0.6815 - val_acc: 0.8078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 329/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9285 - acc: 0.7138\n",
      "Epoch 00329: val_loss did not improve from 0.67762\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.9284 - acc: 0.7138 - val_loss: 0.6797 - val_acc: 0.8046\n",
      "Epoch 330/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9277 - acc: 0.7153\n",
      "Epoch 00330: val_loss improved from 0.67762 to 0.67577, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/330-0.6758.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9276 - acc: 0.7153 - val_loss: 0.6758 - val_acc: 0.8074\n",
      "Epoch 331/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9241 - acc: 0.7190\n",
      "Epoch 00331: val_loss did not improve from 0.67577\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.9240 - acc: 0.7191 - val_loss: 0.6823 - val_acc: 0.8020\n",
      "Epoch 332/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9202 - acc: 0.7173\n",
      "Epoch 00332: val_loss did not improve from 0.67577\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9201 - acc: 0.7173 - val_loss: 0.6870 - val_acc: 0.8032\n",
      "Epoch 333/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9299 - acc: 0.7143\n",
      "Epoch 00333: val_loss did not improve from 0.67577\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.9298 - acc: 0.7143 - val_loss: 0.6797 - val_acc: 0.8062\n",
      "Epoch 334/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9293 - acc: 0.7164\n",
      "Epoch 00334: val_loss did not improve from 0.67577\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.9293 - acc: 0.7164 - val_loss: 0.6801 - val_acc: 0.8069\n",
      "Epoch 335/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9212 - acc: 0.7180\n",
      "Epoch 00335: val_loss did not improve from 0.67577\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9211 - acc: 0.7180 - val_loss: 0.6789 - val_acc: 0.8069\n",
      "Epoch 336/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9244 - acc: 0.7148\n",
      "Epoch 00336: val_loss did not improve from 0.67577\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.9243 - acc: 0.7148 - val_loss: 0.6804 - val_acc: 0.8064\n",
      "Epoch 337/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9234 - acc: 0.7153\n",
      "Epoch 00337: val_loss improved from 0.67577 to 0.67501, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/337-0.6750.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9233 - acc: 0.7153 - val_loss: 0.6750 - val_acc: 0.8060\n",
      "Epoch 338/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9192 - acc: 0.7168\n",
      "Epoch 00338: val_loss improved from 0.67501 to 0.66600, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/338-0.6660.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.9192 - acc: 0.7169 - val_loss: 0.6660 - val_acc: 0.8078\n",
      "Epoch 339/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9149 - acc: 0.7178\n",
      "Epoch 00339: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9149 - acc: 0.7178 - val_loss: 0.6813 - val_acc: 0.8046\n",
      "Epoch 340/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9198 - acc: 0.7151\n",
      "Epoch 00340: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9198 - acc: 0.7151 - val_loss: 0.6798 - val_acc: 0.8057\n",
      "Epoch 341/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9169 - acc: 0.7168\n",
      "Epoch 00341: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9168 - acc: 0.7168 - val_loss: 0.6778 - val_acc: 0.8064\n",
      "Epoch 342/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9233 - acc: 0.7149\n",
      "Epoch 00342: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9232 - acc: 0.7149 - val_loss: 0.6759 - val_acc: 0.8067\n",
      "Epoch 343/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9230 - acc: 0.7168\n",
      "Epoch 00343: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9230 - acc: 0.7168 - val_loss: 0.6745 - val_acc: 0.8076\n",
      "Epoch 344/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9162 - acc: 0.7186\n",
      "Epoch 00344: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.9163 - acc: 0.7185 - val_loss: 0.6768 - val_acc: 0.8085\n",
      "Epoch 345/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9242 - acc: 0.7154\n",
      "Epoch 00345: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9242 - acc: 0.7154 - val_loss: 0.6745 - val_acc: 0.8092\n",
      "Epoch 346/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9178 - acc: 0.7174\n",
      "Epoch 00346: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.9178 - acc: 0.7174 - val_loss: 0.6743 - val_acc: 0.8097\n",
      "Epoch 347/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9143 - acc: 0.7193\n",
      "Epoch 00347: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9142 - acc: 0.7194 - val_loss: 0.6744 - val_acc: 0.8083\n",
      "Epoch 348/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9165 - acc: 0.7179\n",
      "Epoch 00348: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9165 - acc: 0.7179 - val_loss: 0.6717 - val_acc: 0.8097\n",
      "Epoch 349/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9183 - acc: 0.7175\n",
      "Epoch 00349: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9182 - acc: 0.7175 - val_loss: 0.6754 - val_acc: 0.8092\n",
      "Epoch 350/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9135 - acc: 0.7180\n",
      "Epoch 00350: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9134 - acc: 0.7181 - val_loss: 0.6741 - val_acc: 0.8064\n",
      "Epoch 351/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9189 - acc: 0.7165\n",
      "Epoch 00351: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9189 - acc: 0.7165 - val_loss: 0.6700 - val_acc: 0.8097\n",
      "Epoch 352/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9160 - acc: 0.7207\n",
      "Epoch 00352: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9161 - acc: 0.7207 - val_loss: 0.6736 - val_acc: 0.8055\n",
      "Epoch 353/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9088 - acc: 0.7202\n",
      "Epoch 00353: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.9089 - acc: 0.7201 - val_loss: 0.6731 - val_acc: 0.8111\n",
      "Epoch 354/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9118 - acc: 0.7164\n",
      "Epoch 00354: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9118 - acc: 0.7163 - val_loss: 0.6664 - val_acc: 0.8118\n",
      "Epoch 355/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9109 - acc: 0.7187\n",
      "Epoch 00355: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.9109 - acc: 0.7187 - val_loss: 0.6701 - val_acc: 0.8090\n",
      "Epoch 356/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9171 - acc: 0.7197\n",
      "Epoch 00356: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9170 - acc: 0.7197 - val_loss: 0.6754 - val_acc: 0.8097\n",
      "Epoch 357/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9116 - acc: 0.7186\n",
      "Epoch 00357: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9117 - acc: 0.7185 - val_loss: 0.6674 - val_acc: 0.8097\n",
      "Epoch 358/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9142 - acc: 0.7176\n",
      "Epoch 00358: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9144 - acc: 0.7175 - val_loss: 0.6666 - val_acc: 0.8092\n",
      "Epoch 359/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9132 - acc: 0.7173\n",
      "Epoch 00359: val_loss did not improve from 0.66600\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.9131 - acc: 0.7173 - val_loss: 0.6695 - val_acc: 0.8071\n",
      "Epoch 360/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9136 - acc: 0.7189\n",
      "Epoch 00360: val_loss improved from 0.66600 to 0.66197, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/360-0.6620.hdf5\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9135 - acc: 0.7189 - val_loss: 0.6620 - val_acc: 0.8146\n",
      "Epoch 361/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9101 - acc: 0.7179\n",
      "Epoch 00361: val_loss did not improve from 0.66197\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9102 - acc: 0.7178 - val_loss: 0.6680 - val_acc: 0.8111\n",
      "Epoch 362/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9126 - acc: 0.7205\n",
      "Epoch 00362: val_loss did not improve from 0.66197\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.9127 - acc: 0.7205 - val_loss: 0.6704 - val_acc: 0.8113\n",
      "Epoch 363/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9097 - acc: 0.7215\n",
      "Epoch 00363: val_loss did not improve from 0.66197\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9098 - acc: 0.7215 - val_loss: 0.6626 - val_acc: 0.8143\n",
      "Epoch 364/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9078 - acc: 0.7195\n",
      "Epoch 00364: val_loss did not improve from 0.66197\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9077 - acc: 0.7195 - val_loss: 0.6678 - val_acc: 0.8134\n",
      "Epoch 365/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9103 - acc: 0.7212\n",
      "Epoch 00365: val_loss did not improve from 0.66197\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9102 - acc: 0.7212 - val_loss: 0.6703 - val_acc: 0.8106\n",
      "Epoch 366/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9038 - acc: 0.7200\n",
      "Epoch 00366: val_loss did not improve from 0.66197\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9038 - acc: 0.7200 - val_loss: 0.6671 - val_acc: 0.8109\n",
      "Epoch 367/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9027 - acc: 0.7223\n",
      "Epoch 00367: val_loss improved from 0.66197 to 0.66143, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/367-0.6614.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.9027 - acc: 0.7223 - val_loss: 0.6614 - val_acc: 0.8123\n",
      "Epoch 368/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9068 - acc: 0.7197\n",
      "Epoch 00368: val_loss did not improve from 0.66143\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9068 - acc: 0.7197 - val_loss: 0.6624 - val_acc: 0.8120\n",
      "Epoch 369/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9045 - acc: 0.7205\n",
      "Epoch 00369: val_loss did not improve from 0.66143\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9045 - acc: 0.7205 - val_loss: 0.6628 - val_acc: 0.8109\n",
      "Epoch 370/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9045 - acc: 0.7240\n",
      "Epoch 00370: val_loss improved from 0.66143 to 0.65878, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/370-0.6588.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9044 - acc: 0.7240 - val_loss: 0.6588 - val_acc: 0.8125\n",
      "Epoch 371/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9051 - acc: 0.7189\n",
      "Epoch 00371: val_loss improved from 0.65878 to 0.65578, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/371-0.6558.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9052 - acc: 0.7189 - val_loss: 0.6558 - val_acc: 0.8153\n",
      "Epoch 372/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9059 - acc: 0.7230\n",
      "Epoch 00372: val_loss did not improve from 0.65578\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.9058 - acc: 0.7230 - val_loss: 0.6596 - val_acc: 0.8118\n",
      "Epoch 373/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9118 - acc: 0.7182\n",
      "Epoch 00373: val_loss did not improve from 0.65578\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.9118 - acc: 0.7182 - val_loss: 0.6676 - val_acc: 0.8137\n",
      "Epoch 374/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9086 - acc: 0.7233\n",
      "Epoch 00374: val_loss did not improve from 0.65578\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9087 - acc: 0.7233 - val_loss: 0.6593 - val_acc: 0.8143\n",
      "Epoch 375/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9047 - acc: 0.7227\n",
      "Epoch 00375: val_loss did not improve from 0.65578\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9047 - acc: 0.7228 - val_loss: 0.6591 - val_acc: 0.8143\n",
      "Epoch 376/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9071 - acc: 0.7221\n",
      "Epoch 00376: val_loss did not improve from 0.65578\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9071 - acc: 0.7221 - val_loss: 0.6593 - val_acc: 0.8162\n",
      "Epoch 377/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9156 - acc: 0.7179\n",
      "Epoch 00377: val_loss improved from 0.65578 to 0.65495, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/377-0.6549.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.9156 - acc: 0.7179 - val_loss: 0.6549 - val_acc: 0.8111\n",
      "Epoch 378/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9033 - acc: 0.7221\n",
      "Epoch 00378: val_loss did not improve from 0.65495\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9032 - acc: 0.7222 - val_loss: 0.6555 - val_acc: 0.8141\n",
      "Epoch 379/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9008 - acc: 0.7252\n",
      "Epoch 00379: val_loss did not improve from 0.65495\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9008 - acc: 0.7252 - val_loss: 0.6670 - val_acc: 0.8090\n",
      "Epoch 380/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9054 - acc: 0.7222\n",
      "Epoch 00380: val_loss did not improve from 0.65495\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9053 - acc: 0.7223 - val_loss: 0.6595 - val_acc: 0.8169\n",
      "Epoch 381/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8977 - acc: 0.7218\n",
      "Epoch 00381: val_loss did not improve from 0.65495\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.8977 - acc: 0.7218 - val_loss: 0.6680 - val_acc: 0.8132\n",
      "Epoch 382/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9069 - acc: 0.7216\n",
      "Epoch 00382: val_loss did not improve from 0.65495\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9068 - acc: 0.7216 - val_loss: 0.6586 - val_acc: 0.8139\n",
      "Epoch 383/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8989 - acc: 0.7252\n",
      "Epoch 00383: val_loss did not improve from 0.65495\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8988 - acc: 0.7252 - val_loss: 0.6617 - val_acc: 0.8157\n",
      "Epoch 384/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9009 - acc: 0.7231\n",
      "Epoch 00384: val_loss did not improve from 0.65495\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.9008 - acc: 0.7231 - val_loss: 0.6629 - val_acc: 0.8143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 385/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8949 - acc: 0.7227\n",
      "Epoch 00385: val_loss improved from 0.65495 to 0.65342, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/385-0.6534.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.8949 - acc: 0.7228 - val_loss: 0.6534 - val_acc: 0.8164\n",
      "Epoch 386/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9031 - acc: 0.7212\n",
      "Epoch 00386: val_loss did not improve from 0.65342\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.9030 - acc: 0.7212 - val_loss: 0.6616 - val_acc: 0.8148\n",
      "Epoch 387/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8990 - acc: 0.7235\n",
      "Epoch 00387: val_loss did not improve from 0.65342\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8989 - acc: 0.7235 - val_loss: 0.6647 - val_acc: 0.8137\n",
      "Epoch 388/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9091 - acc: 0.7223\n",
      "Epoch 00388: val_loss did not improve from 0.65342\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.9091 - acc: 0.7223 - val_loss: 0.6630 - val_acc: 0.8123\n",
      "Epoch 389/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8992 - acc: 0.7221\n",
      "Epoch 00389: val_loss did not improve from 0.65342\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.8993 - acc: 0.7221 - val_loss: 0.6553 - val_acc: 0.8148\n",
      "Epoch 390/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9006 - acc: 0.7255\n",
      "Epoch 00390: val_loss did not improve from 0.65342\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9006 - acc: 0.7255 - val_loss: 0.6548 - val_acc: 0.8141\n",
      "Epoch 391/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9012 - acc: 0.7243\n",
      "Epoch 00391: val_loss improved from 0.65342 to 0.65025, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/391-0.6503.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9013 - acc: 0.7243 - val_loss: 0.6503 - val_acc: 0.8185\n",
      "Epoch 392/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9022 - acc: 0.7234\n",
      "Epoch 00392: val_loss did not improve from 0.65025\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.9022 - acc: 0.7233 - val_loss: 0.6629 - val_acc: 0.8146\n",
      "Epoch 393/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8940 - acc: 0.7227\n",
      "Epoch 00393: val_loss did not improve from 0.65025\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.8939 - acc: 0.7227 - val_loss: 0.6511 - val_acc: 0.8143\n",
      "Epoch 394/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8958 - acc: 0.7224\n",
      "Epoch 00394: val_loss did not improve from 0.65025\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.8958 - acc: 0.7225 - val_loss: 0.6525 - val_acc: 0.8148\n",
      "Epoch 395/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8947 - acc: 0.7274\n",
      "Epoch 00395: val_loss did not improve from 0.65025\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.8947 - acc: 0.7274 - val_loss: 0.6559 - val_acc: 0.8176\n",
      "Epoch 396/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8980 - acc: 0.7264\n",
      "Epoch 00396: val_loss did not improve from 0.65025\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8981 - acc: 0.7264 - val_loss: 0.6560 - val_acc: 0.8183\n",
      "Epoch 397/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8960 - acc: 0.7250\n",
      "Epoch 00397: val_loss improved from 0.65025 to 0.64941, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/397-0.6494.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.8961 - acc: 0.7250 - val_loss: 0.6494 - val_acc: 0.8169\n",
      "Epoch 398/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8979 - acc: 0.7216\n",
      "Epoch 00398: val_loss did not improve from 0.64941\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.8979 - acc: 0.7216 - val_loss: 0.6562 - val_acc: 0.8141\n",
      "Epoch 399/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8981 - acc: 0.7234\n",
      "Epoch 00399: val_loss did not improve from 0.64941\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.8981 - acc: 0.7234 - val_loss: 0.6515 - val_acc: 0.8164\n",
      "Epoch 400/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8932 - acc: 0.7250\n",
      "Epoch 00400: val_loss did not improve from 0.64941\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8931 - acc: 0.7250 - val_loss: 0.6508 - val_acc: 0.8164\n",
      "Epoch 401/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8989 - acc: 0.7236\n",
      "Epoch 00401: val_loss did not improve from 0.64941\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8988 - acc: 0.7237 - val_loss: 0.6595 - val_acc: 0.8132\n",
      "Epoch 402/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8948 - acc: 0.7236\n",
      "Epoch 00402: val_loss did not improve from 0.64941\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.8949 - acc: 0.7236 - val_loss: 0.6494 - val_acc: 0.8139\n",
      "Epoch 403/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8932 - acc: 0.7225\n",
      "Epoch 00403: val_loss did not improve from 0.64941\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8936 - acc: 0.7225 - val_loss: 0.6551 - val_acc: 0.8178\n",
      "Epoch 404/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8981 - acc: 0.7233\n",
      "Epoch 00404: val_loss did not improve from 0.64941\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.8980 - acc: 0.7233 - val_loss: 0.6495 - val_acc: 0.8146\n",
      "Epoch 405/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8929 - acc: 0.7244\n",
      "Epoch 00405: val_loss did not improve from 0.64941\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8928 - acc: 0.7244 - val_loss: 0.6743 - val_acc: 0.8085\n",
      "Epoch 406/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8977 - acc: 0.7253\n",
      "Epoch 00406: val_loss did not improve from 0.64941\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.8976 - acc: 0.7253 - val_loss: 0.6528 - val_acc: 0.8176\n",
      "Epoch 407/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8906 - acc: 0.7277\n",
      "Epoch 00407: val_loss improved from 0.64941 to 0.64583, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/407-0.6458.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.8906 - acc: 0.7277 - val_loss: 0.6458 - val_acc: 0.8199\n",
      "Epoch 408/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8926 - acc: 0.7268\n",
      "Epoch 00408: val_loss improved from 0.64583 to 0.64531, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/408-0.6453.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8925 - acc: 0.7268 - val_loss: 0.6453 - val_acc: 0.8195\n",
      "Epoch 409/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8860 - acc: 0.7286\n",
      "Epoch 00409: val_loss improved from 0.64531 to 0.64041, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/409-0.6404.hdf5\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.8861 - acc: 0.7286 - val_loss: 0.6404 - val_acc: 0.8241\n",
      "Epoch 410/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8899 - acc: 0.7274\n",
      "Epoch 00410: val_loss did not improve from 0.64041\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8900 - acc: 0.7273 - val_loss: 0.6442 - val_acc: 0.8192\n",
      "Epoch 411/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8917 - acc: 0.7253\n",
      "Epoch 00411: val_loss did not improve from 0.64041\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.8917 - acc: 0.7253 - val_loss: 0.6524 - val_acc: 0.8183\n",
      "Epoch 412/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8851 - acc: 0.7274\n",
      "Epoch 00412: val_loss did not improve from 0.64041\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.8852 - acc: 0.7273 - val_loss: 0.6483 - val_acc: 0.8171\n",
      "Epoch 413/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8892 - acc: 0.7274\n",
      "Epoch 00413: val_loss did not improve from 0.64041\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.8891 - acc: 0.7274 - val_loss: 0.6484 - val_acc: 0.8209\n",
      "Epoch 414/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8905 - acc: 0.7257\n",
      "Epoch 00414: val_loss did not improve from 0.64041\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.8904 - acc: 0.7258 - val_loss: 0.6505 - val_acc: 0.8197\n",
      "Epoch 415/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8876 - acc: 0.7256\n",
      "Epoch 00415: val_loss did not improve from 0.64041\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.8875 - acc: 0.7257 - val_loss: 0.6466 - val_acc: 0.8185\n",
      "Epoch 416/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8868 - acc: 0.7271\n",
      "Epoch 00416: val_loss did not improve from 0.64041\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.8868 - acc: 0.7271 - val_loss: 0.6467 - val_acc: 0.8192\n",
      "Epoch 417/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8959 - acc: 0.7241\n",
      "Epoch 00417: val_loss did not improve from 0.64041\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.8958 - acc: 0.7241 - val_loss: 0.6503 - val_acc: 0.8181\n",
      "Epoch 418/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8895 - acc: 0.7237\n",
      "Epoch 00418: val_loss did not improve from 0.64041\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8894 - acc: 0.7237 - val_loss: 0.6476 - val_acc: 0.8190\n",
      "Epoch 419/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8850 - acc: 0.7276\n",
      "Epoch 00419: val_loss did not improve from 0.64041\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8850 - acc: 0.7276 - val_loss: 0.6544 - val_acc: 0.8164\n",
      "Epoch 420/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8894 - acc: 0.7250\n",
      "Epoch 00420: val_loss did not improve from 0.64041\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.8894 - acc: 0.7250 - val_loss: 0.6470 - val_acc: 0.8195\n",
      "Epoch 421/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8862 - acc: 0.7269\n",
      "Epoch 00421: val_loss did not improve from 0.64041\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8863 - acc: 0.7269 - val_loss: 0.6417 - val_acc: 0.8218\n",
      "Epoch 422/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8931 - acc: 0.7249\n",
      "Epoch 00422: val_loss did not improve from 0.64041\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8931 - acc: 0.7250 - val_loss: 0.6547 - val_acc: 0.8176\n",
      "Epoch 423/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8766 - acc: 0.7317\n",
      "Epoch 00423: val_loss improved from 0.64041 to 0.63712, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/423-0.6371.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8765 - acc: 0.7317 - val_loss: 0.6371 - val_acc: 0.8239\n",
      "Epoch 424/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8862 - acc: 0.7282\n",
      "Epoch 00424: val_loss did not improve from 0.63712\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8862 - acc: 0.7282 - val_loss: 0.6446 - val_acc: 0.8190\n",
      "Epoch 425/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8832 - acc: 0.7293\n",
      "Epoch 00425: val_loss did not improve from 0.63712\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.8833 - acc: 0.7293 - val_loss: 0.6450 - val_acc: 0.8202\n",
      "Epoch 426/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8903 - acc: 0.7245\n",
      "Epoch 00426: val_loss did not improve from 0.63712\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.8903 - acc: 0.7245 - val_loss: 0.6419 - val_acc: 0.8216\n",
      "Epoch 427/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8797 - acc: 0.7290\n",
      "Epoch 00427: val_loss did not improve from 0.63712\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.8797 - acc: 0.7290 - val_loss: 0.6431 - val_acc: 0.8195\n",
      "Epoch 428/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8856 - acc: 0.7302\n",
      "Epoch 00428: val_loss did not improve from 0.63712\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.8856 - acc: 0.7301 - val_loss: 0.6483 - val_acc: 0.8192\n",
      "Epoch 429/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8803 - acc: 0.7299\n",
      "Epoch 00429: val_loss did not improve from 0.63712\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8802 - acc: 0.7300 - val_loss: 0.6499 - val_acc: 0.8153\n",
      "Epoch 430/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8830 - acc: 0.7290\n",
      "Epoch 00430: val_loss did not improve from 0.63712\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.8831 - acc: 0.7289 - val_loss: 0.6394 - val_acc: 0.8232\n",
      "Epoch 431/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8895 - acc: 0.7267\n",
      "Epoch 00431: val_loss did not improve from 0.63712\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.8895 - acc: 0.7267 - val_loss: 0.6466 - val_acc: 0.8174\n",
      "Epoch 432/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8860 - acc: 0.7295\n",
      "Epoch 00432: val_loss did not improve from 0.63712\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8860 - acc: 0.7295 - val_loss: 0.6400 - val_acc: 0.8209\n",
      "Epoch 433/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8852 - acc: 0.7293\n",
      "Epoch 00433: val_loss improved from 0.63712 to 0.63555, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/433-0.6355.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.8851 - acc: 0.7293 - val_loss: 0.6355 - val_acc: 0.8244\n",
      "Epoch 434/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8868 - acc: 0.7275\n",
      "Epoch 00434: val_loss did not improve from 0.63555\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.8868 - acc: 0.7275 - val_loss: 0.6457 - val_acc: 0.8204\n",
      "Epoch 435/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8813 - acc: 0.7300\n",
      "Epoch 00435: val_loss improved from 0.63555 to 0.63542, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/435-0.6354.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.8813 - acc: 0.7300 - val_loss: 0.6354 - val_acc: 0.8248\n",
      "Epoch 436/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8806 - acc: 0.7324\n",
      "Epoch 00436: val_loss did not improve from 0.63542\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8807 - acc: 0.7324 - val_loss: 0.6529 - val_acc: 0.8188\n",
      "Epoch 437/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8754 - acc: 0.7301\n",
      "Epoch 00437: val_loss improved from 0.63542 to 0.63430, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/437-0.6343.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8754 - acc: 0.7300 - val_loss: 0.6343 - val_acc: 0.8230\n",
      "Epoch 438/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8776 - acc: 0.7296\n",
      "Epoch 00438: val_loss did not improve from 0.63430\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.8777 - acc: 0.7296 - val_loss: 0.6394 - val_acc: 0.8223\n",
      "Epoch 439/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8754 - acc: 0.7308\n",
      "Epoch 00439: val_loss did not improve from 0.63430\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.8756 - acc: 0.7307 - val_loss: 0.6409 - val_acc: 0.8209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 440/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8686 - acc: 0.7330\n",
      "Epoch 00440: val_loss did not improve from 0.63430\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8686 - acc: 0.7330 - val_loss: 0.6358 - val_acc: 0.8262\n",
      "Epoch 441/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8705 - acc: 0.7340\n",
      "Epoch 00441: val_loss did not improve from 0.63430\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8705 - acc: 0.7340 - val_loss: 0.6395 - val_acc: 0.8223\n",
      "Epoch 442/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8764 - acc: 0.7293\n",
      "Epoch 00442: val_loss did not improve from 0.63430\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.8763 - acc: 0.7294 - val_loss: 0.6372 - val_acc: 0.8227\n",
      "Epoch 443/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8746 - acc: 0.7324\n",
      "Epoch 00443: val_loss improved from 0.63430 to 0.63061, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/443-0.6306.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.8747 - acc: 0.7324 - val_loss: 0.6306 - val_acc: 0.8241\n",
      "Epoch 444/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8819 - acc: 0.7313\n",
      "Epoch 00444: val_loss did not improve from 0.63061\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.8819 - acc: 0.7313 - val_loss: 0.6399 - val_acc: 0.8225\n",
      "Epoch 445/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8794 - acc: 0.7324\n",
      "Epoch 00445: val_loss did not improve from 0.63061\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.8793 - acc: 0.7325 - val_loss: 0.6369 - val_acc: 0.8248\n",
      "Epoch 446/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8802 - acc: 0.7319\n",
      "Epoch 00446: val_loss did not improve from 0.63061\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8803 - acc: 0.7319 - val_loss: 0.6391 - val_acc: 0.8225\n",
      "Epoch 447/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8726 - acc: 0.7327\n",
      "Epoch 00447: val_loss did not improve from 0.63061\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8726 - acc: 0.7326 - val_loss: 0.6407 - val_acc: 0.8239\n",
      "Epoch 448/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8701 - acc: 0.7284\n",
      "Epoch 00448: val_loss did not improve from 0.63061\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8700 - acc: 0.7284 - val_loss: 0.6407 - val_acc: 0.8209\n",
      "Epoch 449/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8731 - acc: 0.7326\n",
      "Epoch 00449: val_loss did not improve from 0.63061\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8730 - acc: 0.7326 - val_loss: 0.6395 - val_acc: 0.8211\n",
      "Epoch 450/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8822 - acc: 0.7304\n",
      "Epoch 00450: val_loss improved from 0.63061 to 0.63034, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/450-0.6303.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.8821 - acc: 0.7304 - val_loss: 0.6303 - val_acc: 0.8281\n",
      "Epoch 451/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8719 - acc: 0.7317\n",
      "Epoch 00451: val_loss did not improve from 0.63034\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.8719 - acc: 0.7317 - val_loss: 0.6347 - val_acc: 0.8239\n",
      "Epoch 452/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8697 - acc: 0.7333\n",
      "Epoch 00452: val_loss did not improve from 0.63034\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.8697 - acc: 0.7333 - val_loss: 0.6439 - val_acc: 0.8183\n",
      "Epoch 453/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8782 - acc: 0.7308\n",
      "Epoch 00453: val_loss did not improve from 0.63034\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.8780 - acc: 0.7308 - val_loss: 0.6357 - val_acc: 0.8253\n",
      "Epoch 454/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8750 - acc: 0.7286\n",
      "Epoch 00454: val_loss did not improve from 0.63034\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8750 - acc: 0.7285 - val_loss: 0.6399 - val_acc: 0.8204\n",
      "Epoch 455/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8686 - acc: 0.7340\n",
      "Epoch 00455: val_loss did not improve from 0.63034\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.8685 - acc: 0.7341 - val_loss: 0.6373 - val_acc: 0.8206\n",
      "Epoch 456/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8742 - acc: 0.7317\n",
      "Epoch 00456: val_loss did not improve from 0.63034\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8741 - acc: 0.7318 - val_loss: 0.6342 - val_acc: 0.8223\n",
      "Epoch 457/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8764 - acc: 0.7294\n",
      "Epoch 00457: val_loss did not improve from 0.63034\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.8765 - acc: 0.7294 - val_loss: 0.6373 - val_acc: 0.8216\n",
      "Epoch 458/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8782 - acc: 0.7322\n",
      "Epoch 00458: val_loss improved from 0.63034 to 0.63015, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/458-0.6302.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.8778 - acc: 0.7323 - val_loss: 0.6302 - val_acc: 0.8223\n",
      "Epoch 459/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8778 - acc: 0.7319\n",
      "Epoch 00459: val_loss did not improve from 0.63015\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8777 - acc: 0.7319 - val_loss: 0.6382 - val_acc: 0.8204\n",
      "Epoch 460/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8695 - acc: 0.7347\n",
      "Epoch 00460: val_loss did not improve from 0.63015\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8694 - acc: 0.7347 - val_loss: 0.6343 - val_acc: 0.8225\n",
      "Epoch 461/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8731 - acc: 0.7317\n",
      "Epoch 00461: val_loss improved from 0.63015 to 0.62997, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/461-0.6300.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.8732 - acc: 0.7316 - val_loss: 0.6300 - val_acc: 0.8258\n",
      "Epoch 462/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8698 - acc: 0.7346\n",
      "Epoch 00462: val_loss improved from 0.62997 to 0.62523, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/462-0.6252.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8697 - acc: 0.7347 - val_loss: 0.6252 - val_acc: 0.8279\n",
      "Epoch 463/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8702 - acc: 0.7344\n",
      "Epoch 00463: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8702 - acc: 0.7343 - val_loss: 0.6292 - val_acc: 0.8255\n",
      "Epoch 464/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8682 - acc: 0.7351\n",
      "Epoch 00464: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8681 - acc: 0.7351 - val_loss: 0.6288 - val_acc: 0.8269\n",
      "Epoch 465/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8755 - acc: 0.7332\n",
      "Epoch 00465: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.8755 - acc: 0.7331 - val_loss: 0.6300 - val_acc: 0.8253\n",
      "Epoch 466/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8770 - acc: 0.7292\n",
      "Epoch 00466: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8770 - acc: 0.7292 - val_loss: 0.6334 - val_acc: 0.8239\n",
      "Epoch 467/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8686 - acc: 0.7319\n",
      "Epoch 00467: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.8685 - acc: 0.7320 - val_loss: 0.6254 - val_acc: 0.8304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 468/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8719 - acc: 0.7320\n",
      "Epoch 00468: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8719 - acc: 0.7320 - val_loss: 0.6363 - val_acc: 0.8248\n",
      "Epoch 469/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8666 - acc: 0.7329\n",
      "Epoch 00469: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8666 - acc: 0.7329 - val_loss: 0.6385 - val_acc: 0.8230\n",
      "Epoch 470/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8677 - acc: 0.7370\n",
      "Epoch 00470: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8677 - acc: 0.7370 - val_loss: 0.6391 - val_acc: 0.8190\n",
      "Epoch 471/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8650 - acc: 0.7357\n",
      "Epoch 00471: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.8650 - acc: 0.7357 - val_loss: 0.6253 - val_acc: 0.8237\n",
      "Epoch 472/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8741 - acc: 0.7318\n",
      "Epoch 00472: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.8739 - acc: 0.7318 - val_loss: 0.6280 - val_acc: 0.8262\n",
      "Epoch 473/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8611 - acc: 0.7335\n",
      "Epoch 00473: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.8611 - acc: 0.7335 - val_loss: 0.6354 - val_acc: 0.8220\n",
      "Epoch 474/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8671 - acc: 0.7340\n",
      "Epoch 00474: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.8671 - acc: 0.7340 - val_loss: 0.6282 - val_acc: 0.8267\n",
      "Epoch 475/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8723 - acc: 0.7327\n",
      "Epoch 00475: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.8722 - acc: 0.7328 - val_loss: 0.6311 - val_acc: 0.8244\n",
      "Epoch 476/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8619 - acc: 0.7368\n",
      "Epoch 00476: val_loss did not improve from 0.62523\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.8619 - acc: 0.7368 - val_loss: 0.6313 - val_acc: 0.8234\n",
      "Epoch 477/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8671 - acc: 0.7362\n",
      "Epoch 00477: val_loss improved from 0.62523 to 0.62293, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/477-0.6229.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8671 - acc: 0.7362 - val_loss: 0.6229 - val_acc: 0.8262\n",
      "Epoch 478/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8680 - acc: 0.7317\n",
      "Epoch 00478: val_loss did not improve from 0.62293\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8679 - acc: 0.7317 - val_loss: 0.6284 - val_acc: 0.8246\n",
      "Epoch 479/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8649 - acc: 0.7310\n",
      "Epoch 00479: val_loss did not improve from 0.62293\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.8649 - acc: 0.7310 - val_loss: 0.6264 - val_acc: 0.8260\n",
      "Epoch 480/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8705 - acc: 0.7342\n",
      "Epoch 00480: val_loss improved from 0.62293 to 0.62032, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/480-0.6203.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8704 - acc: 0.7342 - val_loss: 0.6203 - val_acc: 0.8293\n",
      "Epoch 481/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8654 - acc: 0.7344\n",
      "Epoch 00481: val_loss improved from 0.62032 to 0.61852, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/481-0.6185.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8654 - acc: 0.7344 - val_loss: 0.6185 - val_acc: 0.8300\n",
      "Epoch 482/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8775 - acc: 0.7313\n",
      "Epoch 00482: val_loss did not improve from 0.61852\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.8775 - acc: 0.7313 - val_loss: 0.6260 - val_acc: 0.8269\n",
      "Epoch 483/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8641 - acc: 0.7364\n",
      "Epoch 00483: val_loss did not improve from 0.61852\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.8641 - acc: 0.7364 - val_loss: 0.6220 - val_acc: 0.8262\n",
      "Epoch 484/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8656 - acc: 0.7346\n",
      "Epoch 00484: val_loss did not improve from 0.61852\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.8656 - acc: 0.7346 - val_loss: 0.6258 - val_acc: 0.8265\n",
      "Epoch 485/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8654 - acc: 0.7361\n",
      "Epoch 00485: val_loss did not improve from 0.61852\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.8653 - acc: 0.7362 - val_loss: 0.6226 - val_acc: 0.8258\n",
      "Epoch 486/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8611 - acc: 0.7369\n",
      "Epoch 00486: val_loss did not improve from 0.61852\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.8611 - acc: 0.7369 - val_loss: 0.6286 - val_acc: 0.8246\n",
      "Epoch 487/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8609 - acc: 0.7367\n",
      "Epoch 00487: val_loss did not improve from 0.61852\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.8609 - acc: 0.7366 - val_loss: 0.6256 - val_acc: 0.8253\n",
      "Epoch 488/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8644 - acc: 0.7373\n",
      "Epoch 00488: val_loss did not improve from 0.61852\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.8644 - acc: 0.7372 - val_loss: 0.6311 - val_acc: 0.8239\n",
      "Epoch 489/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8653 - acc: 0.7354\n",
      "Epoch 00489: val_loss did not improve from 0.61852\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.8653 - acc: 0.7354 - val_loss: 0.6390 - val_acc: 0.8237\n",
      "Epoch 490/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8575 - acc: 0.7393\n",
      "Epoch 00490: val_loss did not improve from 0.61852\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8574 - acc: 0.7393 - val_loss: 0.6193 - val_acc: 0.8265\n",
      "Epoch 491/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8628 - acc: 0.7363\n",
      "Epoch 00491: val_loss did not improve from 0.61852\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.8628 - acc: 0.7363 - val_loss: 0.6205 - val_acc: 0.8283\n",
      "Epoch 492/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8646 - acc: 0.7347\n",
      "Epoch 00492: val_loss did not improve from 0.61852\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.8645 - acc: 0.7347 - val_loss: 0.6244 - val_acc: 0.8258\n",
      "Epoch 493/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8583 - acc: 0.7350\n",
      "Epoch 00493: val_loss did not improve from 0.61852\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8583 - acc: 0.7350 - val_loss: 0.6203 - val_acc: 0.8276\n",
      "Epoch 494/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8569 - acc: 0.7365\n",
      "Epoch 00494: val_loss did not improve from 0.61852\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.8569 - acc: 0.7365 - val_loss: 0.6226 - val_acc: 0.8237\n",
      "Epoch 495/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8617 - acc: 0.7368\n",
      "Epoch 00495: val_loss improved from 0.61852 to 0.61686, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv_checkpoint/495-0.6169.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.8618 - acc: 0.7368 - val_loss: 0.6169 - val_acc: 0.8267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8608 - acc: 0.7336\n",
      "Epoch 00496: val_loss did not improve from 0.61686\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.8608 - acc: 0.7336 - val_loss: 0.6329 - val_acc: 0.8213\n",
      "Epoch 497/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8611 - acc: 0.7349\n",
      "Epoch 00497: val_loss did not improve from 0.61686\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.8611 - acc: 0.7349 - val_loss: 0.6278 - val_acc: 0.8234\n",
      "Epoch 498/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8615 - acc: 0.7358\n",
      "Epoch 00498: val_loss did not improve from 0.61686\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8615 - acc: 0.7358 - val_loss: 0.6189 - val_acc: 0.8269\n",
      "Epoch 499/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8588 - acc: 0.7358\n",
      "Epoch 00499: val_loss did not improve from 0.61686\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.8590 - acc: 0.7357 - val_loss: 0.6250 - val_acc: 0.8265\n",
      "Epoch 500/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8586 - acc: 0.7371\n",
      "Epoch 00500: val_loss did not improve from 0.61686\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.8587 - acc: 0.7371 - val_loss: 0.6241 - val_acc: 0.8230\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 277us/sample - loss: 0.6655 - acc: 0.8000\n",
      "Loss: 0.6654508444255263 Accuracy: 0.8\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6838 - acc: 0.1191\n",
      "Epoch 00001: val_loss improved from inf to 2.50539, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/001-2.5054.hdf5\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 2.6838 - acc: 0.1191 - val_loss: 2.5054 - val_acc: 0.2392\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3724 - acc: 0.2274\n",
      "Epoch 00002: val_loss improved from 2.50539 to 2.15333, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/002-2.1533.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 2.3724 - acc: 0.2273 - val_loss: 2.1533 - val_acc: 0.3594\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1820 - acc: 0.2787\n",
      "Epoch 00003: val_loss improved from 2.15333 to 1.98541, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/003-1.9854.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 2.1819 - acc: 0.2787 - val_loss: 1.9854 - val_acc: 0.4100\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0686 - acc: 0.3141\n",
      "Epoch 00004: val_loss improved from 1.98541 to 1.88361, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/004-1.8836.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 2.0686 - acc: 0.3141 - val_loss: 1.8836 - val_acc: 0.4323\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9806 - acc: 0.3409\n",
      "Epoch 00005: val_loss improved from 1.88361 to 1.78699, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/005-1.7870.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 1.9807 - acc: 0.3409 - val_loss: 1.7870 - val_acc: 0.4635\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9120 - acc: 0.3677\n",
      "Epoch 00006: val_loss improved from 1.78699 to 1.71458, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/006-1.7146.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 1.9120 - acc: 0.3677 - val_loss: 1.7146 - val_acc: 0.4859\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8437 - acc: 0.3908\n",
      "Epoch 00007: val_loss improved from 1.71458 to 1.66287, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/007-1.6629.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 1.8438 - acc: 0.3907 - val_loss: 1.6629 - val_acc: 0.5139\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7920 - acc: 0.4107\n",
      "Epoch 00008: val_loss improved from 1.66287 to 1.58908, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/008-1.5891.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 1.7920 - acc: 0.4107 - val_loss: 1.5891 - val_acc: 0.5253\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7390 - acc: 0.4300\n",
      "Epoch 00009: val_loss improved from 1.58908 to 1.53766, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/009-1.5377.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 1.7389 - acc: 0.4301 - val_loss: 1.5377 - val_acc: 0.5439\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6905 - acc: 0.4503\n",
      "Epoch 00010: val_loss improved from 1.53766 to 1.50495, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/010-1.5049.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 1.6905 - acc: 0.4502 - val_loss: 1.5049 - val_acc: 0.5660\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6484 - acc: 0.4676\n",
      "Epoch 00011: val_loss improved from 1.50495 to 1.44063, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/011-1.4406.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 1.6483 - acc: 0.4676 - val_loss: 1.4406 - val_acc: 0.5740\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6105 - acc: 0.4762\n",
      "Epoch 00012: val_loss improved from 1.44063 to 1.39929, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/012-1.3993.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 1.6103 - acc: 0.4762 - val_loss: 1.3993 - val_acc: 0.5938\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5729 - acc: 0.4921\n",
      "Epoch 00013: val_loss improved from 1.39929 to 1.37371, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/013-1.3737.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 1.5729 - acc: 0.4921 - val_loss: 1.3737 - val_acc: 0.5849\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5399 - acc: 0.5027\n",
      "Epoch 00014: val_loss improved from 1.37371 to 1.35028, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/014-1.3503.hdf5\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 1.5399 - acc: 0.5027 - val_loss: 1.3503 - val_acc: 0.6010\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5054 - acc: 0.5168\n",
      "Epoch 00015: val_loss improved from 1.35028 to 1.29651, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/015-1.2965.hdf5\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 1.5054 - acc: 0.5168 - val_loss: 1.2965 - val_acc: 0.6208\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4783 - acc: 0.5275\n",
      "Epoch 00016: val_loss improved from 1.29651 to 1.27307, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/016-1.2731.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 1.4783 - acc: 0.5275 - val_loss: 1.2731 - val_acc: 0.6303\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4521 - acc: 0.5325\n",
      "Epoch 00017: val_loss improved from 1.27307 to 1.25141, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/017-1.2514.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 1.4521 - acc: 0.5326 - val_loss: 1.2514 - val_acc: 0.6392\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4319 - acc: 0.5472\n",
      "Epoch 00018: val_loss improved from 1.25141 to 1.22142, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/018-1.2214.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 1.4319 - acc: 0.5472 - val_loss: 1.2214 - val_acc: 0.6466\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4088 - acc: 0.5544\n",
      "Epoch 00019: val_loss improved from 1.22142 to 1.20084, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/019-1.2008.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 1.4089 - acc: 0.5544 - val_loss: 1.2008 - val_acc: 0.6520\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3849 - acc: 0.5643\n",
      "Epoch 00020: val_loss improved from 1.20084 to 1.18079, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/020-1.1808.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 1.3849 - acc: 0.5643 - val_loss: 1.1808 - val_acc: 0.6629\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3603 - acc: 0.5685\n",
      "Epoch 00021: val_loss improved from 1.18079 to 1.15523, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/021-1.1552.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 1.3602 - acc: 0.5685 - val_loss: 1.1552 - val_acc: 0.6639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3416 - acc: 0.5764\n",
      "Epoch 00022: val_loss improved from 1.15523 to 1.13259, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/022-1.1326.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 1.3417 - acc: 0.5763 - val_loss: 1.1326 - val_acc: 0.6650\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3216 - acc: 0.5841\n",
      "Epoch 00023: val_loss improved from 1.13259 to 1.13253, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/023-1.1325.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 1.3216 - acc: 0.5841 - val_loss: 1.1325 - val_acc: 0.6746\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3093 - acc: 0.5904\n",
      "Epoch 00024: val_loss did not improve from 1.13253\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 1.3093 - acc: 0.5903 - val_loss: 1.1378 - val_acc: 0.6671\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2928 - acc: 0.5949\n",
      "Epoch 00025: val_loss improved from 1.13253 to 1.08785, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/025-1.0879.hdf5\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 1.2927 - acc: 0.5950 - val_loss: 1.0879 - val_acc: 0.6862\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2719 - acc: 0.6046\n",
      "Epoch 00026: val_loss did not improve from 1.08785\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 1.2718 - acc: 0.6047 - val_loss: 1.0944 - val_acc: 0.6832\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2596 - acc: 0.6077\n",
      "Epoch 00027: val_loss improved from 1.08785 to 1.06706, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/027-1.0671.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 1.2596 - acc: 0.6077 - val_loss: 1.0671 - val_acc: 0.6972\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2435 - acc: 0.6154\n",
      "Epoch 00028: val_loss improved from 1.06706 to 1.04745, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/028-1.0475.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 1.2435 - acc: 0.6154 - val_loss: 1.0475 - val_acc: 0.7011\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2268 - acc: 0.6219\n",
      "Epoch 00029: val_loss improved from 1.04745 to 1.04171, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/029-1.0417.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 1.2267 - acc: 0.6219 - val_loss: 1.0417 - val_acc: 0.7009\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2082 - acc: 0.6286\n",
      "Epoch 00030: val_loss improved from 1.04171 to 1.00953, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/030-1.0095.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 1.2081 - acc: 0.6286 - val_loss: 1.0095 - val_acc: 0.7079\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2022 - acc: 0.6314\n",
      "Epoch 00031: val_loss improved from 1.00953 to 0.98860, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/031-0.9886.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 1.2021 - acc: 0.6315 - val_loss: 0.9886 - val_acc: 0.7209\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1801 - acc: 0.6357\n",
      "Epoch 00032: val_loss improved from 0.98860 to 0.97512, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/032-0.9751.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 1.1801 - acc: 0.6356 - val_loss: 0.9751 - val_acc: 0.7233\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1740 - acc: 0.6407\n",
      "Epoch 00033: val_loss did not improve from 0.97512\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 1.1740 - acc: 0.6406 - val_loss: 1.0085 - val_acc: 0.7032\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1599 - acc: 0.6445\n",
      "Epoch 00034: val_loss improved from 0.97512 to 0.95120, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/034-0.9512.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 1.1601 - acc: 0.6445 - val_loss: 0.9512 - val_acc: 0.7331\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1442 - acc: 0.6487\n",
      "Epoch 00035: val_loss improved from 0.95120 to 0.94102, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/035-0.9410.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 1.1443 - acc: 0.6487 - val_loss: 0.9410 - val_acc: 0.7396\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1411 - acc: 0.6518\n",
      "Epoch 00036: val_loss improved from 0.94102 to 0.92928, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/036-0.9293.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 1.1411 - acc: 0.6518 - val_loss: 0.9293 - val_acc: 0.7342\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1293 - acc: 0.6521\n",
      "Epoch 00037: val_loss improved from 0.92928 to 0.91910, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/037-0.9191.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 1.1293 - acc: 0.6521 - val_loss: 0.9191 - val_acc: 0.7407\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1137 - acc: 0.6579\n",
      "Epoch 00038: val_loss improved from 0.91910 to 0.90571, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/038-0.9057.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 1.1137 - acc: 0.6579 - val_loss: 0.9057 - val_acc: 0.7440\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0956 - acc: 0.6653\n",
      "Epoch 00039: val_loss improved from 0.90571 to 0.89679, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/039-0.8968.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 1.0955 - acc: 0.6653 - val_loss: 0.8968 - val_acc: 0.7466\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0863 - acc: 0.6680\n",
      "Epoch 00040: val_loss did not improve from 0.89679\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 1.0863 - acc: 0.6680 - val_loss: 0.9004 - val_acc: 0.7468\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0734 - acc: 0.6733\n",
      "Epoch 00041: val_loss improved from 0.89679 to 0.87158, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/041-0.8716.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 1.0733 - acc: 0.6733 - val_loss: 0.8716 - val_acc: 0.7526\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0643 - acc: 0.6753\n",
      "Epoch 00042: val_loss did not improve from 0.87158\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 1.0643 - acc: 0.6753 - val_loss: 0.8733 - val_acc: 0.7489\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0616 - acc: 0.6781\n",
      "Epoch 00043: val_loss improved from 0.87158 to 0.84942, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/043-0.8494.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 1.0615 - acc: 0.6781 - val_loss: 0.8494 - val_acc: 0.7547\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0463 - acc: 0.6799\n",
      "Epoch 00044: val_loss improved from 0.84942 to 0.83680, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/044-0.8368.hdf5\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 1.0463 - acc: 0.6799 - val_loss: 0.8368 - val_acc: 0.7640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0375 - acc: 0.6844\n",
      "Epoch 00045: val_loss improved from 0.83680 to 0.82647, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/045-0.8265.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 1.0375 - acc: 0.6844 - val_loss: 0.8265 - val_acc: 0.7673\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0289 - acc: 0.6879\n",
      "Epoch 00046: val_loss improved from 0.82647 to 0.81804, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/046-0.8180.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 1.0289 - acc: 0.6879 - val_loss: 0.8180 - val_acc: 0.7692\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0188 - acc: 0.6903\n",
      "Epoch 00047: val_loss improved from 0.81804 to 0.81426, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/047-0.8143.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 1.0187 - acc: 0.6903 - val_loss: 0.8143 - val_acc: 0.7685\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0109 - acc: 0.6927\n",
      "Epoch 00048: val_loss improved from 0.81426 to 0.79812, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/048-0.7981.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 1.0108 - acc: 0.6927 - val_loss: 0.7981 - val_acc: 0.7699\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0019 - acc: 0.6964\n",
      "Epoch 00049: val_loss improved from 0.79812 to 0.79154, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/049-0.7915.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 1.0021 - acc: 0.6964 - val_loss: 0.7915 - val_acc: 0.7759\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9950 - acc: 0.7009\n",
      "Epoch 00050: val_loss improved from 0.79154 to 0.78254, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/050-0.7825.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.9950 - acc: 0.7009 - val_loss: 0.7825 - val_acc: 0.7754\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9815 - acc: 0.7043\n",
      "Epoch 00051: val_loss improved from 0.78254 to 0.77570, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/051-0.7757.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.9815 - acc: 0.7043 - val_loss: 0.7757 - val_acc: 0.7799\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9715 - acc: 0.7081\n",
      "Epoch 00052: val_loss improved from 0.77570 to 0.76194, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/052-0.7619.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.9715 - acc: 0.7081 - val_loss: 0.7619 - val_acc: 0.7850\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9728 - acc: 0.7092\n",
      "Epoch 00053: val_loss improved from 0.76194 to 0.75579, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/053-0.7558.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.9727 - acc: 0.7092 - val_loss: 0.7558 - val_acc: 0.7878\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9619 - acc: 0.7105\n",
      "Epoch 00054: val_loss improved from 0.75579 to 0.74306, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/054-0.7431.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.9619 - acc: 0.7106 - val_loss: 0.7431 - val_acc: 0.7945\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9608 - acc: 0.7128\n",
      "Epoch 00055: val_loss did not improve from 0.74306\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.9608 - acc: 0.7128 - val_loss: 0.7515 - val_acc: 0.7852\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9469 - acc: 0.7129\n",
      "Epoch 00056: val_loss improved from 0.74306 to 0.73747, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/056-0.7375.hdf5\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.9468 - acc: 0.7129 - val_loss: 0.7375 - val_acc: 0.7915\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9412 - acc: 0.7157\n",
      "Epoch 00057: val_loss did not improve from 0.73747\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.9412 - acc: 0.7157 - val_loss: 0.7418 - val_acc: 0.7855\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9338 - acc: 0.7177\n",
      "Epoch 00058: val_loss improved from 0.73747 to 0.72742, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/058-0.7274.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.9337 - acc: 0.7177 - val_loss: 0.7274 - val_acc: 0.7929\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9329 - acc: 0.7196\n",
      "Epoch 00059: val_loss improved from 0.72742 to 0.72447, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/059-0.7245.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.9329 - acc: 0.7197 - val_loss: 0.7245 - val_acc: 0.7964\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9301 - acc: 0.7201\n",
      "Epoch 00060: val_loss improved from 0.72447 to 0.71181, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/060-0.7118.hdf5\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.9302 - acc: 0.7201 - val_loss: 0.7118 - val_acc: 0.7962\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9175 - acc: 0.7248\n",
      "Epoch 00061: val_loss did not improve from 0.71181\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.9175 - acc: 0.7248 - val_loss: 0.7291 - val_acc: 0.7941\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9084 - acc: 0.7299\n",
      "Epoch 00062: val_loss improved from 0.71181 to 0.68943, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/062-0.6894.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.9084 - acc: 0.7300 - val_loss: 0.6894 - val_acc: 0.8060\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9086 - acc: 0.7275\n",
      "Epoch 00063: val_loss improved from 0.68943 to 0.68292, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/063-0.6829.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.9087 - acc: 0.7275 - val_loss: 0.6829 - val_acc: 0.8055\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9021 - acc: 0.7315\n",
      "Epoch 00064: val_loss did not improve from 0.68292\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.9021 - acc: 0.7314 - val_loss: 0.6880 - val_acc: 0.8020\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8966 - acc: 0.7319\n",
      "Epoch 00065: val_loss did not improve from 0.68292\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.8968 - acc: 0.7319 - val_loss: 0.6852 - val_acc: 0.8032\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8978 - acc: 0.7290\n",
      "Epoch 00066: val_loss improved from 0.68292 to 0.66904, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/066-0.6690.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.8978 - acc: 0.7290 - val_loss: 0.6690 - val_acc: 0.8116\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8865 - acc: 0.7354\n",
      "Epoch 00067: val_loss did not improve from 0.66904\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.8866 - acc: 0.7353 - val_loss: 0.6767 - val_acc: 0.8046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8810 - acc: 0.7354\n",
      "Epoch 00068: val_loss did not improve from 0.66904\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.8810 - acc: 0.7354 - val_loss: 0.6739 - val_acc: 0.8050\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8767 - acc: 0.7373\n",
      "Epoch 00069: val_loss improved from 0.66904 to 0.65970, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/069-0.6597.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.8766 - acc: 0.7373 - val_loss: 0.6597 - val_acc: 0.8099\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8615 - acc: 0.7418\n",
      "Epoch 00070: val_loss did not improve from 0.65970\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.8615 - acc: 0.7418 - val_loss: 0.6754 - val_acc: 0.8085\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8644 - acc: 0.7422\n",
      "Epoch 00071: val_loss improved from 0.65970 to 0.65537, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/071-0.6554.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.8644 - acc: 0.7422 - val_loss: 0.6554 - val_acc: 0.8099\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8615 - acc: 0.7432\n",
      "Epoch 00072: val_loss improved from 0.65537 to 0.65240, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/072-0.6524.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.8614 - acc: 0.7432 - val_loss: 0.6524 - val_acc: 0.8141\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8507 - acc: 0.7441\n",
      "Epoch 00073: val_loss improved from 0.65240 to 0.65044, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/073-0.6504.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.8508 - acc: 0.7441 - val_loss: 0.6504 - val_acc: 0.8120\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8546 - acc: 0.7453\n",
      "Epoch 00074: val_loss improved from 0.65044 to 0.64059, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/074-0.6406.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.8546 - acc: 0.7453 - val_loss: 0.6406 - val_acc: 0.8155\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8530 - acc: 0.7461\n",
      "Epoch 00075: val_loss improved from 0.64059 to 0.62241, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/075-0.6224.hdf5\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.8531 - acc: 0.7461 - val_loss: 0.6224 - val_acc: 0.8244\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8394 - acc: 0.7480\n",
      "Epoch 00076: val_loss did not improve from 0.62241\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.8396 - acc: 0.7481 - val_loss: 0.6300 - val_acc: 0.8164\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8372 - acc: 0.7485\n",
      "Epoch 00077: val_loss improved from 0.62241 to 0.62074, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/077-0.6207.hdf5\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.8372 - acc: 0.7485 - val_loss: 0.6207 - val_acc: 0.8248\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8283 - acc: 0.7576\n",
      "Epoch 00078: val_loss did not improve from 0.62074\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.8283 - acc: 0.7576 - val_loss: 0.6274 - val_acc: 0.8181\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8268 - acc: 0.7531\n",
      "Epoch 00079: val_loss improved from 0.62074 to 0.61858, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/079-0.6186.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.8268 - acc: 0.7531 - val_loss: 0.6186 - val_acc: 0.8227\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8295 - acc: 0.7535\n",
      "Epoch 00080: val_loss improved from 0.61858 to 0.61614, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/080-0.6161.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.8294 - acc: 0.7535 - val_loss: 0.6161 - val_acc: 0.8185\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8194 - acc: 0.7551\n",
      "Epoch 00081: val_loss improved from 0.61614 to 0.61518, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/081-0.6152.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.8193 - acc: 0.7551 - val_loss: 0.6152 - val_acc: 0.8232\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8214 - acc: 0.7566\n",
      "Epoch 00082: val_loss improved from 0.61518 to 0.59170, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/082-0.5917.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.8214 - acc: 0.7566 - val_loss: 0.5917 - val_acc: 0.8309\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8043 - acc: 0.7597\n",
      "Epoch 00083: val_loss improved from 0.59170 to 0.59132, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/083-0.5913.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.8043 - acc: 0.7597 - val_loss: 0.5913 - val_acc: 0.8276\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8132 - acc: 0.7591\n",
      "Epoch 00084: val_loss did not improve from 0.59132\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.8132 - acc: 0.7591 - val_loss: 0.5960 - val_acc: 0.8274\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8024 - acc: 0.7630\n",
      "Epoch 00085: val_loss did not improve from 0.59132\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.8024 - acc: 0.7629 - val_loss: 0.5947 - val_acc: 0.8316\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8008 - acc: 0.7637\n",
      "Epoch 00086: val_loss improved from 0.59132 to 0.58185, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/086-0.5818.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.8010 - acc: 0.7636 - val_loss: 0.5818 - val_acc: 0.8339\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8002 - acc: 0.7635\n",
      "Epoch 00087: val_loss improved from 0.58185 to 0.57991, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/087-0.5799.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.8002 - acc: 0.7635 - val_loss: 0.5799 - val_acc: 0.8344\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7894 - acc: 0.7671\n",
      "Epoch 00088: val_loss improved from 0.57991 to 0.56639, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/088-0.5664.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.7894 - acc: 0.7672 - val_loss: 0.5664 - val_acc: 0.8348\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7903 - acc: 0.7643\n",
      "Epoch 00089: val_loss did not improve from 0.56639\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.7904 - acc: 0.7642 - val_loss: 0.5815 - val_acc: 0.8362\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7822 - acc: 0.7693\n",
      "Epoch 00090: val_loss improved from 0.56639 to 0.56635, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/090-0.5663.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.7822 - acc: 0.7694 - val_loss: 0.5663 - val_acc: 0.8365\n",
      "Epoch 91/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7797 - acc: 0.7704\n",
      "Epoch 00091: val_loss improved from 0.56635 to 0.55967, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/091-0.5597.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.7796 - acc: 0.7704 - val_loss: 0.5597 - val_acc: 0.8407\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7758 - acc: 0.7707\n",
      "Epoch 00092: val_loss did not improve from 0.55967\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.7758 - acc: 0.7708 - val_loss: 0.5675 - val_acc: 0.8390\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7739 - acc: 0.7703\n",
      "Epoch 00093: val_loss did not improve from 0.55967\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.7739 - acc: 0.7703 - val_loss: 0.5601 - val_acc: 0.8386\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7727 - acc: 0.7701\n",
      "Epoch 00094: val_loss did not improve from 0.55967\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.7726 - acc: 0.7701 - val_loss: 0.5635 - val_acc: 0.8416\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7649 - acc: 0.7723\n",
      "Epoch 00095: val_loss improved from 0.55967 to 0.55534, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/095-0.5553.hdf5\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.7649 - acc: 0.7723 - val_loss: 0.5553 - val_acc: 0.8416\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7624 - acc: 0.7727\n",
      "Epoch 00096: val_loss improved from 0.55534 to 0.54173, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/096-0.5417.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.7624 - acc: 0.7727 - val_loss: 0.5417 - val_acc: 0.8463\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7575 - acc: 0.7767\n",
      "Epoch 00097: val_loss did not improve from 0.54173\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.7575 - acc: 0.7767 - val_loss: 0.5504 - val_acc: 0.8425\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7511 - acc: 0.7746\n",
      "Epoch 00098: val_loss improved from 0.54173 to 0.53900, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/098-0.5390.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.7510 - acc: 0.7747 - val_loss: 0.5390 - val_acc: 0.8467\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7542 - acc: 0.7762\n",
      "Epoch 00099: val_loss did not improve from 0.53900\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.7542 - acc: 0.7762 - val_loss: 0.5474 - val_acc: 0.8439\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7491 - acc: 0.7770\n",
      "Epoch 00100: val_loss improved from 0.53900 to 0.53384, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/100-0.5338.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.7491 - acc: 0.7769 - val_loss: 0.5338 - val_acc: 0.8479\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7449 - acc: 0.7794\n",
      "Epoch 00101: val_loss did not improve from 0.53384\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.7449 - acc: 0.7794 - val_loss: 0.5381 - val_acc: 0.8532\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7428 - acc: 0.7795\n",
      "Epoch 00102: val_loss improved from 0.53384 to 0.53330, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/102-0.5333.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.7427 - acc: 0.7795 - val_loss: 0.5333 - val_acc: 0.8479\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7399 - acc: 0.7785\n",
      "Epoch 00103: val_loss improved from 0.53330 to 0.53005, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/103-0.5300.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.7399 - acc: 0.7785 - val_loss: 0.5300 - val_acc: 0.8519\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7408 - acc: 0.7800\n",
      "Epoch 00104: val_loss improved from 0.53005 to 0.52741, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/104-0.5274.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.7408 - acc: 0.7799 - val_loss: 0.5274 - val_acc: 0.8553\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7274 - acc: 0.7845\n",
      "Epoch 00105: val_loss improved from 0.52741 to 0.52450, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/105-0.5245.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.7274 - acc: 0.7845 - val_loss: 0.5245 - val_acc: 0.8486\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7296 - acc: 0.7846\n",
      "Epoch 00106: val_loss improved from 0.52450 to 0.52028, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/106-0.5203.hdf5\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.7296 - acc: 0.7846 - val_loss: 0.5203 - val_acc: 0.8570\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7276 - acc: 0.7829\n",
      "Epoch 00107: val_loss improved from 0.52028 to 0.51602, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/107-0.5160.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.7277 - acc: 0.7828 - val_loss: 0.5160 - val_acc: 0.8565\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7233 - acc: 0.7851\n",
      "Epoch 00108: val_loss did not improve from 0.51602\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.7232 - acc: 0.7851 - val_loss: 0.5332 - val_acc: 0.8474\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7229 - acc: 0.7853\n",
      "Epoch 00109: val_loss did not improve from 0.51602\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.7229 - acc: 0.7852 - val_loss: 0.5205 - val_acc: 0.8488\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7202 - acc: 0.7862\n",
      "Epoch 00110: val_loss improved from 0.51602 to 0.51421, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/110-0.5142.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.7202 - acc: 0.7862 - val_loss: 0.5142 - val_acc: 0.8493\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7069 - acc: 0.7897\n",
      "Epoch 00111: val_loss improved from 0.51421 to 0.50611, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/111-0.5061.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.7069 - acc: 0.7897 - val_loss: 0.5061 - val_acc: 0.8567\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7105 - acc: 0.7890\n",
      "Epoch 00112: val_loss did not improve from 0.50611\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.7105 - acc: 0.7889 - val_loss: 0.5124 - val_acc: 0.8612\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7091 - acc: 0.7905\n",
      "Epoch 00113: val_loss improved from 0.50611 to 0.49846, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/113-0.4985.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.7091 - acc: 0.7905 - val_loss: 0.4985 - val_acc: 0.8588\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7020 - acc: 0.7929\n",
      "Epoch 00114: val_loss did not improve from 0.49846\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.7020 - acc: 0.7929 - val_loss: 0.5061 - val_acc: 0.8549\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7027 - acc: 0.7914\n",
      "Epoch 00115: val_loss improved from 0.49846 to 0.48852, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/115-0.4885.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.7026 - acc: 0.7914 - val_loss: 0.4885 - val_acc: 0.8675\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7082 - acc: 0.7918\n",
      "Epoch 00116: val_loss did not improve from 0.48852\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.7083 - acc: 0.7918 - val_loss: 0.4913 - val_acc: 0.8665\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6983 - acc: 0.7929\n",
      "Epoch 00117: val_loss did not improve from 0.48852\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.6983 - acc: 0.7929 - val_loss: 0.4896 - val_acc: 0.8658\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6922 - acc: 0.7941\n",
      "Epoch 00118: val_loss improved from 0.48852 to 0.48145, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/118-0.4815.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.6922 - acc: 0.7941 - val_loss: 0.4815 - val_acc: 0.8647\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6889 - acc: 0.7948\n",
      "Epoch 00119: val_loss did not improve from 0.48145\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.6889 - acc: 0.7948 - val_loss: 0.4971 - val_acc: 0.8612\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6919 - acc: 0.7954\n",
      "Epoch 00120: val_loss improved from 0.48145 to 0.48070, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/120-0.4807.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.6918 - acc: 0.7954 - val_loss: 0.4807 - val_acc: 0.8647\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6887 - acc: 0.7964\n",
      "Epoch 00121: val_loss did not improve from 0.48070\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.6892 - acc: 0.7964 - val_loss: 0.5287 - val_acc: 0.8484\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6868 - acc: 0.7972\n",
      "Epoch 00122: val_loss did not improve from 0.48070\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.6868 - acc: 0.7972 - val_loss: 0.4816 - val_acc: 0.8717\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6762 - acc: 0.7985\n",
      "Epoch 00123: val_loss did not improve from 0.48070\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.6761 - acc: 0.7985 - val_loss: 0.4894 - val_acc: 0.8612\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6785 - acc: 0.7988\n",
      "Epoch 00124: val_loss did not improve from 0.48070\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.6784 - acc: 0.7988 - val_loss: 0.4899 - val_acc: 0.8682\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6796 - acc: 0.7977\n",
      "Epoch 00125: val_loss improved from 0.48070 to 0.47415, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/125-0.4741.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.6795 - acc: 0.7977 - val_loss: 0.4741 - val_acc: 0.8677\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6750 - acc: 0.8004\n",
      "Epoch 00126: val_loss improved from 0.47415 to 0.47327, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/126-0.4733.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.6750 - acc: 0.8004 - val_loss: 0.4733 - val_acc: 0.8696\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6795 - acc: 0.8005\n",
      "Epoch 00127: val_loss improved from 0.47327 to 0.46953, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/127-0.4695.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.6795 - acc: 0.8005 - val_loss: 0.4695 - val_acc: 0.8696\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6684 - acc: 0.8020\n",
      "Epoch 00128: val_loss did not improve from 0.46953\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.6684 - acc: 0.8020 - val_loss: 0.4715 - val_acc: 0.8714\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6646 - acc: 0.8042\n",
      "Epoch 00129: val_loss did not improve from 0.46953\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.6647 - acc: 0.8042 - val_loss: 0.4740 - val_acc: 0.8712\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6682 - acc: 0.8031\n",
      "Epoch 00130: val_loss improved from 0.46953 to 0.46108, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/130-0.4611.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.6682 - acc: 0.8032 - val_loss: 0.4611 - val_acc: 0.8761\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6629 - acc: 0.8037\n",
      "Epoch 00131: val_loss improved from 0.46108 to 0.45471, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/131-0.4547.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.6628 - acc: 0.8037 - val_loss: 0.4547 - val_acc: 0.8744\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6604 - acc: 0.8058\n",
      "Epoch 00132: val_loss did not improve from 0.45471\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.6603 - acc: 0.8058 - val_loss: 0.4639 - val_acc: 0.8775\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6578 - acc: 0.8040\n",
      "Epoch 00133: val_loss improved from 0.45471 to 0.45153, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/133-0.4515.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.6577 - acc: 0.8040 - val_loss: 0.4515 - val_acc: 0.8786\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6524 - acc: 0.8058\n",
      "Epoch 00134: val_loss improved from 0.45153 to 0.45104, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/134-0.4510.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.6524 - acc: 0.8058 - val_loss: 0.4510 - val_acc: 0.8775\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6590 - acc: 0.8050\n",
      "Epoch 00135: val_loss did not improve from 0.45104\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.6589 - acc: 0.8050 - val_loss: 0.4638 - val_acc: 0.8730\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6547 - acc: 0.8048\n",
      "Epoch 00136: val_loss did not improve from 0.45104\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.6547 - acc: 0.8048 - val_loss: 0.4645 - val_acc: 0.8705\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6502 - acc: 0.8081\n",
      "Epoch 00137: val_loss did not improve from 0.45104\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.6502 - acc: 0.8081 - val_loss: 0.4724 - val_acc: 0.8656\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6492 - acc: 0.8070\n",
      "Epoch 00138: val_loss improved from 0.45104 to 0.44634, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/138-0.4463.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.6493 - acc: 0.8070 - val_loss: 0.4463 - val_acc: 0.8812\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6430 - acc: 0.8118\n",
      "Epoch 00139: val_loss did not improve from 0.44634\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.6431 - acc: 0.8117 - val_loss: 0.4485 - val_acc: 0.8740\n",
      "Epoch 140/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6492 - acc: 0.8068\n",
      "Epoch 00140: val_loss did not improve from 0.44634\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.6492 - acc: 0.8068 - val_loss: 0.4860 - val_acc: 0.8684\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6504 - acc: 0.8060\n",
      "Epoch 00141: val_loss did not improve from 0.44634\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.6503 - acc: 0.8060 - val_loss: 0.4756 - val_acc: 0.8684\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6402 - acc: 0.8108\n",
      "Epoch 00142: val_loss improved from 0.44634 to 0.44205, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/142-0.4420.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.6401 - acc: 0.8108 - val_loss: 0.4420 - val_acc: 0.8777\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6396 - acc: 0.8098\n",
      "Epoch 00143: val_loss improved from 0.44205 to 0.44170, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/143-0.4417.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.6395 - acc: 0.8098 - val_loss: 0.4417 - val_acc: 0.8779\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6366 - acc: 0.8115\n",
      "Epoch 00144: val_loss did not improve from 0.44170\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.6366 - acc: 0.8115 - val_loss: 0.4433 - val_acc: 0.8789\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6314 - acc: 0.8141\n",
      "Epoch 00145: val_loss improved from 0.44170 to 0.43351, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/145-0.4335.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.6315 - acc: 0.8141 - val_loss: 0.4335 - val_acc: 0.8835\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6308 - acc: 0.8156\n",
      "Epoch 00146: val_loss did not improve from 0.43351\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.6307 - acc: 0.8157 - val_loss: 0.4615 - val_acc: 0.8726\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6314 - acc: 0.8107\n",
      "Epoch 00147: val_loss did not improve from 0.43351\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.6315 - acc: 0.8106 - val_loss: 0.4378 - val_acc: 0.8814\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6349 - acc: 0.8134\n",
      "Epoch 00148: val_loss did not improve from 0.43351\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.6349 - acc: 0.8134 - val_loss: 0.4383 - val_acc: 0.8824\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6254 - acc: 0.8144\n",
      "Epoch 00149: val_loss improved from 0.43351 to 0.42806, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/149-0.4281.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.6256 - acc: 0.8143 - val_loss: 0.4281 - val_acc: 0.8812\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6216 - acc: 0.8169\n",
      "Epoch 00150: val_loss did not improve from 0.42806\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.6215 - acc: 0.8169 - val_loss: 0.4326 - val_acc: 0.8814\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6221 - acc: 0.8148\n",
      "Epoch 00151: val_loss did not improve from 0.42806\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.6221 - acc: 0.8148 - val_loss: 0.4285 - val_acc: 0.8840\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6243 - acc: 0.8147\n",
      "Epoch 00152: val_loss improved from 0.42806 to 0.42714, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/152-0.4271.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.6244 - acc: 0.8147 - val_loss: 0.4271 - val_acc: 0.8835\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6189 - acc: 0.8168\n",
      "Epoch 00153: val_loss did not improve from 0.42714\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.6189 - acc: 0.8168 - val_loss: 0.4334 - val_acc: 0.8840\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6156 - acc: 0.8161\n",
      "Epoch 00154: val_loss did not improve from 0.42714\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.6155 - acc: 0.8161 - val_loss: 0.4328 - val_acc: 0.8868\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6141 - acc: 0.8184\n",
      "Epoch 00155: val_loss did not improve from 0.42714\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.6141 - acc: 0.8184 - val_loss: 0.4304 - val_acc: 0.8845\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6205 - acc: 0.8165\n",
      "Epoch 00156: val_loss did not improve from 0.42714\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.6205 - acc: 0.8165 - val_loss: 0.4273 - val_acc: 0.8849\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6136 - acc: 0.8169\n",
      "Epoch 00157: val_loss improved from 0.42714 to 0.42277, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/157-0.4228.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.6135 - acc: 0.8169 - val_loss: 0.4228 - val_acc: 0.8884\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6053 - acc: 0.8211\n",
      "Epoch 00158: val_loss improved from 0.42277 to 0.41950, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/158-0.4195.hdf5\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.6055 - acc: 0.8210 - val_loss: 0.4195 - val_acc: 0.8873\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6142 - acc: 0.8188\n",
      "Epoch 00159: val_loss did not improve from 0.41950\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.6142 - acc: 0.8188 - val_loss: 0.4267 - val_acc: 0.8861\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.8223\n",
      "Epoch 00160: val_loss improved from 0.41950 to 0.41507, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/160-0.4151.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.6031 - acc: 0.8223 - val_loss: 0.4151 - val_acc: 0.8901\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6054 - acc: 0.8191\n",
      "Epoch 00161: val_loss did not improve from 0.41507\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.6053 - acc: 0.8192 - val_loss: 0.4184 - val_acc: 0.8873\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6079 - acc: 0.8200\n",
      "Epoch 00162: val_loss improved from 0.41507 to 0.41203, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/162-0.4120.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.6078 - acc: 0.8201 - val_loss: 0.4120 - val_acc: 0.8882\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6026 - acc: 0.8229\n",
      "Epoch 00163: val_loss did not improve from 0.41203\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.6025 - acc: 0.8229 - val_loss: 0.4154 - val_acc: 0.8910\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5996 - acc: 0.8221\n",
      "Epoch 00164: val_loss did not improve from 0.41203\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.5996 - acc: 0.8222 - val_loss: 0.4362 - val_acc: 0.8826\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5948 - acc: 0.8230\n",
      "Epoch 00165: val_loss improved from 0.41203 to 0.40985, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/165-0.4098.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5948 - acc: 0.8230 - val_loss: 0.4098 - val_acc: 0.8894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5976 - acc: 0.8232\n",
      "Epoch 00166: val_loss did not improve from 0.40985\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5977 - acc: 0.8231 - val_loss: 0.4446 - val_acc: 0.8800\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5949 - acc: 0.8224\n",
      "Epoch 00167: val_loss did not improve from 0.40985\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.5948 - acc: 0.8224 - val_loss: 0.4133 - val_acc: 0.8887\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5942 - acc: 0.8240\n",
      "Epoch 00168: val_loss improved from 0.40985 to 0.40473, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/168-0.4047.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.5943 - acc: 0.8240 - val_loss: 0.4047 - val_acc: 0.8919\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5928 - acc: 0.8253\n",
      "Epoch 00169: val_loss improved from 0.40473 to 0.40379, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/169-0.4038.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.5929 - acc: 0.8253 - val_loss: 0.4038 - val_acc: 0.8935\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5852 - acc: 0.8244\n",
      "Epoch 00170: val_loss did not improve from 0.40379\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5851 - acc: 0.8244 - val_loss: 0.4086 - val_acc: 0.8905\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5858 - acc: 0.8261\n",
      "Epoch 00171: val_loss did not improve from 0.40379\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.5861 - acc: 0.8261 - val_loss: 0.4233 - val_acc: 0.8831\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5899 - acc: 0.8265\n",
      "Epoch 00172: val_loss did not improve from 0.40379\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.5899 - acc: 0.8265 - val_loss: 0.4082 - val_acc: 0.8926\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5875 - acc: 0.8268\n",
      "Epoch 00173: val_loss did not improve from 0.40379\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.5874 - acc: 0.8268 - val_loss: 0.4178 - val_acc: 0.8887\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5901 - acc: 0.8248\n",
      "Epoch 00174: val_loss did not improve from 0.40379\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5901 - acc: 0.8247 - val_loss: 0.4052 - val_acc: 0.8905\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5870 - acc: 0.8265\n",
      "Epoch 00175: val_loss improved from 0.40379 to 0.39971, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/175-0.3997.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.5869 - acc: 0.8265 - val_loss: 0.3997 - val_acc: 0.8938\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5862 - acc: 0.8261\n",
      "Epoch 00176: val_loss improved from 0.39971 to 0.39963, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/176-0.3996.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.5863 - acc: 0.8261 - val_loss: 0.3996 - val_acc: 0.8926\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5769 - acc: 0.8286\n",
      "Epoch 00177: val_loss did not improve from 0.39963\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.5769 - acc: 0.8286 - val_loss: 0.4068 - val_acc: 0.8884\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5770 - acc: 0.8296\n",
      "Epoch 00178: val_loss did not improve from 0.39963\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.5769 - acc: 0.8296 - val_loss: 0.3998 - val_acc: 0.8928\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5747 - acc: 0.8288\n",
      "Epoch 00179: val_loss did not improve from 0.39963\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.5747 - acc: 0.8287 - val_loss: 0.4035 - val_acc: 0.8921\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5769 - acc: 0.8285\n",
      "Epoch 00180: val_loss did not improve from 0.39963\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.5769 - acc: 0.8285 - val_loss: 0.4170 - val_acc: 0.8831\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5790 - acc: 0.8277\n",
      "Epoch 00181: val_loss improved from 0.39963 to 0.39814, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/181-0.3981.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.5790 - acc: 0.8277 - val_loss: 0.3981 - val_acc: 0.8945\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5764 - acc: 0.8292\n",
      "Epoch 00182: val_loss improved from 0.39814 to 0.39307, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/182-0.3931.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.5766 - acc: 0.8291 - val_loss: 0.3931 - val_acc: 0.8947\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5693 - acc: 0.8318\n",
      "Epoch 00183: val_loss improved from 0.39307 to 0.39233, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/183-0.3923.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5693 - acc: 0.8318 - val_loss: 0.3923 - val_acc: 0.8984\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5682 - acc: 0.8315\n",
      "Epoch 00184: val_loss improved from 0.39233 to 0.38936, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/184-0.3894.hdf5\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.5682 - acc: 0.8315 - val_loss: 0.3894 - val_acc: 0.8970\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5655 - acc: 0.8313\n",
      "Epoch 00185: val_loss did not improve from 0.38936\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.5654 - acc: 0.8313 - val_loss: 0.4013 - val_acc: 0.8940\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5682 - acc: 0.8319\n",
      "Epoch 00186: val_loss did not improve from 0.38936\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.5683 - acc: 0.8318 - val_loss: 0.4182 - val_acc: 0.8868\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5684 - acc: 0.8327\n",
      "Epoch 00187: val_loss did not improve from 0.38936\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.5684 - acc: 0.8327 - val_loss: 0.3924 - val_acc: 0.8933\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5673 - acc: 0.8313\n",
      "Epoch 00188: val_loss did not improve from 0.38936\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.5673 - acc: 0.8312 - val_loss: 0.3918 - val_acc: 0.8977\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5648 - acc: 0.8309\n",
      "Epoch 00189: val_loss did not improve from 0.38936\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.5649 - acc: 0.8309 - val_loss: 0.3895 - val_acc: 0.8954\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5591 - acc: 0.8326\n",
      "Epoch 00190: val_loss did not improve from 0.38936\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.5592 - acc: 0.8325 - val_loss: 0.3959 - val_acc: 0.8931\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5562 - acc: 0.8346\n",
      "Epoch 00191: val_loss improved from 0.38936 to 0.38777, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/191-0.3878.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.5562 - acc: 0.8345 - val_loss: 0.3878 - val_acc: 0.8963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5603 - acc: 0.8344\n",
      "Epoch 00192: val_loss did not improve from 0.38777\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5604 - acc: 0.8344 - val_loss: 0.3951 - val_acc: 0.8996\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5582 - acc: 0.8345\n",
      "Epoch 00193: val_loss did not improve from 0.38777\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.5583 - acc: 0.8345 - val_loss: 0.3888 - val_acc: 0.8966\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5577 - acc: 0.8338\n",
      "Epoch 00194: val_loss did not improve from 0.38777\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.5579 - acc: 0.8338 - val_loss: 0.3976 - val_acc: 0.8942\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5545 - acc: 0.8330\n",
      "Epoch 00195: val_loss did not improve from 0.38777\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.5547 - acc: 0.8330 - val_loss: 0.3958 - val_acc: 0.8961\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5542 - acc: 0.8349\n",
      "Epoch 00196: val_loss did not improve from 0.38777\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5543 - acc: 0.8349 - val_loss: 0.3895 - val_acc: 0.8959\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5505 - acc: 0.8366\n",
      "Epoch 00197: val_loss improved from 0.38777 to 0.38054, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/197-0.3805.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.5505 - acc: 0.8366 - val_loss: 0.3805 - val_acc: 0.8975\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5521 - acc: 0.8390\n",
      "Epoch 00198: val_loss improved from 0.38054 to 0.37757, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/198-0.3776.hdf5\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.5522 - acc: 0.8390 - val_loss: 0.3776 - val_acc: 0.8991\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5558 - acc: 0.8358\n",
      "Epoch 00199: val_loss did not improve from 0.37757\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.5558 - acc: 0.8358 - val_loss: 0.4016 - val_acc: 0.8921\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5553 - acc: 0.8354\n",
      "Epoch 00200: val_loss did not improve from 0.37757\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.5552 - acc: 0.8355 - val_loss: 0.3825 - val_acc: 0.8991\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5498 - acc: 0.8372\n",
      "Epoch 00201: val_loss did not improve from 0.37757\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.5497 - acc: 0.8372 - val_loss: 0.3984 - val_acc: 0.8928\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5501 - acc: 0.8385\n",
      "Epoch 00202: val_loss improved from 0.37757 to 0.37222, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/202-0.3722.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.5501 - acc: 0.8384 - val_loss: 0.3722 - val_acc: 0.9005\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5466 - acc: 0.8382\n",
      "Epoch 00203: val_loss did not improve from 0.37222\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.5466 - acc: 0.8382 - val_loss: 0.3979 - val_acc: 0.8933\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5445 - acc: 0.8368\n",
      "Epoch 00204: val_loss did not improve from 0.37222\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5448 - acc: 0.8367 - val_loss: 0.3948 - val_acc: 0.8973\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5475 - acc: 0.8345\n",
      "Epoch 00205: val_loss improved from 0.37222 to 0.37064, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/205-0.3706.hdf5\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.5475 - acc: 0.8345 - val_loss: 0.3706 - val_acc: 0.9031\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5463 - acc: 0.8388\n",
      "Epoch 00206: val_loss did not improve from 0.37064\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.5463 - acc: 0.8388 - val_loss: 0.3787 - val_acc: 0.9012\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5397 - acc: 0.8368\n",
      "Epoch 00207: val_loss did not improve from 0.37064\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.5397 - acc: 0.8368 - val_loss: 0.3752 - val_acc: 0.9036\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5373 - acc: 0.8389\n",
      "Epoch 00208: val_loss did not improve from 0.37064\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5372 - acc: 0.8389 - val_loss: 0.3821 - val_acc: 0.8984\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5402 - acc: 0.8374\n",
      "Epoch 00209: val_loss did not improve from 0.37064\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.5406 - acc: 0.8374 - val_loss: 0.3837 - val_acc: 0.8991\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5434 - acc: 0.8386\n",
      "Epoch 00210: val_loss did not improve from 0.37064\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5433 - acc: 0.8386 - val_loss: 0.3837 - val_acc: 0.8963\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5387 - acc: 0.8385\n",
      "Epoch 00211: val_loss did not improve from 0.37064\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.5387 - acc: 0.8384 - val_loss: 0.3928 - val_acc: 0.8926\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5370 - acc: 0.8395\n",
      "Epoch 00212: val_loss did not improve from 0.37064\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.5370 - acc: 0.8396 - val_loss: 0.3783 - val_acc: 0.9024\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5300 - acc: 0.8412\n",
      "Epoch 00213: val_loss did not improve from 0.37064\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.5300 - acc: 0.8412 - val_loss: 0.3774 - val_acc: 0.9008\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5370 - acc: 0.8395\n",
      "Epoch 00214: val_loss improved from 0.37064 to 0.36462, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/214-0.3646.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.5369 - acc: 0.8395 - val_loss: 0.3646 - val_acc: 0.9022\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5302 - acc: 0.8417\n",
      "Epoch 00215: val_loss did not improve from 0.36462\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.5304 - acc: 0.8417 - val_loss: 0.3647 - val_acc: 0.9029\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5305 - acc: 0.8418\n",
      "Epoch 00216: val_loss did not improve from 0.36462\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.5304 - acc: 0.8418 - val_loss: 0.3683 - val_acc: 0.9017\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5360 - acc: 0.8429\n",
      "Epoch 00217: val_loss did not improve from 0.36462\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.5363 - acc: 0.8428 - val_loss: 0.3718 - val_acc: 0.9040\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5325 - acc: 0.8406\n",
      "Epoch 00218: val_loss did not improve from 0.36462\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.5325 - acc: 0.8406 - val_loss: 0.3831 - val_acc: 0.8982\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5256 - acc: 0.8433\n",
      "Epoch 00219: val_loss improved from 0.36462 to 0.36374, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/219-0.3637.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.5255 - acc: 0.8433 - val_loss: 0.3637 - val_acc: 0.9057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5263 - acc: 0.8414\n",
      "Epoch 00220: val_loss did not improve from 0.36374\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.5263 - acc: 0.8415 - val_loss: 0.3691 - val_acc: 0.9029\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5333 - acc: 0.8418\n",
      "Epoch 00221: val_loss did not improve from 0.36374\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5332 - acc: 0.8418 - val_loss: 0.3712 - val_acc: 0.9047\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5300 - acc: 0.8408\n",
      "Epoch 00222: val_loss did not improve from 0.36374\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.5300 - acc: 0.8408 - val_loss: 0.3639 - val_acc: 0.9061\n",
      "Epoch 223/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5259 - acc: 0.8415\n",
      "Epoch 00223: val_loss did not improve from 0.36374\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5259 - acc: 0.8415 - val_loss: 0.3733 - val_acc: 0.8996\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5246 - acc: 0.8416\n",
      "Epoch 00224: val_loss did not improve from 0.36374\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.5246 - acc: 0.8416 - val_loss: 0.3876 - val_acc: 0.8994\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5257 - acc: 0.8437\n",
      "Epoch 00225: val_loss did not improve from 0.36374\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5257 - acc: 0.8437 - val_loss: 0.3651 - val_acc: 0.9045\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5172 - acc: 0.8445\n",
      "Epoch 00226: val_loss did not improve from 0.36374\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.5173 - acc: 0.8444 - val_loss: 0.3644 - val_acc: 0.9029\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5273 - acc: 0.8428\n",
      "Epoch 00227: val_loss improved from 0.36374 to 0.36362, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/227-0.3636.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.5273 - acc: 0.8428 - val_loss: 0.3636 - val_acc: 0.9026\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5229 - acc: 0.8440\n",
      "Epoch 00228: val_loss did not improve from 0.36362\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5229 - acc: 0.8441 - val_loss: 0.3680 - val_acc: 0.9029\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5205 - acc: 0.8440\n",
      "Epoch 00229: val_loss did not improve from 0.36362\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5205 - acc: 0.8440 - val_loss: 0.3641 - val_acc: 0.9052\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5149 - acc: 0.8447\n",
      "Epoch 00230: val_loss improved from 0.36362 to 0.35460, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/230-0.3546.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.5149 - acc: 0.8447 - val_loss: 0.3546 - val_acc: 0.9050\n",
      "Epoch 231/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5188 - acc: 0.8423\n",
      "Epoch 00231: val_loss improved from 0.35460 to 0.35319, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/231-0.3532.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.5188 - acc: 0.8422 - val_loss: 0.3532 - val_acc: 0.9066\n",
      "Epoch 232/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5196 - acc: 0.8455\n",
      "Epoch 00232: val_loss did not improve from 0.35319\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.5195 - acc: 0.8455 - val_loss: 0.3636 - val_acc: 0.9066\n",
      "Epoch 233/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5156 - acc: 0.8442\n",
      "Epoch 00233: val_loss did not improve from 0.35319\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5157 - acc: 0.8442 - val_loss: 0.3602 - val_acc: 0.9073\n",
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5165 - acc: 0.8443\n",
      "Epoch 00234: val_loss did not improve from 0.35319\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.5164 - acc: 0.8443 - val_loss: 0.3642 - val_acc: 0.9038\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5142 - acc: 0.8463\n",
      "Epoch 00235: val_loss did not improve from 0.35319\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.5142 - acc: 0.8463 - val_loss: 0.3674 - val_acc: 0.9038\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5191 - acc: 0.8443\n",
      "Epoch 00236: val_loss did not improve from 0.35319\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.5191 - acc: 0.8442 - val_loss: 0.3566 - val_acc: 0.9050\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5152 - acc: 0.8446\n",
      "Epoch 00237: val_loss did not improve from 0.35319\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.5152 - acc: 0.8446 - val_loss: 0.3596 - val_acc: 0.9061\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5113 - acc: 0.8468\n",
      "Epoch 00238: val_loss did not improve from 0.35319\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.5112 - acc: 0.8468 - val_loss: 0.3682 - val_acc: 0.9050\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5070 - acc: 0.8474\n",
      "Epoch 00239: val_loss did not improve from 0.35319\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.5069 - acc: 0.8474 - val_loss: 0.3573 - val_acc: 0.9059\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5070 - acc: 0.8489\n",
      "Epoch 00240: val_loss did not improve from 0.35319\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.5069 - acc: 0.8489 - val_loss: 0.3573 - val_acc: 0.9054\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5111 - acc: 0.8473\n",
      "Epoch 00241: val_loss improved from 0.35319 to 0.35128, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/241-0.3513.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.5110 - acc: 0.8473 - val_loss: 0.3513 - val_acc: 0.9087\n",
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5068 - acc: 0.8492\n",
      "Epoch 00242: val_loss did not improve from 0.35128\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.5068 - acc: 0.8492 - val_loss: 0.3722 - val_acc: 0.9008\n",
      "Epoch 243/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5053 - acc: 0.8473\n",
      "Epoch 00243: val_loss did not improve from 0.35128\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.5054 - acc: 0.8473 - val_loss: 0.3515 - val_acc: 0.9071\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5101 - acc: 0.8466\n",
      "Epoch 00244: val_loss improved from 0.35128 to 0.34978, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/244-0.3498.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.5101 - acc: 0.8466 - val_loss: 0.3498 - val_acc: 0.9106\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5007 - acc: 0.8500\n",
      "Epoch 00245: val_loss did not improve from 0.34978\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.5006 - acc: 0.8500 - val_loss: 0.3545 - val_acc: 0.9087\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5026 - acc: 0.8498\n",
      "Epoch 00246: val_loss did not improve from 0.34978\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5026 - acc: 0.8498 - val_loss: 0.3671 - val_acc: 0.9036\n",
      "Epoch 247/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5034 - acc: 0.8483\n",
      "Epoch 00247: val_loss did not improve from 0.34978\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5034 - acc: 0.8483 - val_loss: 0.3520 - val_acc: 0.9085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 248/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5032 - acc: 0.8473\n",
      "Epoch 00248: val_loss did not improve from 0.34978\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5032 - acc: 0.8473 - val_loss: 0.3518 - val_acc: 0.9068\n",
      "Epoch 249/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4986 - acc: 0.8486\n",
      "Epoch 00249: val_loss did not improve from 0.34978\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.4986 - acc: 0.8486 - val_loss: 0.3546 - val_acc: 0.9073\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5084 - acc: 0.8488\n",
      "Epoch 00250: val_loss did not improve from 0.34978\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.5083 - acc: 0.8488 - val_loss: 0.3564 - val_acc: 0.9096\n",
      "Epoch 251/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4944 - acc: 0.8519\n",
      "Epoch 00251: val_loss did not improve from 0.34978\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.4943 - acc: 0.8519 - val_loss: 0.3523 - val_acc: 0.9059\n",
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4993 - acc: 0.8497\n",
      "Epoch 00252: val_loss did not improve from 0.34978\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.4993 - acc: 0.8497 - val_loss: 0.3591 - val_acc: 0.9054\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4984 - acc: 0.8497\n",
      "Epoch 00253: val_loss did not improve from 0.34978\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.4985 - acc: 0.8497 - val_loss: 0.3519 - val_acc: 0.9068\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4975 - acc: 0.8509\n",
      "Epoch 00254: val_loss did not improve from 0.34978\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.4975 - acc: 0.8509 - val_loss: 0.3517 - val_acc: 0.9059\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4955 - acc: 0.8522\n",
      "Epoch 00255: val_loss did not improve from 0.34978\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.4956 - acc: 0.8522 - val_loss: 0.3500 - val_acc: 0.9092\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4927 - acc: 0.8528\n",
      "Epoch 00256: val_loss improved from 0.34978 to 0.34458, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/256-0.3446.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.4926 - acc: 0.8528 - val_loss: 0.3446 - val_acc: 0.9089\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4993 - acc: 0.8488\n",
      "Epoch 00257: val_loss did not improve from 0.34458\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.4993 - acc: 0.8489 - val_loss: 0.3454 - val_acc: 0.9092\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4964 - acc: 0.8523\n",
      "Epoch 00258: val_loss improved from 0.34458 to 0.34016, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/258-0.3402.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.4963 - acc: 0.8523 - val_loss: 0.3402 - val_acc: 0.9087\n",
      "Epoch 259/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4950 - acc: 0.8507\n",
      "Epoch 00259: val_loss did not improve from 0.34016\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.4950 - acc: 0.8507 - val_loss: 0.3426 - val_acc: 0.9106\n",
      "Epoch 260/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4945 - acc: 0.8519\n",
      "Epoch 00260: val_loss did not improve from 0.34016\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.4944 - acc: 0.8519 - val_loss: 0.3699 - val_acc: 0.9022\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4958 - acc: 0.8506\n",
      "Epoch 00261: val_loss did not improve from 0.34016\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.4957 - acc: 0.8506 - val_loss: 0.3417 - val_acc: 0.9099\n",
      "Epoch 262/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4949 - acc: 0.8494\n",
      "Epoch 00262: val_loss did not improve from 0.34016\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.4948 - acc: 0.8494 - val_loss: 0.3666 - val_acc: 0.9010\n",
      "Epoch 263/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4947 - acc: 0.8511\n",
      "Epoch 00263: val_loss did not improve from 0.34016\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.4948 - acc: 0.8511 - val_loss: 0.3477 - val_acc: 0.9089\n",
      "Epoch 264/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4857 - acc: 0.8534\n",
      "Epoch 00264: val_loss did not improve from 0.34016\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.4858 - acc: 0.8533 - val_loss: 0.3486 - val_acc: 0.9085\n",
      "Epoch 265/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4868 - acc: 0.8531\n",
      "Epoch 00265: val_loss improved from 0.34016 to 0.33865, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/265-0.3386.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.4868 - acc: 0.8531 - val_loss: 0.3386 - val_acc: 0.9126\n",
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4831 - acc: 0.8532\n",
      "Epoch 00266: val_loss did not improve from 0.33865\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.4831 - acc: 0.8531 - val_loss: 0.3393 - val_acc: 0.9106\n",
      "Epoch 267/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4831 - acc: 0.8544\n",
      "Epoch 00267: val_loss did not improve from 0.33865\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.4831 - acc: 0.8544 - val_loss: 0.3406 - val_acc: 0.9080\n",
      "Epoch 268/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4883 - acc: 0.8544\n",
      "Epoch 00268: val_loss did not improve from 0.33865\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.4884 - acc: 0.8544 - val_loss: 0.3445 - val_acc: 0.9108\n",
      "Epoch 269/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4865 - acc: 0.8530\n",
      "Epoch 00269: val_loss did not improve from 0.33865\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.4865 - acc: 0.8530 - val_loss: 0.3521 - val_acc: 0.9092\n",
      "Epoch 270/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4894 - acc: 0.8534\n",
      "Epoch 00270: val_loss did not improve from 0.33865\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.4895 - acc: 0.8534 - val_loss: 0.3440 - val_acc: 0.9087\n",
      "Epoch 271/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4857 - acc: 0.8532\n",
      "Epoch 00271: val_loss did not improve from 0.33865\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.4858 - acc: 0.8532 - val_loss: 0.3503 - val_acc: 0.9068\n",
      "Epoch 272/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4752 - acc: 0.8558\n",
      "Epoch 00272: val_loss improved from 0.33865 to 0.33426, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/272-0.3343.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.4753 - acc: 0.8558 - val_loss: 0.3343 - val_acc: 0.9126\n",
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4833 - acc: 0.8527\n",
      "Epoch 00273: val_loss did not improve from 0.33426\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.4834 - acc: 0.8527 - val_loss: 0.3379 - val_acc: 0.9147\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4801 - acc: 0.8547\n",
      "Epoch 00274: val_loss did not improve from 0.33426\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.4801 - acc: 0.8547 - val_loss: 0.3352 - val_acc: 0.9103\n",
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4834 - acc: 0.8543\n",
      "Epoch 00275: val_loss did not improve from 0.33426\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4833 - acc: 0.8543 - val_loss: 0.3366 - val_acc: 0.9115\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4812 - acc: 0.8551\n",
      "Epoch 00276: val_loss did not improve from 0.33426\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.4812 - acc: 0.8550 - val_loss: 0.3365 - val_acc: 0.9113\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4778 - acc: 0.8548\n",
      "Epoch 00277: val_loss did not improve from 0.33426\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.4777 - acc: 0.8548 - val_loss: 0.3402 - val_acc: 0.9110\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4771 - acc: 0.8542\n",
      "Epoch 00278: val_loss improved from 0.33426 to 0.33339, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/278-0.3334.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.4771 - acc: 0.8542 - val_loss: 0.3334 - val_acc: 0.9131\n",
      "Epoch 279/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4788 - acc: 0.8552\n",
      "Epoch 00279: val_loss did not improve from 0.33339\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.4788 - acc: 0.8552 - val_loss: 0.3391 - val_acc: 0.9150\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4807 - acc: 0.8553\n",
      "Epoch 00280: val_loss did not improve from 0.33339\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.4806 - acc: 0.8553 - val_loss: 0.3363 - val_acc: 0.9096\n",
      "Epoch 281/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4712 - acc: 0.8583\n",
      "Epoch 00281: val_loss did not improve from 0.33339\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.4711 - acc: 0.8583 - val_loss: 0.3397 - val_acc: 0.9115\n",
      "Epoch 282/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4693 - acc: 0.8561\n",
      "Epoch 00282: val_loss did not improve from 0.33339\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.4693 - acc: 0.8561 - val_loss: 0.3391 - val_acc: 0.9129\n",
      "Epoch 283/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4752 - acc: 0.8568\n",
      "Epoch 00283: val_loss did not improve from 0.33339\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.4752 - acc: 0.8568 - val_loss: 0.3534 - val_acc: 0.9092\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4810 - acc: 0.8565\n",
      "Epoch 00284: val_loss did not improve from 0.33339\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.4810 - acc: 0.8565 - val_loss: 0.3422 - val_acc: 0.9117\n",
      "Epoch 285/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4730 - acc: 0.8583\n",
      "Epoch 00285: val_loss did not improve from 0.33339\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.4730 - acc: 0.8583 - val_loss: 0.3383 - val_acc: 0.9110\n",
      "Epoch 286/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4750 - acc: 0.8547\n",
      "Epoch 00286: val_loss did not improve from 0.33339\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.4751 - acc: 0.8547 - val_loss: 0.3407 - val_acc: 0.9124\n",
      "Epoch 287/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4668 - acc: 0.8597\n",
      "Epoch 00287: val_loss improved from 0.33339 to 0.33179, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/287-0.3318.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.4667 - acc: 0.8597 - val_loss: 0.3318 - val_acc: 0.9138\n",
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4763 - acc: 0.8574\n",
      "Epoch 00288: val_loss improved from 0.33179 to 0.33115, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/288-0.3311.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.4763 - acc: 0.8574 - val_loss: 0.3311 - val_acc: 0.9161\n",
      "Epoch 289/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4720 - acc: 0.8581\n",
      "Epoch 00289: val_loss did not improve from 0.33115\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.4721 - acc: 0.8581 - val_loss: 0.3325 - val_acc: 0.9115\n",
      "Epoch 290/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4728 - acc: 0.8570\n",
      "Epoch 00290: val_loss did not improve from 0.33115\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.4728 - acc: 0.8570 - val_loss: 0.3373 - val_acc: 0.9113\n",
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4704 - acc: 0.8584\n",
      "Epoch 00291: val_loss did not improve from 0.33115\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.4703 - acc: 0.8584 - val_loss: 0.3362 - val_acc: 0.9108\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4635 - acc: 0.8593\n",
      "Epoch 00292: val_loss improved from 0.33115 to 0.33076, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/292-0.3308.hdf5\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.4635 - acc: 0.8593 - val_loss: 0.3308 - val_acc: 0.9157\n",
      "Epoch 293/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4643 - acc: 0.8592\n",
      "Epoch 00293: val_loss improved from 0.33076 to 0.32723, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/293-0.3272.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.4642 - acc: 0.8592 - val_loss: 0.3272 - val_acc: 0.9161\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4687 - acc: 0.8560\n",
      "Epoch 00294: val_loss did not improve from 0.32723\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.4687 - acc: 0.8561 - val_loss: 0.3517 - val_acc: 0.9068\n",
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4701 - acc: 0.8586\n",
      "Epoch 00295: val_loss did not improve from 0.32723\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.4701 - acc: 0.8586 - val_loss: 0.3487 - val_acc: 0.9071\n",
      "Epoch 296/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4622 - acc: 0.8606\n",
      "Epoch 00296: val_loss improved from 0.32723 to 0.32267, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/296-0.3227.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.4622 - acc: 0.8606 - val_loss: 0.3227 - val_acc: 0.9150\n",
      "Epoch 297/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4684 - acc: 0.8578\n",
      "Epoch 00297: val_loss did not improve from 0.32267\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.4684 - acc: 0.8578 - val_loss: 0.3285 - val_acc: 0.9161\n",
      "Epoch 298/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4647 - acc: 0.8577\n",
      "Epoch 00298: val_loss did not improve from 0.32267\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.4647 - acc: 0.8577 - val_loss: 0.3292 - val_acc: 0.9133\n",
      "Epoch 299/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4666 - acc: 0.8583\n",
      "Epoch 00299: val_loss did not improve from 0.32267\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.4666 - acc: 0.8583 - val_loss: 0.3311 - val_acc: 0.9138\n",
      "Epoch 300/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4653 - acc: 0.8590\n",
      "Epoch 00300: val_loss did not improve from 0.32267\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.4652 - acc: 0.8591 - val_loss: 0.3285 - val_acc: 0.9157\n",
      "Epoch 301/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.8610\n",
      "Epoch 00301: val_loss did not improve from 0.32267\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.4610 - acc: 0.8610 - val_loss: 0.3275 - val_acc: 0.9124\n",
      "Epoch 302/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4648 - acc: 0.8596\n",
      "Epoch 00302: val_loss did not improve from 0.32267\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.4647 - acc: 0.8596 - val_loss: 0.3366 - val_acc: 0.9099\n",
      "Epoch 303/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4609 - acc: 0.8615\n",
      "Epoch 00303: val_loss did not improve from 0.32267\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.4608 - acc: 0.8616 - val_loss: 0.3264 - val_acc: 0.9147\n",
      "Epoch 304/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4630 - acc: 0.8592\n",
      "Epoch 00304: val_loss improved from 0.32267 to 0.31917, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/304-0.3192.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.4629 - acc: 0.8592 - val_loss: 0.3192 - val_acc: 0.9173\n",
      "Epoch 305/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4523 - acc: 0.8632\n",
      "Epoch 00305: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.4523 - acc: 0.8632 - val_loss: 0.3328 - val_acc: 0.9101\n",
      "Epoch 306/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8624\n",
      "Epoch 00306: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.4591 - acc: 0.8624 - val_loss: 0.3375 - val_acc: 0.9094\n",
      "Epoch 307/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4603 - acc: 0.8589\n",
      "Epoch 00307: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.4603 - acc: 0.8589 - val_loss: 0.3336 - val_acc: 0.9126\n",
      "Epoch 308/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4562 - acc: 0.8623\n",
      "Epoch 00308: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.4563 - acc: 0.8622 - val_loss: 0.3225 - val_acc: 0.9157\n",
      "Epoch 309/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4591 - acc: 0.8612\n",
      "Epoch 00309: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.4591 - acc: 0.8612 - val_loss: 0.3312 - val_acc: 0.9133\n",
      "Epoch 310/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4594 - acc: 0.8607\n",
      "Epoch 00310: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.4594 - acc: 0.8608 - val_loss: 0.3209 - val_acc: 0.9119\n",
      "Epoch 311/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4556 - acc: 0.8632\n",
      "Epoch 00311: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.4556 - acc: 0.8631 - val_loss: 0.3275 - val_acc: 0.9180\n",
      "Epoch 312/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4567 - acc: 0.8617\n",
      "Epoch 00312: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.4566 - acc: 0.8617 - val_loss: 0.3274 - val_acc: 0.9115\n",
      "Epoch 313/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4578 - acc: 0.8615\n",
      "Epoch 00313: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.4577 - acc: 0.8615 - val_loss: 0.3238 - val_acc: 0.9157\n",
      "Epoch 314/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4527 - acc: 0.8635\n",
      "Epoch 00314: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.4527 - acc: 0.8635 - val_loss: 0.3231 - val_acc: 0.9180\n",
      "Epoch 315/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4569 - acc: 0.8624\n",
      "Epoch 00315: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.4569 - acc: 0.8624 - val_loss: 0.3574 - val_acc: 0.9050\n",
      "Epoch 316/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4559 - acc: 0.8598\n",
      "Epoch 00316: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4560 - acc: 0.8598 - val_loss: 0.3239 - val_acc: 0.9147\n",
      "Epoch 317/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4495 - acc: 0.8639\n",
      "Epoch 00317: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.4495 - acc: 0.8639 - val_loss: 0.3245 - val_acc: 0.9152\n",
      "Epoch 318/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4539 - acc: 0.8611\n",
      "Epoch 00318: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.4540 - acc: 0.8610 - val_loss: 0.3239 - val_acc: 0.9145\n",
      "Epoch 319/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4517 - acc: 0.8630\n",
      "Epoch 00319: val_loss did not improve from 0.31917\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.4518 - acc: 0.8630 - val_loss: 0.3236 - val_acc: 0.9152\n",
      "Epoch 320/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4528 - acc: 0.8602\n",
      "Epoch 00320: val_loss improved from 0.31917 to 0.31756, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/320-0.3176.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.4527 - acc: 0.8602 - val_loss: 0.3176 - val_acc: 0.9159\n",
      "Epoch 321/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4474 - acc: 0.8642\n",
      "Epoch 00321: val_loss did not improve from 0.31756\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.4473 - acc: 0.8642 - val_loss: 0.3257 - val_acc: 0.9117\n",
      "Epoch 322/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4498 - acc: 0.8638\n",
      "Epoch 00322: val_loss did not improve from 0.31756\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.4498 - acc: 0.8638 - val_loss: 0.3202 - val_acc: 0.9150\n",
      "Epoch 323/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4463 - acc: 0.8635\n",
      "Epoch 00323: val_loss did not improve from 0.31756\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.4463 - acc: 0.8635 - val_loss: 0.3217 - val_acc: 0.9152\n",
      "Epoch 324/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4464 - acc: 0.8649\n",
      "Epoch 00324: val_loss did not improve from 0.31756\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.4464 - acc: 0.8649 - val_loss: 0.3228 - val_acc: 0.9150\n",
      "Epoch 325/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4509 - acc: 0.8636\n",
      "Epoch 00325: val_loss did not improve from 0.31756\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.4509 - acc: 0.8636 - val_loss: 0.3218 - val_acc: 0.9157\n",
      "Epoch 326/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4482 - acc: 0.8637\n",
      "Epoch 00326: val_loss improved from 0.31756 to 0.31594, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/326-0.3159.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.4482 - acc: 0.8637 - val_loss: 0.3159 - val_acc: 0.9145\n",
      "Epoch 327/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4488 - acc: 0.8634\n",
      "Epoch 00327: val_loss did not improve from 0.31594\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.4488 - acc: 0.8634 - val_loss: 0.3197 - val_acc: 0.9159\n",
      "Epoch 328/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.8624\n",
      "Epoch 00328: val_loss improved from 0.31594 to 0.31499, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/328-0.3150.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.4471 - acc: 0.8624 - val_loss: 0.3150 - val_acc: 0.9175\n",
      "Epoch 329/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4455 - acc: 0.8629\n",
      "Epoch 00329: val_loss did not improve from 0.31499\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.4455 - acc: 0.8629 - val_loss: 0.3430 - val_acc: 0.9059\n",
      "Epoch 330/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4486 - acc: 0.8647\n",
      "Epoch 00330: val_loss did not improve from 0.31499\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.4486 - acc: 0.8647 - val_loss: 0.3167 - val_acc: 0.9173\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4405 - acc: 0.8659\n",
      "Epoch 00331: val_loss did not improve from 0.31499\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.4405 - acc: 0.8659 - val_loss: 0.3156 - val_acc: 0.9171\n",
      "Epoch 332/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4454 - acc: 0.8633\n",
      "Epoch 00332: val_loss did not improve from 0.31499\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.4455 - acc: 0.8633 - val_loss: 0.3240 - val_acc: 0.9122\n",
      "Epoch 333/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4416 - acc: 0.8664\n",
      "Epoch 00333: val_loss did not improve from 0.31499\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.4417 - acc: 0.8663 - val_loss: 0.3179 - val_acc: 0.9199\n",
      "Epoch 334/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4462 - acc: 0.8639\n",
      "Epoch 00334: val_loss did not improve from 0.31499\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.4462 - acc: 0.8639 - val_loss: 0.3169 - val_acc: 0.9145\n",
      "Epoch 335/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4468 - acc: 0.8644\n",
      "Epoch 00335: val_loss did not improve from 0.31499\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.4468 - acc: 0.8644 - val_loss: 0.3162 - val_acc: 0.9178\n",
      "Epoch 336/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4449 - acc: 0.8660\n",
      "Epoch 00336: val_loss did not improve from 0.31499\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.4451 - acc: 0.8660 - val_loss: 0.3265 - val_acc: 0.9152\n",
      "Epoch 337/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4411 - acc: 0.8664\n",
      "Epoch 00337: val_loss did not improve from 0.31499\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.4410 - acc: 0.8664 - val_loss: 0.3163 - val_acc: 0.9161\n",
      "Epoch 338/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4408 - acc: 0.8654\n",
      "Epoch 00338: val_loss did not improve from 0.31499\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.4408 - acc: 0.8654 - val_loss: 0.3180 - val_acc: 0.9161\n",
      "Epoch 339/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4392 - acc: 0.8668\n",
      "Epoch 00339: val_loss improved from 0.31499 to 0.31183, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/339-0.3118.hdf5\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.4392 - acc: 0.8668 - val_loss: 0.3118 - val_acc: 0.9178\n",
      "Epoch 340/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4430 - acc: 0.8626\n",
      "Epoch 00340: val_loss did not improve from 0.31183\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.4430 - acc: 0.8627 - val_loss: 0.3195 - val_acc: 0.9150\n",
      "Epoch 341/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4403 - acc: 0.8657\n",
      "Epoch 00341: val_loss did not improve from 0.31183\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.4403 - acc: 0.8658 - val_loss: 0.3129 - val_acc: 0.9154\n",
      "Epoch 342/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8667\n",
      "Epoch 00342: val_loss did not improve from 0.31183\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.4410 - acc: 0.8667 - val_loss: 0.3190 - val_acc: 0.9152\n",
      "Epoch 343/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4371 - acc: 0.8661\n",
      "Epoch 00343: val_loss did not improve from 0.31183\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.4371 - acc: 0.8661 - val_loss: 0.3146 - val_acc: 0.9173\n",
      "Epoch 344/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4396 - acc: 0.8676\n",
      "Epoch 00344: val_loss improved from 0.31183 to 0.30993, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/344-0.3099.hdf5\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.4396 - acc: 0.8677 - val_loss: 0.3099 - val_acc: 0.9166\n",
      "Epoch 345/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4391 - acc: 0.8651\n",
      "Epoch 00345: val_loss improved from 0.30993 to 0.30983, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/345-0.3098.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.4391 - acc: 0.8651 - val_loss: 0.3098 - val_acc: 0.9180\n",
      "Epoch 346/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4381 - acc: 0.8648\n",
      "Epoch 00346: val_loss did not improve from 0.30983\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.4380 - acc: 0.8648 - val_loss: 0.3210 - val_acc: 0.9150\n",
      "Epoch 347/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4372 - acc: 0.8661\n",
      "Epoch 00347: val_loss did not improve from 0.30983\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.4372 - acc: 0.8661 - val_loss: 0.3128 - val_acc: 0.9201\n",
      "Epoch 348/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4341 - acc: 0.8677\n",
      "Epoch 00348: val_loss did not improve from 0.30983\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.4342 - acc: 0.8676 - val_loss: 0.3131 - val_acc: 0.9164\n",
      "Epoch 349/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4369 - acc: 0.8668\n",
      "Epoch 00349: val_loss did not improve from 0.30983\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4371 - acc: 0.8668 - val_loss: 0.3130 - val_acc: 0.9161\n",
      "Epoch 350/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4358 - acc: 0.8677\n",
      "Epoch 00350: val_loss did not improve from 0.30983\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.4357 - acc: 0.8677 - val_loss: 0.3260 - val_acc: 0.9143\n",
      "Epoch 351/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4418 - acc: 0.8643\n",
      "Epoch 00351: val_loss improved from 0.30983 to 0.30812, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/351-0.3081.hdf5\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.4418 - acc: 0.8643 - val_loss: 0.3081 - val_acc: 0.9180\n",
      "Epoch 352/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4378 - acc: 0.8661\n",
      "Epoch 00352: val_loss did not improve from 0.30812\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.4377 - acc: 0.8661 - val_loss: 0.3101 - val_acc: 0.9166\n",
      "Epoch 353/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4365 - acc: 0.8665\n",
      "Epoch 00353: val_loss did not improve from 0.30812\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.4365 - acc: 0.8665 - val_loss: 0.3256 - val_acc: 0.9126\n",
      "Epoch 354/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4382 - acc: 0.8667\n",
      "Epoch 00354: val_loss did not improve from 0.30812\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.4383 - acc: 0.8666 - val_loss: 0.3135 - val_acc: 0.9192\n",
      "Epoch 355/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4370 - acc: 0.8653\n",
      "Epoch 00355: val_loss did not improve from 0.30812\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.4370 - acc: 0.8653 - val_loss: 0.3179 - val_acc: 0.9168\n",
      "Epoch 356/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4292 - acc: 0.8692\n",
      "Epoch 00356: val_loss did not improve from 0.30812\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.4292 - acc: 0.8692 - val_loss: 0.3170 - val_acc: 0.9168\n",
      "Epoch 357/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4271 - acc: 0.8701\n",
      "Epoch 00357: val_loss did not improve from 0.30812\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.4272 - acc: 0.8701 - val_loss: 0.3092 - val_acc: 0.9196\n",
      "Epoch 358/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4320 - acc: 0.8668\n",
      "Epoch 00358: val_loss did not improve from 0.30812\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.4320 - acc: 0.8668 - val_loss: 0.3137 - val_acc: 0.9192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4288 - acc: 0.8703\n",
      "Epoch 00359: val_loss improved from 0.30812 to 0.30790, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/359-0.3079.hdf5\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.4288 - acc: 0.8703 - val_loss: 0.3079 - val_acc: 0.9194\n",
      "Epoch 360/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4261 - acc: 0.8706\n",
      "Epoch 00360: val_loss did not improve from 0.30790\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.4262 - acc: 0.8706 - val_loss: 0.3135 - val_acc: 0.9166\n",
      "Epoch 361/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4334 - acc: 0.8656\n",
      "Epoch 00361: val_loss did not improve from 0.30790\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.4334 - acc: 0.8656 - val_loss: 0.3184 - val_acc: 0.9131\n",
      "Epoch 362/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4249 - acc: 0.8705\n",
      "Epoch 00362: val_loss improved from 0.30790 to 0.30612, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/362-0.3061.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.4249 - acc: 0.8705 - val_loss: 0.3061 - val_acc: 0.9171\n",
      "Epoch 363/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4310 - acc: 0.8679\n",
      "Epoch 00363: val_loss did not improve from 0.30612\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.4310 - acc: 0.8679 - val_loss: 0.3082 - val_acc: 0.9206\n",
      "Epoch 364/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4336 - acc: 0.8687\n",
      "Epoch 00364: val_loss did not improve from 0.30612\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.4336 - acc: 0.8687 - val_loss: 0.3240 - val_acc: 0.9145\n",
      "Epoch 365/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4284 - acc: 0.8690\n",
      "Epoch 00365: val_loss did not improve from 0.30612\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.4284 - acc: 0.8690 - val_loss: 0.3120 - val_acc: 0.9171\n",
      "Epoch 366/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4336 - acc: 0.8679\n",
      "Epoch 00366: val_loss did not improve from 0.30612\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.4335 - acc: 0.8679 - val_loss: 0.3299 - val_acc: 0.9122\n",
      "Epoch 367/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4263 - acc: 0.8686\n",
      "Epoch 00367: val_loss improved from 0.30612 to 0.30370, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/367-0.3037.hdf5\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.4263 - acc: 0.8686 - val_loss: 0.3037 - val_acc: 0.9201\n",
      "Epoch 368/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4244 - acc: 0.8702\n",
      "Epoch 00368: val_loss did not improve from 0.30370\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.4245 - acc: 0.8702 - val_loss: 0.3072 - val_acc: 0.9182\n",
      "Epoch 369/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4261 - acc: 0.8706\n",
      "Epoch 00369: val_loss did not improve from 0.30370\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.4261 - acc: 0.8706 - val_loss: 0.3083 - val_acc: 0.9194\n",
      "Epoch 370/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4272 - acc: 0.8702\n",
      "Epoch 00370: val_loss improved from 0.30370 to 0.30293, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/370-0.3029.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.4272 - acc: 0.8702 - val_loss: 0.3029 - val_acc: 0.9194\n",
      "Epoch 371/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4225 - acc: 0.8693\n",
      "Epoch 00371: val_loss did not improve from 0.30293\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.4227 - acc: 0.8693 - val_loss: 0.3183 - val_acc: 0.9147\n",
      "Epoch 372/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4267 - acc: 0.8704\n",
      "Epoch 00372: val_loss improved from 0.30293 to 0.29970, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/372-0.2997.hdf5\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.4267 - acc: 0.8704 - val_loss: 0.2997 - val_acc: 0.9187\n",
      "Epoch 373/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4245 - acc: 0.8684\n",
      "Epoch 00373: val_loss did not improve from 0.29970\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.4245 - acc: 0.8684 - val_loss: 0.3063 - val_acc: 0.9187\n",
      "Epoch 374/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4278 - acc: 0.8682\n",
      "Epoch 00374: val_loss did not improve from 0.29970\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4278 - acc: 0.8681 - val_loss: 0.3032 - val_acc: 0.9194\n",
      "Epoch 375/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4285 - acc: 0.8690\n",
      "Epoch 00375: val_loss did not improve from 0.29970\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.4285 - acc: 0.8690 - val_loss: 0.3116 - val_acc: 0.9171\n",
      "Epoch 376/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4286 - acc: 0.8684\n",
      "Epoch 00376: val_loss did not improve from 0.29970\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.4286 - acc: 0.8684 - val_loss: 0.3012 - val_acc: 0.9199\n",
      "Epoch 377/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4235 - acc: 0.8701\n",
      "Epoch 00377: val_loss did not improve from 0.29970\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.4235 - acc: 0.8701 - val_loss: 0.2997 - val_acc: 0.9189\n",
      "Epoch 378/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4218 - acc: 0.8685\n",
      "Epoch 00378: val_loss did not improve from 0.29970\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.4217 - acc: 0.8685 - val_loss: 0.3006 - val_acc: 0.9203\n",
      "Epoch 379/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4196 - acc: 0.8717\n",
      "Epoch 00379: val_loss did not improve from 0.29970\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.4196 - acc: 0.8717 - val_loss: 0.3024 - val_acc: 0.9194\n",
      "Epoch 380/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4255 - acc: 0.8711\n",
      "Epoch 00380: val_loss did not improve from 0.29970\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.4254 - acc: 0.8711 - val_loss: 0.3109 - val_acc: 0.9143\n",
      "Epoch 381/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4209 - acc: 0.8697\n",
      "Epoch 00381: val_loss did not improve from 0.29970\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.4209 - acc: 0.8697 - val_loss: 0.3189 - val_acc: 0.9157\n",
      "Epoch 382/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4178 - acc: 0.8711\n",
      "Epoch 00382: val_loss did not improve from 0.29970\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.4178 - acc: 0.8711 - val_loss: 0.3110 - val_acc: 0.9203\n",
      "Epoch 383/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4198 - acc: 0.8710\n",
      "Epoch 00383: val_loss improved from 0.29970 to 0.29807, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/383-0.2981.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.4197 - acc: 0.8709 - val_loss: 0.2981 - val_acc: 0.9196\n",
      "Epoch 384/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4193 - acc: 0.8724\n",
      "Epoch 00384: val_loss did not improve from 0.29807\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4193 - acc: 0.8724 - val_loss: 0.3007 - val_acc: 0.9208\n",
      "Epoch 385/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4240 - acc: 0.8688\n",
      "Epoch 00385: val_loss did not improve from 0.29807\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.4241 - acc: 0.8687 - val_loss: 0.3013 - val_acc: 0.9187\n",
      "Epoch 386/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4145 - acc: 0.8721\n",
      "Epoch 00386: val_loss did not improve from 0.29807\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.4145 - acc: 0.8721 - val_loss: 0.3018 - val_acc: 0.9182\n",
      "Epoch 387/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4183 - acc: 0.8719\n",
      "Epoch 00387: val_loss did not improve from 0.29807\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4184 - acc: 0.8719 - val_loss: 0.3015 - val_acc: 0.9189\n",
      "Epoch 388/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4166 - acc: 0.8717\n",
      "Epoch 00388: val_loss did not improve from 0.29807\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.4166 - acc: 0.8718 - val_loss: 0.3055 - val_acc: 0.9220\n",
      "Epoch 389/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4120 - acc: 0.8733\n",
      "Epoch 00389: val_loss did not improve from 0.29807\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.4121 - acc: 0.8733 - val_loss: 0.3078 - val_acc: 0.9173\n",
      "Epoch 390/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4153 - acc: 0.8746\n",
      "Epoch 00390: val_loss did not improve from 0.29807\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.4152 - acc: 0.8746 - val_loss: 0.3061 - val_acc: 0.9182\n",
      "Epoch 391/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4178 - acc: 0.8729\n",
      "Epoch 00391: val_loss did not improve from 0.29807\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4178 - acc: 0.8729 - val_loss: 0.3024 - val_acc: 0.9182\n",
      "Epoch 392/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4156 - acc: 0.8729\n",
      "Epoch 00392: val_loss did not improve from 0.29807\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.4156 - acc: 0.8729 - val_loss: 0.3049 - val_acc: 0.9189\n",
      "Epoch 393/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4114 - acc: 0.8720\n",
      "Epoch 00393: val_loss improved from 0.29807 to 0.29706, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/393-0.2971.hdf5\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.4114 - acc: 0.8720 - val_loss: 0.2971 - val_acc: 0.9217\n",
      "Epoch 394/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4130 - acc: 0.8736\n",
      "Epoch 00394: val_loss did not improve from 0.29706\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.4130 - acc: 0.8736 - val_loss: 0.3180 - val_acc: 0.9136\n",
      "Epoch 395/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4170 - acc: 0.8731\n",
      "Epoch 00395: val_loss did not improve from 0.29706\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.4170 - acc: 0.8731 - val_loss: 0.2993 - val_acc: 0.9199\n",
      "Epoch 396/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4138 - acc: 0.8752\n",
      "Epoch 00396: val_loss did not improve from 0.29706\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.4138 - acc: 0.8752 - val_loss: 0.3107 - val_acc: 0.9147\n",
      "Epoch 397/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4148 - acc: 0.8740\n",
      "Epoch 00397: val_loss did not improve from 0.29706\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.4148 - acc: 0.8740 - val_loss: 0.3030 - val_acc: 0.9201\n",
      "Epoch 398/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4127 - acc: 0.8727\n",
      "Epoch 00398: val_loss did not improve from 0.29706\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.4127 - acc: 0.8727 - val_loss: 0.2980 - val_acc: 0.9217\n",
      "Epoch 399/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4122 - acc: 0.8732\n",
      "Epoch 00399: val_loss did not improve from 0.29706\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4122 - acc: 0.8733 - val_loss: 0.3034 - val_acc: 0.9187\n",
      "Epoch 400/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4117 - acc: 0.8736\n",
      "Epoch 00400: val_loss did not improve from 0.29706\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4118 - acc: 0.8735 - val_loss: 0.3043 - val_acc: 0.9196\n",
      "Epoch 401/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4156 - acc: 0.8728\n",
      "Epoch 00401: val_loss did not improve from 0.29706\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4156 - acc: 0.8728 - val_loss: 0.3006 - val_acc: 0.9161\n",
      "Epoch 402/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4119 - acc: 0.8735\n",
      "Epoch 00402: val_loss improved from 0.29706 to 0.29700, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/402-0.2970.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.4119 - acc: 0.8735 - val_loss: 0.2970 - val_acc: 0.9192\n",
      "Epoch 403/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4173 - acc: 0.8720\n",
      "Epoch 00403: val_loss did not improve from 0.29700\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4173 - acc: 0.8720 - val_loss: 0.2979 - val_acc: 0.9203\n",
      "Epoch 404/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4136 - acc: 0.8754\n",
      "Epoch 00404: val_loss improved from 0.29700 to 0.29324, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/404-0.2932.hdf5\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.4136 - acc: 0.8753 - val_loss: 0.2932 - val_acc: 0.9217\n",
      "Epoch 405/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4105 - acc: 0.8735\n",
      "Epoch 00405: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.4105 - acc: 0.8735 - val_loss: 0.2967 - val_acc: 0.9206\n",
      "Epoch 406/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4128 - acc: 0.8731\n",
      "Epoch 00406: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4128 - acc: 0.8731 - val_loss: 0.3112 - val_acc: 0.9175\n",
      "Epoch 407/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4134 - acc: 0.8726\n",
      "Epoch 00407: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.4134 - acc: 0.8725 - val_loss: 0.2961 - val_acc: 0.9175\n",
      "Epoch 408/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4136 - acc: 0.8736\n",
      "Epoch 00408: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.4138 - acc: 0.8736 - val_loss: 0.3014 - val_acc: 0.9175\n",
      "Epoch 409/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4132 - acc: 0.8738\n",
      "Epoch 00409: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.4133 - acc: 0.8738 - val_loss: 0.3053 - val_acc: 0.9152\n",
      "Epoch 410/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4023 - acc: 0.8757\n",
      "Epoch 00410: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.4022 - acc: 0.8757 - val_loss: 0.2951 - val_acc: 0.9213\n",
      "Epoch 411/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4116 - acc: 0.8727\n",
      "Epoch 00411: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.4117 - acc: 0.8727 - val_loss: 0.2973 - val_acc: 0.9175\n",
      "Epoch 412/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4113 - acc: 0.8739\n",
      "Epoch 00412: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.4112 - acc: 0.8740 - val_loss: 0.2959 - val_acc: 0.9206\n",
      "Epoch 413/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4059 - acc: 0.8765\n",
      "Epoch 00413: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.4059 - acc: 0.8766 - val_loss: 0.2978 - val_acc: 0.9175\n",
      "Epoch 414/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4089 - acc: 0.8747\n",
      "Epoch 00414: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.4090 - acc: 0.8747 - val_loss: 0.2949 - val_acc: 0.9224\n",
      "Epoch 415/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4097 - acc: 0.8731\n",
      "Epoch 00415: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.4097 - acc: 0.8731 - val_loss: 0.2968 - val_acc: 0.9201\n",
      "Epoch 416/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4099 - acc: 0.8742\n",
      "Epoch 00416: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.4099 - acc: 0.8742 - val_loss: 0.2994 - val_acc: 0.9203\n",
      "Epoch 417/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4033 - acc: 0.8774\n",
      "Epoch 00417: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.4033 - acc: 0.8774 - val_loss: 0.2973 - val_acc: 0.9201\n",
      "Epoch 418/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4006 - acc: 0.8776\n",
      "Epoch 00418: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.4007 - acc: 0.8775 - val_loss: 0.2979 - val_acc: 0.9206\n",
      "Epoch 419/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4081 - acc: 0.8751\n",
      "Epoch 00419: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.4081 - acc: 0.8751 - val_loss: 0.2950 - val_acc: 0.9238\n",
      "Epoch 420/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4069 - acc: 0.8738\n",
      "Epoch 00420: val_loss did not improve from 0.29324\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.4069 - acc: 0.8738 - val_loss: 0.3015 - val_acc: 0.9201\n",
      "Epoch 421/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4050 - acc: 0.8753\n",
      "Epoch 00421: val_loss improved from 0.29324 to 0.29192, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/421-0.2919.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.4050 - acc: 0.8753 - val_loss: 0.2919 - val_acc: 0.9220\n",
      "Epoch 422/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4070 - acc: 0.8741\n",
      "Epoch 00422: val_loss did not improve from 0.29192\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.4070 - acc: 0.8741 - val_loss: 0.2950 - val_acc: 0.9220\n",
      "Epoch 423/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4029 - acc: 0.8751\n",
      "Epoch 00423: val_loss did not improve from 0.29192\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.4029 - acc: 0.8751 - val_loss: 0.2963 - val_acc: 0.9168\n",
      "Epoch 424/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4044 - acc: 0.8773\n",
      "Epoch 00424: val_loss did not improve from 0.29192\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.4044 - acc: 0.8772 - val_loss: 0.3008 - val_acc: 0.9185\n",
      "Epoch 425/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4021 - acc: 0.8749\n",
      "Epoch 00425: val_loss improved from 0.29192 to 0.29181, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/425-0.2918.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.4021 - acc: 0.8749 - val_loss: 0.2918 - val_acc: 0.9229\n",
      "Epoch 426/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4038 - acc: 0.8760\n",
      "Epoch 00426: val_loss did not improve from 0.29181\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.4038 - acc: 0.8760 - val_loss: 0.3065 - val_acc: 0.9203\n",
      "Epoch 427/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4038 - acc: 0.8765\n",
      "Epoch 00427: val_loss did not improve from 0.29181\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.4039 - acc: 0.8765 - val_loss: 0.2949 - val_acc: 0.9234\n",
      "Epoch 428/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4031 - acc: 0.8753\n",
      "Epoch 00428: val_loss did not improve from 0.29181\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.4031 - acc: 0.8753 - val_loss: 0.2938 - val_acc: 0.9185\n",
      "Epoch 429/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4050 - acc: 0.8740\n",
      "Epoch 00429: val_loss improved from 0.29181 to 0.29172, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/429-0.2917.hdf5\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.4050 - acc: 0.8740 - val_loss: 0.2917 - val_acc: 0.9215\n",
      "Epoch 430/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4036 - acc: 0.8749\n",
      "Epoch 00430: val_loss improved from 0.29172 to 0.28903, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/430-0.2890.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4036 - acc: 0.8749 - val_loss: 0.2890 - val_acc: 0.9210\n",
      "Epoch 431/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4020 - acc: 0.8780\n",
      "Epoch 00431: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.4020 - acc: 0.8781 - val_loss: 0.2920 - val_acc: 0.9201\n",
      "Epoch 432/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3984 - acc: 0.8761\n",
      "Epoch 00432: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.3984 - acc: 0.8761 - val_loss: 0.2950 - val_acc: 0.9201\n",
      "Epoch 433/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3995 - acc: 0.8763\n",
      "Epoch 00433: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.3994 - acc: 0.8763 - val_loss: 0.2916 - val_acc: 0.9180\n",
      "Epoch 434/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4002 - acc: 0.8796\n",
      "Epoch 00434: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.4002 - acc: 0.8796 - val_loss: 0.2990 - val_acc: 0.9178\n",
      "Epoch 435/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3971 - acc: 0.8763\n",
      "Epoch 00435: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.3972 - acc: 0.8763 - val_loss: 0.2990 - val_acc: 0.9203\n",
      "Epoch 436/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3999 - acc: 0.8786\n",
      "Epoch 00436: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3999 - acc: 0.8786 - val_loss: 0.2989 - val_acc: 0.9203\n",
      "Epoch 437/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4009 - acc: 0.8765\n",
      "Epoch 00437: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.4008 - acc: 0.8765 - val_loss: 0.2939 - val_acc: 0.9206\n",
      "Epoch 438/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4046 - acc: 0.8759\n",
      "Epoch 00438: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.4046 - acc: 0.8759 - val_loss: 0.2924 - val_acc: 0.9220\n",
      "Epoch 439/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3998 - acc: 0.8758\n",
      "Epoch 00439: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.3998 - acc: 0.8758 - val_loss: 0.2982 - val_acc: 0.9220\n",
      "Epoch 440/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3998 - acc: 0.8762\n",
      "Epoch 00440: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.3998 - acc: 0.8762 - val_loss: 0.3121 - val_acc: 0.9138\n",
      "Epoch 441/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3992 - acc: 0.8760\n",
      "Epoch 00441: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.3993 - acc: 0.8759 - val_loss: 0.2992 - val_acc: 0.9203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 442/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3938 - acc: 0.8788\n",
      "Epoch 00442: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.3938 - acc: 0.8788 - val_loss: 0.2943 - val_acc: 0.9189\n",
      "Epoch 443/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3918 - acc: 0.8779\n",
      "Epoch 00443: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.3918 - acc: 0.8779 - val_loss: 0.2902 - val_acc: 0.9217\n",
      "Epoch 444/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3961 - acc: 0.8767\n",
      "Epoch 00444: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.3961 - acc: 0.8767 - val_loss: 0.2954 - val_acc: 0.9229\n",
      "Epoch 445/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3931 - acc: 0.8785\n",
      "Epoch 00445: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.3931 - acc: 0.8785 - val_loss: 0.2918 - val_acc: 0.9208\n",
      "Epoch 446/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3921 - acc: 0.8795\n",
      "Epoch 00446: val_loss did not improve from 0.28903\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.3921 - acc: 0.8795 - val_loss: 0.2904 - val_acc: 0.9222\n",
      "Epoch 447/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3962 - acc: 0.8769\n",
      "Epoch 00447: val_loss improved from 0.28903 to 0.28767, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/447-0.2877.hdf5\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.3962 - acc: 0.8769 - val_loss: 0.2877 - val_acc: 0.9206\n",
      "Epoch 448/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3912 - acc: 0.8798\n",
      "Epoch 00448: val_loss did not improve from 0.28767\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.3912 - acc: 0.8798 - val_loss: 0.2935 - val_acc: 0.9215\n",
      "Epoch 449/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3927 - acc: 0.8784\n",
      "Epoch 00449: val_loss did not improve from 0.28767\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.3927 - acc: 0.8784 - val_loss: 0.2923 - val_acc: 0.9217\n",
      "Epoch 450/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3973 - acc: 0.8769\n",
      "Epoch 00450: val_loss did not improve from 0.28767\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.3973 - acc: 0.8769 - val_loss: 0.2914 - val_acc: 0.9236\n",
      "Epoch 451/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3985 - acc: 0.8762\n",
      "Epoch 00451: val_loss improved from 0.28767 to 0.28542, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/451-0.2854.hdf5\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.3985 - acc: 0.8762 - val_loss: 0.2854 - val_acc: 0.9243\n",
      "Epoch 452/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3943 - acc: 0.8779\n",
      "Epoch 00452: val_loss did not improve from 0.28542\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.3943 - acc: 0.8780 - val_loss: 0.2982 - val_acc: 0.9220\n",
      "Epoch 453/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3918 - acc: 0.8786\n",
      "Epoch 00453: val_loss did not improve from 0.28542\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.3918 - acc: 0.8786 - val_loss: 0.2911 - val_acc: 0.9187\n",
      "Epoch 454/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3934 - acc: 0.8787\n",
      "Epoch 00454: val_loss did not improve from 0.28542\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.3933 - acc: 0.8787 - val_loss: 0.2865 - val_acc: 0.9224\n",
      "Epoch 455/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3916 - acc: 0.8784\n",
      "Epoch 00455: val_loss did not improve from 0.28542\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3916 - acc: 0.8784 - val_loss: 0.2929 - val_acc: 0.9203\n",
      "Epoch 456/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3935 - acc: 0.8782\n",
      "Epoch 00456: val_loss did not improve from 0.28542\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3935 - acc: 0.8782 - val_loss: 0.2900 - val_acc: 0.9224\n",
      "Epoch 457/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3890 - acc: 0.8819\n",
      "Epoch 00457: val_loss did not improve from 0.28542\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.3891 - acc: 0.8819 - val_loss: 0.2984 - val_acc: 0.9213\n",
      "Epoch 458/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3901 - acc: 0.8796\n",
      "Epoch 00458: val_loss did not improve from 0.28542\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3900 - acc: 0.8796 - val_loss: 0.2884 - val_acc: 0.9234\n",
      "Epoch 459/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3936 - acc: 0.8786\n",
      "Epoch 00459: val_loss did not improve from 0.28542\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3935 - acc: 0.8786 - val_loss: 0.2856 - val_acc: 0.9210\n",
      "Epoch 460/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3876 - acc: 0.8809\n",
      "Epoch 00460: val_loss did not improve from 0.28542\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3876 - acc: 0.8809 - val_loss: 0.2910 - val_acc: 0.9213\n",
      "Epoch 461/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3860 - acc: 0.8813\n",
      "Epoch 00461: val_loss did not improve from 0.28542\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.3860 - acc: 0.8813 - val_loss: 0.2877 - val_acc: 0.9208\n",
      "Epoch 462/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3952 - acc: 0.8786\n",
      "Epoch 00462: val_loss did not improve from 0.28542\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.3951 - acc: 0.8787 - val_loss: 0.2929 - val_acc: 0.9215\n",
      "Epoch 463/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3872 - acc: 0.8805\n",
      "Epoch 00463: val_loss did not improve from 0.28542\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.3871 - acc: 0.8805 - val_loss: 0.2904 - val_acc: 0.9220\n",
      "Epoch 464/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3872 - acc: 0.8780\n",
      "Epoch 00464: val_loss improved from 0.28542 to 0.28422, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/464-0.2842.hdf5\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.3872 - acc: 0.8780 - val_loss: 0.2842 - val_acc: 0.9238\n",
      "Epoch 465/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3902 - acc: 0.8810\n",
      "Epoch 00465: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.3902 - acc: 0.8810 - val_loss: 0.2870 - val_acc: 0.9231\n",
      "Epoch 466/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3890 - acc: 0.8803\n",
      "Epoch 00466: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.3890 - acc: 0.8803 - val_loss: 0.2938 - val_acc: 0.9210\n",
      "Epoch 467/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3822 - acc: 0.8818\n",
      "Epoch 00467: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.3821 - acc: 0.8818 - val_loss: 0.2986 - val_acc: 0.9189\n",
      "Epoch 468/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3857 - acc: 0.8816\n",
      "Epoch 00468: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.3858 - acc: 0.8816 - val_loss: 0.2868 - val_acc: 0.9213\n",
      "Epoch 469/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3866 - acc: 0.8793\n",
      "Epoch 00469: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.3866 - acc: 0.8794 - val_loss: 0.2867 - val_acc: 0.9213\n",
      "Epoch 470/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3836 - acc: 0.8821\n",
      "Epoch 00470: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.3836 - acc: 0.8821 - val_loss: 0.2932 - val_acc: 0.9222\n",
      "Epoch 471/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3851 - acc: 0.8815\n",
      "Epoch 00471: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.3851 - acc: 0.8815 - val_loss: 0.2941 - val_acc: 0.9224\n",
      "Epoch 472/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3885 - acc: 0.8802\n",
      "Epoch 00472: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.3885 - acc: 0.8803 - val_loss: 0.2882 - val_acc: 0.9231\n",
      "Epoch 473/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3916 - acc: 0.8799\n",
      "Epoch 00473: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3916 - acc: 0.8799 - val_loss: 0.2974 - val_acc: 0.9194\n",
      "Epoch 474/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3896 - acc: 0.8787\n",
      "Epoch 00474: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.3896 - acc: 0.8787 - val_loss: 0.2945 - val_acc: 0.9199\n",
      "Epoch 475/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3832 - acc: 0.8804\n",
      "Epoch 00475: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.3832 - acc: 0.8804 - val_loss: 0.2853 - val_acc: 0.9224\n",
      "Epoch 476/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3858 - acc: 0.8796\n",
      "Epoch 00476: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.3858 - acc: 0.8796 - val_loss: 0.2882 - val_acc: 0.9210\n",
      "Epoch 477/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3844 - acc: 0.8801\n",
      "Epoch 00477: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3845 - acc: 0.8801 - val_loss: 0.2873 - val_acc: 0.9213\n",
      "Epoch 478/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3843 - acc: 0.8805\n",
      "Epoch 00478: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.3843 - acc: 0.8806 - val_loss: 0.2902 - val_acc: 0.9203\n",
      "Epoch 479/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3819 - acc: 0.8823\n",
      "Epoch 00479: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.3819 - acc: 0.8823 - val_loss: 0.2846 - val_acc: 0.9231\n",
      "Epoch 480/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3808 - acc: 0.8827\n",
      "Epoch 00480: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.3809 - acc: 0.8827 - val_loss: 0.2939 - val_acc: 0.9192\n",
      "Epoch 481/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3865 - acc: 0.8801\n",
      "Epoch 00481: val_loss did not improve from 0.28422\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.3865 - acc: 0.8801 - val_loss: 0.2953 - val_acc: 0.9192\n",
      "Epoch 482/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3854 - acc: 0.8811\n",
      "Epoch 00482: val_loss improved from 0.28422 to 0.28149, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/482-0.2815.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.3854 - acc: 0.8811 - val_loss: 0.2815 - val_acc: 0.9220\n",
      "Epoch 483/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3821 - acc: 0.8805\n",
      "Epoch 00483: val_loss did not improve from 0.28149\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.3820 - acc: 0.8805 - val_loss: 0.2853 - val_acc: 0.9250\n",
      "Epoch 484/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3848 - acc: 0.8812\n",
      "Epoch 00484: val_loss did not improve from 0.28149\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.3848 - acc: 0.8812 - val_loss: 0.2897 - val_acc: 0.9213\n",
      "Epoch 485/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3863 - acc: 0.8808\n",
      "Epoch 00485: val_loss did not improve from 0.28149\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.3862 - acc: 0.8808 - val_loss: 0.2838 - val_acc: 0.9222\n",
      "Epoch 486/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3849 - acc: 0.8793\n",
      "Epoch 00486: val_loss did not improve from 0.28149\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.3849 - acc: 0.8793 - val_loss: 0.2999 - val_acc: 0.9147\n",
      "Epoch 487/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3892 - acc: 0.8798\n",
      "Epoch 00487: val_loss did not improve from 0.28149\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.3893 - acc: 0.8797 - val_loss: 0.2905 - val_acc: 0.9187\n",
      "Epoch 488/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3835 - acc: 0.8817\n",
      "Epoch 00488: val_loss did not improve from 0.28149\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.3835 - acc: 0.8817 - val_loss: 0.2844 - val_acc: 0.9194\n",
      "Epoch 489/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3762 - acc: 0.8828\n",
      "Epoch 00489: val_loss did not improve from 0.28149\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.3761 - acc: 0.8828 - val_loss: 0.2875 - val_acc: 0.9206\n",
      "Epoch 490/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3888 - acc: 0.8815\n",
      "Epoch 00490: val_loss did not improve from 0.28149\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3887 - acc: 0.8815 - val_loss: 0.2968 - val_acc: 0.9171\n",
      "Epoch 491/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3806 - acc: 0.8818\n",
      "Epoch 00491: val_loss did not improve from 0.28149\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.3808 - acc: 0.8818 - val_loss: 0.2889 - val_acc: 0.9234\n",
      "Epoch 492/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3832 - acc: 0.8815\n",
      "Epoch 00492: val_loss improved from 0.28149 to 0.28055, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv_checkpoint/492-0.2805.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.3832 - acc: 0.8815 - val_loss: 0.2805 - val_acc: 0.9231\n",
      "Epoch 493/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3764 - acc: 0.8835\n",
      "Epoch 00493: val_loss did not improve from 0.28055\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.3764 - acc: 0.8834 - val_loss: 0.2897 - val_acc: 0.9234\n",
      "Epoch 494/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3859 - acc: 0.8802\n",
      "Epoch 00494: val_loss did not improve from 0.28055\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.3858 - acc: 0.8802 - val_loss: 0.2820 - val_acc: 0.9229\n",
      "Epoch 495/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3765 - acc: 0.8854\n",
      "Epoch 00495: val_loss did not improve from 0.28055\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3764 - acc: 0.8854 - val_loss: 0.2848 - val_acc: 0.9236\n",
      "Epoch 496/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3792 - acc: 0.8807\n",
      "Epoch 00496: val_loss did not improve from 0.28055\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.3793 - acc: 0.8807 - val_loss: 0.2850 - val_acc: 0.9229\n",
      "Epoch 497/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3748 - acc: 0.8839\n",
      "Epoch 00497: val_loss did not improve from 0.28055\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3748 - acc: 0.8839 - val_loss: 0.2892 - val_acc: 0.9215\n",
      "Epoch 498/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3746 - acc: 0.8833\n",
      "Epoch 00498: val_loss did not improve from 0.28055\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3746 - acc: 0.8832 - val_loss: 0.2835 - val_acc: 0.9257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 499/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3754 - acc: 0.8849\n",
      "Epoch 00499: val_loss did not improve from 0.28055\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3755 - acc: 0.8849 - val_loss: 0.2899 - val_acc: 0.9217\n",
      "Epoch 500/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3823 - acc: 0.8812\n",
      "Epoch 00500: val_loss did not improve from 0.28055\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.3823 - acc: 0.8812 - val_loss: 0.2816 - val_acc: 0.9231\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 302us/sample - loss: 0.3259 - acc: 0.9088\n",
      "Loss: 0.3258861377479379 Accuracy: 0.9088266\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6473 - acc: 0.1283\n",
      "Epoch 00001: val_loss improved from inf to 2.40547, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/001-2.4055.hdf5\n",
      "36805/36805 [==============================] - 20s 556us/sample - loss: 2.6472 - acc: 0.1284 - val_loss: 2.4055 - val_acc: 0.2530\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2535 - acc: 0.2633\n",
      "Epoch 00002: val_loss improved from 2.40547 to 1.95135, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/002-1.9514.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 2.2535 - acc: 0.2633 - val_loss: 1.9514 - val_acc: 0.4044\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9713 - acc: 0.3493\n",
      "Epoch 00003: val_loss improved from 1.95135 to 1.70130, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/003-1.7013.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 1.9713 - acc: 0.3492 - val_loss: 1.7013 - val_acc: 0.4778\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8113 - acc: 0.4025\n",
      "Epoch 00004: val_loss improved from 1.70130 to 1.55430, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/004-1.5543.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 1.8113 - acc: 0.4025 - val_loss: 1.5543 - val_acc: 0.5227\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6930 - acc: 0.4426\n",
      "Epoch 00005: val_loss improved from 1.55430 to 1.43189, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/005-1.4319.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 1.6929 - acc: 0.4426 - val_loss: 1.4319 - val_acc: 0.5693\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5967 - acc: 0.4798\n",
      "Epoch 00006: val_loss improved from 1.43189 to 1.34737, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/006-1.3474.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 1.5966 - acc: 0.4798 - val_loss: 1.3474 - val_acc: 0.5945\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5150 - acc: 0.5101\n",
      "Epoch 00007: val_loss improved from 1.34737 to 1.28656, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/007-1.2866.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 1.5150 - acc: 0.5101 - val_loss: 1.2866 - val_acc: 0.6240\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4356 - acc: 0.5406\n",
      "Epoch 00008: val_loss improved from 1.28656 to 1.18692, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/008-1.1869.hdf5\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 1.4356 - acc: 0.5406 - val_loss: 1.1869 - val_acc: 0.6506\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3783 - acc: 0.5621\n",
      "Epoch 00009: val_loss improved from 1.18692 to 1.12362, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/009-1.1236.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 1.3782 - acc: 0.5622 - val_loss: 1.1236 - val_acc: 0.6799\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3199 - acc: 0.5849\n",
      "Epoch 00010: val_loss improved from 1.12362 to 1.06255, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/010-1.0625.hdf5\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 1.3198 - acc: 0.5849 - val_loss: 1.0625 - val_acc: 0.7051\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2573 - acc: 0.6083\n",
      "Epoch 00011: val_loss improved from 1.06255 to 1.00975, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/011-1.0097.hdf5\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 1.2573 - acc: 0.6083 - val_loss: 1.0097 - val_acc: 0.7167\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2142 - acc: 0.6193\n",
      "Epoch 00012: val_loss improved from 1.00975 to 0.96022, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/012-0.9602.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 1.2141 - acc: 0.6193 - val_loss: 0.9602 - val_acc: 0.7319\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1707 - acc: 0.6381\n",
      "Epoch 00013: val_loss improved from 0.96022 to 0.91917, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/013-0.9192.hdf5\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 1.1708 - acc: 0.6381 - val_loss: 0.9192 - val_acc: 0.7379\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1317 - acc: 0.6540\n",
      "Epoch 00014: val_loss improved from 0.91917 to 0.87948, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/014-0.8795.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 1.1319 - acc: 0.6539 - val_loss: 0.8795 - val_acc: 0.7563\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1013 - acc: 0.6595\n",
      "Epoch 00015: val_loss improved from 0.87948 to 0.84696, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/015-0.8470.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 1.1013 - acc: 0.6594 - val_loss: 0.8470 - val_acc: 0.7685\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0525 - acc: 0.6764\n",
      "Epoch 00016: val_loss improved from 0.84696 to 0.81331, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/016-0.8133.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 1.0524 - acc: 0.6764 - val_loss: 0.8133 - val_acc: 0.7799\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0246 - acc: 0.6891\n",
      "Epoch 00017: val_loss improved from 0.81331 to 0.80690, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/017-0.8069.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 1.0245 - acc: 0.6891 - val_loss: 0.8069 - val_acc: 0.7782\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9823 - acc: 0.7023\n",
      "Epoch 00018: val_loss improved from 0.80690 to 0.75861, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/018-0.7586.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.9823 - acc: 0.7023 - val_loss: 0.7586 - val_acc: 0.7950\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9623 - acc: 0.7108\n",
      "Epoch 00019: val_loss improved from 0.75861 to 0.72410, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/019-0.7241.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.9624 - acc: 0.7108 - val_loss: 0.7241 - val_acc: 0.7962\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9314 - acc: 0.7216\n",
      "Epoch 00020: val_loss improved from 0.72410 to 0.69612, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/020-0.6961.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.9315 - acc: 0.7216 - val_loss: 0.6961 - val_acc: 0.8150\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9072 - acc: 0.7316\n",
      "Epoch 00021: val_loss improved from 0.69612 to 0.68724, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/021-0.6872.hdf5\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.9074 - acc: 0.7316 - val_loss: 0.6872 - val_acc: 0.8111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8845 - acc: 0.7353\n",
      "Epoch 00022: val_loss improved from 0.68724 to 0.64878, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/022-0.6488.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.8845 - acc: 0.7353 - val_loss: 0.6488 - val_acc: 0.8230\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8683 - acc: 0.7408\n",
      "Epoch 00023: val_loss improved from 0.64878 to 0.63675, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/023-0.6367.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.8682 - acc: 0.7409 - val_loss: 0.6367 - val_acc: 0.8220\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8448 - acc: 0.7476\n",
      "Epoch 00024: val_loss improved from 0.63675 to 0.61744, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/024-0.6174.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.8448 - acc: 0.7475 - val_loss: 0.6174 - val_acc: 0.8360\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8315 - acc: 0.7531\n",
      "Epoch 00025: val_loss did not improve from 0.61744\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.8315 - acc: 0.7531 - val_loss: 0.6218 - val_acc: 0.8265\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8039 - acc: 0.7612\n",
      "Epoch 00026: val_loss improved from 0.61744 to 0.57273, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/026-0.5727.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.8038 - acc: 0.7612 - val_loss: 0.5727 - val_acc: 0.8456\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7845 - acc: 0.7663\n",
      "Epoch 00027: val_loss improved from 0.57273 to 0.57055, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/027-0.5705.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.7845 - acc: 0.7663 - val_loss: 0.5705 - val_acc: 0.8463\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7664 - acc: 0.7734\n",
      "Epoch 00028: val_loss improved from 0.57055 to 0.55333, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/028-0.5533.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.7664 - acc: 0.7734 - val_loss: 0.5533 - val_acc: 0.8458\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7532 - acc: 0.7776\n",
      "Epoch 00029: val_loss improved from 0.55333 to 0.54114, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/029-0.5411.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.7531 - acc: 0.7776 - val_loss: 0.5411 - val_acc: 0.8526\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7416 - acc: 0.7793\n",
      "Epoch 00030: val_loss improved from 0.54114 to 0.51907, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/030-0.5191.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.7416 - acc: 0.7793 - val_loss: 0.5191 - val_acc: 0.8612\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7278 - acc: 0.7854\n",
      "Epoch 00031: val_loss did not improve from 0.51907\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.7278 - acc: 0.7854 - val_loss: 0.5313 - val_acc: 0.8595\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7115 - acc: 0.7907\n",
      "Epoch 00032: val_loss improved from 0.51907 to 0.50051, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/032-0.5005.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.7115 - acc: 0.7907 - val_loss: 0.5005 - val_acc: 0.8630\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6998 - acc: 0.7916\n",
      "Epoch 00033: val_loss improved from 0.50051 to 0.48375, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/033-0.4837.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.6997 - acc: 0.7916 - val_loss: 0.4837 - val_acc: 0.8686\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6901 - acc: 0.7949\n",
      "Epoch 00034: val_loss improved from 0.48375 to 0.48010, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/034-0.4801.hdf5\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.6900 - acc: 0.7949 - val_loss: 0.4801 - val_acc: 0.8677\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6794 - acc: 0.8008\n",
      "Epoch 00035: val_loss improved from 0.48010 to 0.45986, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/035-0.4599.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.6794 - acc: 0.8009 - val_loss: 0.4599 - val_acc: 0.8770\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6664 - acc: 0.8027\n",
      "Epoch 00036: val_loss improved from 0.45986 to 0.45120, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/036-0.4512.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.6666 - acc: 0.8027 - val_loss: 0.4512 - val_acc: 0.8782\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6559 - acc: 0.8056\n",
      "Epoch 00037: val_loss did not improve from 0.45120\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.6559 - acc: 0.8056 - val_loss: 0.4574 - val_acc: 0.8796\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6398 - acc: 0.8101\n",
      "Epoch 00038: val_loss improved from 0.45120 to 0.43861, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/038-0.4386.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.6398 - acc: 0.8100 - val_loss: 0.4386 - val_acc: 0.8847\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6338 - acc: 0.8129\n",
      "Epoch 00039: val_loss did not improve from 0.43861\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.6337 - acc: 0.8129 - val_loss: 0.4518 - val_acc: 0.8800\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6262 - acc: 0.8143\n",
      "Epoch 00040: val_loss improved from 0.43861 to 0.41891, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/040-0.4189.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.6263 - acc: 0.8142 - val_loss: 0.4189 - val_acc: 0.8868\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6192 - acc: 0.8178\n",
      "Epoch 00041: val_loss did not improve from 0.41891\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.6191 - acc: 0.8179 - val_loss: 0.4218 - val_acc: 0.8884\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6071 - acc: 0.8205\n",
      "Epoch 00042: val_loss improved from 0.41891 to 0.40849, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/042-0.4085.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.6072 - acc: 0.8204 - val_loss: 0.4085 - val_acc: 0.8940\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6005 - acc: 0.8218\n",
      "Epoch 00043: val_loss improved from 0.40849 to 0.40280, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/043-0.4028.hdf5\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.6005 - acc: 0.8218 - val_loss: 0.4028 - val_acc: 0.8959\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5889 - acc: 0.8269\n",
      "Epoch 00044: val_loss did not improve from 0.40280\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.5889 - acc: 0.8269 - val_loss: 0.4173 - val_acc: 0.8842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5843 - acc: 0.8270\n",
      "Epoch 00045: val_loss improved from 0.40280 to 0.38673, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/045-0.3867.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.5842 - acc: 0.8270 - val_loss: 0.3867 - val_acc: 0.8980\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5724 - acc: 0.8290\n",
      "Epoch 00046: val_loss improved from 0.38673 to 0.37633, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/046-0.3763.hdf5\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.5723 - acc: 0.8290 - val_loss: 0.3763 - val_acc: 0.8989\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5716 - acc: 0.8317\n",
      "Epoch 00047: val_loss did not improve from 0.37633\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.5716 - acc: 0.8317 - val_loss: 0.3791 - val_acc: 0.8966\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5702 - acc: 0.8309\n",
      "Epoch 00048: val_loss did not improve from 0.37633\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.5702 - acc: 0.8309 - val_loss: 0.3779 - val_acc: 0.8991\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5614 - acc: 0.8352\n",
      "Epoch 00049: val_loss improved from 0.37633 to 0.37003, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/049-0.3700.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.5615 - acc: 0.8352 - val_loss: 0.3700 - val_acc: 0.9012\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5490 - acc: 0.8371\n",
      "Epoch 00050: val_loss improved from 0.37003 to 0.36698, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/050-0.3670.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.5489 - acc: 0.8371 - val_loss: 0.3670 - val_acc: 0.9022\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5442 - acc: 0.8387\n",
      "Epoch 00051: val_loss improved from 0.36698 to 0.35121, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/051-0.3512.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.5443 - acc: 0.8386 - val_loss: 0.3512 - val_acc: 0.9059\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5412 - acc: 0.8409\n",
      "Epoch 00052: val_loss did not improve from 0.35121\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.5412 - acc: 0.8409 - val_loss: 0.3594 - val_acc: 0.9036\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5334 - acc: 0.8426\n",
      "Epoch 00053: val_loss improved from 0.35121 to 0.35031, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/053-0.3503.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.5333 - acc: 0.8426 - val_loss: 0.3503 - val_acc: 0.9033\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5273 - acc: 0.8424\n",
      "Epoch 00054: val_loss improved from 0.35031 to 0.34251, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/054-0.3425.hdf5\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.5276 - acc: 0.8423 - val_loss: 0.3425 - val_acc: 0.9071\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5215 - acc: 0.8433\n",
      "Epoch 00055: val_loss improved from 0.34251 to 0.33852, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/055-0.3385.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.5215 - acc: 0.8433 - val_loss: 0.3385 - val_acc: 0.9103\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5150 - acc: 0.8469\n",
      "Epoch 00056: val_loss did not improve from 0.33852\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.5149 - acc: 0.8470 - val_loss: 0.3413 - val_acc: 0.9066\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5161 - acc: 0.8465\n",
      "Epoch 00057: val_loss improved from 0.33852 to 0.32921, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/057-0.3292.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.5162 - acc: 0.8465 - val_loss: 0.3292 - val_acc: 0.9133\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5043 - acc: 0.8499\n",
      "Epoch 00058: val_loss did not improve from 0.32921\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.5043 - acc: 0.8499 - val_loss: 0.3324 - val_acc: 0.9103\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5034 - acc: 0.8506\n",
      "Epoch 00059: val_loss did not improve from 0.32921\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.5034 - acc: 0.8506 - val_loss: 0.3386 - val_acc: 0.9071\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4954 - acc: 0.8532\n",
      "Epoch 00060: val_loss improved from 0.32921 to 0.32917, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/060-0.3292.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.4954 - acc: 0.8532 - val_loss: 0.3292 - val_acc: 0.9117\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4953 - acc: 0.8549\n",
      "Epoch 00061: val_loss improved from 0.32917 to 0.31365, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/061-0.3137.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.4953 - acc: 0.8550 - val_loss: 0.3137 - val_acc: 0.9154\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4895 - acc: 0.8529\n",
      "Epoch 00062: val_loss did not improve from 0.31365\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.4895 - acc: 0.8529 - val_loss: 0.3195 - val_acc: 0.9175\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4826 - acc: 0.8588\n",
      "Epoch 00063: val_loss improved from 0.31365 to 0.31218, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/063-0.3122.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.4827 - acc: 0.8588 - val_loss: 0.3122 - val_acc: 0.9194\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4809 - acc: 0.8578\n",
      "Epoch 00064: val_loss did not improve from 0.31218\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.4809 - acc: 0.8578 - val_loss: 0.3238 - val_acc: 0.9101\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4733 - acc: 0.8590\n",
      "Epoch 00065: val_loss did not improve from 0.31218\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.4734 - acc: 0.8590 - val_loss: 0.3156 - val_acc: 0.9133\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4649 - acc: 0.8604\n",
      "Epoch 00066: val_loss improved from 0.31218 to 0.29882, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/066-0.2988.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.4649 - acc: 0.8604 - val_loss: 0.2988 - val_acc: 0.9199\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4692 - acc: 0.8611\n",
      "Epoch 00067: val_loss improved from 0.29882 to 0.29626, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/067-0.2963.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.4692 - acc: 0.8612 - val_loss: 0.2963 - val_acc: 0.9234\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4609 - acc: 0.8645\n",
      "Epoch 00068: val_loss did not improve from 0.29626\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.4609 - acc: 0.8645 - val_loss: 0.3119 - val_acc: 0.9145\n",
      "Epoch 69/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4582 - acc: 0.8626\n",
      "Epoch 00069: val_loss did not improve from 0.29626\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.4581 - acc: 0.8626 - val_loss: 0.3034 - val_acc: 0.9143\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4566 - acc: 0.8644\n",
      "Epoch 00070: val_loss improved from 0.29626 to 0.29264, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/070-0.2926.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.4566 - acc: 0.8644 - val_loss: 0.2926 - val_acc: 0.9206\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4519 - acc: 0.8655\n",
      "Epoch 00071: val_loss did not improve from 0.29264\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.4518 - acc: 0.8655 - val_loss: 0.2982 - val_acc: 0.9192\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4475 - acc: 0.8646\n",
      "Epoch 00072: val_loss did not improve from 0.29264\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.4475 - acc: 0.8647 - val_loss: 0.3056 - val_acc: 0.9157\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4514 - acc: 0.8662\n",
      "Epoch 00073: val_loss did not improve from 0.29264\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.4514 - acc: 0.8662 - val_loss: 0.2979 - val_acc: 0.9194\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4463 - acc: 0.8673\n",
      "Epoch 00074: val_loss did not improve from 0.29264\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.4463 - acc: 0.8672 - val_loss: 0.2965 - val_acc: 0.9210\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4444 - acc: 0.8688\n",
      "Epoch 00075: val_loss improved from 0.29264 to 0.27959, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/075-0.2796.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.4444 - acc: 0.8688 - val_loss: 0.2796 - val_acc: 0.9271\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4396 - acc: 0.8692\n",
      "Epoch 00076: val_loss did not improve from 0.27959\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.4396 - acc: 0.8692 - val_loss: 0.2833 - val_acc: 0.9236\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4318 - acc: 0.8696\n",
      "Epoch 00077: val_loss improved from 0.27959 to 0.27180, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/077-0.2718.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.4318 - acc: 0.8696 - val_loss: 0.2718 - val_acc: 0.9269\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4327 - acc: 0.8705\n",
      "Epoch 00078: val_loss did not improve from 0.27180\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.4327 - acc: 0.8705 - val_loss: 0.3027 - val_acc: 0.9185\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4298 - acc: 0.8703\n",
      "Epoch 00079: val_loss did not improve from 0.27180\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.4297 - acc: 0.8703 - val_loss: 0.2800 - val_acc: 0.9266\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4282 - acc: 0.8711\n",
      "Epoch 00080: val_loss did not improve from 0.27180\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.4284 - acc: 0.8711 - val_loss: 0.2723 - val_acc: 0.9255\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4226 - acc: 0.8743\n",
      "Epoch 00081: val_loss did not improve from 0.27180\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.4226 - acc: 0.8743 - val_loss: 0.2722 - val_acc: 0.9276\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4171 - acc: 0.8736\n",
      "Epoch 00082: val_loss did not improve from 0.27180\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.4172 - acc: 0.8736 - val_loss: 0.2822 - val_acc: 0.9220\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4204 - acc: 0.8742\n",
      "Epoch 00083: val_loss improved from 0.27180 to 0.26615, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/083-0.2662.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.4204 - acc: 0.8743 - val_loss: 0.2662 - val_acc: 0.9287\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4176 - acc: 0.8746\n",
      "Epoch 00084: val_loss did not improve from 0.26615\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.4175 - acc: 0.8746 - val_loss: 0.2688 - val_acc: 0.9290\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4076 - acc: 0.8768\n",
      "Epoch 00085: val_loss did not improve from 0.26615\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.4076 - acc: 0.8768 - val_loss: 0.2712 - val_acc: 0.9285\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4127 - acc: 0.8770\n",
      "Epoch 00086: val_loss did not improve from 0.26615\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.4127 - acc: 0.8770 - val_loss: 0.2723 - val_acc: 0.9264\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4130 - acc: 0.8760\n",
      "Epoch 00087: val_loss did not improve from 0.26615\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.4130 - acc: 0.8760 - val_loss: 0.2665 - val_acc: 0.9308\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4067 - acc: 0.8769\n",
      "Epoch 00088: val_loss improved from 0.26615 to 0.25980, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/088-0.2598.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.4066 - acc: 0.8769 - val_loss: 0.2598 - val_acc: 0.9306\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4035 - acc: 0.8793\n",
      "Epoch 00089: val_loss did not improve from 0.25980\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.4035 - acc: 0.8793 - val_loss: 0.2608 - val_acc: 0.9315\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4019 - acc: 0.8801\n",
      "Epoch 00090: val_loss improved from 0.25980 to 0.25645, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/090-0.2564.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.4018 - acc: 0.8801 - val_loss: 0.2564 - val_acc: 0.9329\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4013 - acc: 0.8793\n",
      "Epoch 00091: val_loss did not improve from 0.25645\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.4013 - acc: 0.8794 - val_loss: 0.2585 - val_acc: 0.9311\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3944 - acc: 0.8810\n",
      "Epoch 00092: val_loss did not improve from 0.25645\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.3944 - acc: 0.8810 - val_loss: 0.2601 - val_acc: 0.9308\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3954 - acc: 0.8818\n",
      "Epoch 00093: val_loss improved from 0.25645 to 0.25426, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/093-0.2543.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3953 - acc: 0.8818 - val_loss: 0.2543 - val_acc: 0.9341\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3926 - acc: 0.8807\n",
      "Epoch 00094: val_loss did not improve from 0.25426\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3927 - acc: 0.8807 - val_loss: 0.2549 - val_acc: 0.9322\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3920 - acc: 0.8822\n",
      "Epoch 00095: val_loss did not improve from 0.25426\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.3920 - acc: 0.8822 - val_loss: 0.2626 - val_acc: 0.9306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3883 - acc: 0.8814\n",
      "Epoch 00096: val_loss did not improve from 0.25426\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3883 - acc: 0.8814 - val_loss: 0.2570 - val_acc: 0.9327\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3890 - acc: 0.8833\n",
      "Epoch 00097: val_loss improved from 0.25426 to 0.25258, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/097-0.2526.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.3890 - acc: 0.8833 - val_loss: 0.2526 - val_acc: 0.9331\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3828 - acc: 0.8856\n",
      "Epoch 00098: val_loss improved from 0.25258 to 0.24990, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/098-0.2499.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3828 - acc: 0.8856 - val_loss: 0.2499 - val_acc: 0.9322\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3843 - acc: 0.8823\n",
      "Epoch 00099: val_loss did not improve from 0.24990\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3842 - acc: 0.8823 - val_loss: 0.2565 - val_acc: 0.9320\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3806 - acc: 0.8862\n",
      "Epoch 00100: val_loss did not improve from 0.24990\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.3806 - acc: 0.8862 - val_loss: 0.2739 - val_acc: 0.9262\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3803 - acc: 0.8869\n",
      "Epoch 00101: val_loss did not improve from 0.24990\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.3803 - acc: 0.8869 - val_loss: 0.2572 - val_acc: 0.9317\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3737 - acc: 0.8895\n",
      "Epoch 00102: val_loss improved from 0.24990 to 0.24574, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/102-0.2457.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3737 - acc: 0.8895 - val_loss: 0.2457 - val_acc: 0.9350\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3788 - acc: 0.8856\n",
      "Epoch 00103: val_loss did not improve from 0.24574\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.3790 - acc: 0.8856 - val_loss: 0.2567 - val_acc: 0.9292\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3773 - acc: 0.8852\n",
      "Epoch 00104: val_loss improved from 0.24574 to 0.23844, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/104-0.2384.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.3772 - acc: 0.8852 - val_loss: 0.2384 - val_acc: 0.9362\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3742 - acc: 0.8861\n",
      "Epoch 00105: val_loss did not improve from 0.23844\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3742 - acc: 0.8861 - val_loss: 0.2446 - val_acc: 0.9362\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3707 - acc: 0.8889\n",
      "Epoch 00106: val_loss did not improve from 0.23844\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.3708 - acc: 0.8888 - val_loss: 0.2387 - val_acc: 0.9371\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3723 - acc: 0.8879\n",
      "Epoch 00107: val_loss did not improve from 0.23844\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3723 - acc: 0.8879 - val_loss: 0.2451 - val_acc: 0.9334\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3621 - acc: 0.8901\n",
      "Epoch 00108: val_loss did not improve from 0.23844\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.3621 - acc: 0.8901 - val_loss: 0.2512 - val_acc: 0.9313\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3661 - acc: 0.8879\n",
      "Epoch 00109: val_loss did not improve from 0.23844\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.3661 - acc: 0.8879 - val_loss: 0.2556 - val_acc: 0.9283\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3594 - acc: 0.8911\n",
      "Epoch 00110: val_loss improved from 0.23844 to 0.23565, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/110-0.2357.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3593 - acc: 0.8911 - val_loss: 0.2357 - val_acc: 0.9380\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3601 - acc: 0.8909\n",
      "Epoch 00111: val_loss did not improve from 0.23565\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.3601 - acc: 0.8909 - val_loss: 0.2436 - val_acc: 0.9338\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3569 - acc: 0.8920\n",
      "Epoch 00112: val_loss improved from 0.23565 to 0.23445, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/112-0.2345.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3570 - acc: 0.8920 - val_loss: 0.2345 - val_acc: 0.9397\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3523 - acc: 0.8934\n",
      "Epoch 00113: val_loss did not improve from 0.23445\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.3523 - acc: 0.8934 - val_loss: 0.2355 - val_acc: 0.9371\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3587 - acc: 0.8919\n",
      "Epoch 00114: val_loss improved from 0.23445 to 0.23242, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/114-0.2324.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.3587 - acc: 0.8919 - val_loss: 0.2324 - val_acc: 0.9366\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3589 - acc: 0.8921\n",
      "Epoch 00115: val_loss did not improve from 0.23242\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.3589 - acc: 0.8921 - val_loss: 0.2440 - val_acc: 0.9371\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3574 - acc: 0.8926\n",
      "Epoch 00116: val_loss did not improve from 0.23242\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3575 - acc: 0.8925 - val_loss: 0.2341 - val_acc: 0.9392\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3535 - acc: 0.8935\n",
      "Epoch 00117: val_loss improved from 0.23242 to 0.22845, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/117-0.2285.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.3535 - acc: 0.8935 - val_loss: 0.2285 - val_acc: 0.9399\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3494 - acc: 0.8945\n",
      "Epoch 00118: val_loss did not improve from 0.22845\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3493 - acc: 0.8945 - val_loss: 0.2426 - val_acc: 0.9371\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3472 - acc: 0.8920\n",
      "Epoch 00119: val_loss did not improve from 0.22845\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3472 - acc: 0.8920 - val_loss: 0.2385 - val_acc: 0.9341\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3480 - acc: 0.8946\n",
      "Epoch 00120: val_loss did not improve from 0.22845\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3480 - acc: 0.8946 - val_loss: 0.2289 - val_acc: 0.9385\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3458 - acc: 0.8947\n",
      "Epoch 00121: val_loss improved from 0.22845 to 0.22206, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/121-0.2221.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.3458 - acc: 0.8947 - val_loss: 0.2221 - val_acc: 0.9408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3452 - acc: 0.8974\n",
      "Epoch 00122: val_loss did not improve from 0.22206\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3452 - acc: 0.8974 - val_loss: 0.2330 - val_acc: 0.9385\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3374 - acc: 0.8974\n",
      "Epoch 00123: val_loss did not improve from 0.22206\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3374 - acc: 0.8974 - val_loss: 0.2383 - val_acc: 0.9380\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3378 - acc: 0.8990\n",
      "Epoch 00124: val_loss did not improve from 0.22206\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.3377 - acc: 0.8991 - val_loss: 0.2277 - val_acc: 0.9394\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3335 - acc: 0.8985\n",
      "Epoch 00125: val_loss did not improve from 0.22206\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3335 - acc: 0.8985 - val_loss: 0.2241 - val_acc: 0.9394\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3375 - acc: 0.8972\n",
      "Epoch 00126: val_loss did not improve from 0.22206\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.3374 - acc: 0.8972 - val_loss: 0.2254 - val_acc: 0.9383\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3325 - acc: 0.8999\n",
      "Epoch 00127: val_loss improved from 0.22206 to 0.22031, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/127-0.2203.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.3325 - acc: 0.9000 - val_loss: 0.2203 - val_acc: 0.9394\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3338 - acc: 0.8979\n",
      "Epoch 00128: val_loss did not improve from 0.22031\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3337 - acc: 0.8979 - val_loss: 0.2252 - val_acc: 0.9411\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3384 - acc: 0.8972\n",
      "Epoch 00129: val_loss did not improve from 0.22031\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3384 - acc: 0.8972 - val_loss: 0.2244 - val_acc: 0.9411\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3329 - acc: 0.8982\n",
      "Epoch 00130: val_loss did not improve from 0.22031\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.3328 - acc: 0.8982 - val_loss: 0.2248 - val_acc: 0.9401\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3254 - acc: 0.9008\n",
      "Epoch 00131: val_loss improved from 0.22031 to 0.21904, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/131-0.2190.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.3254 - acc: 0.9008 - val_loss: 0.2190 - val_acc: 0.9418\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3270 - acc: 0.8995\n",
      "Epoch 00132: val_loss improved from 0.21904 to 0.21745, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/132-0.2174.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3269 - acc: 0.8995 - val_loss: 0.2174 - val_acc: 0.9425\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3279 - acc: 0.9012\n",
      "Epoch 00133: val_loss did not improve from 0.21745\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3280 - acc: 0.9011 - val_loss: 0.2175 - val_acc: 0.9418\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3306 - acc: 0.8999\n",
      "Epoch 00134: val_loss improved from 0.21745 to 0.21007, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/134-0.2101.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.3305 - acc: 0.8999 - val_loss: 0.2101 - val_acc: 0.9450\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3256 - acc: 0.9001\n",
      "Epoch 00135: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.3255 - acc: 0.9001 - val_loss: 0.2173 - val_acc: 0.9404\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3243 - acc: 0.9013\n",
      "Epoch 00136: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.3242 - acc: 0.9013 - val_loss: 0.2214 - val_acc: 0.9408\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3178 - acc: 0.9040\n",
      "Epoch 00137: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3177 - acc: 0.9040 - val_loss: 0.2110 - val_acc: 0.9432\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3180 - acc: 0.9028\n",
      "Epoch 00138: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3181 - acc: 0.9028 - val_loss: 0.2222 - val_acc: 0.9420\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3211 - acc: 0.9034\n",
      "Epoch 00139: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.3211 - acc: 0.9034 - val_loss: 0.2218 - val_acc: 0.9406\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3132 - acc: 0.9051\n",
      "Epoch 00140: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3131 - acc: 0.9051 - val_loss: 0.2171 - val_acc: 0.9415\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3230 - acc: 0.9018\n",
      "Epoch 00141: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.3230 - acc: 0.9018 - val_loss: 0.2214 - val_acc: 0.9420\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3194 - acc: 0.9023\n",
      "Epoch 00142: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3194 - acc: 0.9023 - val_loss: 0.2229 - val_acc: 0.9415\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3155 - acc: 0.9036\n",
      "Epoch 00143: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3154 - acc: 0.9036 - val_loss: 0.2130 - val_acc: 0.9439\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3132 - acc: 0.9051\n",
      "Epoch 00144: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3132 - acc: 0.9051 - val_loss: 0.2108 - val_acc: 0.9420\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3150 - acc: 0.9043\n",
      "Epoch 00145: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3150 - acc: 0.9043 - val_loss: 0.2217 - val_acc: 0.9392\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3146 - acc: 0.9060\n",
      "Epoch 00146: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3146 - acc: 0.9060 - val_loss: 0.2229 - val_acc: 0.9420\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3097 - acc: 0.9050\n",
      "Epoch 00147: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.3096 - acc: 0.9050 - val_loss: 0.2150 - val_acc: 0.9399\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3117 - acc: 0.9050\n",
      "Epoch 00148: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3118 - acc: 0.9050 - val_loss: 0.2176 - val_acc: 0.9406\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3105 - acc: 0.9044\n",
      "Epoch 00149: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.3105 - acc: 0.9044 - val_loss: 0.2138 - val_acc: 0.9390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3093 - acc: 0.9068\n",
      "Epoch 00150: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.3093 - acc: 0.9068 - val_loss: 0.2155 - val_acc: 0.9429\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3031 - acc: 0.9078\n",
      "Epoch 00151: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.3031 - acc: 0.9078 - val_loss: 0.2126 - val_acc: 0.9432\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3072 - acc: 0.9068\n",
      "Epoch 00152: val_loss improved from 0.21007 to 0.20911, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/152-0.2091.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.3072 - acc: 0.9068 - val_loss: 0.2091 - val_acc: 0.9418\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3030 - acc: 0.9070\n",
      "Epoch 00153: val_loss did not improve from 0.20911\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3029 - acc: 0.9070 - val_loss: 0.2114 - val_acc: 0.9441\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3033 - acc: 0.9075\n",
      "Epoch 00154: val_loss did not improve from 0.20911\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3033 - acc: 0.9075 - val_loss: 0.2100 - val_acc: 0.9434\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3065 - acc: 0.9058\n",
      "Epoch 00155: val_loss improved from 0.20911 to 0.20560, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/155-0.2056.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.3065 - acc: 0.9058 - val_loss: 0.2056 - val_acc: 0.9436\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3039 - acc: 0.9064\n",
      "Epoch 00156: val_loss did not improve from 0.20560\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3039 - acc: 0.9064 - val_loss: 0.2085 - val_acc: 0.9406\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3053 - acc: 0.9063\n",
      "Epoch 00157: val_loss did not improve from 0.20560\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3053 - acc: 0.9063 - val_loss: 0.2109 - val_acc: 0.9422\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3038 - acc: 0.9068\n",
      "Epoch 00158: val_loss did not improve from 0.20560\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3038 - acc: 0.9068 - val_loss: 0.2125 - val_acc: 0.9401\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2984 - acc: 0.9101\n",
      "Epoch 00159: val_loss improved from 0.20560 to 0.20478, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/159-0.2048.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2984 - acc: 0.9101 - val_loss: 0.2048 - val_acc: 0.9460\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2939 - acc: 0.9101\n",
      "Epoch 00160: val_loss did not improve from 0.20478\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2939 - acc: 0.9101 - val_loss: 0.2101 - val_acc: 0.9422\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2997 - acc: 0.9101\n",
      "Epoch 00161: val_loss did not improve from 0.20478\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2997 - acc: 0.9101 - val_loss: 0.2051 - val_acc: 0.9443\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2983 - acc: 0.9078\n",
      "Epoch 00162: val_loss improved from 0.20478 to 0.20322, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/162-0.2032.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2983 - acc: 0.9078 - val_loss: 0.2032 - val_acc: 0.9478\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2972 - acc: 0.9092\n",
      "Epoch 00163: val_loss did not improve from 0.20322\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2972 - acc: 0.9092 - val_loss: 0.2046 - val_acc: 0.9476\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2946 - acc: 0.9107\n",
      "Epoch 00164: val_loss improved from 0.20322 to 0.20049, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/164-0.2005.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.2945 - acc: 0.9107 - val_loss: 0.2005 - val_acc: 0.9453\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2949 - acc: 0.9102\n",
      "Epoch 00165: val_loss did not improve from 0.20049\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2948 - acc: 0.9103 - val_loss: 0.2065 - val_acc: 0.9432\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2864 - acc: 0.9092\n",
      "Epoch 00166: val_loss did not improve from 0.20049\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2865 - acc: 0.9092 - val_loss: 0.2073 - val_acc: 0.9436\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2908 - acc: 0.9103\n",
      "Epoch 00167: val_loss did not improve from 0.20049\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2908 - acc: 0.9103 - val_loss: 0.2050 - val_acc: 0.9446\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2898 - acc: 0.9113\n",
      "Epoch 00168: val_loss improved from 0.20049 to 0.19535, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/168-0.1953.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2898 - acc: 0.9113 - val_loss: 0.1953 - val_acc: 0.9478\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2862 - acc: 0.9110\n",
      "Epoch 00169: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2863 - acc: 0.9109 - val_loss: 0.2097 - val_acc: 0.9443\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2847 - acc: 0.9136\n",
      "Epoch 00170: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2847 - acc: 0.9136 - val_loss: 0.2039 - val_acc: 0.9460\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2874 - acc: 0.9111\n",
      "Epoch 00171: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2873 - acc: 0.9111 - val_loss: 0.2042 - val_acc: 0.9455\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2859 - acc: 0.9129\n",
      "Epoch 00172: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2858 - acc: 0.9129 - val_loss: 0.2024 - val_acc: 0.9453\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2858 - acc: 0.9129\n",
      "Epoch 00173: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2857 - acc: 0.9129 - val_loss: 0.1993 - val_acc: 0.9443\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2817 - acc: 0.9127\n",
      "Epoch 00174: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.2818 - acc: 0.9126 - val_loss: 0.2109 - val_acc: 0.9450\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2848 - acc: 0.9137\n",
      "Epoch 00175: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2848 - acc: 0.9137 - val_loss: 0.2040 - val_acc: 0.9469\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2836 - acc: 0.9137\n",
      "Epoch 00176: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2836 - acc: 0.9137 - val_loss: 0.2059 - val_acc: 0.9457\n",
      "Epoch 177/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2810 - acc: 0.9146\n",
      "Epoch 00177: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2810 - acc: 0.9146 - val_loss: 0.2019 - val_acc: 0.9446\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2811 - acc: 0.9148\n",
      "Epoch 00178: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2811 - acc: 0.9148 - val_loss: 0.2128 - val_acc: 0.9422\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2786 - acc: 0.9141\n",
      "Epoch 00179: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2787 - acc: 0.9141 - val_loss: 0.2154 - val_acc: 0.9422\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2737 - acc: 0.9155\n",
      "Epoch 00180: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2736 - acc: 0.9156 - val_loss: 0.1998 - val_acc: 0.9455\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2807 - acc: 0.9125\n",
      "Epoch 00181: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.2807 - acc: 0.9125 - val_loss: 0.2121 - val_acc: 0.9432\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2724 - acc: 0.9157\n",
      "Epoch 00182: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2724 - acc: 0.9157 - val_loss: 0.2076 - val_acc: 0.9443\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.9152\n",
      "Epoch 00183: val_loss did not improve from 0.19535\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2757 - acc: 0.9152 - val_loss: 0.2004 - val_acc: 0.9462\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2759 - acc: 0.9154\n",
      "Epoch 00184: val_loss improved from 0.19535 to 0.19246, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/184-0.1925.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2759 - acc: 0.9154 - val_loss: 0.1925 - val_acc: 0.9485\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2772 - acc: 0.9145\n",
      "Epoch 00185: val_loss did not improve from 0.19246\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2772 - acc: 0.9145 - val_loss: 0.2014 - val_acc: 0.9455\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2706 - acc: 0.9159\n",
      "Epoch 00186: val_loss did not improve from 0.19246\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2706 - acc: 0.9159 - val_loss: 0.2041 - val_acc: 0.9441\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2714 - acc: 0.9158\n",
      "Epoch 00187: val_loss did not improve from 0.19246\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2714 - acc: 0.9158 - val_loss: 0.2053 - val_acc: 0.9462\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2747 - acc: 0.9156\n",
      "Epoch 00188: val_loss did not improve from 0.19246\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.2747 - acc: 0.9156 - val_loss: 0.2040 - val_acc: 0.9443\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2740 - acc: 0.9160\n",
      "Epoch 00189: val_loss did not improve from 0.19246\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2739 - acc: 0.9160 - val_loss: 0.2002 - val_acc: 0.9448\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2710 - acc: 0.9167\n",
      "Epoch 00190: val_loss did not improve from 0.19246\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2710 - acc: 0.9167 - val_loss: 0.1998 - val_acc: 0.9455\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2712 - acc: 0.9167\n",
      "Epoch 00191: val_loss did not improve from 0.19246\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2712 - acc: 0.9168 - val_loss: 0.1997 - val_acc: 0.9474\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2715 - acc: 0.9142\n",
      "Epoch 00192: val_loss did not improve from 0.19246\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.2717 - acc: 0.9142 - val_loss: 0.1992 - val_acc: 0.9478\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2724 - acc: 0.9170\n",
      "Epoch 00193: val_loss improved from 0.19246 to 0.18846, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/193-0.1885.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.2724 - acc: 0.9169 - val_loss: 0.1885 - val_acc: 0.9492\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2715 - acc: 0.9173\n",
      "Epoch 00194: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.2715 - acc: 0.9173 - val_loss: 0.1964 - val_acc: 0.9497\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2680 - acc: 0.9176\n",
      "Epoch 00195: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2680 - acc: 0.9176 - val_loss: 0.1972 - val_acc: 0.9460\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2667 - acc: 0.9165\n",
      "Epoch 00196: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2667 - acc: 0.9166 - val_loss: 0.1988 - val_acc: 0.9488\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2671 - acc: 0.9171\n",
      "Epoch 00197: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2671 - acc: 0.9171 - val_loss: 0.1970 - val_acc: 0.9490\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2617 - acc: 0.9190\n",
      "Epoch 00198: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2617 - acc: 0.9191 - val_loss: 0.1919 - val_acc: 0.9520\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2644 - acc: 0.9174\n",
      "Epoch 00199: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2644 - acc: 0.9175 - val_loss: 0.1958 - val_acc: 0.9499\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2643 - acc: 0.9180\n",
      "Epoch 00200: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2643 - acc: 0.9180 - val_loss: 0.1900 - val_acc: 0.9515\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2604 - acc: 0.9195\n",
      "Epoch 00201: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2604 - acc: 0.9195 - val_loss: 0.2007 - val_acc: 0.9471\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2630 - acc: 0.9197\n",
      "Epoch 00202: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2630 - acc: 0.9197 - val_loss: 0.1915 - val_acc: 0.9495\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2640 - acc: 0.9186\n",
      "Epoch 00203: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.2640 - acc: 0.9186 - val_loss: 0.1947 - val_acc: 0.9509\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2615 - acc: 0.9188\n",
      "Epoch 00204: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2619 - acc: 0.9187 - val_loss: 0.1978 - val_acc: 0.9478\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2586 - acc: 0.9201\n",
      "Epoch 00205: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.2586 - acc: 0.9201 - val_loss: 0.1981 - val_acc: 0.9483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2581 - acc: 0.9211\n",
      "Epoch 00206: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2580 - acc: 0.9211 - val_loss: 0.1942 - val_acc: 0.9497\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2620 - acc: 0.9195\n",
      "Epoch 00207: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2622 - acc: 0.9195 - val_loss: 0.1967 - val_acc: 0.9490\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2546 - acc: 0.9216\n",
      "Epoch 00208: val_loss did not improve from 0.18846\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2546 - acc: 0.9216 - val_loss: 0.1904 - val_acc: 0.9502\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2569 - acc: 0.9203\n",
      "Epoch 00209: val_loss improved from 0.18846 to 0.18809, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/209-0.1881.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.2570 - acc: 0.9203 - val_loss: 0.1881 - val_acc: 0.9520\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2581 - acc: 0.9187\n",
      "Epoch 00210: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2581 - acc: 0.9187 - val_loss: 0.1992 - val_acc: 0.9474\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2552 - acc: 0.9212\n",
      "Epoch 00211: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2552 - acc: 0.9213 - val_loss: 0.1945 - val_acc: 0.9513\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2578 - acc: 0.9187\n",
      "Epoch 00212: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2578 - acc: 0.9187 - val_loss: 0.1994 - val_acc: 0.9495\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2529 - acc: 0.9206\n",
      "Epoch 00213: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2529 - acc: 0.9206 - val_loss: 0.1956 - val_acc: 0.9497\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2531 - acc: 0.9211\n",
      "Epoch 00214: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2530 - acc: 0.9211 - val_loss: 0.2028 - val_acc: 0.9464\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2493 - acc: 0.9231\n",
      "Epoch 00215: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2493 - acc: 0.9231 - val_loss: 0.1996 - val_acc: 0.9455\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2548 - acc: 0.9221\n",
      "Epoch 00216: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2548 - acc: 0.9221 - val_loss: 0.2022 - val_acc: 0.9457\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2498 - acc: 0.9218\n",
      "Epoch 00217: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2497 - acc: 0.9218 - val_loss: 0.1976 - val_acc: 0.9464\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2509 - acc: 0.9232\n",
      "Epoch 00218: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2510 - acc: 0.9232 - val_loss: 0.1942 - val_acc: 0.9506\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2529 - acc: 0.9209\n",
      "Epoch 00219: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2529 - acc: 0.9209 - val_loss: 0.1951 - val_acc: 0.9504\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2493 - acc: 0.9208\n",
      "Epoch 00220: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2493 - acc: 0.9208 - val_loss: 0.1913 - val_acc: 0.9515\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2465 - acc: 0.9232\n",
      "Epoch 00221: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2464 - acc: 0.9232 - val_loss: 0.1964 - val_acc: 0.9513\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2493 - acc: 0.9233\n",
      "Epoch 00222: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2494 - acc: 0.9233 - val_loss: 0.2027 - val_acc: 0.9469\n",
      "Epoch 223/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2506 - acc: 0.9214\n",
      "Epoch 00223: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2506 - acc: 0.9214 - val_loss: 0.2137 - val_acc: 0.9432\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2502 - acc: 0.9217\n",
      "Epoch 00224: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2502 - acc: 0.9217 - val_loss: 0.1918 - val_acc: 0.9488\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2473 - acc: 0.9229\n",
      "Epoch 00225: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2472 - acc: 0.9229 - val_loss: 0.1886 - val_acc: 0.9520\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2473 - acc: 0.9221\n",
      "Epoch 00226: val_loss did not improve from 0.18809\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2473 - acc: 0.9221 - val_loss: 0.1991 - val_acc: 0.9485\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2468 - acc: 0.9234\n",
      "Epoch 00227: val_loss improved from 0.18809 to 0.18755, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/227-0.1876.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.2467 - acc: 0.9234 - val_loss: 0.1876 - val_acc: 0.9520\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2448 - acc: 0.9244\n",
      "Epoch 00228: val_loss did not improve from 0.18755\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2447 - acc: 0.9244 - val_loss: 0.1922 - val_acc: 0.9509\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2447 - acc: 0.9230\n",
      "Epoch 00229: val_loss did not improve from 0.18755\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2447 - acc: 0.9230 - val_loss: 0.1950 - val_acc: 0.9499\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2415 - acc: 0.9247\n",
      "Epoch 00230: val_loss did not improve from 0.18755\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2415 - acc: 0.9247 - val_loss: 0.2141 - val_acc: 0.9432\n",
      "Epoch 231/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2381 - acc: 0.9248\n",
      "Epoch 00231: val_loss improved from 0.18755 to 0.18602, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/231-0.1860.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.2380 - acc: 0.9248 - val_loss: 0.1860 - val_acc: 0.9534\n",
      "Epoch 232/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2444 - acc: 0.9232\n",
      "Epoch 00232: val_loss did not improve from 0.18602\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2444 - acc: 0.9232 - val_loss: 0.2024 - val_acc: 0.9481\n",
      "Epoch 233/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2427 - acc: 0.9240\n",
      "Epoch 00233: val_loss did not improve from 0.18602\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2426 - acc: 0.9241 - val_loss: 0.2042 - val_acc: 0.9471\n",
      "Epoch 234/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2357 - acc: 0.9258\n",
      "Epoch 00234: val_loss did not improve from 0.18602\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.2359 - acc: 0.9258 - val_loss: 0.1925 - val_acc: 0.9509\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2412 - acc: 0.9234\n",
      "Epoch 00235: val_loss did not improve from 0.18602\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2413 - acc: 0.9234 - val_loss: 0.1966 - val_acc: 0.9506\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2383 - acc: 0.9259\n",
      "Epoch 00236: val_loss did not improve from 0.18602\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2382 - acc: 0.9259 - val_loss: 0.1931 - val_acc: 0.9506\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2357 - acc: 0.9252\n",
      "Epoch 00237: val_loss did not improve from 0.18602\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2357 - acc: 0.9251 - val_loss: 0.1995 - val_acc: 0.9455\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2385 - acc: 0.9249\n",
      "Epoch 00238: val_loss did not improve from 0.18602\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2384 - acc: 0.9249 - val_loss: 0.1905 - val_acc: 0.9513\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2406 - acc: 0.9250\n",
      "Epoch 00239: val_loss did not improve from 0.18602\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2406 - acc: 0.9250 - val_loss: 0.1922 - val_acc: 0.9488\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2403 - acc: 0.9258\n",
      "Epoch 00240: val_loss did not improve from 0.18602\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2403 - acc: 0.9257 - val_loss: 0.1891 - val_acc: 0.9515\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2364 - acc: 0.9254\n",
      "Epoch 00241: val_loss did not improve from 0.18602\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2364 - acc: 0.9254 - val_loss: 0.1994 - val_acc: 0.9502\n",
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2390 - acc: 0.9250\n",
      "Epoch 00242: val_loss improved from 0.18602 to 0.18162, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv_checkpoint/242-0.1816.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2390 - acc: 0.9250 - val_loss: 0.1816 - val_acc: 0.9536\n",
      "Epoch 243/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2386 - acc: 0.9272\n",
      "Epoch 00243: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2386 - acc: 0.9272 - val_loss: 0.1997 - val_acc: 0.9490\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2372 - acc: 0.9262\n",
      "Epoch 00244: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.2372 - acc: 0.9262 - val_loss: 0.1893 - val_acc: 0.9527\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2344 - acc: 0.9275\n",
      "Epoch 00245: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2345 - acc: 0.9275 - val_loss: 0.1929 - val_acc: 0.9506\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2376 - acc: 0.9251\n",
      "Epoch 00246: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2376 - acc: 0.9251 - val_loss: 0.1892 - val_acc: 0.9525\n",
      "Epoch 247/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2343 - acc: 0.9269\n",
      "Epoch 00247: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2343 - acc: 0.9269 - val_loss: 0.2005 - val_acc: 0.9490\n",
      "Epoch 248/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2341 - acc: 0.9277\n",
      "Epoch 00248: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2341 - acc: 0.9277 - val_loss: 0.1988 - val_acc: 0.9509\n",
      "Epoch 249/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2348 - acc: 0.9268\n",
      "Epoch 00249: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2348 - acc: 0.9267 - val_loss: 0.1987 - val_acc: 0.9509\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2323 - acc: 0.9278\n",
      "Epoch 00250: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.2324 - acc: 0.9278 - val_loss: 0.1910 - val_acc: 0.9506\n",
      "Epoch 251/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2310 - acc: 0.9270\n",
      "Epoch 00251: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2310 - acc: 0.9270 - val_loss: 0.2002 - val_acc: 0.9481\n",
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2353 - acc: 0.9270\n",
      "Epoch 00252: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.2353 - acc: 0.9270 - val_loss: 0.1980 - val_acc: 0.9474\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2364 - acc: 0.9262\n",
      "Epoch 00253: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.2364 - acc: 0.9262 - val_loss: 0.1945 - val_acc: 0.9490\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2315 - acc: 0.9278\n",
      "Epoch 00254: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.2315 - acc: 0.9278 - val_loss: 0.1996 - val_acc: 0.9490\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2243 - acc: 0.9291\n",
      "Epoch 00255: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2242 - acc: 0.9291 - val_loss: 0.1901 - val_acc: 0.9522\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2268 - acc: 0.9274\n",
      "Epoch 00256: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2268 - acc: 0.9274 - val_loss: 0.1891 - val_acc: 0.9527\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2239 - acc: 0.9292\n",
      "Epoch 00257: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.2239 - acc: 0.9292 - val_loss: 0.1891 - val_acc: 0.9522\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2297 - acc: 0.9272\n",
      "Epoch 00258: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.2298 - acc: 0.9272 - val_loss: 0.1932 - val_acc: 0.9506\n",
      "Epoch 259/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2294 - acc: 0.9274\n",
      "Epoch 00259: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2294 - acc: 0.9274 - val_loss: 0.1863 - val_acc: 0.9525\n",
      "Epoch 260/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2236 - acc: 0.9296\n",
      "Epoch 00260: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2236 - acc: 0.9297 - val_loss: 0.1925 - val_acc: 0.9513\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9297\n",
      "Epoch 00261: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2263 - acc: 0.9297 - val_loss: 0.1956 - val_acc: 0.9478\n",
      "Epoch 262/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2198 - acc: 0.9305\n",
      "Epoch 00262: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.2198 - acc: 0.9306 - val_loss: 0.1883 - val_acc: 0.9509\n",
      "Epoch 263/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9274\n",
      "Epoch 00263: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2264 - acc: 0.9274 - val_loss: 0.2059 - val_acc: 0.9481\n",
      "Epoch 264/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2266 - acc: 0.9289\n",
      "Epoch 00264: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2266 - acc: 0.9289 - val_loss: 0.1924 - val_acc: 0.9520\n",
      "Epoch 265/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9293\n",
      "Epoch 00265: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2241 - acc: 0.9293 - val_loss: 0.1961 - val_acc: 0.9490\n",
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2260 - acc: 0.9287\n",
      "Epoch 00266: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2259 - acc: 0.9287 - val_loss: 0.2005 - val_acc: 0.9515\n",
      "Epoch 267/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2246 - acc: 0.9290\n",
      "Epoch 00267: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2247 - acc: 0.9290 - val_loss: 0.1919 - val_acc: 0.9527\n",
      "Epoch 268/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2171 - acc: 0.9314\n",
      "Epoch 00268: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2171 - acc: 0.9314 - val_loss: 0.1857 - val_acc: 0.9534\n",
      "Epoch 269/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2228 - acc: 0.9291\n",
      "Epoch 00269: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2228 - acc: 0.9291 - val_loss: 0.1856 - val_acc: 0.9522\n",
      "Epoch 270/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2173 - acc: 0.9308\n",
      "Epoch 00270: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2172 - acc: 0.9308 - val_loss: 0.1942 - val_acc: 0.9497\n",
      "Epoch 271/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2157 - acc: 0.9323\n",
      "Epoch 00271: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2156 - acc: 0.9323 - val_loss: 0.1931 - val_acc: 0.9511\n",
      "Epoch 272/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2208 - acc: 0.9305\n",
      "Epoch 00272: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2208 - acc: 0.9304 - val_loss: 0.1951 - val_acc: 0.9518\n",
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2196 - acc: 0.9301\n",
      "Epoch 00273: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2196 - acc: 0.9301 - val_loss: 0.1923 - val_acc: 0.9509\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9318\n",
      "Epoch 00274: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2135 - acc: 0.9318 - val_loss: 0.2127 - val_acc: 0.9457\n",
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2204 - acc: 0.9289\n",
      "Epoch 00275: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2204 - acc: 0.9289 - val_loss: 0.1980 - val_acc: 0.9515\n",
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2155 - acc: 0.9307\n",
      "Epoch 00276: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2154 - acc: 0.9307 - val_loss: 0.1964 - val_acc: 0.9513\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2223 - acc: 0.9306\n",
      "Epoch 00277: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2224 - acc: 0.9306 - val_loss: 0.1939 - val_acc: 0.9525\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2221 - acc: 0.9314\n",
      "Epoch 00278: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2221 - acc: 0.9314 - val_loss: 0.2042 - val_acc: 0.9474\n",
      "Epoch 279/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2163 - acc: 0.9308\n",
      "Epoch 00279: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2163 - acc: 0.9308 - val_loss: 0.1939 - val_acc: 0.9504\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2169 - acc: 0.9331\n",
      "Epoch 00280: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2170 - acc: 0.9331 - val_loss: 0.2024 - val_acc: 0.9455\n",
      "Epoch 281/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2179 - acc: 0.9308\n",
      "Epoch 00281: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2178 - acc: 0.9308 - val_loss: 0.1974 - val_acc: 0.9509\n",
      "Epoch 282/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2159 - acc: 0.9302\n",
      "Epoch 00282: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2158 - acc: 0.9302 - val_loss: 0.1887 - val_acc: 0.9532\n",
      "Epoch 283/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2187 - acc: 0.9293\n",
      "Epoch 00283: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2187 - acc: 0.9293 - val_loss: 0.1930 - val_acc: 0.9520\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2159 - acc: 0.9321\n",
      "Epoch 00284: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.2159 - acc: 0.9320 - val_loss: 0.1930 - val_acc: 0.9515\n",
      "Epoch 285/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9323\n",
      "Epoch 00285: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2132 - acc: 0.9323 - val_loss: 0.1863 - val_acc: 0.9518\n",
      "Epoch 286/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2122 - acc: 0.9327\n",
      "Epoch 00286: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2121 - acc: 0.9327 - val_loss: 0.1874 - val_acc: 0.9525\n",
      "Epoch 287/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2120 - acc: 0.9336\n",
      "Epoch 00287: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2120 - acc: 0.9336 - val_loss: 0.1875 - val_acc: 0.9541\n",
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2136 - acc: 0.9329\n",
      "Epoch 00288: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2136 - acc: 0.9329 - val_loss: 0.1841 - val_acc: 0.9529\n",
      "Epoch 289/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2148 - acc: 0.9329\n",
      "Epoch 00289: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.2148 - acc: 0.9329 - val_loss: 0.1834 - val_acc: 0.9536\n",
      "Epoch 290/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2082 - acc: 0.9338\n",
      "Epoch 00290: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2082 - acc: 0.9338 - val_loss: 0.1931 - val_acc: 0.9509\n",
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2100 - acc: 0.9324\n",
      "Epoch 00291: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2100 - acc: 0.9324 - val_loss: 0.1955 - val_acc: 0.9506\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2160 - acc: 0.9312\n",
      "Epoch 00292: val_loss did not improve from 0.18162\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.2159 - acc: 0.9313 - val_loss: 0.1926 - val_acc: 0.9515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 284us/sample - loss: 0.2175 - acc: 0.9369\n",
      "Loss: 0.21751798870407532 Accuracy: 0.93686396\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5828 - acc: 0.1527\n",
      "Epoch 00001: val_loss improved from inf to 2.11480, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/001-2.1148.hdf5\n",
      "36805/36805 [==============================] - 21s 567us/sample - loss: 2.5827 - acc: 0.1527 - val_loss: 2.1148 - val_acc: 0.3704\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9921 - acc: 0.3523\n",
      "Epoch 00002: val_loss improved from 2.11480 to 1.53910, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/002-1.5391.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 1.9920 - acc: 0.3523 - val_loss: 1.5391 - val_acc: 0.5260\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6483 - acc: 0.4581\n",
      "Epoch 00003: val_loss improved from 1.53910 to 1.26859, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/003-1.2686.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 1.6482 - acc: 0.4581 - val_loss: 1.2686 - val_acc: 0.6131\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4514 - acc: 0.5250\n",
      "Epoch 00004: val_loss improved from 1.26859 to 1.10284, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/004-1.1028.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 1.4514 - acc: 0.5250 - val_loss: 1.1028 - val_acc: 0.6730\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3109 - acc: 0.5733\n",
      "Epoch 00005: val_loss improved from 1.10284 to 0.97883, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/005-0.9788.hdf5\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 1.3110 - acc: 0.5732 - val_loss: 0.9788 - val_acc: 0.7151\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1980 - acc: 0.6147\n",
      "Epoch 00006: val_loss improved from 0.97883 to 0.87661, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/006-0.8766.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 1.1980 - acc: 0.6147 - val_loss: 0.8766 - val_acc: 0.7391\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1200 - acc: 0.6413\n",
      "Epoch 00007: val_loss improved from 0.87661 to 0.82148, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/007-0.8215.hdf5\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 1.1201 - acc: 0.6413 - val_loss: 0.8215 - val_acc: 0.7622\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0340 - acc: 0.6724\n",
      "Epoch 00008: val_loss improved from 0.82148 to 0.76916, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/008-0.7692.hdf5\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 1.0341 - acc: 0.6724 - val_loss: 0.7692 - val_acc: 0.7794\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9785 - acc: 0.6882\n",
      "Epoch 00009: val_loss improved from 0.76916 to 0.68875, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/009-0.6887.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.9785 - acc: 0.6882 - val_loss: 0.6887 - val_acc: 0.8001\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9247 - acc: 0.7088\n",
      "Epoch 00010: val_loss improved from 0.68875 to 0.66502, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/010-0.6650.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.9246 - acc: 0.7088 - val_loss: 0.6650 - val_acc: 0.8095\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8797 - acc: 0.7236\n",
      "Epoch 00011: val_loss improved from 0.66502 to 0.62442, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/011-0.6244.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.8796 - acc: 0.7237 - val_loss: 0.6244 - val_acc: 0.8167\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8459 - acc: 0.7339\n",
      "Epoch 00012: val_loss improved from 0.62442 to 0.59728, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/012-0.5973.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.8458 - acc: 0.7339 - val_loss: 0.5973 - val_acc: 0.8244\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8088 - acc: 0.7473\n",
      "Epoch 00013: val_loss improved from 0.59728 to 0.56727, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/013-0.5673.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.8089 - acc: 0.7473 - val_loss: 0.5673 - val_acc: 0.8421\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7736 - acc: 0.7573\n",
      "Epoch 00014: val_loss improved from 0.56727 to 0.53645, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/014-0.5364.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.7735 - acc: 0.7573 - val_loss: 0.5364 - val_acc: 0.8407\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7394 - acc: 0.7689\n",
      "Epoch 00015: val_loss improved from 0.53645 to 0.50641, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/015-0.5064.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.7393 - acc: 0.7690 - val_loss: 0.5064 - val_acc: 0.8539\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7143 - acc: 0.7770\n",
      "Epoch 00016: val_loss improved from 0.50641 to 0.48366, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/016-0.4837.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.7144 - acc: 0.7770 - val_loss: 0.4837 - val_acc: 0.8574\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6928 - acc: 0.7818\n",
      "Epoch 00017: val_loss improved from 0.48366 to 0.46909, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/017-0.4691.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.6927 - acc: 0.7819 - val_loss: 0.4691 - val_acc: 0.8595\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6666 - acc: 0.7925\n",
      "Epoch 00018: val_loss improved from 0.46909 to 0.46454, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/018-0.4645.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.6666 - acc: 0.7925 - val_loss: 0.4645 - val_acc: 0.8663\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6529 - acc: 0.7963\n",
      "Epoch 00019: val_loss improved from 0.46454 to 0.43724, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/019-0.4372.hdf5\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.6529 - acc: 0.7963 - val_loss: 0.4372 - val_acc: 0.8726\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6327 - acc: 0.8027\n",
      "Epoch 00020: val_loss improved from 0.43724 to 0.41940, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/020-0.4194.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.6327 - acc: 0.8027 - val_loss: 0.4194 - val_acc: 0.8814\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6051 - acc: 0.8124\n",
      "Epoch 00021: val_loss improved from 0.41940 to 0.40554, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/021-0.4055.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.6051 - acc: 0.8124 - val_loss: 0.4055 - val_acc: 0.8791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6010 - acc: 0.8139\n",
      "Epoch 00022: val_loss improved from 0.40554 to 0.40348, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/022-0.4035.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.6010 - acc: 0.8139 - val_loss: 0.4035 - val_acc: 0.8812\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5788 - acc: 0.8232\n",
      "Epoch 00023: val_loss improved from 0.40348 to 0.40000, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/023-0.4000.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.5788 - acc: 0.8232 - val_loss: 0.4000 - val_acc: 0.8789\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5592 - acc: 0.8277\n",
      "Epoch 00024: val_loss improved from 0.40000 to 0.37534, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/024-0.3753.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.5591 - acc: 0.8277 - val_loss: 0.3753 - val_acc: 0.8915\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5470 - acc: 0.8313\n",
      "Epoch 00025: val_loss did not improve from 0.37534\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.5470 - acc: 0.8314 - val_loss: 0.3776 - val_acc: 0.8877\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5349 - acc: 0.8347\n",
      "Epoch 00026: val_loss improved from 0.37534 to 0.35648, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/026-0.3565.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.5349 - acc: 0.8347 - val_loss: 0.3565 - val_acc: 0.8991\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5188 - acc: 0.8392\n",
      "Epoch 00027: val_loss improved from 0.35648 to 0.33769, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/027-0.3377.hdf5\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.5189 - acc: 0.8392 - val_loss: 0.3377 - val_acc: 0.9094\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5060 - acc: 0.8428\n",
      "Epoch 00028: val_loss improved from 0.33769 to 0.32984, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/028-0.3298.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.5062 - acc: 0.8428 - val_loss: 0.3298 - val_acc: 0.9054\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5002 - acc: 0.8447\n",
      "Epoch 00029: val_loss improved from 0.32984 to 0.31924, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/029-0.3192.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.5002 - acc: 0.8447 - val_loss: 0.3192 - val_acc: 0.9078\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4840 - acc: 0.8485\n",
      "Epoch 00030: val_loss improved from 0.31924 to 0.31413, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/030-0.3141.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.4839 - acc: 0.8485 - val_loss: 0.3141 - val_acc: 0.9103\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4803 - acc: 0.8529\n",
      "Epoch 00031: val_loss improved from 0.31413 to 0.30222, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/031-0.3022.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4803 - acc: 0.8528 - val_loss: 0.3022 - val_acc: 0.9133\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4705 - acc: 0.8558\n",
      "Epoch 00032: val_loss improved from 0.30222 to 0.29919, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/032-0.2992.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.4705 - acc: 0.8558 - val_loss: 0.2992 - val_acc: 0.9143\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4576 - acc: 0.8568\n",
      "Epoch 00033: val_loss improved from 0.29919 to 0.28992, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/033-0.2899.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.4575 - acc: 0.8569 - val_loss: 0.2899 - val_acc: 0.9152\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4446 - acc: 0.8620\n",
      "Epoch 00034: val_loss improved from 0.28992 to 0.28877, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/034-0.2888.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.4445 - acc: 0.8620 - val_loss: 0.2888 - val_acc: 0.9143\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4458 - acc: 0.8628\n",
      "Epoch 00035: val_loss improved from 0.28877 to 0.27297, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/035-0.2730.hdf5\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.4457 - acc: 0.8628 - val_loss: 0.2730 - val_acc: 0.9206\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4299 - acc: 0.8675\n",
      "Epoch 00036: val_loss did not improve from 0.27297\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.4298 - acc: 0.8675 - val_loss: 0.2841 - val_acc: 0.9143\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4239 - acc: 0.8702\n",
      "Epoch 00037: val_loss improved from 0.27297 to 0.26887, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/037-0.2689.hdf5\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.4239 - acc: 0.8702 - val_loss: 0.2689 - val_acc: 0.9243\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4135 - acc: 0.8723\n",
      "Epoch 00038: val_loss improved from 0.26887 to 0.26846, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/038-0.2685.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.4136 - acc: 0.8722 - val_loss: 0.2685 - val_acc: 0.9199\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4086 - acc: 0.8737\n",
      "Epoch 00039: val_loss improved from 0.26846 to 0.25712, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/039-0.2571.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.4086 - acc: 0.8737 - val_loss: 0.2571 - val_acc: 0.9269\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3944 - acc: 0.8781\n",
      "Epoch 00040: val_loss did not improve from 0.25712\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.3945 - acc: 0.8781 - val_loss: 0.2638 - val_acc: 0.9220\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3959 - acc: 0.8790\n",
      "Epoch 00041: val_loss improved from 0.25712 to 0.24562, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/041-0.2456.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.3959 - acc: 0.8790 - val_loss: 0.2456 - val_acc: 0.9297\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3841 - acc: 0.8815\n",
      "Epoch 00042: val_loss improved from 0.24562 to 0.24307, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/042-0.2431.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.3841 - acc: 0.8815 - val_loss: 0.2431 - val_acc: 0.9287\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3790 - acc: 0.8827\n",
      "Epoch 00043: val_loss improved from 0.24307 to 0.23472, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/043-0.2347.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.3790 - acc: 0.8827 - val_loss: 0.2347 - val_acc: 0.9308\n",
      "Epoch 44/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3664 - acc: 0.8853\n",
      "Epoch 00044: val_loss improved from 0.23472 to 0.23106, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/044-0.2311.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.3664 - acc: 0.8853 - val_loss: 0.2311 - val_acc: 0.9341\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3686 - acc: 0.8867\n",
      "Epoch 00045: val_loss improved from 0.23106 to 0.22688, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/045-0.2269.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.3686 - acc: 0.8867 - val_loss: 0.2269 - val_acc: 0.9338\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3625 - acc: 0.8888\n",
      "Epoch 00046: val_loss did not improve from 0.22688\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.3625 - acc: 0.8888 - val_loss: 0.2284 - val_acc: 0.9343\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3583 - acc: 0.8893\n",
      "Epoch 00047: val_loss did not improve from 0.22688\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.3583 - acc: 0.8893 - val_loss: 0.2314 - val_acc: 0.9338\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3481 - acc: 0.8942\n",
      "Epoch 00048: val_loss improved from 0.22688 to 0.21635, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/048-0.2163.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.3481 - acc: 0.8943 - val_loss: 0.2163 - val_acc: 0.9359\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3443 - acc: 0.8934\n",
      "Epoch 00049: val_loss did not improve from 0.21635\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.3443 - acc: 0.8934 - val_loss: 0.2170 - val_acc: 0.9376\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3423 - acc: 0.8942\n",
      "Epoch 00050: val_loss improved from 0.21635 to 0.21544, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/050-0.2154.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.3423 - acc: 0.8942 - val_loss: 0.2154 - val_acc: 0.9357\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3353 - acc: 0.8962\n",
      "Epoch 00051: val_loss did not improve from 0.21544\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.3353 - acc: 0.8962 - val_loss: 0.2200 - val_acc: 0.9345\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3287 - acc: 0.8978\n",
      "Epoch 00052: val_loss improved from 0.21544 to 0.21304, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/052-0.2130.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.3286 - acc: 0.8978 - val_loss: 0.2130 - val_acc: 0.9359\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3264 - acc: 0.8995\n",
      "Epoch 00053: val_loss did not improve from 0.21304\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.3264 - acc: 0.8995 - val_loss: 0.2199 - val_acc: 0.9348\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3192 - acc: 0.9008\n",
      "Epoch 00054: val_loss improved from 0.21304 to 0.20982, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/054-0.2098.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.3192 - acc: 0.9009 - val_loss: 0.2098 - val_acc: 0.9397\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3203 - acc: 0.9009\n",
      "Epoch 00055: val_loss improved from 0.20982 to 0.20492, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/055-0.2049.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.3203 - acc: 0.9009 - val_loss: 0.2049 - val_acc: 0.9413\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3124 - acc: 0.9039\n",
      "Epoch 00056: val_loss improved from 0.20492 to 0.20325, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/056-0.2032.hdf5\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.3123 - acc: 0.9040 - val_loss: 0.2032 - val_acc: 0.9413\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3088 - acc: 0.9058\n",
      "Epoch 00057: val_loss did not improve from 0.20325\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.3087 - acc: 0.9058 - val_loss: 0.2076 - val_acc: 0.9392\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3077 - acc: 0.9044\n",
      "Epoch 00058: val_loss improved from 0.20325 to 0.20106, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/058-0.2011.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.3077 - acc: 0.9044 - val_loss: 0.2011 - val_acc: 0.9427\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3026 - acc: 0.9070\n",
      "Epoch 00059: val_loss improved from 0.20106 to 0.19286, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/059-0.1929.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.3026 - acc: 0.9071 - val_loss: 0.1929 - val_acc: 0.9446\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2994 - acc: 0.9070\n",
      "Epoch 00060: val_loss did not improve from 0.19286\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.2993 - acc: 0.9070 - val_loss: 0.2023 - val_acc: 0.9413\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2955 - acc: 0.9086\n",
      "Epoch 00061: val_loss improved from 0.19286 to 0.18974, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/061-0.1897.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.2955 - acc: 0.9086 - val_loss: 0.1897 - val_acc: 0.9453\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2913 - acc: 0.9081\n",
      "Epoch 00062: val_loss did not improve from 0.18974\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.2913 - acc: 0.9081 - val_loss: 0.1934 - val_acc: 0.9432\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2904 - acc: 0.9091\n",
      "Epoch 00063: val_loss did not improve from 0.18974\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.2905 - acc: 0.9091 - val_loss: 0.2041 - val_acc: 0.9443\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2872 - acc: 0.9123\n",
      "Epoch 00064: val_loss did not improve from 0.18974\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.2872 - acc: 0.9123 - val_loss: 0.1931 - val_acc: 0.9474\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2930 - acc: 0.9102\n",
      "Epoch 00065: val_loss did not improve from 0.18974\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.2931 - acc: 0.9102 - val_loss: 0.1934 - val_acc: 0.9460\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2823 - acc: 0.9124\n",
      "Epoch 00066: val_loss did not improve from 0.18974\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.2823 - acc: 0.9124 - val_loss: 0.1962 - val_acc: 0.9439\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2807 - acc: 0.9132\n",
      "Epoch 00067: val_loss did not improve from 0.18974\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.2807 - acc: 0.9132 - val_loss: 0.1911 - val_acc: 0.9448\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2787 - acc: 0.9107\n",
      "Epoch 00068: val_loss improved from 0.18974 to 0.18421, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/068-0.1842.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.2787 - acc: 0.9107 - val_loss: 0.1842 - val_acc: 0.9457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9161\n",
      "Epoch 00069: val_loss improved from 0.18421 to 0.18258, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/069-0.1826.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.2707 - acc: 0.9161 - val_loss: 0.1826 - val_acc: 0.9474\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2672 - acc: 0.9177\n",
      "Epoch 00070: val_loss did not improve from 0.18258\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.2672 - acc: 0.9177 - val_loss: 0.1831 - val_acc: 0.9474\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2715 - acc: 0.9154\n",
      "Epoch 00071: val_loss did not improve from 0.18258\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.2715 - acc: 0.9154 - val_loss: 0.1853 - val_acc: 0.9474\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2624 - acc: 0.9173\n",
      "Epoch 00072: val_loss improved from 0.18258 to 0.17590, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/072-0.1759.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.2624 - acc: 0.9173 - val_loss: 0.1759 - val_acc: 0.9509\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2596 - acc: 0.9188\n",
      "Epoch 00073: val_loss improved from 0.17590 to 0.17301, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/073-0.1730.hdf5\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.2598 - acc: 0.9188 - val_loss: 0.1730 - val_acc: 0.9518\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2596 - acc: 0.9194\n",
      "Epoch 00074: val_loss did not improve from 0.17301\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.2596 - acc: 0.9194 - val_loss: 0.1843 - val_acc: 0.9469\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2614 - acc: 0.9190\n",
      "Epoch 00075: val_loss did not improve from 0.17301\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.2615 - acc: 0.9190 - val_loss: 0.1849 - val_acc: 0.9488\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2520 - acc: 0.9210\n",
      "Epoch 00076: val_loss did not improve from 0.17301\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.2519 - acc: 0.9210 - val_loss: 0.1752 - val_acc: 0.9495\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2546 - acc: 0.9200\n",
      "Epoch 00077: val_loss did not improve from 0.17301\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.2546 - acc: 0.9200 - val_loss: 0.1823 - val_acc: 0.9476\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2523 - acc: 0.9200\n",
      "Epoch 00078: val_loss improved from 0.17301 to 0.17181, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/078-0.1718.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.2523 - acc: 0.9200 - val_loss: 0.1718 - val_acc: 0.9509\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2456 - acc: 0.9218\n",
      "Epoch 00079: val_loss improved from 0.17181 to 0.16965, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/079-0.1697.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.2456 - acc: 0.9218 - val_loss: 0.1697 - val_acc: 0.9518\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2468 - acc: 0.9233\n",
      "Epoch 00080: val_loss improved from 0.16965 to 0.16753, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/080-0.1675.hdf5\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.2468 - acc: 0.9234 - val_loss: 0.1675 - val_acc: 0.9513\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2442 - acc: 0.9236\n",
      "Epoch 00081: val_loss improved from 0.16753 to 0.16683, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/081-0.1668.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.2441 - acc: 0.9236 - val_loss: 0.1668 - val_acc: 0.9504\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2441 - acc: 0.9238\n",
      "Epoch 00082: val_loss improved from 0.16683 to 0.16528, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/082-0.1653.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.2441 - acc: 0.9238 - val_loss: 0.1653 - val_acc: 0.9522\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2435 - acc: 0.9235\n",
      "Epoch 00083: val_loss did not improve from 0.16528\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.2434 - acc: 0.9235 - val_loss: 0.1700 - val_acc: 0.9483\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2386 - acc: 0.9247\n",
      "Epoch 00084: val_loss did not improve from 0.16528\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.2385 - acc: 0.9247 - val_loss: 0.1666 - val_acc: 0.9525\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2381 - acc: 0.9247\n",
      "Epoch 00085: val_loss did not improve from 0.16528\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.2381 - acc: 0.9246 - val_loss: 0.1660 - val_acc: 0.9520\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2358 - acc: 0.9260\n",
      "Epoch 00086: val_loss improved from 0.16528 to 0.16298, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/086-0.1630.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.2357 - acc: 0.9260 - val_loss: 0.1630 - val_acc: 0.9536\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2266 - acc: 0.9286\n",
      "Epoch 00087: val_loss did not improve from 0.16298\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.2266 - acc: 0.9286 - val_loss: 0.1668 - val_acc: 0.9499\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2292 - acc: 0.9274\n",
      "Epoch 00088: val_loss did not improve from 0.16298\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.2292 - acc: 0.9274 - val_loss: 0.1648 - val_acc: 0.9511\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2304 - acc: 0.9268\n",
      "Epoch 00089: val_loss improved from 0.16298 to 0.15833, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/089-0.1583.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.2303 - acc: 0.9268 - val_loss: 0.1583 - val_acc: 0.9546\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2254 - acc: 0.9283\n",
      "Epoch 00090: val_loss did not improve from 0.15833\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.2255 - acc: 0.9283 - val_loss: 0.1634 - val_acc: 0.9513\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9297\n",
      "Epoch 00091: val_loss did not improve from 0.15833\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.2264 - acc: 0.9297 - val_loss: 0.1725 - val_acc: 0.9513\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2223 - acc: 0.9289\n",
      "Epoch 00092: val_loss did not improve from 0.15833\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.2223 - acc: 0.9289 - val_loss: 0.1654 - val_acc: 0.9520\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2188 - acc: 0.9296\n",
      "Epoch 00093: val_loss did not improve from 0.15833\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.2188 - acc: 0.9296 - val_loss: 0.1602 - val_acc: 0.9539\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2219 - acc: 0.9299\n",
      "Epoch 00094: val_loss improved from 0.15833 to 0.15384, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/094-0.1538.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.2219 - acc: 0.9300 - val_loss: 0.1538 - val_acc: 0.9569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2199 - acc: 0.9298\n",
      "Epoch 00095: val_loss did not improve from 0.15384\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.2200 - acc: 0.9298 - val_loss: 0.1706 - val_acc: 0.9509\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2161 - acc: 0.9305\n",
      "Epoch 00096: val_loss did not improve from 0.15384\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.2161 - acc: 0.9305 - val_loss: 0.1603 - val_acc: 0.9527\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2141 - acc: 0.9323\n",
      "Epoch 00097: val_loss did not improve from 0.15384\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.2140 - acc: 0.9323 - val_loss: 0.1606 - val_acc: 0.9520\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9322\n",
      "Epoch 00098: val_loss did not improve from 0.15384\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.2127 - acc: 0.9322 - val_loss: 0.1589 - val_acc: 0.9539\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2075 - acc: 0.9332\n",
      "Epoch 00099: val_loss improved from 0.15384 to 0.15330, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/099-0.1533.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.2075 - acc: 0.9332 - val_loss: 0.1533 - val_acc: 0.9560\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2089 - acc: 0.9328\n",
      "Epoch 00100: val_loss improved from 0.15330 to 0.14983, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/100-0.1498.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.2089 - acc: 0.9328 - val_loss: 0.1498 - val_acc: 0.9592\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9329\n",
      "Epoch 00101: val_loss did not improve from 0.14983\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.2090 - acc: 0.9329 - val_loss: 0.1589 - val_acc: 0.9527\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9345\n",
      "Epoch 00102: val_loss did not improve from 0.14983\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.2089 - acc: 0.9345 - val_loss: 0.1548 - val_acc: 0.9567\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2045 - acc: 0.9337\n",
      "Epoch 00103: val_loss did not improve from 0.14983\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.2045 - acc: 0.9337 - val_loss: 0.1555 - val_acc: 0.9553\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2029 - acc: 0.9358\n",
      "Epoch 00104: val_loss did not improve from 0.14983\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.2030 - acc: 0.9358 - val_loss: 0.1594 - val_acc: 0.9509\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9364\n",
      "Epoch 00105: val_loss did not improve from 0.14983\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1984 - acc: 0.9364 - val_loss: 0.1574 - val_acc: 0.9546\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2002 - acc: 0.9354\n",
      "Epoch 00106: val_loss improved from 0.14983 to 0.14836, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/106-0.1484.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.2002 - acc: 0.9354 - val_loss: 0.1484 - val_acc: 0.9571\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2004 - acc: 0.9350\n",
      "Epoch 00107: val_loss did not improve from 0.14836\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.2004 - acc: 0.9350 - val_loss: 0.1489 - val_acc: 0.9574\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9362\n",
      "Epoch 00108: val_loss did not improve from 0.14836\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1962 - acc: 0.9362 - val_loss: 0.1535 - val_acc: 0.9539\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1946 - acc: 0.9356\n",
      "Epoch 00109: val_loss did not improve from 0.14836\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1946 - acc: 0.9356 - val_loss: 0.1522 - val_acc: 0.9576\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1963 - acc: 0.9378\n",
      "Epoch 00110: val_loss did not improve from 0.14836\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.1963 - acc: 0.9378 - val_loss: 0.1489 - val_acc: 0.9581\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1897 - acc: 0.9387\n",
      "Epoch 00111: val_loss did not improve from 0.14836\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1896 - acc: 0.9387 - val_loss: 0.1531 - val_acc: 0.9571\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9374\n",
      "Epoch 00112: val_loss did not improve from 0.14836\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1935 - acc: 0.9374 - val_loss: 0.1536 - val_acc: 0.9557\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9390\n",
      "Epoch 00113: val_loss did not improve from 0.14836\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1923 - acc: 0.9390 - val_loss: 0.1502 - val_acc: 0.9555\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9389\n",
      "Epoch 00114: val_loss did not improve from 0.14836\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1885 - acc: 0.9389 - val_loss: 0.1504 - val_acc: 0.9557\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1874 - acc: 0.9398\n",
      "Epoch 00115: val_loss did not improve from 0.14836\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1874 - acc: 0.9398 - val_loss: 0.1517 - val_acc: 0.9548\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1884 - acc: 0.9392\n",
      "Epoch 00116: val_loss did not improve from 0.14836\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1884 - acc: 0.9392 - val_loss: 0.1550 - val_acc: 0.9546\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1868 - acc: 0.9399\n",
      "Epoch 00117: val_loss did not improve from 0.14836\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.1868 - acc: 0.9399 - val_loss: 0.1580 - val_acc: 0.9534\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9412\n",
      "Epoch 00118: val_loss did not improve from 0.14836\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1820 - acc: 0.9412 - val_loss: 0.1530 - val_acc: 0.9564\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9405\n",
      "Epoch 00119: val_loss improved from 0.14836 to 0.14816, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/119-0.1482.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1830 - acc: 0.9405 - val_loss: 0.1482 - val_acc: 0.9564\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1863 - acc: 0.9398\n",
      "Epoch 00120: val_loss did not improve from 0.14816\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1863 - acc: 0.9397 - val_loss: 0.1562 - val_acc: 0.9557\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1788 - acc: 0.9425\n",
      "Epoch 00121: val_loss did not improve from 0.14816\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1788 - acc: 0.9425 - val_loss: 0.1545 - val_acc: 0.9527\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1758 - acc: 0.9415\n",
      "Epoch 00122: val_loss improved from 0.14816 to 0.14671, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/122-0.1467.hdf5\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1757 - acc: 0.9416 - val_loss: 0.1467 - val_acc: 0.9569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1801 - acc: 0.9421\n",
      "Epoch 00123: val_loss did not improve from 0.14671\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1801 - acc: 0.9421 - val_loss: 0.1483 - val_acc: 0.9571\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1766 - acc: 0.9427\n",
      "Epoch 00124: val_loss did not improve from 0.14671\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1766 - acc: 0.9428 - val_loss: 0.1498 - val_acc: 0.9574\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1797 - acc: 0.9417\n",
      "Epoch 00125: val_loss did not improve from 0.14671\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1796 - acc: 0.9417 - val_loss: 0.1500 - val_acc: 0.9576\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9433\n",
      "Epoch 00126: val_loss did not improve from 0.14671\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.1746 - acc: 0.9433 - val_loss: 0.1513 - val_acc: 0.9581\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9441\n",
      "Epoch 00127: val_loss improved from 0.14671 to 0.14456, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/127-0.1446.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1716 - acc: 0.9441 - val_loss: 0.1446 - val_acc: 0.9564\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1733 - acc: 0.9443\n",
      "Epoch 00128: val_loss did not improve from 0.14456\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.1733 - acc: 0.9444 - val_loss: 0.1463 - val_acc: 0.9564\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9442\n",
      "Epoch 00129: val_loss did not improve from 0.14456\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.1704 - acc: 0.9442 - val_loss: 0.1477 - val_acc: 0.9583\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1733 - acc: 0.9428\n",
      "Epoch 00130: val_loss did not improve from 0.14456\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1733 - acc: 0.9428 - val_loss: 0.1546 - val_acc: 0.9553\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1699 - acc: 0.9440\n",
      "Epoch 00131: val_loss did not improve from 0.14456\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1699 - acc: 0.9441 - val_loss: 0.1480 - val_acc: 0.9574\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9422\n",
      "Epoch 00132: val_loss did not improve from 0.14456\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.1750 - acc: 0.9422 - val_loss: 0.1503 - val_acc: 0.9564\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9454\n",
      "Epoch 00133: val_loss did not improve from 0.14456\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1677 - acc: 0.9454 - val_loss: 0.1450 - val_acc: 0.9597\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1697 - acc: 0.9450\n",
      "Epoch 00134: val_loss improved from 0.14456 to 0.14143, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/134-0.1414.hdf5\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.1697 - acc: 0.9450 - val_loss: 0.1414 - val_acc: 0.9585\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9454\n",
      "Epoch 00135: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1689 - acc: 0.9454 - val_loss: 0.1489 - val_acc: 0.9581\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1693 - acc: 0.9440\n",
      "Epoch 00136: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.1693 - acc: 0.9440 - val_loss: 0.1497 - val_acc: 0.9585\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1661 - acc: 0.9456\n",
      "Epoch 00137: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1661 - acc: 0.9456 - val_loss: 0.1424 - val_acc: 0.9599\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1633 - acc: 0.9473\n",
      "Epoch 00138: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1633 - acc: 0.9473 - val_loss: 0.1551 - val_acc: 0.9560\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1646 - acc: 0.9446\n",
      "Epoch 00139: val_loss did not improve from 0.14143\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1646 - acc: 0.9446 - val_loss: 0.1451 - val_acc: 0.9588\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1628 - acc: 0.9467\n",
      "Epoch 00140: val_loss improved from 0.14143 to 0.14120, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/140-0.1412.hdf5\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.1628 - acc: 0.9467 - val_loss: 0.1412 - val_acc: 0.9595\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1613 - acc: 0.9463\n",
      "Epoch 00141: val_loss did not improve from 0.14120\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 0.1613 - acc: 0.9463 - val_loss: 0.1446 - val_acc: 0.9616\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9486\n",
      "Epoch 00142: val_loss improved from 0.14120 to 0.13993, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/142-0.1399.hdf5\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1608 - acc: 0.9486 - val_loss: 0.1399 - val_acc: 0.9613\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1610 - acc: 0.9466\n",
      "Epoch 00143: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1610 - acc: 0.9466 - val_loss: 0.1488 - val_acc: 0.9602\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1601 - acc: 0.9475\n",
      "Epoch 00144: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1601 - acc: 0.9475 - val_loss: 0.1454 - val_acc: 0.9574\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9497\n",
      "Epoch 00145: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1550 - acc: 0.9497 - val_loss: 0.1457 - val_acc: 0.9583\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1570 - acc: 0.9471\n",
      "Epoch 00146: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1569 - acc: 0.9471 - val_loss: 0.1490 - val_acc: 0.9562\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9469\n",
      "Epoch 00147: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1606 - acc: 0.9469 - val_loss: 0.1436 - val_acc: 0.9611\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1570 - acc: 0.9482\n",
      "Epoch 00148: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1570 - acc: 0.9481 - val_loss: 0.1516 - val_acc: 0.9564\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1540 - acc: 0.9492\n",
      "Epoch 00149: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1539 - acc: 0.9492 - val_loss: 0.1425 - val_acc: 0.9597\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9512\n",
      "Epoch 00150: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1516 - acc: 0.9511 - val_loss: 0.1558 - val_acc: 0.9564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1540 - acc: 0.9489\n",
      "Epoch 00151: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1540 - acc: 0.9489 - val_loss: 0.1451 - val_acc: 0.9578\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1511 - acc: 0.9508\n",
      "Epoch 00152: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1511 - acc: 0.9508 - val_loss: 0.1428 - val_acc: 0.9595\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1466 - acc: 0.9522\n",
      "Epoch 00153: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1466 - acc: 0.9522 - val_loss: 0.1498 - val_acc: 0.9588\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1512 - acc: 0.9505\n",
      "Epoch 00154: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1512 - acc: 0.9505 - val_loss: 0.1462 - val_acc: 0.9595\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1493 - acc: 0.9505\n",
      "Epoch 00155: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1493 - acc: 0.9505 - val_loss: 0.1520 - val_acc: 0.9562\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9511\n",
      "Epoch 00156: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1500 - acc: 0.9511 - val_loss: 0.1476 - val_acc: 0.9585\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9506\n",
      "Epoch 00157: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1490 - acc: 0.9506 - val_loss: 0.1499 - val_acc: 0.9560\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9495\n",
      "Epoch 00158: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1514 - acc: 0.9495 - val_loss: 0.1472 - val_acc: 0.9581\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1504 - acc: 0.9511\n",
      "Epoch 00159: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.1504 - acc: 0.9511 - val_loss: 0.1541 - val_acc: 0.9546\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1461 - acc: 0.9521\n",
      "Epoch 00160: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1460 - acc: 0.9521 - val_loss: 0.1405 - val_acc: 0.9597\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9526\n",
      "Epoch 00161: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.1463 - acc: 0.9526 - val_loss: 0.1422 - val_acc: 0.9588\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9515\n",
      "Epoch 00162: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 17s 473us/sample - loss: 0.1457 - acc: 0.9516 - val_loss: 0.1463 - val_acc: 0.9592\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9532\n",
      "Epoch 00163: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1419 - acc: 0.9532 - val_loss: 0.1500 - val_acc: 0.9585\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9517\n",
      "Epoch 00164: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.1448 - acc: 0.9517 - val_loss: 0.1447 - val_acc: 0.9588\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1398 - acc: 0.9549\n",
      "Epoch 00165: val_loss improved from 0.13993 to 0.13945, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/165-0.1395.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1398 - acc: 0.9549 - val_loss: 0.1395 - val_acc: 0.9592\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9526\n",
      "Epoch 00166: val_loss did not improve from 0.13945\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1406 - acc: 0.9526 - val_loss: 0.1556 - val_acc: 0.9546\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9536\n",
      "Epoch 00167: val_loss did not improve from 0.13945\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1381 - acc: 0.9536 - val_loss: 0.1515 - val_acc: 0.9590\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9522\n",
      "Epoch 00168: val_loss did not improve from 0.13945\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1409 - acc: 0.9522 - val_loss: 0.1503 - val_acc: 0.9564\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9546\n",
      "Epoch 00169: val_loss did not improve from 0.13945\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1351 - acc: 0.9546 - val_loss: 0.1415 - val_acc: 0.9604\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9538\n",
      "Epoch 00170: val_loss did not improve from 0.13945\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1394 - acc: 0.9538 - val_loss: 0.1431 - val_acc: 0.9602\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9533\n",
      "Epoch 00171: val_loss improved from 0.13945 to 0.13814, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv_checkpoint/171-0.1381.hdf5\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1388 - acc: 0.9533 - val_loss: 0.1381 - val_acc: 0.9599\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9546\n",
      "Epoch 00172: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1406 - acc: 0.9546 - val_loss: 0.1524 - val_acc: 0.9592\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9555\n",
      "Epoch 00173: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1345 - acc: 0.9555 - val_loss: 0.1399 - val_acc: 0.9609\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9540\n",
      "Epoch 00174: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1375 - acc: 0.9540 - val_loss: 0.1430 - val_acc: 0.9616\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9554\n",
      "Epoch 00175: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1345 - acc: 0.9553 - val_loss: 0.1423 - val_acc: 0.9604\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9541\n",
      "Epoch 00176: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.1354 - acc: 0.9541 - val_loss: 0.1550 - val_acc: 0.9557\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1352 - acc: 0.9544\n",
      "Epoch 00177: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1352 - acc: 0.9544 - val_loss: 0.1448 - val_acc: 0.9585\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9544\n",
      "Epoch 00178: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1354 - acc: 0.9544 - val_loss: 0.1413 - val_acc: 0.9627\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9555\n",
      "Epoch 00179: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1344 - acc: 0.9555 - val_loss: 0.1444 - val_acc: 0.9606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9565\n",
      "Epoch 00180: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1299 - acc: 0.9565 - val_loss: 0.1484 - val_acc: 0.9578\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9574\n",
      "Epoch 00181: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1302 - acc: 0.9574 - val_loss: 0.1561 - val_acc: 0.9583\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9552\n",
      "Epoch 00182: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.1313 - acc: 0.9552 - val_loss: 0.1508 - val_acc: 0.9597\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9564\n",
      "Epoch 00183: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1277 - acc: 0.9564 - val_loss: 0.1451 - val_acc: 0.9618\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9571\n",
      "Epoch 00184: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1252 - acc: 0.9572 - val_loss: 0.1468 - val_acc: 0.9588\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9568\n",
      "Epoch 00185: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1306 - acc: 0.9568 - val_loss: 0.1597 - val_acc: 0.9585\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9567\n",
      "Epoch 00186: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.1284 - acc: 0.9567 - val_loss: 0.1416 - val_acc: 0.9616\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9585\n",
      "Epoch 00187: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1235 - acc: 0.9585 - val_loss: 0.1395 - val_acc: 0.9623\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9575\n",
      "Epoch 00188: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1293 - acc: 0.9575 - val_loss: 0.1558 - val_acc: 0.9585\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9566\n",
      "Epoch 00189: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1278 - acc: 0.9566 - val_loss: 0.1399 - val_acc: 0.9620\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9570\n",
      "Epoch 00190: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1265 - acc: 0.9570 - val_loss: 0.1435 - val_acc: 0.9613\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9587\n",
      "Epoch 00191: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1230 - acc: 0.9587 - val_loss: 0.1540 - val_acc: 0.9613\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9583\n",
      "Epoch 00192: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1245 - acc: 0.9583 - val_loss: 0.1471 - val_acc: 0.9597\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9581\n",
      "Epoch 00193: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1226 - acc: 0.9581 - val_loss: 0.1446 - val_acc: 0.9613\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9585\n",
      "Epoch 00194: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1233 - acc: 0.9585 - val_loss: 0.1456 - val_acc: 0.9576\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9590\n",
      "Epoch 00195: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.1211 - acc: 0.9590 - val_loss: 0.1457 - val_acc: 0.9602\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9590\n",
      "Epoch 00196: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1196 - acc: 0.9590 - val_loss: 0.1574 - val_acc: 0.9595\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9574\n",
      "Epoch 00197: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1246 - acc: 0.9574 - val_loss: 0.1422 - val_acc: 0.9627\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9581\n",
      "Epoch 00198: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1253 - acc: 0.9581 - val_loss: 0.1450 - val_acc: 0.9623\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9604\n",
      "Epoch 00199: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 472us/sample - loss: 0.1172 - acc: 0.9604 - val_loss: 0.1516 - val_acc: 0.9583\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9601\n",
      "Epoch 00200: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1195 - acc: 0.9601 - val_loss: 0.1515 - val_acc: 0.9604\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9586\n",
      "Epoch 00201: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1212 - acc: 0.9586 - val_loss: 0.1474 - val_acc: 0.9599\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9607\n",
      "Epoch 00202: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1183 - acc: 0.9607 - val_loss: 0.1468 - val_acc: 0.9609\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9602\n",
      "Epoch 00203: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1179 - acc: 0.9602 - val_loss: 0.1454 - val_acc: 0.9611\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9602\n",
      "Epoch 00204: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1180 - acc: 0.9602 - val_loss: 0.1500 - val_acc: 0.9581\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9608\n",
      "Epoch 00205: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1167 - acc: 0.9608 - val_loss: 0.1482 - val_acc: 0.9602\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9611\n",
      "Epoch 00206: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1167 - acc: 0.9611 - val_loss: 0.1555 - val_acc: 0.9592\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9615\n",
      "Epoch 00207: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1128 - acc: 0.9615 - val_loss: 0.1509 - val_acc: 0.9597\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9593\n",
      "Epoch 00208: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 0.1189 - acc: 0.9593 - val_loss: 0.1500 - val_acc: 0.9595\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9617\n",
      "Epoch 00209: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1145 - acc: 0.9617 - val_loss: 0.1610 - val_acc: 0.9595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9603\n",
      "Epoch 00210: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 476us/sample - loss: 0.1172 - acc: 0.9603 - val_loss: 0.1505 - val_acc: 0.9609\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9605\n",
      "Epoch 00211: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1138 - acc: 0.9605 - val_loss: 0.1506 - val_acc: 0.9620\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9603\n",
      "Epoch 00212: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1184 - acc: 0.9603 - val_loss: 0.1507 - val_acc: 0.9611\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9599\n",
      "Epoch 00213: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1176 - acc: 0.9599 - val_loss: 0.1460 - val_acc: 0.9599\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9623\n",
      "Epoch 00214: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1122 - acc: 0.9623 - val_loss: 0.1600 - val_acc: 0.9602\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9630\n",
      "Epoch 00215: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 474us/sample - loss: 0.1102 - acc: 0.9630 - val_loss: 0.1475 - val_acc: 0.9595\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9618\n",
      "Epoch 00216: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1117 - acc: 0.9618 - val_loss: 0.1470 - val_acc: 0.9599\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9618\n",
      "Epoch 00217: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1137 - acc: 0.9619 - val_loss: 0.1390 - val_acc: 0.9606\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9620\n",
      "Epoch 00218: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.1095 - acc: 0.9620 - val_loss: 0.1472 - val_acc: 0.9606\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9619\n",
      "Epoch 00219: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 17s 475us/sample - loss: 0.1131 - acc: 0.9619 - val_loss: 0.1537 - val_acc: 0.9599\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9629\n",
      "Epoch 00220: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.1085 - acc: 0.9629 - val_loss: 0.1513 - val_acc: 0.9595\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9623\n",
      "Epoch 00221: val_loss did not improve from 0.13814\n",
      "36805/36805 [==============================] - 18s 477us/sample - loss: 0.1104 - acc: 0.9623 - val_loss: 0.1460 - val_acc: 0.9625\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 282us/sample - loss: 0.2004 - acc: 0.9418\n",
      "Loss: 0.20042766913199103 Accuracy: 0.9418484\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3746 - acc: 0.2193\n",
      "Epoch 00001: val_loss improved from inf to 1.68085, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/001-1.6809.hdf5\n",
      "36805/36805 [==============================] - 23s 621us/sample - loss: 2.3745 - acc: 0.2193 - val_loss: 1.6809 - val_acc: 0.5269\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6483 - acc: 0.4703\n",
      "Epoch 00002: val_loss improved from 1.68085 to 1.20398, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/002-1.2040.hdf5\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 1.6483 - acc: 0.4703 - val_loss: 1.2040 - val_acc: 0.6632\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3282 - acc: 0.5761\n",
      "Epoch 00003: val_loss improved from 1.20398 to 0.97898, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/003-0.9790.hdf5\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 1.3281 - acc: 0.5761 - val_loss: 0.9790 - val_acc: 0.7049\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1374 - acc: 0.6379\n",
      "Epoch 00004: val_loss improved from 0.97898 to 0.81754, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/004-0.8175.hdf5\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 1.1373 - acc: 0.6379 - val_loss: 0.8175 - val_acc: 0.7529\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0085 - acc: 0.6789\n",
      "Epoch 00005: val_loss improved from 0.81754 to 0.73688, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/005-0.7369.hdf5\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 1.0084 - acc: 0.6790 - val_loss: 0.7369 - val_acc: 0.7724\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9148 - acc: 0.7080\n",
      "Epoch 00006: val_loss improved from 0.73688 to 0.66240, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/006-0.6624.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.9147 - acc: 0.7081 - val_loss: 0.6624 - val_acc: 0.7992\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8423 - acc: 0.7336\n",
      "Epoch 00007: val_loss improved from 0.66240 to 0.61003, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/007-0.6100.hdf5\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.8423 - acc: 0.7336 - val_loss: 0.6100 - val_acc: 0.8113\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7763 - acc: 0.7543\n",
      "Epoch 00008: val_loss improved from 0.61003 to 0.55002, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/008-0.5500.hdf5\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.7763 - acc: 0.7544 - val_loss: 0.5500 - val_acc: 0.8309\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7275 - acc: 0.7687\n",
      "Epoch 00009: val_loss improved from 0.55002 to 0.49677, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/009-0.4968.hdf5\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.7276 - acc: 0.7687 - val_loss: 0.4968 - val_acc: 0.8523\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6773 - acc: 0.7846\n",
      "Epoch 00010: val_loss improved from 0.49677 to 0.46938, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/010-0.4694.hdf5\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.6776 - acc: 0.7845 - val_loss: 0.4694 - val_acc: 0.8586\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6390 - acc: 0.7996\n",
      "Epoch 00011: val_loss improved from 0.46938 to 0.45486, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/011-0.4549.hdf5\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.6390 - acc: 0.7996 - val_loss: 0.4549 - val_acc: 0.8644\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6100 - acc: 0.8095\n",
      "Epoch 00012: val_loss improved from 0.45486 to 0.40618, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/012-0.4062.hdf5\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.6100 - acc: 0.8096 - val_loss: 0.4062 - val_acc: 0.8768\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5754 - acc: 0.8204\n",
      "Epoch 00013: val_loss improved from 0.40618 to 0.39036, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/013-0.3904.hdf5\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.5755 - acc: 0.8204 - val_loss: 0.3904 - val_acc: 0.8847\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5504 - acc: 0.8267\n",
      "Epoch 00014: val_loss improved from 0.39036 to 0.36109, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/014-0.3611.hdf5\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.5503 - acc: 0.8267 - val_loss: 0.3611 - val_acc: 0.8908\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5254 - acc: 0.8367\n",
      "Epoch 00015: val_loss improved from 0.36109 to 0.35346, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/015-0.3535.hdf5\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.5254 - acc: 0.8367 - val_loss: 0.3535 - val_acc: 0.8870\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5074 - acc: 0.8399\n",
      "Epoch 00016: val_loss improved from 0.35346 to 0.34711, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/016-0.3471.hdf5\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.5073 - acc: 0.8399 - val_loss: 0.3471 - val_acc: 0.8924\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4859 - acc: 0.8450\n",
      "Epoch 00017: val_loss improved from 0.34711 to 0.33621, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/017-0.3362.hdf5\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.4859 - acc: 0.8449 - val_loss: 0.3362 - val_acc: 0.8973\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4652 - acc: 0.8565\n",
      "Epoch 00018: val_loss improved from 0.33621 to 0.30828, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/018-0.3083.hdf5\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.4652 - acc: 0.8565 - val_loss: 0.3083 - val_acc: 0.9106\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4461 - acc: 0.8590\n",
      "Epoch 00019: val_loss improved from 0.30828 to 0.29323, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/019-0.2932.hdf5\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.4460 - acc: 0.8591 - val_loss: 0.2932 - val_acc: 0.9110\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4334 - acc: 0.8638\n",
      "Epoch 00020: val_loss improved from 0.29323 to 0.27482, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/020-0.2748.hdf5\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.4334 - acc: 0.8638 - val_loss: 0.2748 - val_acc: 0.9168\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4188 - acc: 0.8695\n",
      "Epoch 00021: val_loss did not improve from 0.27482\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.4188 - acc: 0.8695 - val_loss: 0.2758 - val_acc: 0.9147\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4071 - acc: 0.8733\n",
      "Epoch 00022: val_loss improved from 0.27482 to 0.26897, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/022-0.2690.hdf5\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.4071 - acc: 0.8734 - val_loss: 0.2690 - val_acc: 0.9178\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3957 - acc: 0.8767\n",
      "Epoch 00023: val_loss improved from 0.26897 to 0.26567, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/023-0.2657.hdf5\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.3956 - acc: 0.8768 - val_loss: 0.2657 - val_acc: 0.9157\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3824 - acc: 0.8785\n",
      "Epoch 00024: val_loss improved from 0.26567 to 0.24753, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/024-0.2475.hdf5\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.3824 - acc: 0.8785 - val_loss: 0.2475 - val_acc: 0.9271\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3723 - acc: 0.8806\n",
      "Epoch 00025: val_loss did not improve from 0.24753\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.3724 - acc: 0.8806 - val_loss: 0.2501 - val_acc: 0.9250\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3573 - acc: 0.8873\n",
      "Epoch 00026: val_loss improved from 0.24753 to 0.24205, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/026-0.2420.hdf5\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.3572 - acc: 0.8873 - val_loss: 0.2420 - val_acc: 0.9264\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3568 - acc: 0.8881\n",
      "Epoch 00027: val_loss improved from 0.24205 to 0.24200, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/027-0.2420.hdf5\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.3567 - acc: 0.8881 - val_loss: 0.2420 - val_acc: 0.9259\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3395 - acc: 0.8934\n",
      "Epoch 00028: val_loss improved from 0.24200 to 0.22661, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/028-0.2266.hdf5\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.3394 - acc: 0.8934 - val_loss: 0.2266 - val_acc: 0.9290\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3322 - acc: 0.8951\n",
      "Epoch 00029: val_loss improved from 0.22661 to 0.22418, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/029-0.2242.hdf5\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.3322 - acc: 0.8950 - val_loss: 0.2242 - val_acc: 0.9285\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3252 - acc: 0.8969\n",
      "Epoch 00030: val_loss improved from 0.22418 to 0.21836, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/030-0.2184.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.3251 - acc: 0.8969 - val_loss: 0.2184 - val_acc: 0.9308\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3200 - acc: 0.8997\n",
      "Epoch 00031: val_loss improved from 0.21836 to 0.20868, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/031-0.2087.hdf5\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.3201 - acc: 0.8996 - val_loss: 0.2087 - val_acc: 0.9352\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3103 - acc: 0.9033\n",
      "Epoch 00032: val_loss did not improve from 0.20868\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.3102 - acc: 0.9033 - val_loss: 0.2091 - val_acc: 0.9348\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3021 - acc: 0.9035\n",
      "Epoch 00033: val_loss improved from 0.20868 to 0.20458, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/033-0.2046.hdf5\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.3020 - acc: 0.9035 - val_loss: 0.2046 - val_acc: 0.9336\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2958 - acc: 0.9065\n",
      "Epoch 00034: val_loss improved from 0.20458 to 0.19566, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/034-0.1957.hdf5\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.2958 - acc: 0.9065 - val_loss: 0.1957 - val_acc: 0.9385\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2978 - acc: 0.9059\n",
      "Epoch 00035: val_loss did not improve from 0.19566\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.2978 - acc: 0.9059 - val_loss: 0.2029 - val_acc: 0.9345\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2861 - acc: 0.9104\n",
      "Epoch 00036: val_loss did not improve from 0.19566\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.2862 - acc: 0.9104 - val_loss: 0.1989 - val_acc: 0.9383\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2803 - acc: 0.9108\n",
      "Epoch 00037: val_loss improved from 0.19566 to 0.18672, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/037-0.1867.hdf5\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.2803 - acc: 0.9108 - val_loss: 0.1867 - val_acc: 0.9404\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2727 - acc: 0.9131\n",
      "Epoch 00038: val_loss did not improve from 0.18672\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.2727 - acc: 0.9131 - val_loss: 0.1888 - val_acc: 0.9378\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2716 - acc: 0.9137\n",
      "Epoch 00039: val_loss did not improve from 0.18672\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.2716 - acc: 0.9137 - val_loss: 0.1874 - val_acc: 0.9392\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2639 - acc: 0.9155\n",
      "Epoch 00040: val_loss did not improve from 0.18672\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.2639 - acc: 0.9155 - val_loss: 0.1914 - val_acc: 0.9350\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2592 - acc: 0.9175\n",
      "Epoch 00041: val_loss did not improve from 0.18672\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.2592 - acc: 0.9175 - val_loss: 0.1891 - val_acc: 0.9406\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2529 - acc: 0.9190\n",
      "Epoch 00042: val_loss did not improve from 0.18672\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.2528 - acc: 0.9190 - val_loss: 0.1870 - val_acc: 0.9394\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2527 - acc: 0.9187\n",
      "Epoch 00043: val_loss improved from 0.18672 to 0.17242, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/043-0.1724.hdf5\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.2526 - acc: 0.9188 - val_loss: 0.1724 - val_acc: 0.9446\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2501 - acc: 0.9201\n",
      "Epoch 00044: val_loss did not improve from 0.17242\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.2500 - acc: 0.9201 - val_loss: 0.1819 - val_acc: 0.9422\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2447 - acc: 0.9225\n",
      "Epoch 00045: val_loss did not improve from 0.17242\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.2446 - acc: 0.9225 - val_loss: 0.1923 - val_acc: 0.9390\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2375 - acc: 0.9250\n",
      "Epoch 00046: val_loss did not improve from 0.17242\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.2375 - acc: 0.9250 - val_loss: 0.1808 - val_acc: 0.9418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2372 - acc: 0.9249\n",
      "Epoch 00047: val_loss did not improve from 0.17242\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.2371 - acc: 0.9250 - val_loss: 0.1768 - val_acc: 0.9448\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2326 - acc: 0.9258\n",
      "Epoch 00048: val_loss improved from 0.17242 to 0.17144, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/048-0.1714.hdf5\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.2326 - acc: 0.9258 - val_loss: 0.1714 - val_acc: 0.9467\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2282 - acc: 0.9265\n",
      "Epoch 00049: val_loss improved from 0.17144 to 0.16431, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/049-0.1643.hdf5\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.2282 - acc: 0.9266 - val_loss: 0.1643 - val_acc: 0.9471\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2275 - acc: 0.9272\n",
      "Epoch 00050: val_loss improved from 0.16431 to 0.16217, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/050-0.1622.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.2275 - acc: 0.9272 - val_loss: 0.1622 - val_acc: 0.9490\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2234 - acc: 0.9286\n",
      "Epoch 00051: val_loss did not improve from 0.16217\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.2234 - acc: 0.9286 - val_loss: 0.1740 - val_acc: 0.9418\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2213 - acc: 0.9285\n",
      "Epoch 00052: val_loss did not improve from 0.16217\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.2213 - acc: 0.9285 - val_loss: 0.1704 - val_acc: 0.9467\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2172 - acc: 0.9292\n",
      "Epoch 00053: val_loss improved from 0.16217 to 0.16188, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/053-0.1619.hdf5\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.2172 - acc: 0.9292 - val_loss: 0.1619 - val_acc: 0.9469\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2123 - acc: 0.9317\n",
      "Epoch 00054: val_loss did not improve from 0.16188\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.2123 - acc: 0.9317 - val_loss: 0.1724 - val_acc: 0.9443\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2069 - acc: 0.9338\n",
      "Epoch 00055: val_loss did not improve from 0.16188\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.2069 - acc: 0.9338 - val_loss: 0.1692 - val_acc: 0.9455\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2053 - acc: 0.9324\n",
      "Epoch 00056: val_loss did not improve from 0.16188\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.2054 - acc: 0.9324 - val_loss: 0.1651 - val_acc: 0.9460\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2055 - acc: 0.9339\n",
      "Epoch 00057: val_loss improved from 0.16188 to 0.15009, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/057-0.1501.hdf5\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.2054 - acc: 0.9339 - val_loss: 0.1501 - val_acc: 0.9520\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1988 - acc: 0.9353\n",
      "Epoch 00058: val_loss did not improve from 0.15009\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.1988 - acc: 0.9353 - val_loss: 0.1579 - val_acc: 0.9504\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1962 - acc: 0.9368\n",
      "Epoch 00059: val_loss did not improve from 0.15009\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.1961 - acc: 0.9369 - val_loss: 0.1575 - val_acc: 0.9492\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9361\n",
      "Epoch 00060: val_loss did not improve from 0.15009\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.1956 - acc: 0.9360 - val_loss: 0.1604 - val_acc: 0.9474\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1915 - acc: 0.9393\n",
      "Epoch 00061: val_loss did not improve from 0.15009\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1915 - acc: 0.9393 - val_loss: 0.1567 - val_acc: 0.9504\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1896 - acc: 0.9390\n",
      "Epoch 00062: val_loss did not improve from 0.15009\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.1895 - acc: 0.9390 - val_loss: 0.1564 - val_acc: 0.9522\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1843 - acc: 0.9390\n",
      "Epoch 00063: val_loss did not improve from 0.15009\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.1843 - acc: 0.9390 - val_loss: 0.1544 - val_acc: 0.9495\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9412\n",
      "Epoch 00064: val_loss did not improve from 0.15009\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1812 - acc: 0.9411 - val_loss: 0.1546 - val_acc: 0.9502\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1857 - acc: 0.9407\n",
      "Epoch 00065: val_loss did not improve from 0.15009\n",
      "36805/36805 [==============================] - 19s 505us/sample - loss: 0.1857 - acc: 0.9407 - val_loss: 0.1503 - val_acc: 0.9506\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1783 - acc: 0.9423\n",
      "Epoch 00066: val_loss did not improve from 0.15009\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.1783 - acc: 0.9423 - val_loss: 0.1548 - val_acc: 0.9518\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1746 - acc: 0.9436\n",
      "Epoch 00067: val_loss did not improve from 0.15009\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.1746 - acc: 0.9435 - val_loss: 0.1559 - val_acc: 0.9490\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1741 - acc: 0.9432\n",
      "Epoch 00068: val_loss improved from 0.15009 to 0.14636, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/068-0.1464.hdf5\n",
      "36805/36805 [==============================] - 19s 504us/sample - loss: 0.1741 - acc: 0.9432 - val_loss: 0.1464 - val_acc: 0.9534\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9439\n",
      "Epoch 00069: val_loss did not improve from 0.14636\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.1740 - acc: 0.9439 - val_loss: 0.1546 - val_acc: 0.9509\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9461\n",
      "Epoch 00070: val_loss did not improve from 0.14636\n",
      "36805/36805 [==============================] - 19s 509us/sample - loss: 0.1654 - acc: 0.9460 - val_loss: 0.1470 - val_acc: 0.9522\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1684 - acc: 0.9451\n",
      "Epoch 00071: val_loss did not improve from 0.14636\n",
      "36805/36805 [==============================] - 18s 502us/sample - loss: 0.1684 - acc: 0.9451 - val_loss: 0.1477 - val_acc: 0.9518\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9447\n",
      "Epoch 00072: val_loss did not improve from 0.14636\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.1671 - acc: 0.9447 - val_loss: 0.1465 - val_acc: 0.9541\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1638 - acc: 0.9476\n",
      "Epoch 00073: val_loss improved from 0.14636 to 0.14286, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/073-0.1429.hdf5\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.1638 - acc: 0.9476 - val_loss: 0.1429 - val_acc: 0.9520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1635 - acc: 0.9467\n",
      "Epoch 00074: val_loss did not improve from 0.14286\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.1635 - acc: 0.9467 - val_loss: 0.1481 - val_acc: 0.9539\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1581 - acc: 0.9486\n",
      "Epoch 00075: val_loss did not improve from 0.14286\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.1582 - acc: 0.9486 - val_loss: 0.1485 - val_acc: 0.9522\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1567 - acc: 0.9488\n",
      "Epoch 00076: val_loss did not improve from 0.14286\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.1569 - acc: 0.9487 - val_loss: 0.1463 - val_acc: 0.9550\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1568 - acc: 0.9483\n",
      "Epoch 00077: val_loss did not improve from 0.14286\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.1568 - acc: 0.9483 - val_loss: 0.1537 - val_acc: 0.9495\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9496\n",
      "Epoch 00078: val_loss did not improve from 0.14286\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.1544 - acc: 0.9496 - val_loss: 0.1457 - val_acc: 0.9553\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1525 - acc: 0.9504\n",
      "Epoch 00079: val_loss improved from 0.14286 to 0.14051, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/079-0.1405.hdf5\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.1525 - acc: 0.9504 - val_loss: 0.1405 - val_acc: 0.9550\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1525 - acc: 0.9496\n",
      "Epoch 00080: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.1525 - acc: 0.9496 - val_loss: 0.1456 - val_acc: 0.9539\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9516\n",
      "Epoch 00081: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.1475 - acc: 0.9516 - val_loss: 0.1518 - val_acc: 0.9529\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9526\n",
      "Epoch 00082: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.1472 - acc: 0.9526 - val_loss: 0.1460 - val_acc: 0.9553\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9517\n",
      "Epoch 00083: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.1448 - acc: 0.9517 - val_loss: 0.1464 - val_acc: 0.9564\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9533\n",
      "Epoch 00084: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.1415 - acc: 0.9533 - val_loss: 0.1414 - val_acc: 0.9541\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9529\n",
      "Epoch 00085: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.1412 - acc: 0.9529 - val_loss: 0.1484 - val_acc: 0.9509\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9540\n",
      "Epoch 00086: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.1387 - acc: 0.9540 - val_loss: 0.1493 - val_acc: 0.9529\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9551\n",
      "Epoch 00087: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.1362 - acc: 0.9551 - val_loss: 0.1505 - val_acc: 0.9509\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9534\n",
      "Epoch 00088: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.1386 - acc: 0.9534 - val_loss: 0.1496 - val_acc: 0.9557\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9551\n",
      "Epoch 00089: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.1353 - acc: 0.9551 - val_loss: 0.1504 - val_acc: 0.9555\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9563\n",
      "Epoch 00090: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.1343 - acc: 0.9563 - val_loss: 0.1536 - val_acc: 0.9529\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9554\n",
      "Epoch 00091: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1338 - acc: 0.9554 - val_loss: 0.1422 - val_acc: 0.9520\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9567\n",
      "Epoch 00092: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.1311 - acc: 0.9567 - val_loss: 0.1476 - val_acc: 0.9567\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9577\n",
      "Epoch 00093: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.1258 - acc: 0.9577 - val_loss: 0.1565 - val_acc: 0.9543\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9570\n",
      "Epoch 00094: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.1301 - acc: 0.9570 - val_loss: 0.1441 - val_acc: 0.9522\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9580\n",
      "Epoch 00095: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.1254 - acc: 0.9580 - val_loss: 0.1447 - val_acc: 0.9590\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9588\n",
      "Epoch 00096: val_loss did not improve from 0.14051\n",
      "36805/36805 [==============================] - 19s 504us/sample - loss: 0.1218 - acc: 0.9588 - val_loss: 0.1497 - val_acc: 0.9576\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9586\n",
      "Epoch 00097: val_loss improved from 0.14051 to 0.13870, saving model to model/checkpoint/1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv_checkpoint/097-0.1387.hdf5\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.1232 - acc: 0.9586 - val_loss: 0.1387 - val_acc: 0.9553\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9589\n",
      "Epoch 00098: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.1224 - acc: 0.9589 - val_loss: 0.1603 - val_acc: 0.9536\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9586\n",
      "Epoch 00099: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.1243 - acc: 0.9586 - val_loss: 0.1530 - val_acc: 0.9543\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9613\n",
      "Epoch 00100: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.1174 - acc: 0.9613 - val_loss: 0.1667 - val_acc: 0.9525\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9604\n",
      "Epoch 00101: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 19s 504us/sample - loss: 0.1195 - acc: 0.9604 - val_loss: 0.1540 - val_acc: 0.9569\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9596\n",
      "Epoch 00102: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.1191 - acc: 0.9596 - val_loss: 0.1653 - val_acc: 0.9541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9593\n",
      "Epoch 00103: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.1219 - acc: 0.9593 - val_loss: 0.1488 - val_acc: 0.9574\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9618\n",
      "Epoch 00104: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.1142 - acc: 0.9618 - val_loss: 0.1425 - val_acc: 0.9557\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9624\n",
      "Epoch 00105: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.1103 - acc: 0.9624 - val_loss: 0.1407 - val_acc: 0.9553\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9620\n",
      "Epoch 00106: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.1116 - acc: 0.9620 - val_loss: 0.1459 - val_acc: 0.9555\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9626\n",
      "Epoch 00107: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 19s 509us/sample - loss: 0.1117 - acc: 0.9626 - val_loss: 0.1449 - val_acc: 0.9576\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9618\n",
      "Epoch 00108: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.1101 - acc: 0.9618 - val_loss: 0.1434 - val_acc: 0.9548\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9626\n",
      "Epoch 00109: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.1090 - acc: 0.9626 - val_loss: 0.1561 - val_acc: 0.9560\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9641\n",
      "Epoch 00110: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.1056 - acc: 0.9641 - val_loss: 0.1524 - val_acc: 0.9532\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9638\n",
      "Epoch 00111: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.1065 - acc: 0.9638 - val_loss: 0.1436 - val_acc: 0.9557\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9645\n",
      "Epoch 00112: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.1071 - acc: 0.9645 - val_loss: 0.1525 - val_acc: 0.9532\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9636\n",
      "Epoch 00113: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.1074 - acc: 0.9636 - val_loss: 0.1532 - val_acc: 0.9569\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9645\n",
      "Epoch 00114: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 19s 503us/sample - loss: 0.1045 - acc: 0.9645 - val_loss: 0.1392 - val_acc: 0.9571\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9652\n",
      "Epoch 00115: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.1032 - acc: 0.9652 - val_loss: 0.1455 - val_acc: 0.9567\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9650\n",
      "Epoch 00116: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.1014 - acc: 0.9650 - val_loss: 0.1570 - val_acc: 0.9555\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9652\n",
      "Epoch 00117: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 19s 505us/sample - loss: 0.1006 - acc: 0.9652 - val_loss: 0.1549 - val_acc: 0.9532\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9658\n",
      "Epoch 00118: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0990 - acc: 0.9658 - val_loss: 0.1573 - val_acc: 0.9553\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9657\n",
      "Epoch 00119: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.1003 - acc: 0.9657 - val_loss: 0.1567 - val_acc: 0.9548\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9654\n",
      "Epoch 00120: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.0996 - acc: 0.9654 - val_loss: 0.1579 - val_acc: 0.9546\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9666\n",
      "Epoch 00121: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1007 - acc: 0.9666 - val_loss: 0.1576 - val_acc: 0.9536\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9668\n",
      "Epoch 00122: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.0972 - acc: 0.9668 - val_loss: 0.1458 - val_acc: 0.9541\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9671\n",
      "Epoch 00123: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.0962 - acc: 0.9671 - val_loss: 0.1479 - val_acc: 0.9562\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9664\n",
      "Epoch 00124: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.1001 - acc: 0.9663 - val_loss: 0.1538 - val_acc: 0.9571\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9677\n",
      "Epoch 00125: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0933 - acc: 0.9677 - val_loss: 0.1570 - val_acc: 0.9576\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9693\n",
      "Epoch 00126: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 19s 505us/sample - loss: 0.0890 - acc: 0.9692 - val_loss: 0.1475 - val_acc: 0.9569\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9679\n",
      "Epoch 00127: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0934 - acc: 0.9679 - val_loss: 0.1504 - val_acc: 0.9564\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9682\n",
      "Epoch 00128: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.0931 - acc: 0.9682 - val_loss: 0.1531 - val_acc: 0.9569\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9693\n",
      "Epoch 00129: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0911 - acc: 0.9694 - val_loss: 0.1684 - val_acc: 0.9560\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9690\n",
      "Epoch 00130: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 19s 504us/sample - loss: 0.0910 - acc: 0.9690 - val_loss: 0.1679 - val_acc: 0.9560\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9698\n",
      "Epoch 00131: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0877 - acc: 0.9698 - val_loss: 0.1647 - val_acc: 0.9534\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9688\n",
      "Epoch 00132: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.0911 - acc: 0.9688 - val_loss: 0.1599 - val_acc: 0.9581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9692\n",
      "Epoch 00133: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.0892 - acc: 0.9692 - val_loss: 0.1572 - val_acc: 0.9583\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9706\n",
      "Epoch 00134: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.0863 - acc: 0.9706 - val_loss: 0.1606 - val_acc: 0.9576\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9707\n",
      "Epoch 00135: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0862 - acc: 0.9707 - val_loss: 0.1574 - val_acc: 0.9560\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9703\n",
      "Epoch 00136: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 19s 510us/sample - loss: 0.0861 - acc: 0.9703 - val_loss: 0.1618 - val_acc: 0.9599\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9721\n",
      "Epoch 00137: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 19s 509us/sample - loss: 0.0816 - acc: 0.9721 - val_loss: 0.1577 - val_acc: 0.9583\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9709\n",
      "Epoch 00138: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.0848 - acc: 0.9708 - val_loss: 0.1464 - val_acc: 0.9569\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9710\n",
      "Epoch 00139: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0854 - acc: 0.9710 - val_loss: 0.1606 - val_acc: 0.9532\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9711\n",
      "Epoch 00140: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.0843 - acc: 0.9711 - val_loss: 0.1477 - val_acc: 0.9588\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9712\n",
      "Epoch 00141: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0828 - acc: 0.9712 - val_loss: 0.1571 - val_acc: 0.9567\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9713\n",
      "Epoch 00142: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0837 - acc: 0.9713 - val_loss: 0.1565 - val_acc: 0.9555\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9727\n",
      "Epoch 00143: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 19s 503us/sample - loss: 0.0792 - acc: 0.9727 - val_loss: 0.1672 - val_acc: 0.9569\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9710\n",
      "Epoch 00144: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.0819 - acc: 0.9710 - val_loss: 0.1713 - val_acc: 0.9546\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9735\n",
      "Epoch 00145: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.0759 - acc: 0.9735 - val_loss: 0.1556 - val_acc: 0.9592\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9714\n",
      "Epoch 00146: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.0833 - acc: 0.9714 - val_loss: 0.1493 - val_acc: 0.9588\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9736\n",
      "Epoch 00147: val_loss did not improve from 0.13870\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0750 - acc: 0.9736 - val_loss: 0.1621 - val_acc: 0.9562\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 324us/sample - loss: 0.2176 - acc: 0.9396\n",
      "Loss: 0.2175688793199951 Accuracy: 0.9395639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_multi_2_GAP_ch_32_DO'\n",
    "\n",
    "for i in range(3, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_cnn(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 32)    192         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 32)    0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 32)     0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 32)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 32)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 32)     0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 32)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 32)           0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 32)           0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64)           0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_average_pooling1d_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           1040        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 11,536\n",
      "Trainable params: 11,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 1s 272us/sample - loss: 0.8719 - acc: 0.7433\n",
      "Loss: 0.8719101119388053 Accuracy: 0.74330217\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 16000, 32)    192         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16000, 32)    0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 5333, 32)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5333, 32)     0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1777, 32)     0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1777, 32)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 592, 32)      0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 592, 32)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 197, 32)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 32)           0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 32)           0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64)           0           global_average_pooling1d_14[0][0]\n",
      "                                                                 global_average_pooling1d_15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           1040        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,688\n",
      "Trainable params: 16,688\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 1s 274us/sample - loss: 0.6655 - acc: 0.8000\n",
      "Loss: 0.6654508444255263 Accuracy: 0.8\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 16000, 32)    192         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16000, 32)    0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 5333, 32)     0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5333, 32)     0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1777, 32)     0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1777, 32)     0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 592, 32)      0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 592, 32)      0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 197, 32)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 197, 64)      0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 65, 64)       0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 32)           0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 64)           0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 96)           0           global_average_pooling1d_16[0][0]\n",
      "                                                                 global_average_pooling1d_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 96)           0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           1552        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,504\n",
      "Trainable params: 27,504\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 306us/sample - loss: 0.3259 - acc: 0.9088\n",
      "Loss: 0.3258861377479379 Accuracy: 0.9088266\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 16000, 32)    192         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16000, 32)    0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 5333, 32)     0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5333, 32)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1777, 32)     0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1777, 32)     0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 592, 32)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 592, 32)      0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 197, 32)      0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 197, 64)      0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 65, 64)       0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 65, 64)       0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 21, 64)       0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 64)           0           max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 64)           0           max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 128)          0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_average_pooling1d_19[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128)          0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           2064        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 48,560\n",
      "Trainable params: 48,560\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 1s 310us/sample - loss: 0.2175 - acc: 0.9369\n",
      "Loss: 0.21751798870407532 Accuracy: 0.93686396\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 16000, 32)    192         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16000, 32)    0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 5333, 32)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5333, 32)     0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 1777, 32)     0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1777, 32)     0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 592, 32)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 592, 32)      0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 197, 32)      0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 197, 64)      0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 65, 64)       0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 65, 64)       0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 21, 64)       0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 21, 64)       0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 7, 64)        0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 64)           0           max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 64)           0           max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 128)          0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_average_pooling1d_21[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 128)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           2064        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 69,104\n",
      "Trainable params: 69,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 317us/sample - loss: 0.2004 - acc: 0.9418\n",
      "Loss: 0.20042766913199103 Accuracy: 0.9418484\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 16000, 32)    192         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16000, 32)    0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 5333, 32)     0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5333, 32)     0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 1777, 32)     0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1777, 32)     0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 592, 32)      0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 592, 32)      0           conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 197, 32)      0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 197, 64)      0           conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 65, 64)       0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 65, 64)       0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 21, 64)       0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 21, 64)       0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 7, 64)        0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 7, 64)        20544       max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 64)        0           conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 2, 64)        0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 64)           0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 64)           0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 128)          0           global_average_pooling1d_22[0][0]\n",
      "                                                                 global_average_pooling1d_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128)          0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           2064        dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 89,648\n",
      "Trainable params: 89,648\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 317us/sample - loss: 0.2176 - acc: 0.9396\n",
      "Loss: 0.2175688793199951 Accuracy: 0.9395639\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_multi_2_GAP_ch_32_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 9):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 32)    192         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 32)    0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 32)     0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 32)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 32)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 32)     0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 32)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 32)           0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 32)           0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64)           0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_average_pooling1d_13[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           1040        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 11,536\n",
      "Trainable params: 11,536\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 337us/sample - loss: 0.8764 - acc: 0.7452\n",
      "Loss: 0.8763977019957664 Accuracy: 0.74517137\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 16000, 32)    192         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16000, 32)    0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 5333, 32)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5333, 32)     0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1777, 32)     0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1777, 32)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 592, 32)      0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 592, 32)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 197, 32)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 32)           0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 32)           0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64)           0           global_average_pooling1d_14[0][0]\n",
      "                                                                 global_average_pooling1d_15[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           1040        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,688\n",
      "Trainable params: 16,688\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 364us/sample - loss: 0.6776 - acc: 0.7944\n",
      "Loss: 0.6776114664221354 Accuracy: 0.7943925\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 16000, 32)    192         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16000, 32)    0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 5333, 32)     0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5333, 32)     0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1777, 32)     0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1777, 32)     0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 592, 32)      0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 592, 32)      0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 197, 32)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 197, 64)      0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 65, 64)       0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 32)           0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 64)           0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 96)           0           global_average_pooling1d_16[0][0]\n",
      "                                                                 global_average_pooling1d_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 96)           0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           1552        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 27,504\n",
      "Trainable params: 27,504\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 345us/sample - loss: 0.3212 - acc: 0.9078\n",
      "Loss: 0.321175901689262 Accuracy: 0.90778816\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 16000, 32)    192         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16000, 32)    0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 5333, 32)     0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5333, 32)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1777, 32)     0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1777, 32)     0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 592, 32)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 592, 32)      0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 197, 32)      0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 197, 64)      0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 65, 64)       0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 65, 64)       0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 21, 64)       0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 64)           0           max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 64)           0           max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 128)          0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_average_pooling1d_19[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 128)          0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           2064        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 48,560\n",
      "Trainable params: 48,560\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 371us/sample - loss: 0.2182 - acc: 0.9369\n",
      "Loss: 0.2182379244643951 Accuracy: 0.93686396\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 16000, 32)    192         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16000, 32)    0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 5333, 32)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5333, 32)     0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 1777, 32)     0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1777, 32)     0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 592, 32)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 592, 32)      0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 197, 32)      0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 197, 64)      0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 65, 64)       0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 65, 64)       0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 21, 64)       0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 21, 64)       0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 7, 64)        0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 64)           0           max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 64)           0           max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 128)          0           global_average_pooling1d_20[0][0]\n",
      "                                                                 global_average_pooling1d_21[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 128)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           2064        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 69,104\n",
      "Trainable params: 69,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 354us/sample - loss: 0.2095 - acc: 0.9448\n",
      "Loss: 0.20951838995390965 Accuracy: 0.944756\n",
      "\n",
      "1D_CNN_custom_multi_2_GAP_ch_32_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 16000, 32)    192         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16000, 32)    0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 5333, 32)     0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5333, 32)     0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 1777, 32)     0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1777, 32)     0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 592, 32)      0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 592, 32)      0           conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 197, 32)      0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 197, 64)      0           conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 65, 64)       0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 65, 64)       0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 21, 64)       0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 21, 64)       0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 7, 64)        0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 7, 64)        20544       max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 64)        0           conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 2, 64)        0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 64)           0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 64)           0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 128)          0           global_average_pooling1d_22[0][0]\n",
      "                                                                 global_average_pooling1d_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 128)          0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           2064        dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 89,648\n",
      "Trainable params: 89,648\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 433us/sample - loss: 0.2288 - acc: 0.9398\n",
      "Loss: 0.22883789180966552 Accuracy: 0.93977153\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
