{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_ch_32_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Conv1D (kernel_size=5, filters=32, strides=1, \n",
    "                      padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=32*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "        \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 56864)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 56864)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                909840    \n",
      "=================================================================\n",
      "Total params: 920,720\n",
      "Trainable params: 920,528\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 18944)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 18944)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                303120    \n",
      "=================================================================\n",
      "Total params: 319,280\n",
      "Trainable params: 319,024\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 12608)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12608)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                201744    \n",
      "=================================================================\n",
      "Total params: 228,464\n",
      "Trainable params: 228,080\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                66576     \n",
      "=================================================================\n",
      "Total params: 114,096\n",
      "Trainable params: 113,584\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 65, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                21520     \n",
      "=================================================================\n",
      "Total params: 89,840\n",
      "Trainable params: 89,200\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 65, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                7184      \n",
      "=================================================================\n",
      "Total params: 96,304\n",
      "Trainable params: 95,536\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 65, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 7, 128)            41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 7, 128)            512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                4112      \n",
      "=================================================================\n",
      "Total params: 134,832\n",
      "Trainable params: 133,808\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model = build_1d_cnn_custom_ch_32_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1696 - acc: 0.3439\n",
      "Epoch 00001: val_loss improved from inf to 1.82974, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_3_conv_checkpoint/001-1.8297.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 2.1695 - acc: 0.3439 - val_loss: 1.8297 - val_acc: 0.4072\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4913 - acc: 0.5318\n",
      "Epoch 00002: val_loss improved from 1.82974 to 1.59983, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_3_conv_checkpoint/002-1.5998.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.4912 - acc: 0.5319 - val_loss: 1.5998 - val_acc: 0.4899\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1995 - acc: 0.6239\n",
      "Epoch 00003: val_loss improved from 1.59983 to 1.43214, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_3_conv_checkpoint/003-1.4321.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 1.1996 - acc: 0.6239 - val_loss: 1.4321 - val_acc: 0.5686\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0013 - acc: 0.6875\n",
      "Epoch 00004: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 1.0012 - acc: 0.6875 - val_loss: 1.4488 - val_acc: 0.5646\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8377 - acc: 0.7342\n",
      "Epoch 00005: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.8378 - acc: 0.7342 - val_loss: 1.4697 - val_acc: 0.5604\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6962 - acc: 0.7804\n",
      "Epoch 00006: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.6962 - acc: 0.7805 - val_loss: 1.5721 - val_acc: 0.5376\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5834 - acc: 0.8188\n",
      "Epoch 00007: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.5834 - acc: 0.8188 - val_loss: 1.5482 - val_acc: 0.5609\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4940 - acc: 0.8466\n",
      "Epoch 00008: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.4941 - acc: 0.8465 - val_loss: 1.5552 - val_acc: 0.5595\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4315 - acc: 0.8660- ETA: 1s - loss: 0\n",
      "Epoch 00009: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.4317 - acc: 0.8660 - val_loss: 2.0925 - val_acc: 0.4624\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3711 - acc: 0.8879\n",
      "Epoch 00010: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.3711 - acc: 0.8879 - val_loss: 1.7074 - val_acc: 0.5639\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3278 - acc: 0.9005\n",
      "Epoch 00011: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.3278 - acc: 0.9005 - val_loss: 1.7140 - val_acc: 0.5563\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2876 - acc: 0.9144\n",
      "Epoch 00012: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.2876 - acc: 0.9143 - val_loss: 1.6520 - val_acc: 0.5786\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2528 - acc: 0.9254\n",
      "Epoch 00013: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2528 - acc: 0.9254 - val_loss: 1.8020 - val_acc: 0.5607\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2310 - acc: 0.9332\n",
      "Epoch 00014: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.2310 - acc: 0.9332 - val_loss: 1.8321 - val_acc: 0.5702\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2062 - acc: 0.9417- ETA: 1s - loss: \n",
      "Epoch 00015: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2062 - acc: 0.9417 - val_loss: 2.1263 - val_acc: 0.5164\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1884 - acc: 0.9465\n",
      "Epoch 00016: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1883 - acc: 0.9465 - val_loss: 1.7772 - val_acc: 0.5956\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1775 - acc: 0.9505\n",
      "Epoch 00017: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1776 - acc: 0.9505 - val_loss: 2.0372 - val_acc: 0.5607\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9545- ETA: 0s - loss: 0.1635 - a\n",
      "Epoch 00018: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1644 - acc: 0.9545 - val_loss: 2.0096 - val_acc: 0.5565\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9592\n",
      "Epoch 00019: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1510 - acc: 0.9592 - val_loss: 2.0123 - val_acc: 0.5649\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9607\n",
      "Epoch 00020: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1396 - acc: 0.9606 - val_loss: 2.1964 - val_acc: 0.5425\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1521 - acc: 0.9577\n",
      "Epoch 00021: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1521 - acc: 0.9577 - val_loss: 1.8892 - val_acc: 0.5924\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9647\n",
      "Epoch 00022: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1274 - acc: 0.9647 - val_loss: 2.0605 - val_acc: 0.5698\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9707\n",
      "Epoch 00023: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1114 - acc: 0.9707 - val_loss: 2.0707 - val_acc: 0.5765\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1116 - acc: 0.9684\n",
      "Epoch 00024: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1116 - acc: 0.9684 - val_loss: 2.3653 - val_acc: 0.5365\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9712\n",
      "Epoch 00025: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1043 - acc: 0.9712 - val_loss: 2.2517 - val_acc: 0.5577\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9722\n",
      "Epoch 00026: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1018 - acc: 0.9722 - val_loss: 2.3457 - val_acc: 0.5511\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9723\n",
      "Epoch 00027: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0987 - acc: 0.9723 - val_loss: 2.5595 - val_acc: 0.5094\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9734\n",
      "Epoch 00028: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0946 - acc: 0.9734 - val_loss: 2.4124 - val_acc: 0.5316\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9739\n",
      "Epoch 00029: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0931 - acc: 0.9739 - val_loss: 2.2244 - val_acc: 0.5751\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9753\n",
      "Epoch 00030: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0889 - acc: 0.9753 - val_loss: 2.4483 - val_acc: 0.5646\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9755\n",
      "Epoch 00031: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0885 - acc: 0.9755 - val_loss: 2.3080 - val_acc: 0.5740\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9783\n",
      "Epoch 00032: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0806 - acc: 0.9783 - val_loss: 2.2544 - val_acc: 0.5765\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9785\n",
      "Epoch 00033: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0791 - acc: 0.9785 - val_loss: 2.1363 - val_acc: 0.5973\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9779\n",
      "Epoch 00034: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0807 - acc: 0.9779 - val_loss: 2.4623 - val_acc: 0.5695\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9830\n",
      "Epoch 00035: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0652 - acc: 0.9830 - val_loss: 2.1434 - val_acc: 0.5963\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9807\n",
      "Epoch 00036: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0720 - acc: 0.9807 - val_loss: 2.2567 - val_acc: 0.5954\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9821- ETA:\n",
      "Epoch 00037: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0679 - acc: 0.9821 - val_loss: 2.4440 - val_acc: 0.5705\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9801\n",
      "Epoch 00038: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0714 - acc: 0.9801 - val_loss: 2.6414 - val_acc: 0.5490\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9809\n",
      "Epoch 00039: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0694 - acc: 0.9809 - val_loss: 2.4198 - val_acc: 0.5826\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9834\n",
      "Epoch 00040: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0639 - acc: 0.9834 - val_loss: 2.2784 - val_acc: 0.5837\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9825\n",
      "Epoch 00041: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0652 - acc: 0.9824 - val_loss: 2.2570 - val_acc: 0.5970\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9805\n",
      "Epoch 00042: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0707 - acc: 0.9805 - val_loss: 2.4523 - val_acc: 0.5826\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9861\n",
      "Epoch 00043: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0554 - acc: 0.9861 - val_loss: 2.2926 - val_acc: 0.5910\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9841\n",
      "Epoch 00044: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0597 - acc: 0.9841 - val_loss: 2.5157 - val_acc: 0.5702\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9847\n",
      "Epoch 00045: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0559 - acc: 0.9847 - val_loss: 2.2830 - val_acc: 0.5977\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9849\n",
      "Epoch 00046: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0556 - acc: 0.9849 - val_loss: 2.8227 - val_acc: 0.5509\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9837\n",
      "Epoch 00047: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0598 - acc: 0.9838 - val_loss: 2.5052 - val_acc: 0.5809\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9869\n",
      "Epoch 00048: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0491 - acc: 0.9869 - val_loss: 2.6687 - val_acc: 0.5742\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9883\n",
      "Epoch 00049: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0483 - acc: 0.9883 - val_loss: 3.2525 - val_acc: 0.4959\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9855\n",
      "Epoch 00050: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0547 - acc: 0.9855 - val_loss: 2.3593 - val_acc: 0.5889\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9866\n",
      "Epoch 00051: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0500 - acc: 0.9866 - val_loss: 2.6513 - val_acc: 0.5637\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9848\n",
      "Epoch 00052: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0542 - acc: 0.9848 - val_loss: 2.5003 - val_acc: 0.5830\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9854\n",
      "Epoch 00053: val_loss did not improve from 1.43214\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0551 - acc: 0.9854 - val_loss: 2.6944 - val_acc: 0.5637\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 455us/sample - loss: 1.5887 - acc: 0.5277\n",
      "Loss: 1.5887069164654424 Accuracy: 0.5277259\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1194 - acc: 0.3396\n",
      "Epoch 00001: val_loss improved from inf to 1.71012, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_4_conv_checkpoint/001-1.7101.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 2.1194 - acc: 0.3396 - val_loss: 1.7101 - val_acc: 0.4314\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4297 - acc: 0.5470\n",
      "Epoch 00002: val_loss improved from 1.71012 to 1.30680, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_4_conv_checkpoint/002-1.3068.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.4297 - acc: 0.5470 - val_loss: 1.3068 - val_acc: 0.5938\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2044 - acc: 0.6222\n",
      "Epoch 00003: val_loss improved from 1.30680 to 1.11397, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_4_conv_checkpoint/003-1.1140.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 1.2046 - acc: 0.6222 - val_loss: 1.1140 - val_acc: 0.6587\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0724 - acc: 0.6664\n",
      "Epoch 00004: val_loss did not improve from 1.11397\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.0724 - acc: 0.6664 - val_loss: 1.1257 - val_acc: 0.6490\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9703 - acc: 0.6989\n",
      "Epoch 00005: val_loss improved from 1.11397 to 1.11382, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_4_conv_checkpoint/005-1.1138.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.9703 - acc: 0.6989 - val_loss: 1.1138 - val_acc: 0.6606\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8847 - acc: 0.7288\n",
      "Epoch 00006: val_loss did not improve from 1.11382\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.8848 - acc: 0.7287 - val_loss: 1.2581 - val_acc: 0.6180\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8188 - acc: 0.7467\n",
      "Epoch 00007: val_loss improved from 1.11382 to 1.10925, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_4_conv_checkpoint/007-1.1092.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.8188 - acc: 0.7466 - val_loss: 1.1092 - val_acc: 0.6699\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7486 - acc: 0.7706\n",
      "Epoch 00008: val_loss improved from 1.10925 to 1.07637, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_4_conv_checkpoint/008-1.0764.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.7486 - acc: 0.7706 - val_loss: 1.0764 - val_acc: 0.6697\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7004 - acc: 0.7844\n",
      "Epoch 00009: val_loss did not improve from 1.07637\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.7004 - acc: 0.7844 - val_loss: 1.1365 - val_acc: 0.6727\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6439 - acc: 0.8024\n",
      "Epoch 00010: val_loss improved from 1.07637 to 1.00063, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_4_conv_checkpoint/010-1.0006.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.6440 - acc: 0.8024 - val_loss: 1.0006 - val_acc: 0.7051\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6033 - acc: 0.8162\n",
      "Epoch 00011: val_loss improved from 1.00063 to 0.99402, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_4_conv_checkpoint/011-0.9940.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.6033 - acc: 0.8162 - val_loss: 0.9940 - val_acc: 0.7128\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5639 - acc: 0.8280\n",
      "Epoch 00012: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.5639 - acc: 0.8280 - val_loss: 1.0207 - val_acc: 0.7081\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5281 - acc: 0.8384\n",
      "Epoch 00013: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.5283 - acc: 0.8384 - val_loss: 1.0434 - val_acc: 0.6981\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5061 - acc: 0.8464\n",
      "Epoch 00014: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.5061 - acc: 0.8464 - val_loss: 1.0831 - val_acc: 0.6976\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4642 - acc: 0.8601\n",
      "Epoch 00015: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4642 - acc: 0.8601 - val_loss: 1.0511 - val_acc: 0.7044\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4381 - acc: 0.8651\n",
      "Epoch 00016: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4382 - acc: 0.8651 - val_loss: 1.0974 - val_acc: 0.6914\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4121 - acc: 0.8757\n",
      "Epoch 00017: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.4121 - acc: 0.8757 - val_loss: 1.0076 - val_acc: 0.7219\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3922 - acc: 0.8797\n",
      "Epoch 00018: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3924 - acc: 0.8796 - val_loss: 1.0520 - val_acc: 0.7079\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3702 - acc: 0.8856\n",
      "Epoch 00019: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3703 - acc: 0.8856 - val_loss: 1.2107 - val_acc: 0.6795\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3530 - acc: 0.8934\n",
      "Epoch 00020: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3531 - acc: 0.8934 - val_loss: 1.0488 - val_acc: 0.7205\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3268 - acc: 0.9009\n",
      "Epoch 00021: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3269 - acc: 0.9009 - val_loss: 1.1288 - val_acc: 0.6981\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3152 - acc: 0.9051\n",
      "Epoch 00022: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3152 - acc: 0.9051 - val_loss: 1.0968 - val_acc: 0.7028\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2960 - acc: 0.9140\n",
      "Epoch 00023: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2961 - acc: 0.9140 - val_loss: 1.1090 - val_acc: 0.7086\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2828 - acc: 0.9168\n",
      "Epoch 00024: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2828 - acc: 0.9168 - val_loss: 1.0428 - val_acc: 0.7268\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2695 - acc: 0.9193\n",
      "Epoch 00025: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2696 - acc: 0.9193 - val_loss: 1.1246 - val_acc: 0.7109\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2578 - acc: 0.9217\n",
      "Epoch 00026: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2577 - acc: 0.9217 - val_loss: 1.1606 - val_acc: 0.6995\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2505 - acc: 0.9247\n",
      "Epoch 00027: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2506 - acc: 0.9247 - val_loss: 1.1688 - val_acc: 0.7028\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2380 - acc: 0.9297\n",
      "Epoch 00028: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2381 - acc: 0.9297 - val_loss: 1.0919 - val_acc: 0.7191\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2367 - acc: 0.9299\n",
      "Epoch 00029: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2368 - acc: 0.9299 - val_loss: 1.1350 - val_acc: 0.7119\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2271 - acc: 0.9318\n",
      "Epoch 00030: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2271 - acc: 0.9318 - val_loss: 1.0977 - val_acc: 0.7219\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9364\n",
      "Epoch 00031: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2126 - acc: 0.9364 - val_loss: 1.1761 - val_acc: 0.7081\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2073 - acc: 0.9382\n",
      "Epoch 00032: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2073 - acc: 0.9382 - val_loss: 1.1820 - val_acc: 0.7060\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2000 - acc: 0.9399\n",
      "Epoch 00033: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1999 - acc: 0.9400 - val_loss: 1.1594 - val_acc: 0.7167\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1860 - acc: 0.9465\n",
      "Epoch 00034: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1861 - acc: 0.9465 - val_loss: 1.2619 - val_acc: 0.7056\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1853 - acc: 0.9460\n",
      "Epoch 00035: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1854 - acc: 0.9460 - val_loss: 1.1446 - val_acc: 0.7251\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1862 - acc: 0.9450\n",
      "Epoch 00036: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1862 - acc: 0.9450 - val_loss: 1.1598 - val_acc: 0.7160\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9473\n",
      "Epoch 00037: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1781 - acc: 0.9473 - val_loss: 1.1744 - val_acc: 0.7202\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9506\n",
      "Epoch 00038: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1709 - acc: 0.9505 - val_loss: 1.2683 - val_acc: 0.7046\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1662 - acc: 0.9499\n",
      "Epoch 00039: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1662 - acc: 0.9499 - val_loss: 1.1791 - val_acc: 0.7144\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1640 - acc: 0.9523\n",
      "Epoch 00040: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1640 - acc: 0.9523 - val_loss: 1.1209 - val_acc: 0.7314\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1527 - acc: 0.9560\n",
      "Epoch 00041: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1528 - acc: 0.9559 - val_loss: 1.1430 - val_acc: 0.7219\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1514 - acc: 0.9554\n",
      "Epoch 00042: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1515 - acc: 0.9554 - val_loss: 1.1616 - val_acc: 0.7247\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9557\n",
      "Epoch 00043: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1517 - acc: 0.9557 - val_loss: 1.2482 - val_acc: 0.7144\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9591\n",
      "Epoch 00044: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1409 - acc: 0.9591 - val_loss: 1.1295 - val_acc: 0.7389\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9584\n",
      "Epoch 00045: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1428 - acc: 0.9583 - val_loss: 1.4567 - val_acc: 0.6813\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9614\n",
      "Epoch 00046: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1354 - acc: 0.9614 - val_loss: 1.2936 - val_acc: 0.7051\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9634\n",
      "Epoch 00047: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1269 - acc: 0.9634 - val_loss: 1.2188 - val_acc: 0.7237\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9636\n",
      "Epoch 00048: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1285 - acc: 0.9636 - val_loss: 1.2677 - val_acc: 0.7105\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9630\n",
      "Epoch 00049: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1267 - acc: 0.9630 - val_loss: 1.2526 - val_acc: 0.7284\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9630\n",
      "Epoch 00050: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1249 - acc: 0.9630 - val_loss: 1.4804 - val_acc: 0.6895\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9651\n",
      "Epoch 00051: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1238 - acc: 0.9651 - val_loss: 1.1861 - val_acc: 0.7289\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9648\n",
      "Epoch 00052: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1218 - acc: 0.9648 - val_loss: 1.2472 - val_acc: 0.7202\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9663\n",
      "Epoch 00053: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1151 - acc: 0.9662 - val_loss: 1.4086 - val_acc: 0.6862\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9659\n",
      "Epoch 00054: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1202 - acc: 0.9658 - val_loss: 1.2779 - val_acc: 0.7223\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9669\n",
      "Epoch 00055: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 0.1153 - acc: 0.9669 - val_loss: 1.2172 - val_acc: 0.7293\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9682\n",
      "Epoch 00056: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1104 - acc: 0.9681 - val_loss: 1.2425 - val_acc: 0.7396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9657\n",
      "Epoch 00057: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1171 - acc: 0.9656 - val_loss: 1.2206 - val_acc: 0.7286\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9696\n",
      "Epoch 00058: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1059 - acc: 0.9696 - val_loss: 1.1783 - val_acc: 0.7407\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9690\n",
      "Epoch 00059: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1050 - acc: 0.9690 - val_loss: 1.2544 - val_acc: 0.7328\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9692\n",
      "Epoch 00060: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1091 - acc: 0.9692 - val_loss: 1.2600 - val_acc: 0.7333\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9716\n",
      "Epoch 00061: val_loss did not improve from 0.99402\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1009 - acc: 0.9716 - val_loss: 1.3044 - val_acc: 0.7261\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 513us/sample - loss: 1.0736 - acc: 0.6712\n",
      "Loss: 1.0736183411607119 Accuracy: 0.67123574\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1079 - acc: 0.3464\n",
      "Epoch 00001: val_loss improved from inf to 1.70032, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv_checkpoint/001-1.7003.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 2.1079 - acc: 0.3464 - val_loss: 1.7003 - val_acc: 0.4307\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4060 - acc: 0.5512\n",
      "Epoch 00002: val_loss improved from 1.70032 to 1.19155, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv_checkpoint/002-1.1916.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.4061 - acc: 0.5511 - val_loss: 1.1916 - val_acc: 0.6271\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1786 - acc: 0.6307\n",
      "Epoch 00003: val_loss improved from 1.19155 to 1.06339, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv_checkpoint/003-1.0634.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.1789 - acc: 0.6306 - val_loss: 1.0634 - val_acc: 0.6730\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0433 - acc: 0.6739\n",
      "Epoch 00004: val_loss improved from 1.06339 to 0.95446, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv_checkpoint/004-0.9545.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 1.0432 - acc: 0.6740 - val_loss: 0.9545 - val_acc: 0.7000\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9427 - acc: 0.7079\n",
      "Epoch 00005: val_loss improved from 0.95446 to 0.92772, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv_checkpoint/005-0.9277.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.9428 - acc: 0.7078 - val_loss: 0.9277 - val_acc: 0.7254\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8666 - acc: 0.7321\n",
      "Epoch 00006: val_loss improved from 0.92772 to 0.88392, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv_checkpoint/006-0.8839.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.8669 - acc: 0.7321 - val_loss: 0.8839 - val_acc: 0.7365\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8101 - acc: 0.7517\n",
      "Epoch 00007: val_loss improved from 0.88392 to 0.83163, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv_checkpoint/007-0.8316.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.8100 - acc: 0.7517 - val_loss: 0.8316 - val_acc: 0.7566\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7608 - acc: 0.7671\n",
      "Epoch 00008: val_loss did not improve from 0.83163\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.7609 - acc: 0.7671 - val_loss: 0.8735 - val_acc: 0.7454\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7144 - acc: 0.7818\n",
      "Epoch 00009: val_loss did not improve from 0.83163\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.7144 - acc: 0.7819 - val_loss: 0.8843 - val_acc: 0.7356\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6773 - acc: 0.7937\n",
      "Epoch 00010: val_loss did not improve from 0.83163\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.6772 - acc: 0.7937 - val_loss: 0.8881 - val_acc: 0.7333\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6371 - acc: 0.8056\n",
      "Epoch 00011: val_loss improved from 0.83163 to 0.81610, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv_checkpoint/011-0.8161.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.6371 - acc: 0.8056 - val_loss: 0.8161 - val_acc: 0.7710\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6017 - acc: 0.8179\n",
      "Epoch 00012: val_loss improved from 0.81610 to 0.78922, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv_checkpoint/012-0.7892.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.6020 - acc: 0.8179 - val_loss: 0.7892 - val_acc: 0.7738\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5729 - acc: 0.8256\n",
      "Epoch 00013: val_loss did not improve from 0.78922\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.5729 - acc: 0.8256 - val_loss: 0.8530 - val_acc: 0.7531\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5442 - acc: 0.8330\n",
      "Epoch 00014: val_loss did not improve from 0.78922\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.5443 - acc: 0.8330 - val_loss: 0.8557 - val_acc: 0.7449\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5183 - acc: 0.8417\n",
      "Epoch 00015: val_loss did not improve from 0.78922\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.5183 - acc: 0.8418 - val_loss: 0.7916 - val_acc: 0.7799\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4939 - acc: 0.8496\n",
      "Epoch 00016: val_loss improved from 0.78922 to 0.76537, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv_checkpoint/016-0.7654.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.4941 - acc: 0.8496 - val_loss: 0.7654 - val_acc: 0.7890\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4725 - acc: 0.8571\n",
      "Epoch 00017: val_loss did not improve from 0.76537\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.4725 - acc: 0.8571 - val_loss: 0.7769 - val_acc: 0.7799\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4477 - acc: 0.8637\n",
      "Epoch 00018: val_loss did not improve from 0.76537\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.4477 - acc: 0.8637 - val_loss: 0.8213 - val_acc: 0.7715\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4257 - acc: 0.8712\n",
      "Epoch 00019: val_loss did not improve from 0.76537\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.4259 - acc: 0.8712 - val_loss: 0.7797 - val_acc: 0.7717\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4113 - acc: 0.8732\n",
      "Epoch 00020: val_loss did not improve from 0.76537\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.4113 - acc: 0.8733 - val_loss: 0.8196 - val_acc: 0.7699\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3893 - acc: 0.8792\n",
      "Epoch 00021: val_loss improved from 0.76537 to 0.76074, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv_checkpoint/021-0.7607.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3894 - acc: 0.8791 - val_loss: 0.7607 - val_acc: 0.7883\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3777 - acc: 0.8854\n",
      "Epoch 00022: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3777 - acc: 0.8853 - val_loss: 0.9332 - val_acc: 0.7496\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3610 - acc: 0.8908\n",
      "Epoch 00023: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3611 - acc: 0.8907 - val_loss: 0.8814 - val_acc: 0.7608\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3467 - acc: 0.8933\n",
      "Epoch 00024: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3467 - acc: 0.8933 - val_loss: 0.9227 - val_acc: 0.7473\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3246 - acc: 0.9015\n",
      "Epoch 00025: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3245 - acc: 0.9015 - val_loss: 0.8009 - val_acc: 0.7785\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3159 - acc: 0.9036\n",
      "Epoch 00026: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3159 - acc: 0.9036 - val_loss: 0.7877 - val_acc: 0.7761\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3055 - acc: 0.9089\n",
      "Epoch 00027: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.3056 - acc: 0.9088 - val_loss: 0.8502 - val_acc: 0.7645\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2946 - acc: 0.9103\n",
      "Epoch 00028: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2948 - acc: 0.9103 - val_loss: 0.8381 - val_acc: 0.7827\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2804 - acc: 0.9141\n",
      "Epoch 00029: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2805 - acc: 0.9140 - val_loss: 0.8065 - val_acc: 0.7759\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2709 - acc: 0.9173\n",
      "Epoch 00030: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2709 - acc: 0.9173 - val_loss: 0.8297 - val_acc: 0.7743\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2595 - acc: 0.9201\n",
      "Epoch 00031: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2595 - acc: 0.9200 - val_loss: 0.8757 - val_acc: 0.7713\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2500 - acc: 0.9247\n",
      "Epoch 00032: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2501 - acc: 0.9247 - val_loss: 0.8000 - val_acc: 0.7843\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2450 - acc: 0.9264\n",
      "Epoch 00033: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2449 - acc: 0.9264 - val_loss: 0.9244 - val_acc: 0.7596\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2345 - acc: 0.9286\n",
      "Epoch 00034: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2345 - acc: 0.9287 - val_loss: 0.9014 - val_acc: 0.7587\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2226 - acc: 0.9348\n",
      "Epoch 00035: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2226 - acc: 0.9348 - val_loss: 0.8062 - val_acc: 0.7885\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2206 - acc: 0.9338\n",
      "Epoch 00036: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2207 - acc: 0.9338 - val_loss: 0.9124 - val_acc: 0.7694\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2149 - acc: 0.9354\n",
      "Epoch 00037: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2149 - acc: 0.9354 - val_loss: 0.7770 - val_acc: 0.7983\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2069 - acc: 0.9370\n",
      "Epoch 00038: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2069 - acc: 0.9370 - val_loss: 0.8657 - val_acc: 0.7738\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2001 - acc: 0.9393\n",
      "Epoch 00039: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.2001 - acc: 0.9393 - val_loss: 0.8247 - val_acc: 0.7880\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1943 - acc: 0.9414\n",
      "Epoch 00040: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1942 - acc: 0.9414 - val_loss: 0.8266 - val_acc: 0.7901\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1818 - acc: 0.9451\n",
      "Epoch 00041: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1819 - acc: 0.9451 - val_loss: 0.9268 - val_acc: 0.7612\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1865 - acc: 0.9429\n",
      "Epoch 00042: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1865 - acc: 0.9429 - val_loss: 0.8893 - val_acc: 0.7694\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1754 - acc: 0.9482\n",
      "Epoch 00043: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1754 - acc: 0.9482 - val_loss: 0.8129 - val_acc: 0.7950\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1746 - acc: 0.9477\n",
      "Epoch 00044: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1749 - acc: 0.9477 - val_loss: 0.8572 - val_acc: 0.7857\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1688 - acc: 0.9489\n",
      "Epoch 00045: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1688 - acc: 0.9489 - val_loss: 1.0963 - val_acc: 0.7375\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1649 - acc: 0.9501\n",
      "Epoch 00046: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1649 - acc: 0.9501 - val_loss: 1.0148 - val_acc: 0.7633\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1588 - acc: 0.9526\n",
      "Epoch 00047: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1588 - acc: 0.9526 - val_loss: 0.8538 - val_acc: 0.7892\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9530\n",
      "Epoch 00048: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1572 - acc: 0.9530 - val_loss: 0.9949 - val_acc: 0.7622\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9541\n",
      "Epoch 00049: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1546 - acc: 0.9541 - val_loss: 1.0079 - val_acc: 0.7615\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1482 - acc: 0.9543\n",
      "Epoch 00050: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1482 - acc: 0.9544 - val_loss: 0.8793 - val_acc: 0.7782\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9568\n",
      "Epoch 00051: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1450 - acc: 0.9568 - val_loss: 0.8742 - val_acc: 0.7883\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9577\n",
      "Epoch 00052: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1405 - acc: 0.9577 - val_loss: 0.9257 - val_acc: 0.7827\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1396 - acc: 0.9588\n",
      "Epoch 00053: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1398 - acc: 0.9588 - val_loss: 1.0676 - val_acc: 0.7522\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9595\n",
      "Epoch 00054: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1379 - acc: 0.9594 - val_loss: 0.8688 - val_acc: 0.7880\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9598\n",
      "Epoch 00055: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1368 - acc: 0.9598 - val_loss: 0.8739 - val_acc: 0.7885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9620\n",
      "Epoch 00056: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1277 - acc: 0.9620 - val_loss: 0.8734 - val_acc: 0.7932\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9616\n",
      "Epoch 00057: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1306 - acc: 0.9616 - val_loss: 0.9321 - val_acc: 0.7829\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9625\n",
      "Epoch 00058: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1263 - acc: 0.9625 - val_loss: 0.9783 - val_acc: 0.7738\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9645\n",
      "Epoch 00059: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1220 - acc: 0.9645 - val_loss: 0.8578 - val_acc: 0.7966\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9641\n",
      "Epoch 00060: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1220 - acc: 0.9641 - val_loss: 0.8709 - val_acc: 0.8055\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9633\n",
      "Epoch 00061: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1213 - acc: 0.9633 - val_loss: 0.9085 - val_acc: 0.7915\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9640\n",
      "Epoch 00062: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1194 - acc: 0.9640 - val_loss: 0.8919 - val_acc: 0.7922\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9665\n",
      "Epoch 00063: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1122 - acc: 0.9665 - val_loss: 0.9614 - val_acc: 0.7857\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9651\n",
      "Epoch 00064: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1191 - acc: 0.9650 - val_loss: 0.9858 - val_acc: 0.7792\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9674\n",
      "Epoch 00065: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1134 - acc: 0.9674 - val_loss: 1.0059 - val_acc: 0.7764\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9705\n",
      "Epoch 00066: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1027 - acc: 0.9705 - val_loss: 0.9101 - val_acc: 0.7957\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9686\n",
      "Epoch 00067: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1062 - acc: 0.9686 - val_loss: 0.9160 - val_acc: 0.7922\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9682\n",
      "Epoch 00068: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1074 - acc: 0.9682 - val_loss: 0.8771 - val_acc: 0.7976\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9695\n",
      "Epoch 00069: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1058 - acc: 0.9695 - val_loss: 0.9012 - val_acc: 0.7939\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9705\n",
      "Epoch 00070: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.0997 - acc: 0.9704 - val_loss: 1.1298 - val_acc: 0.7615\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9678\n",
      "Epoch 00071: val_loss did not improve from 0.76074\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 0.1036 - acc: 0.9678 - val_loss: 1.1267 - val_acc: 0.7452\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 552us/sample - loss: 0.8717 - acc: 0.7458\n",
      "Loss: 0.8716720554935102 Accuracy: 0.7457944\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1971 - acc: 0.3080\n",
      "Epoch 00001: val_loss improved from inf to 1.69530, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/001-1.6953.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 2.1970 - acc: 0.3080 - val_loss: 1.6953 - val_acc: 0.4407\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3857 - acc: 0.5571\n",
      "Epoch 00002: val_loss improved from 1.69530 to 1.11963, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/002-1.1196.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.3858 - acc: 0.5571 - val_loss: 1.1196 - val_acc: 0.6546\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1348 - acc: 0.6428\n",
      "Epoch 00003: val_loss improved from 1.11963 to 1.00300, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/003-1.0030.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.1348 - acc: 0.6428 - val_loss: 1.0030 - val_acc: 0.6951\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0029 - acc: 0.6887\n",
      "Epoch 00004: val_loss improved from 1.00300 to 0.93646, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/004-0.9365.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.0029 - acc: 0.6887 - val_loss: 0.9365 - val_acc: 0.7191\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9027 - acc: 0.7204\n",
      "Epoch 00005: val_loss improved from 0.93646 to 0.90753, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/005-0.9075.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.9026 - acc: 0.7204 - val_loss: 0.9075 - val_acc: 0.7179\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8365 - acc: 0.7434\n",
      "Epoch 00006: val_loss improved from 0.90753 to 0.82957, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/006-0.8296.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.8366 - acc: 0.7434 - val_loss: 0.8296 - val_acc: 0.7440\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7743 - acc: 0.7642\n",
      "Epoch 00007: val_loss improved from 0.82957 to 0.72070, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/007-0.7207.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.7744 - acc: 0.7642 - val_loss: 0.7207 - val_acc: 0.8006\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7246 - acc: 0.7805\n",
      "Epoch 00008: val_loss improved from 0.72070 to 0.66544, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/008-0.6654.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.7246 - acc: 0.7805 - val_loss: 0.6654 - val_acc: 0.8090\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6821 - acc: 0.7945\n",
      "Epoch 00009: val_loss did not improve from 0.66544\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.6821 - acc: 0.7945 - val_loss: 0.6969 - val_acc: 0.7992\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6447 - acc: 0.8059\n",
      "Epoch 00010: val_loss did not improve from 0.66544\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.6448 - acc: 0.8059 - val_loss: 0.6655 - val_acc: 0.8041\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6065 - acc: 0.8186\n",
      "Epoch 00011: val_loss improved from 0.66544 to 0.60244, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/011-0.6024.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.6066 - acc: 0.8185 - val_loss: 0.6024 - val_acc: 0.8307\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5819 - acc: 0.8274\n",
      "Epoch 00012: val_loss did not improve from 0.60244\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5822 - acc: 0.8273 - val_loss: 0.6535 - val_acc: 0.8118\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5541 - acc: 0.8360\n",
      "Epoch 00013: val_loss improved from 0.60244 to 0.58011, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/013-0.5801.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5541 - acc: 0.8360 - val_loss: 0.5801 - val_acc: 0.8339\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5283 - acc: 0.8441\n",
      "Epoch 00014: val_loss did not improve from 0.58011\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5283 - acc: 0.8441 - val_loss: 0.6283 - val_acc: 0.8139\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5061 - acc: 0.8518\n",
      "Epoch 00015: val_loss improved from 0.58011 to 0.57298, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/015-0.5730.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5062 - acc: 0.8518 - val_loss: 0.5730 - val_acc: 0.8355\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4850 - acc: 0.8578\n",
      "Epoch 00016: val_loss did not improve from 0.57298\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4851 - acc: 0.8577 - val_loss: 0.6208 - val_acc: 0.8258\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4669 - acc: 0.8621\n",
      "Epoch 00017: val_loss improved from 0.57298 to 0.54185, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/017-0.5418.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4669 - acc: 0.8621 - val_loss: 0.5418 - val_acc: 0.8472\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4496 - acc: 0.8666\n",
      "Epoch 00018: val_loss did not improve from 0.54185\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4496 - acc: 0.8666 - val_loss: 0.5954 - val_acc: 0.8330\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4306 - acc: 0.8744\n",
      "Epoch 00019: val_loss improved from 0.54185 to 0.51133, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/019-0.5113.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4307 - acc: 0.8744 - val_loss: 0.5113 - val_acc: 0.8586\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4141 - acc: 0.8776\n",
      "Epoch 00020: val_loss did not improve from 0.51133\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4145 - acc: 0.8775 - val_loss: 0.5469 - val_acc: 0.8477\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4077 - acc: 0.8807\n",
      "Epoch 00021: val_loss did not improve from 0.51133\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4078 - acc: 0.8807 - val_loss: 0.5651 - val_acc: 0.8381\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3872 - acc: 0.8858\n",
      "Epoch 00022: val_loss did not improve from 0.51133\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3875 - acc: 0.8857 - val_loss: 0.5410 - val_acc: 0.8439\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3821 - acc: 0.8868\n",
      "Epoch 00023: val_loss improved from 0.51133 to 0.48197, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/023-0.4820.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3822 - acc: 0.8868 - val_loss: 0.4820 - val_acc: 0.8698\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3640 - acc: 0.8928\n",
      "Epoch 00024: val_loss did not improve from 0.48197\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3639 - acc: 0.8928 - val_loss: 0.5151 - val_acc: 0.8535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3528 - acc: 0.8961\n",
      "Epoch 00025: val_loss did not improve from 0.48197\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3529 - acc: 0.8960 - val_loss: 0.4894 - val_acc: 0.8609\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3467 - acc: 0.8979\n",
      "Epoch 00026: val_loss did not improve from 0.48197\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3468 - acc: 0.8978 - val_loss: 0.4982 - val_acc: 0.8661\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3332 - acc: 0.9021\n",
      "Epoch 00027: val_loss did not improve from 0.48197\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3332 - acc: 0.9021 - val_loss: 0.5090 - val_acc: 0.8523\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3218 - acc: 0.9051\n",
      "Epoch 00028: val_loss did not improve from 0.48197\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3218 - acc: 0.9051 - val_loss: 0.5215 - val_acc: 0.8549\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3122 - acc: 0.9079\n",
      "Epoch 00029: val_loss did not improve from 0.48197\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3123 - acc: 0.9079 - val_loss: 0.6487 - val_acc: 0.8323\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3048 - acc: 0.9106\n",
      "Epoch 00030: val_loss did not improve from 0.48197\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3049 - acc: 0.9106 - val_loss: 0.5345 - val_acc: 0.8602\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2990 - acc: 0.9121\n",
      "Epoch 00031: val_loss improved from 0.48197 to 0.47485, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/031-0.4748.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2991 - acc: 0.9121 - val_loss: 0.4748 - val_acc: 0.8663\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2884 - acc: 0.9157\n",
      "Epoch 00032: val_loss did not improve from 0.47485\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2884 - acc: 0.9157 - val_loss: 0.4830 - val_acc: 0.8649\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2802 - acc: 0.9157\n",
      "Epoch 00033: val_loss did not improve from 0.47485\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2803 - acc: 0.9157 - val_loss: 0.4767 - val_acc: 0.8726\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2702 - acc: 0.9216\n",
      "Epoch 00034: val_loss did not improve from 0.47485\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2703 - acc: 0.9216 - val_loss: 0.5686 - val_acc: 0.8400\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2678 - acc: 0.9203\n",
      "Epoch 00035: val_loss did not improve from 0.47485\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2682 - acc: 0.9202 - val_loss: 0.4986 - val_acc: 0.8616\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2602 - acc: 0.9223\n",
      "Epoch 00036: val_loss did not improve from 0.47485\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2603 - acc: 0.9222 - val_loss: 0.5210 - val_acc: 0.8546\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2567 - acc: 0.9235\n",
      "Epoch 00037: val_loss improved from 0.47485 to 0.46450, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/037-0.4645.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2568 - acc: 0.9235 - val_loss: 0.4645 - val_acc: 0.8740\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2474 - acc: 0.9267\n",
      "Epoch 00038: val_loss did not improve from 0.46450\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2474 - acc: 0.9267 - val_loss: 0.5025 - val_acc: 0.8584\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2371 - acc: 0.9293\n",
      "Epoch 00039: val_loss did not improve from 0.46450\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2371 - acc: 0.9292 - val_loss: 0.4781 - val_acc: 0.8649\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2394 - acc: 0.9280\n",
      "Epoch 00040: val_loss improved from 0.46450 to 0.46232, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/040-0.4623.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2394 - acc: 0.9280 - val_loss: 0.4623 - val_acc: 0.8735\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2237 - acc: 0.9346\n",
      "Epoch 00041: val_loss improved from 0.46232 to 0.45225, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/041-0.4522.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2239 - acc: 0.9346 - val_loss: 0.4522 - val_acc: 0.8719\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2284 - acc: 0.9312\n",
      "Epoch 00042: val_loss improved from 0.45225 to 0.44574, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/042-0.4457.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2284 - acc: 0.9312 - val_loss: 0.4457 - val_acc: 0.8754\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2188 - acc: 0.9338\n",
      "Epoch 00043: val_loss did not improve from 0.44574\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2188 - acc: 0.9338 - val_loss: 0.4636 - val_acc: 0.8754\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2133 - acc: 0.9358\n",
      "Epoch 00044: val_loss did not improve from 0.44574\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2134 - acc: 0.9358 - val_loss: 0.4709 - val_acc: 0.8724\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2103 - acc: 0.9362\n",
      "Epoch 00045: val_loss did not improve from 0.44574\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2103 - acc: 0.9362 - val_loss: 0.4599 - val_acc: 0.8800\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2041 - acc: 0.9398\n",
      "Epoch 00046: val_loss did not improve from 0.44574\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2041 - acc: 0.9398 - val_loss: 0.4542 - val_acc: 0.8810\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1996 - acc: 0.9411\n",
      "Epoch 00047: val_loss did not improve from 0.44574\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1997 - acc: 0.9410 - val_loss: 0.4925 - val_acc: 0.8637\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1951 - acc: 0.9413\n",
      "Epoch 00048: val_loss did not improve from 0.44574\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1950 - acc: 0.9413 - val_loss: 0.4787 - val_acc: 0.8775\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9408\n",
      "Epoch 00049: val_loss did not improve from 0.44574\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1911 - acc: 0.9408 - val_loss: 0.4862 - val_acc: 0.8758\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1896 - acc: 0.9435\n",
      "Epoch 00050: val_loss did not improve from 0.44574\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1896 - acc: 0.9435 - val_loss: 0.4718 - val_acc: 0.8782\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9456\n",
      "Epoch 00051: val_loss improved from 0.44574 to 0.43486, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv_checkpoint/051-0.4349.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1811 - acc: 0.9456 - val_loss: 0.4349 - val_acc: 0.8840\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9439\n",
      "Epoch 00052: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1821 - acc: 0.9438 - val_loss: 0.4849 - val_acc: 0.8661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1798 - acc: 0.9457\n",
      "Epoch 00053: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1798 - acc: 0.9457 - val_loss: 0.4602 - val_acc: 0.8772\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9498\n",
      "Epoch 00054: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1679 - acc: 0.9498 - val_loss: 0.4614 - val_acc: 0.8800\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1661 - acc: 0.9494\n",
      "Epoch 00055: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1661 - acc: 0.9494 - val_loss: 0.4360 - val_acc: 0.8821\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1697 - acc: 0.9491\n",
      "Epoch 00056: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1699 - acc: 0.9491 - val_loss: 0.5985 - val_acc: 0.8432\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9496\n",
      "Epoch 00057: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1689 - acc: 0.9497 - val_loss: 0.4673 - val_acc: 0.8775\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1555 - acc: 0.9528\n",
      "Epoch 00058: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1556 - acc: 0.9528 - val_loss: 0.4639 - val_acc: 0.8779\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1573 - acc: 0.9532\n",
      "Epoch 00059: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1575 - acc: 0.9531 - val_loss: 0.5004 - val_acc: 0.8649\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9521\n",
      "Epoch 00060: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1603 - acc: 0.9521 - val_loss: 0.4783 - val_acc: 0.8763\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9545\n",
      "Epoch 00061: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1520 - acc: 0.9545 - val_loss: 0.5454 - val_acc: 0.8670\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1484 - acc: 0.9552\n",
      "Epoch 00062: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1483 - acc: 0.9552 - val_loss: 0.4444 - val_acc: 0.8849\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1458 - acc: 0.9580\n",
      "Epoch 00063: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1459 - acc: 0.9580 - val_loss: 0.5403 - val_acc: 0.8644\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9555\n",
      "Epoch 00064: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1469 - acc: 0.9554 - val_loss: 0.4615 - val_acc: 0.8810\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9579\n",
      "Epoch 00065: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1407 - acc: 0.9579 - val_loss: 0.4707 - val_acc: 0.8782\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1365 - acc: 0.9585\n",
      "Epoch 00066: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1369 - acc: 0.9585 - val_loss: 0.4597 - val_acc: 0.8812\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1374 - acc: 0.9595\n",
      "Epoch 00067: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1373 - acc: 0.9595 - val_loss: 0.4560 - val_acc: 0.8880\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9598\n",
      "Epoch 00068: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1313 - acc: 0.9597 - val_loss: 0.4389 - val_acc: 0.8931\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9583\n",
      "Epoch 00069: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1380 - acc: 0.9583 - val_loss: 0.4517 - val_acc: 0.8898\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9621\n",
      "Epoch 00070: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1281 - acc: 0.9621 - val_loss: 0.4402 - val_acc: 0.8849\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9615\n",
      "Epoch 00071: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1289 - acc: 0.9614 - val_loss: 0.4363 - val_acc: 0.8868\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9618\n",
      "Epoch 00072: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1264 - acc: 0.9618 - val_loss: 0.4514 - val_acc: 0.8908\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9632\n",
      "Epoch 00073: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1210 - acc: 0.9632 - val_loss: 0.4960 - val_acc: 0.8847\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9635\n",
      "Epoch 00074: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1206 - acc: 0.9635 - val_loss: 0.4999 - val_acc: 0.8796\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9630\n",
      "Epoch 00075: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1232 - acc: 0.9630 - val_loss: 0.4457 - val_acc: 0.8898\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9642\n",
      "Epoch 00076: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1172 - acc: 0.9642 - val_loss: 0.4733 - val_acc: 0.8873\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9667\n",
      "Epoch 00077: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1141 - acc: 0.9667 - val_loss: 0.5444 - val_acc: 0.8693\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9652\n",
      "Epoch 00078: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1159 - acc: 0.9652 - val_loss: 0.4613 - val_acc: 0.8859\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9673\n",
      "Epoch 00079: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1102 - acc: 0.9672 - val_loss: 0.4850 - val_acc: 0.8724\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9661\n",
      "Epoch 00080: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1115 - acc: 0.9661 - val_loss: 0.4697 - val_acc: 0.8817\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9686\n",
      "Epoch 00081: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1067 - acc: 0.9686 - val_loss: 0.4533 - val_acc: 0.8884\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9689\n",
      "Epoch 00082: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1038 - acc: 0.9689 - val_loss: 0.4811 - val_acc: 0.8863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9678\n",
      "Epoch 00083: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1081 - acc: 0.9678 - val_loss: 0.4739 - val_acc: 0.8777\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9691\n",
      "Epoch 00084: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1041 - acc: 0.9691 - val_loss: 0.4961 - val_acc: 0.8775\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9702\n",
      "Epoch 00085: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1021 - acc: 0.9702 - val_loss: 0.5455 - val_acc: 0.8728\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9685\n",
      "Epoch 00086: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1042 - acc: 0.9685 - val_loss: 0.4585 - val_acc: 0.8870\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9693\n",
      "Epoch 00087: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1019 - acc: 0.9693 - val_loss: 0.5012 - val_acc: 0.8779\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9718\n",
      "Epoch 00088: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0959 - acc: 0.9717 - val_loss: 0.4441 - val_acc: 0.8949\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9708\n",
      "Epoch 00089: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0996 - acc: 0.9708 - val_loss: 0.4693 - val_acc: 0.8882\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9725\n",
      "Epoch 00090: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0942 - acc: 0.9725 - val_loss: 0.4849 - val_acc: 0.8819\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9721\n",
      "Epoch 00091: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0943 - acc: 0.9721 - val_loss: 0.4674 - val_acc: 0.8861\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9732\n",
      "Epoch 00092: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0924 - acc: 0.9732 - val_loss: 0.4978 - val_acc: 0.8744\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9721\n",
      "Epoch 00093: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0936 - acc: 0.9721 - val_loss: 0.4573 - val_acc: 0.8901\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9748\n",
      "Epoch 00094: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0885 - acc: 0.9748 - val_loss: 0.5206 - val_acc: 0.8730\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9730\n",
      "Epoch 00095: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0914 - acc: 0.9730 - val_loss: 0.4805 - val_acc: 0.8880\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9720\n",
      "Epoch 00096: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0931 - acc: 0.9720 - val_loss: 0.4576 - val_acc: 0.8875\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9749\n",
      "Epoch 00097: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0865 - acc: 0.9749 - val_loss: 0.4749 - val_acc: 0.8891\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9751\n",
      "Epoch 00098: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0831 - acc: 0.9751 - val_loss: 0.4614 - val_acc: 0.8940\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9760\n",
      "Epoch 00099: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0822 - acc: 0.9759 - val_loss: 0.4936 - val_acc: 0.8891\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0879 - acc: 0.9734\n",
      "Epoch 00100: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0880 - acc: 0.9733 - val_loss: 0.4637 - val_acc: 0.8898\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9759\n",
      "Epoch 00101: val_loss did not improve from 0.43486\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.0817 - acc: 0.9758 - val_loss: 0.4506 - val_acc: 0.8921\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 565us/sample - loss: 0.5385 - acc: 0.8536\n",
      "Loss: 0.5385464418838081 Accuracy: 0.85358256\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3530 - acc: 0.2590\n",
      "Epoch 00001: val_loss improved from inf to 1.84534, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/001-1.8453.hdf5\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 2.3531 - acc: 0.2590 - val_loss: 1.8453 - val_acc: 0.3941\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5085 - acc: 0.5105\n",
      "Epoch 00002: val_loss improved from 1.84534 to 1.14646, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/002-1.1465.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.5086 - acc: 0.5104 - val_loss: 1.1465 - val_acc: 0.6466\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1904 - acc: 0.6248\n",
      "Epoch 00003: val_loss improved from 1.14646 to 0.94382, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/003-0.9438.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.1904 - acc: 0.6248 - val_loss: 0.9438 - val_acc: 0.7268\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9922 - acc: 0.6964\n",
      "Epoch 00004: val_loss improved from 0.94382 to 0.93786, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/004-0.9379.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.9921 - acc: 0.6965 - val_loss: 0.9379 - val_acc: 0.7105\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8508 - acc: 0.7435\n",
      "Epoch 00005: val_loss improved from 0.93786 to 0.77036, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/005-0.7704.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.8510 - acc: 0.7434 - val_loss: 0.7704 - val_acc: 0.7766\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7503 - acc: 0.7761\n",
      "Epoch 00006: val_loss did not improve from 0.77036\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.7503 - acc: 0.7761 - val_loss: 1.0997 - val_acc: 0.6525\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6699 - acc: 0.8001\n",
      "Epoch 00007: val_loss improved from 0.77036 to 0.56395, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/007-0.5640.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.6700 - acc: 0.8001 - val_loss: 0.5640 - val_acc: 0.8409\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6078 - acc: 0.8198\n",
      "Epoch 00008: val_loss improved from 0.56395 to 0.53716, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/008-0.5372.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.6079 - acc: 0.8198 - val_loss: 0.5372 - val_acc: 0.8544\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5535 - acc: 0.8372\n",
      "Epoch 00009: val_loss improved from 0.53716 to 0.52649, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/009-0.5265.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.5536 - acc: 0.8372 - val_loss: 0.5265 - val_acc: 0.8479\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5140 - acc: 0.8469\n",
      "Epoch 00010: val_loss improved from 0.52649 to 0.46861, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/010-0.4686.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.5141 - acc: 0.8468 - val_loss: 0.4686 - val_acc: 0.8675\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4735 - acc: 0.8597\n",
      "Epoch 00011: val_loss did not improve from 0.46861\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4736 - acc: 0.8597 - val_loss: 0.5119 - val_acc: 0.8523\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4451 - acc: 0.8689\n",
      "Epoch 00012: val_loss improved from 0.46861 to 0.39734, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/012-0.3973.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4450 - acc: 0.8689 - val_loss: 0.3973 - val_acc: 0.8884\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4129 - acc: 0.8776\n",
      "Epoch 00013: val_loss improved from 0.39734 to 0.38702, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/013-0.3870.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4130 - acc: 0.8776 - val_loss: 0.3870 - val_acc: 0.8896\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3912 - acc: 0.8843\n",
      "Epoch 00014: val_loss improved from 0.38702 to 0.36947, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/014-0.3695.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3912 - acc: 0.8843 - val_loss: 0.3695 - val_acc: 0.8919\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3725 - acc: 0.8909\n",
      "Epoch 00015: val_loss did not improve from 0.36947\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3726 - acc: 0.8908 - val_loss: 0.3815 - val_acc: 0.8891\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3542 - acc: 0.8950\n",
      "Epoch 00016: val_loss did not improve from 0.36947\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3542 - acc: 0.8950 - val_loss: 0.3842 - val_acc: 0.8859\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3345 - acc: 0.9014\n",
      "Epoch 00017: val_loss did not improve from 0.36947\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3345 - acc: 0.9014 - val_loss: 0.3898 - val_acc: 0.8849\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3164 - acc: 0.9051\n",
      "Epoch 00018: val_loss improved from 0.36947 to 0.35539, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/018-0.3554.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3164 - acc: 0.9051 - val_loss: 0.3554 - val_acc: 0.8949\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3078 - acc: 0.9088\n",
      "Epoch 00019: val_loss improved from 0.35539 to 0.34747, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/019-0.3475.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.3079 - acc: 0.9088 - val_loss: 0.3475 - val_acc: 0.8996\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2953 - acc: 0.9118\n",
      "Epoch 00020: val_loss improved from 0.34747 to 0.31583, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/020-0.3158.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2953 - acc: 0.9119 - val_loss: 0.3158 - val_acc: 0.9106\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2807 - acc: 0.9162\n",
      "Epoch 00021: val_loss improved from 0.31583 to 0.30654, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/021-0.3065.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2807 - acc: 0.9162 - val_loss: 0.3065 - val_acc: 0.9152\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2762 - acc: 0.9176\n",
      "Epoch 00022: val_loss improved from 0.30654 to 0.29356, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/022-0.2936.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2763 - acc: 0.9176 - val_loss: 0.2936 - val_acc: 0.9150\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2594 - acc: 0.9223\n",
      "Epoch 00023: val_loss did not improve from 0.29356\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2595 - acc: 0.9223 - val_loss: 0.3244 - val_acc: 0.9117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2517 - acc: 0.9254\n",
      "Epoch 00024: val_loss did not improve from 0.29356\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2517 - acc: 0.9254 - val_loss: 0.3138 - val_acc: 0.9157\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2432 - acc: 0.9262\n",
      "Epoch 00025: val_loss did not improve from 0.29356\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2432 - acc: 0.9262 - val_loss: 0.3198 - val_acc: 0.9119\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2355 - acc: 0.9289\n",
      "Epoch 00026: val_loss did not improve from 0.29356\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2358 - acc: 0.9288 - val_loss: 0.3316 - val_acc: 0.9005\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2300 - acc: 0.9286\n",
      "Epoch 00027: val_loss improved from 0.29356 to 0.28872, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/027-0.2887.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2300 - acc: 0.9287 - val_loss: 0.2887 - val_acc: 0.9187\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2199 - acc: 0.9332\n",
      "Epoch 00028: val_loss improved from 0.28872 to 0.27665, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/028-0.2767.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2198 - acc: 0.9332 - val_loss: 0.2767 - val_acc: 0.9185\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2114 - acc: 0.9353\n",
      "Epoch 00029: val_loss improved from 0.27665 to 0.26634, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/029-0.2663.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2114 - acc: 0.9353 - val_loss: 0.2663 - val_acc: 0.9238\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2062 - acc: 0.9366\n",
      "Epoch 00030: val_loss did not improve from 0.26634\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2062 - acc: 0.9366 - val_loss: 0.2820 - val_acc: 0.9215\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2010 - acc: 0.9373\n",
      "Epoch 00031: val_loss did not improve from 0.26634\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2011 - acc: 0.9372 - val_loss: 0.2962 - val_acc: 0.9210\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9390\n",
      "Epoch 00032: val_loss did not improve from 0.26634\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1982 - acc: 0.9389 - val_loss: 0.3057 - val_acc: 0.9157\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1898 - acc: 0.9425\n",
      "Epoch 00033: val_loss improved from 0.26634 to 0.26359, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/033-0.2636.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1897 - acc: 0.9425 - val_loss: 0.2636 - val_acc: 0.9250\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1813 - acc: 0.9442\n",
      "Epoch 00034: val_loss improved from 0.26359 to 0.24283, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/034-0.2428.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1813 - acc: 0.9441 - val_loss: 0.2428 - val_acc: 0.9327\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1760 - acc: 0.9458\n",
      "Epoch 00035: val_loss did not improve from 0.24283\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1760 - acc: 0.9458 - val_loss: 0.2719 - val_acc: 0.9227\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9451\n",
      "Epoch 00036: val_loss did not improve from 0.24283\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1768 - acc: 0.9451 - val_loss: 0.2717 - val_acc: 0.9264\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1706 - acc: 0.9472\n",
      "Epoch 00037: val_loss did not improve from 0.24283\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1707 - acc: 0.9472 - val_loss: 0.2923 - val_acc: 0.9210\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1657 - acc: 0.9493\n",
      "Epoch 00038: val_loss did not improve from 0.24283\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1657 - acc: 0.9493 - val_loss: 0.2579 - val_acc: 0.9280\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9479\n",
      "Epoch 00039: val_loss did not improve from 0.24283\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1654 - acc: 0.9479 - val_loss: 0.2498 - val_acc: 0.9308\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9492\n",
      "Epoch 00040: val_loss did not improve from 0.24283\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1597 - acc: 0.9492 - val_loss: 0.2468 - val_acc: 0.9331\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1542 - acc: 0.9529\n",
      "Epoch 00041: val_loss did not improve from 0.24283\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1544 - acc: 0.9529 - val_loss: 0.2566 - val_acc: 0.9304\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9533\n",
      "Epoch 00042: val_loss did not improve from 0.24283\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1500 - acc: 0.9533 - val_loss: 0.2466 - val_acc: 0.9336\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9543\n",
      "Epoch 00043: val_loss did not improve from 0.24283\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1473 - acc: 0.9543 - val_loss: 0.2598 - val_acc: 0.9255\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9560\n",
      "Epoch 00044: val_loss did not improve from 0.24283\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1409 - acc: 0.9560 - val_loss: 0.3006 - val_acc: 0.9203\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9572\n",
      "Epoch 00045: val_loss did not improve from 0.24283\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1386 - acc: 0.9572 - val_loss: 0.2778 - val_acc: 0.9241\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9602\n",
      "Epoch 00046: val_loss did not improve from 0.24283\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1317 - acc: 0.9602 - val_loss: 0.2668 - val_acc: 0.9283\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9572\n",
      "Epoch 00047: val_loss did not improve from 0.24283\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1368 - acc: 0.9572 - val_loss: 0.2590 - val_acc: 0.9278\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9600\n",
      "Epoch 00048: val_loss improved from 0.24283 to 0.24163, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/048-0.2416.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1294 - acc: 0.9600 - val_loss: 0.2416 - val_acc: 0.9392\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9600\n",
      "Epoch 00049: val_loss did not improve from 0.24163\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1264 - acc: 0.9600 - val_loss: 0.2644 - val_acc: 0.9276\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9599\n",
      "Epoch 00050: val_loss did not improve from 0.24163\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1264 - acc: 0.9598 - val_loss: 0.2570 - val_acc: 0.9336\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9612\n",
      "Epoch 00051: val_loss did not improve from 0.24163\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1232 - acc: 0.9612 - val_loss: 0.2552 - val_acc: 0.9343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9632\n",
      "Epoch 00052: val_loss did not improve from 0.24163\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1178 - acc: 0.9632 - val_loss: 0.2749 - val_acc: 0.9262\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9643\n",
      "Epoch 00053: val_loss did not improve from 0.24163\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1135 - acc: 0.9643 - val_loss: 0.2644 - val_acc: 0.9290\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9661\n",
      "Epoch 00054: val_loss improved from 0.24163 to 0.23680, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/054-0.2368.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1110 - acc: 0.9661 - val_loss: 0.2368 - val_acc: 0.9369\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9658\n",
      "Epoch 00055: val_loss did not improve from 0.23680\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1106 - acc: 0.9657 - val_loss: 0.2500 - val_acc: 0.9311\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9668\n",
      "Epoch 00056: val_loss did not improve from 0.23680\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1056 - acc: 0.9668 - val_loss: 0.2790 - val_acc: 0.9220\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9674\n",
      "Epoch 00057: val_loss did not improve from 0.23680\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1045 - acc: 0.9675 - val_loss: 0.3292 - val_acc: 0.9138\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9688\n",
      "Epoch 00058: val_loss improved from 0.23680 to 0.22804, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv_checkpoint/058-0.2280.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1000 - acc: 0.9688 - val_loss: 0.2280 - val_acc: 0.9399\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9673\n",
      "Epoch 00059: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1029 - acc: 0.9673 - val_loss: 0.2651 - val_acc: 0.9304\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9697\n",
      "Epoch 00060: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0967 - acc: 0.9697 - val_loss: 0.2799 - val_acc: 0.9271\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9696\n",
      "Epoch 00061: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0967 - acc: 0.9696 - val_loss: 0.3337 - val_acc: 0.9126\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9704\n",
      "Epoch 00062: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0967 - acc: 0.9704 - val_loss: 0.2328 - val_acc: 0.9373\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9723\n",
      "Epoch 00063: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0917 - acc: 0.9723 - val_loss: 0.2574 - val_acc: 0.9317\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9713\n",
      "Epoch 00064: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0916 - acc: 0.9713 - val_loss: 0.2683 - val_acc: 0.9334\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9721\n",
      "Epoch 00065: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0921 - acc: 0.9721 - val_loss: 0.2823 - val_acc: 0.9290\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9717\n",
      "Epoch 00066: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0926 - acc: 0.9717 - val_loss: 0.2462 - val_acc: 0.9362\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9751\n",
      "Epoch 00067: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0825 - acc: 0.9751 - val_loss: 0.2467 - val_acc: 0.9380\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9729\n",
      "Epoch 00068: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0861 - acc: 0.9729 - val_loss: 0.2410 - val_acc: 0.9383\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9761\n",
      "Epoch 00069: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0802 - acc: 0.9761 - val_loss: 0.2966 - val_acc: 0.9245\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9733\n",
      "Epoch 00070: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0842 - acc: 0.9732 - val_loss: 0.2542 - val_acc: 0.9329\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9749\n",
      "Epoch 00071: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0828 - acc: 0.9749 - val_loss: 0.2474 - val_acc: 0.9357\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9756\n",
      "Epoch 00072: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0800 - acc: 0.9756 - val_loss: 0.2618 - val_acc: 0.9315\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9776\n",
      "Epoch 00073: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0738 - acc: 0.9776 - val_loss: 0.2688 - val_acc: 0.9359\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9769\n",
      "Epoch 00074: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0742 - acc: 0.9769 - val_loss: 0.2742 - val_acc: 0.9294\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9769\n",
      "Epoch 00075: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0751 - acc: 0.9769 - val_loss: 0.2417 - val_acc: 0.9366\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9767\n",
      "Epoch 00076: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0758 - acc: 0.9766 - val_loss: 0.3019 - val_acc: 0.9236\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9756\n",
      "Epoch 00077: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0775 - acc: 0.9756 - val_loss: 0.2766 - val_acc: 0.9359\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9787\n",
      "Epoch 00078: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0689 - acc: 0.9787 - val_loss: 0.2826 - val_acc: 0.9338\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9778\n",
      "Epoch 00079: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0692 - acc: 0.9778 - val_loss: 0.2719 - val_acc: 0.9313\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9801\n",
      "Epoch 00080: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0657 - acc: 0.9801 - val_loss: 0.2684 - val_acc: 0.9385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9796\n",
      "Epoch 00081: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0671 - acc: 0.9796 - val_loss: 0.2664 - val_acc: 0.9345\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9808\n",
      "Epoch 00082: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0636 - acc: 0.9808 - val_loss: 0.2500 - val_acc: 0.9369\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9802\n",
      "Epoch 00083: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0660 - acc: 0.9802 - val_loss: 0.2808 - val_acc: 0.9376\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9813\n",
      "Epoch 00084: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0629 - acc: 0.9813 - val_loss: 0.2924 - val_acc: 0.9231\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9812\n",
      "Epoch 00085: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0626 - acc: 0.9812 - val_loss: 0.2552 - val_acc: 0.9411\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9809\n",
      "Epoch 00086: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0620 - acc: 0.9809 - val_loss: 0.2766 - val_acc: 0.9327\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9811\n",
      "Epoch 00087: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0612 - acc: 0.9811 - val_loss: 0.2462 - val_acc: 0.9413\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9817\n",
      "Epoch 00088: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0610 - acc: 0.9817 - val_loss: 0.2903 - val_acc: 0.9259\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9817\n",
      "Epoch 00089: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0583 - acc: 0.9817 - val_loss: 0.2515 - val_acc: 0.9401\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9826\n",
      "Epoch 00090: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0557 - acc: 0.9826 - val_loss: 0.2851 - val_acc: 0.9357\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9824\n",
      "Epoch 00091: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0579 - acc: 0.9824 - val_loss: 0.2902 - val_acc: 0.9311\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9835\n",
      "Epoch 00092: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0549 - acc: 0.9835 - val_loss: 0.2622 - val_acc: 0.9399\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9810\n",
      "Epoch 00093: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0618 - acc: 0.9810 - val_loss: 0.2601 - val_acc: 0.9355\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9833\n",
      "Epoch 00094: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0548 - acc: 0.9833 - val_loss: 0.2805 - val_acc: 0.9336\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9846\n",
      "Epoch 00095: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0496 - acc: 0.9846 - val_loss: 0.2799 - val_acc: 0.9317\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9835\n",
      "Epoch 00096: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0530 - acc: 0.9835 - val_loss: 0.3018 - val_acc: 0.9301\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9842\n",
      "Epoch 00097: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0532 - acc: 0.9842 - val_loss: 0.3036 - val_acc: 0.9271\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9837\n",
      "Epoch 00098: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0559 - acc: 0.9837 - val_loss: 0.2685 - val_acc: 0.9352\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9837\n",
      "Epoch 00099: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0526 - acc: 0.9837 - val_loss: 0.2899 - val_acc: 0.9338\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9846\n",
      "Epoch 00100: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0508 - acc: 0.9846 - val_loss: 0.2750 - val_acc: 0.9341\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9839\n",
      "Epoch 00101: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0524 - acc: 0.9839 - val_loss: 0.2776 - val_acc: 0.9322\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9869\n",
      "Epoch 00102: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0436 - acc: 0.9869 - val_loss: 0.2923 - val_acc: 0.9357\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9842\n",
      "Epoch 00103: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0507 - acc: 0.9842 - val_loss: 0.2661 - val_acc: 0.9380\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9838\n",
      "Epoch 00104: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0516 - acc: 0.9838 - val_loss: 0.2895 - val_acc: 0.9359\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9861\n",
      "Epoch 00105: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0463 - acc: 0.9861 - val_loss: 0.3149 - val_acc: 0.9313\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9843\n",
      "Epoch 00106: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0500 - acc: 0.9843 - val_loss: 0.2789 - val_acc: 0.9394\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9852\n",
      "Epoch 00107: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0487 - acc: 0.9852 - val_loss: 0.2766 - val_acc: 0.9357\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9872\n",
      "Epoch 00108: val_loss did not improve from 0.22804\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0430 - acc: 0.9872 - val_loss: 0.2723 - val_acc: 0.9387\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 592us/sample - loss: 0.2878 - acc: 0.9215\n",
      "Loss: 0.2878187735782605 Accuracy: 0.9214953\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3171 - acc: 0.2796\n",
      "Epoch 00001: val_loss improved from inf to 1.81445, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/001-1.8145.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 2.3171 - acc: 0.2796 - val_loss: 1.8145 - val_acc: 0.4482\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4596 - acc: 0.5391\n",
      "Epoch 00002: val_loss improved from 1.81445 to 1.05789, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/002-1.0579.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 1.4596 - acc: 0.5391 - val_loss: 1.0579 - val_acc: 0.6895\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0801 - acc: 0.6647\n",
      "Epoch 00003: val_loss improved from 1.05789 to 0.75688, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/003-0.7569.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 1.0801 - acc: 0.6647 - val_loss: 0.7569 - val_acc: 0.7911\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8405 - acc: 0.7456\n",
      "Epoch 00004: val_loss improved from 0.75688 to 0.58570, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/004-0.5857.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.8404 - acc: 0.7456 - val_loss: 0.5857 - val_acc: 0.8418\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6892 - acc: 0.7924\n",
      "Epoch 00005: val_loss improved from 0.58570 to 0.50967, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/005-0.5097.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.6893 - acc: 0.7923 - val_loss: 0.5097 - val_acc: 0.8558\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5786 - acc: 0.8267\n",
      "Epoch 00006: val_loss improved from 0.50967 to 0.42091, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/006-0.4209.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.5785 - acc: 0.8267 - val_loss: 0.4209 - val_acc: 0.8807\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4999 - acc: 0.8511\n",
      "Epoch 00007: val_loss improved from 0.42091 to 0.38093, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/007-0.3809.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4999 - acc: 0.8511 - val_loss: 0.3809 - val_acc: 0.8882\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4418 - acc: 0.8687\n",
      "Epoch 00008: val_loss improved from 0.38093 to 0.35555, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/008-0.3555.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4421 - acc: 0.8686 - val_loss: 0.3555 - val_acc: 0.8959\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3986 - acc: 0.8816\n",
      "Epoch 00009: val_loss improved from 0.35555 to 0.29925, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/009-0.2993.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3986 - acc: 0.8816 - val_loss: 0.2993 - val_acc: 0.9192\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3588 - acc: 0.8925\n",
      "Epoch 00010: val_loss improved from 0.29925 to 0.28949, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/010-0.2895.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3588 - acc: 0.8925 - val_loss: 0.2895 - val_acc: 0.9182\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3301 - acc: 0.9017\n",
      "Epoch 00011: val_loss improved from 0.28949 to 0.27198, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/011-0.2720.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3301 - acc: 0.9017 - val_loss: 0.2720 - val_acc: 0.9243\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3068 - acc: 0.9093\n",
      "Epoch 00012: val_loss improved from 0.27198 to 0.26780, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/012-0.2678.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3068 - acc: 0.9093 - val_loss: 0.2678 - val_acc: 0.9238\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2846 - acc: 0.9150\n",
      "Epoch 00013: val_loss improved from 0.26780 to 0.26137, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/013-0.2614.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2846 - acc: 0.9150 - val_loss: 0.2614 - val_acc: 0.9243\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2657 - acc: 0.9196\n",
      "Epoch 00014: val_loss improved from 0.26137 to 0.23999, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/014-0.2400.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2659 - acc: 0.9195 - val_loss: 0.2400 - val_acc: 0.9306\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2542 - acc: 0.9218\n",
      "Epoch 00015: val_loss did not improve from 0.23999\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2542 - acc: 0.9217 - val_loss: 0.2499 - val_acc: 0.9287\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2350 - acc: 0.9288\n",
      "Epoch 00016: val_loss improved from 0.23999 to 0.22577, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/016-0.2258.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2350 - acc: 0.9288 - val_loss: 0.2258 - val_acc: 0.9343\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2242 - acc: 0.9328\n",
      "Epoch 00017: val_loss did not improve from 0.22577\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2242 - acc: 0.9328 - val_loss: 0.2320 - val_acc: 0.9313\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2095 - acc: 0.9369\n",
      "Epoch 00018: val_loss improved from 0.22577 to 0.20574, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/018-0.2057.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2095 - acc: 0.9369 - val_loss: 0.2057 - val_acc: 0.9420\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1999 - acc: 0.9391\n",
      "Epoch 00019: val_loss did not improve from 0.20574\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1999 - acc: 0.9391 - val_loss: 0.2325 - val_acc: 0.9341\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1932 - acc: 0.9401\n",
      "Epoch 00020: val_loss improved from 0.20574 to 0.19186, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/020-0.1919.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1932 - acc: 0.9401 - val_loss: 0.1919 - val_acc: 0.9448\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1808 - acc: 0.9451\n",
      "Epoch 00021: val_loss did not improve from 0.19186\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1808 - acc: 0.9451 - val_loss: 0.2005 - val_acc: 0.9441\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1779 - acc: 0.9462\n",
      "Epoch 00022: val_loss improved from 0.19186 to 0.18113, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/022-0.1811.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1779 - acc: 0.9462 - val_loss: 0.1811 - val_acc: 0.9464\n",
      "Epoch 23/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9483\n",
      "Epoch 00023: val_loss did not improve from 0.18113\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1689 - acc: 0.9483 - val_loss: 0.1931 - val_acc: 0.9469\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1590 - acc: 0.9518\n",
      "Epoch 00024: val_loss did not improve from 0.18113\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1590 - acc: 0.9518 - val_loss: 0.1857 - val_acc: 0.9469\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9521\n",
      "Epoch 00025: val_loss did not improve from 0.18113\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1559 - acc: 0.9521 - val_loss: 0.2000 - val_acc: 0.9439\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9532\n",
      "Epoch 00026: val_loss improved from 0.18113 to 0.17953, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/026-0.1795.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1520 - acc: 0.9532 - val_loss: 0.1795 - val_acc: 0.9502\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1395 - acc: 0.9568\n",
      "Epoch 00027: val_loss did not improve from 0.17953\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1395 - acc: 0.9568 - val_loss: 0.1812 - val_acc: 0.9483\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1404 - acc: 0.9564\n",
      "Epoch 00028: val_loss did not improve from 0.17953\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1405 - acc: 0.9564 - val_loss: 0.1801 - val_acc: 0.9476\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9598\n",
      "Epoch 00029: val_loss did not improve from 0.17953\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1306 - acc: 0.9598 - val_loss: 0.1924 - val_acc: 0.9432\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9604\n",
      "Epoch 00030: val_loss did not improve from 0.17953\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1288 - acc: 0.9604 - val_loss: 0.2250 - val_acc: 0.9338\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9613\n",
      "Epoch 00031: val_loss improved from 0.17953 to 0.17947, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/031-0.1795.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1245 - acc: 0.9613 - val_loss: 0.1795 - val_acc: 0.9485\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9641\n",
      "Epoch 00032: val_loss improved from 0.17947 to 0.17444, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/032-0.1744.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1173 - acc: 0.9641 - val_loss: 0.1744 - val_acc: 0.9506\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9644\n",
      "Epoch 00033: val_loss did not improve from 0.17444\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1148 - acc: 0.9644 - val_loss: 0.1942 - val_acc: 0.9478\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9657\n",
      "Epoch 00034: val_loss did not improve from 0.17444\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1087 - acc: 0.9656 - val_loss: 0.1753 - val_acc: 0.9506\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9658\n",
      "Epoch 00035: val_loss did not improve from 0.17444\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1099 - acc: 0.9658 - val_loss: 0.1778 - val_acc: 0.9502\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9668\n",
      "Epoch 00036: val_loss did not improve from 0.17444\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1060 - acc: 0.9668 - val_loss: 0.1776 - val_acc: 0.9488\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9701\n",
      "Epoch 00037: val_loss did not improve from 0.17444\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0981 - acc: 0.9701 - val_loss: 0.1833 - val_acc: 0.9490\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9704\n",
      "Epoch 00038: val_loss did not improve from 0.17444\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0958 - acc: 0.9704 - val_loss: 0.1763 - val_acc: 0.9522\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9722\n",
      "Epoch 00039: val_loss did not improve from 0.17444\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0917 - acc: 0.9722 - val_loss: 0.1916 - val_acc: 0.9446\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9719\n",
      "Epoch 00040: val_loss did not improve from 0.17444\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0890 - acc: 0.9719 - val_loss: 0.1766 - val_acc: 0.9522\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9715\n",
      "Epoch 00041: val_loss did not improve from 0.17444\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0905 - acc: 0.9716 - val_loss: 0.1969 - val_acc: 0.9420\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9745\n",
      "Epoch 00042: val_loss did not improve from 0.17444\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0826 - acc: 0.9744 - val_loss: 0.1790 - val_acc: 0.9509\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9714\n",
      "Epoch 00043: val_loss improved from 0.17444 to 0.16981, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv_checkpoint/043-0.1698.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0891 - acc: 0.9714 - val_loss: 0.1698 - val_acc: 0.9518\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9763\n",
      "Epoch 00044: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0777 - acc: 0.9763 - val_loss: 0.1918 - val_acc: 0.9481\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9762\n",
      "Epoch 00045: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0771 - acc: 0.9763 - val_loss: 0.2459 - val_acc: 0.9425\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9782\n",
      "Epoch 00046: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0717 - acc: 0.9782 - val_loss: 0.1892 - val_acc: 0.9464\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9770\n",
      "Epoch 00047: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0735 - acc: 0.9769 - val_loss: 0.1985 - val_acc: 0.9439\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9803\n",
      "Epoch 00048: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0666 - acc: 0.9803 - val_loss: 0.1814 - val_acc: 0.9515\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9785\n",
      "Epoch 00049: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0685 - acc: 0.9785 - val_loss: 0.1902 - val_acc: 0.9536\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9797\n",
      "Epoch 00050: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0666 - acc: 0.9797 - val_loss: 0.1798 - val_acc: 0.9541\n",
      "Epoch 51/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9806\n",
      "Epoch 00051: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0634 - acc: 0.9806 - val_loss: 0.1901 - val_acc: 0.9483\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9814\n",
      "Epoch 00052: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0610 - acc: 0.9814 - val_loss: 0.1853 - val_acc: 0.9529\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9801\n",
      "Epoch 00053: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0657 - acc: 0.9801 - val_loss: 0.1895 - val_acc: 0.9490\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9828\n",
      "Epoch 00054: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0555 - acc: 0.9828 - val_loss: 0.1717 - val_acc: 0.9564\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9817\n",
      "Epoch 00055: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0587 - acc: 0.9817 - val_loss: 0.1976 - val_acc: 0.9481\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9820\n",
      "Epoch 00056: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0601 - acc: 0.9820 - val_loss: 0.1852 - val_acc: 0.9525\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9845\n",
      "Epoch 00057: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0507 - acc: 0.9845 - val_loss: 0.1872 - val_acc: 0.9492\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9844\n",
      "Epoch 00058: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0520 - acc: 0.9844 - val_loss: 0.1887 - val_acc: 0.9513\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9829\n",
      "Epoch 00059: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0569 - acc: 0.9828 - val_loss: 0.1832 - val_acc: 0.9532\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9832\n",
      "Epoch 00060: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0542 - acc: 0.9832 - val_loss: 0.1777 - val_acc: 0.9527\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9871\n",
      "Epoch 00061: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0449 - acc: 0.9871 - val_loss: 0.1934 - val_acc: 0.9506\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9841\n",
      "Epoch 00062: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0507 - acc: 0.9841 - val_loss: 0.1912 - val_acc: 0.9506\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9853\n",
      "Epoch 00063: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0478 - acc: 0.9853 - val_loss: 0.1820 - val_acc: 0.9518\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9858\n",
      "Epoch 00064: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0472 - acc: 0.9858 - val_loss: 0.1976 - val_acc: 0.9502\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9880\n",
      "Epoch 00065: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0420 - acc: 0.9879 - val_loss: 0.1998 - val_acc: 0.9511\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9850\n",
      "Epoch 00066: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0501 - acc: 0.9850 - val_loss: 0.2244 - val_acc: 0.9469\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9877\n",
      "Epoch 00067: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0408 - acc: 0.9877 - val_loss: 0.1960 - val_acc: 0.9518\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9856\n",
      "Epoch 00068: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0461 - acc: 0.9856 - val_loss: 0.1765 - val_acc: 0.9569\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9878\n",
      "Epoch 00069: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0405 - acc: 0.9878 - val_loss: 0.1934 - val_acc: 0.9534\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9892\n",
      "Epoch 00070: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0375 - acc: 0.9892 - val_loss: 0.2030 - val_acc: 0.9504\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9879\n",
      "Epoch 00071: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0410 - acc: 0.9879 - val_loss: 0.1851 - val_acc: 0.9536\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9867\n",
      "Epoch 00072: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0435 - acc: 0.9867 - val_loss: 0.2231 - val_acc: 0.9441\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9905\n",
      "Epoch 00073: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0340 - acc: 0.9905 - val_loss: 0.1876 - val_acc: 0.9550\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9906\n",
      "Epoch 00074: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0338 - acc: 0.9906 - val_loss: 0.1977 - val_acc: 0.9520\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9893\n",
      "Epoch 00075: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0343 - acc: 0.9893 - val_loss: 0.2045 - val_acc: 0.9527\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9893\n",
      "Epoch 00076: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0350 - acc: 0.9893 - val_loss: 0.2008 - val_acc: 0.9527\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9892\n",
      "Epoch 00077: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0355 - acc: 0.9891 - val_loss: 0.2083 - val_acc: 0.9520\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9869\n",
      "Epoch 00078: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0416 - acc: 0.9869 - val_loss: 0.2002 - val_acc: 0.9529\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9881\n",
      "Epoch 00079: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0385 - acc: 0.9881 - val_loss: 0.1895 - val_acc: 0.9539\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9912\n",
      "Epoch 00080: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0303 - acc: 0.9912 - val_loss: 0.2151 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9907\n",
      "Epoch 00081: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0319 - acc: 0.9907 - val_loss: 0.2100 - val_acc: 0.9490\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9895\n",
      "Epoch 00082: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0340 - acc: 0.9895 - val_loss: 0.2174 - val_acc: 0.9490\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9892\n",
      "Epoch 00083: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0343 - acc: 0.9892 - val_loss: 0.1913 - val_acc: 0.9532\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9920\n",
      "Epoch 00084: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0283 - acc: 0.9919 - val_loss: 0.2035 - val_acc: 0.9506\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9870\n",
      "Epoch 00085: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0432 - acc: 0.9870 - val_loss: 0.2096 - val_acc: 0.9532\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9926\n",
      "Epoch 00086: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0276 - acc: 0.9926 - val_loss: 0.1888 - val_acc: 0.9560\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9926\n",
      "Epoch 00087: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0273 - acc: 0.9926 - val_loss: 0.2303 - val_acc: 0.9488\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9915\n",
      "Epoch 00088: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0281 - acc: 0.9915 - val_loss: 0.2105 - val_acc: 0.9520\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9898\n",
      "Epoch 00089: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0325 - acc: 0.9898 - val_loss: 0.1988 - val_acc: 0.9560\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9912\n",
      "Epoch 00090: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0303 - acc: 0.9912 - val_loss: 0.2399 - val_acc: 0.9485\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9926\n",
      "Epoch 00091: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0254 - acc: 0.9926 - val_loss: 0.2186 - val_acc: 0.9448\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9927\n",
      "Epoch 00092: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0250 - acc: 0.9927 - val_loss: 0.2079 - val_acc: 0.9532\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9872\n",
      "Epoch 00093: val_loss did not improve from 0.16981\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0394 - acc: 0.9872 - val_loss: 0.2022 - val_acc: 0.9532\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 617us/sample - loss: 0.2140 - acc: 0.9369\n",
      "Loss: 0.21403507006007438 Accuracy: 0.93686396\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9196 - acc: 0.4088\n",
      "Epoch 00001: val_loss improved from inf to 1.21338, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/001-1.2134.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 1.9195 - acc: 0.4089 - val_loss: 1.2134 - val_acc: 0.6499\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9192 - acc: 0.7101\n",
      "Epoch 00002: val_loss improved from 1.21338 to 0.57270, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/002-0.5727.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.9191 - acc: 0.7101 - val_loss: 0.5727 - val_acc: 0.8330\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6318 - acc: 0.8055\n",
      "Epoch 00003: val_loss improved from 0.57270 to 0.40049, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/003-0.4005.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.6317 - acc: 0.8055 - val_loss: 0.4005 - val_acc: 0.8800\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4882 - acc: 0.8521\n",
      "Epoch 00004: val_loss improved from 0.40049 to 0.33663, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/004-0.3366.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.4882 - acc: 0.8521 - val_loss: 0.3366 - val_acc: 0.9043\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4029 - acc: 0.8773\n",
      "Epoch 00005: val_loss improved from 0.33663 to 0.28878, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/005-0.2888.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.4029 - acc: 0.8773 - val_loss: 0.2888 - val_acc: 0.9161\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3474 - acc: 0.8943\n",
      "Epoch 00006: val_loss improved from 0.28878 to 0.25511, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/006-0.2551.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.3474 - acc: 0.8943 - val_loss: 0.2551 - val_acc: 0.9241\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3088 - acc: 0.9053\n",
      "Epoch 00007: val_loss improved from 0.25511 to 0.24271, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/007-0.2427.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.3088 - acc: 0.9053 - val_loss: 0.2427 - val_acc: 0.9269\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2760 - acc: 0.9153\n",
      "Epoch 00008: val_loss improved from 0.24271 to 0.22623, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/008-0.2262.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2760 - acc: 0.9153 - val_loss: 0.2262 - val_acc: 0.9327\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2501 - acc: 0.9231\n",
      "Epoch 00009: val_loss did not improve from 0.22623\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2502 - acc: 0.9231 - val_loss: 0.2268 - val_acc: 0.9352\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2259 - acc: 0.9302\n",
      "Epoch 00010: val_loss improved from 0.22623 to 0.20780, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/010-0.2078.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2260 - acc: 0.9302 - val_loss: 0.2078 - val_acc: 0.9357\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2059 - acc: 0.9377\n",
      "Epoch 00011: val_loss improved from 0.20780 to 0.19576, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/011-0.1958.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2059 - acc: 0.9377 - val_loss: 0.1958 - val_acc: 0.9427\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1902 - acc: 0.9434\n",
      "Epoch 00012: val_loss improved from 0.19576 to 0.19191, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/012-0.1919.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1902 - acc: 0.9434 - val_loss: 0.1919 - val_acc: 0.9429\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9452\n",
      "Epoch 00013: val_loss did not improve from 0.19191\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1768 - acc: 0.9452 - val_loss: 0.2021 - val_acc: 0.9385\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9481\n",
      "Epoch 00014: val_loss improved from 0.19191 to 0.17811, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/014-0.1781.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1664 - acc: 0.9481 - val_loss: 0.1781 - val_acc: 0.9476\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1495 - acc: 0.9547\n",
      "Epoch 00015: val_loss did not improve from 0.17811\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1495 - acc: 0.9547 - val_loss: 0.1861 - val_acc: 0.9439\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9570\n",
      "Epoch 00016: val_loss improved from 0.17811 to 0.17152, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/016-0.1715.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1417 - acc: 0.9570 - val_loss: 0.1715 - val_acc: 0.9499\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9594\n",
      "Epoch 00017: val_loss did not improve from 0.17152\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1336 - acc: 0.9594 - val_loss: 0.1976 - val_acc: 0.9415\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1270 - acc: 0.9603\n",
      "Epoch 00018: val_loss did not improve from 0.17152\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1270 - acc: 0.9603 - val_loss: 0.1745 - val_acc: 0.9483\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9640\n",
      "Epoch 00019: val_loss did not improve from 0.17152\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1147 - acc: 0.9640 - val_loss: 0.1901 - val_acc: 0.9441\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9647\n",
      "Epoch 00020: val_loss did not improve from 0.17152\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1127 - acc: 0.9647 - val_loss: 0.1814 - val_acc: 0.9453\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9667\n",
      "Epoch 00021: val_loss improved from 0.17152 to 0.15205, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/021-0.1520.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1070 - acc: 0.9667 - val_loss: 0.1520 - val_acc: 0.9536\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9703\n",
      "Epoch 00022: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0973 - acc: 0.9703 - val_loss: 0.1922 - val_acc: 0.9422\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9724\n",
      "Epoch 00023: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0900 - acc: 0.9723 - val_loss: 0.1870 - val_acc: 0.9450\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9725\n",
      "Epoch 00024: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0890 - acc: 0.9725 - val_loss: 0.1889 - val_acc: 0.9450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9752\n",
      "Epoch 00025: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0813 - acc: 0.9752 - val_loss: 0.1727 - val_acc: 0.9504\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9756\n",
      "Epoch 00026: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0788 - acc: 0.9756 - val_loss: 0.1712 - val_acc: 0.9499\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9790\n",
      "Epoch 00027: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0712 - acc: 0.9791 - val_loss: 0.1607 - val_acc: 0.9541\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9786\n",
      "Epoch 00028: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0713 - acc: 0.9786 - val_loss: 0.2377 - val_acc: 0.9348\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9800\n",
      "Epoch 00029: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0660 - acc: 0.9799 - val_loss: 0.1534 - val_acc: 0.9539\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9803\n",
      "Epoch 00030: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0649 - acc: 0.9802 - val_loss: 0.1588 - val_acc: 0.9536\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9793\n",
      "Epoch 00031: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0687 - acc: 0.9793 - val_loss: 0.1780 - val_acc: 0.9492\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9848\n",
      "Epoch 00032: val_loss did not improve from 0.15205\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0532 - acc: 0.9848 - val_loss: 0.1576 - val_acc: 0.9534\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9858\n",
      "Epoch 00033: val_loss improved from 0.15205 to 0.14876, saving model to model/checkpoint/1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv_checkpoint/033-0.1488.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0502 - acc: 0.9858 - val_loss: 0.1488 - val_acc: 0.9567\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9849\n",
      "Epoch 00034: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0520 - acc: 0.9849 - val_loss: 0.1876 - val_acc: 0.9471\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9852\n",
      "Epoch 00035: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0497 - acc: 0.9852 - val_loss: 0.1822 - val_acc: 0.9515\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9873\n",
      "Epoch 00036: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0458 - acc: 0.9873 - val_loss: 0.1653 - val_acc: 0.9553\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9885\n",
      "Epoch 00037: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0411 - acc: 0.9885 - val_loss: 0.1702 - val_acc: 0.9522\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9882\n",
      "Epoch 00038: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0414 - acc: 0.9882 - val_loss: 0.1729 - val_acc: 0.9502\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9888\n",
      "Epoch 00039: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0393 - acc: 0.9888 - val_loss: 0.1776 - val_acc: 0.9518\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9878\n",
      "Epoch 00040: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0416 - acc: 0.9878 - val_loss: 0.1794 - val_acc: 0.9525\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9880\n",
      "Epoch 00041: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0389 - acc: 0.9880 - val_loss: 0.1979 - val_acc: 0.9497\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9904\n",
      "Epoch 00042: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0342 - acc: 0.9904 - val_loss: 0.1584 - val_acc: 0.9564\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9898\n",
      "Epoch 00043: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0350 - acc: 0.9897 - val_loss: 0.1864 - val_acc: 0.9525\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9905\n",
      "Epoch 00044: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0343 - acc: 0.9905 - val_loss: 0.1817 - val_acc: 0.9541\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9914\n",
      "Epoch 00045: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0300 - acc: 0.9914 - val_loss: 0.1686 - val_acc: 0.9567\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9918\n",
      "Epoch 00046: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0290 - acc: 0.9918 - val_loss: 0.1974 - val_acc: 0.9474\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9917\n",
      "Epoch 00047: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0294 - acc: 0.9917 - val_loss: 0.2182 - val_acc: 0.9464\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9927\n",
      "Epoch 00048: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0267 - acc: 0.9927 - val_loss: 0.1788 - val_acc: 0.9578\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9923\n",
      "Epoch 00049: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0260 - acc: 0.9923 - val_loss: 0.1839 - val_acc: 0.9532\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9930\n",
      "Epoch 00050: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0247 - acc: 0.9930 - val_loss: 0.1850 - val_acc: 0.9555\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9913\n",
      "Epoch 00051: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0301 - acc: 0.9913 - val_loss: 0.1758 - val_acc: 0.9550\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9918\n",
      "Epoch 00052: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0270 - acc: 0.9918 - val_loss: 0.1807 - val_acc: 0.9536\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9938\n",
      "Epoch 00053: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0221 - acc: 0.9938 - val_loss: 0.1796 - val_acc: 0.9564\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9951\n",
      "Epoch 00054: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0196 - acc: 0.9951 - val_loss: 0.1986 - val_acc: 0.9476\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9938\n",
      "Epoch 00055: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0225 - acc: 0.9938 - val_loss: 0.1917 - val_acc: 0.9502\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9948\n",
      "Epoch 00056: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0200 - acc: 0.9948 - val_loss: 0.2389 - val_acc: 0.9443\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9914\n",
      "Epoch 00057: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0292 - acc: 0.9914 - val_loss: 0.1878 - val_acc: 0.9522\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9946\n",
      "Epoch 00058: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0190 - acc: 0.9946 - val_loss: 0.1717 - val_acc: 0.9571\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9951\n",
      "Epoch 00059: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0188 - acc: 0.9951 - val_loss: 0.2178 - val_acc: 0.9460\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9924\n",
      "Epoch 00060: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0255 - acc: 0.9924 - val_loss: 0.1896 - val_acc: 0.9492\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9922\n",
      "Epoch 00061: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0257 - acc: 0.9922 - val_loss: 0.1992 - val_acc: 0.9527\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9965\n",
      "Epoch 00062: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0148 - acc: 0.9964 - val_loss: 0.1780 - val_acc: 0.9569\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9928\n",
      "Epoch 00063: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0250 - acc: 0.9928 - val_loss: 0.1789 - val_acc: 0.9555\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9939\n",
      "Epoch 00064: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0211 - acc: 0.9939 - val_loss: 0.1735 - val_acc: 0.9602\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9959\n",
      "Epoch 00065: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0155 - acc: 0.9959 - val_loss: 0.1935 - val_acc: 0.9527\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9962\n",
      "Epoch 00066: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0156 - acc: 0.9962 - val_loss: 0.1735 - val_acc: 0.9564\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9960\n",
      "Epoch 00067: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0153 - acc: 0.9960 - val_loss: 0.2121 - val_acc: 0.9474\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9955\n",
      "Epoch 00068: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0166 - acc: 0.9954 - val_loss: 0.1781 - val_acc: 0.9541\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9909\n",
      "Epoch 00069: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0294 - acc: 0.9909 - val_loss: 0.1961 - val_acc: 0.9541\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9968\n",
      "Epoch 00070: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0123 - acc: 0.9968 - val_loss: 0.2078 - val_acc: 0.9536\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9939\n",
      "Epoch 00071: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0208 - acc: 0.9939 - val_loss: 0.1836 - val_acc: 0.9578\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9957\n",
      "Epoch 00072: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0154 - acc: 0.9957 - val_loss: 0.1852 - val_acc: 0.9581\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9958\n",
      "Epoch 00073: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0149 - acc: 0.9958 - val_loss: 0.1867 - val_acc: 0.9555\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9967\n",
      "Epoch 00074: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0126 - acc: 0.9966 - val_loss: 0.2123 - val_acc: 0.9522\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9932\n",
      "Epoch 00075: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0239 - acc: 0.9932 - val_loss: 0.1972 - val_acc: 0.9548\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9956\n",
      "Epoch 00076: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0155 - acc: 0.9956 - val_loss: 0.1721 - val_acc: 0.9578\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9973\n",
      "Epoch 00077: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0105 - acc: 0.9973 - val_loss: 0.2109 - val_acc: 0.9534\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9962\n",
      "Epoch 00078: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0139 - acc: 0.9963 - val_loss: 0.1899 - val_acc: 0.9555\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9950\n",
      "Epoch 00079: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0177 - acc: 0.9950 - val_loss: 0.2042 - val_acc: 0.9541\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9932\n",
      "Epoch 00080: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0235 - acc: 0.9931 - val_loss: 0.2026 - val_acc: 0.9569\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9945\n",
      "Epoch 00081: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0169 - acc: 0.9945 - val_loss: 0.1955 - val_acc: 0.9532\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9977\n",
      "Epoch 00082: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0096 - acc: 0.9976 - val_loss: 0.1841 - val_acc: 0.9578\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9942\n",
      "Epoch 00083: val_loss did not improve from 0.14876\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0176 - acc: 0.9942 - val_loss: 0.1891 - val_acc: 0.9562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 635us/sample - loss: 0.2189 - acc: 0.9385\n",
      "Loss: 0.21890912561262507 Accuracy: 0.93852544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    base = '1D_CNN_custom_ch_32_DO_025_DO_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_ch_32_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 56864)             0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 56864)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                909840    \n",
      "=================================================================\n",
      "Total params: 920,720\n",
      "Trainable params: 920,528\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 583us/sample - loss: 1.5887 - acc: 0.5277\n",
      "Loss: 1.5887069164654424 Accuracy: 0.5277259\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 18944)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 18944)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                303120    \n",
      "=================================================================\n",
      "Total params: 319,280\n",
      "Trainable params: 319,024\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 674us/sample - loss: 1.0736 - acc: 0.6712\n",
      "Loss: 1.0736183411607119 Accuracy: 0.67123574\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 12608)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 12608)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                201744    \n",
      "=================================================================\n",
      "Total params: 228,464\n",
      "Trainable params: 228,080\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 639us/sample - loss: 0.8717 - acc: 0.7458\n",
      "Loss: 0.8716720554935102 Accuracy: 0.7457944\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                66576     \n",
      "=================================================================\n",
      "Total params: 114,096\n",
      "Trainable params: 113,584\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 660us/sample - loss: 0.5385 - acc: 0.8536\n",
      "Loss: 0.5385464418838081 Accuracy: 0.85358256\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                21520     \n",
      "=================================================================\n",
      "Total params: 89,840\n",
      "Trainable params: 89,200\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 685us/sample - loss: 0.2878 - acc: 0.9215\n",
      "Loss: 0.2878187735782605 Accuracy: 0.9214953\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                7184      \n",
      "=================================================================\n",
      "Total params: 96,304\n",
      "Trainable params: 95,536\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 714us/sample - loss: 0.2140 - acc: 0.9369\n",
      "Loss: 0.21403507006007438 Accuracy: 0.93686396\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 128)            41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 7, 128)            512       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                4112      \n",
      "=================================================================\n",
      "Total params: 134,832\n",
      "Trainable params: 133,808\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 761us/sample - loss: 0.2189 - acc: 0.9385\n",
      "Loss: 0.21890912561262507 Accuracy: 0.93852544\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_ch_32_DO_025_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 56864)             0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 56864)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                909840    \n",
      "=================================================================\n",
      "Total params: 920,720\n",
      "Trainable params: 920,528\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 743us/sample - loss: 3.0797 - acc: 0.5167\n",
      "Loss: 3.0796620655654006 Accuracy: 0.51671857\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 18944)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 18944)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                303120    \n",
      "=================================================================\n",
      "Total params: 319,280\n",
      "Trainable params: 319,024\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 747us/sample - loss: 1.4400 - acc: 0.6885\n",
      "Loss: 1.4400061950752916 Accuracy: 0.6884735\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 12608)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 12608)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                201744    \n",
      "=================================================================\n",
      "Total params: 228,464\n",
      "Trainable params: 228,080\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 748us/sample - loss: 1.2662 - acc: 0.7045\n",
      "Loss: 1.2661703642283644 Accuracy: 0.7044652\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4160)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                66576     \n",
      "=================================================================\n",
      "Total params: 114,096\n",
      "Trainable params: 113,584\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 776us/sample - loss: 0.5811 - acc: 0.8627\n",
      "Loss: 0.5810959149124961 Accuracy: 0.86272067\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1344)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                21520     \n",
      "=================================================================\n",
      "Total params: 89,840\n",
      "Trainable params: 89,200\n",
      "Non-trainable params: 640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 798us/sample - loss: 0.3288 - acc: 0.9188\n",
      "Loss: 0.3288142160292974 Accuracy: 0.9187954\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 448)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                7184      \n",
      "=================================================================\n",
      "Total params: 96,304\n",
      "Trainable params: 95,536\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 828us/sample - loss: 0.2500 - acc: 0.9400\n",
      "Loss: 0.24999272338078896 Accuracy: 0.93997926\n",
      "\n",
      "1D_CNN_custom_ch_32_DO_025_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 5333, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 64)           10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 592, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 197, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 65, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 64)            20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 21, 64)            256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 64)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 7, 64)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 128)            41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 7, 128)            512       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                4112      \n",
      "=================================================================\n",
      "Total params: 134,832\n",
      "Trainable params: 133,808\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 862us/sample - loss: 0.2496 - acc: 0.9477\n",
      "Loss: 0.24962142276677263 Accuracy: 0.94766355\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
