{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_BN(conv_num=1):\n",
    "    init_channel = 64\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=init_channel, strides=1, \n",
    "                      padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=int(init_channel/(2**int((i+1)/3))), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,480,656\n",
      "Trainable params: 18,432,528\n",
      "Non-trainable params: 2,048,128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 6,847,696\n",
      "Trainable params: 6,164,816\n",
      "Non-trainable params: 682,880\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,316,816\n",
      "Trainable params: 2,088,976\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 18944)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 18944)             75776     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                303120    \n",
      "=================================================================\n",
      "Total params: 431,536\n",
      "Trainable params: 393,200\n",
      "Non-trainable params: 38,336\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 6304)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 6304)              25216     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                100880    \n",
      "=================================================================\n",
      "Total params: 184,016\n",
      "Trainable params: 170,896\n",
      "Non-trainable params: 13,120\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 197, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2080)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 2080)              8320      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                33296     \n",
      "=================================================================\n",
      "Total params: 104,816\n",
      "Trainable params: 100,080\n",
      "Non-trainable params: 4,736\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 197, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 16)            2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 65, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 336)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 336)               1344      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                5392      \n",
      "=================================================================\n",
      "Total params: 72,576\n",
      "Trainable params: 71,296\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 16)            2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 65, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 16)            1296      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 21, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 112)               448       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                1808      \n",
      "=================================================================\n",
      "Total params: 69,456\n",
      "Trainable params: 68,592\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 197, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 16)            2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 65, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 16)            1296      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 21, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 16)             1296      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 7, 16)             64        \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 69,216\n",
      "Trainable params: 68,480\n",
      "Non-trainable params: 736\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8683 - acc: 0.4417\n",
      "Epoch 00001: val_loss improved from inf to 1.57015, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_4_conv_checkpoint/001-1.5702.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.8683 - acc: 0.4417 - val_loss: 1.5702 - val_acc: 0.5057\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2013 - acc: 0.6376\n",
      "Epoch 00002: val_loss improved from 1.57015 to 1.26658, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_4_conv_checkpoint/002-1.2666.hdf5\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 1.2013 - acc: 0.6376 - val_loss: 1.2666 - val_acc: 0.6238\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9541 - acc: 0.7132\n",
      "Epoch 00003: val_loss improved from 1.26658 to 1.20449, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_4_conv_checkpoint/003-1.2045.hdf5\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.9541 - acc: 0.7132 - val_loss: 1.2045 - val_acc: 0.6527\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7836 - acc: 0.7646\n",
      "Epoch 00004: val_loss did not improve from 1.20449\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.7838 - acc: 0.7645 - val_loss: 1.4315 - val_acc: 0.5851\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6434 - acc: 0.8079\n",
      "Epoch 00005: val_loss improved from 1.20449 to 1.16739, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_4_conv_checkpoint/005-1.1674.hdf5\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.6438 - acc: 0.8079 - val_loss: 1.1674 - val_acc: 0.6765\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5388 - acc: 0.8423\n",
      "Epoch 00006: val_loss did not improve from 1.16739\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.5389 - acc: 0.8423 - val_loss: 1.1998 - val_acc: 0.6527\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4477 - acc: 0.8717\n",
      "Epoch 00007: val_loss improved from 1.16739 to 1.11438, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_4_conv_checkpoint/007-1.1144.hdf5\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.4478 - acc: 0.8717 - val_loss: 1.1144 - val_acc: 0.6792\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3653 - acc: 0.9002\n",
      "Epoch 00008: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.3655 - acc: 0.9001 - val_loss: 1.1447 - val_acc: 0.6869\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3136 - acc: 0.9170\n",
      "Epoch 00009: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.3137 - acc: 0.9170 - val_loss: 1.1708 - val_acc: 0.6827\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2541 - acc: 0.9389\n",
      "Epoch 00010: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2542 - acc: 0.9388 - val_loss: 1.1815 - val_acc: 0.6846\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2112 - acc: 0.9519\n",
      "Epoch 00011: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.2113 - acc: 0.9519 - val_loss: 1.1778 - val_acc: 0.6946\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1883 - acc: 0.9579\n",
      "Epoch 00012: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.1883 - acc: 0.9578 - val_loss: 1.2042 - val_acc: 0.6909\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9684\n",
      "Epoch 00013: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.1559 - acc: 0.9683 - val_loss: 1.2876 - val_acc: 0.6739\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9702\n",
      "Epoch 00014: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.1501 - acc: 0.9701 - val_loss: 1.2206 - val_acc: 0.6956\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9785\n",
      "Epoch 00015: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.1235 - acc: 0.9785 - val_loss: 1.3717 - val_acc: 0.6758\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9821\n",
      "Epoch 00016: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.1063 - acc: 0.9821 - val_loss: 1.2871 - val_acc: 0.6902\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9842\n",
      "Epoch 00017: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0982 - acc: 0.9842 - val_loss: 1.3083 - val_acc: 0.6953\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9843\n",
      "Epoch 00018: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0922 - acc: 0.9843 - val_loss: 1.2620 - val_acc: 0.7016\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9889\n",
      "Epoch 00019: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0737 - acc: 0.9888 - val_loss: 1.5426 - val_acc: 0.6669\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9839\n",
      "Epoch 00020: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0888 - acc: 0.9839 - val_loss: 1.4085 - val_acc: 0.6748\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9917\n",
      "Epoch 00021: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0606 - acc: 0.9917 - val_loss: 1.3975 - val_acc: 0.6848\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9888\n",
      "Epoch 00022: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0685 - acc: 0.9888 - val_loss: 1.3443 - val_acc: 0.6879\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9926\n",
      "Epoch 00023: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0565 - acc: 0.9925 - val_loss: 1.4551 - val_acc: 0.6862\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9913\n",
      "Epoch 00024: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0584 - acc: 0.9913 - val_loss: 1.4393 - val_acc: 0.7004\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9934\n",
      "Epoch 00025: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0481 - acc: 0.9933 - val_loss: 1.4626 - val_acc: 0.6935\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9882\n",
      "Epoch 00026: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0641 - acc: 0.9882 - val_loss: 1.5462 - val_acc: 0.6830\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9941\n",
      "Epoch 00027: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0462 - acc: 0.9940 - val_loss: 1.4570 - val_acc: 0.6949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9946\n",
      "Epoch 00028: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0429 - acc: 0.9945 - val_loss: 1.5391 - val_acc: 0.6841\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9926\n",
      "Epoch 00029: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0470 - acc: 0.9925 - val_loss: 1.5452 - val_acc: 0.6990\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9935\n",
      "Epoch 00030: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0433 - acc: 0.9934 - val_loss: 1.5953 - val_acc: 0.6697\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9917\n",
      "Epoch 00031: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0499 - acc: 0.9917 - val_loss: 1.4697 - val_acc: 0.6995\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9956\n",
      "Epoch 00032: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0372 - acc: 0.9955 - val_loss: 1.6442 - val_acc: 0.6718\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9915\n",
      "Epoch 00033: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0467 - acc: 0.9914 - val_loss: 1.5747 - val_acc: 0.6823\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9968\n",
      "Epoch 00034: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0310 - acc: 0.9968 - val_loss: 1.5243 - val_acc: 0.6939\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9958\n",
      "Epoch 00035: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0337 - acc: 0.9958 - val_loss: 1.8281 - val_acc: 0.6543\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9949\n",
      "Epoch 00036: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0327 - acc: 0.9949 - val_loss: 1.5766 - val_acc: 0.6855\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9953\n",
      "Epoch 00037: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0328 - acc: 0.9952 - val_loss: 1.8054 - val_acc: 0.6627\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9933\n",
      "Epoch 00038: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0387 - acc: 0.9933 - val_loss: 1.5935 - val_acc: 0.6932\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9943\n",
      "Epoch 00039: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0354 - acc: 0.9943 - val_loss: 1.8237 - val_acc: 0.6692\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9948\n",
      "Epoch 00040: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0344 - acc: 0.9948 - val_loss: 1.6222 - val_acc: 0.6914\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9946\n",
      "Epoch 00041: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0326 - acc: 0.9946 - val_loss: 1.7242 - val_acc: 0.6765\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9946\n",
      "Epoch 00042: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0329 - acc: 0.9946 - val_loss: 1.6262 - val_acc: 0.6914\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9961\n",
      "Epoch 00043: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0282 - acc: 0.9961 - val_loss: 1.6848 - val_acc: 0.6774\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9965\n",
      "Epoch 00044: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0268 - acc: 0.9965 - val_loss: 1.5907 - val_acc: 0.6935\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9968\n",
      "Epoch 00045: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0255 - acc: 0.9967 - val_loss: 1.8090 - val_acc: 0.6660\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9942\n",
      "Epoch 00046: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0306 - acc: 0.9942 - val_loss: 1.8424 - val_acc: 0.6671\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9955\n",
      "Epoch 00047: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0280 - acc: 0.9955 - val_loss: 1.6669 - val_acc: 0.6895\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9957\n",
      "Epoch 00048: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0278 - acc: 0.9956 - val_loss: 1.7422 - val_acc: 0.6783\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9963\n",
      "Epoch 00049: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0248 - acc: 0.9963 - val_loss: 1.8003 - val_acc: 0.6781\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9953\n",
      "Epoch 00050: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0292 - acc: 0.9952 - val_loss: 1.8544 - val_acc: 0.6711\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9914\n",
      "Epoch 00051: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0423 - acc: 0.9914 - val_loss: 1.7502 - val_acc: 0.6848\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9976\n",
      "Epoch 00052: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0221 - acc: 0.9976 - val_loss: 1.7422 - val_acc: 0.6825\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9961\n",
      "Epoch 00053: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0245 - acc: 0.9961 - val_loss: 1.6991 - val_acc: 0.6909\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9982\n",
      "Epoch 00054: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0190 - acc: 0.9981 - val_loss: 1.6867 - val_acc: 0.6939\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9971\n",
      "Epoch 00055: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0199 - acc: 0.9971 - val_loss: 1.7189 - val_acc: 0.6841\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9983\n",
      "Epoch 00056: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0162 - acc: 0.9983 - val_loss: 2.2012 - val_acc: 0.6324\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9950\n",
      "Epoch 00057: val_loss did not improve from 1.11438\n",
      "36805/36805 [==============================] - 83s 2ms/sample - loss: 0.0286 - acc: 0.9949 - val_loss: 1.9342 - val_acc: 0.6625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_4_ch_64_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 887us/sample - loss: 1.2374 - acc: 0.6426\n",
      "Loss: 1.2374102445901491 Accuracy: 0.64257526\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9009 - acc: 0.4162\n",
      "Epoch 00001: val_loss improved from inf to 1.56035, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_5_conv_checkpoint/001-1.5603.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.9008 - acc: 0.4162 - val_loss: 1.5603 - val_acc: 0.5015\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2525 - acc: 0.6199\n",
      "Epoch 00002: val_loss improved from 1.56035 to 1.13491, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_5_conv_checkpoint/002-1.1349.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.2526 - acc: 0.6198 - val_loss: 1.1349 - val_acc: 0.6557\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0563 - acc: 0.6804\n",
      "Epoch 00003: val_loss improved from 1.13491 to 1.06715, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_5_conv_checkpoint/003-1.0672.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.0565 - acc: 0.6804 - val_loss: 1.0672 - val_acc: 0.6648\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9375 - acc: 0.7163\n",
      "Epoch 00004: val_loss did not improve from 1.06715\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.9374 - acc: 0.7163 - val_loss: 1.0880 - val_acc: 0.6820\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8549 - acc: 0.7417\n",
      "Epoch 00005: val_loss improved from 1.06715 to 0.88241, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_5_conv_checkpoint/005-0.8824.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.8549 - acc: 0.7417 - val_loss: 0.8824 - val_acc: 0.7454\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7878 - acc: 0.7646\n",
      "Epoch 00006: val_loss did not improve from 0.88241\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.7878 - acc: 0.7647 - val_loss: 0.9134 - val_acc: 0.7317\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7358 - acc: 0.7799\n",
      "Epoch 00007: val_loss improved from 0.88241 to 0.86333, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_5_conv_checkpoint/007-0.8633.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.7358 - acc: 0.7799 - val_loss: 0.8633 - val_acc: 0.7477\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6961 - acc: 0.7935\n",
      "Epoch 00008: val_loss improved from 0.86333 to 0.83937, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_5_conv_checkpoint/008-0.8394.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.6964 - acc: 0.7935 - val_loss: 0.8394 - val_acc: 0.7619\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6591 - acc: 0.8039\n",
      "Epoch 00009: val_loss did not improve from 0.83937\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.6590 - acc: 0.8039 - val_loss: 0.8420 - val_acc: 0.7568\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6140 - acc: 0.8165\n",
      "Epoch 00010: val_loss improved from 0.83937 to 0.81551, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_5_conv_checkpoint/010-0.8155.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.6139 - acc: 0.8165 - val_loss: 0.8155 - val_acc: 0.7619\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5812 - acc: 0.8285\n",
      "Epoch 00011: val_loss did not improve from 0.81551\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5817 - acc: 0.8284 - val_loss: 0.9748 - val_acc: 0.7256\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5504 - acc: 0.8388\n",
      "Epoch 00012: val_loss improved from 0.81551 to 0.78278, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_5_conv_checkpoint/012-0.7828.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5504 - acc: 0.8388 - val_loss: 0.7828 - val_acc: 0.7724\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5112 - acc: 0.8487\n",
      "Epoch 00013: val_loss did not improve from 0.78278\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5114 - acc: 0.8486 - val_loss: 0.8516 - val_acc: 0.7517\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4952 - acc: 0.8552\n",
      "Epoch 00014: val_loss improved from 0.78278 to 0.77204, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_5_conv_checkpoint/014-0.7720.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4952 - acc: 0.8552 - val_loss: 0.7720 - val_acc: 0.7771\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4616 - acc: 0.8650\n",
      "Epoch 00015: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4617 - acc: 0.8649 - val_loss: 0.8962 - val_acc: 0.7398\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4324 - acc: 0.8720\n",
      "Epoch 00016: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4325 - acc: 0.8720 - val_loss: 0.8733 - val_acc: 0.7603\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4100 - acc: 0.8798\n",
      "Epoch 00017: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4100 - acc: 0.8798 - val_loss: 0.8608 - val_acc: 0.7605\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3859 - acc: 0.8885\n",
      "Epoch 00018: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3859 - acc: 0.8885 - val_loss: 0.8618 - val_acc: 0.7543\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3638 - acc: 0.8952\n",
      "Epoch 00019: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3638 - acc: 0.8952 - val_loss: 0.8570 - val_acc: 0.7617\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3426 - acc: 0.9025\n",
      "Epoch 00020: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3427 - acc: 0.9025 - val_loss: 0.7932 - val_acc: 0.7701\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3323 - acc: 0.9038\n",
      "Epoch 00021: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3324 - acc: 0.9038 - val_loss: 0.9006 - val_acc: 0.7549\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3076 - acc: 0.9128\n",
      "Epoch 00022: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3077 - acc: 0.9128 - val_loss: 0.8484 - val_acc: 0.7713\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2906 - acc: 0.9189\n",
      "Epoch 00023: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2906 - acc: 0.9189 - val_loss: 0.9007 - val_acc: 0.7675\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2723 - acc: 0.9255\n",
      "Epoch 00024: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2724 - acc: 0.9255 - val_loss: 0.8688 - val_acc: 0.7508\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2628 - acc: 0.9274\n",
      "Epoch 00025: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2628 - acc: 0.9275 - val_loss: 0.8846 - val_acc: 0.7561\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2406 - acc: 0.9343\n",
      "Epoch 00026: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2407 - acc: 0.9342 - val_loss: 0.8578 - val_acc: 0.7715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2316 - acc: 0.9373\n",
      "Epoch 00027: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2319 - acc: 0.9372 - val_loss: 0.8565 - val_acc: 0.7687\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2196 - acc: 0.9419\n",
      "Epoch 00028: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2198 - acc: 0.9419 - val_loss: 0.9335 - val_acc: 0.7582\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2054 - acc: 0.9455\n",
      "Epoch 00029: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2054 - acc: 0.9455 - val_loss: 0.9264 - val_acc: 0.7447\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1996 - acc: 0.9490\n",
      "Epoch 00030: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1997 - acc: 0.9489 - val_loss: 0.9490 - val_acc: 0.7484\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1860 - acc: 0.9523\n",
      "Epoch 00031: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1862 - acc: 0.9522 - val_loss: 0.9769 - val_acc: 0.7384\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1767 - acc: 0.9553\n",
      "Epoch 00032: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1768 - acc: 0.9552 - val_loss: 0.9186 - val_acc: 0.7650\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1746 - acc: 0.9549\n",
      "Epoch 00033: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1749 - acc: 0.9548 - val_loss: 1.0872 - val_acc: 0.7305\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1688 - acc: 0.9561\n",
      "Epoch 00034: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1692 - acc: 0.9560 - val_loss: 0.9367 - val_acc: 0.7643\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9624\n",
      "Epoch 00035: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1521 - acc: 0.9624 - val_loss: 0.9454 - val_acc: 0.7582\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1420 - acc: 0.9679\n",
      "Epoch 00036: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1421 - acc: 0.9679 - val_loss: 0.9626 - val_acc: 0.7643\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9665\n",
      "Epoch 00037: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1405 - acc: 0.9664 - val_loss: 1.0106 - val_acc: 0.7463\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9670\n",
      "Epoch 00038: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1389 - acc: 0.9669 - val_loss: 1.0851 - val_acc: 0.7426\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9707\n",
      "Epoch 00039: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1274 - acc: 0.9707 - val_loss: 0.9326 - val_acc: 0.7636\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9730\n",
      "Epoch 00040: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1186 - acc: 0.9730 - val_loss: 0.9492 - val_acc: 0.7654\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9748\n",
      "Epoch 00041: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1154 - acc: 0.9747 - val_loss: 1.0131 - val_acc: 0.7575\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9724\n",
      "Epoch 00042: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1210 - acc: 0.9724 - val_loss: 0.9560 - val_acc: 0.7615\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9788\n",
      "Epoch 00043: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1019 - acc: 0.9787 - val_loss: 0.9709 - val_acc: 0.7589\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9767\n",
      "Epoch 00044: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1055 - acc: 0.9766 - val_loss: 1.0388 - val_acc: 0.7554\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9771\n",
      "Epoch 00045: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1052 - acc: 0.9771 - val_loss: 0.9413 - val_acc: 0.7741\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0929 - acc: 0.9817\n",
      "Epoch 00046: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0929 - acc: 0.9817 - val_loss: 1.0024 - val_acc: 0.7722\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9810\n",
      "Epoch 00047: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0937 - acc: 0.9810 - val_loss: 1.0574 - val_acc: 0.7589\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9817\n",
      "Epoch 00048: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0885 - acc: 0.9817 - val_loss: 1.1930 - val_acc: 0.7268\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9836\n",
      "Epoch 00049: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0831 - acc: 0.9835 - val_loss: 1.1782 - val_acc: 0.7417\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9832\n",
      "Epoch 00050: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0834 - acc: 0.9832 - val_loss: 1.0861 - val_acc: 0.7524\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9819\n",
      "Epoch 00051: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0860 - acc: 0.9819 - val_loss: 1.0237 - val_acc: 0.7729\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9815\n",
      "Epoch 00052: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0840 - acc: 0.9816 - val_loss: 1.0656 - val_acc: 0.7596\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9865\n",
      "Epoch 00053: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0710 - acc: 0.9864 - val_loss: 1.0102 - val_acc: 0.7743\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9838\n",
      "Epoch 00054: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0765 - acc: 0.9837 - val_loss: 1.0509 - val_acc: 0.7615\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9863\n",
      "Epoch 00055: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0704 - acc: 0.9863 - val_loss: 1.0750 - val_acc: 0.7601\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9860\n",
      "Epoch 00056: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0695 - acc: 0.9860 - val_loss: 1.0534 - val_acc: 0.7657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9882\n",
      "Epoch 00057: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0628 - acc: 0.9882 - val_loss: 1.0593 - val_acc: 0.7654\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9874\n",
      "Epoch 00058: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0647 - acc: 0.9873 - val_loss: 1.3041 - val_acc: 0.7186\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9829\n",
      "Epoch 00059: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0772 - acc: 0.9829 - val_loss: 1.1972 - val_acc: 0.7461\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9889\n",
      "Epoch 00060: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0595 - acc: 0.9888 - val_loss: 1.0698 - val_acc: 0.7708\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9887\n",
      "Epoch 00061: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0600 - acc: 0.9887 - val_loss: 1.2528 - val_acc: 0.7282\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9883\n",
      "Epoch 00062: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0602 - acc: 0.9882 - val_loss: 1.0584 - val_acc: 0.7680\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9892\n",
      "Epoch 00063: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0584 - acc: 0.9892 - val_loss: 1.0822 - val_acc: 0.7710\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9876\n",
      "Epoch 00064: val_loss did not improve from 0.77204\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0603 - acc: 0.9876 - val_loss: 1.1533 - val_acc: 0.7522\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 917us/sample - loss: 0.8586 - acc: 0.7373\n",
      "Loss: 0.8586242485021629 Accuracy: 0.73727936\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1032 - acc: 0.3497\n",
      "Epoch 00001: val_loss improved from inf to 1.69012, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/001-1.6901.hdf5\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 2.1031 - acc: 0.3497 - val_loss: 1.6901 - val_acc: 0.4631\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3971 - acc: 0.5654\n",
      "Epoch 00002: val_loss improved from 1.69012 to 1.21012, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/002-1.2101.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 1.3973 - acc: 0.5653 - val_loss: 1.2101 - val_acc: 0.6366\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1527 - acc: 0.6509\n",
      "Epoch 00003: val_loss improved from 1.21012 to 1.01885, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/003-1.0188.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 1.1528 - acc: 0.6509 - val_loss: 1.0188 - val_acc: 0.6911\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0114 - acc: 0.6966\n",
      "Epoch 00004: val_loss improved from 1.01885 to 0.95369, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/004-0.9537.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.0116 - acc: 0.6965 - val_loss: 0.9537 - val_acc: 0.7144\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9197 - acc: 0.7281\n",
      "Epoch 00005: val_loss improved from 0.95369 to 0.85645, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/005-0.8565.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.9198 - acc: 0.7281 - val_loss: 0.8565 - val_acc: 0.7549\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8475 - acc: 0.7503\n",
      "Epoch 00006: val_loss did not improve from 0.85645\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.8477 - acc: 0.7503 - val_loss: 0.9283 - val_acc: 0.7207\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7921 - acc: 0.7684\n",
      "Epoch 00007: val_loss improved from 0.85645 to 0.79746, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/007-0.7975.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.7920 - acc: 0.7684 - val_loss: 0.7975 - val_acc: 0.7771\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7468 - acc: 0.7816\n",
      "Epoch 00008: val_loss did not improve from 0.79746\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.7468 - acc: 0.7816 - val_loss: 0.8242 - val_acc: 0.7615\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7044 - acc: 0.7941\n",
      "Epoch 00009: val_loss improved from 0.79746 to 0.73666, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/009-0.7367.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.7043 - acc: 0.7941 - val_loss: 0.7367 - val_acc: 0.7955\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6698 - acc: 0.8062\n",
      "Epoch 00010: val_loss improved from 0.73666 to 0.72087, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/010-0.7209.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.6700 - acc: 0.8061 - val_loss: 0.7209 - val_acc: 0.7915\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6424 - acc: 0.8144\n",
      "Epoch 00011: val_loss did not improve from 0.72087\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.6426 - acc: 0.8143 - val_loss: 0.7598 - val_acc: 0.7871\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6134 - acc: 0.8241\n",
      "Epoch 00012: val_loss did not improve from 0.72087\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.6136 - acc: 0.8240 - val_loss: 0.8473 - val_acc: 0.7552\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5840 - acc: 0.8306\n",
      "Epoch 00013: val_loss improved from 0.72087 to 0.70603, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/013-0.7060.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5841 - acc: 0.8306 - val_loss: 0.7060 - val_acc: 0.7966\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5597 - acc: 0.8379\n",
      "Epoch 00014: val_loss improved from 0.70603 to 0.66294, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/014-0.6629.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.5597 - acc: 0.8379 - val_loss: 0.6629 - val_acc: 0.8167\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5333 - acc: 0.8468\n",
      "Epoch 00015: val_loss did not improve from 0.66294\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5335 - acc: 0.8467 - val_loss: 0.6911 - val_acc: 0.8013\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5187 - acc: 0.8508\n",
      "Epoch 00016: val_loss improved from 0.66294 to 0.60721, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/016-0.6072.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5187 - acc: 0.8508 - val_loss: 0.6072 - val_acc: 0.8337\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4940 - acc: 0.8583\n",
      "Epoch 00017: val_loss did not improve from 0.60721\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4940 - acc: 0.8583 - val_loss: 0.6142 - val_acc: 0.8281\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4737 - acc: 0.8628\n",
      "Epoch 00018: val_loss did not improve from 0.60721\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4738 - acc: 0.8628 - val_loss: 0.6205 - val_acc: 0.8332\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4554 - acc: 0.8692\n",
      "Epoch 00019: val_loss improved from 0.60721 to 0.60542, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/019-0.6054.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.4554 - acc: 0.8692 - val_loss: 0.6054 - val_acc: 0.8360\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4391 - acc: 0.8738\n",
      "Epoch 00020: val_loss improved from 0.60542 to 0.58580, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/020-0.5858.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4391 - acc: 0.8738 - val_loss: 0.5858 - val_acc: 0.8351\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4209 - acc: 0.8796\n",
      "Epoch 00021: val_loss did not improve from 0.58580\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4213 - acc: 0.8795 - val_loss: 0.6177 - val_acc: 0.8202\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4035 - acc: 0.8854\n",
      "Epoch 00022: val_loss did not improve from 0.58580\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4036 - acc: 0.8854 - val_loss: 0.6029 - val_acc: 0.8374\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3935 - acc: 0.8871\n",
      "Epoch 00023: val_loss did not improve from 0.58580\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3936 - acc: 0.8870 - val_loss: 0.6337 - val_acc: 0.8209\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3797 - acc: 0.8915\n",
      "Epoch 00024: val_loss improved from 0.58580 to 0.55617, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/024-0.5562.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3799 - acc: 0.8915 - val_loss: 0.5562 - val_acc: 0.8479\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3661 - acc: 0.8942\n",
      "Epoch 00025: val_loss improved from 0.55617 to 0.55184, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/025-0.5518.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3661 - acc: 0.8942 - val_loss: 0.5518 - val_acc: 0.8491\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3493 - acc: 0.8988\n",
      "Epoch 00026: val_loss did not improve from 0.55184\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3495 - acc: 0.8988 - val_loss: 0.6136 - val_acc: 0.8281\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3493 - acc: 0.9010\n",
      "Epoch 00027: val_loss did not improve from 0.55184\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3494 - acc: 0.9010 - val_loss: 0.6248 - val_acc: 0.8395\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3291 - acc: 0.9060\n",
      "Epoch 00028: val_loss improved from 0.55184 to 0.55022, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/028-0.5502.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3292 - acc: 0.9060 - val_loss: 0.5502 - val_acc: 0.8437\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3193 - acc: 0.9077\n",
      "Epoch 00029: val_loss did not improve from 0.55022\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3194 - acc: 0.9076 - val_loss: 0.5761 - val_acc: 0.8383\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3099 - acc: 0.9089\n",
      "Epoch 00030: val_loss did not improve from 0.55022\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3100 - acc: 0.9088 - val_loss: 0.5926 - val_acc: 0.8360\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2964 - acc: 0.9153\n",
      "Epoch 00031: val_loss improved from 0.55022 to 0.53743, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/031-0.5374.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2967 - acc: 0.9152 - val_loss: 0.5374 - val_acc: 0.8546\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2871 - acc: 0.9180\n",
      "Epoch 00032: val_loss did not improve from 0.53743\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2871 - acc: 0.9180 - val_loss: 0.5585 - val_acc: 0.8465\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2744 - acc: 0.9210\n",
      "Epoch 00033: val_loss did not improve from 0.53743\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2744 - acc: 0.9210 - val_loss: 0.5485 - val_acc: 0.8528\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2690 - acc: 0.9220\n",
      "Epoch 00034: val_loss did not improve from 0.53743\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2692 - acc: 0.9219 - val_loss: 0.5815 - val_acc: 0.8383\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2683 - acc: 0.9244\n",
      "Epoch 00035: val_loss improved from 0.53743 to 0.52991, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/035-0.5299.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2687 - acc: 0.9244 - val_loss: 0.5299 - val_acc: 0.8535\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2735 - acc: 0.9196\n",
      "Epoch 00036: val_loss did not improve from 0.52991\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2736 - acc: 0.9196 - val_loss: 0.5434 - val_acc: 0.8565\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2501 - acc: 0.9294\n",
      "Epoch 00037: val_loss improved from 0.52991 to 0.51854, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/037-0.5185.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2501 - acc: 0.9294 - val_loss: 0.5185 - val_acc: 0.8595\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2396 - acc: 0.9319\n",
      "Epoch 00038: val_loss did not improve from 0.51854\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2397 - acc: 0.9319 - val_loss: 0.6029 - val_acc: 0.8407\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2272 - acc: 0.9351\n",
      "Epoch 00039: val_loss improved from 0.51854 to 0.50966, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/039-0.5097.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2273 - acc: 0.9350 - val_loss: 0.5097 - val_acc: 0.8609\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2238 - acc: 0.9376\n",
      "Epoch 00040: val_loss did not improve from 0.50966\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2238 - acc: 0.9375 - val_loss: 0.5174 - val_acc: 0.8565\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2195 - acc: 0.9379\n",
      "Epoch 00041: val_loss improved from 0.50966 to 0.50301, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_6_conv_checkpoint/041-0.5030.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2197 - acc: 0.9378 - val_loss: 0.5030 - val_acc: 0.8700\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2126 - acc: 0.9408\n",
      "Epoch 00042: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2129 - acc: 0.9408 - val_loss: 0.5920 - val_acc: 0.8376\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2104 - acc: 0.9399\n",
      "Epoch 00043: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2104 - acc: 0.9399 - val_loss: 0.5290 - val_acc: 0.8526\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1972 - acc: 0.9449\n",
      "Epoch 00044: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1973 - acc: 0.9448 - val_loss: 0.5580 - val_acc: 0.8432\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2031 - acc: 0.9428\n",
      "Epoch 00045: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2031 - acc: 0.9428 - val_loss: 0.5718 - val_acc: 0.8463\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1845 - acc: 0.9484\n",
      "Epoch 00046: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1845 - acc: 0.9484 - val_loss: 0.5588 - val_acc: 0.8628\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1813 - acc: 0.9496\n",
      "Epoch 00047: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1814 - acc: 0.9495 - val_loss: 0.5327 - val_acc: 0.8565\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1790 - acc: 0.9498\n",
      "Epoch 00048: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1791 - acc: 0.9498 - val_loss: 0.5416 - val_acc: 0.8546\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1742 - acc: 0.9510\n",
      "Epoch 00049: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1746 - acc: 0.9509 - val_loss: 0.5780 - val_acc: 0.8423\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1758 - acc: 0.9508\n",
      "Epoch 00050: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1759 - acc: 0.9507 - val_loss: 0.5472 - val_acc: 0.8488\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1639 - acc: 0.9547\n",
      "Epoch 00051: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1640 - acc: 0.9546 - val_loss: 0.5745 - val_acc: 0.8542\n",
      "Epoch 52/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9567\n",
      "Epoch 00052: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1599 - acc: 0.9567 - val_loss: 0.5472 - val_acc: 0.8530\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9561\n",
      "Epoch 00053: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1598 - acc: 0.9560 - val_loss: 0.5711 - val_acc: 0.8521\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1536 - acc: 0.9580\n",
      "Epoch 00054: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1537 - acc: 0.9580 - val_loss: 0.5220 - val_acc: 0.8642\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9620\n",
      "Epoch 00055: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1434 - acc: 0.9620 - val_loss: 0.5670 - val_acc: 0.8512\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9594\n",
      "Epoch 00056: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1475 - acc: 0.9594 - val_loss: 0.5412 - val_acc: 0.8523\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1427 - acc: 0.9613\n",
      "Epoch 00057: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1429 - acc: 0.9613 - val_loss: 0.5766 - val_acc: 0.8523\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9629\n",
      "Epoch 00058: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1403 - acc: 0.9628 - val_loss: 0.6088 - val_acc: 0.8465\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9654\n",
      "Epoch 00059: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1297 - acc: 0.9653 - val_loss: 0.5330 - val_acc: 0.8649\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9668\n",
      "Epoch 00060: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1283 - acc: 0.9668 - val_loss: 0.5060 - val_acc: 0.8686\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9666\n",
      "Epoch 00061: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1248 - acc: 0.9665 - val_loss: 0.5564 - val_acc: 0.8614\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9665\n",
      "Epoch 00062: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1284 - acc: 0.9665 - val_loss: 0.5641 - val_acc: 0.8588\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9676\n",
      "Epoch 00063: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1230 - acc: 0.9675 - val_loss: 0.6490 - val_acc: 0.8383\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9678\n",
      "Epoch 00064: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1220 - acc: 0.9677 - val_loss: 0.5528 - val_acc: 0.8649\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1164 - acc: 0.9707\n",
      "Epoch 00065: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1164 - acc: 0.9707 - val_loss: 0.5703 - val_acc: 0.8544\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1143 - acc: 0.9699\n",
      "Epoch 00066: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1143 - acc: 0.9699 - val_loss: 0.5947 - val_acc: 0.8528\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9733\n",
      "Epoch 00067: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1059 - acc: 0.9733 - val_loss: 0.5950 - val_acc: 0.8544\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9704\n",
      "Epoch 00068: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1112 - acc: 0.9703 - val_loss: 0.5754 - val_acc: 0.8572\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9726\n",
      "Epoch 00069: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1053 - acc: 0.9726 - val_loss: 0.6918 - val_acc: 0.8407\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9734\n",
      "Epoch 00070: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1046 - acc: 0.9734 - val_loss: 0.6254 - val_acc: 0.8502\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9733\n",
      "Epoch 00071: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1038 - acc: 0.9732 - val_loss: 0.5651 - val_acc: 0.8579\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9749\n",
      "Epoch 00072: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1011 - acc: 0.9749 - val_loss: 0.5821 - val_acc: 0.8588\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9779\n",
      "Epoch 00073: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0905 - acc: 0.9778 - val_loss: 0.6377 - val_acc: 0.8470\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9734\n",
      "Epoch 00074: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0999 - acc: 0.9734 - val_loss: 0.5475 - val_acc: 0.8642\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9765\n",
      "Epoch 00075: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0912 - acc: 0.9764 - val_loss: 0.6202 - val_acc: 0.8509\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9771\n",
      "Epoch 00076: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0915 - acc: 0.9771 - val_loss: 0.5834 - val_acc: 0.8539\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9781\n",
      "Epoch 00077: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0878 - acc: 0.9780 - val_loss: 0.6737 - val_acc: 0.8328\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9780\n",
      "Epoch 00078: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0883 - acc: 0.9780 - val_loss: 0.5950 - val_acc: 0.8581\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9789\n",
      "Epoch 00079: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0848 - acc: 0.9788 - val_loss: 0.5710 - val_acc: 0.8649\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9768\n",
      "Epoch 00080: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0882 - acc: 0.9768 - val_loss: 0.5734 - val_acc: 0.8630\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9792\n",
      "Epoch 00081: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0827 - acc: 0.9792 - val_loss: 0.6076 - val_acc: 0.8581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9815\n",
      "Epoch 00082: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0775 - acc: 0.9815 - val_loss: 0.7000 - val_acc: 0.8465\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9797\n",
      "Epoch 00083: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0811 - acc: 0.9797 - val_loss: 0.5742 - val_acc: 0.8637\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9820\n",
      "Epoch 00084: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0760 - acc: 0.9819 - val_loss: 0.6170 - val_acc: 0.8579\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9782\n",
      "Epoch 00085: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0838 - acc: 0.9781 - val_loss: 0.5880 - val_acc: 0.8612\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9807\n",
      "Epoch 00086: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0767 - acc: 0.9807 - val_loss: 0.6072 - val_acc: 0.8591\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9836\n",
      "Epoch 00087: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0711 - acc: 0.9836 - val_loss: 0.5786 - val_acc: 0.8675\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9832\n",
      "Epoch 00088: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0702 - acc: 0.9832 - val_loss: 0.6011 - val_acc: 0.8602\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9831\n",
      "Epoch 00089: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0708 - acc: 0.9830 - val_loss: 0.6884 - val_acc: 0.8474\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9820\n",
      "Epoch 00090: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0735 - acc: 0.9819 - val_loss: 0.6029 - val_acc: 0.8591\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9750\n",
      "Epoch 00091: val_loss did not improve from 0.50301\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0944 - acc: 0.9749 - val_loss: 0.6124 - val_acc: 0.8584\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 894us/sample - loss: 0.5741 - acc: 0.8363\n",
      "Loss: 0.574137274684193 Accuracy: 0.8363448\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6384 - acc: 0.1993\n",
      "Epoch 00001: val_loss improved from inf to 2.18367, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/001-2.1837.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 2.6384 - acc: 0.1993 - val_loss: 2.1837 - val_acc: 0.3284\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8648 - acc: 0.4183\n",
      "Epoch 00002: val_loss improved from 2.18367 to 1.65732, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/002-1.6573.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 1.8647 - acc: 0.4183 - val_loss: 1.6573 - val_acc: 0.4948\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5336 - acc: 0.5276\n",
      "Epoch 00003: val_loss improved from 1.65732 to 1.37975, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/003-1.3797.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 1.5336 - acc: 0.5276 - val_loss: 1.3797 - val_acc: 0.5891\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3248 - acc: 0.6011\n",
      "Epoch 00004: val_loss improved from 1.37975 to 1.27301, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/004-1.2730.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 1.3248 - acc: 0.6011 - val_loss: 1.2730 - val_acc: 0.6161\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1721 - acc: 0.6518\n",
      "Epoch 00005: val_loss improved from 1.27301 to 1.15224, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/005-1.1522.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 1.1723 - acc: 0.6518 - val_loss: 1.1522 - val_acc: 0.6548\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0630 - acc: 0.6877\n",
      "Epoch 00006: val_loss improved from 1.15224 to 0.97784, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/006-0.9778.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 1.0630 - acc: 0.6876 - val_loss: 0.9778 - val_acc: 0.7151\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9697 - acc: 0.7207\n",
      "Epoch 00007: val_loss improved from 0.97784 to 0.95574, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/007-0.9557.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.9698 - acc: 0.7207 - val_loss: 0.9557 - val_acc: 0.7237\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9000 - acc: 0.7432\n",
      "Epoch 00008: val_loss improved from 0.95574 to 0.81497, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/008-0.8150.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.9001 - acc: 0.7431 - val_loss: 0.8150 - val_acc: 0.7664\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8339 - acc: 0.7626\n",
      "Epoch 00009: val_loss did not improve from 0.81497\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.8340 - acc: 0.7626 - val_loss: 0.9145 - val_acc: 0.7370\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7742 - acc: 0.7823\n",
      "Epoch 00010: val_loss improved from 0.81497 to 0.70840, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/010-0.7084.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.7743 - acc: 0.7823 - val_loss: 0.7084 - val_acc: 0.7976\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7258 - acc: 0.7946\n",
      "Epoch 00011: val_loss did not improve from 0.70840\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.7258 - acc: 0.7946 - val_loss: 0.7240 - val_acc: 0.7936\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6853 - acc: 0.8058\n",
      "Epoch 00012: val_loss improved from 0.70840 to 0.69468, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/012-0.6947.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.6853 - acc: 0.8058 - val_loss: 0.6947 - val_acc: 0.8106\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6479 - acc: 0.8158\n",
      "Epoch 00013: val_loss did not improve from 0.69468\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.6479 - acc: 0.8158 - val_loss: 0.7357 - val_acc: 0.7873\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6173 - acc: 0.8250\n",
      "Epoch 00014: val_loss improved from 0.69468 to 0.60541, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/014-0.6054.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6173 - acc: 0.8250 - val_loss: 0.6054 - val_acc: 0.8244\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5887 - acc: 0.8343\n",
      "Epoch 00015: val_loss did not improve from 0.60541\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.5887 - acc: 0.8343 - val_loss: 0.6825 - val_acc: 0.8076\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5633 - acc: 0.8401\n",
      "Epoch 00016: val_loss did not improve from 0.60541\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.5635 - acc: 0.8400 - val_loss: 0.6192 - val_acc: 0.8304\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5590 - acc: 0.8418\n",
      "Epoch 00017: val_loss improved from 0.60541 to 0.58925, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/017-0.5893.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.5590 - acc: 0.8418 - val_loss: 0.5893 - val_acc: 0.8286\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5212 - acc: 0.8523\n",
      "Epoch 00018: val_loss improved from 0.58925 to 0.52828, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/018-0.5283.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.5215 - acc: 0.8522 - val_loss: 0.5283 - val_acc: 0.8553\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5042 - acc: 0.8588\n",
      "Epoch 00019: val_loss did not improve from 0.52828\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.5042 - acc: 0.8588 - val_loss: 0.5688 - val_acc: 0.8418\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4872 - acc: 0.8614\n",
      "Epoch 00020: val_loss improved from 0.52828 to 0.49732, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/020-0.4973.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4874 - acc: 0.8613 - val_loss: 0.4973 - val_acc: 0.8574\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4758 - acc: 0.8656\n",
      "Epoch 00021: val_loss did not improve from 0.49732\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.4762 - acc: 0.8655 - val_loss: 0.5962 - val_acc: 0.8297\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4668 - acc: 0.8679\n",
      "Epoch 00022: val_loss did not improve from 0.49732\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.4670 - acc: 0.8678 - val_loss: 0.5037 - val_acc: 0.8593\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4400 - acc: 0.8746\n",
      "Epoch 00023: val_loss improved from 0.49732 to 0.44411, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/023-0.4441.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.4400 - acc: 0.8746 - val_loss: 0.4441 - val_acc: 0.8710\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4282 - acc: 0.8762\n",
      "Epoch 00024: val_loss did not improve from 0.44411\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.4288 - acc: 0.8760 - val_loss: 0.4856 - val_acc: 0.8577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4187 - acc: 0.8783\n",
      "Epoch 00025: val_loss did not improve from 0.44411\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.4187 - acc: 0.8783 - val_loss: 0.5021 - val_acc: 0.8581\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4065 - acc: 0.8819\n",
      "Epoch 00026: val_loss did not improve from 0.44411\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.4066 - acc: 0.8819 - val_loss: 0.4520 - val_acc: 0.8768\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3943 - acc: 0.8864\n",
      "Epoch 00027: val_loss did not improve from 0.44411\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.3946 - acc: 0.8863 - val_loss: 0.5160 - val_acc: 0.8507\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3878 - acc: 0.8890\n",
      "Epoch 00028: val_loss did not improve from 0.44411\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.3878 - acc: 0.8890 - val_loss: 0.5219 - val_acc: 0.8544\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3761 - acc: 0.8918\n",
      "Epoch 00029: val_loss did not improve from 0.44411\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.3762 - acc: 0.8917 - val_loss: 0.4481 - val_acc: 0.8712\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3664 - acc: 0.8927\n",
      "Epoch 00030: val_loss did not improve from 0.44411\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.3664 - acc: 0.8927 - val_loss: 0.6515 - val_acc: 0.8318\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3551 - acc: 0.8983\n",
      "Epoch 00031: val_loss did not improve from 0.44411\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.3552 - acc: 0.8982 - val_loss: 0.5391 - val_acc: 0.8423\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3460 - acc: 0.8999\n",
      "Epoch 00032: val_loss did not improve from 0.44411\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.3461 - acc: 0.8999 - val_loss: 0.5209 - val_acc: 0.8577\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3364 - acc: 0.9031\n",
      "Epoch 00033: val_loss did not improve from 0.44411\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.3367 - acc: 0.9030 - val_loss: 0.4757 - val_acc: 0.8654\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3342 - acc: 0.9022\n",
      "Epoch 00034: val_loss improved from 0.44411 to 0.42474, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/034-0.4247.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.3342 - acc: 0.9022 - val_loss: 0.4247 - val_acc: 0.8814\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3211 - acc: 0.9052\n",
      "Epoch 00035: val_loss did not improve from 0.42474\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.3218 - acc: 0.9051 - val_loss: 0.4252 - val_acc: 0.8772\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3165 - acc: 0.9085\n",
      "Epoch 00036: val_loss improved from 0.42474 to 0.40020, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/036-0.4002.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.3166 - acc: 0.9085 - val_loss: 0.4002 - val_acc: 0.8873\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3067 - acc: 0.9096\n",
      "Epoch 00037: val_loss did not improve from 0.40020\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.3067 - acc: 0.9097 - val_loss: 0.4266 - val_acc: 0.8842\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3025 - acc: 0.9130\n",
      "Epoch 00038: val_loss improved from 0.40020 to 0.39069, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/038-0.3907.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3025 - acc: 0.9130 - val_loss: 0.3907 - val_acc: 0.8926\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2944 - acc: 0.9133\n",
      "Epoch 00039: val_loss did not improve from 0.39069\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2944 - acc: 0.9132 - val_loss: 0.4011 - val_acc: 0.8845\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2852 - acc: 0.9145\n",
      "Epoch 00040: val_loss did not improve from 0.39069\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2854 - acc: 0.9144 - val_loss: 0.4354 - val_acc: 0.8831\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2844 - acc: 0.9155\n",
      "Epoch 00041: val_loss did not improve from 0.39069\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2844 - acc: 0.9155 - val_loss: 0.5125 - val_acc: 0.8728\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.9176\n",
      "Epoch 00042: val_loss did not improve from 0.39069\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2805 - acc: 0.9175 - val_loss: 0.4567 - val_acc: 0.8838\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2724 - acc: 0.9199\n",
      "Epoch 00043: val_loss did not improve from 0.39069\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2724 - acc: 0.9199 - val_loss: 0.4149 - val_acc: 0.8868\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2652 - acc: 0.9227\n",
      "Epoch 00044: val_loss did not improve from 0.39069\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2655 - acc: 0.9226 - val_loss: 0.4121 - val_acc: 0.8826\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2649 - acc: 0.9228\n",
      "Epoch 00045: val_loss improved from 0.39069 to 0.37964, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/045-0.3796.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2650 - acc: 0.9227 - val_loss: 0.3796 - val_acc: 0.8977\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2501 - acc: 0.9268\n",
      "Epoch 00046: val_loss did not improve from 0.37964\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2506 - acc: 0.9268 - val_loss: 0.4278 - val_acc: 0.8826\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2548 - acc: 0.9257\n",
      "Epoch 00047: val_loss did not improve from 0.37964\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2549 - acc: 0.9256 - val_loss: 0.3811 - val_acc: 0.8940\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2403 - acc: 0.9290\n",
      "Epoch 00048: val_loss did not improve from 0.37964\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2406 - acc: 0.9290 - val_loss: 0.3915 - val_acc: 0.8901\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2367 - acc: 0.9316\n",
      "Epoch 00049: val_loss improved from 0.37964 to 0.37240, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_7_conv_checkpoint/049-0.3724.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2366 - acc: 0.9316 - val_loss: 0.3724 - val_acc: 0.8968\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2322 - acc: 0.9308\n",
      "Epoch 00050: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2323 - acc: 0.9308 - val_loss: 0.4184 - val_acc: 0.8873\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2279 - acc: 0.9328\n",
      "Epoch 00051: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2279 - acc: 0.9328 - val_loss: 0.3977 - val_acc: 0.8875\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2227 - acc: 0.9344\n",
      "Epoch 00052: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2227 - acc: 0.9344 - val_loss: 0.4014 - val_acc: 0.8926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2218 - acc: 0.9340\n",
      "Epoch 00053: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2220 - acc: 0.9339 - val_loss: 0.3935 - val_acc: 0.8935\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2162 - acc: 0.9350\n",
      "Epoch 00054: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2162 - acc: 0.9350 - val_loss: 0.3791 - val_acc: 0.8970\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2071 - acc: 0.9387\n",
      "Epoch 00055: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2071 - acc: 0.9387 - val_loss: 0.3796 - val_acc: 0.8912\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2055 - acc: 0.9392\n",
      "Epoch 00056: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2055 - acc: 0.9392 - val_loss: 0.4131 - val_acc: 0.8901\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2000 - acc: 0.9401\n",
      "Epoch 00057: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2000 - acc: 0.9401 - val_loss: 0.3981 - val_acc: 0.8873\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2008 - acc: 0.9392\n",
      "Epoch 00058: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.2010 - acc: 0.9392 - val_loss: 0.3882 - val_acc: 0.8945\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9423\n",
      "Epoch 00059: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1965 - acc: 0.9422 - val_loss: 0.3951 - val_acc: 0.8968\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1880 - acc: 0.9449\n",
      "Epoch 00060: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1879 - acc: 0.9450 - val_loss: 0.4338 - val_acc: 0.8796\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1809 - acc: 0.9465\n",
      "Epoch 00061: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1811 - acc: 0.9465 - val_loss: 0.3797 - val_acc: 0.8942\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1874 - acc: 0.9439\n",
      "Epoch 00062: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1875 - acc: 0.9438 - val_loss: 0.4008 - val_acc: 0.8917\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1796 - acc: 0.9471\n",
      "Epoch 00063: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1797 - acc: 0.9471 - val_loss: 0.4300 - val_acc: 0.8828\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1844 - acc: 0.9451\n",
      "Epoch 00064: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1844 - acc: 0.9451 - val_loss: 0.3824 - val_acc: 0.8966\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1670 - acc: 0.9511\n",
      "Epoch 00065: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1670 - acc: 0.9511 - val_loss: 0.4494 - val_acc: 0.8891\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1656 - acc: 0.9514\n",
      "Epoch 00066: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1659 - acc: 0.9513 - val_loss: 0.4310 - val_acc: 0.8917\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9497\n",
      "Epoch 00067: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1692 - acc: 0.9497 - val_loss: 0.4108 - val_acc: 0.8831\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1683 - acc: 0.9502\n",
      "Epoch 00068: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1684 - acc: 0.9501 - val_loss: 0.4199 - val_acc: 0.9015\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1585 - acc: 0.9540\n",
      "Epoch 00069: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1585 - acc: 0.9540 - val_loss: 0.4693 - val_acc: 0.8880\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1542 - acc: 0.9546\n",
      "Epoch 00070: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1544 - acc: 0.9546 - val_loss: 0.3821 - val_acc: 0.8949\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1545 - acc: 0.9544\n",
      "Epoch 00071: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1546 - acc: 0.9544 - val_loss: 0.4259 - val_acc: 0.8898\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1685 - acc: 0.9492\n",
      "Epoch 00072: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1687 - acc: 0.9491 - val_loss: 0.4123 - val_acc: 0.8889\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9548\n",
      "Epoch 00073: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1522 - acc: 0.9548 - val_loss: 0.4151 - val_acc: 0.8956\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9577\n",
      "Epoch 00074: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1449 - acc: 0.9576 - val_loss: 0.3962 - val_acc: 0.9001\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9599\n",
      "Epoch 00075: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1409 - acc: 0.9599 - val_loss: 0.3889 - val_acc: 0.8945\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9588\n",
      "Epoch 00076: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1409 - acc: 0.9587 - val_loss: 0.4501 - val_acc: 0.8863\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9577\n",
      "Epoch 00077: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1460 - acc: 0.9577 - val_loss: 0.4342 - val_acc: 0.8938\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1436 - acc: 0.9576\n",
      "Epoch 00078: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1437 - acc: 0.9575 - val_loss: 0.4030 - val_acc: 0.9029\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9593\n",
      "Epoch 00079: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1386 - acc: 0.9592 - val_loss: 0.4040 - val_acc: 0.8973\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9631\n",
      "Epoch 00080: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1290 - acc: 0.9630 - val_loss: 0.4084 - val_acc: 0.8919\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9619\n",
      "Epoch 00081: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1337 - acc: 0.9618 - val_loss: 0.4218 - val_acc: 0.8891\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9560\n",
      "Epoch 00082: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1481 - acc: 0.9560 - val_loss: 0.4110 - val_acc: 0.8921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9626\n",
      "Epoch 00083: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1300 - acc: 0.9626 - val_loss: 0.4562 - val_acc: 0.8961\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9646\n",
      "Epoch 00084: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1217 - acc: 0.9646 - val_loss: 0.4372 - val_acc: 0.8870\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9646\n",
      "Epoch 00085: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1200 - acc: 0.9646 - val_loss: 0.4241 - val_acc: 0.8945\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9646\n",
      "Epoch 00086: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1208 - acc: 0.9647 - val_loss: 0.4479 - val_acc: 0.8884\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9655\n",
      "Epoch 00087: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1177 - acc: 0.9654 - val_loss: 0.4692 - val_acc: 0.8826\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9663\n",
      "Epoch 00088: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1207 - acc: 0.9663 - val_loss: 0.4551 - val_acc: 0.8884\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9672\n",
      "Epoch 00089: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1145 - acc: 0.9671 - val_loss: 0.4567 - val_acc: 0.8915\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9631\n",
      "Epoch 00090: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1261 - acc: 0.9630 - val_loss: 0.4059 - val_acc: 0.8942\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9686\n",
      "Epoch 00091: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1104 - acc: 0.9686 - val_loss: 0.4139 - val_acc: 0.9003\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9685\n",
      "Epoch 00092: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1088 - acc: 0.9685 - val_loss: 0.4202 - val_acc: 0.8961\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9677\n",
      "Epoch 00093: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1112 - acc: 0.9677 - val_loss: 0.4340 - val_acc: 0.8903\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9685\n",
      "Epoch 00094: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1077 - acc: 0.9684 - val_loss: 0.4230 - val_acc: 0.8982\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9688\n",
      "Epoch 00095: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1097 - acc: 0.9687 - val_loss: 0.4999 - val_acc: 0.8842\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9711\n",
      "Epoch 00096: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1025 - acc: 0.9711 - val_loss: 0.4473 - val_acc: 0.8926\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9715\n",
      "Epoch 00097: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.0990 - acc: 0.9715 - val_loss: 0.5281 - val_acc: 0.8826\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9705\n",
      "Epoch 00098: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1013 - acc: 0.9705 - val_loss: 0.4838 - val_acc: 0.8894\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9703\n",
      "Epoch 00099: val_loss did not improve from 0.37240\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.1003 - acc: 0.9703 - val_loss: 0.4209 - val_acc: 0.8970\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 925us/sample - loss: 0.4625 - acc: 0.8654\n",
      "Loss: 0.46254912905727713 Accuracy: 0.8654206\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6495 - acc: 0.1919\n",
      "Epoch 00001: val_loss improved from inf to 2.37974, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/001-2.3797.hdf5\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 2.6495 - acc: 0.1919 - val_loss: 2.3797 - val_acc: 0.2485\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9657 - acc: 0.3861\n",
      "Epoch 00002: val_loss improved from 2.37974 to 1.68574, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/002-1.6857.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.9657 - acc: 0.3861 - val_loss: 1.6857 - val_acc: 0.4775\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5855 - acc: 0.5163\n",
      "Epoch 00003: val_loss improved from 1.68574 to 1.38479, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/003-1.3848.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.5854 - acc: 0.5163 - val_loss: 1.3848 - val_acc: 0.5816\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3276 - acc: 0.6023\n",
      "Epoch 00004: val_loss improved from 1.38479 to 1.18911, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/004-1.1891.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.3276 - acc: 0.6023 - val_loss: 1.1891 - val_acc: 0.6427\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1506 - acc: 0.6608\n",
      "Epoch 00005: val_loss did not improve from 1.18911\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.1508 - acc: 0.6608 - val_loss: 1.2524 - val_acc: 0.6145\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0200 - acc: 0.7061\n",
      "Epoch 00006: val_loss improved from 1.18911 to 0.89364, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/006-0.8936.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.0199 - acc: 0.7061 - val_loss: 0.8936 - val_acc: 0.7370\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9163 - acc: 0.7366\n",
      "Epoch 00007: val_loss improved from 0.89364 to 0.83041, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/007-0.8304.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.9164 - acc: 0.7366 - val_loss: 0.8304 - val_acc: 0.7584\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8283 - acc: 0.7641\n",
      "Epoch 00008: val_loss did not improve from 0.83041\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.8283 - acc: 0.7641 - val_loss: 1.0401 - val_acc: 0.6629\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7619 - acc: 0.7832\n",
      "Epoch 00009: val_loss improved from 0.83041 to 0.69756, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/009-0.6976.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7619 - acc: 0.7832 - val_loss: 0.6976 - val_acc: 0.7987\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7021 - acc: 0.8013\n",
      "Epoch 00010: val_loss improved from 0.69756 to 0.64853, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/010-0.6485.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7022 - acc: 0.8012 - val_loss: 0.6485 - val_acc: 0.8155\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6557 - acc: 0.8160\n",
      "Epoch 00011: val_loss did not improve from 0.64853\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6557 - acc: 0.8159 - val_loss: 0.6508 - val_acc: 0.8139\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6111 - acc: 0.8268\n",
      "Epoch 00012: val_loss improved from 0.64853 to 0.62384, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/012-0.6238.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6112 - acc: 0.8268 - val_loss: 0.6238 - val_acc: 0.8174\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5799 - acc: 0.8359\n",
      "Epoch 00013: val_loss improved from 0.62384 to 0.53601, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/013-0.5360.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5800 - acc: 0.8358 - val_loss: 0.5360 - val_acc: 0.8374\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5440 - acc: 0.8452\n",
      "Epoch 00014: val_loss improved from 0.53601 to 0.52489, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/014-0.5249.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5442 - acc: 0.8452 - val_loss: 0.5249 - val_acc: 0.8491\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5174 - acc: 0.8535\n",
      "Epoch 00015: val_loss improved from 0.52489 to 0.48200, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/015-0.4820.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5175 - acc: 0.8534 - val_loss: 0.4820 - val_acc: 0.8633\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4886 - acc: 0.8619\n",
      "Epoch 00016: val_loss did not improve from 0.48200\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4886 - acc: 0.8619 - val_loss: 0.5405 - val_acc: 0.8383\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4681 - acc: 0.8665\n",
      "Epoch 00017: val_loss improved from 0.48200 to 0.45180, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/017-0.4518.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4682 - acc: 0.8665 - val_loss: 0.4518 - val_acc: 0.8642\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4444 - acc: 0.8723\n",
      "Epoch 00018: val_loss improved from 0.45180 to 0.43425, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/018-0.4343.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4444 - acc: 0.8722 - val_loss: 0.4343 - val_acc: 0.8728\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4255 - acc: 0.8799\n",
      "Epoch 00019: val_loss did not improve from 0.43425\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4257 - acc: 0.8799 - val_loss: 0.4383 - val_acc: 0.8710\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4076 - acc: 0.8834\n",
      "Epoch 00020: val_loss improved from 0.43425 to 0.38914, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/020-0.3891.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4076 - acc: 0.8834 - val_loss: 0.3891 - val_acc: 0.8838\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3937 - acc: 0.8882\n",
      "Epoch 00021: val_loss did not improve from 0.38914\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3937 - acc: 0.8881 - val_loss: 0.3982 - val_acc: 0.8859\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3815 - acc: 0.8912\n",
      "Epoch 00022: val_loss did not improve from 0.38914\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3816 - acc: 0.8912 - val_loss: 0.3980 - val_acc: 0.8840\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3638 - acc: 0.8968\n",
      "Epoch 00023: val_loss improved from 0.38914 to 0.38892, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/023-0.3889.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3639 - acc: 0.8968 - val_loss: 0.3889 - val_acc: 0.8873\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.8988\n",
      "Epoch 00024: val_loss improved from 0.38892 to 0.34717, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/024-0.3472.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3536 - acc: 0.8987 - val_loss: 0.3472 - val_acc: 0.9045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3479 - acc: 0.8996\n",
      "Epoch 00025: val_loss did not improve from 0.34717\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3481 - acc: 0.8996 - val_loss: 0.3720 - val_acc: 0.8915\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3338 - acc: 0.9033\n",
      "Epoch 00026: val_loss did not improve from 0.34717\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3338 - acc: 0.9032 - val_loss: 0.3552 - val_acc: 0.9036\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3226 - acc: 0.9068\n",
      "Epoch 00027: val_loss did not improve from 0.34717\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3226 - acc: 0.9068 - val_loss: 0.3667 - val_acc: 0.8915\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3132 - acc: 0.9089\n",
      "Epoch 00028: val_loss did not improve from 0.34717\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3133 - acc: 0.9089 - val_loss: 0.3624 - val_acc: 0.8984\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3048 - acc: 0.9108\n",
      "Epoch 00029: val_loss improved from 0.34717 to 0.32046, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/029-0.3205.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3048 - acc: 0.9108 - val_loss: 0.3205 - val_acc: 0.9110\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2933 - acc: 0.9153\n",
      "Epoch 00030: val_loss did not improve from 0.32046\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2934 - acc: 0.9153 - val_loss: 0.3759 - val_acc: 0.8889\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2917 - acc: 0.9163\n",
      "Epoch 00031: val_loss did not improve from 0.32046\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2917 - acc: 0.9163 - val_loss: 0.3344 - val_acc: 0.9033\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.9178\n",
      "Epoch 00032: val_loss improved from 0.32046 to 0.29957, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/032-0.2996.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2801 - acc: 0.9178 - val_loss: 0.2996 - val_acc: 0.9136\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2718 - acc: 0.9219\n",
      "Epoch 00033: val_loss did not improve from 0.29957\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2719 - acc: 0.9219 - val_loss: 0.3377 - val_acc: 0.8991\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2700 - acc: 0.9218\n",
      "Epoch 00034: val_loss did not improve from 0.29957\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2701 - acc: 0.9217 - val_loss: 0.3457 - val_acc: 0.8989\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2610 - acc: 0.9237\n",
      "Epoch 00035: val_loss did not improve from 0.29957\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2610 - acc: 0.9237 - val_loss: 0.3131 - val_acc: 0.9101\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2519 - acc: 0.9254\n",
      "Epoch 00036: val_loss did not improve from 0.29957\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2522 - acc: 0.9252 - val_loss: 0.3154 - val_acc: 0.9101\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2496 - acc: 0.9258\n",
      "Epoch 00037: val_loss did not improve from 0.29957\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2497 - acc: 0.9258 - val_loss: 0.3205 - val_acc: 0.9064\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2396 - acc: 0.9294\n",
      "Epoch 00038: val_loss improved from 0.29957 to 0.29041, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/038-0.2904.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2397 - acc: 0.9294 - val_loss: 0.2904 - val_acc: 0.9157\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2351 - acc: 0.9316\n",
      "Epoch 00039: val_loss did not improve from 0.29041\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2351 - acc: 0.9316 - val_loss: 0.2973 - val_acc: 0.9175\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2249 - acc: 0.9343\n",
      "Epoch 00040: val_loss did not improve from 0.29041\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2249 - acc: 0.9343 - val_loss: 0.2915 - val_acc: 0.9164\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2274 - acc: 0.9322\n",
      "Epoch 00041: val_loss did not improve from 0.29041\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2276 - acc: 0.9321 - val_loss: 0.3112 - val_acc: 0.9075\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2197 - acc: 0.9352\n",
      "Epoch 00042: val_loss did not improve from 0.29041\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2197 - acc: 0.9351 - val_loss: 0.3013 - val_acc: 0.9119\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2150 - acc: 0.9362\n",
      "Epoch 00043: val_loss did not improve from 0.29041\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2151 - acc: 0.9362 - val_loss: 0.3111 - val_acc: 0.9092\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2093 - acc: 0.9382\n",
      "Epoch 00044: val_loss improved from 0.29041 to 0.28161, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/044-0.2816.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2095 - acc: 0.9382 - val_loss: 0.2816 - val_acc: 0.9208\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2034 - acc: 0.9410\n",
      "Epoch 00045: val_loss did not improve from 0.28161\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2037 - acc: 0.9410 - val_loss: 0.3096 - val_acc: 0.9101\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2003 - acc: 0.9396\n",
      "Epoch 00046: val_loss did not improve from 0.28161\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2003 - acc: 0.9396 - val_loss: 0.2972 - val_acc: 0.9161\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1941 - acc: 0.9423\n",
      "Epoch 00047: val_loss did not improve from 0.28161\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1941 - acc: 0.9423 - val_loss: 0.3113 - val_acc: 0.9087\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1921 - acc: 0.9420\n",
      "Epoch 00048: val_loss improved from 0.28161 to 0.27931, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/048-0.2793.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1921 - acc: 0.9420 - val_loss: 0.2793 - val_acc: 0.9164\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1855 - acc: 0.9460\n",
      "Epoch 00049: val_loss improved from 0.27931 to 0.27682, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/049-0.2768.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1855 - acc: 0.9460 - val_loss: 0.2768 - val_acc: 0.9220\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9464\n",
      "Epoch 00050: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1821 - acc: 0.9464 - val_loss: 0.3167 - val_acc: 0.9131\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9484\n",
      "Epoch 00051: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1755 - acc: 0.9484 - val_loss: 0.2914 - val_acc: 0.9150\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9486\n",
      "Epoch 00052: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1752 - acc: 0.9486 - val_loss: 0.3029 - val_acc: 0.9126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1754 - acc: 0.9474\n",
      "Epoch 00053: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1754 - acc: 0.9474 - val_loss: 0.2893 - val_acc: 0.9180\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1725 - acc: 0.9491\n",
      "Epoch 00054: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1727 - acc: 0.9491 - val_loss: 0.2854 - val_acc: 0.9250\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1588 - acc: 0.9528\n",
      "Epoch 00055: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1587 - acc: 0.9528 - val_loss: 0.3007 - val_acc: 0.9147\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9526\n",
      "Epoch 00056: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1600 - acc: 0.9526 - val_loss: 0.2977 - val_acc: 0.9157\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9520\n",
      "Epoch 00057: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1622 - acc: 0.9519 - val_loss: 0.2862 - val_acc: 0.9189\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9504\n",
      "Epoch 00058: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1635 - acc: 0.9503 - val_loss: 0.3162 - val_acc: 0.9113\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9565\n",
      "Epoch 00059: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1501 - acc: 0.9565 - val_loss: 0.2945 - val_acc: 0.9145\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9550\n",
      "Epoch 00060: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1508 - acc: 0.9550 - val_loss: 0.3376 - val_acc: 0.9026\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9579\n",
      "Epoch 00061: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1425 - acc: 0.9579 - val_loss: 0.2889 - val_acc: 0.9157\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9591\n",
      "Epoch 00062: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1393 - acc: 0.9591 - val_loss: 0.2827 - val_acc: 0.9201\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9589\n",
      "Epoch 00063: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1379 - acc: 0.9588 - val_loss: 0.2881 - val_acc: 0.9115\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9576\n",
      "Epoch 00064: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1392 - acc: 0.9576 - val_loss: 0.2952 - val_acc: 0.9175\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9566\n",
      "Epoch 00065: val_loss did not improve from 0.27682\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1419 - acc: 0.9566 - val_loss: 0.2916 - val_acc: 0.9196\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9613\n",
      "Epoch 00066: val_loss improved from 0.27682 to 0.27196, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_8_conv_checkpoint/066-0.2720.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1293 - acc: 0.9613 - val_loss: 0.2720 - val_acc: 0.9227\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9630\n",
      "Epoch 00067: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1253 - acc: 0.9630 - val_loss: 0.2975 - val_acc: 0.9171\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9631\n",
      "Epoch 00068: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1262 - acc: 0.9630 - val_loss: 0.2726 - val_acc: 0.9234\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9624\n",
      "Epoch 00069: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1277 - acc: 0.9623 - val_loss: 0.2834 - val_acc: 0.9136\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9633\n",
      "Epoch 00070: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1233 - acc: 0.9633 - val_loss: 0.2768 - val_acc: 0.9187\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1204 - acc: 0.9636\n",
      "Epoch 00071: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1205 - acc: 0.9636 - val_loss: 0.2900 - val_acc: 0.9194\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9647\n",
      "Epoch 00072: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1186 - acc: 0.9646 - val_loss: 0.2916 - val_acc: 0.9150\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9635\n",
      "Epoch 00073: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1231 - acc: 0.9635 - val_loss: 0.2753 - val_acc: 0.9248\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9670\n",
      "Epoch 00074: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1135 - acc: 0.9669 - val_loss: 0.3479 - val_acc: 0.9078\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9657\n",
      "Epoch 00075: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1149 - acc: 0.9657 - val_loss: 0.2935 - val_acc: 0.9129\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9688\n",
      "Epoch 00076: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1063 - acc: 0.9687 - val_loss: 0.3185 - val_acc: 0.9038\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9663\n",
      "Epoch 00077: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1129 - acc: 0.9662 - val_loss: 0.3189 - val_acc: 0.9108\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9697\n",
      "Epoch 00078: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1037 - acc: 0.9697 - val_loss: 0.2965 - val_acc: 0.9185\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9685\n",
      "Epoch 00079: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1059 - acc: 0.9685 - val_loss: 0.2945 - val_acc: 0.9180\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9718\n",
      "Epoch 00080: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0988 - acc: 0.9719 - val_loss: 0.2890 - val_acc: 0.9201\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9726\n",
      "Epoch 00081: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0974 - acc: 0.9725 - val_loss: 0.3646 - val_acc: 0.9078\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9666\n",
      "Epoch 00082: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1129 - acc: 0.9666 - val_loss: 0.3014 - val_acc: 0.9161\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9675\n",
      "Epoch 00083: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1068 - acc: 0.9675 - val_loss: 0.3200 - val_acc: 0.9126\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9725\n",
      "Epoch 00084: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0923 - acc: 0.9724 - val_loss: 0.2897 - val_acc: 0.9185\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9733\n",
      "Epoch 00085: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0924 - acc: 0.9732 - val_loss: 0.3177 - val_acc: 0.9166\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9690\n",
      "Epoch 00086: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1060 - acc: 0.9689 - val_loss: 0.2896 - val_acc: 0.9217\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9756\n",
      "Epoch 00087: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0847 - acc: 0.9756 - val_loss: 0.3009 - val_acc: 0.9168\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9754\n",
      "Epoch 00088: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0855 - acc: 0.9754 - val_loss: 0.2944 - val_acc: 0.9199\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9758\n",
      "Epoch 00089: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0843 - acc: 0.9757 - val_loss: 0.4024 - val_acc: 0.8917\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9730\n",
      "Epoch 00090: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0909 - acc: 0.9730 - val_loss: 0.2898 - val_acc: 0.9217\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9771\n",
      "Epoch 00091: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0802 - acc: 0.9770 - val_loss: 0.3231 - val_acc: 0.9171\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9741\n",
      "Epoch 00092: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0885 - acc: 0.9741 - val_loss: 0.3035 - val_acc: 0.9178\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9770\n",
      "Epoch 00093: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0822 - acc: 0.9769 - val_loss: 0.3509 - val_acc: 0.9061\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9770\n",
      "Epoch 00094: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0820 - acc: 0.9770 - val_loss: 0.3277 - val_acc: 0.9113\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9782\n",
      "Epoch 00095: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0781 - acc: 0.9782 - val_loss: 0.3517 - val_acc: 0.9092\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9730\n",
      "Epoch 00096: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0894 - acc: 0.9730 - val_loss: 0.3159 - val_acc: 0.9126\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9648\n",
      "Epoch 00097: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1123 - acc: 0.9648 - val_loss: 0.2915 - val_acc: 0.9185\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9793\n",
      "Epoch 00098: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0734 - acc: 0.9794 - val_loss: 0.3347 - val_acc: 0.9124\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9808\n",
      "Epoch 00099: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0684 - acc: 0.9807 - val_loss: 0.2925 - val_acc: 0.9227\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9787\n",
      "Epoch 00100: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0740 - acc: 0.9787 - val_loss: 0.3234 - val_acc: 0.9159\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9797\n",
      "Epoch 00101: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0702 - acc: 0.9797 - val_loss: 0.3316 - val_acc: 0.9152\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9786\n",
      "Epoch 00102: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0749 - acc: 0.9785 - val_loss: 0.3267 - val_acc: 0.9103\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9717\n",
      "Epoch 00103: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0905 - acc: 0.9717 - val_loss: 0.3154 - val_acc: 0.9180\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9798\n",
      "Epoch 00104: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0696 - acc: 0.9798 - val_loss: 0.3105 - val_acc: 0.9157\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9805\n",
      "Epoch 00105: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0680 - acc: 0.9804 - val_loss: 0.3063 - val_acc: 0.9175\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9810\n",
      "Epoch 00106: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0666 - acc: 0.9810 - val_loss: 0.3275 - val_acc: 0.9150\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9787\n",
      "Epoch 00107: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0716 - acc: 0.9786 - val_loss: 0.3265 - val_acc: 0.9180\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9707\n",
      "Epoch 00108: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0946 - acc: 0.9706 - val_loss: 0.3126 - val_acc: 0.9171\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9809\n",
      "Epoch 00109: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0672 - acc: 0.9809 - val_loss: 0.3048 - val_acc: 0.9187\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9841\n",
      "Epoch 00110: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0578 - acc: 0.9841 - val_loss: 0.3480 - val_acc: 0.9092\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9775\n",
      "Epoch 00111: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0748 - acc: 0.9775 - val_loss: 0.3127 - val_acc: 0.9206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9834\n",
      "Epoch 00112: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0593 - acc: 0.9834 - val_loss: 0.3128 - val_acc: 0.9203\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9847\n",
      "Epoch 00113: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0573 - acc: 0.9846 - val_loss: 0.3249 - val_acc: 0.9161\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9789\n",
      "Epoch 00114: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0700 - acc: 0.9789 - val_loss: 0.3512 - val_acc: 0.9140\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9814\n",
      "Epoch 00115: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0657 - acc: 0.9814 - val_loss: 0.3259 - val_acc: 0.9129\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9837\n",
      "Epoch 00116: val_loss did not improve from 0.27196\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0580 - acc: 0.9838 - val_loss: 0.3424 - val_acc: 0.9138\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 988us/sample - loss: 0.3589 - acc: 0.9022\n",
      "Loss: 0.3588696733380156 Accuracy: 0.9021807\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5289 - acc: 0.2202\n",
      "Epoch 00001: val_loss improved from inf to 2.27535, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/001-2.2754.hdf5\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 2.5287 - acc: 0.2203 - val_loss: 2.2754 - val_acc: 0.2895\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8754 - acc: 0.4136\n",
      "Epoch 00002: val_loss improved from 2.27535 to 1.62337, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/002-1.6234.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.8754 - acc: 0.4137 - val_loss: 1.6234 - val_acc: 0.5120\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5353 - acc: 0.5274\n",
      "Epoch 00003: val_loss improved from 1.62337 to 1.33448, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/003-1.3345.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.5352 - acc: 0.5273 - val_loss: 1.3345 - val_acc: 0.5926\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2906 - acc: 0.6039\n",
      "Epoch 00004: val_loss improved from 1.33448 to 1.11682, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/004-1.1168.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.2906 - acc: 0.6038 - val_loss: 1.1168 - val_acc: 0.6620\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1129 - acc: 0.6687\n",
      "Epoch 00005: val_loss improved from 1.11682 to 0.96249, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/005-0.9625.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.1131 - acc: 0.6686 - val_loss: 0.9625 - val_acc: 0.7163\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9745 - acc: 0.7156\n",
      "Epoch 00006: val_loss improved from 0.96249 to 0.88362, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/006-0.8836.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9745 - acc: 0.7156 - val_loss: 0.8836 - val_acc: 0.7536\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8602 - acc: 0.7533\n",
      "Epoch 00007: val_loss improved from 0.88362 to 0.78507, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/007-0.7851.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8602 - acc: 0.7533 - val_loss: 0.7851 - val_acc: 0.7754\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7785 - acc: 0.7740\n",
      "Epoch 00008: val_loss improved from 0.78507 to 0.70681, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/008-0.7068.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7785 - acc: 0.7741 - val_loss: 0.7068 - val_acc: 0.7945\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7042 - acc: 0.7985\n",
      "Epoch 00009: val_loss improved from 0.70681 to 0.62693, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/009-0.6269.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7042 - acc: 0.7985 - val_loss: 0.6269 - val_acc: 0.8199\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6480 - acc: 0.8132\n",
      "Epoch 00010: val_loss improved from 0.62693 to 0.59319, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/010-0.5932.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6483 - acc: 0.8132 - val_loss: 0.5932 - val_acc: 0.8295\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6020 - acc: 0.8268\n",
      "Epoch 00011: val_loss improved from 0.59319 to 0.55647, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/011-0.5565.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6020 - acc: 0.8268 - val_loss: 0.5565 - val_acc: 0.8446\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5556 - acc: 0.8393\n",
      "Epoch 00012: val_loss improved from 0.55647 to 0.48404, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/012-0.4840.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5556 - acc: 0.8393 - val_loss: 0.4840 - val_acc: 0.8595\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5201 - acc: 0.8485\n",
      "Epoch 00013: val_loss improved from 0.48404 to 0.45352, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/013-0.4535.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5202 - acc: 0.8485 - val_loss: 0.4535 - val_acc: 0.8686\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4895 - acc: 0.8584\n",
      "Epoch 00014: val_loss improved from 0.45352 to 0.44804, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/014-0.4480.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4896 - acc: 0.8583 - val_loss: 0.4480 - val_acc: 0.8668\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4642 - acc: 0.8682\n",
      "Epoch 00015: val_loss did not improve from 0.44804\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4641 - acc: 0.8682 - val_loss: 0.4682 - val_acc: 0.8593\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4393 - acc: 0.8714\n",
      "Epoch 00016: val_loss improved from 0.44804 to 0.41741, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/016-0.4174.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4395 - acc: 0.8714 - val_loss: 0.4174 - val_acc: 0.8749\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4235 - acc: 0.8754\n",
      "Epoch 00017: val_loss improved from 0.41741 to 0.41472, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/017-0.4147.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4235 - acc: 0.8754 - val_loss: 0.4147 - val_acc: 0.8765\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4016 - acc: 0.8826\n",
      "Epoch 00018: val_loss improved from 0.41472 to 0.39144, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/018-0.3914.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4016 - acc: 0.8826 - val_loss: 0.3914 - val_acc: 0.8845\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3850 - acc: 0.8876\n",
      "Epoch 00019: val_loss improved from 0.39144 to 0.38282, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/019-0.3828.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3850 - acc: 0.8876 - val_loss: 0.3828 - val_acc: 0.8868\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3710 - acc: 0.8910\n",
      "Epoch 00020: val_loss improved from 0.38282 to 0.35876, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/020-0.3588.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3713 - acc: 0.8909 - val_loss: 0.3588 - val_acc: 0.8933\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3555 - acc: 0.8960\n",
      "Epoch 00021: val_loss improved from 0.35876 to 0.35709, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/021-0.3571.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3555 - acc: 0.8959 - val_loss: 0.3571 - val_acc: 0.8912\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3396 - acc: 0.8992\n",
      "Epoch 00022: val_loss improved from 0.35709 to 0.35502, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/022-0.3550.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3398 - acc: 0.8992 - val_loss: 0.3550 - val_acc: 0.8963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.9023\n",
      "Epoch 00023: val_loss improved from 0.35502 to 0.35331, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/023-0.3533.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3314 - acc: 0.9022 - val_loss: 0.3533 - val_acc: 0.8952\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3178 - acc: 0.9071\n",
      "Epoch 00024: val_loss improved from 0.35331 to 0.34279, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/024-0.3428.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3179 - acc: 0.9070 - val_loss: 0.3428 - val_acc: 0.8959\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3104 - acc: 0.9077\n",
      "Epoch 00025: val_loss improved from 0.34279 to 0.31432, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/025-0.3143.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3103 - acc: 0.9076 - val_loss: 0.3143 - val_acc: 0.9061\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2974 - acc: 0.9130\n",
      "Epoch 00026: val_loss improved from 0.31432 to 0.30495, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/026-0.3050.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2974 - acc: 0.9131 - val_loss: 0.3050 - val_acc: 0.9103\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2907 - acc: 0.9137\n",
      "Epoch 00027: val_loss improved from 0.30495 to 0.30043, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/027-0.3004.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2907 - acc: 0.9137 - val_loss: 0.3004 - val_acc: 0.9096\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2819 - acc: 0.9165\n",
      "Epoch 00028: val_loss did not improve from 0.30043\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2821 - acc: 0.9165 - val_loss: 0.3074 - val_acc: 0.9078\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2810 - acc: 0.9176\n",
      "Epoch 00029: val_loss did not improve from 0.30043\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2810 - acc: 0.9176 - val_loss: 0.3161 - val_acc: 0.9015\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2650 - acc: 0.9201\n",
      "Epoch 00030: val_loss improved from 0.30043 to 0.28396, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/030-0.2840.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2650 - acc: 0.9201 - val_loss: 0.2840 - val_acc: 0.9161\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2567 - acc: 0.9230\n",
      "Epoch 00031: val_loss did not improve from 0.28396\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2567 - acc: 0.9231 - val_loss: 0.2876 - val_acc: 0.9108\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2498 - acc: 0.9255\n",
      "Epoch 00032: val_loss did not improve from 0.28396\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2497 - acc: 0.9255 - val_loss: 0.2860 - val_acc: 0.9096\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2405 - acc: 0.9284\n",
      "Epoch 00033: val_loss did not improve from 0.28396\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2405 - acc: 0.9284 - val_loss: 0.2928 - val_acc: 0.9129\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2391 - acc: 0.9288\n",
      "Epoch 00034: val_loss improved from 0.28396 to 0.28232, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/034-0.2823.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2391 - acc: 0.9287 - val_loss: 0.2823 - val_acc: 0.9147\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2324 - acc: 0.9299\n",
      "Epoch 00035: val_loss improved from 0.28232 to 0.28024, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/035-0.2802.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2325 - acc: 0.9298 - val_loss: 0.2802 - val_acc: 0.9108\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2236 - acc: 0.9327\n",
      "Epoch 00036: val_loss did not improve from 0.28024\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2236 - acc: 0.9327 - val_loss: 0.2875 - val_acc: 0.9147\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2202 - acc: 0.9339\n",
      "Epoch 00037: val_loss improved from 0.28024 to 0.27566, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/037-0.2757.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2203 - acc: 0.9339 - val_loss: 0.2757 - val_acc: 0.9224\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2158 - acc: 0.9355\n",
      "Epoch 00038: val_loss did not improve from 0.27566\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2160 - acc: 0.9354 - val_loss: 0.2828 - val_acc: 0.9131\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2137 - acc: 0.9339\n",
      "Epoch 00039: val_loss improved from 0.27566 to 0.27449, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/039-0.2745.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2138 - acc: 0.9338 - val_loss: 0.2745 - val_acc: 0.9147\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2038 - acc: 0.9388\n",
      "Epoch 00040: val_loss did not improve from 0.27449\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2038 - acc: 0.9387 - val_loss: 0.2759 - val_acc: 0.9196\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1973 - acc: 0.9402\n",
      "Epoch 00041: val_loss did not improve from 0.27449\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1973 - acc: 0.9402 - val_loss: 0.2785 - val_acc: 0.9203\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1929 - acc: 0.9414\n",
      "Epoch 00042: val_loss did not improve from 0.27449\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1928 - acc: 0.9414 - val_loss: 0.2966 - val_acc: 0.9129\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1875 - acc: 0.9428\n",
      "Epoch 00043: val_loss improved from 0.27449 to 0.26239, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/043-0.2624.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1875 - acc: 0.9428 - val_loss: 0.2624 - val_acc: 0.9224\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1848 - acc: 0.9447\n",
      "Epoch 00044: val_loss did not improve from 0.26239\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1849 - acc: 0.9447 - val_loss: 0.2970 - val_acc: 0.9119\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1836 - acc: 0.9447\n",
      "Epoch 00045: val_loss did not improve from 0.26239\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1836 - acc: 0.9447 - val_loss: 0.2708 - val_acc: 0.9196\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1782 - acc: 0.9455\n",
      "Epoch 00046: val_loss did not improve from 0.26239\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1784 - acc: 0.9454 - val_loss: 0.2861 - val_acc: 0.9171\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1794 - acc: 0.9461\n",
      "Epoch 00047: val_loss did not improve from 0.26239\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1796 - acc: 0.9460 - val_loss: 0.2641 - val_acc: 0.9175\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9461\n",
      "Epoch 00048: val_loss did not improve from 0.26239\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1758 - acc: 0.9461 - val_loss: 0.2703 - val_acc: 0.9187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1727 - acc: 0.9483\n",
      "Epoch 00049: val_loss did not improve from 0.26239\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1728 - acc: 0.9483 - val_loss: 0.2661 - val_acc: 0.9208\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1615 - acc: 0.9511\n",
      "Epoch 00050: val_loss did not improve from 0.26239\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1616 - acc: 0.9510 - val_loss: 0.2674 - val_acc: 0.9196\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1648 - acc: 0.9508\n",
      "Epoch 00051: val_loss did not improve from 0.26239\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1650 - acc: 0.9508 - val_loss: 0.2833 - val_acc: 0.9159\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1593 - acc: 0.9504\n",
      "Epoch 00052: val_loss did not improve from 0.26239\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1596 - acc: 0.9503 - val_loss: 0.2747 - val_acc: 0.9182\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9517\n",
      "Epoch 00053: val_loss did not improve from 0.26239\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1566 - acc: 0.9517 - val_loss: 0.2680 - val_acc: 0.9224\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1479 - acc: 0.9552\n",
      "Epoch 00054: val_loss improved from 0.26239 to 0.26177, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/054-0.2618.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1481 - acc: 0.9551 - val_loss: 0.2618 - val_acc: 0.9262\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1539 - acc: 0.9526\n",
      "Epoch 00055: val_loss improved from 0.26177 to 0.25140, saving model to model/checkpoint/1D_CNN_custom_4_ch_64_BN_9_conv_checkpoint/055-0.2514.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1539 - acc: 0.9526 - val_loss: 0.2514 - val_acc: 0.9259\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1427 - acc: 0.9565\n",
      "Epoch 00056: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1428 - acc: 0.9565 - val_loss: 0.2757 - val_acc: 0.9192\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9571\n",
      "Epoch 00057: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1407 - acc: 0.9571 - val_loss: 0.3140 - val_acc: 0.9087\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9592\n",
      "Epoch 00058: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1358 - acc: 0.9592 - val_loss: 0.2818 - val_acc: 0.9210\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1359 - acc: 0.9587\n",
      "Epoch 00059: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1360 - acc: 0.9587 - val_loss: 0.2662 - val_acc: 0.9215\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9591\n",
      "Epoch 00060: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1336 - acc: 0.9591 - val_loss: 0.2928 - val_acc: 0.9157\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9596\n",
      "Epoch 00061: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1328 - acc: 0.9596 - val_loss: 0.2714 - val_acc: 0.9238\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9609\n",
      "Epoch 00062: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1274 - acc: 0.9609 - val_loss: 0.2757 - val_acc: 0.9201\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9598\n",
      "Epoch 00063: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1279 - acc: 0.9598 - val_loss: 0.2760 - val_acc: 0.9206\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9616\n",
      "Epoch 00064: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1239 - acc: 0.9616 - val_loss: 0.2767 - val_acc: 0.9203\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9634\n",
      "Epoch 00065: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1209 - acc: 0.9634 - val_loss: 0.2649 - val_acc: 0.9255\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9639\n",
      "Epoch 00066: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1201 - acc: 0.9638 - val_loss: 0.2730 - val_acc: 0.9189\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1224 - acc: 0.9616\n",
      "Epoch 00067: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1227 - acc: 0.9615 - val_loss: 0.2673 - val_acc: 0.9222\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9618\n",
      "Epoch 00068: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1221 - acc: 0.9618 - val_loss: 0.2829 - val_acc: 0.9210\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9662\n",
      "Epoch 00069: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1119 - acc: 0.9661 - val_loss: 0.2767 - val_acc: 0.9210\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9606\n",
      "Epoch 00070: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1272 - acc: 0.9606 - val_loss: 0.2822 - val_acc: 0.9224\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9690\n",
      "Epoch 00071: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1030 - acc: 0.9689 - val_loss: 0.2709 - val_acc: 0.9271\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9672\n",
      "Epoch 00072: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1072 - acc: 0.9672 - val_loss: 0.2671 - val_acc: 0.9245\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9698\n",
      "Epoch 00073: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1003 - acc: 0.9697 - val_loss: 0.2794 - val_acc: 0.9259\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9670\n",
      "Epoch 00074: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1073 - acc: 0.9670 - val_loss: 0.2995 - val_acc: 0.9180\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9694\n",
      "Epoch 00075: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1008 - acc: 0.9694 - val_loss: 0.2885 - val_acc: 0.9175\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9680\n",
      "Epoch 00076: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1040 - acc: 0.9680 - val_loss: 0.2835 - val_acc: 0.9227\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9684\n",
      "Epoch 00077: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1026 - acc: 0.9683 - val_loss: 0.3160 - val_acc: 0.9157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9729\n",
      "Epoch 00078: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0917 - acc: 0.9728 - val_loss: 0.2828 - val_acc: 0.9238\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9718\n",
      "Epoch 00079: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0939 - acc: 0.9717 - val_loss: 0.2961 - val_acc: 0.9238\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9685\n",
      "Epoch 00080: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1015 - acc: 0.9685 - val_loss: 0.2764 - val_acc: 0.9266\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9719\n",
      "Epoch 00081: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0928 - acc: 0.9719 - val_loss: 0.2917 - val_acc: 0.9220\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9720\n",
      "Epoch 00082: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0894 - acc: 0.9720 - val_loss: 0.2887 - val_acc: 0.9245\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9728\n",
      "Epoch 00083: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0895 - acc: 0.9728 - val_loss: 0.2768 - val_acc: 0.9250\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9738\n",
      "Epoch 00084: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0870 - acc: 0.9738 - val_loss: 0.3102 - val_acc: 0.9133\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9671\n",
      "Epoch 00085: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1056 - acc: 0.9671 - val_loss: 0.2911 - val_acc: 0.9222\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9749\n",
      "Epoch 00086: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0811 - acc: 0.9749 - val_loss: 0.3111 - val_acc: 0.9173\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9767\n",
      "Epoch 00087: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0781 - acc: 0.9767 - val_loss: 0.3119 - val_acc: 0.9164\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9733\n",
      "Epoch 00088: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0874 - acc: 0.9732 - val_loss: 0.3103 - val_acc: 0.9213\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9745\n",
      "Epoch 00089: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0860 - acc: 0.9745 - val_loss: 0.2969 - val_acc: 0.9264\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9759\n",
      "Epoch 00090: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0806 - acc: 0.9758 - val_loss: 0.2888 - val_acc: 0.9250\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9760\n",
      "Epoch 00091: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0779 - acc: 0.9760 - val_loss: 0.3017 - val_acc: 0.9248\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9776\n",
      "Epoch 00092: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0737 - acc: 0.9775 - val_loss: 0.3087 - val_acc: 0.9206\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9777\n",
      "Epoch 00093: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0727 - acc: 0.9777 - val_loss: 0.2995 - val_acc: 0.9257\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9726\n",
      "Epoch 00094: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0868 - acc: 0.9726 - val_loss: 0.2975 - val_acc: 0.9234\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9791\n",
      "Epoch 00095: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0692 - acc: 0.9791 - val_loss: 0.3057 - val_acc: 0.9187\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9775\n",
      "Epoch 00096: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0736 - acc: 0.9775 - val_loss: 0.2934 - val_acc: 0.9185\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9787\n",
      "Epoch 00097: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0716 - acc: 0.9786 - val_loss: 0.3181 - val_acc: 0.9161\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9762\n",
      "Epoch 00098: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0786 - acc: 0.9762 - val_loss: 0.2893 - val_acc: 0.9273\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9769\n",
      "Epoch 00099: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0763 - acc: 0.9768 - val_loss: 0.3296 - val_acc: 0.9145\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9726\n",
      "Epoch 00100: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0881 - acc: 0.9726 - val_loss: 0.2883 - val_acc: 0.9245\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9820\n",
      "Epoch 00101: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0624 - acc: 0.9820 - val_loss: 0.3386 - val_acc: 0.9150\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9788\n",
      "Epoch 00102: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0707 - acc: 0.9788 - val_loss: 0.2889 - val_acc: 0.9238\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9786\n",
      "Epoch 00103: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0696 - acc: 0.9786 - val_loss: 0.3033 - val_acc: 0.9236\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9791\n",
      "Epoch 00104: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0677 - acc: 0.9791 - val_loss: 0.3002 - val_acc: 0.9210\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9798\n",
      "Epoch 00105: val_loss did not improve from 0.25140\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0668 - acc: 0.9798 - val_loss: 0.3047 - val_acc: 0.9250\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.3331 - acc: 0.9067\n",
      "Loss: 0.3330987807065403 Accuracy: 0.9067497\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(4, 10):\n",
    "    base = '1D_CNN_custom_4_ch_64_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_4_ch_64_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 18944)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 18944)             75776     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                303120    \n",
      "=================================================================\n",
      "Total params: 431,536\n",
      "Trainable params: 393,200\n",
      "Non-trainable params: 38,336\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.2374 - acc: 0.6426\n",
      "Loss: 1.2374102445901491 Accuracy: 0.64257526\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 6304)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 6304)              25216     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                100880    \n",
      "=================================================================\n",
      "Total params: 184,016\n",
      "Trainable params: 170,896\n",
      "Non-trainable params: 13,120\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.8586 - acc: 0.7373\n",
      "Loss: 0.8586242485021629 Accuracy: 0.73727936\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 197, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 2080)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 2080)              8320      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                33296     \n",
      "=================================================================\n",
      "Total params: 104,816\n",
      "Trainable params: 100,080\n",
      "Non-trainable params: 4,736\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.5741 - acc: 0.8363\n",
      "Loss: 0.574137274684193 Accuracy: 0.8363448\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 197, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 16)            2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 65, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 336)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 336)               1344      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                5392      \n",
      "=================================================================\n",
      "Total params: 72,576\n",
      "Trainable params: 71,296\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.4625 - acc: 0.8654\n",
      "Loss: 0.46254912905727713 Accuracy: 0.8654206\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 197, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 16)            2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 65, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 16)            1296      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 112)               448       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                1808      \n",
      "=================================================================\n",
      "Total params: 69,456\n",
      "Trainable params: 68,592\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.3589 - acc: 0.9022\n",
      "Loss: 0.3588696733380156 Accuracy: 0.9021807\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 16)            2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 16)            1296      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 16)             1296      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 7, 16)             64        \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 69,216\n",
      "Trainable params: 68,480\n",
      "Non-trainable params: 736\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3331 - acc: 0.9067\n",
      "Loss: 0.3330987807065403 Accuracy: 0.9067497\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_4_ch_64_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(4, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_4_ch_64_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 18944)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 18944)             75776     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                303120    \n",
      "=================================================================\n",
      "Total params: 431,536\n",
      "Trainable params: 393,200\n",
      "Non-trainable params: 38,336\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 2.2050 - acc: 0.6106\n",
      "Loss: 2.2049991533887474 Accuracy: 0.6105919\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 6304)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 6304)              25216     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                100880    \n",
      "=================================================================\n",
      "Total params: 184,016\n",
      "Trainable params: 170,896\n",
      "Non-trainable params: 13,120\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.3736 - acc: 0.7043\n",
      "Loss: 1.3735831491672361 Accuracy: 0.70425755\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_54 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 197, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 197, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 2080)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 2080)              8320      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                33296     \n",
      "=================================================================\n",
      "Total params: 104,816\n",
      "Trainable params: 100,080\n",
      "Non-trainable params: 4,736\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.7174 - acc: 0.8359\n",
      "Loss: 0.7174327435399389 Accuracy: 0.8359294\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 197, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 65, 16)            2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 65, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 65, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 336)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 336)               1344      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                5392      \n",
      "=================================================================\n",
      "Total params: 72,576\n",
      "Trainable params: 71,296\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.5084 - acc: 0.8748\n",
      "Loss: 0.5084045664791254 Accuracy: 0.87476635\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 197, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 197, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 65, 16)            2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 65, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 65, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 21, 16)            1296      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 112)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 112)               448       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                1808      \n",
      "=================================================================\n",
      "Total params: 69,456\n",
      "Trainable params: 68,592\n",
      "Non-trainable params: 864\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4245 - acc: 0.8968\n",
      "Loss: 0.4245051181305544 Accuracy: 0.8967809\n",
      "\n",
      "1D_CNN_custom_4_ch_64_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 32)          10272     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 1777, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 592, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 592, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 592, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 197, 32)           5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 197, 32)           128       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 197, 32)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 65, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 65, 16)            2576      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 65, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 65, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 21, 16)            1296      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 21, 16)            64        \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 21, 16)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 7, 16)             1296      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 7, 16)             64        \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 7, 16)             0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2, 16)             0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 69,216\n",
      "Trainable params: 68,480\n",
      "Non-trainable params: 736\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3986 - acc: 0.9032\n",
      "Loss: 0.39860395674641136 Accuracy: 0.9032191\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(4, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
