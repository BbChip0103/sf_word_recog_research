{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_ch_32_BN_2(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=32, strides=1, \n",
    "                      padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=32*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())    \n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 512000)            2048000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                8192016   \n",
      "=================================================================\n",
      "Total params: 10,240,336\n",
      "Trainable params: 9,216,272\n",
      "Non-trainable params: 1,024,064\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 256000)            1024000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                4096016   \n",
      "=================================================================\n",
      "Total params: 5,125,616\n",
      "Trainable params: 4,613,488\n",
      "Non-trainable params: 512,128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 128000)            512000    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,570,896\n",
      "Trainable params: 2,314,704\n",
      "Non-trainable params: 256,192\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 64000)             256000    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,296,176\n",
      "Trainable params: 1,167,920\n",
      "Non-trainable params: 128,256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 64000)             256000    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,306,736\n",
      "Trainable params: 1,178,352\n",
      "Non-trainable params: 128,384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 32000)             128000    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 687,536\n",
      "Trainable params: 623,024\n",
      "Non-trainable params: 64,512\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 16000)             64000     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 388,336\n",
      "Trainable params: 355,696\n",
      "Non-trainable params: 32,640\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 8000)              32000     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                128016    \n",
      "=================================================================\n",
      "Total params: 249,136\n",
      "Trainable params: 232,368\n",
      "Non-trainable params: 16,768\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 7936)              31744     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 289,456\n",
      "Trainable params: 272,560\n",
      "Non-trainable params: 16,896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 3968)              15872     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                63504     \n",
      "=================================================================\n",
      "Total params: 292,656\n",
      "Trainable params: 283,440\n",
      "Non-trainable params: 9,216\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 1920)              7680      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                30736     \n",
      "=================================================================\n",
      "Total params: 334,256\n",
      "Trainable params: 328,880\n",
      "Non-trainable params: 5,376\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 15, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 396,336\n",
      "Trainable params: 392,752\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 15, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                12304     \n",
      "=================================================================\n",
      "Total params: 558,896\n",
      "Trainable params: 555,056\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 14):\n",
    "    model = build_1d_cnn_custom_ch_32_BN_2(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4825 - acc: 0.3888\n",
      "Epoch 00001: val_loss improved from inf to 2.36079, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_3_conv_checkpoint/001-2.3608.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 2.4827 - acc: 0.3888 - val_loss: 2.3608 - val_acc: 0.3392\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8425 - acc: 0.7620\n",
      "Epoch 00002: val_loss did not improve from 2.36079\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.8426 - acc: 0.7619 - val_loss: 2.4083 - val_acc: 0.4232\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3540 - acc: 0.9114\n",
      "Epoch 00003: val_loss improved from 2.36079 to 2.29884, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_3_conv_checkpoint/003-2.2988.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3540 - acc: 0.9114 - val_loss: 2.2988 - val_acc: 0.4624\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1938 - acc: 0.9604\n",
      "Epoch 00004: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1940 - acc: 0.9603 - val_loss: 2.3272 - val_acc: 0.4810\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1537 - acc: 0.9726\n",
      "Epoch 00005: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1538 - acc: 0.9726 - val_loss: 2.6887 - val_acc: 0.4689\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9818\n",
      "Epoch 00006: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1123 - acc: 0.9818 - val_loss: 2.5515 - val_acc: 0.4736\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9862\n",
      "Epoch 00007: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0891 - acc: 0.9862 - val_loss: 2.6664 - val_acc: 0.4759\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9864\n",
      "Epoch 00008: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0836 - acc: 0.9864 - val_loss: 3.0061 - val_acc: 0.4580\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9863\n",
      "Epoch 00009: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0811 - acc: 0.9863 - val_loss: 3.4456 - val_acc: 0.4186\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9748\n",
      "Epoch 00010: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1183 - acc: 0.9748 - val_loss: 3.5302 - val_acc: 0.4270\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9824\n",
      "Epoch 00011: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0852 - acc: 0.9823 - val_loss: 3.3887 - val_acc: 0.4563\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9817\n",
      "Epoch 00012: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0871 - acc: 0.9816 - val_loss: 3.7201 - val_acc: 0.4465\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9818\n",
      "Epoch 00013: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0821 - acc: 0.9817 - val_loss: 3.5145 - val_acc: 0.4512\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9810\n",
      "Epoch 00014: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0881 - acc: 0.9809 - val_loss: 3.4560 - val_acc: 0.4703\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9832\n",
      "Epoch 00015: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0804 - acc: 0.9832 - val_loss: 4.1108 - val_acc: 0.4503\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9849\n",
      "Epoch 00016: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0738 - acc: 0.9848 - val_loss: 3.7074 - val_acc: 0.4549\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9884\n",
      "Epoch 00017: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0595 - acc: 0.9884 - val_loss: 4.0039 - val_acc: 0.4610\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9913\n",
      "Epoch 00018: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0515 - acc: 0.9913 - val_loss: 3.8269 - val_acc: 0.4654\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9874\n",
      "Epoch 00019: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0676 - acc: 0.9874 - val_loss: 3.9867 - val_acc: 0.4638\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9868\n",
      "Epoch 00020: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0663 - acc: 0.9868 - val_loss: 4.6568 - val_acc: 0.4125\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9898\n",
      "Epoch 00021: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0565 - acc: 0.9898 - val_loss: 4.3627 - val_acc: 0.4444\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9868\n",
      "Epoch 00022: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0723 - acc: 0.9868 - val_loss: 4.8228 - val_acc: 0.4163\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9888\n",
      "Epoch 00023: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0632 - acc: 0.9888 - val_loss: 5.5621 - val_acc: 0.3683\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9884\n",
      "Epoch 00024: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0621 - acc: 0.9884 - val_loss: 4.8079 - val_acc: 0.4258\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9916\n",
      "Epoch 00025: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0537 - acc: 0.9915 - val_loss: 4.4665 - val_acc: 0.4458\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9834\n",
      "Epoch 00026: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0830 - acc: 0.9834 - val_loss: 4.8478 - val_acc: 0.4349\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9911\n",
      "Epoch 00027: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0508 - acc: 0.9910 - val_loss: 4.6519 - val_acc: 0.4563\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9908\n",
      "Epoch 00028: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0535 - acc: 0.9907 - val_loss: 4.5619 - val_acc: 0.4484\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9882\n",
      "Epoch 00029: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0624 - acc: 0.9882 - val_loss: 4.4315 - val_acc: 0.4642\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9902\n",
      "Epoch 00030: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0564 - acc: 0.9902 - val_loss: 4.9427 - val_acc: 0.4342\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9878\n",
      "Epoch 00031: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0641 - acc: 0.9878 - val_loss: 4.5393 - val_acc: 0.4628\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9920\n",
      "Epoch 00032: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0472 - acc: 0.9920 - val_loss: 4.8414 - val_acc: 0.4437\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9918\n",
      "Epoch 00033: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0487 - acc: 0.9918 - val_loss: 4.6123 - val_acc: 0.4705\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9930\n",
      "Epoch 00034: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0471 - acc: 0.9930 - val_loss: 4.7065 - val_acc: 0.4507\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9904\n",
      "Epoch 00035: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0553 - acc: 0.9904 - val_loss: 5.2090 - val_acc: 0.4370\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9933\n",
      "Epoch 00036: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0451 - acc: 0.9933 - val_loss: 5.3221 - val_acc: 0.4281\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9887\n",
      "Epoch 00037: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0618 - acc: 0.9887 - val_loss: 5.0434 - val_acc: 0.4489\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9938\n",
      "Epoch 00038: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0427 - acc: 0.9938 - val_loss: 4.8278 - val_acc: 0.4628\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9930\n",
      "Epoch 00039: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0457 - acc: 0.9930 - val_loss: 5.3233 - val_acc: 0.4430\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9892\n",
      "Epoch 00040: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0595 - acc: 0.9892 - val_loss: 5.5127 - val_acc: 0.4258\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9927\n",
      "Epoch 00041: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0477 - acc: 0.9927 - val_loss: 4.9448 - val_acc: 0.4603\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9926\n",
      "Epoch 00042: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0473 - acc: 0.9926 - val_loss: 5.2500 - val_acc: 0.4486\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9910\n",
      "Epoch 00043: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0520 - acc: 0.9910 - val_loss: 5.4097 - val_acc: 0.4405\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9909\n",
      "Epoch 00044: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0528 - acc: 0.9909 - val_loss: 5.4521 - val_acc: 0.4330\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9920\n",
      "Epoch 00045: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0473 - acc: 0.9920 - val_loss: 5.5575 - val_acc: 0.4221\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9890\n",
      "Epoch 00046: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0634 - acc: 0.9889 - val_loss: 5.4466 - val_acc: 0.4326\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9889\n",
      "Epoch 00047: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0620 - acc: 0.9889 - val_loss: 5.2247 - val_acc: 0.4475\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9927\n",
      "Epoch 00048: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0501 - acc: 0.9926 - val_loss: 5.5069 - val_acc: 0.4456\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9910\n",
      "Epoch 00049: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0542 - acc: 0.9910 - val_loss: 5.2629 - val_acc: 0.4591\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9956\n",
      "Epoch 00050: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0379 - acc: 0.9955 - val_loss: 5.4710 - val_acc: 0.4458\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9896\n",
      "Epoch 00051: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0635 - acc: 0.9895 - val_loss: 5.3644 - val_acc: 0.4461\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9924\n",
      "Epoch 00052: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0515 - acc: 0.9924 - val_loss: 5.3693 - val_acc: 0.4507\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9935\n",
      "Epoch 00053: val_loss did not improve from 2.29884\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0434 - acc: 0.9934 - val_loss: 5.4087 - val_acc: 0.4547\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 540us/sample - loss: 2.4626 - acc: 0.4326\n",
      "Loss: 2.462566647128524 Accuracy: 0.43260643\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1258 - acc: 0.4157\n",
      "Epoch 00001: val_loss improved from inf to 2.19438, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_4_conv_checkpoint/001-2.1944.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 2.1258 - acc: 0.4157 - val_loss: 2.1944 - val_acc: 0.3913\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9862 - acc: 0.7062\n",
      "Epoch 00002: val_loss improved from 2.19438 to 1.60145, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_4_conv_checkpoint/002-1.6014.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.9863 - acc: 0.7062 - val_loss: 1.6014 - val_acc: 0.5579\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5301 - acc: 0.8478\n",
      "Epoch 00003: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5303 - acc: 0.8477 - val_loss: 1.6833 - val_acc: 0.5579\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3094 - acc: 0.9245\n",
      "Epoch 00004: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3096 - acc: 0.9244 - val_loss: 1.6352 - val_acc: 0.5830\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2029 - acc: 0.9582\n",
      "Epoch 00005: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2031 - acc: 0.9581 - val_loss: 1.6861 - val_acc: 0.5761\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9771\n",
      "Epoch 00006: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1407 - acc: 0.9770 - val_loss: 1.8331 - val_acc: 0.5737\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9849\n",
      "Epoch 00007: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1060 - acc: 0.9848 - val_loss: 1.7881 - val_acc: 0.5898\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9879\n",
      "Epoch 00008: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0867 - acc: 0.9878 - val_loss: 2.3904 - val_acc: 0.4978\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9879\n",
      "Epoch 00009: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0798 - acc: 0.9879 - val_loss: 2.0130 - val_acc: 0.5546\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9872\n",
      "Epoch 00010: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0771 - acc: 0.9871 - val_loss: 1.9630 - val_acc: 0.5686\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9914\n",
      "Epoch 00011: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0570 - acc: 0.9914 - val_loss: 2.0825 - val_acc: 0.5672\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9939\n",
      "Epoch 00012: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0456 - acc: 0.9939 - val_loss: 2.2288 - val_acc: 0.5572\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9890\n",
      "Epoch 00013: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0608 - acc: 0.9889 - val_loss: 2.2219 - val_acc: 0.5628\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9923\n",
      "Epoch 00014: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0459 - acc: 0.9923 - val_loss: 2.2496 - val_acc: 0.5616\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9964\n",
      "Epoch 00015: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0305 - acc: 0.9964 - val_loss: 2.1673 - val_acc: 0.5700\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9933\n",
      "Epoch 00016: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0419 - acc: 0.9933 - val_loss: 2.4198 - val_acc: 0.5570\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9935\n",
      "Epoch 00017: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0398 - acc: 0.9935 - val_loss: 2.9101 - val_acc: 0.4966\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9913\n",
      "Epoch 00018: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0460 - acc: 0.9912 - val_loss: 2.6377 - val_acc: 0.5413\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9903\n",
      "Epoch 00019: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0479 - acc: 0.9903 - val_loss: 2.4204 - val_acc: 0.5649\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9946\n",
      "Epoch 00020: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0314 - acc: 0.9946 - val_loss: 2.6095 - val_acc: 0.5467\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9953\n",
      "Epoch 00021: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0297 - acc: 0.9953 - val_loss: 2.6133 - val_acc: 0.5413\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9951\n",
      "Epoch 00022: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0290 - acc: 0.9950 - val_loss: 2.6894 - val_acc: 0.5423\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9919\n",
      "Epoch 00023: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0375 - acc: 0.9919 - val_loss: 2.5878 - val_acc: 0.5588\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9958\n",
      "Epoch 00024: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0274 - acc: 0.9958 - val_loss: 2.7813 - val_acc: 0.5337\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9935\n",
      "Epoch 00025: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0360 - acc: 0.9934 - val_loss: 2.6633 - val_acc: 0.5537\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9936\n",
      "Epoch 00026: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0306 - acc: 0.9936 - val_loss: 2.7427 - val_acc: 0.5516\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9975\n",
      "Epoch 00027: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0192 - acc: 0.9974 - val_loss: 2.7046 - val_acc: 0.5588\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9941\n",
      "Epoch 00028: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0313 - acc: 0.9941 - val_loss: 2.7979 - val_acc: 0.5537\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9935\n",
      "Epoch 00029: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0328 - acc: 0.9935 - val_loss: 2.8725 - val_acc: 0.5441\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9911\n",
      "Epoch 00030: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0434 - acc: 0.9911 - val_loss: 2.7615 - val_acc: 0.5577\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9960\n",
      "Epoch 00031: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0244 - acc: 0.9959 - val_loss: 2.8409 - val_acc: 0.5469\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9968\n",
      "Epoch 00032: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0219 - acc: 0.9967 - val_loss: 2.8458 - val_acc: 0.5644\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9912\n",
      "Epoch 00033: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0406 - acc: 0.9911 - val_loss: 3.1140 - val_acc: 0.5402\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9923\n",
      "Epoch 00034: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0336 - acc: 0.9923 - val_loss: 2.9762 - val_acc: 0.5444\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9964\n",
      "Epoch 00035: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0233 - acc: 0.9963 - val_loss: 2.8934 - val_acc: 0.5537\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9950\n",
      "Epoch 00036: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0276 - acc: 0.9950 - val_loss: 2.9884 - val_acc: 0.5483\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9965\n",
      "Epoch 00037: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0228 - acc: 0.9965 - val_loss: 3.0409 - val_acc: 0.5430\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9962\n",
      "Epoch 00038: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0224 - acc: 0.9962 - val_loss: 3.0504 - val_acc: 0.5495\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9976\n",
      "Epoch 00039: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0180 - acc: 0.9976 - val_loss: 2.9607 - val_acc: 0.5595\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9980\n",
      "Epoch 00040: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0160 - acc: 0.9979 - val_loss: 2.9970 - val_acc: 0.5656\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9926\n",
      "Epoch 00041: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0365 - acc: 0.9926 - val_loss: 3.2022 - val_acc: 0.5486\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9976\n",
      "Epoch 00042: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0179 - acc: 0.9976 - val_loss: 3.5457 - val_acc: 0.5010\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9947\n",
      "Epoch 00043: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0276 - acc: 0.9946 - val_loss: 3.2790 - val_acc: 0.5311\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9940\n",
      "Epoch 00044: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0290 - acc: 0.9939 - val_loss: 3.1875 - val_acc: 0.5418\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9955\n",
      "Epoch 00045: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0258 - acc: 0.9954 - val_loss: 3.5487 - val_acc: 0.5236\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9965\n",
      "Epoch 00046: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0234 - acc: 0.9965 - val_loss: 3.4507 - val_acc: 0.5188\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9958\n",
      "Epoch 00047: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0250 - acc: 0.9958 - val_loss: 3.2960 - val_acc: 0.5418\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9949\n",
      "Epoch 00048: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0268 - acc: 0.9949 - val_loss: 3.3153 - val_acc: 0.5427\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9949\n",
      "Epoch 00049: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0274 - acc: 0.9949 - val_loss: 3.2617 - val_acc: 0.5521\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9975\n",
      "Epoch 00050: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0189 - acc: 0.9975 - val_loss: 3.2376 - val_acc: 0.5504\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9968\n",
      "Epoch 00051: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0209 - acc: 0.9968 - val_loss: 3.6118 - val_acc: 0.5299\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9964\n",
      "Epoch 00052: val_loss did not improve from 1.60145\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0227 - acc: 0.9964 - val_loss: 3.2729 - val_acc: 0.5542\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 595us/sample - loss: 1.8428 - acc: 0.4933\n",
      "Loss: 1.8428133879866555 Accuracy: 0.49325025\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0154 - acc: 0.4495\n",
      "Epoch 00001: val_loss improved from inf to 1.85120, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_5_conv_checkpoint/001-1.8512.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 2.0153 - acc: 0.4495 - val_loss: 1.8512 - val_acc: 0.4503\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9645 - acc: 0.7141\n",
      "Epoch 00002: val_loss did not improve from 1.85120\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.9649 - acc: 0.7140 - val_loss: 1.9953 - val_acc: 0.4945\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5428 - acc: 0.8371\n",
      "Epoch 00003: val_loss did not improve from 1.85120\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.5432 - acc: 0.8371 - val_loss: 1.8807 - val_acc: 0.5306\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3012 - acc: 0.9207\n",
      "Epoch 00004: val_loss improved from 1.85120 to 1.53196, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_5_conv_checkpoint/004-1.5320.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.3016 - acc: 0.9206 - val_loss: 1.5320 - val_acc: 0.6182\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1951 - acc: 0.9558\n",
      "Epoch 00005: val_loss improved from 1.53196 to 1.52244, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_5_conv_checkpoint/005-1.5224.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1952 - acc: 0.9558 - val_loss: 1.5224 - val_acc: 0.6168\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9751\n",
      "Epoch 00006: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1325 - acc: 0.9751 - val_loss: 1.6314 - val_acc: 0.6154\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9866\n",
      "Epoch 00007: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0954 - acc: 0.9865 - val_loss: 1.5947 - val_acc: 0.6175\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9848\n",
      "Epoch 00008: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0915 - acc: 0.9848 - val_loss: 1.6834 - val_acc: 0.6129\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9884\n",
      "Epoch 00009: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0709 - acc: 0.9883 - val_loss: 1.6825 - val_acc: 0.6231\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9903\n",
      "Epoch 00010: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0635 - acc: 0.9903 - val_loss: 1.8269 - val_acc: 0.6110\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9878\n",
      "Epoch 00011: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0664 - acc: 0.9878 - val_loss: 1.9727 - val_acc: 0.5991\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9880\n",
      "Epoch 00012: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0630 - acc: 0.9880 - val_loss: 1.8718 - val_acc: 0.6124\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9910\n",
      "Epoch 00013: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0511 - acc: 0.9910 - val_loss: 2.0054 - val_acc: 0.6040\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9886\n",
      "Epoch 00014: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0559 - acc: 0.9886 - val_loss: 2.0639 - val_acc: 0.5984\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9887\n",
      "Epoch 00015: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0550 - acc: 0.9886 - val_loss: 2.1428 - val_acc: 0.5947\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9891\n",
      "Epoch 00016: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0486 - acc: 0.9891 - val_loss: 2.0127 - val_acc: 0.6094\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9943\n",
      "Epoch 00017: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0343 - acc: 0.9943 - val_loss: 2.1152 - val_acc: 0.6075\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9907\n",
      "Epoch 00018: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0446 - acc: 0.9907 - val_loss: 2.0929 - val_acc: 0.6129\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9926\n",
      "Epoch 00019: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0392 - acc: 0.9925 - val_loss: 2.1582 - val_acc: 0.6203\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9929\n",
      "Epoch 00020: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0365 - acc: 0.9929 - val_loss: 2.1249 - val_acc: 0.6143\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9953\n",
      "Epoch 00021: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0314 - acc: 0.9953 - val_loss: 2.3322 - val_acc: 0.5993\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9935\n",
      "Epoch 00022: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0367 - acc: 0.9935 - val_loss: 2.3000 - val_acc: 0.6052\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9957\n",
      "Epoch 00023: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0263 - acc: 0.9957 - val_loss: 2.3181 - val_acc: 0.5938\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9895\n",
      "Epoch 00024: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0480 - acc: 0.9895 - val_loss: 2.4037 - val_acc: 0.5954\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9905\n",
      "Epoch 00025: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0428 - acc: 0.9905 - val_loss: 2.5850 - val_acc: 0.5691\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9878\n",
      "Epoch 00026: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0517 - acc: 0.9878 - val_loss: 2.3783 - val_acc: 0.6101\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9949\n",
      "Epoch 00027: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0278 - acc: 0.9948 - val_loss: 2.4228 - val_acc: 0.6066\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9949\n",
      "Epoch 00028: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0284 - acc: 0.9949 - val_loss: 2.4974 - val_acc: 0.5917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9932\n",
      "Epoch 00029: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0344 - acc: 0.9932 - val_loss: 2.4499 - val_acc: 0.6068\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9966\n",
      "Epoch 00030: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0243 - acc: 0.9965 - val_loss: 2.5910 - val_acc: 0.5945\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9909\n",
      "Epoch 00031: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0400 - acc: 0.9908 - val_loss: 2.4830 - val_acc: 0.6052\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9951\n",
      "Epoch 00032: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0243 - acc: 0.9951 - val_loss: 2.5447 - val_acc: 0.6014\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9953\n",
      "Epoch 00033: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0249 - acc: 0.9952 - val_loss: 2.6215 - val_acc: 0.5921\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9941\n",
      "Epoch 00034: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0292 - acc: 0.9941 - val_loss: 2.6657 - val_acc: 0.5970\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9919\n",
      "Epoch 00035: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0377 - acc: 0.9918 - val_loss: 2.9547 - val_acc: 0.5784\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9926\n",
      "Epoch 00036: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0355 - acc: 0.9926 - val_loss: 2.5973 - val_acc: 0.6101\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9962\n",
      "Epoch 00037: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0230 - acc: 0.9962 - val_loss: 2.8273 - val_acc: 0.5914\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9925\n",
      "Epoch 00038: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0353 - acc: 0.9925 - val_loss: 2.6871 - val_acc: 0.6047\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9966\n",
      "Epoch 00039: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0223 - acc: 0.9965 - val_loss: 2.8990 - val_acc: 0.5952\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9941\n",
      "Epoch 00040: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0311 - acc: 0.9941 - val_loss: 2.8649 - val_acc: 0.5837\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9948\n",
      "Epoch 00041: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0272 - acc: 0.9948 - val_loss: 2.6827 - val_acc: 0.6066\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9972\n",
      "Epoch 00042: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0199 - acc: 0.9972 - val_loss: 2.8152 - val_acc: 0.5928\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9941\n",
      "Epoch 00043: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0303 - acc: 0.9941 - val_loss: 2.8046 - val_acc: 0.6035\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9939\n",
      "Epoch 00044: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0314 - acc: 0.9939 - val_loss: 2.8119 - val_acc: 0.6010\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9944\n",
      "Epoch 00045: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0273 - acc: 0.9943 - val_loss: 2.9083 - val_acc: 0.5982\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9949\n",
      "Epoch 00046: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0259 - acc: 0.9949 - val_loss: 2.7677 - val_acc: 0.6168\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9948\n",
      "Epoch 00047: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0268 - acc: 0.9947 - val_loss: 2.8854 - val_acc: 0.5996\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9932\n",
      "Epoch 00048: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0327 - acc: 0.9932 - val_loss: 2.9217 - val_acc: 0.6038\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9952\n",
      "Epoch 00049: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0244 - acc: 0.9951 - val_loss: 2.9121 - val_acc: 0.5963\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9948\n",
      "Epoch 00050: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0282 - acc: 0.9947 - val_loss: 2.9027 - val_acc: 0.6052\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9957\n",
      "Epoch 00051: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0235 - acc: 0.9957 - val_loss: 3.0015 - val_acc: 0.5973\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9953\n",
      "Epoch 00052: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0253 - acc: 0.9953 - val_loss: 2.8462 - val_acc: 0.6150\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9964\n",
      "Epoch 00053: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0212 - acc: 0.9964 - val_loss: 2.9551 - val_acc: 0.6103\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9968\n",
      "Epoch 00054: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0198 - acc: 0.9968 - val_loss: 2.8929 - val_acc: 0.6084\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9970\n",
      "Epoch 00055: val_loss did not improve from 1.52244\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0197 - acc: 0.9969 - val_loss: 3.0155 - val_acc: 0.5905\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 687us/sample - loss: 1.6488 - acc: 0.5823\n",
      "Loss: 1.648780586588296 Accuracy: 0.58234686\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8866 - acc: 0.4481\n",
      "Epoch 00001: val_loss improved from inf to 1.63336, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_6_conv_checkpoint/001-1.6334.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 1.8866 - acc: 0.4480 - val_loss: 1.6334 - val_acc: 0.4976\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0850 - acc: 0.6761\n",
      "Epoch 00002: val_loss improved from 1.63336 to 1.24425, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_6_conv_checkpoint/002-1.2442.hdf5\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 1.0851 - acc: 0.6761 - val_loss: 1.2442 - val_acc: 0.6476\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7548 - acc: 0.7721\n",
      "Epoch 00003: val_loss improved from 1.24425 to 1.15070, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_6_conv_checkpoint/003-1.1507.hdf5\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.7549 - acc: 0.7720 - val_loss: 1.1507 - val_acc: 0.6681\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5276 - acc: 0.8445\n",
      "Epoch 00004: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.5277 - acc: 0.8444 - val_loss: 1.1743 - val_acc: 0.6737\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3692 - acc: 0.8979\n",
      "Epoch 00005: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.3693 - acc: 0.8978 - val_loss: 1.2214 - val_acc: 0.6765\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2693 - acc: 0.9337\n",
      "Epoch 00006: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.2693 - acc: 0.9337 - val_loss: 1.1715 - val_acc: 0.6806\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9580\n",
      "Epoch 00007: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1959 - acc: 0.9579 - val_loss: 1.1739 - val_acc: 0.6904\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1543 - acc: 0.9705\n",
      "Epoch 00008: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1544 - acc: 0.9705 - val_loss: 1.2232 - val_acc: 0.6802\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9793\n",
      "Epoch 00009: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.1213 - acc: 0.9792 - val_loss: 1.2902 - val_acc: 0.6678\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9849\n",
      "Epoch 00010: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0995 - acc: 0.9848 - val_loss: 1.3843 - val_acc: 0.6711\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9866\n",
      "Epoch 00011: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0857 - acc: 0.9866 - val_loss: 1.2744 - val_acc: 0.6834\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9887\n",
      "Epoch 00012: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0731 - acc: 0.9886 - val_loss: 1.3436 - val_acc: 0.6765\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9911\n",
      "Epoch 00013: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0615 - acc: 0.9911 - val_loss: 1.3329 - val_acc: 0.6883\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9895\n",
      "Epoch 00014: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0648 - acc: 0.9895 - val_loss: 1.3592 - val_acc: 0.6855\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9927\n",
      "Epoch 00015: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0497 - acc: 0.9927 - val_loss: 1.6147 - val_acc: 0.6497\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9934\n",
      "Epoch 00016: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0460 - acc: 0.9934 - val_loss: 1.6468 - val_acc: 0.6541\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9955\n",
      "Epoch 00017: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0391 - acc: 0.9955 - val_loss: 1.5650 - val_acc: 0.6625\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9939\n",
      "Epoch 00018: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0410 - acc: 0.9939 - val_loss: 1.5758 - val_acc: 0.6660\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9918\n",
      "Epoch 00019: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0459 - acc: 0.9918 - val_loss: 1.5974 - val_acc: 0.6723\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9961\n",
      "Epoch 00020: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0317 - acc: 0.9961 - val_loss: 1.7343 - val_acc: 0.6536\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9929\n",
      "Epoch 00021: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0430 - acc: 0.9929 - val_loss: 1.6592 - val_acc: 0.6515\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9931\n",
      "Epoch 00022: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0392 - acc: 0.9931 - val_loss: 1.5761 - val_acc: 0.6844\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9973\n",
      "Epoch 00023: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0251 - acc: 0.9973 - val_loss: 2.0048 - val_acc: 0.6320\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9961\n",
      "Epoch 00024: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0275 - acc: 0.9961 - val_loss: 1.5839 - val_acc: 0.6869\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9957\n",
      "Epoch 00025: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0287 - acc: 0.9957 - val_loss: 1.9435 - val_acc: 0.6427\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9910\n",
      "Epoch 00026: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0447 - acc: 0.9909 - val_loss: 1.6059 - val_acc: 0.6758\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9944\n",
      "Epoch 00027: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0324 - acc: 0.9943 - val_loss: 1.6995 - val_acc: 0.6699\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9918\n",
      "Epoch 00028: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0423 - acc: 0.9917 - val_loss: 1.6946 - val_acc: 0.6776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9939\n",
      "Epoch 00029: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0325 - acc: 0.9938 - val_loss: 1.6736 - val_acc: 0.6862\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9960\n",
      "Epoch 00030: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0235 - acc: 0.9960 - val_loss: 1.7168 - val_acc: 0.6741\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9985\n",
      "Epoch 00031: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0170 - acc: 0.9985 - val_loss: 1.7084 - val_acc: 0.6869\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9944\n",
      "Epoch 00032: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0317 - acc: 0.9943 - val_loss: 1.7503 - val_acc: 0.6813\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9962\n",
      "Epoch 00033: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0254 - acc: 0.9961 - val_loss: 2.0052 - val_acc: 0.6527\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9920\n",
      "Epoch 00034: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0365 - acc: 0.9920 - val_loss: 1.8005 - val_acc: 0.6769\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9968\n",
      "Epoch 00035: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0219 - acc: 0.9968 - val_loss: 1.6527 - val_acc: 0.6921\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9969\n",
      "Epoch 00036: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0212 - acc: 0.9969 - val_loss: 2.1408 - val_acc: 0.6245\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9903\n",
      "Epoch 00037: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0455 - acc: 0.9903 - val_loss: 1.9643 - val_acc: 0.6627\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9943\n",
      "Epoch 00038: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0289 - acc: 0.9943 - val_loss: 1.7885 - val_acc: 0.6872\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9977\n",
      "Epoch 00039: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0170 - acc: 0.9977 - val_loss: 1.7657 - val_acc: 0.6883\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9953\n",
      "Epoch 00040: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0235 - acc: 0.9953 - val_loss: 1.7539 - val_acc: 0.6944\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9956\n",
      "Epoch 00041: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0227 - acc: 0.9955 - val_loss: 2.1051 - val_acc: 0.6408\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9942\n",
      "Epoch 00042: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0308 - acc: 0.9942 - val_loss: 1.7520 - val_acc: 0.6900\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9983\n",
      "Epoch 00043: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0160 - acc: 0.9982 - val_loss: 1.8427 - val_acc: 0.6783\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9912\n",
      "Epoch 00044: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0384 - acc: 0.9912 - val_loss: 1.8887 - val_acc: 0.6699\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9961\n",
      "Epoch 00045: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0225 - acc: 0.9960 - val_loss: 1.9671 - val_acc: 0.6613\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9947\n",
      "Epoch 00046: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0283 - acc: 0.9947 - val_loss: 1.9359 - val_acc: 0.6690\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9975\n",
      "Epoch 00047: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0170 - acc: 0.9975 - val_loss: 1.9249 - val_acc: 0.6760\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9978\n",
      "Epoch 00048: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0163 - acc: 0.9978 - val_loss: 1.8669 - val_acc: 0.6804\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9983\n",
      "Epoch 00049: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0152 - acc: 0.9983 - val_loss: 2.1447 - val_acc: 0.6534\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9959\n",
      "Epoch 00050: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0246 - acc: 0.9959 - val_loss: 2.0768 - val_acc: 0.6569\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9970\n",
      "Epoch 00051: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0196 - acc: 0.9970 - val_loss: 2.1443 - val_acc: 0.6599\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9962\n",
      "Epoch 00052: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 56s 2ms/sample - loss: 0.0212 - acc: 0.9962 - val_loss: 1.9609 - val_acc: 0.6797\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9919\n",
      "Epoch 00053: val_loss did not improve from 1.15070\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0371 - acc: 0.9919 - val_loss: 1.9000 - val_acc: 0.6874\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 720us/sample - loss: 1.3158 - acc: 0.6451\n",
      "Loss: 1.3158366868800464 Accuracy: 0.6450675\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8191 - acc: 0.4498\n",
      "Epoch 00001: val_loss improved from inf to 1.51706, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_7_conv_checkpoint/001-1.5171.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.8191 - acc: 0.4498 - val_loss: 1.5171 - val_acc: 0.5134\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1400 - acc: 0.6557\n",
      "Epoch 00002: val_loss improved from 1.51706 to 1.16175, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_7_conv_checkpoint/002-1.1617.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 1.1403 - acc: 0.6557 - val_loss: 1.1617 - val_acc: 0.6562\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9089 - acc: 0.7239\n",
      "Epoch 00003: val_loss improved from 1.16175 to 0.95442, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_7_conv_checkpoint/003-0.9544.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.9088 - acc: 0.7240 - val_loss: 0.9544 - val_acc: 0.7165\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7477 - acc: 0.7739\n",
      "Epoch 00004: val_loss did not improve from 0.95442\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.7477 - acc: 0.7738 - val_loss: 0.9660 - val_acc: 0.7296\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6284 - acc: 0.8126\n",
      "Epoch 00005: val_loss did not improve from 0.95442\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.6284 - acc: 0.8126 - val_loss: 1.1201 - val_acc: 0.6853\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5253 - acc: 0.8448\n",
      "Epoch 00006: val_loss did not improve from 0.95442\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.5256 - acc: 0.8447 - val_loss: 1.5663 - val_acc: 0.5961\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4411 - acc: 0.8727\n",
      "Epoch 00007: val_loss improved from 0.95442 to 0.89792, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_7_conv_checkpoint/007-0.8979.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.4412 - acc: 0.8727 - val_loss: 0.8979 - val_acc: 0.7498\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3656 - acc: 0.8973\n",
      "Epoch 00008: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3656 - acc: 0.8972 - val_loss: 1.0436 - val_acc: 0.7130\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3031 - acc: 0.9167\n",
      "Epoch 00009: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3030 - acc: 0.9167 - val_loss: 0.9497 - val_acc: 0.7440\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2474 - acc: 0.9362\n",
      "Epoch 00010: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2477 - acc: 0.9362 - val_loss: 0.9358 - val_acc: 0.7449\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9469\n",
      "Epoch 00011: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2122 - acc: 0.9468 - val_loss: 0.9516 - val_acc: 0.7480\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1821 - acc: 0.9583\n",
      "Epoch 00012: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1821 - acc: 0.9583 - val_loss: 0.9407 - val_acc: 0.7608\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9689\n",
      "Epoch 00013: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.1465 - acc: 0.9689 - val_loss: 1.0663 - val_acc: 0.7286\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1307 - acc: 0.9718\n",
      "Epoch 00014: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1309 - acc: 0.9718 - val_loss: 1.0521 - val_acc: 0.7372\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9764\n",
      "Epoch 00015: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1188 - acc: 0.9763 - val_loss: 0.9932 - val_acc: 0.7587\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9782\n",
      "Epoch 00016: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1082 - acc: 0.9782 - val_loss: 0.9709 - val_acc: 0.7643\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9868\n",
      "Epoch 00017: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0808 - acc: 0.9868 - val_loss: 0.9976 - val_acc: 0.7594\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9849\n",
      "Epoch 00018: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0839 - acc: 0.9849 - val_loss: 1.0705 - val_acc: 0.7349\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9894\n",
      "Epoch 00019: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0685 - acc: 0.9893 - val_loss: 1.0395 - val_acc: 0.7549\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9890\n",
      "Epoch 00020: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0704 - acc: 0.9889 - val_loss: 0.9751 - val_acc: 0.7680\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9901\n",
      "Epoch 00021: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0608 - acc: 0.9901 - val_loss: 1.0785 - val_acc: 0.7501\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9929\n",
      "Epoch 00022: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0522 - acc: 0.9928 - val_loss: 1.1161 - val_acc: 0.7452\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9844\n",
      "Epoch 00023: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0755 - acc: 0.9843 - val_loss: 1.1140 - val_acc: 0.7473\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9932\n",
      "Epoch 00024: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0493 - acc: 0.9932 - val_loss: 1.1468 - val_acc: 0.7433\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9890\n",
      "Epoch 00025: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0576 - acc: 0.9889 - val_loss: 1.0310 - val_acc: 0.7650\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9923\n",
      "Epoch 00026: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0474 - acc: 0.9922 - val_loss: 1.3640 - val_acc: 0.7142\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9872\n",
      "Epoch 00027: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0631 - acc: 0.9872 - val_loss: 1.1713 - val_acc: 0.7370\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9945\n",
      "Epoch 00028: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0394 - acc: 0.9945 - val_loss: 1.1698 - val_acc: 0.7414\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9934\n",
      "Epoch 00029: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0422 - acc: 0.9933 - val_loss: 1.1670 - val_acc: 0.7598\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9918\n",
      "Epoch 00030: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0451 - acc: 0.9917 - val_loss: 1.1417 - val_acc: 0.7582\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9885\n",
      "Epoch 00031: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0586 - acc: 0.9885 - val_loss: 1.1786 - val_acc: 0.7491\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9961\n",
      "Epoch 00032: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0306 - acc: 0.9961 - val_loss: 1.2258 - val_acc: 0.7421\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9842\n",
      "Epoch 00033: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0726 - acc: 0.9841 - val_loss: 1.2591 - val_acc: 0.7391\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9910\n",
      "Epoch 00034: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0475 - acc: 0.9910 - val_loss: 1.1124 - val_acc: 0.7605\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9970\n",
      "Epoch 00035: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0261 - acc: 0.9970 - val_loss: 1.0988 - val_acc: 0.7706\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9961\n",
      "Epoch 00036: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0294 - acc: 0.9961 - val_loss: 1.0894 - val_acc: 0.7731\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9972\n",
      "Epoch 00037: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0250 - acc: 0.9972 - val_loss: 1.2562 - val_acc: 0.7501\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9941\n",
      "Epoch 00038: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0352 - acc: 0.9941 - val_loss: 1.3372 - val_acc: 0.7356\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9967\n",
      "Epoch 00039: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0265 - acc: 0.9967 - val_loss: 1.5738 - val_acc: 0.7025\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9917\n",
      "Epoch 00040: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0419 - acc: 0.9917 - val_loss: 1.1524 - val_acc: 0.7570\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9950\n",
      "Epoch 00041: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0286 - acc: 0.9949 - val_loss: 1.2256 - val_acc: 0.7519\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9931\n",
      "Epoch 00042: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0369 - acc: 0.9930 - val_loss: 1.2515 - val_acc: 0.7482\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9953\n",
      "Epoch 00043: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0287 - acc: 0.9953 - val_loss: 1.1454 - val_acc: 0.7696\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9963\n",
      "Epoch 00044: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0258 - acc: 0.9963 - val_loss: 1.7161 - val_acc: 0.6935\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9945\n",
      "Epoch 00045: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0305 - acc: 0.9945 - val_loss: 1.3394 - val_acc: 0.7340\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9940\n",
      "Epoch 00046: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0331 - acc: 0.9940 - val_loss: 1.3320 - val_acc: 0.7386\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9936\n",
      "Epoch 00047: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0340 - acc: 0.9936 - val_loss: 1.2463 - val_acc: 0.7554\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9950\n",
      "Epoch 00048: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0281 - acc: 0.9950 - val_loss: 1.2248 - val_acc: 0.7580\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9945\n",
      "Epoch 00049: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0294 - acc: 0.9945 - val_loss: 1.3723 - val_acc: 0.7328\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9975\n",
      "Epoch 00050: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0204 - acc: 0.9975 - val_loss: 1.3144 - val_acc: 0.7431\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9923\n",
      "Epoch 00051: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0357 - acc: 0.9923 - val_loss: 1.2665 - val_acc: 0.7591\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9940\n",
      "Epoch 00052: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0318 - acc: 0.9940 - val_loss: 1.3063 - val_acc: 0.7459\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9936\n",
      "Epoch 00053: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0304 - acc: 0.9936 - val_loss: 1.3036 - val_acc: 0.7563\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9942\n",
      "Epoch 00054: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0304 - acc: 0.9942 - val_loss: 1.3177 - val_acc: 0.7508\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9944\n",
      "Epoch 00055: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0293 - acc: 0.9944 - val_loss: 1.2202 - val_acc: 0.7645\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9946\n",
      "Epoch 00056: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0280 - acc: 0.9946 - val_loss: 1.2332 - val_acc: 0.7587\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9978\n",
      "Epoch 00057: val_loss did not improve from 0.89792\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0188 - acc: 0.9977 - val_loss: 1.2779 - val_acc: 0.7608\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 815us/sample - loss: 0.9934 - acc: 0.7148\n",
      "Loss: 0.9933747239078193 Accuracy: 0.7148494\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8737 - acc: 0.4288\n",
      "Epoch 00001: val_loss improved from inf to 1.58942, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_8_conv_checkpoint/001-1.5894.hdf5\n",
      "36805/36805 [==============================] - 80s 2ms/sample - loss: 1.8737 - acc: 0.4288 - val_loss: 1.5894 - val_acc: 0.5076\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1698 - acc: 0.6490\n",
      "Epoch 00002: val_loss improved from 1.58942 to 1.10118, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_8_conv_checkpoint/002-1.1012.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 1.1699 - acc: 0.6490 - val_loss: 1.1012 - val_acc: 0.6716\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9487 - acc: 0.7204\n",
      "Epoch 00003: val_loss improved from 1.10118 to 0.94613, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_8_conv_checkpoint/003-0.9461.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.9488 - acc: 0.7204 - val_loss: 0.9461 - val_acc: 0.7219\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8119 - acc: 0.7603\n",
      "Epoch 00004: val_loss improved from 0.94613 to 0.82112, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_8_conv_checkpoint/004-0.8211.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.8119 - acc: 0.7603 - val_loss: 0.8211 - val_acc: 0.7708\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7157 - acc: 0.7921\n",
      "Epoch 00005: val_loss did not improve from 0.82112\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.7157 - acc: 0.7921 - val_loss: 0.9522 - val_acc: 0.7219\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6434 - acc: 0.8154\n",
      "Epoch 00006: val_loss did not improve from 0.82112\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.6437 - acc: 0.8154 - val_loss: 0.8920 - val_acc: 0.7382\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5702 - acc: 0.8323\n",
      "Epoch 00007: val_loss improved from 0.82112 to 0.77379, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_8_conv_checkpoint/007-0.7738.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.5702 - acc: 0.8323 - val_loss: 0.7738 - val_acc: 0.7820\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5146 - acc: 0.8494\n",
      "Epoch 00008: val_loss did not improve from 0.77379\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.5148 - acc: 0.8494 - val_loss: 0.9358 - val_acc: 0.7517\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4579 - acc: 0.8682\n",
      "Epoch 00009: val_loss improved from 0.77379 to 0.69360, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_8_conv_checkpoint/009-0.6936.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.4579 - acc: 0.8683 - val_loss: 0.6936 - val_acc: 0.8036\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4084 - acc: 0.8837\n",
      "Epoch 00010: val_loss did not improve from 0.69360\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.4084 - acc: 0.8837 - val_loss: 0.7725 - val_acc: 0.7822\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3659 - acc: 0.8952\n",
      "Epoch 00011: val_loss did not improve from 0.69360\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.3666 - acc: 0.8951 - val_loss: 0.7843 - val_acc: 0.7722\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3472 - acc: 0.9014\n",
      "Epoch 00012: val_loss did not improve from 0.69360\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.3473 - acc: 0.9013 - val_loss: 0.7286 - val_acc: 0.7932\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3022 - acc: 0.9130\n",
      "Epoch 00013: val_loss did not improve from 0.69360\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.3022 - acc: 0.9130 - val_loss: 0.9395 - val_acc: 0.7505\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2686 - acc: 0.9257\n",
      "Epoch 00014: val_loss did not improve from 0.69360\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.2687 - acc: 0.9256 - val_loss: 0.7016 - val_acc: 0.8078\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2326 - acc: 0.9366\n",
      "Epoch 00015: val_loss improved from 0.69360 to 0.69006, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_8_conv_checkpoint/015-0.6901.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.2329 - acc: 0.9365 - val_loss: 0.6901 - val_acc: 0.8251\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2146 - acc: 0.9404\n",
      "Epoch 00016: val_loss improved from 0.69006 to 0.66895, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_8_conv_checkpoint/016-0.6689.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.2146 - acc: 0.9404 - val_loss: 0.6689 - val_acc: 0.8239\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9502\n",
      "Epoch 00017: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1893 - acc: 0.9502 - val_loss: 0.7308 - val_acc: 0.8057\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1816 - acc: 0.9540\n",
      "Epoch 00018: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1816 - acc: 0.9541 - val_loss: 0.6830 - val_acc: 0.8209\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9628\n",
      "Epoch 00019: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1522 - acc: 0.9628 - val_loss: 0.6700 - val_acc: 0.8246\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9688\n",
      "Epoch 00020: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1340 - acc: 0.9688 - val_loss: 0.7213 - val_acc: 0.8190\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9710\n",
      "Epoch 00021: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1262 - acc: 0.9709 - val_loss: 0.7559 - val_acc: 0.8032\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9718\n",
      "Epoch 00022: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.1195 - acc: 0.9718 - val_loss: 0.8365 - val_acc: 0.7885\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9768\n",
      "Epoch 00023: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1051 - acc: 0.9768 - val_loss: 0.7680 - val_acc: 0.8015\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9816\n",
      "Epoch 00024: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0913 - acc: 0.9816 - val_loss: 0.7739 - val_acc: 0.7997\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9804\n",
      "Epoch 00025: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0902 - acc: 0.9803 - val_loss: 0.8054 - val_acc: 0.7941\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9803\n",
      "Epoch 00026: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0879 - acc: 0.9803 - val_loss: 0.7014 - val_acc: 0.8239\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9852\n",
      "Epoch 00027: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0751 - acc: 0.9851 - val_loss: 0.8519 - val_acc: 0.7978\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9844\n",
      "Epoch 00028: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0757 - acc: 0.9844 - val_loss: 0.7079 - val_acc: 0.8307\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9880\n",
      "Epoch 00029: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0617 - acc: 0.9880 - val_loss: 0.8189 - val_acc: 0.8018\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9859\n",
      "Epoch 00030: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0679 - acc: 0.9858 - val_loss: 0.8147 - val_acc: 0.8130\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9839\n",
      "Epoch 00031: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0751 - acc: 0.9838 - val_loss: 0.8109 - val_acc: 0.8099\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9866\n",
      "Epoch 00032: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0633 - acc: 0.9866 - val_loss: 0.7762 - val_acc: 0.8213\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9871\n",
      "Epoch 00033: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0582 - acc: 0.9871 - val_loss: 0.8414 - val_acc: 0.8139\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9888\n",
      "Epoch 00034: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0561 - acc: 0.9887 - val_loss: 0.7779 - val_acc: 0.8204\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9872\n",
      "Epoch 00035: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0604 - acc: 0.9872 - val_loss: 0.8055 - val_acc: 0.8169\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9924\n",
      "Epoch 00036: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0451 - acc: 0.9924 - val_loss: 0.8606 - val_acc: 0.8018\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9933\n",
      "Epoch 00037: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0401 - acc: 0.9933 - val_loss: 1.1573 - val_acc: 0.7654\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9882\n",
      "Epoch 00038: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0553 - acc: 0.9881 - val_loss: 0.8548 - val_acc: 0.8078\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9882\n",
      "Epoch 00039: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0526 - acc: 0.9882 - val_loss: 0.9048 - val_acc: 0.8064\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9925\n",
      "Epoch 00040: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0419 - acc: 0.9925 - val_loss: 0.7956 - val_acc: 0.8230\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9916\n",
      "Epoch 00041: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0418 - acc: 0.9916 - val_loss: 1.0310 - val_acc: 0.7806\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9917\n",
      "Epoch 00042: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0416 - acc: 0.9917 - val_loss: 0.8195 - val_acc: 0.8206\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9939\n",
      "Epoch 00043: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0348 - acc: 0.9939 - val_loss: 0.9026 - val_acc: 0.8022\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9943\n",
      "Epoch 00044: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0332 - acc: 0.9943 - val_loss: 0.8519 - val_acc: 0.8050\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9927\n",
      "Epoch 00045: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0382 - acc: 0.9926 - val_loss: 1.0395 - val_acc: 0.7806\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9881\n",
      "Epoch 00046: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0490 - acc: 0.9881 - val_loss: 0.8563 - val_acc: 0.8148\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9961\n",
      "Epoch 00047: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0275 - acc: 0.9961 - val_loss: 0.8463 - val_acc: 0.8130\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9926\n",
      "Epoch 00048: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0368 - acc: 0.9926 - val_loss: 0.8325 - val_acc: 0.8255\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9919\n",
      "Epoch 00049: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0398 - acc: 0.9919 - val_loss: 0.9844 - val_acc: 0.8015\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9962\n",
      "Epoch 00050: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0256 - acc: 0.9963 - val_loss: 0.8069 - val_acc: 0.8309\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9945\n",
      "Epoch 00051: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0307 - acc: 0.9944 - val_loss: 0.8711 - val_acc: 0.8241\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9874\n",
      "Epoch 00052: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0541 - acc: 0.9874 - val_loss: 0.8109 - val_acc: 0.8267\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9890\n",
      "Epoch 00053: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0443 - acc: 0.9890 - val_loss: 0.8269 - val_acc: 0.8234\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9966\n",
      "Epoch 00054: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0241 - acc: 0.9966 - val_loss: 0.8399 - val_acc: 0.8311\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9972\n",
      "Epoch 00055: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0207 - acc: 0.9971 - val_loss: 1.0073 - val_acc: 0.7994\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9908\n",
      "Epoch 00056: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0405 - acc: 0.9908 - val_loss: 0.8034 - val_acc: 0.8300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9971\n",
      "Epoch 00057: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0221 - acc: 0.9971 - val_loss: 0.9113 - val_acc: 0.8137\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9912\n",
      "Epoch 00058: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0396 - acc: 0.9912 - val_loss: 0.8727 - val_acc: 0.8150\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9903\n",
      "Epoch 00059: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0430 - acc: 0.9903 - val_loss: 0.8137 - val_acc: 0.8323\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9979\n",
      "Epoch 00060: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0191 - acc: 0.9979 - val_loss: 0.7797 - val_acc: 0.8379\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9947\n",
      "Epoch 00061: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0279 - acc: 0.9947 - val_loss: 0.8298 - val_acc: 0.8269\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9943\n",
      "Epoch 00062: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0285 - acc: 0.9943 - val_loss: 0.9754 - val_acc: 0.8069\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9932\n",
      "Epoch 00063: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0333 - acc: 0.9932 - val_loss: 0.7654 - val_acc: 0.8376\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9953\n",
      "Epoch 00064: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0247 - acc: 0.9953 - val_loss: 0.8392 - val_acc: 0.8293\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9952\n",
      "Epoch 00065: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0257 - acc: 0.9952 - val_loss: 0.7972 - val_acc: 0.8386\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9945\n",
      "Epoch 00066: val_loss did not improve from 0.66895\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0289 - acc: 0.9945 - val_loss: 0.9201 - val_acc: 0.8197\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 867us/sample - loss: 0.7487 - acc: 0.7931\n",
      "Loss: 0.7487056278613002 Accuracy: 0.79314643\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8014 - acc: 0.4492\n",
      "Epoch 00001: val_loss improved from inf to 1.55011, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_9_conv_checkpoint/001-1.5501.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.8015 - acc: 0.4492 - val_loss: 1.5501 - val_acc: 0.5029\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0602 - acc: 0.6840\n",
      "Epoch 00002: val_loss improved from 1.55011 to 1.10731, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_9_conv_checkpoint/002-1.1073.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 1.0602 - acc: 0.6840 - val_loss: 1.1073 - val_acc: 0.6657\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8281 - acc: 0.7586\n",
      "Epoch 00003: val_loss improved from 1.10731 to 0.86697, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_9_conv_checkpoint/003-0.8670.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.8282 - acc: 0.7586 - val_loss: 0.8670 - val_acc: 0.7377\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6759 - acc: 0.8048\n",
      "Epoch 00004: val_loss improved from 0.86697 to 0.66691, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_9_conv_checkpoint/004-0.6669.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.6758 - acc: 0.8048 - val_loss: 0.6669 - val_acc: 0.8071\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5731 - acc: 0.8348\n",
      "Epoch 00005: val_loss improved from 0.66691 to 0.65220, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_9_conv_checkpoint/005-0.6522.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.5731 - acc: 0.8348 - val_loss: 0.6522 - val_acc: 0.8137\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4928 - acc: 0.8573\n",
      "Epoch 00006: val_loss did not improve from 0.65220\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.4931 - acc: 0.8572 - val_loss: 0.6524 - val_acc: 0.8116\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4354 - acc: 0.8769\n",
      "Epoch 00007: val_loss improved from 0.65220 to 0.55733, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_9_conv_checkpoint/007-0.5573.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.4359 - acc: 0.8768 - val_loss: 0.5573 - val_acc: 0.8397\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3850 - acc: 0.8899\n",
      "Epoch 00008: val_loss improved from 0.55733 to 0.51001, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_9_conv_checkpoint/008-0.5100.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.3851 - acc: 0.8899 - val_loss: 0.5100 - val_acc: 0.8581\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3383 - acc: 0.9035\n",
      "Epoch 00009: val_loss improved from 0.51001 to 0.50294, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_9_conv_checkpoint/009-0.5029.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.3383 - acc: 0.9035 - val_loss: 0.5029 - val_acc: 0.8563\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2996 - acc: 0.9147\n",
      "Epoch 00010: val_loss did not improve from 0.50294\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.2995 - acc: 0.9147 - val_loss: 0.5132 - val_acc: 0.8549\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2637 - acc: 0.9261\n",
      "Epoch 00011: val_loss improved from 0.50294 to 0.46674, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_9_conv_checkpoint/011-0.4667.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.2639 - acc: 0.9260 - val_loss: 0.4667 - val_acc: 0.8679\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2403 - acc: 0.9310\n",
      "Epoch 00012: val_loss did not improve from 0.46674\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.2403 - acc: 0.9310 - val_loss: 0.4748 - val_acc: 0.8656\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2091 - acc: 0.9406\n",
      "Epoch 00013: val_loss improved from 0.46674 to 0.45734, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_9_conv_checkpoint/013-0.4573.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.2091 - acc: 0.9406 - val_loss: 0.4573 - val_acc: 0.8744\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1816 - acc: 0.9499\n",
      "Epoch 00014: val_loss did not improve from 0.45734\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.1816 - acc: 0.9499 - val_loss: 0.4794 - val_acc: 0.8679\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1635 - acc: 0.9557\n",
      "Epoch 00015: val_loss did not improve from 0.45734\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.1635 - acc: 0.9557 - val_loss: 0.4849 - val_acc: 0.8593\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1460 - acc: 0.9621\n",
      "Epoch 00016: val_loss did not improve from 0.45734\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.1460 - acc: 0.9621 - val_loss: 0.5072 - val_acc: 0.8605\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1348 - acc: 0.9650\n",
      "Epoch 00017: val_loss did not improve from 0.45734\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.1349 - acc: 0.9650 - val_loss: 0.4593 - val_acc: 0.8777\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9714\n",
      "Epoch 00018: val_loss did not improve from 0.45734\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.1171 - acc: 0.9714 - val_loss: 0.4800 - val_acc: 0.8756\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9679\n",
      "Epoch 00019: val_loss improved from 0.45734 to 0.41595, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_9_conv_checkpoint/019-0.4160.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.1207 - acc: 0.9679 - val_loss: 0.4160 - val_acc: 0.8866\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9800\n",
      "Epoch 00020: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0901 - acc: 0.9800 - val_loss: 0.4893 - val_acc: 0.8710\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9804\n",
      "Epoch 00021: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0850 - acc: 0.9803 - val_loss: 0.4244 - val_acc: 0.8835\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9801\n",
      "Epoch 00022: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0830 - acc: 0.9801 - val_loss: 0.5350 - val_acc: 0.8623\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9833\n",
      "Epoch 00023: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0761 - acc: 0.9833 - val_loss: 0.4627 - val_acc: 0.8824\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9836\n",
      "Epoch 00024: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0708 - acc: 0.9836 - val_loss: 0.4389 - val_acc: 0.8814\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9837\n",
      "Epoch 00025: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0710 - acc: 0.9837 - val_loss: 0.4802 - val_acc: 0.8765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9852\n",
      "Epoch 00026: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0649 - acc: 0.9852 - val_loss: 0.4817 - val_acc: 0.8765\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9909\n",
      "Epoch 00027: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0474 - acc: 0.9908 - val_loss: 0.4595 - val_acc: 0.8854\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9837\n",
      "Epoch 00028: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0682 - acc: 0.9836 - val_loss: 0.4843 - val_acc: 0.8765\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9833\n",
      "Epoch 00029: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0687 - acc: 0.9832 - val_loss: 0.4475 - val_acc: 0.8863\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9864\n",
      "Epoch 00030: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0578 - acc: 0.9863 - val_loss: 0.4342 - val_acc: 0.8980\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9890\n",
      "Epoch 00031: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0504 - acc: 0.9890 - val_loss: 0.4335 - val_acc: 0.8905\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9912\n",
      "Epoch 00032: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0424 - acc: 0.9911 - val_loss: 0.4398 - val_acc: 0.8915\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9914\n",
      "Epoch 00033: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0421 - acc: 0.9914 - val_loss: 0.5525 - val_acc: 0.8600\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9946\n",
      "Epoch 00034: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0323 - acc: 0.9946 - val_loss: 0.5262 - val_acc: 0.8705\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9858\n",
      "Epoch 00035: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0557 - acc: 0.9858 - val_loss: 0.4948 - val_acc: 0.8835\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9946\n",
      "Epoch 00036: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0308 - acc: 0.9946 - val_loss: 0.4818 - val_acc: 0.8775\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9867\n",
      "Epoch 00037: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0523 - acc: 0.9867 - val_loss: 0.4369 - val_acc: 0.8947\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9908\n",
      "Epoch 00038: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0412 - acc: 0.9908 - val_loss: 0.4581 - val_acc: 0.8898\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9964\n",
      "Epoch 00039: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0236 - acc: 0.9964 - val_loss: 0.4974 - val_acc: 0.8861\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9927\n",
      "Epoch 00040: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0352 - acc: 0.9926 - val_loss: 0.6173 - val_acc: 0.8621\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9908\n",
      "Epoch 00041: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0387 - acc: 0.9908 - val_loss: 0.4842 - val_acc: 0.8887\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9933\n",
      "Epoch 00042: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0315 - acc: 0.9933 - val_loss: 0.4545 - val_acc: 0.8917\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9955\n",
      "Epoch 00043: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0245 - acc: 0.9955 - val_loss: 0.5488 - val_acc: 0.8726\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9907\n",
      "Epoch 00044: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0407 - acc: 0.9906 - val_loss: 0.5353 - val_acc: 0.8740\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9880\n",
      "Epoch 00045: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0479 - acc: 0.9880 - val_loss: 0.4663 - val_acc: 0.8908\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9960\n",
      "Epoch 00046: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0219 - acc: 0.9960 - val_loss: 0.4757 - val_acc: 0.8952\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9977\n",
      "Epoch 00047: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0168 - acc: 0.9977 - val_loss: 0.4685 - val_acc: 0.8905\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9961\n",
      "Epoch 00048: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0215 - acc: 0.9961 - val_loss: 0.4706 - val_acc: 0.8980\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9865\n",
      "Epoch 00049: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0498 - acc: 0.9865 - val_loss: 0.4560 - val_acc: 0.8961\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9977\n",
      "Epoch 00050: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0171 - acc: 0.9976 - val_loss: 0.5070 - val_acc: 0.8882\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9910\n",
      "Epoch 00051: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0356 - acc: 0.9909 - val_loss: 0.5715 - val_acc: 0.8684\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9928\n",
      "Epoch 00052: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0320 - acc: 0.9928 - val_loss: 0.4989 - val_acc: 0.8894\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9961\n",
      "Epoch 00053: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0211 - acc: 0.9961 - val_loss: 0.4596 - val_acc: 0.8973\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9984\n",
      "Epoch 00054: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0142 - acc: 0.9983 - val_loss: 0.4957 - val_acc: 0.8931\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9895\n",
      "Epoch 00055: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0401 - acc: 0.9894 - val_loss: 0.5360 - val_acc: 0.8803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9926\n",
      "Epoch 00056: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0315 - acc: 0.9926 - val_loss: 0.4588 - val_acc: 0.8982\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9953\n",
      "Epoch 00057: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0229 - acc: 0.9953 - val_loss: 0.4713 - val_acc: 0.8970\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9975\n",
      "Epoch 00058: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0154 - acc: 0.9975 - val_loss: 0.4846 - val_acc: 0.8931\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9913\n",
      "Epoch 00059: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0342 - acc: 0.9913 - val_loss: 0.4888 - val_acc: 0.8901\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9885\n",
      "Epoch 00060: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0454 - acc: 0.9884 - val_loss: 0.4581 - val_acc: 0.9001\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9962\n",
      "Epoch 00061: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0202 - acc: 0.9962 - val_loss: 0.4863 - val_acc: 0.8898\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9947\n",
      "Epoch 00062: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0232 - acc: 0.9947 - val_loss: 0.5578 - val_acc: 0.8833\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9918\n",
      "Epoch 00063: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0332 - acc: 0.9918 - val_loss: 0.4485 - val_acc: 0.9001\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9941\n",
      "Epoch 00064: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0248 - acc: 0.9941 - val_loss: 0.4921 - val_acc: 0.8884\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9942\n",
      "Epoch 00065: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0257 - acc: 0.9942 - val_loss: 0.4402 - val_acc: 0.9050\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9961\n",
      "Epoch 00066: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0200 - acc: 0.9961 - val_loss: 0.4980 - val_acc: 0.8882\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9928\n",
      "Epoch 00067: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0305 - acc: 0.9928 - val_loss: 0.4395 - val_acc: 0.8968\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9933\n",
      "Epoch 00068: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0276 - acc: 0.9932 - val_loss: 0.4346 - val_acc: 0.9008\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9954\n",
      "Epoch 00069: val_loss did not improve from 0.41595\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 0.0212 - acc: 0.9954 - val_loss: 0.5048 - val_acc: 0.8917\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 881us/sample - loss: 0.5148 - acc: 0.8590\n",
      "Loss: 0.5148487983339177 Accuracy: 0.8589823\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8998 - acc: 0.4218\n",
      "Epoch 00001: val_loss improved from inf to 1.42441, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/001-1.4244.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 1.8996 - acc: 0.4219 - val_loss: 1.4244 - val_acc: 0.5488\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0868 - acc: 0.6773\n",
      "Epoch 00002: val_loss improved from 1.42441 to 1.09659, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/002-1.0966.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 1.0870 - acc: 0.6772 - val_loss: 1.0966 - val_acc: 0.6734\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7760 - acc: 0.7743\n",
      "Epoch 00003: val_loss improved from 1.09659 to 0.62766, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/003-0.6277.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.7763 - acc: 0.7742 - val_loss: 0.6277 - val_acc: 0.8272\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.8265\n",
      "Epoch 00004: val_loss improved from 0.62766 to 0.57126, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/004-0.5713.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.6022 - acc: 0.8265 - val_loss: 0.5713 - val_acc: 0.8369\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4801 - acc: 0.8628\n",
      "Epoch 00005: val_loss improved from 0.57126 to 0.46054, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/005-0.4605.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.4801 - acc: 0.8628 - val_loss: 0.4605 - val_acc: 0.8744\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4047 - acc: 0.8832\n",
      "Epoch 00006: val_loss did not improve from 0.46054\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.4047 - acc: 0.8832 - val_loss: 0.5223 - val_acc: 0.8442\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3421 - acc: 0.9019\n",
      "Epoch 00007: val_loss improved from 0.46054 to 0.37954, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/007-0.3795.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.3421 - acc: 0.9019 - val_loss: 0.3795 - val_acc: 0.8919\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2973 - acc: 0.9143\n",
      "Epoch 00008: val_loss did not improve from 0.37954\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.2973 - acc: 0.9143 - val_loss: 0.4425 - val_acc: 0.8712\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2619 - acc: 0.9235\n",
      "Epoch 00009: val_loss did not improve from 0.37954\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.2620 - acc: 0.9234 - val_loss: 0.3904 - val_acc: 0.8877\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2314 - acc: 0.9333\n",
      "Epoch 00010: val_loss improved from 0.37954 to 0.35473, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/010-0.3547.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.2314 - acc: 0.9333 - val_loss: 0.3547 - val_acc: 0.9003\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2056 - acc: 0.9411\n",
      "Epoch 00011: val_loss did not improve from 0.35473\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.2057 - acc: 0.9410 - val_loss: 0.3565 - val_acc: 0.8977\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1862 - acc: 0.9460\n",
      "Epoch 00012: val_loss improved from 0.35473 to 0.30601, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/012-0.3060.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1863 - acc: 0.9460 - val_loss: 0.3060 - val_acc: 0.9099\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1628 - acc: 0.9549\n",
      "Epoch 00013: val_loss improved from 0.30601 to 0.29867, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/013-0.2987.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1631 - acc: 0.9548 - val_loss: 0.2987 - val_acc: 0.9150\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1586 - acc: 0.9551\n",
      "Epoch 00014: val_loss improved from 0.29867 to 0.29214, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/014-0.2921.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1586 - acc: 0.9551 - val_loss: 0.2921 - val_acc: 0.9168\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9629\n",
      "Epoch 00015: val_loss did not improve from 0.29214\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1310 - acc: 0.9628 - val_loss: 0.2961 - val_acc: 0.9133\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9666\n",
      "Epoch 00016: val_loss did not improve from 0.29214\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1183 - acc: 0.9666 - val_loss: 0.3048 - val_acc: 0.9147\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9716\n",
      "Epoch 00017: val_loss did not improve from 0.29214\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.1082 - acc: 0.9716 - val_loss: 0.3131 - val_acc: 0.9101\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9735\n",
      "Epoch 00018: val_loss did not improve from 0.29214\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0981 - acc: 0.9735 - val_loss: 0.3295 - val_acc: 0.9101\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9762\n",
      "Epoch 00019: val_loss did not improve from 0.29214\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0866 - acc: 0.9763 - val_loss: 0.3622 - val_acc: 0.8987\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9799\n",
      "Epoch 00020: val_loss did not improve from 0.29214\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0762 - acc: 0.9798 - val_loss: 0.4348 - val_acc: 0.8859\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9798\n",
      "Epoch 00021: val_loss improved from 0.29214 to 0.28435, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/021-0.2843.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0757 - acc: 0.9798 - val_loss: 0.2843 - val_acc: 0.9201\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9813\n",
      "Epoch 00022: val_loss improved from 0.28435 to 0.27499, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/022-0.2750.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0733 - acc: 0.9813 - val_loss: 0.2750 - val_acc: 0.9245\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9858\n",
      "Epoch 00023: val_loss did not improve from 0.27499\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0569 - acc: 0.9858 - val_loss: 0.3232 - val_acc: 0.9117\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9873\n",
      "Epoch 00024: val_loss improved from 0.27499 to 0.27033, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/024-0.2703.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0544 - acc: 0.9873 - val_loss: 0.2703 - val_acc: 0.9269\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9882\n",
      "Epoch 00025: val_loss did not improve from 0.27033\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0483 - acc: 0.9882 - val_loss: 0.3825 - val_acc: 0.8987\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9880\n",
      "Epoch 00026: val_loss did not improve from 0.27033\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0480 - acc: 0.9879 - val_loss: 0.2887 - val_acc: 0.9201\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9830\n",
      "Epoch 00027: val_loss did not improve from 0.27033\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0629 - acc: 0.9830 - val_loss: 0.2911 - val_acc: 0.9250\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9927\n",
      "Epoch 00028: val_loss did not improve from 0.27033\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0339 - acc: 0.9927 - val_loss: 0.3561 - val_acc: 0.9078\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9842\n",
      "Epoch 00029: val_loss did not improve from 0.27033\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0569 - acc: 0.9842 - val_loss: 0.2752 - val_acc: 0.9266\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9932\n",
      "Epoch 00030: val_loss improved from 0.27033 to 0.26664, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/030-0.2666.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0315 - acc: 0.9932 - val_loss: 0.2666 - val_acc: 0.9308\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9936\n",
      "Epoch 00031: val_loss did not improve from 0.26664\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0290 - acc: 0.9936 - val_loss: 0.3266 - val_acc: 0.9227\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9894\n",
      "Epoch 00032: val_loss did not improve from 0.26664\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0420 - acc: 0.9893 - val_loss: 0.5618 - val_acc: 0.8686\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9910\n",
      "Epoch 00033: val_loss did not improve from 0.26664\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0375 - acc: 0.9910 - val_loss: 0.3294 - val_acc: 0.9206\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9905\n",
      "Epoch 00034: val_loss improved from 0.26664 to 0.25561, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/034-0.2556.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0383 - acc: 0.9905 - val_loss: 0.2556 - val_acc: 0.9355\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9919\n",
      "Epoch 00035: val_loss improved from 0.25561 to 0.24567, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/035-0.2457.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0329 - acc: 0.9919 - val_loss: 0.2457 - val_acc: 0.9357\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9957\n",
      "Epoch 00036: val_loss did not improve from 0.24567\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0211 - acc: 0.9957 - val_loss: 0.2927 - val_acc: 0.9255\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9948\n",
      "Epoch 00037: val_loss did not improve from 0.24567\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0241 - acc: 0.9948 - val_loss: 0.3140 - val_acc: 0.9238\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9949\n",
      "Epoch 00038: val_loss did not improve from 0.24567\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0231 - acc: 0.9949 - val_loss: 0.2779 - val_acc: 0.9287\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9949\n",
      "Epoch 00039: val_loss did not improve from 0.24567\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0236 - acc: 0.9949 - val_loss: 0.3559 - val_acc: 0.9208\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9877\n",
      "Epoch 00040: val_loss did not improve from 0.24567\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0429 - acc: 0.9877 - val_loss: 0.2882 - val_acc: 0.9334\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9923\n",
      "Epoch 00041: val_loss did not improve from 0.24567\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0305 - acc: 0.9923 - val_loss: 0.2969 - val_acc: 0.9313\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9934\n",
      "Epoch 00042: val_loss did not improve from 0.24567\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0272 - acc: 0.9934 - val_loss: 0.2520 - val_acc: 0.9371\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9940\n",
      "Epoch 00043: val_loss did not improve from 0.24567\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0247 - acc: 0.9940 - val_loss: 0.2940 - val_acc: 0.9248\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9940\n",
      "Epoch 00044: val_loss did not improve from 0.24567\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0250 - acc: 0.9940 - val_loss: 0.2731 - val_acc: 0.9287\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9941\n",
      "Epoch 00045: val_loss did not improve from 0.24567\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0239 - acc: 0.9940 - val_loss: 0.2825 - val_acc: 0.9336\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9903\n",
      "Epoch 00046: val_loss improved from 0.24567 to 0.23800, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_10_conv_checkpoint/046-0.2380.hdf5\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0358 - acc: 0.9903 - val_loss: 0.2380 - val_acc: 0.9385\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9963\n",
      "Epoch 00047: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0165 - acc: 0.9963 - val_loss: 0.2394 - val_acc: 0.9422\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9986\n",
      "Epoch 00048: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0099 - acc: 0.9986 - val_loss: 0.2627 - val_acc: 0.9348\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9940\n",
      "Epoch 00049: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0238 - acc: 0.9940 - val_loss: 0.3143 - val_acc: 0.9238\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9930\n",
      "Epoch 00050: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0267 - acc: 0.9930 - val_loss: 0.2598 - val_acc: 0.9362\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9983\n",
      "Epoch 00051: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0112 - acc: 0.9983 - val_loss: 0.2597 - val_acc: 0.9350\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9960\n",
      "Epoch 00052: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0167 - acc: 0.9960 - val_loss: 0.2604 - val_acc: 0.9366\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9971\n",
      "Epoch 00053: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0143 - acc: 0.9971 - val_loss: 0.5164 - val_acc: 0.8919\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9946\n",
      "Epoch 00054: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0215 - acc: 0.9946 - val_loss: 0.2615 - val_acc: 0.9366\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9976\n",
      "Epoch 00055: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0115 - acc: 0.9976 - val_loss: 0.3543 - val_acc: 0.9192\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9926\n",
      "Epoch 00056: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0265 - acc: 0.9926 - val_loss: 0.2909 - val_acc: 0.9336\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9988\n",
      "Epoch 00057: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0080 - acc: 0.9988 - val_loss: 0.2787 - val_acc: 0.9364\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9917\n",
      "Epoch 00058: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0306 - acc: 0.9917 - val_loss: 0.2580 - val_acc: 0.9373\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9979\n",
      "Epoch 00059: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0106 - acc: 0.9979 - val_loss: 0.2847 - val_acc: 0.9366\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9920\n",
      "Epoch 00060: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0296 - acc: 0.9920 - val_loss: 0.2842 - val_acc: 0.9338\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9957\n",
      "Epoch 00061: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0186 - acc: 0.9957 - val_loss: 0.2764 - val_acc: 0.9385\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9947\n",
      "Epoch 00062: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0205 - acc: 0.9947 - val_loss: 0.2726 - val_acc: 0.9383\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9987\n",
      "Epoch 00063: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0081 - acc: 0.9987 - val_loss: 0.2504 - val_acc: 0.9418\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9992\n",
      "Epoch 00064: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0064 - acc: 0.9992 - val_loss: 0.2834 - val_acc: 0.9392\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9969\n",
      "Epoch 00065: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0131 - acc: 0.9969 - val_loss: 0.3526 - val_acc: 0.9255\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9911\n",
      "Epoch 00066: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0302 - acc: 0.9911 - val_loss: 0.2705 - val_acc: 0.9355\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9981\n",
      "Epoch 00067: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0096 - acc: 0.9981 - val_loss: 0.2863 - val_acc: 0.9366\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9960\n",
      "Epoch 00068: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0151 - acc: 0.9960 - val_loss: 0.2838 - val_acc: 0.9338\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9955\n",
      "Epoch 00069: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0172 - acc: 0.9955 - val_loss: 0.2818 - val_acc: 0.9378\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9975\n",
      "Epoch 00070: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0104 - acc: 0.9975 - val_loss: 0.2813 - val_acc: 0.9364\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9985\n",
      "Epoch 00071: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0080 - acc: 0.9985 - val_loss: 0.2859 - val_acc: 0.9380\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9938\n",
      "Epoch 00072: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0245 - acc: 0.9938 - val_loss: 0.3036 - val_acc: 0.9352\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9990\n",
      "Epoch 00073: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0067 - acc: 0.9990 - val_loss: 0.2731 - val_acc: 0.9390\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9949\n",
      "Epoch 00074: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0172 - acc: 0.9949 - val_loss: 0.3034 - val_acc: 0.9345\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9982\n",
      "Epoch 00075: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0081 - acc: 0.9982 - val_loss: 0.3327 - val_acc: 0.9294\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9930\n",
      "Epoch 00076: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0242 - acc: 0.9929 - val_loss: 0.2892 - val_acc: 0.9364\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9950\n",
      "Epoch 00077: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0186 - acc: 0.9949 - val_loss: 0.2864 - val_acc: 0.9320\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9977\n",
      "Epoch 00078: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0098 - acc: 0.9977 - val_loss: 0.2940 - val_acc: 0.9359\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9964\n",
      "Epoch 00079: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0136 - acc: 0.9964 - val_loss: 0.2776 - val_acc: 0.9397\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9972\n",
      "Epoch 00080: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0112 - acc: 0.9972 - val_loss: 0.3460 - val_acc: 0.9222\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9906\n",
      "Epoch 00081: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0323 - acc: 0.9906 - val_loss: 0.2874 - val_acc: 0.9352\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9986\n",
      "Epoch 00082: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0076 - acc: 0.9986 - val_loss: 0.2517 - val_acc: 0.9390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9994\n",
      "Epoch 00083: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0049 - acc: 0.9994 - val_loss: 0.2935 - val_acc: 0.9392\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9983\n",
      "Epoch 00084: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0088 - acc: 0.9983 - val_loss: 0.2859 - val_acc: 0.9371\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9983\n",
      "Epoch 00085: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0091 - acc: 0.9983 - val_loss: 0.2674 - val_acc: 0.9378\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9926\n",
      "Epoch 00086: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0246 - acc: 0.9926 - val_loss: 0.2941 - val_acc: 0.9362\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9992\n",
      "Epoch 00087: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0053 - acc: 0.9992 - val_loss: 0.2873 - val_acc: 0.9362\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9941\n",
      "Epoch 00088: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0200 - acc: 0.9941 - val_loss: 0.2779 - val_acc: 0.9422\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9981\n",
      "Epoch 00089: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0086 - acc: 0.9980 - val_loss: 0.2520 - val_acc: 0.9448\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9952\n",
      "Epoch 00090: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0178 - acc: 0.9952 - val_loss: 0.2980 - val_acc: 0.9343\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9951\n",
      "Epoch 00091: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0182 - acc: 0.9951 - val_loss: 0.2653 - val_acc: 0.9418\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9966\n",
      "Epoch 00092: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0125 - acc: 0.9966 - val_loss: 0.2987 - val_acc: 0.9329\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9964\n",
      "Epoch 00093: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0145 - acc: 0.9964 - val_loss: 0.2537 - val_acc: 0.9436\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9990\n",
      "Epoch 00094: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0049 - acc: 0.9990 - val_loss: 0.2579 - val_acc: 0.9429\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9995\n",
      "Epoch 00095: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0038 - acc: 0.9995 - val_loss: 0.2602 - val_acc: 0.9450\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9965\n",
      "Epoch 00096: val_loss did not improve from 0.23800\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0126 - acc: 0.9965 - val_loss: 0.2942 - val_acc: 0.9357\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_10_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 933us/sample - loss: 0.3260 - acc: 0.9178\n",
      "Loss: 0.32596479585454224 Accuracy: 0.91775703\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7593 - acc: 0.4621\n",
      "Epoch 00001: val_loss improved from inf to 1.27142, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/001-1.2714.hdf5\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 1.7592 - acc: 0.4621 - val_loss: 1.2714 - val_acc: 0.6038\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8797 - acc: 0.7404\n",
      "Epoch 00002: val_loss improved from 1.27142 to 0.67488, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/002-0.6749.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.8796 - acc: 0.7404 - val_loss: 0.6749 - val_acc: 0.8064\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5910 - acc: 0.8301\n",
      "Epoch 00003: val_loss improved from 0.67488 to 0.50040, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/003-0.5004.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.5911 - acc: 0.8301 - val_loss: 0.5004 - val_acc: 0.8563\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4418 - acc: 0.8720\n",
      "Epoch 00004: val_loss improved from 0.50040 to 0.48195, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/004-0.4820.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.4418 - acc: 0.8720 - val_loss: 0.4820 - val_acc: 0.8647\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.8973\n",
      "Epoch 00005: val_loss improved from 0.48195 to 0.34484, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/005-0.3448.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.3533 - acc: 0.8973 - val_loss: 0.3448 - val_acc: 0.9012\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2956 - acc: 0.9139\n",
      "Epoch 00006: val_loss improved from 0.34484 to 0.33630, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/006-0.3363.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.2956 - acc: 0.9138 - val_loss: 0.3363 - val_acc: 0.9026\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2521 - acc: 0.9265\n",
      "Epoch 00007: val_loss did not improve from 0.33630\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.2521 - acc: 0.9265 - val_loss: 0.3388 - val_acc: 0.8980\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2162 - acc: 0.9371\n",
      "Epoch 00008: val_loss improved from 0.33630 to 0.28400, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/008-0.2840.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.2162 - acc: 0.9371 - val_loss: 0.2840 - val_acc: 0.9215\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1889 - acc: 0.9448\n",
      "Epoch 00009: val_loss improved from 0.28400 to 0.26686, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/009-0.2669.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.1889 - acc: 0.9448 - val_loss: 0.2669 - val_acc: 0.9245\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1660 - acc: 0.9525\n",
      "Epoch 00010: val_loss improved from 0.26686 to 0.26357, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/010-0.2636.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.1661 - acc: 0.9525 - val_loss: 0.2636 - val_acc: 0.9203\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1493 - acc: 0.9551\n",
      "Epoch 00011: val_loss improved from 0.26357 to 0.25146, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/011-0.2515.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.1493 - acc: 0.9551 - val_loss: 0.2515 - val_acc: 0.9290\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9622\n",
      "Epoch 00012: val_loss improved from 0.25146 to 0.24528, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/012-0.2453.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.1313 - acc: 0.9621 - val_loss: 0.2453 - val_acc: 0.9278\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1185 - acc: 0.9659\n",
      "Epoch 00013: val_loss improved from 0.24528 to 0.23433, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/013-0.2343.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.1185 - acc: 0.9659 - val_loss: 0.2343 - val_acc: 0.9311\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9715\n",
      "Epoch 00014: val_loss did not improve from 0.23433\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0990 - acc: 0.9715 - val_loss: 0.2707 - val_acc: 0.9196\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9727\n",
      "Epoch 00015: val_loss did not improve from 0.23433\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0959 - acc: 0.9727 - val_loss: 0.2542 - val_acc: 0.9236\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9759\n",
      "Epoch 00016: val_loss improved from 0.23433 to 0.20749, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/016-0.2075.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0855 - acc: 0.9759 - val_loss: 0.2075 - val_acc: 0.9399\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9819\n",
      "Epoch 00017: val_loss improved from 0.20749 to 0.20162, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/017-0.2016.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0658 - acc: 0.9819 - val_loss: 0.2016 - val_acc: 0.9453\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9805\n",
      "Epoch 00018: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0698 - acc: 0.9805 - val_loss: 0.3256 - val_acc: 0.9045\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9855\n",
      "Epoch 00019: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0578 - acc: 0.9854 - val_loss: 0.2238 - val_acc: 0.9418\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9846\n",
      "Epoch 00020: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0589 - acc: 0.9846 - val_loss: 0.2254 - val_acc: 0.9357\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9877\n",
      "Epoch 00021: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0470 - acc: 0.9877 - val_loss: 0.2559 - val_acc: 0.9320\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9898\n",
      "Epoch 00022: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0428 - acc: 0.9898 - val_loss: 0.2589 - val_acc: 0.9297\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9911\n",
      "Epoch 00023: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0378 - acc: 0.9911 - val_loss: 0.2362 - val_acc: 0.9359\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9918\n",
      "Epoch 00024: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0352 - acc: 0.9917 - val_loss: 0.2181 - val_acc: 0.9401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9898\n",
      "Epoch 00025: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0409 - acc: 0.9898 - val_loss: 0.2098 - val_acc: 0.9453\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9936\n",
      "Epoch 00026: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0284 - acc: 0.9936 - val_loss: 0.2440 - val_acc: 0.9331\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9901\n",
      "Epoch 00027: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0398 - acc: 0.9901 - val_loss: 0.2072 - val_acc: 0.9443\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9943\n",
      "Epoch 00028: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0255 - acc: 0.9943 - val_loss: 0.2420 - val_acc: 0.9357\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9947\n",
      "Epoch 00029: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0246 - acc: 0.9947 - val_loss: 0.2183 - val_acc: 0.9446\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9948\n",
      "Epoch 00030: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0225 - acc: 0.9948 - val_loss: 0.2643 - val_acc: 0.9306\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9922\n",
      "Epoch 00031: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0301 - acc: 0.9921 - val_loss: 0.2560 - val_acc: 0.9404\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9923\n",
      "Epoch 00032: val_loss did not improve from 0.20162\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0301 - acc: 0.9923 - val_loss: 0.2536 - val_acc: 0.9329\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9907\n",
      "Epoch 00033: val_loss improved from 0.20162 to 0.19715, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/033-0.1971.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0326 - acc: 0.9907 - val_loss: 0.1971 - val_acc: 0.9462\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9964\n",
      "Epoch 00034: val_loss did not improve from 0.19715\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0166 - acc: 0.9964 - val_loss: 0.2416 - val_acc: 0.9338\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9914\n",
      "Epoch 00035: val_loss did not improve from 0.19715\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0322 - acc: 0.9914 - val_loss: 0.2176 - val_acc: 0.9441\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9921\n",
      "Epoch 00036: val_loss improved from 0.19715 to 0.19427, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/036-0.1943.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0310 - acc: 0.9921 - val_loss: 0.1943 - val_acc: 0.9478\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9981\n",
      "Epoch 00037: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0117 - acc: 0.9980 - val_loss: 0.2230 - val_acc: 0.9425\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9944\n",
      "Epoch 00038: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0229 - acc: 0.9944 - val_loss: 0.2239 - val_acc: 0.9401\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9931\n",
      "Epoch 00039: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0277 - acc: 0.9931 - val_loss: 0.2036 - val_acc: 0.9483\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9982\n",
      "Epoch 00040: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0114 - acc: 0.9982 - val_loss: 0.2293 - val_acc: 0.9422\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9974\n",
      "Epoch 00041: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0125 - acc: 0.9974 - val_loss: 0.2294 - val_acc: 0.9413\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9958\n",
      "Epoch 00042: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0186 - acc: 0.9958 - val_loss: 0.2448 - val_acc: 0.9399\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9949\n",
      "Epoch 00043: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0197 - acc: 0.9949 - val_loss: 0.2039 - val_acc: 0.9504\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9969\n",
      "Epoch 00044: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0139 - acc: 0.9969 - val_loss: 0.2647 - val_acc: 0.9355\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9932\n",
      "Epoch 00045: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0257 - acc: 0.9932 - val_loss: 0.2256 - val_acc: 0.9394\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9986\n",
      "Epoch 00046: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0085 - acc: 0.9986 - val_loss: 0.2237 - val_acc: 0.9432\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9949\n",
      "Epoch 00047: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0197 - acc: 0.9949 - val_loss: 0.2876 - val_acc: 0.9373\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9940\n",
      "Epoch 00048: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0224 - acc: 0.9939 - val_loss: 0.2070 - val_acc: 0.9488\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9945\n",
      "Epoch 00049: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0213 - acc: 0.9945 - val_loss: 0.2102 - val_acc: 0.9467\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9990\n",
      "Epoch 00050: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0069 - acc: 0.9990 - val_loss: 0.2021 - val_acc: 0.9502\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9988\n",
      "Epoch 00051: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0066 - acc: 0.9988 - val_loss: 0.2039 - val_acc: 0.9511\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9969\n",
      "Epoch 00052: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0126 - acc: 0.9969 - val_loss: 0.2749 - val_acc: 0.9313\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9967\n",
      "Epoch 00053: val_loss did not improve from 0.19427\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0134 - acc: 0.9966 - val_loss: 0.2704 - val_acc: 0.9401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9921\n",
      "Epoch 00054: val_loss improved from 0.19427 to 0.19090, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/054-0.1909.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0278 - acc: 0.9921 - val_loss: 0.1909 - val_acc: 0.9485\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9993\n",
      "Epoch 00055: val_loss did not improve from 0.19090\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0065 - acc: 0.9993 - val_loss: 0.2125 - val_acc: 0.9455\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9933\n",
      "Epoch 00056: val_loss did not improve from 0.19090\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0227 - acc: 0.9933 - val_loss: 0.2104 - val_acc: 0.9471\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9962\n",
      "Epoch 00057: val_loss improved from 0.19090 to 0.18215, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_11_conv_checkpoint/057-0.1821.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0151 - acc: 0.9963 - val_loss: 0.1821 - val_acc: 0.9522\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9990\n",
      "Epoch 00058: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0067 - acc: 0.9990 - val_loss: 0.2666 - val_acc: 0.9362\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9946\n",
      "Epoch 00059: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0202 - acc: 0.9945 - val_loss: 0.2528 - val_acc: 0.9394\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9943\n",
      "Epoch 00060: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0203 - acc: 0.9943 - val_loss: 0.2017 - val_acc: 0.9502\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9993\n",
      "Epoch 00061: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0051 - acc: 0.9993 - val_loss: 0.1924 - val_acc: 0.9548\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9988\n",
      "Epoch 00062: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0065 - acc: 0.9988 - val_loss: 0.2277 - val_acc: 0.9490\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9985\n",
      "Epoch 00063: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0079 - acc: 0.9985 - val_loss: 0.2299 - val_acc: 0.9474\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9973\n",
      "Epoch 00064: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0111 - acc: 0.9973 - val_loss: 0.2463 - val_acc: 0.9383\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9932\n",
      "Epoch 00065: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0226 - acc: 0.9932 - val_loss: 0.2023 - val_acc: 0.9522\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9987\n",
      "Epoch 00066: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0065 - acc: 0.9987 - val_loss: 0.2047 - val_acc: 0.9534\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9961\n",
      "Epoch 00067: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0146 - acc: 0.9961 - val_loss: 0.2108 - val_acc: 0.9529\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9989\n",
      "Epoch 00068: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0056 - acc: 0.9989 - val_loss: 0.2105 - val_acc: 0.9492\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9988\n",
      "Epoch 00069: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0058 - acc: 0.9988 - val_loss: 0.2985 - val_acc: 0.9364\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9982\n",
      "Epoch 00070: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0081 - acc: 0.9982 - val_loss: 0.2440 - val_acc: 0.9467\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9974\n",
      "Epoch 00071: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0105 - acc: 0.9974 - val_loss: 0.2565 - val_acc: 0.9429\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9956\n",
      "Epoch 00072: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0150 - acc: 0.9956 - val_loss: 0.2350 - val_acc: 0.9460\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9940\n",
      "Epoch 00073: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0193 - acc: 0.9940 - val_loss: 0.2227 - val_acc: 0.9481\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 00074: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0037 - acc: 0.9995 - val_loss: 0.2110 - val_acc: 0.9483\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9990\n",
      "Epoch 00075: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0048 - acc: 0.9990 - val_loss: 0.2911 - val_acc: 0.9369\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9980\n",
      "Epoch 00076: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0088 - acc: 0.9980 - val_loss: 0.2238 - val_acc: 0.9448\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9952\n",
      "Epoch 00077: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0178 - acc: 0.9952 - val_loss: 0.2051 - val_acc: 0.9499\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9975\n",
      "Epoch 00078: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0102 - acc: 0.9975 - val_loss: 0.1960 - val_acc: 0.9513\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 00079: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0039 - acc: 0.9993 - val_loss: 0.2249 - val_acc: 0.9488\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9954\n",
      "Epoch 00080: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0166 - acc: 0.9953 - val_loss: 0.2187 - val_acc: 0.9490\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9961\n",
      "Epoch 00081: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0141 - acc: 0.9961 - val_loss: 0.1893 - val_acc: 0.9548\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9994\n",
      "Epoch 00082: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0035 - acc: 0.9993 - val_loss: 0.2146 - val_acc: 0.9511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 00083: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0126 - acc: 0.9961 - val_loss: 0.2085 - val_acc: 0.9509\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9981\n",
      "Epoch 00084: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0083 - acc: 0.9981 - val_loss: 0.2029 - val_acc: 0.9550\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9988\n",
      "Epoch 00085: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0057 - acc: 0.9988 - val_loss: 0.2667 - val_acc: 0.9425\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9989\n",
      "Epoch 00086: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0049 - acc: 0.9989 - val_loss: 0.2503 - val_acc: 0.9436\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9983\n",
      "Epoch 00087: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0071 - acc: 0.9983 - val_loss: 0.3014 - val_acc: 0.9369\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9937\n",
      "Epoch 00088: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0213 - acc: 0.9937 - val_loss: 0.2042 - val_acc: 0.9541\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9992\n",
      "Epoch 00089: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0039 - acc: 0.9992 - val_loss: 0.2124 - val_acc: 0.9520\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9995\n",
      "Epoch 00090: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0030 - acc: 0.9995 - val_loss: 0.2039 - val_acc: 0.9520\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9988\n",
      "Epoch 00091: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0049 - acc: 0.9987 - val_loss: 0.2718 - val_acc: 0.9422\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9938\n",
      "Epoch 00092: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0207 - acc: 0.9938 - val_loss: 0.2432 - val_acc: 0.9467\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 00093: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0040 - acc: 0.9992 - val_loss: 0.2146 - val_acc: 0.9553\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9952\n",
      "Epoch 00094: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0170 - acc: 0.9952 - val_loss: 0.2094 - val_acc: 0.9532\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9990\n",
      "Epoch 00095: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0056 - acc: 0.9989 - val_loss: 0.2233 - val_acc: 0.9509\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9921\n",
      "Epoch 00096: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0274 - acc: 0.9921 - val_loss: 0.2067 - val_acc: 0.9534\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9967\n",
      "Epoch 00097: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0122 - acc: 0.9967 - val_loss: 0.2017 - val_acc: 0.9555\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9995\n",
      "Epoch 00098: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0033 - acc: 0.9995 - val_loss: 0.1982 - val_acc: 0.9550\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9996\n",
      "Epoch 00099: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0027 - acc: 0.9996 - val_loss: 0.1886 - val_acc: 0.9567\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9997\n",
      "Epoch 00100: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0025 - acc: 0.9997 - val_loss: 0.1919 - val_acc: 0.9583\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9981\n",
      "Epoch 00101: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0068 - acc: 0.9981 - val_loss: 0.2357 - val_acc: 0.9492\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9977\n",
      "Epoch 00102: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0087 - acc: 0.9977 - val_loss: 0.3282 - val_acc: 0.9313\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9942\n",
      "Epoch 00103: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0206 - acc: 0.9942 - val_loss: 0.2251 - val_acc: 0.9502\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9954\n",
      "Epoch 00104: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0153 - acc: 0.9953 - val_loss: 0.1984 - val_acc: 0.9527\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9959\n",
      "Epoch 00105: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0136 - acc: 0.9959 - val_loss: 0.1958 - val_acc: 0.9529\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9996\n",
      "Epoch 00106: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0029 - acc: 0.9996 - val_loss: 0.2002 - val_acc: 0.9543\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9957\n",
      "Epoch 00107: val_loss did not improve from 0.18215\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0153 - acc: 0.9956 - val_loss: 0.2321 - val_acc: 0.9436\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_11_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 969us/sample - loss: 0.2282 - acc: 0.9443\n",
      "Loss: 0.2282284504442881 Accuracy: 0.9443406\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6728 - acc: 0.4854\n",
      "Epoch 00001: val_loss improved from inf to 1.28050, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_12_conv_checkpoint/001-1.2805.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 1.6726 - acc: 0.4855 - val_loss: 1.2805 - val_acc: 0.5952\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7228 - acc: 0.7858\n",
      "Epoch 00002: val_loss improved from 1.28050 to 0.64450, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_12_conv_checkpoint/002-0.6445.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.7230 - acc: 0.7858 - val_loss: 0.6445 - val_acc: 0.8034\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4724 - acc: 0.8617\n",
      "Epoch 00003: val_loss improved from 0.64450 to 0.39016, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_12_conv_checkpoint/003-0.3902.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.4725 - acc: 0.8617 - val_loss: 0.3902 - val_acc: 0.8910\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3531 - acc: 0.8960\n",
      "Epoch 00004: val_loss did not improve from 0.39016\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.3532 - acc: 0.8960 - val_loss: 0.4327 - val_acc: 0.8696\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2805 - acc: 0.9164\n",
      "Epoch 00005: val_loss improved from 0.39016 to 0.29592, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_12_conv_checkpoint/005-0.2959.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.2805 - acc: 0.9164 - val_loss: 0.2959 - val_acc: 0.9152\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2279 - acc: 0.9337\n",
      "Epoch 00006: val_loss improved from 0.29592 to 0.25420, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_12_conv_checkpoint/006-0.2542.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.2279 - acc: 0.9338 - val_loss: 0.2542 - val_acc: 0.9248\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9417\n",
      "Epoch 00007: val_loss improved from 0.25420 to 0.23514, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_12_conv_checkpoint/007-0.2351.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1959 - acc: 0.9416 - val_loss: 0.2351 - val_acc: 0.9329\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9495\n",
      "Epoch 00008: val_loss did not improve from 0.23514\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1704 - acc: 0.9495 - val_loss: 0.2491 - val_acc: 0.9304\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9555\n",
      "Epoch 00009: val_loss improved from 0.23514 to 0.21130, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_12_conv_checkpoint/009-0.2113.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1497 - acc: 0.9555 - val_loss: 0.2113 - val_acc: 0.9359\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1294 - acc: 0.9618\n",
      "Epoch 00010: val_loss did not improve from 0.21130\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1295 - acc: 0.9617 - val_loss: 0.2119 - val_acc: 0.9392\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9652\n",
      "Epoch 00011: val_loss did not improve from 0.21130\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1184 - acc: 0.9652 - val_loss: 0.2290 - val_acc: 0.9350\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9689\n",
      "Epoch 00012: val_loss improved from 0.21130 to 0.18020, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_12_conv_checkpoint/012-0.1802.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1060 - acc: 0.9688 - val_loss: 0.1802 - val_acc: 0.9455\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9722\n",
      "Epoch 00013: val_loss did not improve from 0.18020\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0975 - acc: 0.9722 - val_loss: 0.1979 - val_acc: 0.9406\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9757\n",
      "Epoch 00014: val_loss did not improve from 0.18020\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0825 - acc: 0.9757 - val_loss: 0.1938 - val_acc: 0.9434\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9813\n",
      "Epoch 00015: val_loss did not improve from 0.18020\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0696 - acc: 0.9813 - val_loss: 0.2005 - val_acc: 0.9406\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9815\n",
      "Epoch 00016: val_loss did not improve from 0.18020\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0662 - acc: 0.9815 - val_loss: 0.2279 - val_acc: 0.9352\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9849\n",
      "Epoch 00017: val_loss did not improve from 0.18020\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0550 - acc: 0.9849 - val_loss: 0.2045 - val_acc: 0.9380\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9859\n",
      "Epoch 00018: val_loss did not improve from 0.18020\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0532 - acc: 0.9859 - val_loss: 0.2116 - val_acc: 0.9401\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9853\n",
      "Epoch 00019: val_loss did not improve from 0.18020\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0525 - acc: 0.9852 - val_loss: 0.2062 - val_acc: 0.9441\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9867\n",
      "Epoch 00020: val_loss did not improve from 0.18020\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0498 - acc: 0.9867 - val_loss: 0.2382 - val_acc: 0.9324\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9927\n",
      "Epoch 00021: val_loss did not improve from 0.18020\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0323 - acc: 0.9927 - val_loss: 0.2057 - val_acc: 0.9408\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9923\n",
      "Epoch 00022: val_loss did not improve from 0.18020\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0310 - acc: 0.9923 - val_loss: 0.2030 - val_acc: 0.9392\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9885\n",
      "Epoch 00023: val_loss improved from 0.18020 to 0.16749, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_12_conv_checkpoint/023-0.1675.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0435 - acc: 0.9885 - val_loss: 0.1675 - val_acc: 0.9546\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9939\n",
      "Epoch 00024: val_loss did not improve from 0.16749\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0265 - acc: 0.9939 - val_loss: 0.2087 - val_acc: 0.9418\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9892\n",
      "Epoch 00025: val_loss did not improve from 0.16749\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0399 - acc: 0.9892 - val_loss: 0.1964 - val_acc: 0.9476\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9953\n",
      "Epoch 00026: val_loss did not improve from 0.16749\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0220 - acc: 0.9952 - val_loss: 0.1814 - val_acc: 0.9511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9877\n",
      "Epoch 00027: val_loss improved from 0.16749 to 0.16099, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_12_conv_checkpoint/027-0.1610.hdf5\n",
      "36805/36805 [==============================] - 65s 2ms/sample - loss: 0.0441 - acc: 0.9877 - val_loss: 0.1610 - val_acc: 0.9536\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9968\n",
      "Epoch 00028: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0168 - acc: 0.9967 - val_loss: 0.1653 - val_acc: 0.9543\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9923\n",
      "Epoch 00029: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0308 - acc: 0.9923 - val_loss: 0.1875 - val_acc: 0.9520\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9971\n",
      "Epoch 00030: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0163 - acc: 0.9971 - val_loss: 0.2502 - val_acc: 0.9350\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9973\n",
      "Epoch 00031: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0146 - acc: 0.9973 - val_loss: 0.2203 - val_acc: 0.9415\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9956\n",
      "Epoch 00032: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0177 - acc: 0.9956 - val_loss: 0.2313 - val_acc: 0.9434\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9934\n",
      "Epoch 00033: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0242 - acc: 0.9934 - val_loss: 0.2032 - val_acc: 0.9490\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9915\n",
      "Epoch 00034: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0303 - acc: 0.9915 - val_loss: 0.1702 - val_acc: 0.9520\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9923\n",
      "Epoch 00035: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0275 - acc: 0.9923 - val_loss: 0.1865 - val_acc: 0.9522\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9983\n",
      "Epoch 00036: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0102 - acc: 0.9983 - val_loss: 0.2064 - val_acc: 0.9511\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9913\n",
      "Epoch 00037: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0313 - acc: 0.9913 - val_loss: 0.1727 - val_acc: 0.9543\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9938\n",
      "Epoch 00038: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0239 - acc: 0.9938 - val_loss: 0.1808 - val_acc: 0.9534\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9984\n",
      "Epoch 00039: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0087 - acc: 0.9984 - val_loss: 0.1677 - val_acc: 0.9574\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9975\n",
      "Epoch 00040: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0120 - acc: 0.9975 - val_loss: 0.1967 - val_acc: 0.9481\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9978\n",
      "Epoch 00041: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0104 - acc: 0.9978 - val_loss: 0.2115 - val_acc: 0.9490\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9960\n",
      "Epoch 00042: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0162 - acc: 0.9959 - val_loss: 0.2015 - val_acc: 0.9525\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9917\n",
      "Epoch 00043: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0275 - acc: 0.9917 - val_loss: 0.2596 - val_acc: 0.9352\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9982\n",
      "Epoch 00044: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0088 - acc: 0.9982 - val_loss: 0.2488 - val_acc: 0.9411\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9981\n",
      "Epoch 00045: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0098 - acc: 0.9981 - val_loss: 0.1728 - val_acc: 0.9567\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9986\n",
      "Epoch 00046: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0084 - acc: 0.9986 - val_loss: 0.2115 - val_acc: 0.9476\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9968\n",
      "Epoch 00047: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0127 - acc: 0.9968 - val_loss: 0.1972 - val_acc: 0.9539\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9957\n",
      "Epoch 00048: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0153 - acc: 0.9957 - val_loss: 0.2200 - val_acc: 0.9474\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9983\n",
      "Epoch 00049: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0086 - acc: 0.9983 - val_loss: 0.2007 - val_acc: 0.9513\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9962\n",
      "Epoch 00050: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0134 - acc: 0.9962 - val_loss: 0.2145 - val_acc: 0.9464\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9989\n",
      "Epoch 00051: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0063 - acc: 0.9989 - val_loss: 0.2165 - val_acc: 0.9462\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9937\n",
      "Epoch 00052: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0234 - acc: 0.9937 - val_loss: 0.2170 - val_acc: 0.9488\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9991\n",
      "Epoch 00053: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0055 - acc: 0.9991 - val_loss: 0.1767 - val_acc: 0.9592\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9975\n",
      "Epoch 00054: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0105 - acc: 0.9975 - val_loss: 0.1631 - val_acc: 0.9588\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9980\n",
      "Epoch 00055: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0086 - acc: 0.9980 - val_loss: 0.2214 - val_acc: 0.9504\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9945\n",
      "Epoch 00056: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0177 - acc: 0.9944 - val_loss: 0.2353 - val_acc: 0.9462\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9934\n",
      "Epoch 00057: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0244 - acc: 0.9933 - val_loss: 0.1856 - val_acc: 0.9553\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9974\n",
      "Epoch 00058: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0117 - acc: 0.9974 - val_loss: 0.1800 - val_acc: 0.9520\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9992\n",
      "Epoch 00059: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0048 - acc: 0.9992 - val_loss: 0.1940 - val_acc: 0.9564\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9967\n",
      "Epoch 00060: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0120 - acc: 0.9966 - val_loss: 0.1760 - val_acc: 0.9553\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9954\n",
      "Epoch 00061: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0166 - acc: 0.9954 - val_loss: 0.2149 - val_acc: 0.9532\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9939\n",
      "Epoch 00062: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0203 - acc: 0.9938 - val_loss: 0.1885 - val_acc: 0.9555\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9977\n",
      "Epoch 00063: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0103 - acc: 0.9977 - val_loss: 0.1758 - val_acc: 0.9576\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9991\n",
      "Epoch 00064: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0048 - acc: 0.9990 - val_loss: 0.1722 - val_acc: 0.9550\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9959\n",
      "Epoch 00065: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0138 - acc: 0.9959 - val_loss: 0.1895 - val_acc: 0.9553\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9988\n",
      "Epoch 00066: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0057 - acc: 0.9988 - val_loss: 0.1786 - val_acc: 0.9562\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9963\n",
      "Epoch 00067: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0132 - acc: 0.9963 - val_loss: 0.1888 - val_acc: 0.9557\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0050 - acc: 0.9989\n",
      "Epoch 00068: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0052 - acc: 0.9988 - val_loss: 0.2266 - val_acc: 0.9436\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9932\n",
      "Epoch 00069: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0229 - acc: 0.9932 - val_loss: 0.1792 - val_acc: 0.9550\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9993\n",
      "Epoch 00070: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0040 - acc: 0.9993 - val_loss: 0.1853 - val_acc: 0.9557\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9996\n",
      "Epoch 00071: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0031 - acc: 0.9996 - val_loss: 0.1901 - val_acc: 0.9571\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9949\n",
      "Epoch 00072: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0190 - acc: 0.9948 - val_loss: 0.2048 - val_acc: 0.9511\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9970\n",
      "Epoch 00073: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0112 - acc: 0.9970 - val_loss: 0.1909 - val_acc: 0.9520\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9994\n",
      "Epoch 00074: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0034 - acc: 0.9994 - val_loss: 0.1732 - val_acc: 0.9569\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9996\n",
      "Epoch 00075: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0033 - acc: 0.9996 - val_loss: 0.1640 - val_acc: 0.9597\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9976\n",
      "Epoch 00076: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0091 - acc: 0.9976 - val_loss: 0.1980 - val_acc: 0.9546\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9959\n",
      "Epoch 00077: val_loss did not improve from 0.16099\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0138 - acc: 0.9959 - val_loss: 0.1837 - val_acc: 0.9569\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_12_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8VNX5+PHPmckkk30ngSwEBAXCElZpUXEXq1Jbq7hVa6ut36+2WltbajftptVuP1o3VFq1rUtxr1ZcCqJV+xURZFUgrCH7vkwy2/P748wkAZKQhAwJ8Lxfr/tK5q7P3Jm5zznn3nuuERGUUkqpg3EMdgBKKaWODJowlFJK9YomDKWUUr2iCUMppVSvaMJQSinVK5owlFJK9UpUpFZsjFkCnA9UiMjELqbfClzRKY7xQKaI1BhjdgCNQADwi8iMSMWplFKqd0yk7sMwxpwCNAGPdZUw9pv3AuDbInJ66PUOYIaIVEUkOKWUUn0WsSYpEVkJ1PRy9suAJyIVi1JKqUMXsSap3jLGxAHzgBs7jRbgNWOMAA+KyOLerCsjI0MKCgoGPkillDpKffjhh1UiktmbeQc9YQAXAP8Rkc61kZNEpMQYMwx43RizOVRjOYAx5uvA1wHy8/NZtWpV5CNWSqmjhDFmZ2/nHQpXSV3Kfs1RIlIS+lsBPAfM6m5hEVksIjNEZEZmZq+SpFJKqX4Y1IRhjEkG5gIvdBoXb4xJDP8PnA2sH5wIlVJKhUXystongFOBDGPMHuCngAtARB4IzfYF4DURae60aBbwnDEmHN/fReTVSMWplFKqdyKWMETksl7M8xfgL/uNKwamDFQcPp+PPXv20NraOlCrPKa43W5yc3NxuVyDHYpSapANhZPeEbVnzx4SExMpKCggVGtRvSQiVFdXs2fPHkaNGjXY4SilBtlQOOkdUa2traSnp2uy6AdjDOnp6Vo7U0oBx0DCADRZHALdd0qpsGMiYRxMW9te/P76wQ5DKaWGNE0YgNdbht/fEJF119XVcd999/Vr2c997nPU1dX1ev7bb7+d3/zmN/3allJKHYwmDMAYBxCMyLp7Shh+v7/HZV955RVSUlIiEZZSSvWZJgwAHIhEJmEsXLiQbdu2UVRUxK233sqKFSs4+eSTmT9/PhMmTADgwgsvZPr06RQWFrJ4cUe3WQUFBVRVVbFjxw7Gjx/PddddR2FhIWeffTYej6fH7a5Zs4bZs2czefJkvvCFL1BbWwvAokWLmDBhApMnT+bSSy8F4K233qKoqIiioiKmTp1KY2NjRPaFUurIdtRfVtvZli0309S05oDxgUAzxjhwOGL7vM6EhCLGjv1Dt9Pvuusu1q9fz5o1drsrVqxg9erVrF+/vv1S1SVLlpCWlobH42HmzJlcdNFFpKen7xf7Fp544gkeeughLrnkEp555hmuvPLKbrd71VVX8cc//pG5c+fyk5/8hDvuuIM//OEP3HXXXWzfvp2YmJj25q7f/OY33HvvvcyZM4empibcbnef94NS6uinNQzgcF8INGvWrH3ua1i0aBFTpkxh9uzZ7N69my1bthywzKhRoygqKgJg+vTp7Nixo9v119fXU1dXx9y5cwG4+uqrWbnS9t04efJkrrjiCv76178SFWXLC3PmzOGWW25h0aJF1NXVtY9XSqnOjqkjQ3c1gebmTRjjJC7u+MMSR3x8fPv/K1as4I033uC9994jLi6OU089tcv7HmJiYtr/dzqdB22S6s7LL7/MypUreemll/jlL3/JunXrWLhwIeeddx6vvPIKc+bMYdmyZYwbN65f61dKHb20hoE96R2pcxiJiYk9nhOor68nNTWVuLg4Nm/ezPvvv3/I20xOTiY1NZW3334bgMcff5y5c+cSDAbZvXs3p512Gr/+9a+pr6+nqamJbdu2MWnSJL7//e8zc+ZMNm/efMgxKKWOPsdUDaN7DsAXkTWnp6czZ84cJk6cyLnnnst55523z/R58+bxwAMPMH78eE444QRmz549INt99NFHuf7662lpaWH06NH8+c9/JhAIcOWVV1JfX4+I8K1vfYuUlBR+/OMfs3z5chwOB4WFhZx77rkDEoNS6ugSsWd6D4YZM2bI/g9Q2rRpE+PHj+9xOY9nG8Ggh/j4Hh89fszqzT5USh2ZjDEfisiM3syrTVJAJC+rVUqpo4UmDCJ7455SSh0tNGEAYLSGoZRSB6EJg3AN4+g5l6OUUpGgCQOwu0E4mi4AUEqpgaYJA+jYDdospZRS3dGEQbhJiiFzHiMhIaFP45VS6nDQhAFoDUMppQ4uYgnDGLPEGFNhjFnfzfRTjTH1xpg1oeEnnabNM8Z8YozZaoxZGKkYO20PiEwNY+HChdx7773tr8MPOWpqauKMM85g2rRpTJo0iRdeeKHX6xQRbr31ViZOnMikSZN46qmnACgtLeWUU06hqKiIiRMn8vbbbxMIBPjKV77SPu/vf//7AX+PSqljQyS7BvkL8CfgsR7meVtEzu88whjjBO4FzgL2AB8YY14UkY2HHNHNN8OaA7s3d4qf2KAHhyMOjLNv6ywqgj903735ggULuPnmm7nhhhsAePrpp1m2bBlut5vnnnuOpKQkqqqqmD17NvPnz+/VM7SfffZZ1qxZw9q1a6mqqmLmzJmccsop/P3vf+ecc87hhz/8IYFAgJaWFtasWUNJSQnr19u83Zcn+CmlVGcRSxgistIYU9CPRWcBW0WkGMAY8yTweeDQE0Y3Itm7+dSpU6moqGDv3r1UVlaSmppKXl4ePp+P2267jZUrV+JwOCgpKaG8vJzs7OyDrvOdd97hsssuw+l0kpWVxdy5c/nggw+YOXMmX/3qV/H5fFx44YUUFRUxevRoiouL+eY3v8l5553H2WefHcF3q5Q6mg1254OfMcasBfYC3xWRDUAOsLvTPHuAEwdka93UBAL+RjyeT4iNPZ6oqKQB2VRnF198MUuXLqWsrIwFCxYA8Le//Y3Kyko+/PBDXC4XBQUFXXZr3hennHIKK1eu5OWXX+YrX/kKt9xyC1dddRVr165l2bJlPPDAAzz99NMsWbJkIN6WUuoYM5gnvVcDI0VkCvBH4Pn+rMQY83VjzCpjzKrKysp+BRLpq6QWLFjAk08+ydKlS7n44osB2635sGHDcLlcLF++nJ07d/Z6fSeffDJPPfUUgUCAyspKVq5cyaxZs9i5cydZWVlcd911XHvttaxevZqqqiqCwSAXXXQRv/jFL1i9enVE3qNS6ug3aDUMEWno9P8rxpj7jDEZQAmQ12nW3NC47tazGFgMtrfa/kUT2aukCgsLaWxsJCcnh+HDhwNwxRVXcMEFFzBp0iRmzJjRpwcWfeELX+C9995jypQpGGO4++67yc7O5tFHH+Wee+7B5XKRkJDAY489RklJCddccw3BoH1vd955Z0Teo1Lq6BfR7s1D5zD+KSIH9BtujMkGykVEjDGzgKXASMAJfAqcgU0UHwCXh5qretTf7s2DwTaam9fhdhfgcmX05q0dU7R7c6WOXn3p3jxiNQxjzBPAqUCGMWYP8FPABSAiDwBfAv7HGOMHPMClYrOX3xhzI7AMmzyW9CZZHGK02Lj0PgyllOpOJK+Suuwg0/+Evey2q2mvAK9EIq6uhZuktC8ppZTqjt7pzdDrGkQppYYiTRhAx50YmjCUUqo7mjAIdw2ij2lVSqmeaMJop49pVUqpnmjCCDEmMjWMuro67rvvvn4t+7nPfU77flJKDRmaMNpFpobRU8Lw+/09LvvKK6+QkpIy4DEppVR/aMIIMcZE5BGtCxcuZNu2bRQVFXHrrbeyYsUKTj75ZObPn8+ECRMAuPDCC5k+fTqFhYUsXry4fdmCggKqqqrYsWMH48eP57rrrqOwsJCzzz4bj8dzwLZeeuklTjzxRKZOncqZZ55JeXk5AE1NTVxzzTVMmjSJyZMn88wzzwDw6quvMm3aNKZMmcIZZ5wx4O9dKXV0GezOBw+rbno3ByAQKMAYg6OPKfQgvZtz1113sX79etaENrxixQpWr17N+vXrGTVqFABLliwhLS0Nj8fDzJkzueiii0hPT99nPVu2bOGJJ57goYce4pJLLuGZZ57hyiuv3Geek046iffffx9jDA8//DB33303v/3tb/n5z39OcnIy69atA6C2tpbKykquu+46Vq5cyahRo6ipqenbG1dKHXOOqYTRk948h2KgzJo1qz1ZACxatIjnnnsOgN27d7Nly5YDEsaoUaMoKioCYPr06ezYseOA9e7Zs4cFCxZQWlqK1+tt38Ybb7zBk08+2T5famoqL730Eqecckr7PGlpaQP6HpVSR59jKmH0VBNoaSlBxEd8/ISIxxEfH9/+/4oVK3jjjTd47733iIuL49RTT+2ym/OYmJj2/51OZ5dNUt/85je55ZZbmD9/PitWrOD222+PSPxKqWOTnsMIsXd7D/xJ78TERBobG7udXl9fT2pqKnFxcWzevJn333+/39uqr68nJycHgEcffbR9/FlnnbXPY2Jra2uZPXs2K1euZPv27QDaJKWUOihNGO1MRC6rTU9PZ86cOUycOJFbb731gOnz5s3D7/czfvx4Fi5cyOzZs/u9rdtvv52LL76Y6dOnk5HR0evuj370I2pra5k4cSJTpkxh+fLlZGZmsnjxYr74xS8yZcqU9gc7KaVUdyLavfnh1t/uzQFaW3fg99eTkDAlUuEdsbR7c6WOXn3p3lxrGO20axCllOqJJoyQSJ3DUEqpo4UmjHYOQCJy855SSh0NNGG0i+xzvZVS6kinCSNEH6KklFI904TRTh+ipJRSPdGEAeD3Y0J5YijUMBISEgY7BKWUOoAmDIC1a3FU1Ide6ElvpZTqSsQShjFmiTGmwhizvpvpVxhjPjbGrDPGvGuMmdJp2o7Q+DXGmFVdLT+gnE5MwCaKga5hLFy4cJ9uOW6//XZ+85vf0NTUxBlnnMG0adOYNGkSL7zwwkHX1V036F11U95dl+ZKKdVfkex88C/An4DHupm+HZgrIrXGmHOBxcCJnaafJiJVAxnQza/ezJqyLvo3b24Gh4NAtB+HIw5jnL1eZ1F2EX+Y132vhgsWLODmm2/mhhtuAODpp59m2bJluN1unnvuOZKSkqiqqmL27NnMnz+/x15zu+oGPRgMdtlNeVddmiul1KGIWMIQkZXGmIIepr/b6eX7QG6kYukd2e/vwJg6dSoVFRXs3buXyspKUlNTycvLw+fzcdttt7Fy5UocDgclJSWUl5eTnZ3d7bq66ga9srKyy27Ku+rSXCmlDsVQ6d78a8C/Or0W4DVjjAAPisjirhcDY8zXga8D5Ofn97iRbmsCmzcjBGnKacHtHo3LNbDPhrj44otZunQpZWVl7Z38/e1vf6OyspIPP/wQl8tFQUFBl92ah/W2G3SllIqUQT/pbYw5DZswvt9p9EkiMg04F7jBGHNKd8uLyGIRmSEiMzIzM/sXhNMJwXDNYuCvklqwYAFPPvkkS5cu5eKLLwZsV+TDhg3D5XKxfPlydu7c2eM6uusGvbtuyrvq0lwppQ7FoCYMY8xk4GHg8yJSHR4vIiWhvxXAc8CsiAbidEIgENr2wCeMwsJCGhsbycnJYfjw4QBcccUVrFq1ikmTJvHYY48xbty4HtfRXTfo3XVT3lWX5kopdSgi2r156BzGP0VkYhfT8oF/A1d1Pp9hjIkHHCLSGPr/deBnIvLqwbbX7+7Nd+5E6mppGu0nJiaP6Oisg763Y4l2b67U0asv3ZtH7ByGMeYJ4FQgwxizB/gp4AIQkQeAnwDpwH2hK4P8oaCzgOdC46KAv/cmWRwShwMCtmYxFG7cU0qpoSiSV0lddpDp1wLXdjG+GDi8TzFyOjHBYOgCKU0YSinVlUE/6X04HLTZzWnvuzBBfYjS/rS7d6VU2FGfMNxuN9XV1T0f+Bx2N5igQWsYHUSE6upq3G73YIeilBoChsp9GBGTm5vLnj17qKys7H6m5maoqsIrDkxMMy5Xy+ELcIhzu93k5g7yPZVKqSHhqE8YLper/S7obi1bBueey4bFuZg5JzF+/BOHJzillDqCHPVNUr2SmAhAlMdFIKC1C6WU6oomDICkJACiPE6CQc8gB6OUUkOTJgxor2G4WjRhKKVUdzRhQEcNo8UQCGjCUEqprmjCgPYahrPFoTUMpZTqxlF/lVSvREVBbCxRLUIwqF2GK6VUV7SGEZaUhLNFtIahlFLd0IQRlpSEszmo5zCUUqobmjDCEhNxNPsJBvU+DKWU6oomjLCkJJzNfkR8iAQGOxqllBpyNGGEJSbiaPYBaLOUUkp1QRNGWFISjiYvgJ74VkqpLmjCCEtKwjS1AZowlFKqK5owwhITcTTZezA0YSil1IE0YYQlJWG8foxXz2EopVRXNGGEtfdYqzUMpZTqSkQThjFmiTGmwhizvpvpxhizyBiz1RjzsTFmWqdpVxtjtoSGqyMZJ9DRn1Qzei+GUkp1IdI1jL8A83qYfi4wNjR8HbgfwBiTBvwUOBGYBfzUGJMa0UhDNQxnizZJKaVUVyKaMERkJVDTwyyfBx4T630gxRgzHDgHeF1EakSkFnidnhPPoQs/da9Fm6SUUqorg91bbQ6wu9PrPaFx3Y2PnE41DE0YfSNi/xrTu3krK20HwWlpB06vq4MNG2z+LiwEp3Pf6du3w7//DV4vjB4No0bByJHg88HWrR1DXZ3dVniIjoaEBLvehARITobU1I4hJcWOd3RThKqrg3Xr4OOPYf16u76ZM+0wdmzHcm1tUF0Nu3dDcbEdtm2D5ma7THhwOGxcwaAdoqNtTElJdhg2DAoK7JCWZt/fxo2werUdqqrs/jbGrisYBL+/Y4iK6lhXUhLEx0NsLLjd9q/Xa9cRHgIBuw+Sk+3fYNCOr6y0f6OjYdw4OOEE+9fhgE2bOoaGhn33b3T0vvHExkJOTseQnt4Rj9sNLS2wcyfs2mWHigq7zoYGaGy0+zY9vWNISbHLh4f4eLvd8NDWZj+D8FBVZbfR3GwHpxOysyEry/51uex7ray02/b57H4Pby8qyn6u1dV2XU4nTJgAEyfa76nbDWvX2u/H2rWwd2/HZxsMQlwcjBnTMaSm2u9UbW3H35qajqG52S4X/o5ERe37+SQldezrxEQb44IFvfm1HprBThiHzBjzdWxzFvn5+f1fUftDlI69hNHcbH+YbW3Q2mr/gv0RRUXZv15vx4+tqckeBNets8P69fZH7XTaISrK/iDy8uyQm2vXHz641Nba9aek2B/PccfZ5detsz/usIQEmDULZs+2P6LXX7fb3Z8xHUkrLDq644BqjI0/cJAeX4yxP76kJPsevF47tLV1HLTCcXu9sGiRfZ2UZN9vVZXdP/sbMcLO03l9waA96DocHfE1NNiD6/4SEjqWDb8eMWLfhGhMx+cVFWUPeI2NHQfd7t57XBxkZto46uvtEJ7X7bbTMjLswfallw6Mz+WyCTMtzX52TU12u15vRzxOp90vNT21NewnLW3fhCdivx9VVXY9wWDv1+Vy2fcQH2+HuDj7PjZvhrKyjv1qjJ0vM9Mus2aNTRAtoVOa0dF2enq6/Z08//yBcTgccPzxthATFdXxGdfXw4oV8PjjXcfodtv1pqXZITu747thjP086+thyxabYBoa7L4Ob3/48GMjYZQAeZ1e54bGlQCn7jd+RVcrEJHFwGKAGTNmSFfz9Eqnk95H+jkMEVvC2bDBlko3brRfts4l2tpaO09p6b4Hw75ITYXJk+Hqq+2XPBDoKFGGS9kffwwvv2wPcuPH2y/1uHF2nm3bbG3ggw/s9FNOsSW2iRNtvO+9Z4df/9qWIk89Fb71LTjzTHvQDpfgi4vtj3nsWDscd1z7x7nPPmlt7Tig1dfvW7oL/wjDB81wqT862h48hg+HSZPs+83Jse910yYb+wcf2ANi+GCSkWHnP+44WwOKi+v959baardfXm5rUzt22L8xMTBtmh3GjOm+JtTder1e8Hg6hqgoG+f+sYnYfWSMPbh2rjX6fHZff/KJff8TJthansvVuzg8HvudKymxB/1wAaW11e7nkSPtkJtr3293gkF7EPd4Ov52Lsw0Ndn3Fy6sZGV1v79E7P72eu1nt3+NNhx3IHDg/mhttftiwwb7/6RJtrbR0+ft8djPs76+o3abnGwTRl+J2Pff1GS3fzgY2b9oNtAbMKYA+KeITOxi2nnAjcDnsCe4F4nIrNBJ7w+B8FVTq4HpItJjGWXGjBmyatWq/gXa0ADJyWz9H3B9/1eMHPmD/q0nwsI/uq6GkpKOvy2dLvQKH8Q6l1hSUmwpdfhwO6Sk2B+p293xY/X57IHd57MHhYSEjlJafr5dvjfNUAPxnsM1HaXUwDLGfCgiM3ozb0RrGMaYJ7A1hQxjzB7slU8uABF5AHgFmyy2Ai3ANaFpNcaYnwMfhFb1s4Mli0OWkABAVPPgNUmJ2BL/xx/bkmXnRBAeuqrWx8TYg3dOji2Bnn++Ld0WFtohM/Owv5UBFRs72BGonogIrf5WnA4nUY4oHEZv7xooIkKzrxkRITEm8eALRFhEE4aIXHaQ6QLc0M20JcCSSMTVJYcDEhKI8nhoDUT+PgyPxzYVhc8DrF1rh6qqfUPKyrLJYNQoOOmkfU8cjhhhh5SUw1PS7482fxvPbnqWOFcc5449l2hn9EGXafG1UNlcSVVLFdWeaqpbqmn2NeMNePEFfHgDXtxRbtJi00iNTSUtNo3CzMJD/kGJCPVt9VQ0V9DsbUYQghIkKEGiHFHERsXijnIT64qlxddCaWMpZU1llDaV0uZvIyYqhhhnDDFRMTS2NbKrfhe7Gnaxq34Xqe5Uzj7ubM4+7mxOSD8B08UHFpQglc2V7G3cS05SDsPihx005m0121j030XUt9VzxqgzOHP0mQxPHN6+vuLaYtaWrQVg6vCpjEoZdcC2m7xNGAzx0fG93let/lb+vf3fvLD5BV789EXKmsr2mZ6TmMMpI09h7si5nFpwKsenH3/AdkWEdRXreKP4DSqaK8hOyGZ4wnCyE7IRhO212ymuLaa4rpjGtsb2fR8bFUtCdALJMcmkuFNIcafgMA5qPDXUtta2/61rraO+tZ661jqCEiQ9Lp2MuAzSY9OJd8Xv8/n6g37a/G20BewQlCBOYxOg0+EkLymPyyZexqSsSfu8h1pPLc9vfp51FevwBXz4gvb72RZoo8XXQrO3mRZfC+4oN5OGTWJy1mQmZ00mNykXb8BLq7+VtkAbVS1VbKnewtaarWyp2cKu+l1UNFdQ2VJJq9+2N2UnZHNC+gmckH4CGXEZ1LbWtr/fGGcML172Yq8/v/6KeJPU4XRITVIAOTmUTa2m4Xdf4/jj7x2wuERs2+8778B//gPvvmvbv8MnrNxuWxMoKoIpU+wwZoy9UiZqv5Re31rP68WvIyIcn348Y9LGtP/QRYSGtgaqWqpwOV1kxmUS6+p/8TwoQSqaK9hdv5v85HyyErJ6vWytp5b7V93PH//vj+0Hk8y4TK6YdAXXTL2GrPgs1lesZ0PlBtZXrGdH3Q5KGkvY27iXuta6Psea4k7hltm3cNPsm0iKSTpguojQFmijoa2B+tZ6dtTtYGPlRjtUbWRn3U4qmitoC7T1edvdiXZGk5+cT15SHnsa9rClZgsA+cn5jE0baw9OoYNUjaeGsqYy/EF7VjnGGcP1M65n4UkLyU7IPmDdH+79kLvfvZulG5cS5YgiMTqRak81AIWZhSS7k/m4/GOavE37LJcck0xRdhFJMUk2odXvorbVXoUwPGE4Y9PHMiZ1DFkJWTiMA4dxYDC0+ls7Erinmo9KP6LZ10xCdALnjjmXqdlTCUqQgATwBXxsrd3KWzveorSpFIDE6EQKUgooSClgZPJIalpr2hMFgMvhwhf0HfA+ncZJXnIeKe4UWv2teHwePH4PjW2NePxdtwQkxSSR4k4h1Z1KstsmFYNpL3xUtVTR4mvpeH/GEOWIak/2Mc4YnA4ngWAAf9CPP+hnd8Nu/EE/k7Mmc8WkK8iKz+IfG//Ba9tewxf0EeeKI8YZQ7QzGpfTRYwzhvjoeOJcccS74mloa2BD5QZafD0XRqOd0RyXehwFKQUMix9GZlwmmfGZBIIBttRs4ZPqT/ik6hNqW2tJddvCUlpsGrlJuSy9ZGmP6+5OX5qkNGF0Nm4cVTm7qLr3UsaN63/lxueztYV33ukYysvttORk+OxnYcYMe5Is74RqWhM3UtK4q720Wt5cTrwrvv0HlpeUx9rytbzwyQss3778gB/WiMQRGAyVLZV4A959piVEJ5AZl0lBSgHjMsYxPmM84zLG4XQ4qWyupLKlksrmyvYSWXgobSpld/3u9gOowzg4reA0Lp14KV8c/0Wcxsk7u95hxY4VrNy1ksa2RhJjEkmITsAd5eatHW/R7GvmnOPO4Tuf+Q7egJc/r/kzL37y4gHxp8emMyZtDDlJOYxIGMGIxBFkJWS1lwbT49JJiE7A5XC1/yBb/a3UeGqo8dRQ3lTOIx89wkufvkSqO5XvfOY7TM6azEdlH9mh9CP2Nu7t8oCUHptO4bBCClIKyIrPskNCFgnRCfscMP1BPx6/p/2g5Y5yMzxxOMMThjM8cTjuKHdHCdXfRnx0PMPih+3TPLO9djuvbXuN14pfo6ypbJ8DVIo7hZzEHEYkjiA7IZtXtrzCo2sfJdoZzQ0zb+DkkSezoWIDGyo3sLZ8Lesr1pMUk8T/zPgfvnXit8hOyGZt2VpeL36dN4rfwOP3UJRVxJTsKRRlFwHwUelHrC5dzUdlH+Hxe8hPzic/KZ/85HwCYg9IW6q3sKVmCzWeGkRsCVwQYpwxpMelkx5rS+knpJ/A58d9ntMKTiMmqusz1CLClpotvLXjLdZVrGNn/U521O1ge+124lxxnDH6DM4afRZnjj6TnMQcaltrKW0spbSpFINhVOoo8pLycDm7PnnlC/iob7M1iEAwQHpcOinuFKIcA99wUtlcydMbnuav6/7K+3veB2ziv2TCJVxSeAkzRszostbYWSAYoLi2mI/LP7aff6caaao7lbHpY8lLysPp6OLM+35E5KDb6y1NGP01axYgwLlEAAAgAElEQVR1zg3sfWQ+EyY80efFPR64/36469dCZWAL5L9NfOFKTP5/iHb7yErKICctnfTYNMqby9lYubG9hBXmjnKTnZBNk7eJqpaqfaaNTRvLheMuZP4J84l3xbf/wLfWbsVg2ksjmXGZeAPe9mRQ0VJBcW0xmyo3Ud9Wf0DcBtNetU9xp5DsTiY7Ibv9YJKTlMPq0tU8sf4JttZsJcoR1V6Vj3ZGc2LOiWQlZNHY1kiTt4kmbxNF2UXc8plbmJw1eZ9tVbVU8Y8N/6DV38qkrElMGjaJYfHDBuTLv2rvKu546w7++ek/29/X2PSxTM2eSkFKAckxySTFJJEUk0RuUi6Fwwp71ewzWLbWbOXnK3/OXz/+K0Gx1dH85HwmDpvI6QWnc93067qsTUXCQB6gjnTbarZR11rHtOHTjop9ogmjv848k8bK99jx17OYNOn5Xi/W1gaLFtfyq6depy7jVWImLKMtZi9gm2FOHnkyCdEJ7dXhak81GXEZTMiYQOGwQsZnjGdU6iiGJwwnKSap/UvY5G1iZ91OdtbvZFTKKMZljDukL6iIUN5czuaqzYiIrfLGZ5Iem97rUs1HZR+xdONSop3RzB05l9m5sw+p2SsS1pWvo76tnilZU4bEicJDVVxbTHlTORMyJ5DsTh7scNRRZshcJXXESUwkaof06SqpZ573ctWLl9KS9wKcFSQhKoXPnXA2pxecztyCud2e4OyNhOgECocVUjissF/L788YQ3ZCdpdt4r1dftrwaUwbPu3gMw+i/U9MHulGp45mdOrowQ5DKU0Y+0hKwtkS7FXCKC6Gm26Cf3p/AJ99ji8N/y7fnvdFZuXOjEgbqlJKDTY9snWWmIijueeEIQJ33QV33AHmhH/CF3/H/06/kXvPv+cwBqqUUodfr+6wMcbcZIxJCj2/4hFjzGpjzNmRDu6wS0rC2eIn4O+49C0QDDD3L3O5/JnLKW0s49Zb4bbb4PQL9+C+7GqmZk/lt/M0WSiljn69rWF8VUT+nzHmHCAV+DLwOPBaxCIbDElJGL8gno4e5F4vfp2VO1cC8Oy6f9G2/B6uv+Fq1k+7DH+5l6e+9BTuqH50BKOUUkeY3t7DHz5r+zngcRHZ0Gnc0SPUY52jqaOG8chHj5Aem861vrW07ZwM86/j5eOO453d7/Dg+Q8yNn3sYEWrlFKHVW8TxofGmNewCWOZMSYR6EMHw0eIUBfnNNpzGFUtVbyw+QXGer7Mw7+czLWu5Sw+/2GavE1cP/16Lp90+SAGq5RSh1dvm6S+BhQBxSLSEupN9prIhTVI2msYtu+Wv378V3xBH+/f9zWuuAIefMCBw/E1rpl6NU5z8PsWlFLqaNLbGsZngE9EpM4YcyXwI+DAW4aPdKEahqPZTzDo55GPHmGYbyau2oncc09Hn/pRjqij4g5PpZTqi94mjPuBFmPMFOA7wDbgsYhFNVg6PXXvv3v+w/qK9dT++2tcfrl9ZoRSSh3Lepsw/KGuyD8P/ElE7gWO/D4X9tfpqXuPfLQEF7H4Vl/Kt789yHEppdQQ0NtzGI3GmB9gL6c92RjjIPQgpKNKqIbh9cDTG58l6tOLOeWkZKZMGeS4lFJqCOhtDWMB0Ia9H6MM+4zto+9utVDCeCMIjd4mPP/5KrfcMsgxKaXUENGrhBFKEn8Dko0x5wOtInL0ncOIi0McDv7hhuim4xgXdwrz5g12UEopNTT0tmuQS4D/Ay4GLgH+a4z5UiQDGxTG4El284EbvKsXcMu3TfuVUUopdazr7TmMHwIzRaQCwBiTCbwB9O+ZgEPYpzkxiGkhoWUCV1452NEopdTQ0dvysyOcLEKq+7DsEWX9cHsuf970VGKH1nOBlFJqUPW2hvGqMWYZEH5u6QLglYMtZIyZB/w/wAk8LCJ37Tf998BpoZdxwDARSQlNCwDrQtN2icj8XsZ6SFalxUPQQVFe6uHYnFJKHTF6lTBE5FZjzEXAnNCoxSLyXE/LGGOcwL3AWcAe4ANjzIsisrHTer/daf5vAlM7rcIjIkW9exsD5+NkoHY0ece1Hu5NK6XUkNbrByiJyDPAM31Y9yxgq4gUAxhjnsTe+Lexm/kvA37ah/VHxJbEZiiZTXZ2zWCHopRSQ0qP5yGMMY3GmIYuhkZjTMNB1p0D7O70ek9oXFfbGQmMAv7dabTbGLPKGPO+MebCHmL8emi+VZWVlQcJqWe+gI/S+GqonEB29qGtSymljjY91jBE5HB1/3EpsFREAp3GjRSREmPMaODfxph1IrKtixgXA4sBZsyYIYcSxLbabQQcAVxVo0lKqjqUVSml1FEnklc6lQB5nV7nhsZ15VI6TqgDICIlob/FwAr2Pb8REZsqNwEwvDIVCbYcZG6llDq2RDJhfACMNcaMMsZEY5PCi/vPZIwZh33s63udxqUaY2JC/2dgT7Z3d+5jwGystJsYVRVDsLEu0ptTSqkjSq9PeveViPiNMTcCy7CX1S4RkQ3GmJ8Bq0QknDwuBZ4M9YYbNh540BgTxCa1uzpfXRUpG6s24mzIY5S3Cn/tjkhvTimljigRSxgAIvIK+92vISI/2e/17V0s9y4wKZKxdWVjxSYC5RPIZQ/equLDvXmllBrSjsq7tfsjKEE2V22GqgnksRt/7U72rfQopdSxTRNGyM66nbQGPFBpE4ZpbMbvrx3ssJRSasjQhBESPuFN5Xjy2E1UC3g8B1zFq5RSxyxNGCGbquwltVTZhOFsgdZWPY+hlFJhmjBCNlZuJC6YTaIzhWQacDZrDUMppTrThBGysXIjcc3jyc21r6PbEvB4tIahlFJhmjAAEWFT1SZM9QTy8g1EReFuS6a1VWsYSikVpgkD2Nu4l4a2Blp3jycvz0BWFu66GK1hKKVUJ5ow6Djh3Vg8gbw8YPRo3CV+2tp2Ewy2DW5wSik1RGjCYL9LakMJw7WnERBaW3cOZmhKKTVkaMLAJozEqFRoympPGM7SWhxevVJKKaXCNGFgm6SGR00AjL1KavRoANxlmjCUUipMEwa2hpHsGw/QXsMAiC2L1pv3lFIq5JhPGP6gn2unXktmzQWkpEBCAu0JI7EyTWsYSikVcswnjChHFHeeeSdR2+bb2gVAVhbExpJQHqc1DKWUCjnmE0bY7t10JAxj7KW1pQaPp1i7OVdKKTRhtNsnYQCMHk30Hg/BYAteb/mgxaWUUkOFJgzA44GqqgMThmt3DQjaRYhSSqEJA4CSEvs33PEgAKNHY5pbcdWhXYQopRSaMADbHAUH1jAAYkv1XgyllIIIJwxjzDxjzCfGmK3GmIVdTP+KMabSGLMmNFzbadrVxpgtoeHqSMbZZcI47jjAXlqrTVJKKQVRkVqxMcYJ3AucBewBPjDGvCgiG/eb9SkRuXG/ZdOAnwIzAAE+DC0bkYdshxPGPk1SBQUAJFQkUapNUkopFdEaxixgq4gUi4gXeBL4fC+XPQd4XURqQknidWBehOJk927IyIDY2E4jY2NhxAhiy1zaJKWUUkQ2YeQAuzu93hMat7+LjDEfG2OWGmPCjUK9XXZA7NmzX3NUWKibc5+vnECgOVKbV0qpI8Jgn/R+CSgQkcnYWsSjfV2BMebrxphVxphVlZWV/Qpi9+79mqPCRo/GtacB0CullFIqkgmjBOhcbs8NjWsnItUiEn5C0cPA9N4u22kdi0VkhojMyMzM7FegB9y0FzZ6NI69NRgv2kWIUuqYF8mE8QEw1hgzyhgTDVwKvNh5BmPM8E4v5wObQv8vA842xqQaY1KBs0PjBlwwCN/4Bszr6gzJ6NEYEdzlemmtUkpF7CopEfEbY27EHuidwBIR2WCM+RmwSkReBL5ljJkP+IEa4CuhZWuMMT/HJh2An4lITSTidDjgzju7mRi6FyOhIommprWR2LxSSh0xIpYwAETkFeCV/cb9pNP/PwB+0M2yS4AlkYzvoEIJI61uLMU1yxAJYsxgn/ZRSqnBoUe/nmRng9tNUlUmPl+51jKUUsc0TRg9CXVzHltqd1NNzb8GOSCllBo8mjAOZvRoHDtKSEiYZhNGMAi33QZvvTXYkSml1GGlCeNgRo+G4mLSUudRX/8egR8vtGfJf//7wY5MKaUOq4ie9D4qjB4NjY2k8xla3gng/NU9ttuQlSttbcOhOVcpdWzQo93BhK6USny7knF3gmdSBixaBLW1sG7dIAenlFKHjyaMgwklDMc3rgd3DBvucCJnnWWn6XkMpdQxRBPGwYwaZf8GAtQ/dBNNqeU0pzfY8StWDGpoSil1OGnCOJi4OPjyl2HxYhLO+xYQurx27tyO8xhKKXUM0ITRG489Bl/9KjExOcTHT+5IGNXVsHH/50EppdTRSRNGH6WlnUt9/Tv4T5phR2izlFLqGKEJo4/S0uYh4qc2eSvk5+uJb6XUMUMTRh8lJ8/B6UymouJJ2yz11lsgMthhKaVUxGnC6COHw8WIEddRWfkPvJ8thMpK2LTp4AsqpdQRThNGP+Tm3owxTkrGhG7c02YppdQxQBNGP8TE5JCVdRW7XUuRnOGaMJRSxwRNGP2Un38rQfHSPCNdz2MopY4JmjD6KS7uBDIyLqT0+GIoK4NPPx3skJRSKqI0YRyC/PzvUzO5xb7Q+zGUUkc5TRiHICnpRKInnEJLfhTy85/bmoZSSh2lNGEcovyRC9nwYz9SUwkXXQRtbYMdklJKRUREE4YxZp4x5hNjzFZjzMIupt9ijNlojPnYGPOmMWZkp2kBY8ya0PBiJOM8FGlp83BMncmnP3DDu+/CjTfqCXCl1FEpYgnDGOME7gXOBSYAlxljJuw320fADBGZDCwF7u40zSMiRaFhfqTiPFTGGE444SHKTm6m6huT4eGH4f77BzssdTSpq4OKisGOQqmI1jBmAVtFpFhEvMCTwOc7zyAiy0UkdNaY94HcCMYTMQkJU8jP/x7rL/kY7zknwk03wTPPaE1jsPj9R8++9/ng5JMhOxtOOgl+9zvYvn2wo1LHqEgmjBxgd6fXe0LjuvM14F+dXruNMauMMe8bYy6MRIADaeTInxAbfzxrv1uGFI6HL30Jzjln38e4lpfDr34Fxx8Pt9569BzUhpJAAObMgdmz7f4+0t13H6xfD1/9KjQ1wXe+Y58C+c1vDnZk6lgkIhEZgC8BD3d6/WXgT93MeyW2hhHTaVxO6O9oYAdwXDfLfh1YBazKz8+XwVRb+5YsX45s2XCzyB/+IJKaKuJwiHztayKXXiricomAyAkn2L933TWo8fZLICDyy1+KPP30YEfStT//2e7bqCiRUaNENm8e7Ij6r6JCJDlZ5OyzRYJBO27rVpHLLrPfq23bBje+/tq0SWTLlsGOQoUAq6S3x/XeztjXAfgMsKzT6x8AP+hivjOBTcCwHtb1F+BLB9vm9OnTB3ZP9sPmzd+Q5csdUl//X5HqapGbb7YHr+RkkZtusj+WQMD+6EHkscd6XmFdnchvfiPy3/8OXJCvviry8cd9X87rFbniChs3iNx338DFNBBaWkRyc0VmzbL7KzNTJC1N5D//sdP37BFZtEjkzDPtZ9HaOrjxHszXvy7idIps3Ljv+JISW/i46abBias/2tpEnnhC5JRT7HcnLU2ktHSwo+qf2lqRnTsHO4oBM1QSRhRQDIwCooG1QOF+80wFtgFj9xufGq5tABnAFmDCwbY5FBKGz1cn776bJ++8kyENDR/akVVVIs3N+87Y2ipyxhk2mbz66oErqq8X+fnPRVJS7MeUlSVSWXmowdkEFi6B/+IXdlxvtLaKfP7zdtmf/Uzkggvs/7/73aHFNJDuucfGtHy5fb11q8iYMSJut00i4UQ3Zoz9O2eOSHn5oIbcrdWrRYzpPil8+csiCQn24NVXL78ssnRpR62lJz6fLfjs3i2yfbutGWzaZJNzb/31ryLDhtl9PmqUyI9/bD+T88/vXQxDSUWFyNixIklJdn8cBYZEwrBx8Dng01BS+GFo3M+A+aH/3wDKgTWh4cXQ+M8C60JJZh3wtd5sbygkDBGR5uYt8u67I2XlyiSprX27+xnr60WKikTi40V+9CM7fP/7IjfcYEtgIDJ/vi2ZRUeLfPGL/f+BVVaKnH66XeeNN4pccon9/zOf6WgeaGiwB9t77rFNasuWiezaJdLYKHLWWXb+P/7RztvWJnLxxXbcL37Rt1hqa+06B1JNjW0CPPfcfcdXVNhx06fbprRwE9WTT9qD1siRImvXDmwsfdHaaj/fJUtE9u6144JBkZNOEsnI6D4hrF5t9/099xw4bflyu879a1BVVR01WxCZPVvkvfc6pvt8Is8/b/fX8OEicXEd8+4/HHdc7wowu3aJxMaKzJwp8q9/2dq1iC1ogG1CPBTBoE2q8+bZmlckNTba9+F2iyQm2gJHbwtcQ9iQSRiHexgqCUNExOPZJe+/f7y89VasVFcv637GvXtFJkywH4XDIRITYxPI+eeLrFrVMd+vf23nefTRvgUSCIi8+65IQYFd91/+YscHgyJ/+5utwcTFiRQW2hJtVwcHp9PGtv+P2+ezJV0QmTHD1jq++lWR731v39g7273bHoxiY0Uuv9weRAbiR/e979n416zp/TIffCAyYoTd3y+91Ltl1q4VOecc+z4PJe7ycpE77hDJzt53X0+f3rFPH3yw53WcdppIXp5tKgx76y1buADbJPfDH9p9/uKLdltRUXa7S5Z0bPvyy+243Fz7esQIkWuuEbnlFjv+D3+wsSxZIvL44yL332+/SyeffPBmvcsuswfY/UvjgYBtnkpKOrTmnTvu6PiOZmXZ9x8JXq9NpA6HyAsv2FoT2O33xd69Ij/9qcj114u8//6QqGFpwhgi2trK5YMPimTFimgpK/t79zMGgx0lr+74/fYHmpQksmNHx3Ivvyzy2c/aA/5554n87//ak+nf/radPyGh4yDQ1XmQ3btFFiywP4bbbxd55RVbciwrsyXV+++36/rXv7qOKxCwP5ozzxSZMkUkJ8e2r8fH71t6FbHNGNOn29LZtdfaGkG4ue3737ex9MeuXfYA9uUv933ZkhIbU1SUyD/+0f18VVV23zoc9jMAW8PqfLDuDZ9P5LvftfGC3e/LltlE9Ktf2c/SGBuT39/zul56ya7jiSfs640bbQFg3DhbU5g/367L4bDzTZpkayZhjY02oYRjOesskWef7V0i/Pvf7TLXXNP9Qe/tt+08P/5x19OLi+335Mwzu//+BwIib74p8tprB27n0Uft+q+6SmTdOttU5HTa2stAHoiDQZGvfMVua/HijvFXXGG39+67B1/H//2fnd/lsp9JuPY2dapNxr2tcQeD9rcyY4bIAw+INDX17z11ogljCPF6a2X16pNl+XLkk0/+R/x+T/9XVlxsE8DcufZgPmeO/QhHj7bnF4qKOg7CbrdtcrjhBlsyPNTzH31RUmKbLFJSRD76yI4LBm1p0xhb2hWxpdNnn7WxOxz2oH355bbk31stLbapLjq6/23K9fV2Xzqd9kC4//oXLbJNhA6Hbc6rrrYXIoDIl77U+6RRX2+bTsIH2k2bup6vurp3B5BAQOT44+3Bo7TUNq9lZdnvSVhxschtt9lCRFtb1+spK+sohPTFT34i3TaL+f32YJib2/NB7cEH7TpuvdWWuOvr7fiaGpHf/96+v3Dt68QTO85Pvfmm/b6cfnrH+6qrE7nwQjvvOefYmsDBPpuPPhL5whfsPrzjDpt4wsmmosLWqs89167z9tv3XbauztbcR42ycQeDdn+/8ILInXfaqyPnzrWFNbAFpZtusk3ADQ32opFJk6T9IoC77z7wXGdn4eY3sDVLsBfT3HyzyKef9vw+e6AJY4gJBLyydeutsnw58sEHU6WlZWv/V7ZkSccPaMQIW8rY/0fR0DD4bas7dtgvdWamPTDeeaeN+c47u56/uNjWZBITpb3kfbAfwdtv21Il2PMTh6Kx0f64HQ5bcm1stAfCrCy7/lNPPfBcx29/a6dddJE96D7/vMh3vmMT9bx5Ik891dFks2uXPTg4nfuWUg/V/ffbGAoKbKm1L8n2UAUCtpZljG2i6VxLeOghG9f+CXh/wWDHQT485OXZJsvwObbHH7fry8mR9ppQcrKtVe9/jicYtMk8fJI9M9MeUN98036fwgfkdevs5wa2YDN7dkeT7PHH2+2GX+fk2As9uqq1/Oc/9jMdObLjuxsesrJsQeTqq0X+9KeOZLh/vO+801GQGD7cJpL9k3swaH8fYJNGeLlLL7WJMyVFxNO/wqgmjCGqsvJFefvtVFm5MklKSx+TYH+qzcGgLen89rd9u1JlMHzyif3RZGTYH99llx28qaC+3p6vSUy0tYYf/ejAUldjo8g3v2nXWVAg8vrrAxNvc7NtHjGmo6Z2xhm2VNtd3OGTt+EhOtoeJPLz7ev0dNuUNXy4bcp67bWBibVzzOHazz//ObDr7u32w1egjRljS8lbttgD9Zw5vWsaCgTsMs8/b5vlrrjCtvF/+OG+87W02GSQlmb3Z0+1Iq/XNtlddFHH/U/hITXVfsaJibaWFE46e/faBHzmmfY93X67jeFg7+GPf7QFihtvtIWB997rOjkczFtv2YsdwCa8K6+0ybK01J5PAvu93z+evXu7bzLuhb4kDGPnPzrMmDFDVq1aNdhh9Ki1dScbN15OQ8O7pKScytix9xEfP36ww4qc9eth7lx7d/LKlRAb27vlSkvt3fB/+xsUFMDpp9suMbZvh927IRi0HT3+6leQkDBw8Xo8cM010NoKCxfaO8YP5tlnYfNm24XHzJngdts7zt980/Yt9vzzMGIEvPwyFBYOXKxhb75puxCZN2/g190bra2wdCk8+CC8844dZwysWgXTpg389pqabPcvKSm9m7+mBj76CEpKYM8e+3fYMHu3fFrawMd3KERg2TJ47DF4/XWoquqYduONsGiR3bcDyBjzoYjM6NW8mjAOP5EgpaUPUVy8kECgmby87zJy5I9wOuMGO7TIqK2FuDiIien7sm+9Bd/+NuzdC6NGdQwXXNC7g/lQ0NBgE6XLNdiRRN7GjfDII5Cbaz831X/BIKxZYxNISgpcf/2AJwvQhDHYYfSa11vBtm23Ul7+GDExIxkz5vdkZFyIicCXQimlutKXhKEPUBpE0dHDGD/+UYqK3iIqKokNG77Ixx+fS0uLPh9cKTX0aMIYAlJSTmH69NWMGfP/aGh4jw8+mMimTV+hquqfBIP6BD+l1NAQNdgBKMvhiCI391sMG7aA7dt/SkXFk5SXP4rTmUR6+vkMG3apfbqf4xhoB1dKDUl6DmOICga91Na+SWXlM1RVPYffX4PLlcmwYZeTnX0VCQlT9VyHUuqQ6Unvo0ww6KOm5lXKyx+jqupFRLzExOSRknIaKSmnkZp6Gm73yMEOUyl1BOpLwtAmqSOAw+EiI+MCMjIuwOerpbJyKTU1y6iufpny8scASEycSW7uzWRmXqzNVkqpiNAaxhFMJEhz8wZqa19n794H8Xg+JTo6h5ycGxkx4jpcrvTBDlEpNcRpk9QxSCRITc2/2L3799TVvYkx0WRkfJ7s7K+SlnYWxjgHO0Sl1BCkTVLHIGMcpKefR3r6eTQ1raes7BHKyh6nsvIfxMTkkpx8MtHRI4iJGUF09AiSkmYRGzt6sMNWSh1BtIZxFAsG26iqeony8kdpbt6I17uXYLC1fXpCwjQyM79EZubFxMWNGcRIlVKDRZukVJdEBL+/jra2PdTWvkZFxT9obPwvAE5nIk5nElFR9q/D4cYYFw6HC2NcOJ1JREdn4nJl4HJlkpJyKnFxxw/yO1JKHSptklJdMsbgcqXicqWSkDCJvLzv0Nq6i6qq52ht3YHf30gg0EAg0Egw2Eow2Eog0IiIF7+/Hp+vkkCgKbQ2B9nZVzFy5E+IjR3V7TZbWj6houIpoqNHkJ19FQ5H9AHz+Hw1OBzuLjtf9Pub2LXrLtzufIYPv07vPVFqEGkNQ/VJINCK11tCScl9lJTcCwTIzv4amZlfwOGIx+mMw+FwU1e3grKyR2ls/L/2ZWNi8hk58jays6/BGCfV1f+itPQhqqtfJioqhZEjf8CIETfgdLoBqKl5g08/vY7W1h0AZGVdzfHHP9A+Pcx2n+IYsMuJg0E/IL1eXyDQTDDYqlelqSOSNkmpw6KtrYSdO39FaelDiPgOmB4fP4ns7KsZNuwKmpvXsn37T2ls/C8xMflAkLa2PbhcWWRnX0VT01pqa18jJiaXkSN/TGPjB5SWPkxs7FhOOOFh6uqWs2PH7SQmzqSw8Fnc7lyamtaxd+99lJU9jtMZz4gR32DEiOuJiRnR6/fg9VbR1PQRzc0f09T0Mc3NH9PcvBERL1FRqbhcw4iOziQ5+SRyc79DdHRG+7K2m/olFBd/D7+/ltjYMSQlzSYx8UTS088lNva4Q9q/waCfurrlVFY+g8uVRl7ed3G5Bv/5DT5fDSLBffbFoayrqekjHA43SUmfwZgjr3u7QKAVER9RUYmDHUq/DJmEYYyZB/w/wAk8LCJ37Tc9BngMmA5UAwtEZEdo2g+ArwEB4Fsisuxg29OEMTja2kppbS0mEGghGGwhEGghLm48iYlF+8wnItTULGP37rtxONwMH34t6ekXtJfka2tXsH37D2hoeB9wkJf3XQoKbsfptA9dqqp6gU2brsThiCcubiz19e/gcLjJzLwEv7+W6up/YoyTzMwvkZp6Tuh8jB2CwVa83jK83nK83jJaWjbR1PQRbW272+OLjh5BfPwkEhIm4XQm4PVW4vNV4PWWUl//H5zOeHJybiIv7zt4vXv55JNv0NDwH5KT55KWNo/Gxv+joeE9vN4ywJCR8Xlyc28hOfmkXjWliQTweLbT3LyOmppXqap6Fp+vCocjnmDQQ1RUMiNH/oicnBtwOPr2bJFg0I/fX4PPV4XPV4XTmUB8fGGX65oFB1AAAA0RSURBVLE1LNu/WWdebzm7dt3N3r33IRIkJ+d/yc+/jejozF7FICKh+4Zeo77+XZqaPmyvPQK43aPJzr6arKyriI0tOOi6vN5yWluL8XiKaWvbSWvrbtra9tDWtgenM460tHNJTz+fhISiHvd/MOhFxN/t82jCx8j91xEMtrF374Ps3PlLAoEGcnNvIT9/YY+Jw+utYu/ee/F4tpKYeCLJyXOIj590wL7ui2CwDa+3HLc7v1/LD4mEYeyF/58CZwF7gA+Ay0RkY6d5/heYLCLXG2MuBb4gIguMMROAJ4BZwAjgDeB4EQn0tE1NGEc+EaGubgUuVyYJCRMPmN7cvJGNGy8jGGxhxIjryc7+SntTkMezjZKSeyktfYRAoKHbbRjjwu0eTWLiNBISpoaGoh5LzM3NG9mx43YqK/+B05lEMNiC05nMccf9huzsq9sPJiJCa+tOysoeoaTkPvz+GhITZ5KcPCeUsMpoaytFxIfTmdA++HzVtLRsJBj0AOBwxJORMZ/MzEtISzsHj2cL27Z9j9raZbjdo8jMvAQRX+hcUxvGGByOuFCTYByBQBOtrTvaB5+vosv9EB8/kYSEaTid8Xg8W/B4ttLauh1jXCQkTCMpaRaJiTNpalpNScm9BINtZGVdiTEuysr+jNMZR27uLaSnn4/Hsw2P5xNaWj4lEGgkKiqFqKhknM5k2tp2U1v7Ol5vKfD/27vX4KjqM47j3yfZze4m2U02XAKK3AQv2AqCEwEvoyAWbcfxBZ16qeN07PgGZ3TGGQvT2lpmOp32hdYXTquttloda6VaGWasF3QYRbmLXAQUECEOISBJdrNJNtndpy/OP7gEgZME2IN5PjM72fPfk81vz9nss+d/Ln/c8p9BPD6D6urpdHcfpKnpH7S2rgC8KxfE4w3E41cSj19JWVkFqdQaUqk1pNNryWS2USh0HPN6wuHhRCJjiEQuoLv7IOn0OkCpqDiP2tobqKq6jKqqKVRWXkqhkKWl5R1aWt6mtXUlhUKWeHw6NTXXUVt7HeXlCVKp1aRSH5FKfUSh0EkiMYuammupqbmGrq4v2Lv3UbLZ/dTWzqGiop7m5pcIh0cyYcISRo2695gi0NW1j/37H+PAgb9SKHQQDtfT03MQgPLyahKJmSQSs6mpuZpEYiahUOK4/4vu7iYymS1kMlvp6NhBZ+cuOjt3k83up6LiPGbPbjzh+/dkglIwZgGPquoP3PRiAFX9fdE8b7p5PhKRENAEjAAWFc9bPN/J/qYVDAOQz3fS3X2AfD7tduSnKSuLUFExioqKUYRCyQHvPG9v38y+fX8kFEowfvySkxaZfL6DpqbnaGx8gmy2kUhktMswGpEKCoUM+Xw7uVyaUChBVdX3im7fP7plVezIkbfYs2cRmcwWdyRbxG0l6NEtPNUeRCqIRscRjY4nGp1AJHIe4fBwQqFhhMPDyOVaaW/fSDq9kXR6A6pZYrFJxGKTicUmUSh0kkqto719gzsUu4z6+jsZN+6Ro0fHZTI72Lv3EQ4dWlqUUIhExhIK1ZDPp8jl2sjl2giFkiSTN1JXdxPJ5Dyi0Qu+dZl5xfZ5WlpW0N6+oeggC095eTXx+JVUV08jGr2QWGwi0ehEotFxxy2v7u5mjhx5g6+/Xk4qtZps9vgP1FjsYpLJGwmFamlre59Uag2q2aLHLyKRmEV5eSVtbavIZLYA3mdmPH4VEyf+jmRyLgCp1Dp2736Itrb3KS+vpqyskrIyb/30bkmNHHknY8c+TGXlFLLZfbS1fUhb2ypSqVW0t28GCkAZkcgYd7KtAEIu10Iud+RornB4OLHYJLcMJhGLTaK+/q4Bva+DUjAWAPNV9edu+m7gKlW9v2ierW6eRje9G7gKeBRYraovuPZngDdUdSl9iMh9wH0AY8eOnfHll1+ekddjzLmiUOhBpLxf+wNU9Vs/bAqFHjKZbYRCNSc8Gq69/RM6O3cTi11ELHbhcR/cJ+rSOXWmAh0dn5FOr0e1m3i8gaqqSwd81YJcLkVHxw4ymW2AkEzOOa4bJ5/vIp1eSz7fTjzecNwXgp6eFlKpDxGJkEzOPe41qSqHD79Oa+t7FApZVLMUClkiEe+SPSe7SGgulyKVWkNb2yq6uvYA6padUl4eL/oycZnvbkA/htRhtar6NPA0eFsYJY5jTMkN5GixE32Yl5WFj9sX1Vd19VSqq6f2+7lPnamMqqpLqKq6ZEC/31colCCRaCCRaDjhPOXlUWprrzvh4+FwkmHDfnjCx0WEESNuY8SI2waUr65uHnV18/r9u2fLmTwk4SugeLtzjGv71nlcl1QN3s5vP79rjDHmLDqTBWMdMFlEJohIBXA7sKzPPMuAe9z9BcC76m2DLQNuF5GIiEwAJgNrMcYYUzJnrEtKVXMicj/wJt5htc+q6jYRWQKsV9VlwDPAP0VkF3AEr6jg5vs38CmQAxae6ggpY4wxZ5aduGeMMUNYf3Z6n3unVRpjjCkJKxjGGGN8sYJhjDHGFysYxhhjfPlO7fQWkUPAQE/1Hg4cPo1xTjfLNziWb3As3+AEOd84VfV16vh3qmAMhois93ukQClYvsGxfINj+QYn6Pn8si4pY4wxvljBMMYY44sVjG88XeoAp2D5BsfyDY7lG5yg5/PF9mEYY4zxxbYwjDHG+DLkC4aIzBeRnSKyS0QWlToPgIg8KyLNboCp3rY6EXlbRD53P5MlynaBiLwnIp+KyDYReSBg+aIislZEPnH5fuvaJ4jIGreeX3ZXUC4ZESkXkY9FZHlA8+0VkS0isklE1ru2QKxjl6VWRJaKyA4R2S4is4KST0Qudsut95YSkQeDkm8whnTBcOOOPwncDEwB7nDjiZfaP4D5fdoWAStUdTKwwk2XQg54SFWnADOBhW6ZBSVfFpijqlOBacB8EZkJ/AF4XFUnAS3AvSXK1+sBYHvRdNDyAdygqtOKDgcNyjoGeAL4n6peAkzFW5aByKeqO91ymwbMADqA14KSb1BUdcjegFnAm0XTi4HFpc7lsowHthZN7wRGu/ujgZ2lzuiyvA7MC2I+oBLYiDfs72Eg9G3rvQS5xuB9YMwBluMN3ByYfC7DXmB4n7ZArGO8gda+wO2DDVq+PpluAlYFNV9/b0N6CwM4H9hfNN3o2oKoXlUPuPtNQH0pwwCIyHjgCmANAcrnuns2Ac3A28BuoFVVc26WUq/nPwEPAwU3PYxg5QNQ4C0R2SAi97m2oKzjCcAh4O+uW+9vIlIVoHzFbgdecveDmK9fhnrBOCep9xWlpIe3iUg18B/gQVVNFT9W6nyqmlevO2AM0ACcnkGhTwMR+RHQrKobSp3lFK5R1el43bULReSYga5LvI5DwHTgz6p6BZChT/dOqd+DAG4/1K3AK30fC0K+gRjqBeNcGjv8oIiMBnA/m0sVRETCeMXiRVV9NWj5eqlqK/AeXhdPrRs3Hkq7nq8GbhWRvcC/8LqlniA4+QBQ1a/cz2a8/vcGgrOOG4FGVV3jppfiFZCg5Ot1M7BRVQ+66aDl67ehXjD8jDseFMXjn9+Dt+/grBMRwRtad7uqPlb0UFDyjRCRWnc/hrd/ZTte4VhQ6nyqulhVx6jqeLz327uqeldQ8gGISJWIxHvv4/XDbyUg61hVm4D9InKxa5qLN5xzIPIVuYNvuqMgePn6r9Q7UUp9A24BPsPr5/5lqfO4TC8BB4AevG9T9+L1c68APgfeAepKlO0avE3pzcAmd7slQPkuBz52+bYCv3btE4G1wC68LoJIANbz9cDyoOVzWT5xt229/xdBWccuyzRgvVvP/wWSActXBXwN1BS1BSbfQG92prcxxhhfhnqXlDHGGJ+sYBhjjPHFCoYxxhhfrGAYY4zxxQqGMcYYX6xgGBMAInJ975VrjQkqKxjGGGN8sYJhTD+IyE/deBubROQpd6HDdhF53I2/sUJERrh5p4nIahHZLCKv9Y5/ICKTROQdN2bHRhG50D19ddEYDy+6s+qNCQwrGMb4JCKXAj8Brlbv4oZ54C68s3rXq+plwErgN+5Xngd+oaqXA1uK2l8EnlRvzI7ZeGf1g3fl3wfxxmaZiHfdKWMCI3TqWYwxzly8AXHWuS//MbwLyBWAl908LwCvikgNUKuqK137c8Ar7hpN56vqawCq2gXgnm+tqja66U14Y6J8cOZfljH+WMEwxj8BnlPVxcc0ijzSZ76BXm8nW3Q/j/1/moCxLilj/FsBLBCRkXB0jOtxeP9HvVeavRP4QFXbgBYRuda13w2sVNU00Cgit7nniIhI5Vl9FcYMkH2DMcYnVf1URH6FNxJdGd7VhBfiDeDT4B5rxtvPAd4lrP/iCsIe4Geu/W7gKRFZ4p7jx2fxZRgzYHa1WmMGSUTaVbW61DmMOdOsS8oYY4wvtoVhjDHGF9vCMMYY44sVDGOMMb5YwTDGGOOLFQxjjDG+WMEwxhjjixUMY4wxvvwf38cvCxgbCVsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2024 - acc: 0.9551\n",
      "Loss: 0.20242220085454057 Accuracy: 0.9551402\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5026 - acc: 0.5290\n",
      "Epoch 00001: val_loss improved from inf to 1.02642, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/001-1.0264.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 1.5027 - acc: 0.5290 - val_loss: 1.0264 - val_acc: 0.6597\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5821 - acc: 0.8201\n",
      "Epoch 00002: val_loss improved from 1.02642 to 0.41555, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/002-0.4156.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.5821 - acc: 0.8201 - val_loss: 0.4156 - val_acc: 0.8654\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3750 - acc: 0.8841\n",
      "Epoch 00003: val_loss improved from 0.41555 to 0.30414, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/003-0.3041.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.3750 - acc: 0.8841 - val_loss: 0.3041 - val_acc: 0.9075\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2812 - acc: 0.9137\n",
      "Epoch 00004: val_loss improved from 0.30414 to 0.29538, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/004-0.2954.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.2813 - acc: 0.9137 - val_loss: 0.2954 - val_acc: 0.9078\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2244 - acc: 0.9317\n",
      "Epoch 00005: val_loss did not improve from 0.29538\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.2245 - acc: 0.9317 - val_loss: 0.3235 - val_acc: 0.8989\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1879 - acc: 0.9416\n",
      "Epoch 00006: val_loss improved from 0.29538 to 0.24804, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/006-0.2480.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.1879 - acc: 0.9416 - val_loss: 0.2480 - val_acc: 0.9248\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1568 - acc: 0.9516\n",
      "Epoch 00007: val_loss improved from 0.24804 to 0.23077, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/007-0.2308.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.1567 - acc: 0.9516 - val_loss: 0.2308 - val_acc: 0.9259\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9609\n",
      "Epoch 00008: val_loss improved from 0.23077 to 0.21366, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/008-0.2137.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.1285 - acc: 0.9608 - val_loss: 0.2137 - val_acc: 0.9348\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1191 - acc: 0.9638\n",
      "Epoch 00009: val_loss improved from 0.21366 to 0.18731, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/009-0.1873.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.1191 - acc: 0.9638 - val_loss: 0.1873 - val_acc: 0.9429\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9710\n",
      "Epoch 00010: val_loss did not improve from 0.18731\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0955 - acc: 0.9710 - val_loss: 0.2189 - val_acc: 0.9366\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9776\n",
      "Epoch 00011: val_loss did not improve from 0.18731\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0785 - acc: 0.9776 - val_loss: 0.2148 - val_acc: 0.9355\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9798\n",
      "Epoch 00012: val_loss did not improve from 0.18731\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0707 - acc: 0.9798 - val_loss: 0.2039 - val_acc: 0.9364\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9833\n",
      "Epoch 00013: val_loss did not improve from 0.18731\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0588 - acc: 0.9833 - val_loss: 0.2278 - val_acc: 0.9362\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9862\n",
      "Epoch 00014: val_loss did not improve from 0.18731\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0500 - acc: 0.9863 - val_loss: 0.2568 - val_acc: 0.9299\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9870\n",
      "Epoch 00015: val_loss did not improve from 0.18731\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0472 - acc: 0.9870 - val_loss: 0.2241 - val_acc: 0.9352\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9882\n",
      "Epoch 00016: val_loss did not improve from 0.18731\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0416 - acc: 0.9881 - val_loss: 0.2290 - val_acc: 0.9324\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9845\n",
      "Epoch 00017: val_loss did not improve from 0.18731\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0534 - acc: 0.9845 - val_loss: 0.2158 - val_acc: 0.9376\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9913\n",
      "Epoch 00018: val_loss did not improve from 0.18731\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0332 - acc: 0.9913 - val_loss: 0.2213 - val_acc: 0.9385\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9919\n",
      "Epoch 00019: val_loss did not improve from 0.18731\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0315 - acc: 0.9918 - val_loss: 0.2127 - val_acc: 0.9401\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9878\n",
      "Epoch 00020: val_loss did not improve from 0.18731\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0414 - acc: 0.9878 - val_loss: 0.1953 - val_acc: 0.9476\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9953\n",
      "Epoch 00021: val_loss did not improve from 0.18731\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0200 - acc: 0.9952 - val_loss: 0.2056 - val_acc: 0.9462\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9881\n",
      "Epoch 00022: val_loss improved from 0.18731 to 0.17861, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/022-0.1786.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0400 - acc: 0.9881 - val_loss: 0.1786 - val_acc: 0.9527\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9957\n",
      "Epoch 00023: val_loss did not improve from 0.17861\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0179 - acc: 0.9956 - val_loss: 0.2386 - val_acc: 0.9341\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9909\n",
      "Epoch 00024: val_loss did not improve from 0.17861\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0329 - acc: 0.9909 - val_loss: 0.2238 - val_acc: 0.9420\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9894\n",
      "Epoch 00025: val_loss did not improve from 0.17861\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0344 - acc: 0.9894 - val_loss: 0.2317 - val_acc: 0.9394\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9929\n",
      "Epoch 00026: val_loss did not improve from 0.17861\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0259 - acc: 0.9928 - val_loss: 0.1875 - val_acc: 0.9502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9931\n",
      "Epoch 00027: val_loss improved from 0.17861 to 0.17551, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/027-0.1755.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0259 - acc: 0.9931 - val_loss: 0.1755 - val_acc: 0.9541\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9973\n",
      "Epoch 00028: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0126 - acc: 0.9973 - val_loss: 0.1869 - val_acc: 0.9539\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9975\n",
      "Epoch 00029: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0108 - acc: 0.9975 - val_loss: 0.2307 - val_acc: 0.9411\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9945\n",
      "Epoch 00030: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0201 - acc: 0.9945 - val_loss: 0.2423 - val_acc: 0.9387\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9951\n",
      "Epoch 00031: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0183 - acc: 0.9951 - val_loss: 0.2206 - val_acc: 0.9446\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9939\n",
      "Epoch 00032: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0205 - acc: 0.9939 - val_loss: 0.2088 - val_acc: 0.9481\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9936\n",
      "Epoch 00033: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0224 - acc: 0.9936 - val_loss: 0.1847 - val_acc: 0.9548\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9972\n",
      "Epoch 00034: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0105 - acc: 0.9972 - val_loss: 0.2047 - val_acc: 0.9518\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9936\n",
      "Epoch 00035: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0214 - acc: 0.9936 - val_loss: 0.2067 - val_acc: 0.9471\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9967\n",
      "Epoch 00036: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0119 - acc: 0.9967 - val_loss: 0.2108 - val_acc: 0.9520\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9969\n",
      "Epoch 00037: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0118 - acc: 0.9969 - val_loss: 0.2518 - val_acc: 0.9362\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9929\n",
      "Epoch 00038: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0228 - acc: 0.9929 - val_loss: 0.2103 - val_acc: 0.9478\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9979\n",
      "Epoch 00039: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0082 - acc: 0.9978 - val_loss: 0.1921 - val_acc: 0.9522\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9928\n",
      "Epoch 00040: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0227 - acc: 0.9928 - val_loss: 0.2140 - val_acc: 0.9485\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9987\n",
      "Epoch 00041: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0065 - acc: 0.9987 - val_loss: 0.2876 - val_acc: 0.9364\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9939\n",
      "Epoch 00042: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0216 - acc: 0.9939 - val_loss: 0.2146 - val_acc: 0.9502\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9986\n",
      "Epoch 00043: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0064 - acc: 0.9986 - val_loss: 0.1979 - val_acc: 0.9520\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 00044: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0037 - acc: 0.9993 - val_loss: 0.1986 - val_acc: 0.9506\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9953\n",
      "Epoch 00045: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0144 - acc: 0.9953 - val_loss: 0.2600 - val_acc: 0.9394\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9934\n",
      "Epoch 00046: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0225 - acc: 0.9934 - val_loss: 0.2025 - val_acc: 0.9499\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9982\n",
      "Epoch 00047: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0078 - acc: 0.9982 - val_loss: 0.2094 - val_acc: 0.9513\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9977\n",
      "Epoch 00048: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0091 - acc: 0.9977 - val_loss: 0.2152 - val_acc: 0.9506\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9977\n",
      "Epoch 00049: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0092 - acc: 0.9976 - val_loss: 0.3154 - val_acc: 0.9394\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9907\n",
      "Epoch 00050: val_loss did not improve from 0.17551\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0311 - acc: 0.9907 - val_loss: 0.2059 - val_acc: 0.9499\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9944\n",
      "Epoch 00051: val_loss improved from 0.17551 to 0.17524, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/051-0.1752.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0196 - acc: 0.9944 - val_loss: 0.1752 - val_acc: 0.9588\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9993\n",
      "Epoch 00052: val_loss did not improve from 0.17524\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0042 - acc: 0.9993 - val_loss: 0.1840 - val_acc: 0.9557\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9993\n",
      "Epoch 00053: val_loss did not improve from 0.17524\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0044 - acc: 0.9993 - val_loss: 0.2081 - val_acc: 0.9532\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9992\n",
      "Epoch 00054: val_loss did not improve from 0.17524\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0043 - acc: 0.9992 - val_loss: 0.1955 - val_acc: 0.9522\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9961\n",
      "Epoch 00055: val_loss did not improve from 0.17524\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0134 - acc: 0.9961 - val_loss: 0.2281 - val_acc: 0.9511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9936\n",
      "Epoch 00056: val_loss improved from 0.17524 to 0.17410, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/056-0.1741.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0212 - acc: 0.9936 - val_loss: 0.1741 - val_acc: 0.9574\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9990\n",
      "Epoch 00057: val_loss did not improve from 0.17410\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0047 - acc: 0.9990 - val_loss: 0.2138 - val_acc: 0.9520\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9992\n",
      "Epoch 00058: val_loss did not improve from 0.17410\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0042 - acc: 0.9991 - val_loss: 0.2278 - val_acc: 0.9485\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9940\n",
      "Epoch 00059: val_loss did not improve from 0.17410\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0204 - acc: 0.9940 - val_loss: 0.2264 - val_acc: 0.9485\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9963\n",
      "Epoch 00060: val_loss did not improve from 0.17410\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0111 - acc: 0.9963 - val_loss: 0.1934 - val_acc: 0.9532\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9993\n",
      "Epoch 00061: val_loss did not improve from 0.17410\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0031 - acc: 0.9993 - val_loss: 0.1850 - val_acc: 0.9581\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9979\n",
      "Epoch 00062: val_loss did not improve from 0.17410\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0070 - acc: 0.9979 - val_loss: 0.2216 - val_acc: 0.9513\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9973\n",
      "Epoch 00063: val_loss did not improve from 0.17410\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0100 - acc: 0.9973 - val_loss: 0.2164 - val_acc: 0.9527\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9979\n",
      "Epoch 00064: val_loss did not improve from 0.17410\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0078 - acc: 0.9978 - val_loss: 0.2674 - val_acc: 0.9446\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9944\n",
      "Epoch 00065: val_loss did not improve from 0.17410\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0191 - acc: 0.9943 - val_loss: 0.1985 - val_acc: 0.9562\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9938\n",
      "Epoch 00066: val_loss did not improve from 0.17410\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0222 - acc: 0.9938 - val_loss: 0.1888 - val_acc: 0.9567\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9991\n",
      "Epoch 00067: val_loss did not improve from 0.17410\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0043 - acc: 0.9991 - val_loss: 0.1789 - val_acc: 0.9597\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9999\n",
      "Epoch 00068: val_loss improved from 0.17410 to 0.17238, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/068-0.1724.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0019 - acc: 0.9999 - val_loss: 0.1724 - val_acc: 0.9606\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9993\n",
      "Epoch 00069: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0029 - acc: 0.9993 - val_loss: 0.2469 - val_acc: 0.9476\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9954\n",
      "Epoch 00070: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0148 - acc: 0.9954 - val_loss: 0.1963 - val_acc: 0.9555\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9996\n",
      "Epoch 00071: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0027 - acc: 0.9996 - val_loss: 0.1987 - val_acc: 0.9567\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9997\n",
      "Epoch 00072: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0020 - acc: 0.9997 - val_loss: 0.1920 - val_acc: 0.9606\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9968\n",
      "Epoch 00073: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0106 - acc: 0.9968 - val_loss: 0.2644 - val_acc: 0.9455\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9942\n",
      "Epoch 00074: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0189 - acc: 0.9942 - val_loss: 0.1807 - val_acc: 0.9604\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9992\n",
      "Epoch 00075: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0036 - acc: 0.9992 - val_loss: 0.1831 - val_acc: 0.9595\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9994\n",
      "Epoch 00076: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0027 - acc: 0.9994 - val_loss: 0.2097 - val_acc: 0.9576\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9984\n",
      "Epoch 00077: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0061 - acc: 0.9984 - val_loss: 0.2357 - val_acc: 0.9525\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9943\n",
      "Epoch 00078: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0195 - acc: 0.9943 - val_loss: 0.2032 - val_acc: 0.9581\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9980\n",
      "Epoch 00079: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0074 - acc: 0.9980 - val_loss: 0.1730 - val_acc: 0.9611\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9974\n",
      "Epoch 00080: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0099 - acc: 0.9974 - val_loss: 0.1746 - val_acc: 0.9604\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9995\n",
      "Epoch 00081: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0025 - acc: 0.9995 - val_loss: 0.2061 - val_acc: 0.9546\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9965\n",
      "Epoch 00082: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0113 - acc: 0.9964 - val_loss: 0.2000 - val_acc: 0.9569\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9957\n",
      "Epoch 00083: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0148 - acc: 0.9957 - val_loss: 0.1727 - val_acc: 0.9592\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 00084: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0028 - acc: 0.9993 - val_loss: 0.1804 - val_acc: 0.9567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9993\n",
      "Epoch 00085: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0032 - acc: 0.9992 - val_loss: 0.2032 - val_acc: 0.9574\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9958\n",
      "Epoch 00086: val_loss did not improve from 0.17238\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0145 - acc: 0.9957 - val_loss: 0.1973 - val_acc: 0.9546\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9972\n",
      "Epoch 00087: val_loss improved from 0.17238 to 0.17172, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/087-0.1717.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0094 - acc: 0.9972 - val_loss: 0.1717 - val_acc: 0.9611\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9983\n",
      "Epoch 00088: val_loss did not improve from 0.17172\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0066 - acc: 0.9983 - val_loss: 0.1872 - val_acc: 0.9604\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 00089: val_loss did not improve from 0.17172\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1825 - val_acc: 0.9604\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9985\n",
      "Epoch 00090: val_loss did not improve from 0.17172\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0054 - acc: 0.9985 - val_loss: 0.1914 - val_acc: 0.9595\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9982\n",
      "Epoch 00091: val_loss did not improve from 0.17172\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0060 - acc: 0.9982 - val_loss: 0.2239 - val_acc: 0.9564\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 00092: val_loss did not improve from 0.17172\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0042 - acc: 0.9990 - val_loss: 0.2181 - val_acc: 0.9574\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9972\n",
      "Epoch 00093: val_loss did not improve from 0.17172\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0095 - acc: 0.9971 - val_loss: 0.2309 - val_acc: 0.9506\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9965\n",
      "Epoch 00094: val_loss did not improve from 0.17172\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0114 - acc: 0.9964 - val_loss: 0.2061 - val_acc: 0.9562\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9962\n",
      "Epoch 00095: val_loss did not improve from 0.17172\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0147 - acc: 0.9961 - val_loss: 0.2183 - val_acc: 0.9564\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9961\n",
      "Epoch 00096: val_loss did not improve from 0.17172\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0141 - acc: 0.9961 - val_loss: 0.1727 - val_acc: 0.9588\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 00097: val_loss did not improve from 0.17172\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0026 - acc: 0.9995 - val_loss: 0.1973 - val_acc: 0.9543\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9967\n",
      "Epoch 00098: val_loss did not improve from 0.17172\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0108 - acc: 0.9967 - val_loss: 0.1810 - val_acc: 0.9585\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9999\n",
      "Epoch 00099: val_loss improved from 0.17172 to 0.17140, saving model to model/checkpoint/1D_CNN_custom_pool_2_ch_32_BN_13_conv_checkpoint/099-0.1714.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0016 - acc: 0.9999 - val_loss: 0.1714 - val_acc: 0.9604\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 00100: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0012 - acc: 0.9998 - val_loss: 0.1870 - val_acc: 0.9567\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9996\n",
      "Epoch 00101: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0020 - acc: 0.9996 - val_loss: 0.2095 - val_acc: 0.9527\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9958\n",
      "Epoch 00102: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0139 - acc: 0.9958 - val_loss: 0.2067 - val_acc: 0.9564\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9990\n",
      "Epoch 00103: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0036 - acc: 0.9990 - val_loss: 0.1877 - val_acc: 0.9595\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 00104: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0025 - acc: 0.9993 - val_loss: 0.1860 - val_acc: 0.9590\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9990\n",
      "Epoch 00105: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0034 - acc: 0.9990 - val_loss: 0.2684 - val_acc: 0.9422\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9982\n",
      "Epoch 00106: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0068 - acc: 0.9982 - val_loss: 0.2542 - val_acc: 0.9499\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9977\n",
      "Epoch 00107: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0078 - acc: 0.9977 - val_loss: 0.2207 - val_acc: 0.9578\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9989\n",
      "Epoch 00108: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0043 - acc: 0.9989 - val_loss: 0.1839 - val_acc: 0.9602\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9992- ETA: 1s - loss: 0.0032 -\n",
      "Epoch 00109: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0033 - acc: 0.9992 - val_loss: 0.2374 - val_acc: 0.9536\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9978\n",
      "Epoch 00110: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0065 - acc: 0.9978 - val_loss: 0.2684 - val_acc: 0.9495\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9982\n",
      "Epoch 00111: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0055 - acc: 0.9982 - val_loss: 0.2349 - val_acc: 0.9497\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9981\n",
      "Epoch 00112: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0064 - acc: 0.9981 - val_loss: 0.1875 - val_acc: 0.9618\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9991\n",
      "Epoch 00113: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0039 - acc: 0.9991 - val_loss: 0.2200 - val_acc: 0.9555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9988\n",
      "Epoch 00114: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0041 - acc: 0.9988 - val_loss: 0.2138 - val_acc: 0.9546\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9960\n",
      "Epoch 00115: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0132 - acc: 0.9960 - val_loss: 0.2557 - val_acc: 0.9469\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9995\n",
      "Epoch 00116: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0019 - acc: 0.9995 - val_loss: 0.1946 - val_acc: 0.9590\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9976\n",
      "Epoch 00117: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0084 - acc: 0.9976 - val_loss: 0.1867 - val_acc: 0.9620\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9994\n",
      "Epoch 00118: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0021 - acc: 0.9994 - val_loss: 0.1840 - val_acc: 0.9618\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 00119: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0033 - acc: 0.9992 - val_loss: 0.1962 - val_acc: 0.9609\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9981\n",
      "Epoch 00120: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0063 - acc: 0.9981 - val_loss: 0.1928 - val_acc: 0.9578\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0016 - acc: 0.9997\n",
      "Epoch 00121: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0017 - acc: 0.9997 - val_loss: 0.2002 - val_acc: 0.9555\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9967\n",
      "Epoch 00122: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0103 - acc: 0.9967 - val_loss: 0.2215 - val_acc: 0.9569\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9991\n",
      "Epoch 00123: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0029 - acc: 0.9991 - val_loss: 0.1971 - val_acc: 0.9611\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 00124: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0013 - acc: 0.9998 - val_loss: 0.1815 - val_acc: 0.9648\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9964\n",
      "Epoch 00125: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0107 - acc: 0.9964 - val_loss: 0.2055 - val_acc: 0.9562\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9993\n",
      "Epoch 00126: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0021 - acc: 0.9993 - val_loss: 0.1746 - val_acc: 0.9630\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.2972e-04 - acc: 0.9998\n",
      "Epoch 00127: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 9.6646e-04 - acc: 0.9998 - val_loss: 0.1936 - val_acc: 0.9625\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9981\n",
      "Epoch 00128: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0069 - acc: 0.9981 - val_loss: 0.1885 - val_acc: 0.9604\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0011 - acc: 0.9998\n",
      "Epoch 00129: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0017 - acc: 0.9997 - val_loss: 0.2044 - val_acc: 0.9609\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9964\n",
      "Epoch 00130: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0123 - acc: 0.9964 - val_loss: 0.1949 - val_acc: 0.9595\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9994\n",
      "Epoch 00131: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0022 - acc: 0.9994 - val_loss: 0.1821 - val_acc: 0.9606\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9991\n",
      "Epoch 00132: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0037 - acc: 0.9991 - val_loss: 0.1963 - val_acc: 0.9588\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9976\n",
      "Epoch 00133: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0077 - acc: 0.9976 - val_loss: 0.1850 - val_acc: 0.9627\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9981\n",
      "Epoch 00134: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0068 - acc: 0.9981 - val_loss: 0.1910 - val_acc: 0.9602\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9993\n",
      "Epoch 00135: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0028 - acc: 0.9993 - val_loss: 0.1941 - val_acc: 0.9599\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 00136: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0017 - acc: 0.9996 - val_loss: 0.1891 - val_acc: 0.9592\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9975\n",
      "Epoch 00137: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0082 - acc: 0.9975 - val_loss: 0.1833 - val_acc: 0.9616\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 00138: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0020 - acc: 0.9996 - val_loss: 0.2026 - val_acc: 0.9597\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9995\n",
      "Epoch 00139: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0022 - acc: 0.9995 - val_loss: 0.2137 - val_acc: 0.9590\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9992\n",
      "Epoch 00140: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0033 - acc: 0.9992 - val_loss: 0.2479 - val_acc: 0.9536\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9977\n",
      "Epoch 00141: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0073 - acc: 0.9977 - val_loss: 0.2681 - val_acc: 0.9478\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9996\n",
      "Epoch 00142: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0017 - acc: 0.9996 - val_loss: 0.1957 - val_acc: 0.9618\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9986\n",
      "Epoch 00143: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0046 - acc: 0.9986 - val_loss: 0.2780 - val_acc: 0.9488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9954\n",
      "Epoch 00144: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0162 - acc: 0.9954 - val_loss: 0.2032 - val_acc: 0.9588\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9996\n",
      "Epoch 00145: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 62s 2ms/sample - loss: 0.0015 - acc: 0.9996 - val_loss: 0.1888 - val_acc: 0.9609\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 00146: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 0.1807 - val_acc: 0.9623\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 00147: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 0.2680 - val_acc: 0.9515\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9995\n",
      "Epoch 00148: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0024 - acc: 0.9995 - val_loss: 0.2209 - val_acc: 0.9576\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9968\n",
      "Epoch 00149: val_loss did not improve from 0.17140\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0109 - acc: 0.9968 - val_loss: 0.1985 - val_acc: 0.9602\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_13_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2364 - acc: 0.9499\n",
      "Loss: 0.23640183421598432 Accuracy: 0.9499481\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 14):\n",
    "    base = '1D_CNN_custom_pool_2_ch_32_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_ch_32_BN_2(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_91 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 128000)            512000    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,570,896\n",
      "Trainable params: 2,314,704\n",
      "Non-trainable params: 256,192\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 965us/sample - loss: 2.4626 - acc: 0.4326\n",
      "Loss: 2.462566647128524 Accuracy: 0.43260643\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_94 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 64000)             256000    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,296,176\n",
      "Trainable params: 1,167,920\n",
      "Non-trainable params: 128,256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.8428 - acc: 0.4933\n",
      "Loss: 1.8428133879866555 Accuracy: 0.49325025\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_98 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 64000)             256000    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,306,736\n",
      "Trainable params: 1,178,352\n",
      "Non-trainable params: 128,384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 953us/sample - loss: 1.6488 - acc: 0.5823\n",
      "Loss: 1.648780586588296 Accuracy: 0.58234686\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_103 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_120 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_121 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_122 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_123 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_124 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_125 ( (None, 32000)             128000    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 687,536\n",
      "Trainable params: 623,024\n",
      "Non-trainable params: 64,512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.3158 - acc: 0.6451\n",
      "Loss: 1.3158366868800464 Accuracy: 0.6450675\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_109 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_126 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_127 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_128 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_129 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_130 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_131 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_132 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_133 ( (None, 16000)             64000     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 388,336\n",
      "Trainable params: 355,696\n",
      "Non-trainable params: 32,640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.9934 - acc: 0.7148\n",
      "Loss: 0.9933747239078193 Accuracy: 0.7148494\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_116 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_134 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_135 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_136 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_137 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_138 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_139 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_140 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_141 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_142 ( (None, 8000)              32000     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                128016    \n",
      "=================================================================\n",
      "Total params: 249,136\n",
      "Trainable params: 232,368\n",
      "Non-trainable params: 16,768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.7487 - acc: 0.7931\n",
      "Loss: 0.7487056278613002 Accuracy: 0.79314643\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_124 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_143 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_144 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_145 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_146 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_147 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_148 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_149 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_150 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_151 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_152 ( (None, 7936)              31744     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 289,456\n",
      "Trainable params: 272,560\n",
      "Non-trainable params: 16,896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.5148 - acc: 0.8590\n",
      "Loss: 0.5148487983339177 Accuracy: 0.8589823\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_10_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_133 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_153 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_154 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_155 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_156 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_157 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_158 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_159 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_160 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_161 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_162 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_163 ( (None, 3968)              15872     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                63504     \n",
      "=================================================================\n",
      "Total params: 292,656\n",
      "Trainable params: 283,440\n",
      "Non-trainable params: 9,216\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3260 - acc: 0.9178\n",
      "Loss: 0.32596479585454224 Accuracy: 0.91775703\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_11_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_143 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_164 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_165 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_166 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_167 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_168 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_169 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_126 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_170 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_127 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_171 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_128 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_172 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_129 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_173 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_130 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_174 ( (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_131 (MaxPoolin (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_175 ( (None, 1920)              7680      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                30736     \n",
      "=================================================================\n",
      "Total params: 334,256\n",
      "Trainable params: 328,880\n",
      "Non-trainable params: 5,376\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2282 - acc: 0.9443\n",
      "Loss: 0.2282284504442881 Accuracy: 0.9443406\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_12_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_154 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_176 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_177 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_132 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_178 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_179 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_180 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_181 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_182 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_183 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_184 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_185 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_186 ( (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_141 (MaxPoolin (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 15, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_187 ( (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_142 (MaxPoolin (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_188 ( (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 396,336\n",
      "Trainable params: 392,752\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2024 - acc: 0.9551\n",
      "Loss: 0.20242220085454057 Accuracy: 0.9551402\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_13_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_166 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_189 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_190 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_191 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_192 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_193 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_194 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_195 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_196 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_149 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_197 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_150 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_198 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_151 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_199 ( (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_152 (MaxPoolin (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 15, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_200 ( (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_201 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_154 (MaxPoolin (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_202 ( (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                12304     \n",
      "=================================================================\n",
      "Total params: 558,896\n",
      "Trainable params: 555,056\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2364 - acc: 0.9499\n",
      "Loss: 0.23640183421598432 Accuracy: 0.9499481\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_pool_2_ch_32_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 14):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_91 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 128000)            512000    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,570,896\n",
      "Trainable params: 2,314,704\n",
      "Non-trainable params: 256,192\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 5.7140 - acc: 0.4285\n",
      "Loss: 5.713995327657381 Accuracy: 0.42845276\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_94 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 64000)             256000    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,296,176\n",
      "Trainable params: 1,167,920\n",
      "Non-trainable params: 128,256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 3.6082 - acc: 0.5063\n",
      "Loss: 3.608238081422055 Accuracy: 0.50633436\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_98 (Conv1D)           (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 64000)             256000    \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,306,736\n",
      "Trainable params: 1,178,352\n",
      "Non-trainable params: 128,384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 3.2840 - acc: 0.5593\n",
      "Loss: 3.283971308820097 Accuracy: 0.55929387\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_103 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_120 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_121 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_122 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_123 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_124 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_125 ( (None, 32000)             128000    \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 687,536\n",
      "Trainable params: 623,024\n",
      "Non-trainable params: 64,512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.0526 - acc: 0.6467\n",
      "Loss: 2.0526468654287937 Accuracy: 0.646729\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_109 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_126 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_127 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_128 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_129 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_130 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_131 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_132 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_133 ( (None, 16000)             64000     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 388,336\n",
      "Trainable params: 355,696\n",
      "Non-trainable params: 32,640\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.4783 - acc: 0.7290\n",
      "Loss: 1.4783112845069275 Accuracy: 0.72897196\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_116 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_134 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_135 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_136 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_137 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_138 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_139 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_140 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_141 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 8000)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_142 ( (None, 8000)              32000     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                128016    \n",
      "=================================================================\n",
      "Total params: 249,136\n",
      "Trainable params: 232,368\n",
      "Non-trainable params: 16,768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 1.0494 - acc: 0.7913\n",
      "Loss: 1.0494167299161694 Accuracy: 0.7912772\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_124 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_143 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_144 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_145 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_146 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_147 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_148 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_149 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_150 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_151 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_152 ( (None, 7936)              31744     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 289,456\n",
      "Trainable params: 272,560\n",
      "Non-trainable params: 16,896\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.6554 - acc: 0.8656\n",
      "Loss: 0.6554447114900884 Accuracy: 0.86562824\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_10_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_133 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_153 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_154 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_155 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_156 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_157 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_158 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_159 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_160 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_161 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_162 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 3968)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_163 ( (None, 3968)              15872     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                63504     \n",
      "=================================================================\n",
      "Total params: 292,656\n",
      "Trainable params: 283,440\n",
      "Non-trainable params: 9,216\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.3791 - acc: 0.9146\n",
      "Loss: 0.3790551776234699 Accuracy: 0.91464174\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_11_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_143 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_164 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_165 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_166 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_167 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_168 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_169 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_126 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_170 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_127 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_171 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_128 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_172 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_129 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_173 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_130 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_174 ( (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_131 (MaxPoolin (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_175 ( (None, 1920)              7680      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                30736     \n",
      "=================================================================\n",
      "Total params: 334,256\n",
      "Trainable params: 328,880\n",
      "Non-trainable params: 5,376\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.2639 - acc: 0.9418\n",
      "Loss: 0.26390035499026565 Accuracy: 0.9418484\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_12_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_154 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_176 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_177 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_132 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_178 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_179 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_180 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_181 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_182 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_183 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_184 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_185 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_186 ( (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_141 (MaxPoolin (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 15, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_187 ( (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_142 (MaxPoolin (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_188 ( (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 396,336\n",
      "Trainable params: 392,752\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2292 - acc: 0.9458\n",
      "Loss: 0.2291822143390326 Accuracy: 0.9457944\n",
      "\n",
      "1D_CNN_custom_pool_2_ch_32_BN_13_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_166 (Conv1D)          (None, 16000, 32)         192       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_189 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 16000, 32)         5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_190 ( (None, 16000, 32)         128       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 16000, 32)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 8000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_191 ( (None, 8000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 8000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 4000, 32)          5152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_192 ( (None, 4000, 32)          128       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 4000, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 2000, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 2000, 64)          10304     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_193 ( (None, 2000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 1000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_194 ( (None, 1000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 1000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 500, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_195 ( (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 250, 64)           20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_196 ( (None, 250, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 250, 64)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_149 (MaxPoolin (None, 125, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 125, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_197 ( (None, 125, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_150 (MaxPoolin (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 62, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_198 ( (None, 62, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 62, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_151 (MaxPoolin (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 31, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_199 ( (None, 31, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 31, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_152 (MaxPoolin (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 15, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_200 ( (None, 15, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 15, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_201 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_154 (MaxPoolin (None, 3, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_202 ( (None, 768)               3072      \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                12304     \n",
      "=================================================================\n",
      "Total params: 558,896\n",
      "Trainable params: 555,056\n",
      "Non-trainable params: 3,840\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2428 - acc: 0.9495\n",
      "Loss: 0.24282508008065995 Accuracy: 0.9495327\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 14):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
