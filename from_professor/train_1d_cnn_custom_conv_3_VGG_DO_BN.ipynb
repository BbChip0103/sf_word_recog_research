{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_VGG_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same')) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())        \n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,397,136\n",
      "Trainable params: 16,396,880\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,499,344\n",
      "Trainable params: 5,498,832\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,883,216\n",
      "Trainable params: 1,882,448\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 694,992\n",
      "Trainable params: 693,968\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 567,248\n",
      "Trainable params: 565,712\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 396,496\n",
      "Trainable params: 394,448\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 405,968\n",
      "Trainable params: 403,408\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 476,880\n",
      "Trainable params: 473,808\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 768,208\n",
      "Trainable params: 764,112\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7513 - acc: 0.4909\n",
      "Epoch 00001: val_loss improved from inf to 1.02341, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/001-1.0234.hdf5\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 1.7513 - acc: 0.4909 - val_loss: 1.0234 - val_acc: 0.6823\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8678 - acc: 0.7349\n",
      "Epoch 00002: val_loss improved from 1.02341 to 0.74881, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/002-0.7488.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.8678 - acc: 0.7350 - val_loss: 0.7488 - val_acc: 0.7829\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.8161\n",
      "Epoch 00003: val_loss improved from 0.74881 to 0.33459, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/003-0.3346.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.6032 - acc: 0.8161 - val_loss: 0.3346 - val_acc: 0.8994\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4651 - acc: 0.8586\n",
      "Epoch 00004: val_loss did not improve from 0.33459\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.4651 - acc: 0.8586 - val_loss: 0.5072 - val_acc: 0.8465\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3751 - acc: 0.8843\n",
      "Epoch 00005: val_loss improved from 0.33459 to 0.28097, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/005-0.2810.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.3753 - acc: 0.8842 - val_loss: 0.2810 - val_acc: 0.9194\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3256 - acc: 0.9004\n",
      "Epoch 00006: val_loss improved from 0.28097 to 0.25956, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/006-0.2596.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.3256 - acc: 0.9004 - val_loss: 0.2596 - val_acc: 0.9283\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2785 - acc: 0.9132\n",
      "Epoch 00007: val_loss improved from 0.25956 to 0.24449, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/007-0.2445.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2784 - acc: 0.9132 - val_loss: 0.2445 - val_acc: 0.9290\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2463 - acc: 0.9232\n",
      "Epoch 00008: val_loss improved from 0.24449 to 0.19501, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/008-0.1950.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2463 - acc: 0.9232 - val_loss: 0.1950 - val_acc: 0.9425\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9310\n",
      "Epoch 00009: val_loss did not improve from 0.19501\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2242 - acc: 0.9310 - val_loss: 0.2329 - val_acc: 0.9311\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9368\n",
      "Epoch 00010: val_loss improved from 0.19501 to 0.16763, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/010-0.1676.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2035 - acc: 0.9368 - val_loss: 0.1676 - val_acc: 0.9513\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9434\n",
      "Epoch 00011: val_loss did not improve from 0.16763\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1829 - acc: 0.9434 - val_loss: 0.1959 - val_acc: 0.9418\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1742 - acc: 0.9445\n",
      "Epoch 00012: val_loss did not improve from 0.16763\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1742 - acc: 0.9445 - val_loss: 0.2049 - val_acc: 0.9394\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9511\n",
      "Epoch 00013: val_loss did not improve from 0.16763\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1549 - acc: 0.9510 - val_loss: 0.1825 - val_acc: 0.9476\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9496\n",
      "Epoch 00014: val_loss did not improve from 0.16763\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1591 - acc: 0.9496 - val_loss: 0.1805 - val_acc: 0.9464\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9592\n",
      "Epoch 00015: val_loss improved from 0.16763 to 0.15682, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/015-0.1568.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1281 - acc: 0.9592 - val_loss: 0.1568 - val_acc: 0.9564\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9628\n",
      "Epoch 00016: val_loss did not improve from 0.15682\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1187 - acc: 0.9627 - val_loss: 0.1795 - val_acc: 0.9495\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1094 - acc: 0.9649\n",
      "Epoch 00017: val_loss improved from 0.15682 to 0.15576, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/017-0.1558.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1094 - acc: 0.9648 - val_loss: 0.1558 - val_acc: 0.9564\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9661\n",
      "Epoch 00018: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.1082 - acc: 0.9660 - val_loss: 0.1878 - val_acc: 0.9527\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9656\n",
      "Epoch 00019: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1059 - acc: 0.9656 - val_loss: 0.1786 - val_acc: 0.9534\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9696\n",
      "Epoch 00020: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0960 - acc: 0.9695 - val_loss: 0.1741 - val_acc: 0.9476\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9750\n",
      "Epoch 00021: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0817 - acc: 0.9750 - val_loss: 0.2109 - val_acc: 0.9413\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9740\n",
      "Epoch 00022: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0828 - acc: 0.9739 - val_loss: 0.1844 - val_acc: 0.9478\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9728\n",
      "Epoch 00023: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0886 - acc: 0.9728 - val_loss: 0.1772 - val_acc: 0.9509\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9820\n",
      "Epoch 00024: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0580 - acc: 0.9820 - val_loss: 0.1607 - val_acc: 0.9550\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9783\n",
      "Epoch 00025: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0679 - acc: 0.9783 - val_loss: 0.1941 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9830\n",
      "Epoch 00026: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0567 - acc: 0.9829 - val_loss: 0.1974 - val_acc: 0.9457\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9807\n",
      "Epoch 00027: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0615 - acc: 0.9807 - val_loss: 0.1743 - val_acc: 0.9529\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9842\n",
      "Epoch 00028: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0513 - acc: 0.9842 - val_loss: 0.1666 - val_acc: 0.9541\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9868\n",
      "Epoch 00029: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0441 - acc: 0.9868 - val_loss: 0.1861 - val_acc: 0.9509\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9860\n",
      "Epoch 00030: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0459 - acc: 0.9859 - val_loss: 0.2542 - val_acc: 0.9292\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9785\n",
      "Epoch 00031: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0671 - acc: 0.9785 - val_loss: 0.1973 - val_acc: 0.9481\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9884\n",
      "Epoch 00032: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0392 - acc: 0.9884 - val_loss: 0.1925 - val_acc: 0.9497\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9875\n",
      "Epoch 00033: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0439 - acc: 0.9874 - val_loss: 0.1821 - val_acc: 0.9553\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9836\n",
      "Epoch 00034: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0524 - acc: 0.9835 - val_loss: 0.1960 - val_acc: 0.9504\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9857\n",
      "Epoch 00035: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0455 - acc: 0.9857 - val_loss: 0.1810 - val_acc: 0.9532\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9931\n",
      "Epoch 00036: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0261 - acc: 0.9931 - val_loss: 0.1772 - val_acc: 0.9602\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9923\n",
      "Epoch 00037: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0266 - acc: 0.9923 - val_loss: 0.2091 - val_acc: 0.9497\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9904\n",
      "Epoch 00038: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0314 - acc: 0.9904 - val_loss: 0.2015 - val_acc: 0.9541\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9902\n",
      "Epoch 00039: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0326 - acc: 0.9902 - val_loss: 0.2261 - val_acc: 0.9469\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9895\n",
      "Epoch 00040: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0332 - acc: 0.9894 - val_loss: 0.2914 - val_acc: 0.9311\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9876\n",
      "Epoch 00041: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0412 - acc: 0.9876 - val_loss: 0.2134 - val_acc: 0.9495\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9887\n",
      "Epoch 00042: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0370 - acc: 0.9887 - val_loss: 0.1851 - val_acc: 0.9539\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9914\n",
      "Epoch 00043: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0294 - acc: 0.9914 - val_loss: 0.1825 - val_acc: 0.9581\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9956\n",
      "Epoch 00044: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0173 - acc: 0.9956 - val_loss: 0.2180 - val_acc: 0.9511\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9914\n",
      "Epoch 00045: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0290 - acc: 0.9914 - val_loss: 0.1906 - val_acc: 0.9555\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9933\n",
      "Epoch 00046: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0230 - acc: 0.9933 - val_loss: 0.2578 - val_acc: 0.9441\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9890\n",
      "Epoch 00047: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0357 - acc: 0.9890 - val_loss: 0.2042 - val_acc: 0.9513\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9955\n",
      "Epoch 00048: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0165 - acc: 0.9955 - val_loss: 0.2047 - val_acc: 0.9534\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9943\n",
      "Epoch 00049: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0197 - acc: 0.9943 - val_loss: 0.1982 - val_acc: 0.9569\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9926\n",
      "Epoch 00050: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0251 - acc: 0.9926 - val_loss: 0.2530 - val_acc: 0.9401\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9886\n",
      "Epoch 00051: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0367 - acc: 0.9886 - val_loss: 0.1966 - val_acc: 0.9539\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9952\n",
      "Epoch 00052: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0168 - acc: 0.9952 - val_loss: 0.1839 - val_acc: 0.9567\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9959\n",
      "Epoch 00053: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0135 - acc: 0.9959 - val_loss: 0.1896 - val_acc: 0.9562\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9933\n",
      "Epoch 00054: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0221 - acc: 0.9933 - val_loss: 0.2624 - val_acc: 0.9427\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9946\n",
      "Epoch 00055: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0188 - acc: 0.9945 - val_loss: 0.2144 - val_acc: 0.9509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9879\n",
      "Epoch 00056: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0384 - acc: 0.9879 - val_loss: 0.2224 - val_acc: 0.9513\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9933\n",
      "Epoch 00057: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0220 - acc: 0.9932 - val_loss: 0.1975 - val_acc: 0.9536\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9942\n",
      "Epoch 00058: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0177 - acc: 0.9942 - val_loss: 0.2100 - val_acc: 0.9520\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9960\n",
      "Epoch 00059: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0160 - acc: 0.9960 - val_loss: 0.2035 - val_acc: 0.9557\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9957\n",
      "Epoch 00060: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0146 - acc: 0.9957 - val_loss: 0.2141 - val_acc: 0.9520\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9945\n",
      "Epoch 00061: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0179 - acc: 0.9945 - val_loss: 0.2978 - val_acc: 0.9331\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9942\n",
      "Epoch 00062: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0175 - acc: 0.9942 - val_loss: 0.2252 - val_acc: 0.9515\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9945\n",
      "Epoch 00063: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0173 - acc: 0.9945 - val_loss: 0.2262 - val_acc: 0.9518\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9933\n",
      "Epoch 00064: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0218 - acc: 0.9933 - val_loss: 0.2529 - val_acc: 0.9488\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9931\n",
      "Epoch 00065: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0212 - acc: 0.9930 - val_loss: 0.2123 - val_acc: 0.9525\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9905\n",
      "Epoch 00066: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0309 - acc: 0.9905 - val_loss: 0.2139 - val_acc: 0.9499\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9964\n",
      "Epoch 00067: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0121 - acc: 0.9964 - val_loss: 0.2059 - val_acc: 0.9550\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.2176 - acc: 0.9418\n",
      "Loss: 0.21759956766264213 Accuracy: 0.9418484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model_name = '1D_CNN_custom_conv_3_VGG_DO_BN_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,397,136\n",
      "Trainable params: 16,396,880\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 723us/sample - loss: 5.5422 - acc: 0.3171\n",
      "Loss: 5.542177775393889 Accuracy: 0.31713396\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,499,344\n",
      "Trainable params: 5,498,832\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.9564 - acc: 0.3389\n",
      "Loss: 2.9564274548741514 Accuracy: 0.3389408\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,883,216\n",
      "Trainable params: 1,882,448\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 1.7631 - acc: 0.4984\n",
      "Loss: 1.7630936730316495 Accuracy: 0.49844238\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 694,992\n",
      "Trainable params: 693,968\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 1.2412 - acc: 0.6544\n",
      "Loss: 1.241225696191857 Accuracy: 0.6544133\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 567,248\n",
      "Trainable params: 565,712\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.9833 - acc: 0.7344\n",
      "Loss: 0.9832576593753581 Accuracy: 0.7343718\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_120 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_121 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_122 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_123 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_124 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_125 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_126 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_127 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_128 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_129 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_130 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_131 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 396,496\n",
      "Trainable params: 394,448\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.8658 - acc: 0.7502\n",
      "Loss: 0.8657846676350135 Accuracy: 0.75015575\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_132 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_133 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_134 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_135 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_136 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_137 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_138 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_139 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_140 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_141 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_142 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_143 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_144 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_145 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 405,968\n",
      "Trainable params: 403,408\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.7129 - acc: 0.8044\n",
      "Loss: 0.7128525783711134 Accuracy: 0.80436134\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_146 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_147 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_148 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_149 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_150 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_151 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_152 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_153 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_154 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_155 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_156 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_157 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_158 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_159 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_160 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_161 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 476,880\n",
      "Trainable params: 473,808\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.3030 - acc: 0.9136\n",
      "Loss: 0.3030172028769338 Accuracy: 0.9136033\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_162 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_163 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_164 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_165 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_166 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_167 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_168 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_169 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_170 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_171 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_172 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_173 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_174 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_175 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_176 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_177 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_178 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_179 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 768,208\n",
      "Trainable params: 764,112\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2176 - acc: 0.9418\n",
      "Loss: 0.21759956766264213 Accuracy: 0.9418484\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 12.3470 - acc: 0.1473\n",
      "Epoch 00001: val_loss improved from inf to 13.84430, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/001-13.8443.hdf5\n",
      "36805/36805 [==============================] - 77s 2ms/sample - loss: 12.3475 - acc: 0.1473 - val_loss: 13.8443 - val_acc: 0.0978\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.9248 - acc: 0.1988\n",
      "Epoch 00002: val_loss improved from 13.84430 to 12.08474, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/002-12.0847.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.9252 - acc: 0.1987 - val_loss: 12.0847 - val_acc: 0.1638\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.4391 - acc: 0.2454\n",
      "Epoch 00003: val_loss improved from 12.08474 to 11.95781, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/003-11.9578.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.4390 - acc: 0.2453 - val_loss: 11.9578 - val_acc: 0.1756\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.2835 - acc: 0.2696\n",
      "Epoch 00004: val_loss improved from 11.95781 to 11.82261, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/004-11.8226.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.2841 - acc: 0.2695 - val_loss: 11.8226 - val_acc: 0.1929\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.2030 - acc: 0.2843\n",
      "Epoch 00005: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.2032 - acc: 0.2843 - val_loss: 12.1461 - val_acc: 0.1696\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1688 - acc: 0.2892\n",
      "Epoch 00006: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1690 - acc: 0.2892 - val_loss: 12.1852 - val_acc: 0.1700\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1687 - acc: 0.2897\n",
      "Epoch 00007: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1681 - acc: 0.2898 - val_loss: 12.3289 - val_acc: 0.1724\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1454 - acc: 0.2956\n",
      "Epoch 00008: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1452 - acc: 0.2956 - val_loss: 12.2632 - val_acc: 0.1770\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1507 - acc: 0.2952\n",
      "Epoch 00009: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1509 - acc: 0.2952 - val_loss: 12.3963 - val_acc: 0.1719\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1531 - acc: 0.2953\n",
      "Epoch 00010: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1538 - acc: 0.2952 - val_loss: 12.5067 - val_acc: 0.1659\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1409 - acc: 0.2979\n",
      "Epoch 00011: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1410 - acc: 0.2979 - val_loss: 12.8103 - val_acc: 0.1570\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1512 - acc: 0.2981\n",
      "Epoch 00012: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1514 - acc: 0.2981 - val_loss: 12.1985 - val_acc: 0.1880\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1446 - acc: 0.2993\n",
      "Epoch 00013: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1440 - acc: 0.2993 - val_loss: 12.2649 - val_acc: 0.1919\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1312 - acc: 0.3010\n",
      "Epoch 00014: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1313 - acc: 0.3010 - val_loss: 12.6821 - val_acc: 0.1649\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1388 - acc: 0.2999\n",
      "Epoch 00015: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1386 - acc: 0.3000 - val_loss: 12.2713 - val_acc: 0.1926\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1184 - acc: 0.3038\n",
      "Epoch 00016: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1191 - acc: 0.3037 - val_loss: 12.2920 - val_acc: 0.1868\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1132 - acc: 0.3039\n",
      "Epoch 00017: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1125 - acc: 0.3039 - val_loss: 12.2799 - val_acc: 0.1926\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1098 - acc: 0.3050\n",
      "Epoch 00018: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1105 - acc: 0.3050 - val_loss: 12.4524 - val_acc: 0.1836\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.1240 - acc: 0.3034\n",
      "Epoch 00019: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.1242 - acc: 0.3034 - val_loss: 12.2967 - val_acc: 0.1987\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.0225 - acc: 0.3029\n",
      "Epoch 00020: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 11.0221 - acc: 0.3029 - val_loss: 12.3999 - val_acc: 0.1861\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 10.8024 - acc: 0.3115\n",
      "Epoch 00021: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 10.8018 - acc: 0.3115 - val_loss: 12.0789 - val_acc: 0.1929\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 10.6376 - acc: 0.3261\n",
      "Epoch 00022: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 10.6375 - acc: 0.3262 - val_loss: 12.6703 - val_acc: 0.1647\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 10.5582 - acc: 0.3349\n",
      "Epoch 00023: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 10.5577 - acc: 0.3349 - val_loss: 12.0737 - val_acc: 0.1859\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 10.4111 - acc: 0.3369\n",
      "Epoch 00024: val_loss did not improve from 11.82261\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 10.4108 - acc: 0.3369 - val_loss: 12.7992 - val_acc: 0.1526\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.8295 - acc: 0.3926\n",
      "Epoch 00025: val_loss improved from 11.82261 to 10.68275, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/025-10.6827.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 8.8300 - acc: 0.3925 - val_loss: 10.6827 - val_acc: 0.2234\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.3524 - acc: 0.4476\n",
      "Epoch 00026: val_loss improved from 10.68275 to 10.41690, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/026-10.4169.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 8.3521 - acc: 0.4476 - val_loss: 10.4169 - val_acc: 0.2371\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.2143 - acc: 0.4670\n",
      "Epoch 00027: val_loss did not improve from 10.41690\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 8.2140 - acc: 0.4670 - val_loss: 10.5809 - val_acc: 0.2402\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.1528 - acc: 0.4789\n",
      "Epoch 00028: val_loss improved from 10.41690 to 10.34659, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/028-10.3466.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 8.1522 - acc: 0.4789 - val_loss: 10.3466 - val_acc: 0.2457\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.1218 - acc: 0.4836\n",
      "Epoch 00029: val_loss did not improve from 10.34659\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 8.1216 - acc: 0.4836 - val_loss: 10.5678 - val_acc: 0.2248\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.1185 - acc: 0.4832\n",
      "Epoch 00030: val_loss did not improve from 10.34659\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 8.1183 - acc: 0.4832 - val_loss: 10.8575 - val_acc: 0.2232\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.6419 - acc: 0.4859\n",
      "Epoch 00031: val_loss did not improve from 10.34659\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 7.6419 - acc: 0.4859 - val_loss: 10.5588 - val_acc: 0.2197\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.1595 - acc: 0.5198\n",
      "Epoch 00032: val_loss improved from 10.34659 to 10.22780, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/032-10.2278.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 7.1598 - acc: 0.5198 - val_loss: 10.2278 - val_acc: 0.2367\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.9864 - acc: 0.5447\n",
      "Epoch 00033: val_loss improved from 10.22780 to 9.75913, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/033-9.7591.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 6.9872 - acc: 0.5447 - val_loss: 9.7591 - val_acc: 0.2551\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.9157 - acc: 0.5570\n",
      "Epoch 00034: val_loss improved from 9.75913 to 9.74317, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/034-9.7432.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 6.9161 - acc: 0.5570 - val_loss: 9.7432 - val_acc: 0.2565\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.8941 - acc: 0.5606\n",
      "Epoch 00035: val_loss did not improve from 9.74317\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 6.8944 - acc: 0.5606 - val_loss: 10.0310 - val_acc: 0.2464\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.8764 - acc: 0.5632\n",
      "Epoch 00036: val_loss did not improve from 9.74317\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 6.8763 - acc: 0.5632 - val_loss: 10.4078 - val_acc: 0.2369\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.8538 - acc: 0.5670\n",
      "Epoch 00037: val_loss did not improve from 9.74317\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 6.8538 - acc: 0.5669 - val_loss: 9.7590 - val_acc: 0.2597\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.8736 - acc: 0.5632\n",
      "Epoch 00038: val_loss did not improve from 9.74317\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 6.8736 - acc: 0.5632 - val_loss: 9.8994 - val_acc: 0.2511\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.8541 - acc: 0.5668\n",
      "Epoch 00039: val_loss did not improve from 9.74317\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 6.8539 - acc: 0.5668 - val_loss: 10.6737 - val_acc: 0.2148\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.2589 - acc: 0.5707\n",
      "Epoch 00040: val_loss did not improve from 9.74317\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 6.2587 - acc: 0.5707 - val_loss: 9.7512 - val_acc: 0.2332\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.7666 - acc: 0.6068\n",
      "Epoch 00041: val_loss improved from 9.74317 to 9.01674, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/041-9.0167.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 5.7662 - acc: 0.6068 - val_loss: 9.0167 - val_acc: 0.2665\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.6396 - acc: 0.6312\n",
      "Epoch 00042: val_loss did not improve from 9.01674\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 5.6391 - acc: 0.6312 - val_loss: 9.5452 - val_acc: 0.2390\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.6174 - acc: 0.6373\n",
      "Epoch 00043: val_loss did not improve from 9.01674\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 5.6175 - acc: 0.6373 - val_loss: 9.3776 - val_acc: 0.2611\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.5745 - acc: 0.6457\n",
      "Epoch 00044: val_loss did not improve from 9.01674\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 5.5746 - acc: 0.6457 - val_loss: 9.2217 - val_acc: 0.2537\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.5732 - acc: 0.6455\n",
      "Epoch 00045: val_loss did not improve from 9.01674\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 5.5729 - acc: 0.6455 - val_loss: 9.1384 - val_acc: 0.2688\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.5687 - acc: 0.6464\n",
      "Epoch 00046: val_loss did not improve from 9.01674\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 5.5680 - acc: 0.6464 - val_loss: 9.1177 - val_acc: 0.2660\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.3290 - acc: 0.6456\n",
      "Epoch 00047: val_loss did not improve from 9.01674\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 5.3291 - acc: 0.6456 - val_loss: 12.1131 - val_acc: 0.1915\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.1346 - acc: 0.6994\n",
      "Epoch 00048: val_loss improved from 9.01674 to 7.42918, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/048-7.4292.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 4.1345 - acc: 0.6994 - val_loss: 7.4292 - val_acc: 0.3175\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.7963 - acc: 0.7369\n",
      "Epoch 00049: val_loss did not improve from 7.42918\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 3.7958 - acc: 0.7370 - val_loss: 8.3993 - val_acc: 0.2504\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3124 - acc: 0.7660\n",
      "Epoch 00050: val_loss improved from 7.42918 to 7.40188, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/050-7.4019.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 3.3130 - acc: 0.7659 - val_loss: 7.4019 - val_acc: 0.3017\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.1621 - acc: 0.7855\n",
      "Epoch 00051: val_loss improved from 7.40188 to 7.11199, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/051-7.1120.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 3.1616 - acc: 0.7856 - val_loss: 7.1120 - val_acc: 0.3159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.0900 - acc: 0.7979\n",
      "Epoch 00052: val_loss did not improve from 7.11199\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 3.0895 - acc: 0.7979 - val_loss: 7.3548 - val_acc: 0.3282\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.0639 - acc: 0.8001\n",
      "Epoch 00053: val_loss improved from 7.11199 to 6.83197, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/053-6.8320.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 3.0648 - acc: 0.8001 - val_loss: 6.8320 - val_acc: 0.3447\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.0396 - acc: 0.8030\n",
      "Epoch 00054: val_loss did not improve from 6.83197\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 3.0401 - acc: 0.8030 - val_loss: 7.1965 - val_acc: 0.3233\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.0209 - acc: 0.8035\n",
      "Epoch 00055: val_loss did not improve from 6.83197\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 3.0213 - acc: 0.8035 - val_loss: 7.0544 - val_acc: 0.3170\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3988 - acc: 0.8069\n",
      "Epoch 00056: val_loss did not improve from 6.83197\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 2.3989 - acc: 0.8069 - val_loss: 10.7655 - val_acc: 0.1768\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0065 - acc: 0.8528\n",
      "Epoch 00057: val_loss improved from 6.83197 to 5.85992, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/057-5.8599.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 2.0067 - acc: 0.8528 - val_loss: 5.8599 - val_acc: 0.3378\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9200 - acc: 0.8712\n",
      "Epoch 00058: val_loss did not improve from 5.85992\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.9206 - acc: 0.8712 - val_loss: 6.4719 - val_acc: 0.3177\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8960 - acc: 0.8755\n",
      "Epoch 00059: val_loss did not improve from 5.85992\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.8966 - acc: 0.8755 - val_loss: 6.2005 - val_acc: 0.3494\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7653 - acc: 0.8749\n",
      "Epoch 00060: val_loss did not improve from 5.85992\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.7651 - acc: 0.8749 - val_loss: 8.5541 - val_acc: 0.2227\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4290 - acc: 0.8854\n",
      "Epoch 00061: val_loss improved from 5.85992 to 5.58333, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/061-5.5833.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.4297 - acc: 0.8854 - val_loss: 5.5833 - val_acc: 0.3324\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3281 - acc: 0.9089\n",
      "Epoch 00062: val_loss did not improve from 5.58333\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.3279 - acc: 0.9089 - val_loss: 5.7173 - val_acc: 0.3515\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3136 - acc: 0.9120\n",
      "Epoch 00063: val_loss did not improve from 5.58333\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.3140 - acc: 0.9120 - val_loss: 5.8683 - val_acc: 0.3417\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3093 - acc: 0.9127\n",
      "Epoch 00064: val_loss did not improve from 5.58333\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.3092 - acc: 0.9127 - val_loss: 5.8573 - val_acc: 0.3392\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2956 - acc: 0.9163\n",
      "Epoch 00065: val_loss did not improve from 5.58333\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.2959 - acc: 0.9162 - val_loss: 6.2002 - val_acc: 0.3357\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2999 - acc: 0.9144\n",
      "Epoch 00066: val_loss did not improve from 5.58333\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.3006 - acc: 0.9144 - val_loss: 6.0238 - val_acc: 0.3336\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2932 - acc: 0.9162\n",
      "Epoch 00067: val_loss did not improve from 5.58333\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.2934 - acc: 0.9162 - val_loss: 6.1438 - val_acc: 0.3357\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2967 - acc: 0.9149\n",
      "Epoch 00068: val_loss did not improve from 5.58333\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.2966 - acc: 0.9149 - val_loss: 7.3377 - val_acc: 0.3012\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2910 - acc: 0.9161\n",
      "Epoch 00069: val_loss did not improve from 5.58333\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.2909 - acc: 0.9161 - val_loss: 7.0671 - val_acc: 0.2893\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2958 - acc: 0.9145\n",
      "Epoch 00070: val_loss did not improve from 5.58333\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.2956 - acc: 0.9145 - val_loss: 7.2616 - val_acc: 0.2863\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5531 - acc: 0.9335\n",
      "Epoch 00071: val_loss did not improve from 5.58333\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5533 - acc: 0.9335 - val_loss: 6.3870 - val_acc: 0.2863\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1800 - acc: 0.9728\n",
      "Epoch 00072: val_loss improved from 5.58333 to 5.21923, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/072-5.2192.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1799 - acc: 0.9728 - val_loss: 5.2192 - val_acc: 0.3433\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9856\n",
      "Epoch 00073: val_loss did not improve from 5.21923\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1282 - acc: 0.9856 - val_loss: 5.2517 - val_acc: 0.3464\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9883\n",
      "Epoch 00074: val_loss did not improve from 5.21923\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1182 - acc: 0.9883 - val_loss: 5.4135 - val_acc: 0.3450\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9904\n",
      "Epoch 00075: val_loss improved from 5.21923 to 5.09194, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_1_conv_checkpoint/075-5.0919.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1100 - acc: 0.9904 - val_loss: 5.0919 - val_acc: 0.3720\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9915\n",
      "Epoch 00076: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1073 - acc: 0.9916 - val_loss: 5.3376 - val_acc: 0.3657\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9907\n",
      "Epoch 00077: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1075 - acc: 0.9907 - val_loss: 5.2405 - val_acc: 0.3715\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9880\n",
      "Epoch 00078: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1159 - acc: 0.9880 - val_loss: 5.1804 - val_acc: 0.3690\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9890\n",
      "Epoch 00079: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1130 - acc: 0.9890 - val_loss: 5.2760 - val_acc: 0.3732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9900\n",
      "Epoch 00080: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1088 - acc: 0.9900 - val_loss: 5.6296 - val_acc: 0.3443\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9914\n",
      "Epoch 00081: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1046 - acc: 0.9914 - val_loss: 5.3078 - val_acc: 0.3555\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9911\n",
      "Epoch 00082: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1062 - acc: 0.9911 - val_loss: 7.7287 - val_acc: 0.2888\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9889\n",
      "Epoch 00083: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1088 - acc: 0.9889 - val_loss: 5.6614 - val_acc: 0.3657\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9913\n",
      "Epoch 00084: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1033 - acc: 0.9913 - val_loss: 5.9278 - val_acc: 0.3576\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9911\n",
      "Epoch 00085: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1031 - acc: 0.9911 - val_loss: 5.6847 - val_acc: 0.3517\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9915\n",
      "Epoch 00086: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1008 - acc: 0.9916 - val_loss: 5.7985 - val_acc: 0.3373\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9909\n",
      "Epoch 00087: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1042 - acc: 0.9909 - val_loss: 7.6856 - val_acc: 0.2867\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9917\n",
      "Epoch 00088: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1015 - acc: 0.9917 - val_loss: 5.4355 - val_acc: 0.3557\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9917\n",
      "Epoch 00089: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0992 - acc: 0.9917 - val_loss: 5.8408 - val_acc: 0.3499\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9918\n",
      "Epoch 00090: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0989 - acc: 0.9918 - val_loss: 5.2520 - val_acc: 0.3713\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9907\n",
      "Epoch 00091: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1035 - acc: 0.9907 - val_loss: 6.0772 - val_acc: 0.3249\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9921\n",
      "Epoch 00092: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0971 - acc: 0.9921 - val_loss: 6.3006 - val_acc: 0.3420\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9910\n",
      "Epoch 00093: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1034 - acc: 0.9910 - val_loss: 9.0253 - val_acc: 0.2548\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9904\n",
      "Epoch 00094: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1000 - acc: 0.9904 - val_loss: 5.5382 - val_acc: 0.3494\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9931\n",
      "Epoch 00095: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0931 - acc: 0.9931 - val_loss: 5.4798 - val_acc: 0.3881\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9918\n",
      "Epoch 00096: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0955 - acc: 0.9918 - val_loss: 6.1185 - val_acc: 0.3336\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9923\n",
      "Epoch 00097: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0959 - acc: 0.9922 - val_loss: 5.7307 - val_acc: 0.3634\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9890\n",
      "Epoch 00098: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1095 - acc: 0.9890 - val_loss: 5.5796 - val_acc: 0.3671\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9927\n",
      "Epoch 00099: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0923 - acc: 0.9927 - val_loss: 6.0839 - val_acc: 0.3562\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9925\n",
      "Epoch 00100: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0948 - acc: 0.9925 - val_loss: 5.5505 - val_acc: 0.3692\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9934\n",
      "Epoch 00101: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0906 - acc: 0.9934 - val_loss: 5.5098 - val_acc: 0.3802\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9930\n",
      "Epoch 00102: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0916 - acc: 0.9930 - val_loss: 5.6859 - val_acc: 0.3564\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9929\n",
      "Epoch 00103: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0913 - acc: 0.9929 - val_loss: 5.7008 - val_acc: 0.3692\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9937\n",
      "Epoch 00104: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0882 - acc: 0.9938 - val_loss: 5.8796 - val_acc: 0.3585\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9914\n",
      "Epoch 00105: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0960 - acc: 0.9914 - val_loss: 5.8735 - val_acc: 0.3457\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9927\n",
      "Epoch 00106: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0922 - acc: 0.9927 - val_loss: 5.5588 - val_acc: 0.3725\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9925\n",
      "Epoch 00107: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0916 - acc: 0.9925 - val_loss: 8.3140 - val_acc: 0.2912\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9930\n",
      "Epoch 00108: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0901 - acc: 0.9930 - val_loss: 5.6947 - val_acc: 0.3736\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9927\n",
      "Epoch 00109: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0923 - acc: 0.9927 - val_loss: 5.8065 - val_acc: 0.3781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9934\n",
      "Epoch 00110: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0893 - acc: 0.9934 - val_loss: 5.4629 - val_acc: 0.3783\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9930\n",
      "Epoch 00111: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0900 - acc: 0.9930 - val_loss: 5.9533 - val_acc: 0.3392\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9930\n",
      "Epoch 00112: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0907 - acc: 0.9930 - val_loss: 6.0972 - val_acc: 0.3573\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9927\n",
      "Epoch 00113: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0910 - acc: 0.9927 - val_loss: 6.5004 - val_acc: 0.3513\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9935\n",
      "Epoch 00114: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0887 - acc: 0.9935 - val_loss: 5.7758 - val_acc: 0.3692\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9931\n",
      "Epoch 00115: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0907 - acc: 0.9931 - val_loss: 5.5598 - val_acc: 0.3722\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9937\n",
      "Epoch 00116: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0888 - acc: 0.9937 - val_loss: 5.4544 - val_acc: 0.3818\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9924\n",
      "Epoch 00117: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0926 - acc: 0.9924 - val_loss: 5.8093 - val_acc: 0.3683\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9924\n",
      "Epoch 00118: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0922 - acc: 0.9924 - val_loss: 6.7849 - val_acc: 0.3205\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9934\n",
      "Epoch 00119: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0888 - acc: 0.9934 - val_loss: 6.1527 - val_acc: 0.3583\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9938\n",
      "Epoch 00120: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0876 - acc: 0.9938 - val_loss: 5.7222 - val_acc: 0.3643\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9936\n",
      "Epoch 00121: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0872 - acc: 0.9936 - val_loss: 5.7739 - val_acc: 0.3857\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9915\n",
      "Epoch 00122: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0963 - acc: 0.9915 - val_loss: 6.1260 - val_acc: 0.3496\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9936\n",
      "Epoch 00123: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0875 - acc: 0.9936 - val_loss: 5.6074 - val_acc: 0.3813\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9936\n",
      "Epoch 00124: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0877 - acc: 0.9936 - val_loss: 6.9947 - val_acc: 0.3382\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9933\n",
      "Epoch 00125: val_loss did not improve from 5.09194\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0900 - acc: 0.9933 - val_loss: 6.2465 - val_acc: 0.3580\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXl4lNXZ/z9n9sm+kAQIgYR931E0ICpqRS1qBbGK1qXYt61b7auitS2+1tZWW1utrT9cqtatVqSWulUsiFZQAUFQ2UkgLNn3TDLb+f1x8mQmkGWyTGaSnM91zfXMPMt57meSOd9z3+ec+wgpJRqNRqPpv5gibYBGo9FoIosWAo1Go+nnaCHQaDSafo4WAo1Go+nnaCHQaDSafo4WAo1Go+nnaCHQaDSafo4WAo1Go+nnaCHQaDSafo4l0gaEwoABA2R2dnakzdBoNJpexZYtW0qklGntndcrhCA7O5vNmzdH2gyNRqPpVQgh8kM5T4eGNBqNpp+jhUCj0Wj6OWETAiHEM0KIIiHEzhaO/VgIIYUQA8J1f41Go9GERjj7CJ4F/gg8H7xTCJEFnAcc6krhHo+HgoIC6uvru1JMv8bhcDBkyBCsVmukTdFoNBEkbEIgpdwghMhu4dAjwJ3AG10pv6CggPj4eLKzsxFCdKWofomUktLSUgoKCsjJyYm0ORqNJoL0aB+BEOJi4IiUcntXy6qvryc1NVWLQCcRQpCamqo9Ko1G03PDR4UQMcA9qLBQKOffCNwIMHTo0NbO6S7z+iX6+9NoNNCzHsEIIAfYLoTIA4YAW4UQA1s6WUq5Uko5U0o5My2t3fkQLVNRAceOddJcjUaj6R/0mBBIKXdIKdOllNlSymygAJgupTwetptWVYVNCCoqKvjTn/7UqWsvuOACKioqQj5/xYoVPPzww526l0aj0bRHOIePvgxsBMYIIQqEEDeE616tYrWC3w8+X7cX3ZYQeL3eNq996623SEpK6nabNBqNpjOETQiklN+WUg6SUlqllEOklE+fcDxbSlkSrvsDSggAPJ5uL3r58uXs37+fqVOncscdd7B+/Xrmzp3LwoULGT9+PACXXHIJM2bMYMKECaxcubLp2uzsbEpKSsjLy2PcuHEsW7aMCRMmcN555+Fyudq877Zt25g9ezaTJ0/m0ksvpby8HIBHH32U8ePHM3nyZK644goAPvjgA6ZOncrUqVOZNm0a1dXV3f49aDSa3k+vyDXUHnv33kZNzbaTD/i8UOeCnTFgNneozLi4qYwa9ftWjz/44IPs3LmTbdvUfdevX8/WrVvZuXNn03DMZ555hpSUFFwuF7NmzeKyyy4jNTX1BNv38vLLL/Pkk09y+eWXs2rVKpYuXdrqfa+55hoee+wx5s2bx89+9jPuu+8+fv/73/Pggw9y8OBB7HZ7U9jp4Ycf5vHHHyc3N5eamhocDkeHvgONRtM/6NspJkTj40nZI7c75ZRTmo3Jf/TRR5kyZQqzZ8/m8OHD7N2796RrcnJymDp1KgAzZswgLy+v1fIrKyupqKhg3rx5AHznO99hw4YNAEyePJmrrrqKF154AYtF6Xtubi633347jz76KBUVFU37NRqNJpg+UTO02nL3eGD7dsjKgoyMsNsRGxvb9H79+vWsXbuWjRs3EhMTw5lnntnimH273d703mw2txsaao0333yTDRs2sGbNGh544AF27NjB8uXLufDCC3nrrbfIzc3l3XffZezYsZ0qX6PR9F36tkdgsYAQYekjiI+PbzPmXllZSXJyMjExMezatYtNmzZ1+Z6JiYkkJyfz4YcfAvDXv/6VefPm4ff7OXz4MGeddRa//vWvqayspKamhv379zNp0iTuuusuZs2axa5du7psg0aj6Xv0CY+gVYRQHcZhEILU1FRyc3OZOHEiCxYs4MILL2x2/Pzzz+eJJ55g3LhxjBkzhtmzZ3fLfZ977jn+53/+h7q6OoYPH85f/vIXfD4fS5cupbKyEiklt9xyC0lJSfz0pz9l3bp1mEwmJkyYwIIFC7rFBo1G07cQsofi511h5syZ8sSFab7++mvGjRvX/sVff606ikePDpN1vZuQv0eNRtPrEEJskVLObO+8vh0agrB5BBqNRtNX0EKg0Wg0/Zz+IQRer5phrNFoNJqT6B9CAEoMNBqNRnMS/UcIdHhIo9FoWkQLQVeQEo4cgU5OAuuW+5eWhiWpnkaj6T9oIegKpaUqzXVhYUinx8XFdWh/u9TVwcGDUFbWues1Go2G/iAERn6d7hYCn095A6DWPWhpPkZRUeCcriKlEp3gNBU1NWqr+z80Gk0X6PtCYDIpMehmIVh+6608/uKLkJoKbjcr7r2Xhx9+mJqaGubPn8/06dOZlJvLG6+8Ag0NIZUppeSOO+5g4sSJTJo0ib/97W8AHDt2jDPmzmXqvHlMnDKFDz/8EJ/Px7Xf/z4Tlyxh0lln8cgjj3Tr82k0mv5D30gxcdttsK2FNNQGtbVKEJzO0MucOhV+30oyO7ebJaefzm2//z0/vP9+KC3l1b//nXfffx+Hw8Hq1atJcLsp2baN2dddx8LLL0dkZbV7y9dff51t27axfft2SkpKmDVrFmeccQYvvfQS35gzh58sWoTPZKJu5Ei2ff45R44eZeff/gYpKVSkpIT+bBqNRhNE3xCC9jCZui8VdUUF5OczbcwYiqqqOFpaSnF+PslxcWRlZeHxeLjnnnvY8N57mITgSHExhbt3MzAzs+1ya2v56KOP+Pa3v43ZbCYjI4N58+bx2WefMWvWLK6/+mo8ZWVcMm8eU8eOZXhmJgcKCrj5oYe48NxzOe/667vn+TQaTb+jbwhBay13wO/3Yso/DNXVMHly5+/h80F+vuqYdTph5EgWX345r732Gsf37GHJ/Png9/Piiy9SfOwYW557DmtODtmnnEJ9XV3rHbpFRWqy265dgfh/Q4PqD3C7ATjj9NPZ8MQTvLltG9fedx+3l5ZyzZVXsv2ll3h382aeePllXv34Y5555pnOP59Go+m39A0haIX6+ny83ipirckIj0d5BUK0f6Hfrypivx8GDFD79u9XFfXgwTBwIJhMLFmyhGXLllFSVMQHf/wjVFdTWVlJelwcVpuNdTt2kH/oENjtUFxsGKXsMJuVd3HokLIpJoa5OTn8v2ef5TsTJ1JWWcmGDz/koUceIf/LLxmSksKym2+moaaGrVu2cMGcOdhMJi679FLGDBvG0vvvD98XqdFo+jR9WgjM5ng8nmL8Zh9mKdXoGmM4aWt4PKrSr6lRFXRhodoaGUwTEppOnTBhAtXV1WQOGcKgtDQoL+eqc8/lm08/zaQrr2TmaaephWBSUlQ/hd8PO3c2v19Skip/9GguveQSNu7YwZSlSxEWC7+56SYGmkw89957PPTEE1jj44mzWnn+3ns5sm8f1913H34Ar5dfteEVaTQaTVuELQ21EOIZ4CKgSEo5sXHfQ8A3ATewH7hOSlnRXlmdTUMtpZ/a2i+w1tixF9TC+PEQE3PyiX6/qqhralTL3eOBnByIj1chnfp6GDQIbLbWb7ZnjxpGChAbC8OHK08AVFjp2DHVV2G3q4rf61Xb1FS1XxmswkLG2sJ79qi5AqAEaPhwFeLavVvtGzIkMKlt2rQOr8sMOg21RtOXCTUNdTg9gmeBPwLPB+17D7hbSukVQvwauBu4K1wGCGHCYhmATxxXO1oaQiqlqnCNMflOJ4wYoSpzCH2Jy8GDlcikpJwsNmazqrTbNzggAqCu+eor9T4xUW1jY1V5Ph/ExQVmNXu9nRKCqOeDD5Q4L1oUaUs0mj5L2IRASrlBCJF9wr5/B33cBIT9122zpVFnPY4ExLFjqqIPbtlXVCgRGDwY0tMDE9A6SlycenUnhrCUlQVCUiaTel9ZqY4bk8m83oAH0pd4+GHYt08LgUYTRiI5oex64O1w38RksmNyJNAwyIysq1Mt7MpKddAIqzgcKvTTWREIJ8OGwdixzfs2srJg1KjAZDnou7OLKysD4TGNRhMWIiIEQoifAF7gxTbOuVEIsVkIsbnYGHHTSazWNDwJPnyjh6gKde9eOHpU5QoyRgKFMpooEpjNJ3saNpvqv4C+LwRVVZFL6qfR9BN6XAiEENeiOpGvkm30VEspV0opZ0opZ6alpXXpnhZLIkJY8JirVes6JUUJQV6eCq8kJ3ep/IjS14VAewQaTdjpUSEQQpwP3AkslFL22K9bdRon4/VWIk2oEUFZWaq1nZUVvd5AKBgdxH11vQXDIwjT6DaNRhNGIRBCvAxsBMYIIQqEEDegRhHFA+8JIbYJIZ4I1/1PxGJJBfx4vRWq4s/IUPmEjBBLB6moqOBPf/pTp6694IILqKhod9RsaAgRWI6zryGl8gj8/r4rdBpNFBDOUUPfbmH30+G6X3uYzbEIYcPjKcNqTVU7u+AJGELwgx/84KRjXq8XSxsdz2+99Van79siFkvfFIK6usCiO3V1bc/j0Gg0nabvp6FuRAiB1ZqCz1eJ39/11uXy5cvZv38/U6dO5Y477mD9+vXMnTuXhQsXMn78eAAuueQSZsyYwYQJE1i5cmXTtdnZ2ZSUlJCXl8e4ceNYtmwZEyZM4LzzzsPVQsfomjVrOPXUU5k2bRrnnHMOhY0L4dTU1HDdddcx6dJLmXzhhaxatQqAd955h+nTpzNlyhTmz5/f5WeNGMYEPdAdxhpNGInC8ZIdp70s1AZSDsLvT8Rkku06A21loQZ48MEH2blzJ9sab7x+/Xq2bt3Kzp07ycnJAeCZZ54hJSUFl8vFrFmzuOyyy0hNTW1Wzt69e3n55Zd58sknufzyy1m1ahVLly5tds6cOXPYtGkTQgieeuopfvOb3/Db3/6W+++/n8TERHa8/Ta4XJRnZlJcXMyyZcvYsGEDOTk5lPXm1cuMYb6ghUCjCSN9QghCRQgzYMLv92A2W+huh+iUU05pEgGARx99lNWrVwNw+PBh9u7de5IQ5OTkMHXqVABmzJhBXl7eSeUWFBSwZMkSjh07htvtbrrH2rVreeWVV5pCQ8nJyaxZs4Yzzjij6ZyU3rxOQbBHoEcOaTRho08IQUfyrXm9XlyufQhhJyZmFCZT983GjTXSUqA8hLVr17Jx40ZiYmI488wzqQ9eZrIRe9BsYLPZ3GJo6Oabb+b2229n4cKFrF+/nhUrVjQ/wegs7msja7RHoNH0CP2mj8DAYknE6RyNlB7q6nbh8ZTRmcR78fHxVFdXt3q8srKS5ORkYmJi2LVrF5s2beq0zZWVlWQ2Lmzz3HPPNe0/99xzefzxx5vmEpQXFzN79mw2bNjAwYMHAXRoSKPRtEu/EwIAiyWemJgxCGGmvv4AtbU7aWg4hterOpL9fi9S+toUiNTUVHJzc5k4cSJ33HHHScfPP/98vF4v48aNY/ny5cyePbvT9q5YsYLFixczY8YMBhjrIwD33nsv5eXlTJw3jylXXsm6998nLS2NlStX8q1vfYspU6awZMmSTt834ujQkEbTI4QtDXV30tk01O0hpcTrrcDtPo7fX9vCGQIh7JhM1kZR8AOy8SUa+xwsgB8pfYBECBNgRggzQlgA0XhcYjJZEMKGEJbG80yNx2k8Rw0BtViSG4+HSFWVyqA6ZkyH50VEdRrqRx6B229X719/HS69NLL2aDS9jGhIQx31qCGlyVityfj9Xvz+Ovz+eozKXnkGDfj9HoQQgLVxKwDZ6DU0AKZGUTAqfQ9+f31jxW6Ig8Dr9TaW3TYm0zHs9qFYLAntngsE0kz0tUlXevioRtMj9GshCMZksmAyJQAhVr6dQEqJlJ5G78GPlIaHAUpMLPj99TQ0HMbl2oPNNhi7fXD7BffVfEPBfQQ6NKTRhA0tBD2IEAIh2p4dazY7sFgSqK/Px+0+iskUg9Wa1HbBfVkIbDZwu7VHoNGEkX7ZWRztCGHC4RiGyRRDff1BfL6Th502w2RSyec6IgRut1qPOZr7iKqqYOBA9V4LgUYTNrQQRClCmHA6RwCC+vr9+P3tVPIdyTckpUrBffhwYInOaKSyMrBUaHeHhmpq1KJEGo1GC0E0YzLZcTqH4/fX43LtbjtHksUSemdxRYVqbZvN6n13ZULtbior1VoRdnv3ewQPPADz5nVvmRpNL0ULQQ8S14k1jS2WBJzOUfj9Dbhcu/H5WqkQrVZoaFApm9vC71eegNMJo0erz/ff32G7WmXHDpgwAY4f73pZVVVqfWans/uF4MiR7rFRo+kDaCHoBQTEwENd3Ze4XPvx+U4IlaSlqbh/cOVWWgrl5c3PO35cnZeVBbGxahnMRx9V8xC6gzfeUOtCf/hh18uqrITERLWKXDhCQ3rBG40G0ELQaZYvX67SOzSyYsUKHn74YWpqapg/fz7Tp09n0qRJvPHGG+2W1Vq66uB00t/4xiXExk7E7U5g2bIfMXnyZCZNmtCUeprERLUE57FjqoI7dgwOHoQDB6C2cbJcTY3an5ysWtoASUngcMDdd3fPF7Nxo9qGkg62Paqq1HOFwyOoqdEL3mg0jfSJ4aO3vXMb2453Q8UTxNSBU/n9+a1ns1uyZAm33XYbP/zhDwF49dVXeffdd3E4HKxevZqEhARKSkqYPXs2CxcubJyI1jItpav2+/0npZM2maz85jdPk5qazWefPYzPV0VtrRMppSo/K0tVnrt3q47jlBRV4R04oMJABw6o4ZjDhgVubjar2bv/93+wdStMn97+l+PxqErUfkLCPinByKm0fXv75bSF16sELFyhIUMcXS694I2m36M9gk4ybdo0ioqKOHr0KNu3byc5OZmsrCyklNxzzz1MnjyZc845hyNHjjQtJNMajz76KFOmTGH27NlN6ao3bdrUYjrptWvXctNNN+N0jsRqHUBsrEstvwmqnyArS1WiaWlqbeacHNV38OWXqgIfPjww78Dg9tuVl/Czn4X28EuXwtlnn7x/714oK1MeRleFwJhVHM7QEOhhqRoNfcQjaKvlHk4WL17Ma6+9xvHjx5uSu7344osUFxezZcsWrFYr2dnZLaafNgg1XfWJCGHCbh+Kx1PSmBajkdRUFfe32dRSnPHxMHgwHD2qPIGgVNlNJCbCnXeq8NDGjXDaaa3fePduePVV9b6oCNLTA8cMb2DJEnjuOdVHccL6CyFjCEG4PAItBBpNE9oj6AJLlizhlVde4bXXXmPx4sWAShmdnp6O1Wpl3bp15Ofnt1lGa+mqW0sn3ZR6GiUG5eV1SOluXqjd3nw95kGDYNIk5SW0xs03q0r93nvbfujf/S7w/j//aX5s40ZVcX+7cbnqrngFRnqJcPYRgBYCjYYwCoEQ4hkhRJEQYmfQvhQhxHtCiL2N2+Rw3b8nmDBhAtXV1WRmZjJo0CAArrrqKjZv3sykSZN4/vnnGTt2bJtltJauurV00k2ppydOZMqUKXz00db212AW4uR4/onExsL//q+q3L/6quVzCgtVS/+GG1Qn89q1zY9v2gSnnALTpqnPXekwDndoKLiPQKPp54QzNPQs8Efg+aB9y4H3pZQPCiGWN36+K4w2hJ0dO3Y0+zxgwAA2GiNnTqCmhVm8drudt99+u8XzFyxYwIIFC5rti4uLa7Y4TV3d3pM9gs5yzTUqPPTXv8KvfnXy8ccfV0NP77hD9QWsXas6iIVQLewvvoCf/ER5FgMHdo9HEI7QkN+vhUCjCSJsHoGUcgNw4vJYFwNGLfYccEm47t9fUGsldNMQyIwM+MY34IUXTp6YVlMDf/oTLFyo1j2YPx/y89VIJIDNm9U1xgI8U6dGb2go2LsIoT9Go+nr9HQfQYaU8ljj++NARmsnCiFuFEJsFkJsLi4u7hnreiFC2BpTW7czozhUrr4aCgpg/frm+x94QHX+GvMN5s9X2/ffV1vDCzr1VLWdMkWFmNyd9FbCGRoK9sy0R6DRRK6zWKolv1qd1imlXCmlnCmlnJnWSidnb1hdLdwIYQXolFfQ4vd38cVqpNFf/xrYt2cP/Pa38J3vBCr6MWMgM1OFh1wu+Oc/1VwFY5TQ1KlquOrXX3fYLiC8oaHaoNXotBBoND0uBIVCiEEAjduizhbkcDgoLS3t92JgMqnJUO12GJ+AlJLS0lIcDkfzA04nLF4Mr72mWuFSwq23qv0PPhg4TwjlFbz/PpxxBnzyCfz4x4HjU6aobWfDQ1VVar6D06lebjf4fJ0r60S0R6DRNKOn5xH8E/gO8GDjtv38C60wZMgQCgoK6O9hI7/fg9tdgtW6C7O5hTkCbeBwOBgyZMjJB66+Gp55Bs48U3X6vvOOWj/YWBvAYP58eP55VUn/4x+q/8Bg1Cg1sWzbNtUJ3VEqK5U3IIQKDYGqtDuRuO8ktBBoNM0ImxAIIV4GzgQGCCEKgJ+jBOBVIcQNQD5weWfLt1qtTbNu+zMeTwX//e8URoz4LVlZt3dPoWecAT/4gWrNf/WVmkXcmEqjGZdeqtJSfPe7MHFi82MWixpG+umnnbPBSDgHyiMALQQaTZgImxBIKb/dyqH54bpnf8RiScRkiqWhoaD7CjWZ1FDR9oiPh9+3Mas7N1dlNq2vV95BRzASzkFzIegOtBBoNM3QM4t7OUII7PYh3SsE3cWcOSpstHlzYN/Pfw5GxtS2MEJDEAgNddfIId1ZrNE0QwtBH8Buz6ShIQqXXTz9dLX973/Vdu9eleV08WL4y1/avlZ7BBpNj6GFoA8QtR5BWpoaZvrRR+qz4Qmcfjpcfz08+WTr1wZ7BOESAodDC4FGgxaCPoHdPgS3+2j3TSrrTubMgY8/VrOOX38dZs1Scw8uuABuvBEeeqjl64I7i7s7NFRTo0YjpaRoIdBo0ELQJ7DbM5HSi9vd6WkZ4SM3V+Ul+ve/4bPP4LLLVEt89WqVrvrOO1Wyu+CUFlKGNzRUW6uS7MXE6BQTGg1aCPoEdruaCxCV4aE5c9T2jjvU9lvfUlubDV56CW66Sc1anj0b1qxRIuByqcV1whkaiosLT3prjaYXooWgDxDVQjBypOor2LlTrYkwalTgmMmkhpc+8wyUlKgJadnZcP756ng4Q0NaCDSaJrQQ9AHs9kwA3O4oHDkkRMAruOyylo9fd51a+ey559TqaB6PEpCZM9U52iPo3ZSWqvCgJmrpE0tV9nes1jSEsEanRwAwb57qE1i0qPVzrFaViqKldBThEILYWFVuaWn3lKlpnauvVv1Cr78eaUs0raCFoA8ghAmbbXD0CsH3vqda9xMmdO76cEwoS0rSHkFPkZ/fPalBNGFDh4b6CGouQRSGhkC1BnNzO3+91Qpmsw4N9VYqKppP4tNEHVoI+ggxMaOoqdmG399Ny1ZGG91ZaRtCoCeU9QwVFVBdHWkrNG2ghaCPkJa2CK+3nLKydyJtSnhwOvWood6I263+bloIohotBH2E5OTzsFoHUFj4YqRNCQ8xMd0/oUwLQfgxVpqrqVFzRDRRiRaCPoLJZCUtbQmlpf/E662MtDndT3dV2l6vmk1seAT19W1XUJs3w+efd/2+/ZWKCrX1eqGhIbK2aFpFC0EfIiNjKX5/PcXFfXCYXneFhowU1IYQQNtpJm65RaXA0HQOQwhAdxhHMVoI+hAJCaficIzom+Gh4NBQcXHnx/8blVGoQlBUpCdDdYVgIdD9BFGLFoI+hBCCjIyrqKj4D3V1eyNtTvcSHBq6/HJYurRz5RgegdFHAG2HnMrKVAI8TefQHkGvQAtBH2PgwGsxm+P4/PNcKio+jLQ53YcRGvL7VRbTzz7rXOdjSx5Ba0Lg86mKrLIP9rn0FNHkEaxdC1lZWpBaQAtBH8PpzGH69E+wWJLYvv1sDh5cQX39oUib1XWM0NDBg6pVX1oKhYUdL6cjQlBersSmslKPeOks0eQRbNsGBQVwJEonXkaQiKSYEEL8CPguIIEdwHVSSp0YvpuIjR3H9Omfsnv39eTn30d+/n0kJs4lIeFUYmMnY7MNRAgrNlsGsbHjIm1uaBihoR07Avu+/BIGDuxYOcFCYHQ+tyYERt+A16vOMVJdaEInmjwCw5by8sjaEYX0uBAIITKBW4DxUkqXEOJV4Arg2Z62pS9jtSYxceLruFwHKCx8kZKSf1BQ8BhSBg/hM3HKKbuJiRkZMTtDxggNBQvBzp0wf37HygkWAqNiak0Igjukq6q0EHSGaPIIDFuCbdIAkUs6ZwGcQggPEAMcjZAdfR6nczjZ2T8lO/un+P1eXK49eDxleL3l7Nx5MUVFL5Kd/fNIm9k+Rmhoxw4YPlxVzDt3drycjnQWB48WqqzsuPehUZVuYqL6/rRHELX0eB+BlPII8DBwCDgGVEop/33ieUKIG4UQm4UQm4uLi3vazD6JyWQhNnY8SUlzGDDgmyQlnUVh4QvI3hD/Dg4NTZoEEyd2Tgg60kcQ7BHoDuPOUVGhOmgh8kJg/A21EJxEjwuBECIZuBjIAQYDsUKIk8YCSilXSilnSilnpqWl9bSZ/YKMjKW4XPuorv400qa0j9OpOmx37w4IwZdfdrwTt7NCoIeQdo6KCsjIUNljdWgoaonEqKFzgINSymIppQd4HTg9Anb0e9LSvoUQdgoLX4i0Ke1jxOelDAhBdTUcPtyxcmpqwGJRayY7HGpfqKEhTcepqIDkZIiPj7xHoENDrRIJITgEzBZCxAghBDAf+DoCdvR7LJZEBgxYSFHR3/D7PZE2p22M1jsEhAA6Hh6qrVXegBD9OzT0r3/BOz2Qqba8XC0CFBcXPR6BFoKTiEQfwSfAa8BW1NBRE7Cyp+3QKDIyluLxFFNe/l6kTWkbo9K222HUqMBqZx0VAmOZyuAyW0sxUVYG6enqfV8Tgvvug/vvD/38V16BqVPVhL6OUFGhhCCaPAIdGjqJiEwok1L+XEo5Vko5UUp5tWw+plHTg6SknI/FkhL94SEjNDRunArtJCVBZmbnhMBYNjEUjyA7W73va30EZWUqZ1OobNwI27d3rBJtaFDfrSEEkfQIvN7A/bVHcBJ6ZnE/x2SykZa2mJKSN/B6o3jqvVFpT54c2NeZkUPBQtDeEphlZZCWps7vax5BWZlKqBcqxizujiT7M74zIzQUSY8g+O+nheAktBBoyMi4Cr+/jtKS3AFtAAAgAElEQVTSNyJtSusYQjBpUmDfxInw9dcqJ1CoBAuBUW5bHkFqKiQk9C0h8HoDOZTcIS5tevy42paUhH4fw3uIBo/A+PuZTFoIWiAkIRBC3CqESBCKp4UQW4UQ54XbOE3PkJiYi90+NLrTV2dlqR9xbm5g38SJKr7/xReBfT6fGmLaGsbqZAbtCUFKipoQ1ZdCQ8HhnVAr9s54BMFCEGmPwLBlyBDdR9ACoXoE10spq4DzgGTgauDBsFml6VGEMJGe/m3Kyv6N292BcEFPMmqUqrROOy2w74ILVGv9nnsC8wluuw3Gj4d9+1ouJ1SPwO1W56amBmbGdpWyMtWv8eqrXS+rq3YYhNpP0FUhiLRHYNiSk6P+lh3t9O7jhCoEonF7AfBXKeWXQfs0fYCMjKsAH8XFf4+0Ka2TnNz8c3o6rFihhkGuWQNvvw1//KP6kb/2WstlhCoERmVpeATdIQRffAFHj8IPfxhoiW/apMJdbXkx3U1HhcDtDoRTOhsaihaPICcnkFFW00SoQrBFCPFvlBC8K4SIB7Sk9iHi4iYRGzup96ScMLjpJuUB3HorXH+9qlSnTYNVqwLn/OUvMGYMfPJJx4WgO/sIDC+lpATuuAP27oWLLlId3v8+KctK+OioEAR3KnfFI3C5Otaf050YthijwHR4qBmhCsENwHJglpSyDrAC14XNKk1EGDToBqqqNnHw4E96jxhYrfDoo5CXpyq4F1+Eb39bLTqfl6eGMN57L+zZA/PmqQo9FCEwKrzu7CPYu1fZe+ed8Oyzyh5QFeXWrV0vP1Q6KgTB6z50xSOAyIWHThQC3WHcjFCF4DRgt5SyojEv0L2A9q36GJmZNzNo0DIOHfoVeXk/6z1iMH8+/OpX8MILyiO47DK1f9Uqte/oUSUQs2ersEBHPYLuCg3t26cyp65YASNGqMpozRrV7xEpIQhlCKkxYgg67hFYLGoOSHy82hep8FBFhZpNPnSo+hzNQiBlj/dhhJqG+s/AFCHEFODHwFPA88C8cBmm6XmEMDF69BNI6Sc//xdUVX1KZuZNpKZegBDmSJvXNsuXB94PH67CQ6++qirwadOUl7BoEfz5z3DJJYFznc6WwwTBHkFCgloLweNRLfrOsnev6vR2OmH9emXbhAkwfboKDdXXB/IfhZNgkeuIRzB0aMc9gqQkVQFHg0eQmKie2fgcrdx6q0qo+P77PXbLUIXAK6WUQoiLgT9KKZ8WQtwQTsM0kUEIE2PGrMTpHMmRI4+xc+dCLJYkHI4ROBzZOBxZ2GyZOBxDcThysNsz8XhKqK8/hBACuz0LhyMbiyUhsg9y2WUqJATwt7+pyshmUz+yYNoLDRkeAajWbEpK5+zx+5VHcM456vOQIeoFSgh8PpVie9aszpXfEcrKVAU9cGDHhGD8+I4l+TOEACLvEVRWKlsMe6LZI/jkExXarK4OfG9hJlQhqBZC3I0aNjpXCGFC9RNo+iBCmBg2bDlZWT+mpOQNysvXUl+fR23tTsrK3sHvr23nehuzZu0kJmZUD1ncAosWKSEYMSIQKmoJp7PlXENlZar1HxcXEILKys4LwbFjSnBGtrAa3PTpart1a88JQUqKmjUdqhDExam5HNu2hX6fYCGIBo8gKSkw8qwnhEBK1QDpKPn5quHwySeBhkOYCVUIlgBXouYTHBdCDAUeCp9ZmmjAZLKSnr6I9PRFTfuklPh8VdTXH6K+/gANDUewWtOw29XiIy7XHnbt+g4lJW8wdOj/Rsp0NUro9tvVD8ncRljL4WjdI0hJUT/kYCHoLHv3qu2oFsRx2DBVQfVUP0GwEARPxmuNwkK1pkBqqgoNhVrBRZNHYNgSF6f+H8ItBGvWwHe+owYpDBgQ+nUuV8AD+/jj6BKCxsr/RWCWEOIi4FMp5fPhNU0TjQghsFgSiYubRFzcpJOOJybO5vDhhykrezuyQgDw29+2f05bncVGPDmhMczVFSEwho62JARCKK+gp4UgPT10j2DgQFWheb2qMk8IIfRXUaEm0EF0eAQ5Oeq7TkoKfx/Bf/6jxOa991T/VKgcOhR4/9//dr9drRBqionLgU+BxcDlwCdCiEVtX6Xpr6SkLKCy8kO83ginHQ6FtvoIjDCQ4RF0ZQjp3r2qj8JYtvFEpk9XrXNPD6wLEewRlJWpyr0tjh8PeAQQeodxNHoEoLyvcHsEO3ao7XsdTO+el6e2EyaoyYY9NO8i1OGjP0HNIfiOlPIa4BTgp+EzS9ObSU29ACk9lJf33KiHTuN0qpmzJ/7gjIRz0H2hoeHDWw9TTZum7Pjqq87fI1SChQDaHxJqhIaMEEeoQ0hbEoJI9xFAzwtBR4Zh5+er7ZVXqobHl192v20tEKoQmKSUwQOOSztwraafkZBwOmZzAmVlb0XalPYJXpzmww8DqSmMyhK6Rwj27Ws5LGQQ3GEcTvx+VQkGC0Fbcwk8HvVddNQjCF6LAAKJ/iLhEfh8qlINFoKOhob+939hyZLQzi0qUq9x46CgoGPpQ/Ly1NyLRY0Bl48/7pidnSTUyvwdIcS7QohrhRDXAm8CveBXrokEJpOV5ORzKSt7O/onpQUvTnP77XDFFWoBlmCPwIiHdzY0ZAwdbWnEkMGoUSqOHm4hqKpS9gQLQVv9BIZIBAtBKB5B8KxiUJljY2Mj4xEYfzfDlqSkjnkExcXw2GPw+usqe217GGtk3H672nYkfUh+vgofjhqlvvNoEgIp5R2o5SQnN75WSinvCqdhmt5NauoCGhoKqK3t4MIxPY0hBIcOwZYtqvV47bXKQzA8AodDxfc76xEYQ0fb8ghMJrXozvbtnbtHqAQn0wtFCIwRLEZnMXROCCByieeCF8iBjoeGnnpKhe28XjWksz2MsNBFFynx70g/QV6eSoMhhEq53kMdxiGHd6SUq6SUtze+VofTKE3vJyXlfADKyt6OsCXtYAjBP/+pYrk/+lFgrLzRAoaupZloa+hoMGPHquGG4SRYCIz1mEMRgowMVZGaTKGFhjZvVtvgoZORWrf4RFEyQkOheKter5qNfsopqnL+6KP2r9mxQz13Rgace66aRR7qIID8fDWcGOD00+HAgeYpPsJEm0IghKgWQlS18KoWQnR6CIUQIkkI8ZoQYpcQ4mshxGntX6XpTdjtmcTFTaOkJMrbDIYQrF6tfrwPPQTf+IbaFywEoWYg3bYNfvITFSM3MIaOthUaAiUUhYXhXQQnOHWGMU+iLSEwKqGMDCUCKSntewT798MPfgAzZ8KZZwb2x8VFJjRkCIHR15OUpCrmurr2r/3nP9Vs6nvuUXmsQhWCSZPUd3vuueqZN21q/zq3W+XFMhLjGYsw9UB4qE0hkFLGSykTWnjFSym7kkPgD8A7UsqxwBTg6y6UpYlS0tOXUFW1CZfrYKRNaR1DCL74Qv1ozWZ44gklBqecEjgvlAykUsKyZfDLX8Lll6vKpr4e/vWvtoeOGowerbaGBxEOgj0Cs7n9fEPBHgEEJpW1hsulOjrNZvj738FuDxxrySMoK4Pnn+/YyJqO0pJHAKGFh/74R9VCv+gimDsXNm5se7it369G+hhLqp51lvou3m7FM/70UxV6AiU4UgY8AmNuycKF7dvZRXp85I8QIhE4A3gaQErpllJGcQYoTWdJT78CgKKiVyJsSRsYQgBwvgpnkZ2tFrsJrrhDCQ29/bYKiVxwgWpJfutbqlX8xhsqKV5bM5whEDrqKSGA9tNMFBaqTl5j1E9qatsewYoVyiv6618DLVuDljyCxx5TM3Bb6lCtrVXhspdfbuuJ2qczQiAlPPAArFunvBuzGebMUfa31Y+Tl6fsNoQgKUk1MJ5//mQB8ftVf9T3vqc65Y05BMb3ZrOpYcWWUBNAdJ5IDAHNAYqBvwghPhdCPCWEiG3vIk3vw+EYRkLC6RQVdfGHHE6CheC8Npbhbk8IpFSVYHY2/OMfalbzv/6lKs133oH77mvfFiN0FM5+gs4IwcCBgc8DBrTtEbz5phLUCy88+VhLHsHatWr7yCMtl7V7Nzz5ZOv3C4UThcDYtjaEtKEBrrlG5aq66qpAosI5c9S2rfCQ0VE8KWjW/Y03wpEj6v8gmNWr4euvlSCsXh2YQ2B4BD1IJITAAkwH/iylnAbUoha9aYYQ4kYhxGYhxObiUNdV1UQd6elXUFu7g9ranpkY02EMIZg6tXmFdyIJCW2Hht55Bz77TPUPWK1q6OCGDWooodHnEIotWVnh9wji4wPptNPSAkNEV6xQ6zYEY0wmM2jLI6ipURXbqae2fPxEj6C6WsXOBwyAd989eTKdsbbzhg2hz2b2+1W5wa1vo8I3hgG35xEsX67Wsbj/fuXZGOGtIUNUJR2KEEyYENh30UXqO1y5MrBPSvjFL5QXOGqUmr+Sl6f6YYystD1IJISgACiQUhrjsF5DCUMzpJQrpZQzpZQz04xhbppeR3r65YCJwsIo9QoMIWivsm7JI1i5UmU3nTBBhTeGDVMtSYO5c5t3OIfC6NHh9wiCM6ga+YZWrVJey3XXweefB46fKAQDBighkFK11tesCRzbulVVxK1lUD3RI/jgA1VhP/64GqL7hz8EjlVXK48gN1cN6Q2+T2uUl6vFhxISlNBlZsKuXUoIEhICobm2hMDjUSKweLHyCE5Mrjd3rpp42Fqfxo4dagZ58OJHVqtaRvXNN9UEM4C33lIhtHvuUfdat04NX87M7NqaF52kx4VASnkcOCyEGNO4az7QA/PqNZHAZssgOflsiopexu9vJ6dNJMjJge9/X8Vp28LoLJZSve65R12Tnq5mkE6ZouLdNlvX7Bk1KvweQbAQpKWpiv2mm9Q8hrQ0FQ5xuQLLfZ7oEdTXqxE3y5apFN9G5f7ZZ2rbmhAYHoFRib73nhLihQvh6qtVHN1o+a9Zo+7zq18pgX399bafq7oaFixQ8fuf/UyJWnW1at1XVgZGDEFACHbvVrOFx4wJeHvvv69suOqqlu8zZ44Sx5b+Rn6/6vwNDgsZfPe76vhTT6m5CPfeq8KIV12lOtd9PiUOJ/ar9BRSyh5/AVOBzcAXwD+A5LbOnzFjhtT0Xo4ff1muW4fcuvUMWV9/JNLmdI6HHlISUFgo5ZVXqvfLlknp8XTvfX73O1V2SUn3lmtw+ulSzp8f+PzYY+p+ZrOUW7ZI+e9/q8+zZql9gwdLuXVr4Pwnn1TH16wxJFHKf/xDHVuyRMqhQ1u/94MPqvNra9Xn8eOlPO889X7nTnXshhuk9PmkXLhQysxM9f5HP5LSZpOyqqp5ecXFUq5aJeWf/yxlbq6y17BFSil/8QtV5tChUk6aFNjv9QZst9nU9pe/VMeuuUbKpCQp6+tbfoaDB6W026U85xxVTjCvvabKeuWVlq8955zAfc3mwHl+v5QjRqj9S5e2/v11AmCzDKVODuWkSL+0EPR+jh17Xn7wQYz86KMBcv/+5fLIkf8ny8rWSa+3NtKmhcb/+3/q5zJypJRCSPnAA+oH3N0YFezHH3dfmdu3S7l+vXo/dqyUixcHjv3tb+p+d9wR2PejH6l9114rZXl587JWr1bHZs6U0uGQMj5eCaKUUg4fLuVll7Vux+OPB8T0yBH1/je/CRy/806175JLVAV9221q/4cfnlzB5uWpCt6oWB0OKV96qfn9amqkHDRIHZ87t/mxCROkPO00Kb/6SsoLL5QyJUXKoiIp4+KkvP761p9BSimfflqVedddgX1+v5TTpkk5evTJAmHwySdSXnedlC+8IGVpafNjd92lyrz33rbv3UG0EGiijpqar+WWLafJ9eutct065Lp1yPXrbXLLlly5Y8e35M6di+WXX14hv/76Wrlnz62yvr4g0iYHeOUV9XNJSpLyzTfDd59du9R9nnuue8rzepV4xcZKefy4lOnpUn7ve4HjlZVS/vrXUtbVBfb5fFLu29dyeRs2BCrfG26QctEi1XIvKVH7HnywdVuee06ds29f4P3nnzc/x/CIQMqNGwPPkJGhKuzKSikPH1aik5SkPJijR6V0u1u+58qVqqxvfrP5/mAR//RTdU5urtq+917rz2DwP/+jzn3+efX5zTfV52eeaf/altiypXv/7o1oIdBELX6/V7pch2RJyZty37475ZYtp8tPPpkgP/lknNy0aaT8+OMsuX69VW7Zcpr0+bo59NJZjh6V8sYbW68gu4uGBhU2+MlPuqe8l14KVKw33SSlxSLl3Xd3vryvvgqUt3WrqviMlj1I+f77rV9reDtjxkg5caKUaWlKdE7k9deVNxBcWf/4x+pak0nKhATliXzySfv2ejwqzNVeS3vBAlV+RkbrLfpg6uulnDNHXbN4sbrH0KGtC1IobNyo/v7diBYCTa/m+PGX5Lp1yAMHfh5pU3qeESOkvPzy5vuqqzseLvL5VAhk/HgVvjGb1U/+oYc6b1thYaD1LKUSSFCVOkhZUdH6tW63CrGdeaYKr113Xej39XhUS/1nP1MVb0e+i1BCeJs2Kftvvjn0cuvrVT+Ew6Guffzx0K/tIbQQaHo9X311tVy3ziQrKj6KtCk9y4IFUk6dGvhcUqJi8iDl2rWB/S6X6mRtDSOe/+KLKiZvVFhPP91523w+Ka+4ItDnIKWU06cHWvqhUlKi7I8m3n775Nh9KOzfL+Ujj3R7a747CFUI9OIymqhl1Kg/4nAMY9++H0XalJ7FGEIqpUphPW+eGp+elgZ33x0Ywrp0KUycCJdeGkhsZ+B2qwlLI0aovEeDBwdmyAYPH+0oJpNK+TBvXmCfMYu4tWGjLZGaquYORBPnn9+572b4cLjttq4PHY4g4U9iodF0EoslgQEDLuHo0SeQ0o8Q/aTdMnq0ylczfbqaqWuxqDxGeXlqYtLq1WqM/KpVqhJeuxbGj1dj+q+8Uk2KuusuJQ7PPRfIVXP33Wose3BG0O7gggvULNzgJH2aXoVQ3kN0M3PmTLnZyG+u6VccOfIn9u79IaedVoDdnhlpc3qGL7+Eiy9WE6mmTVOTraZMUbNwJ09WuXCKi9Wx//xHpYj45S/hpZcCuYTGjYOHH1aVdLiRUonSggWB5HSaqEAIsUVKObPd87QQaKKZsrL3+OKL85gyZR3JyWdG2pzIs3q1ymoaH69SZwfPRHW71WzdmhrlHfRA1kpNdBOqEOj/FE1U43Sq1Mwu114tBACXXKIWUj/zzJPTEdhsLWf91GjaQQuBJqpxOLIQwobLta/9k/sDQqhV1DSabqSf9L5peitCmHE6h+NyhTERm0bTz9FCoIl6nM5R2iPQaMKIFgJN1ON0jsTl2oeU/kibotH0SbQQaKIep3MUfr+LhoajkTZFo+mTaCHQRD1Op1rLV4eHNJrwoIVAE/UEDyHVaDTdjxYCTdSjh5BqNOFFC4Em6tFDSDWa8KKFQNMrUENItRBoNOFAC4GmV6CGkO7XQ0g1mjAQMSEQQpiFEJ8LIf4VKRs0vQc9hFSjCR+R9AhuBb6O4P01vQhj5FBt7fYIW6LR9D0iIgRCiCHAhcBTkbi/pveRmJiLzTaQw4d/G2lTNJo+R6Q8gt8DdwI64KsJCbPZydChy6moWEd5+fpIm6PR9Cl6XAiEEBcBRVLKLe2cd6MQYrMQYnNxcXEPWaeJZgYNuhGbbRB5eT+nNyyopNH0FiLhEeQCC4UQecArwNlCiBdOPElKuVJKOVNKOTMtLa2nbdREIcoruJvKyg1UVKyLtDkaTZ+hx4VASnm3lHKIlDIbuAL4j5RyaU/boemdDBq0DJstk0OHfhVpUzSaPoOeR6DpVZjNDgYNuoHy8vf1UFKNppuIqBBIKddLKS+KpA2a3kdGxpWApKjolUibotH0CbRHoOl1xMSMIS5uBoWFL0XaFI2mT6CFQNMryci4ipqaLdTV7Y60KRpNr0cLgaZXkp6+BBDaK9BougEtBJpeid0+mKSksykqeknPKdBouogWAk2vJSNjKS7XPvLyVmgx0Gi6gCXSBmg0nSUjYymVlR+Qn/9/NDQcYfToP2MyWSNtlkbT69BCoOm1mEwWxox5Brt9KPn5/0d19SdkZt5MRsZVmM2xkTZPo+k1aCHQ9GqEEOTk3Eds7ETy8x9gz57vsW/frTido3A6RxMTM6rx/Qjs9izs9kxMJnukzdZoogotBJo+QXr6YtLSFlFV9THFxauoq9tDbe0OSkvfQEpv0Jkmxo17gYyMb0fMVo0m2tBCoOkzCCFITMwlMTG3aZ/f76Wh4RAu134aGgo4ePCnFBW9rIVAowlCC4GmT2MyWXA6h+N0DgeguvpTCgtfwO93YzLZImydRhMd6OGjmn5FcvI38PlqqKraFGlTNJqoQQuBpl+RnHwWYKas7N1Im6LRRA1aCDT9CoslkYSE2ZSX/zvSpmg0UYMWAk2/IyXlPKqrt+B2l0TaFI0mKtBCoOl3pKR8A5CUl6+NtCkaTVSghUDT74iPn4nFkqTDQxpNI1oINP0OIcwkJ59DWdnb+P2eSJuj0UQcLQSafklGxtW43ccpKVkdaVM0moijhUDTL0lNvRCHYzgFBX+ItCkaTcTpcSEQQmQJIdYJIb4SQnwphLi1p23QaIQwM2TILVRVfUxV1WeRNkejiSiR8Ai8wI+llOOB2cAPhRDjI2CHpp8zcOB1mM3x2ivQ9Ht6XAiklMeklFsb31cDXwOZPW2HRmOxJDBw4PUUF/8Nl2t/pM3RaCJGRPsIhBDZwDTgkxaO3SiE2CyE2FxcXNzTpmn6CUOG3IIQVj77bCJ7995GXd1epPRF2iyNpkcRkVrrVQgRB3wAPCClfL2tc2fOnCk3b97cM4Zp+h0u137y83/B8eN/BXwIYcXpHM2IEb8hNfWCSJun0XQaIcQWKeXM9s6LiEcghLACq4AX2xMBjSbcOJ0jGDv2L5x66h7GjHmKrKwfI4Rgx44LOXDgXu0haPo8Pb4egRBCAE8DX0spf9fT99doWiN43YJhw37G3r03c+jQAzQ0HGbcuOcibJ1GEz4i4RHkAlcDZwshtjW+tP+tiSrMZidjxz5FVtYdFBY+T3X1tkibpNGEjUiMGvpISimklJOllFMbX2/1tB0aTSgMHXoPFksSeXk/j7QpGk3Y0DOLNZo2sFqTGDLkx5SW/pOqKj1gQdM30UKg0bTDkCG3YLGkaK9A02fRQqDRtIPFkkBW1h2Ulb3Frl3X43YXRdokjaZb6fFRQxpNbyQr63a83nIKCn5HcfHrpKVditWajtWagsnkwGRyYLEkYbUOwGyOx+9vQEo3Qtgwm2MRwoqUXqT0YjLZMJkcgAm/vwEhLMTEjEENqNNoeh4tBBpNCJhMNkaM+DUDB17HgQN3UVb2Hh5PMVK6u6X8KVPeJzn57G4pS6PpKFoINJoOEBs7lkmT3gBASonfX4ffX4/fX4/XW4nHU4LPV40QdkwmG36/G7+/Fr/fg8lkBcxI6cHvdyGlH5PJyldfXUV5uRYCTeTQQqDRdBIhBGZzLGZzLAB2e+dyJx4+/DBVVR93p2kaTYfQncUaTYRJSDidqqpP9LKZmoihPQKNJsIkJuZy5MijVFdvo6RkFh9/DFu3QnExlJSAywVeb+Dl84HfD1KqlxDqZbGol8nU/Ljx3u9XLwOTCcxmtfX51Cs4B2Xwe+MeRjktYZwjROBeQqjyg/vBg+914jGTCaxWtfV41CvYDuNZjPsZW+NZje/DYlHPduIzn/hcwftaKvdEgssKvq9he/DzBH/3Ld3T+P6FaP43PfE7ffppOOOMk6/vTrQQaDSN1NZCWRm43eoF6odYXw+VlapSPnAA9u+HiopAxWz84L1eVXH5fIEKVsrmlZ6xz6hQTCbwei8mL+9LSkpGUlur9sfGQkYGpKaq9zExqkyjgguudIzyfL6AUBjHjK0QgUrnxGv8fnXMKBeaC0xwJRtc3okEV3zGvUDdwzgOgXsF2xF8rsej9lmtAVEwrj9ROFoTK0NsTrQ3+LmCywj+Lk8st7XzTizLuG8wwX+Hlr4r438j+G964rMlJp5sS3ejhUDTp/D7oa4uUCEGt6SNH69RYR88CO+9Bx98AHl5qnIPhdRU9QpugRutUKtV/agNQQiugE+spMH4sdvJyclj7tyDnH76hcyZAxMmnFx5aDThQguBptdRVATbt8POnbBrFxw6BIcPQ2EhlJef3CprC4cD5sxRr8xMVcHb7WCzBc6x2SApCVJSICcnPC20r756kYqKdZx22hE9n0DT42gh0EQ9VVXw1lvw5pvw8ccqPGOQmgrZ2TBqFMydqz4nJgZCKMGt9OBYus0GaWlw2mlKDCJNYmIuRUUvUV+fh9OZE2lzNP0MLQSasCKliql//jns26de5eWqA7SuDqqroaameSfciR1yBQUqZp+Wpir7738fZsxQ4ZP09J5/pnCQmJgLQGXlf7UQaHocLQSaJqRU4ZU9e1SFXVSkOk+rqlTM2+1uHnM3PhstbCkDIz3cbmhoUGWVlQXuMXAgDBgATqfqAM3MVJ2hFkvAhhM75AYPhosvhtmzVcu+LxIbOxGzOYGqqv8ycODSSJuj6WdoIeiDuN2qFX34cKAyr6hQFXNDQ6DFbYxycLtVhb15sxoZE4zDAQkJqqI3RnEYIRebTW19PlWuEIHzbDaIi4NLL4VTT1Ut+NGj1T7NyQhhJinpLIqLVzNixCOYzVEQr9L0G7QQ9BGKiuAf/4BVq+A//1Et9ZYwhu4ZGCNfsrPhm9+EqVNhzBgYORIGDVKtdk3PMGTILWzf/gaFhX9l8OBlkTYnrJTUlRBjjSHG2rF/MCklHr8Hm9nW/skhlucLWpPaYup4lejxeXB5XcTZ4jCJ9od6+aWf4tpiUmNSm93P7XN323N1FC0EUY7brcawFxWpV2Wliqu7XKolXl0Nb78NGzaolv6IEXDrrTB+PGRlqVBMSooa9eJw9O7QSq27lhhrzEmjarx+LyV1JZTWlVLmKqOkroRjNQ3VafwAABKhSURBVMc4XnOcBHsC2UnZZMZnEmONIc4Wx/Dk4U1l+Pw+XvvqNQCGJQ3D4/Ow7fg2CqoK+N7M7zE8Wa1hXOepY/XXq8mryKOgqgCf9JFoTyTeHo/FZMFismA1WbGarVhNVswmMyZhaqpoEuwJTBs4jVGpo1qtLJKSzsIZO403tt/P8d0F1Hvr8TTONjYJEy6Pi92lu9lduhuv34vT4sRqtlLvrafeWw8EKjK3z43P72NY0jAmpE0gLSaN8vpy6r31XDDqAhaNX0Sdp44/f/ZnXt/1OlaTlThbHDHWGJxWJ7HWWNJi0kiPTWfm4JnMGToHs8nMuoPreGHHC9S4a3BanDT4GsivyOdo9VEmZUzivOHnMTx5OMdrjlPVUMWi8YsYljQMgK3HtvKHT/7AR4c+4kD5ARwWB+ePPJ/crFwOlB/gy+IvKXeVNz1zoj2RREcidZ46SupKKHOVUVFfgdvnJtmRzMiUkcTb4ymtK6WyoZJYayxJjiSSnckMiBmA0+Jkf/l+dpfsZuyAsSyfs5zZQ2bz7LZn+d3G33Go8hANvoZmf4MRySPIHZpLdmI2x2qOcazmGGZhxml10uBt4Ej1EQprCpv+Ni6PC5fXBYBZmEmNSWVS+iTOH3k+kzMms+34Nj498ilFtUW4vC4q6is4VHkIt8+N0+JkxuAZpDpT+aLwCw5WHGR48nDOyj6LrIQsDlcd5lDlIX59zq+ZNmha13487SBkSzMnooyZM2fKzZu7Z3Uotxt271Yx8P37VUy8qEjFwRsa1HFjUozbrSYTNTT+rwRPHjEmEBnj06H57M3gySJGzNuInQeHZoIn1Jw4M9HlCkxsaovx42HRIrjsMpg0qXFmp/Tj8Xlw+9zUe+vxSR9pMWmYTW0rgdvn5lj1MY5UH6HB24Bf+jGbzE0/ygR7Agn2BOq99RwsP0hBVQE2s414ezzDEocxKH5Qs/LKXeV8fvxzDlUeYkTyCMYOGKuurTjYrFVYWV9JYW0hNe4aLCYLdrOdBaMWMCRhCA3eBu58704e/fRRJqVP4rvTv0uiPZF/7f0XH+R9QHFdcah/fgAuHHUhL132Ek6Lk2v+cQ2v7HzlpHMEgnh7PE8vfJoUZwo3rrmR/eX7ARgQMwCLyUJlfWVTJRAqcbY4BsUNIsWZQpwtDqvZisVkQSCQSD4t+IiiugoEArvF3nTMJ31YTVZGp45mzIAxOC1OXF4XHp8Hp9WJ3WwHlLBJJHazHSEE+8v382XRl5TXl5PsSMYv/RypPkKCPaGpJXvGsDOIscZQ3VCNy+vC5XFR466huK64SWAS7AmkOFPIq8gj2ZHMwLiB1HvrMZvMZCdlkx6bzuajm9lTuqfZ81pNVpZNX0aVu4oXvniBJEcSZ+eczezM2RyqPMTqXas5Un2ERHsiE9Mnkh6bjtVsRUpJRX1FUwWfGpNKiiOFZGcycbY4jlYfZV/ZPmo9taQ6U5sEo9xVTnl9OaV1pdR6aslJymFU6ijWHVxHYW0hsdZYaj21nJp5Kmdmn4nNbMNqsiKEwOv3sr1wO/899F+K64rJiM1gYNxAJBKXx4XVbCUzPpNB8YNwmB1YzVYcFgeJ9kQcFgcV9RUU1Rax6cgmdhbtbPoORiSPICsxC6fFSYI9gWGJwxiSMIQD5Qf49OinlLnKmJwxmdEpo9lRtIMP8j+gsr6SgXEDGZo4lN+e91tyh+Z26P+s6f9YiC1SypntntcfhGD/fjX08N1/+1m/sZI6UQTxRyGmFGv9INKtI0i2p2KzS2w2iTB7weTDbHNjj2nAavdiknaEz4FZOjBJOyYhmsIqmDxU2nZRZzmMNLnB5CVBDiXZNwazsFJu3kWl6QBWiwm72almk+LCLzzYicNGPF7hokYW0kA1dpmE3Z+KzSaxOuuIjTUzPm0sEwePwBFfT6XIw2LzMDZ1PAkxDg7Ub+bPn/2ZTUc2NbWMg91dA4vJQlZCFkmOJEzChNlkxmpSFVFFfQVHq49SUleCpPP/E0MShjAhbQJlrjKOVB/haPXRTpdlFmYWT1jMntI9bD22laWTl7KrZBebj6r/hUFxg/jGyG8wLHEYaTFpDIgZoCoMZwqD4gaRFptGjbumqcXq8rr4qvgrVqxfwejU0QxLGsY7+97hl2f/km+O+Sb5FfkIIZg6cCoN3gauWHUFnx75FICRKSN5/ILHmTt0Lk6rs8lGn9+HT/rw+Dx4/J6mrbHfJEyYhZlSVylbjm7h8+OfU1xXTJmrjBp3DV6/F48vkGMoJymHabYPOTNzOLmzNnb7nAIpJR8e+pBntz2LzWzjllNvYXza+FbPrWyo5IO8D/jXnn9xpPoIV026isvGX4bD0nIfRl5FHkW1RQyOH4zH5+HX//01T3/+NBaThR/N/hF35d5FoiMwEcMv/ZTUlZAWkxbW+RMuj4tntz3LxwUfc+2Uazk75+xW7yelxOv3YjVbO32/gqoCdpXsYkrGFNJi0zp0rV/68fq93RImimohEEKcD/wBMANPSSkfbOv8zgrBE0/Ab57bycHEp2HCqxB/DETXn1cgiLHGEG+PJ8Yaw+HKw03ubDgxCRN+GRhbaTFZyIzPJL8yn1hrLPOHz2dg7EBSY1Kxm+1YzVZsZhtOixMhBAVVBeRX5lPdUI1P+vD5fU2VV6IjkcFxgxkUP4ishCwGxw8mxhqDSZjw+D1UNVRRUV9BVUMVVQ1VWE1WhicPJysxC4/PQ7W7mj2le/j0yKfsKtlFWmwamfGZjE4dzYxBMxiWNIz9ZfvZVbKLGGsMOck5pMem4/K4qPPUEW+PJyM2gwR7Aj7po6SuhKe2PsVTW5/CJEw8e8mzLByzEICdRTvx+DxMGTglpJjsiaw7uI5Ff19Euaucxy94nO/P+n6L57l9bh7Y8AAAy+csbyYA4aSg4DH27bsFu30oqanfJC5uKhZLIhZLAmZzPGZzHCaTHSEsqJ8QgEqJ7fVWNy6IY0EIKyaTDSFszbbqN+9DSl/jYjl+TCY7/7+9e4+RqyzjOP79ndntdstWtmtrlWVLW9logZSLBKl44WZgEYE/MBa5qST8gwqGRGnQeImJMRpRI3IJIAUbICBoQ0CBSjDEcLdy6bbSQrULlF4s22273dmZefzjfWd3tu2yy9LuOTPzfJLJzpw558zznnfmfc55Z/Z9k6Q57jMI+8jF9QaBUlwWXjfcT4DQoJrlKZXC5XOSNJMkjZRKBd7cvp5EMLvlkBjD6D3SpVKewcGtlEq7mTLlw+Ryk3PMa1VmE4GkHPBv4PNAD/AscIGZrRptm4kmgpN+8k3+UfwtORo5veOLnDDvSNqa25g5bSbt09tpa27jzb43WbdtHb27e8vx0ZA0kFOOKbkpQ5fnA4WBob7Y/kI/O/M76cv3sSO/gzkHz2Hh7IXMnzGfqQ1TEWL9O+vp3tLNYHGQBbMW0NnWCUB/oR8hpjaES8ud+Z1sH9hOU0PTUEPYO9DL1l1bkULCGSgMsHrLatZsXTPU5y3Eyo0r6d7SzSlzT+GSoy8ZcaZVK/oH+0mU0NTQtF/327O9hw29G1jUsWi/7nd/MCvx9tt3snnzA2zb9gil0nvrfsqOBNh7hLqQoKYhJTERla9eba+y5nIHkyRhdrew7RSkxqH1K/Y6lKTMChSLOyiV+pEaSJIphMQlIInJK8QWXtsqEhwxUVbeKmMvJ99i3FZD+zMbjLfSUExJ0ojUSGj2krh+/H6quItisQ+zArlcC7lcS1wvvAfKx2bBgqW0tn5u/Id9RLzZTQSLgB+a2Rnx8RIAM/vpaNtMNBE8/OrDrN6ymosWXvSeL8+cy4JSaYB8fhOFQi/F4naKxb541j84NPVl+Yw8l5tGLjc9nvUXKJXKDVM4Uy+V8nFGtdAYDjd+is/3j2iUy1cMUi42ZsnQ1UH4WwTC+mYWp+BsihP29FMq7Y7TeDbHbQfjRD27KBZ3ERrgHMONNORyH6CxcSZJ0kQ+v5F8fiNmxRinDe0jGG5UQ8MZYpMa4lVTczxG+aEGPzTSFveZVDT+5ase4vEs77t8g3LiMCvFbXMV25b2aPTLMZXjLY14fTCS5CAaGqYjNVAs7qBQ6GM48ZQTW46OjqtpaVk4offPeBNBGr8aagc2VDzuAT6550qSLgcuB5gzZ86EXqirs4uuzq4JbetcFiRJE1OndgAdaYfialhmxzc0s5vN7HgzO37WLD+bd865AyWNRPAGI09vDo3LnHPOpSCNRPAs0ClpnqQpwGJgeQpxOOecI4XvCMysIOkbwF8JX7/fZmavTHYczjnnglSGmDCzh4CH0nht55xzI2X2y2LnnHOTwxOBc87VOU8EzjlX56pi0DlJm4H/THDzmcCWMdfKNi9DNtRCGaA2yuFlGJ/DzGzMf8SqikTwfkh6bjz/Yp1lXoZsqIUyQG2Uw8uwf3nXkHPO1TlPBM45V+fqIRHcnHYA+4GXIRtqoQxQG+XwMuxHNf8dgXPOuXdXD1cEzjnn3kVNJwJJZ0paI2mtpGvSjmc8JHVIelzSKkmvSLoyLm+T9KikV+PfGWnHOhZJOUn/lPRgfDxP0tOxPu6Jgw5mlqRWSfdJWi2pW9KiaqsHSd+O76OXJd0laWrW60HSbZI2SXq5Ytk+j7uC38SyvCjpuPQiHzZKGX4e30svSnpAUmvFc0tiGdZIOmOy463ZRBCnxLwe6AKOAC6QtO9ZurOlAFxtZkcAJwJXxLivAVaYWSewIj7OuiuB7orHPwOuM7PDgW3AZalENX6/Bv5iZh8HjiaUpWrqQVI78C3geDM7ijDI42KyXw+3A2fusWy0494FdMbb5cANkxTjWG5n7zI8ChxlZgsJ0/UuAYif78XAkXGb36k8zdkkqdlEAJwArDWz1yzMz3c3cG7KMY3JzN4ysxfi/T5C49NOiH1pXG0pcF46EY6PpEOBLwC3xMcCTgXui6tkugySDgY+C9wKYGZ5M3uHKqsHwsCSzQpzMk4D3iLj9WBmfwf+t8fi0Y77ucAdFjwFtEr6yOREOrp9lcHMHrHy5MvwFGEuFghluNvMBszsdWAtof2aNLWcCPY1JWZ7SrFMiKS5wLHA08BsM3srPrURmJ1SWOP1K+A7DM9e/kHgnYoPQtbrYx6wGfh97N66RdJBVFE9mNkbwC+A/xISQC/wPNVVD2WjHfdq/Zx/HXg43k+9DLWcCKqapBbgj8BVZra98jkLP/XK7M+9JJ0NbDKz59OO5X1oAI4DbjCzY4Gd7NENVAX1MINwtjkPOAQ4iL27K6pO1o/7WCRdS+gCXpZ2LGW1nAiqdkpMSY2EJLDMzO6Pi98uX/LGv5vSim8cTgLOkbSe0CV3KqG/vTV2UUD266MH6DGzp+Pj+wiJoZrq4XTgdTPbbGaDwP2Euqmmeigb7bhX1edc0leBs4ELbfi3+6mXoZYTQVVOiRn70m8Fus3slxVPLQcujfcvBf482bGNl5ktMbNDzWwu4bj/zcwuBB4Hzo+rZb0MG4ENkj4WF50GrKKK6oHQJXSipGnxfVUuQ9XUQ4XRjvty4JL466ETgd6KLqRMkXQmobv0HDPbVfHUcmCxpCZJ8whffD8zqcGZWc3egLMI386vA65NO55xxvxpwmXvi8DKeDuL0Me+AngVeAxoSzvWcZbnZODBeH8+4Q2+FrgXaEo7vjFiPwZ4LtbFn4AZ1VYPwI+A1cDLwJ1AU9brAbiL8J3GIOHK7LLRjjsgwq8D1wEvEX4hldUyrCV8F1D+XN9Ysf61sQxrgK7Jjtf/s9g55+pcLXcNOeecGwdPBM45V+c8ETjnXJ3zROCcc3XOE4FzztU5TwTOHWCSTi6PwOpcFnkicM65OueJwLlI0kWSnpG0UtJNcT6FHZKui2P6r5A0K657jKSnKsaWL4+Pf7ikxyT9S9ILkj4ad99SMbfBsvifvs5lgicC5wBJC4AvAyeZ2TFAEbiQMFDbc2Z2JPAE8IO4yR3Ady2MLf9SxfJlwPVmdjTwKcJ/l0IYRfYqwtwY8wlj/jiXCQ1jr+JcXTgN+ATwbDxZbyYMbFYC7onr/AG4P85V0GpmT8TlS4F7JU0H2s3sAQAz2w0Q9/eMmfXExyuBucCTB75Yzo3NE4FzgYClZrZkxELp+3usN9ExWQYq7hfxz57LEO8aci5YAZwv6UMwNEfuYYTPSHmkzq8AT5pZL7BN0mfi8ouBJyzMKNcj6by4jyZJ0ya1FM5NgJ+VOAeY2SpJ3wMekZQQRo28gjAhzQnxuU2E7xEgDIV8Y2zoXwO+FpdfDNwk6cdxH1+axGI4NyE++qhz70LSDjNrSTsO5w4k7xpyzrk651cEzjlX5/yKwDnn6pwnAuecq3OeCJxzrs55InDOuTrnicA55+qcJwLnnKtz/wdiLx7y1SIi9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 691us/sample - loss: 5.3634 - acc: 0.3448\n",
      "Loss: 5.3634026266951675 Accuracy: 0.34475598\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.3684 - acc: 0.2955\n",
      "Epoch 00001: val_loss improved from inf to 2.96340, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_2_conv_checkpoint/001-2.9634.hdf5\n",
      "36805/36805 [==============================] - 129s 4ms/sample - loss: 3.3683 - acc: 0.2955 - val_loss: 2.9634 - val_acc: 0.2765\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4488 - acc: 0.6035\n",
      "Epoch 00002: val_loss did not improve from 2.96340\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 1.4487 - acc: 0.6035 - val_loss: 3.2256 - val_acc: 0.3189\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8319 - acc: 0.7580\n",
      "Epoch 00003: val_loss improved from 2.96340 to 2.91779, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_2_conv_checkpoint/003-2.9178.hdf5\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.8319 - acc: 0.7580 - val_loss: 2.9178 - val_acc: 0.3790\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5296 - acc: 0.8430\n",
      "Epoch 00004: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.5297 - acc: 0.8429 - val_loss: 3.6335 - val_acc: 0.3389\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4094 - acc: 0.8809\n",
      "Epoch 00005: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.4094 - acc: 0.8809 - val_loss: 3.4209 - val_acc: 0.3664\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3454 - acc: 0.9018\n",
      "Epoch 00006: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.3454 - acc: 0.9018 - val_loss: 3.5848 - val_acc: 0.3713\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3014 - acc: 0.9138\n",
      "Epoch 00007: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.3014 - acc: 0.9138 - val_loss: 4.5347 - val_acc: 0.3538\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2664 - acc: 0.9247\n",
      "Epoch 00008: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.2665 - acc: 0.9247 - val_loss: 4.4396 - val_acc: 0.3678\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2577 - acc: 0.9292\n",
      "Epoch 00009: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.2577 - acc: 0.9292 - val_loss: 4.3309 - val_acc: 0.3790\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2308 - acc: 0.9385\n",
      "Epoch 00010: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.2307 - acc: 0.9385 - val_loss: 4.7700 - val_acc: 0.3597\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2112 - acc: 0.9430\n",
      "Epoch 00011: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.2112 - acc: 0.9430 - val_loss: 4.8940 - val_acc: 0.3643\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9406\n",
      "Epoch 00012: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.2263 - acc: 0.9406 - val_loss: 4.9081 - val_acc: 0.3548\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9517\n",
      "Epoch 00013: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1846 - acc: 0.9517 - val_loss: 4.7007 - val_acc: 0.3683\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9543\n",
      "Epoch 00014: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1780 - acc: 0.9543 - val_loss: 5.2082 - val_acc: 0.3706\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1732 - acc: 0.9554\n",
      "Epoch 00015: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1733 - acc: 0.9554 - val_loss: 5.5652 - val_acc: 0.3347\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1568 - acc: 0.9606\n",
      "Epoch 00016: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1568 - acc: 0.9606 - val_loss: 5.3930 - val_acc: 0.3718\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1512 - acc: 0.9629\n",
      "Epoch 00017: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1512 - acc: 0.9629 - val_loss: 4.7200 - val_acc: 0.3925\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9677\n",
      "Epoch 00018: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1364 - acc: 0.9677 - val_loss: 6.9163 - val_acc: 0.3021\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1440 - acc: 0.9651\n",
      "Epoch 00019: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.1440 - acc: 0.9651 - val_loss: 5.4590 - val_acc: 0.3753\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1506 - acc: 0.9661\n",
      "Epoch 00020: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.1506 - acc: 0.9661 - val_loss: 6.4902 - val_acc: 0.3329\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9671\n",
      "Epoch 00021: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.1363 - acc: 0.9672 - val_loss: 5.2944 - val_acc: 0.3864\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9707\n",
      "Epoch 00022: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1320 - acc: 0.9707 - val_loss: 5.2565 - val_acc: 0.3948\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9719\n",
      "Epoch 00023: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1233 - acc: 0.9719 - val_loss: 5.2395 - val_acc: 0.4034\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9727\n",
      "Epoch 00024: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1213 - acc: 0.9727 - val_loss: 5.4694 - val_acc: 0.3881\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9685\n",
      "Epoch 00025: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1394 - acc: 0.9685 - val_loss: 5.7614 - val_acc: 0.3818\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9765\n",
      "Epoch 00026: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.1064 - acc: 0.9765 - val_loss: 5.4367 - val_acc: 0.4060\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1206 - acc: 0.9725\n",
      "Epoch 00027: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.1206 - acc: 0.9725 - val_loss: 6.1533 - val_acc: 0.3620\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9760\n",
      "Epoch 00028: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.1113 - acc: 0.9759 - val_loss: 5.5039 - val_acc: 0.4011\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9748\n",
      "Epoch 00029: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1126 - acc: 0.9748 - val_loss: 5.4244 - val_acc: 0.4128\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9767\n",
      "Epoch 00030: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1068 - acc: 0.9767 - val_loss: 5.3487 - val_acc: 0.4018\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9811\n",
      "Epoch 00031: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.0904 - acc: 0.9811 - val_loss: 5.8442 - val_acc: 0.3876\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0998 - acc: 0.9789\n",
      "Epoch 00032: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.0998 - acc: 0.9789 - val_loss: 5.9693 - val_acc: 0.3923\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9799\n",
      "Epoch 00033: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.0975 - acc: 0.9799 - val_loss: 5.6937 - val_acc: 0.4104\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9807\n",
      "Epoch 00034: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0961 - acc: 0.9807 - val_loss: 6.5092 - val_acc: 0.3552\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9797\n",
      "Epoch 00035: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0991 - acc: 0.9797 - val_loss: 6.1295 - val_acc: 0.3694\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1014 - acc: 0.9798\n",
      "Epoch 00036: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.1014 - acc: 0.9798 - val_loss: 5.6062 - val_acc: 0.4051\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9806\n",
      "Epoch 00037: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0929 - acc: 0.9806 - val_loss: 5.7925 - val_acc: 0.4076\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9799\n",
      "Epoch 00038: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0940 - acc: 0.9799 - val_loss: 5.9207 - val_acc: 0.3946\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9834\n",
      "Epoch 00039: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0843 - acc: 0.9834 - val_loss: 5.7428 - val_acc: 0.4062\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9833\n",
      "Epoch 00040: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0820 - acc: 0.9833 - val_loss: 5.7256 - val_acc: 0.4053\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9836\n",
      "Epoch 00041: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0819 - acc: 0.9836 - val_loss: 5.7743 - val_acc: 0.3953\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9822\n",
      "Epoch 00042: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0914 - acc: 0.9822 - val_loss: 6.3058 - val_acc: 0.3760\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9815\n",
      "Epoch 00043: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0977 - acc: 0.9814 - val_loss: 6.0892 - val_acc: 0.3871\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9825\n",
      "Epoch 00044: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0888 - acc: 0.9825 - val_loss: 5.9377 - val_acc: 0.3934\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9860\n",
      "Epoch 00045: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0744 - acc: 0.9860 - val_loss: 6.6430 - val_acc: 0.3732\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9836\n",
      "Epoch 00046: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0864 - acc: 0.9836 - val_loss: 6.2882 - val_acc: 0.3864\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9857\n",
      "Epoch 00047: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.0723 - acc: 0.9857 - val_loss: 6.0047 - val_acc: 0.3902\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9860\n",
      "Epoch 00048: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.0727 - acc: 0.9860 - val_loss: 6.2122 - val_acc: 0.3853\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9834\n",
      "Epoch 00049: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.0851 - acc: 0.9834 - val_loss: 6.2758 - val_acc: 0.3979\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9851\n",
      "Epoch 00050: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0795 - acc: 0.9851 - val_loss: 5.8285 - val_acc: 0.4081\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9856\n",
      "Epoch 00051: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0776 - acc: 0.9856 - val_loss: 5.9423 - val_acc: 0.4130\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9879\n",
      "Epoch 00052: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 0.0647 - acc: 0.9879 - val_loss: 5.9281 - val_acc: 0.4111\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9861\n",
      "Epoch 00053: val_loss did not improve from 2.91779\n",
      "36805/36805 [==============================] - 127s 3ms/sample - loss: 0.0764 - acc: 0.9861 - val_loss: 6.0977 - val_acc: 0.3967\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 3.0365 - acc: 0.3452\n",
      "Loss: 3.036466135092366 Accuracy: 0.34517133\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4245 - acc: 0.3597\n",
      "Epoch 00001: val_loss improved from inf to 1.90375, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_3_conv_checkpoint/001-1.9038.hdf5\n",
      "36805/36805 [==============================] - 149s 4ms/sample - loss: 2.4243 - acc: 0.3597 - val_loss: 1.9038 - val_acc: 0.3993\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4344 - acc: 0.5692\n",
      "Epoch 00002: val_loss improved from 1.90375 to 1.78106, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_3_conv_checkpoint/002-1.7811.hdf5\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 1.4344 - acc: 0.5692 - val_loss: 1.7811 - val_acc: 0.4985\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0308 - acc: 0.6806\n",
      "Epoch 00003: val_loss did not improve from 1.78106\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 1.0309 - acc: 0.6806 - val_loss: 1.8354 - val_acc: 0.4903\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7624 - acc: 0.7573\n",
      "Epoch 00004: val_loss did not improve from 1.78106\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.7625 - acc: 0.7573 - val_loss: 1.7968 - val_acc: 0.5143\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5940 - acc: 0.8112\n",
      "Epoch 00005: val_loss improved from 1.78106 to 1.59943, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_3_conv_checkpoint/005-1.5994.hdf5\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.5940 - acc: 0.8112 - val_loss: 1.5994 - val_acc: 0.5733\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4709 - acc: 0.8510\n",
      "Epoch 00006: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.4709 - acc: 0.8510 - val_loss: 1.7718 - val_acc: 0.5490\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3789 - acc: 0.8799\n",
      "Epoch 00007: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.3790 - acc: 0.8799 - val_loss: 1.7235 - val_acc: 0.5686\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3261 - acc: 0.8965\n",
      "Epoch 00008: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.3261 - acc: 0.8966 - val_loss: 1.9269 - val_acc: 0.5521\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2711 - acc: 0.9162\n",
      "Epoch 00009: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.2711 - acc: 0.9162 - val_loss: 1.8756 - val_acc: 0.5644\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2563 - acc: 0.9206\n",
      "Epoch 00010: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.2563 - acc: 0.9206 - val_loss: 2.1984 - val_acc: 0.5201\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2150 - acc: 0.9325\n",
      "Epoch 00011: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.2151 - acc: 0.9325 - val_loss: 2.0791 - val_acc: 0.5565\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2238 - acc: 0.9315\n",
      "Epoch 00012: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.2238 - acc: 0.9315 - val_loss: 1.9900 - val_acc: 0.5865\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1948 - acc: 0.9402\n",
      "Epoch 00013: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1947 - acc: 0.9402 - val_loss: 2.0939 - val_acc: 0.5749\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1806 - acc: 0.9455\n",
      "Epoch 00014: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1809 - acc: 0.9455 - val_loss: 2.2743 - val_acc: 0.5483\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1763 - acc: 0.9468\n",
      "Epoch 00015: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1763 - acc: 0.9468 - val_loss: 2.1886 - val_acc: 0.5737\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9525\n",
      "Epoch 00016: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1575 - acc: 0.9525 - val_loss: 2.4993 - val_acc: 0.5441\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9555\n",
      "Epoch 00017: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1502 - acc: 0.9555 - val_loss: 2.3118 - val_acc: 0.5667\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9575\n",
      "Epoch 00018: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1408 - acc: 0.9575 - val_loss: 2.6462 - val_acc: 0.5264\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9561\n",
      "Epoch 00019: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1465 - acc: 0.9560 - val_loss: 2.2923 - val_acc: 0.5639\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9585\n",
      "Epoch 00020: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1379 - acc: 0.9585 - val_loss: 2.2585 - val_acc: 0.5795\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9627\n",
      "Epoch 00021: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1261 - acc: 0.9626 - val_loss: 2.4274 - val_acc: 0.5693\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9615\n",
      "Epoch 00022: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.1278 - acc: 0.9615 - val_loss: 2.3505 - val_acc: 0.5809\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9599\n",
      "Epoch 00023: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1335 - acc: 0.9599 - val_loss: 2.4469 - val_acc: 0.5653\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9653\n",
      "Epoch 00024: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.1137 - acc: 0.9653 - val_loss: 2.4459 - val_acc: 0.5761\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1170 - acc: 0.9664\n",
      "Epoch 00025: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1173 - acc: 0.9664 - val_loss: 2.6377 - val_acc: 0.5544\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9627\n",
      "Epoch 00026: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1289 - acc: 0.9626 - val_loss: 2.3704 - val_acc: 0.5905\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9689\n",
      "Epoch 00027: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1075 - acc: 0.9688 - val_loss: 2.4426 - val_acc: 0.5772\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9689\n",
      "Epoch 00028: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.1092 - acc: 0.9689 - val_loss: 2.5586 - val_acc: 0.5735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9733\n",
      "Epoch 00029: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.0955 - acc: 0.9733 - val_loss: 2.4986 - val_acc: 0.5847\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9732\n",
      "Epoch 00030: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.0926 - acc: 0.9732 - val_loss: 2.6435 - val_acc: 0.5737\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9736\n",
      "Epoch 00031: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0943 - acc: 0.9736 - val_loss: 2.5785 - val_acc: 0.5865\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9749\n",
      "Epoch 00032: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.0888 - acc: 0.9749 - val_loss: 2.5845 - val_acc: 0.5861\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9750\n",
      "Epoch 00033: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0925 - acc: 0.9750 - val_loss: 2.9204 - val_acc: 0.5616\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9739\n",
      "Epoch 00034: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0952 - acc: 0.9739 - val_loss: 2.5673 - val_acc: 0.5823\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9768\n",
      "Epoch 00035: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.0845 - acc: 0.9768 - val_loss: 2.6093 - val_acc: 0.5872\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9781\n",
      "Epoch 00036: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0802 - acc: 0.9780 - val_loss: 2.6709 - val_acc: 0.5823\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9753\n",
      "Epoch 00037: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.0891 - acc: 0.9752 - val_loss: 2.7057 - val_acc: 0.5823\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9787\n",
      "Epoch 00038: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0770 - acc: 0.9787 - val_loss: 2.5397 - val_acc: 0.5986\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9762\n",
      "Epoch 00039: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0886 - acc: 0.9762 - val_loss: 2.8562 - val_acc: 0.5726\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9782\n",
      "Epoch 00040: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0796 - acc: 0.9782 - val_loss: 2.6737 - val_acc: 0.5889\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9775\n",
      "Epoch 00041: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.0842 - acc: 0.9775 - val_loss: 2.7893 - val_acc: 0.5795\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9806\n",
      "Epoch 00042: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0719 - acc: 0.9806 - val_loss: 3.0499 - val_acc: 0.5705\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9808\n",
      "Epoch 00043: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0722 - acc: 0.9808 - val_loss: 2.8102 - val_acc: 0.5844\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9812\n",
      "Epoch 00044: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.0699 - acc: 0.9813 - val_loss: 2.6980 - val_acc: 0.5961\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9805\n",
      "Epoch 00045: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0738 - acc: 0.9805 - val_loss: 2.7571 - val_acc: 0.5973\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9802\n",
      "Epoch 00046: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.0718 - acc: 0.9802 - val_loss: 2.8747 - val_acc: 0.5865\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9795\n",
      "Epoch 00047: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.0783 - acc: 0.9795 - val_loss: 2.6802 - val_acc: 0.5949\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9813\n",
      "Epoch 00048: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0691 - acc: 0.9813 - val_loss: 2.9401 - val_acc: 0.5786\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9829\n",
      "Epoch 00049: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.0644 - acc: 0.9829 - val_loss: 2.7019 - val_acc: 0.6010\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9821\n",
      "Epoch 00050: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0660 - acc: 0.9821 - val_loss: 2.8762 - val_acc: 0.5826\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9824\n",
      "Epoch 00051: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0666 - acc: 0.9824 - val_loss: 2.8257 - val_acc: 0.5973\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9823\n",
      "Epoch 00052: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0662 - acc: 0.9823 - val_loss: 2.8692 - val_acc: 0.5900\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9821\n",
      "Epoch 00053: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 145s 4ms/sample - loss: 0.0671 - acc: 0.9821 - val_loss: 2.8983 - val_acc: 0.5919\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9832\n",
      "Epoch 00054: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0637 - acc: 0.9832 - val_loss: 2.8434 - val_acc: 0.5942\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9822\n",
      "Epoch 00055: val_loss did not improve from 1.59943\n",
      "36805/36805 [==============================] - 144s 4ms/sample - loss: 0.0651 - acc: 0.9822 - val_loss: 2.9294 - val_acc: 0.5851\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.7968 - acc: 0.5221\n",
      "Loss: 1.7968388077625976 Accuracy: 0.5221184\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2810 - acc: 0.3600\n",
      "Epoch 00001: val_loss improved from inf to 1.93974, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_4_conv_checkpoint/001-1.9397.hdf5\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 2.2811 - acc: 0.3600 - val_loss: 1.9397 - val_acc: 0.4002\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5138 - acc: 0.5376\n",
      "Epoch 00002: val_loss improved from 1.93974 to 1.30155, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_4_conv_checkpoint/002-1.3016.hdf5\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 1.5139 - acc: 0.5376 - val_loss: 1.3016 - val_acc: 0.5989\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2644 - acc: 0.6122\n",
      "Epoch 00003: val_loss improved from 1.30155 to 1.28605, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_4_conv_checkpoint/003-1.2861.hdf5\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 1.2643 - acc: 0.6123 - val_loss: 1.2861 - val_acc: 0.6063\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0921 - acc: 0.6602\n",
      "Epoch 00004: val_loss improved from 1.28605 to 1.16428, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_4_conv_checkpoint/004-1.1643.hdf5\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 1.0920 - acc: 0.6603 - val_loss: 1.1643 - val_acc: 0.6473\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9625 - acc: 0.7003\n",
      "Epoch 00005: val_loss did not improve from 1.16428\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.9625 - acc: 0.7003 - val_loss: 1.2454 - val_acc: 0.6299\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8391 - acc: 0.7371\n",
      "Epoch 00006: val_loss did not improve from 1.16428\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.8391 - acc: 0.7372 - val_loss: 1.4837 - val_acc: 0.5639\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7445 - acc: 0.7647\n",
      "Epoch 00007: val_loss did not improve from 1.16428\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.7445 - acc: 0.7647 - val_loss: 1.4349 - val_acc: 0.5961\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6615 - acc: 0.7898\n",
      "Epoch 00008: val_loss did not improve from 1.16428\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.6616 - acc: 0.7897 - val_loss: 1.2708 - val_acc: 0.6271\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6043 - acc: 0.8093\n",
      "Epoch 00009: val_loss did not improve from 1.16428\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.6044 - acc: 0.8093 - val_loss: 1.2444 - val_acc: 0.6490\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5376 - acc: 0.8296\n",
      "Epoch 00010: val_loss improved from 1.16428 to 1.10923, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_4_conv_checkpoint/010-1.1092.hdf5\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.5376 - acc: 0.8296 - val_loss: 1.1092 - val_acc: 0.6832\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4968 - acc: 0.8417\n",
      "Epoch 00011: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.4968 - acc: 0.8418 - val_loss: 1.2307 - val_acc: 0.6536\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4535 - acc: 0.8548\n",
      "Epoch 00012: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.4536 - acc: 0.8548 - val_loss: 1.2338 - val_acc: 0.6583\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4212 - acc: 0.8653\n",
      "Epoch 00013: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.4212 - acc: 0.8653 - val_loss: 1.2892 - val_acc: 0.6629\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3855 - acc: 0.8778\n",
      "Epoch 00014: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.3854 - acc: 0.8778 - val_loss: 1.2762 - val_acc: 0.6576\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3476 - acc: 0.8899\n",
      "Epoch 00015: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.3477 - acc: 0.8898 - val_loss: 1.1989 - val_acc: 0.6918\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3298 - acc: 0.8944\n",
      "Epoch 00016: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.3299 - acc: 0.8944 - val_loss: 1.2265 - val_acc: 0.6844\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3092 - acc: 0.9009\n",
      "Epoch 00017: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.3092 - acc: 0.9009 - val_loss: 1.2210 - val_acc: 0.7018\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2904 - acc: 0.9090\n",
      "Epoch 00018: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.2904 - acc: 0.9090 - val_loss: 1.2299 - val_acc: 0.6865\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2727 - acc: 0.9146\n",
      "Epoch 00019: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.2729 - acc: 0.9145 - val_loss: 1.2632 - val_acc: 0.6886\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2577 - acc: 0.9189\n",
      "Epoch 00020: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.2577 - acc: 0.9189 - val_loss: 1.5240 - val_acc: 0.6434\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2485 - acc: 0.9208\n",
      "Epoch 00021: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.2485 - acc: 0.9208 - val_loss: 1.2852 - val_acc: 0.6956\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2418 - acc: 0.9237\n",
      "Epoch 00022: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.2418 - acc: 0.9237 - val_loss: 1.3271 - val_acc: 0.6937\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2204 - acc: 0.9310\n",
      "Epoch 00023: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.2203 - acc: 0.9310 - val_loss: 1.2633 - val_acc: 0.6974\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9330\n",
      "Epoch 00024: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.2107 - acc: 0.9330 - val_loss: 1.2596 - val_acc: 0.7063\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2040 - acc: 0.9364\n",
      "Epoch 00025: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.2040 - acc: 0.9364 - val_loss: 1.3300 - val_acc: 0.6946\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1954 - acc: 0.9394\n",
      "Epoch 00026: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1954 - acc: 0.9394 - val_loss: 1.2339 - val_acc: 0.7095\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9392\n",
      "Epoch 00027: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1924 - acc: 0.9391 - val_loss: 1.3724 - val_acc: 0.6869\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1859 - acc: 0.9410\n",
      "Epoch 00028: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1860 - acc: 0.9410 - val_loss: 1.2163 - val_acc: 0.7174\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1774 - acc: 0.9442\n",
      "Epoch 00029: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1774 - acc: 0.9441 - val_loss: 1.2924 - val_acc: 0.7102\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1702 - acc: 0.9470\n",
      "Epoch 00030: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1703 - acc: 0.9469 - val_loss: 1.3021 - val_acc: 0.6993\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9460\n",
      "Epoch 00031: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1689 - acc: 0.9460 - val_loss: 1.4160 - val_acc: 0.6879\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9517\n",
      "Epoch 00032: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1592 - acc: 0.9517 - val_loss: 1.3062 - val_acc: 0.7133\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9486\n",
      "Epoch 00033: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1581 - acc: 0.9486 - val_loss: 1.2880 - val_acc: 0.7140\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1528 - acc: 0.9528\n",
      "Epoch 00034: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1528 - acc: 0.9528 - val_loss: 1.3653 - val_acc: 0.6974\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9558\n",
      "Epoch 00035: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1449 - acc: 0.9557 - val_loss: 1.2935 - val_acc: 0.7174\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1521 - acc: 0.9523\n",
      "Epoch 00036: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1521 - acc: 0.9523 - val_loss: 1.3000 - val_acc: 0.7112\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9598\n",
      "Epoch 00037: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1325 - acc: 0.9598 - val_loss: 1.7182 - val_acc: 0.6723\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1404 - acc: 0.9551\n",
      "Epoch 00038: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1404 - acc: 0.9551 - val_loss: 1.4693 - val_acc: 0.6986\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9597\n",
      "Epoch 00039: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1297 - acc: 0.9597 - val_loss: 1.3790 - val_acc: 0.7032\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9579\n",
      "Epoch 00040: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1351 - acc: 0.9579 - val_loss: 1.3838 - val_acc: 0.7114\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9613\n",
      "Epoch 00041: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1265 - acc: 0.9613 - val_loss: 1.2999 - val_acc: 0.7237\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9620\n",
      "Epoch 00042: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1240 - acc: 0.9620 - val_loss: 1.3709 - val_acc: 0.7188\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9641\n",
      "Epoch 00043: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1181 - acc: 0.9641 - val_loss: 1.4164 - val_acc: 0.7123\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1191 - acc: 0.9630\n",
      "Epoch 00044: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1191 - acc: 0.9630 - val_loss: 1.4459 - val_acc: 0.7154\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9652\n",
      "Epoch 00045: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1141 - acc: 0.9652 - val_loss: 1.4795 - val_acc: 0.7065\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1189 - acc: 0.9636\n",
      "Epoch 00046: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1189 - acc: 0.9636 - val_loss: 1.5384 - val_acc: 0.7042\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9663\n",
      "Epoch 00047: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1112 - acc: 0.9663 - val_loss: 1.3444 - val_acc: 0.7237\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9677\n",
      "Epoch 00048: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1052 - acc: 0.9677 - val_loss: 1.4354 - val_acc: 0.7135\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9676\n",
      "Epoch 00049: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1061 - acc: 0.9676 - val_loss: 1.3857 - val_acc: 0.7226\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9661\n",
      "Epoch 00050: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1114 - acc: 0.9661 - val_loss: 1.3829 - val_acc: 0.7282\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9700\n",
      "Epoch 00051: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1042 - acc: 0.9700 - val_loss: 1.3220 - val_acc: 0.7370\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9688\n",
      "Epoch 00052: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1032 - acc: 0.9688 - val_loss: 1.5118 - val_acc: 0.7030\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9680\n",
      "Epoch 00053: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1055 - acc: 0.9679 - val_loss: 1.4495 - val_acc: 0.7133\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9682\n",
      "Epoch 00054: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.1039 - acc: 0.9682 - val_loss: 1.3669 - val_acc: 0.7282\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9709\n",
      "Epoch 00055: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0944 - acc: 0.9709 - val_loss: 1.3944 - val_acc: 0.7282\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9716\n",
      "Epoch 00056: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0941 - acc: 0.9716 - val_loss: 1.5099 - val_acc: 0.7037\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9716\n",
      "Epoch 00057: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0941 - acc: 0.9716 - val_loss: 1.4401 - val_acc: 0.7275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9724\n",
      "Epoch 00058: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0911 - acc: 0.9723 - val_loss: 1.3801 - val_acc: 0.7314\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9726\n",
      "Epoch 00059: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0908 - acc: 0.9726 - val_loss: 1.5098 - val_acc: 0.7223\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9733\n",
      "Epoch 00060: val_loss did not improve from 1.10923\n",
      "36805/36805 [==============================] - 150s 4ms/sample - loss: 0.0909 - acc: 0.9732 - val_loss: 1.3999 - val_acc: 0.7321\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 1.2333 - acc: 0.6496\n",
      "Loss: 1.2332667967240758 Accuracy: 0.64963657\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0789 - acc: 0.4033\n",
      "Epoch 00001: val_loss improved from inf to 1.41285, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_5_conv_checkpoint/001-1.4128.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 2.0787 - acc: 0.4034 - val_loss: 1.4128 - val_acc: 0.5390\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4378 - acc: 0.5689\n",
      "Epoch 00002: val_loss improved from 1.41285 to 1.14488, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_5_conv_checkpoint/002-1.1449.hdf5\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 1.4384 - acc: 0.5688 - val_loss: 1.1449 - val_acc: 0.6506\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2043 - acc: 0.6319\n",
      "Epoch 00003: val_loss did not improve from 1.14488\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 1.2043 - acc: 0.6319 - val_loss: 1.2542 - val_acc: 0.6205\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0448 - acc: 0.6795\n",
      "Epoch 00004: val_loss improved from 1.14488 to 1.11862, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_5_conv_checkpoint/004-1.1186.hdf5\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 1.0447 - acc: 0.6796 - val_loss: 1.1186 - val_acc: 0.6711\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9096 - acc: 0.7188\n",
      "Epoch 00005: val_loss improved from 1.11862 to 1.04188, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_5_conv_checkpoint/005-1.0419.hdf5\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.9098 - acc: 0.7188 - val_loss: 1.0419 - val_acc: 0.6897\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8198 - acc: 0.7471\n",
      "Epoch 00006: val_loss improved from 1.04188 to 1.03917, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_5_conv_checkpoint/006-1.0392.hdf5\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.8197 - acc: 0.7471 - val_loss: 1.0392 - val_acc: 0.7030\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7289 - acc: 0.7740\n",
      "Epoch 00007: val_loss did not improve from 1.03917\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.7288 - acc: 0.7741 - val_loss: 1.0423 - val_acc: 0.7011\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6596 - acc: 0.7940\n",
      "Epoch 00008: val_loss improved from 1.03917 to 0.98816, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_5_conv_checkpoint/008-0.9882.hdf5\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.6595 - acc: 0.7940 - val_loss: 0.9882 - val_acc: 0.7149\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6025 - acc: 0.8113\n",
      "Epoch 00009: val_loss improved from 0.98816 to 0.98010, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_5_conv_checkpoint/009-0.9801.hdf5\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.6025 - acc: 0.8113 - val_loss: 0.9801 - val_acc: 0.7216\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5529 - acc: 0.8267\n",
      "Epoch 00010: val_loss improved from 0.98010 to 0.95609, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_5_conv_checkpoint/010-0.9561.hdf5\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.5529 - acc: 0.8267 - val_loss: 0.9561 - val_acc: 0.7244\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4971 - acc: 0.8427\n",
      "Epoch 00011: val_loss did not improve from 0.95609\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.4972 - acc: 0.8427 - val_loss: 0.9576 - val_acc: 0.7268\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4491 - acc: 0.8568\n",
      "Epoch 00012: val_loss improved from 0.95609 to 0.95290, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_5_conv_checkpoint/012-0.9529.hdf5\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.4491 - acc: 0.8568 - val_loss: 0.9529 - val_acc: 0.7400\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4245 - acc: 0.8664\n",
      "Epoch 00013: val_loss improved from 0.95290 to 0.89820, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_5_conv_checkpoint/013-0.8982.hdf5\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.4244 - acc: 0.8664 - val_loss: 0.8982 - val_acc: 0.7447\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3809 - acc: 0.8825\n",
      "Epoch 00014: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.3809 - acc: 0.8825 - val_loss: 1.0702 - val_acc: 0.7156\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3684 - acc: 0.8828\n",
      "Epoch 00015: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.3685 - acc: 0.8828 - val_loss: 0.9854 - val_acc: 0.7358\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3360 - acc: 0.8934\n",
      "Epoch 00016: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.3360 - acc: 0.8934 - val_loss: 0.9503 - val_acc: 0.7424\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3172 - acc: 0.8995\n",
      "Epoch 00017: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.3172 - acc: 0.8995 - val_loss: 0.9165 - val_acc: 0.7503\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3016 - acc: 0.9036\n",
      "Epoch 00018: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.3015 - acc: 0.9035 - val_loss: 0.9456 - val_acc: 0.7566\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2806 - acc: 0.9101\n",
      "Epoch 00019: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.2806 - acc: 0.9101 - val_loss: 0.9386 - val_acc: 0.7543\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2708 - acc: 0.9141\n",
      "Epoch 00020: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.2709 - acc: 0.9140 - val_loss: 1.0196 - val_acc: 0.7314\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2501 - acc: 0.9215\n",
      "Epoch 00021: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.2501 - acc: 0.9215 - val_loss: 0.9614 - val_acc: 0.7563\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2541 - acc: 0.9194\n",
      "Epoch 00022: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.2542 - acc: 0.9193 - val_loss: 1.0346 - val_acc: 0.7363\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2320 - acc: 0.9269\n",
      "Epoch 00023: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.2320 - acc: 0.9269 - val_loss: 0.9663 - val_acc: 0.7491\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2153 - acc: 0.9327\n",
      "Epoch 00024: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.2153 - acc: 0.9327 - val_loss: 0.9703 - val_acc: 0.7591\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2070 - acc: 0.9337\n",
      "Epoch 00025: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.2070 - acc: 0.9337 - val_loss: 1.0780 - val_acc: 0.7484\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9369\n",
      "Epoch 00026: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.2023 - acc: 0.9369 - val_loss: 0.9607 - val_acc: 0.7619\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1948 - acc: 0.9382\n",
      "Epoch 00027: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1950 - acc: 0.9382 - val_loss: 1.0767 - val_acc: 0.7463\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1922 - acc: 0.9383\n",
      "Epoch 00028: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1923 - acc: 0.9383 - val_loss: 1.0245 - val_acc: 0.7573\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1833 - acc: 0.9422\n",
      "Epoch 00029: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1833 - acc: 0.9422 - val_loss: 1.0003 - val_acc: 0.7519\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9470\n",
      "Epoch 00030: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1702 - acc: 0.9470 - val_loss: 1.0301 - val_acc: 0.7517\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9464\n",
      "Epoch 00031: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1736 - acc: 0.9464 - val_loss: 1.0081 - val_acc: 0.7608\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9475\n",
      "Epoch 00032: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1664 - acc: 0.9475 - val_loss: 0.9933 - val_acc: 0.7666\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1567 - acc: 0.9514\n",
      "Epoch 00033: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1567 - acc: 0.9514 - val_loss: 1.0592 - val_acc: 0.7584\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9517\n",
      "Epoch 00034: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1532 - acc: 0.9517 - val_loss: 1.0439 - val_acc: 0.7608\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9547\n",
      "Epoch 00035: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1468 - acc: 0.9547 - val_loss: 1.1767 - val_acc: 0.7454\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9546\n",
      "Epoch 00036: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1435 - acc: 0.9546 - val_loss: 1.0427 - val_acc: 0.7675\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9557\n",
      "Epoch 00037: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1405 - acc: 0.9557 - val_loss: 1.0399 - val_acc: 0.7584\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9600\n",
      "Epoch 00038: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1324 - acc: 0.9600 - val_loss: 1.1387 - val_acc: 0.7531\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9571\n",
      "Epoch 00039: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1383 - acc: 0.9571 - val_loss: 1.0669 - val_acc: 0.7682\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9601\n",
      "Epoch 00040: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1299 - acc: 0.9601 - val_loss: 0.9775 - val_acc: 0.7799\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9603\n",
      "Epoch 00041: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1286 - acc: 0.9602 - val_loss: 0.9953 - val_acc: 0.7808\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9604\n",
      "Epoch 00042: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1279 - acc: 0.9604 - val_loss: 1.0242 - val_acc: 0.7741\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9601\n",
      "Epoch 00043: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1260 - acc: 0.9601 - val_loss: 1.1357 - val_acc: 0.7508\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1282 - acc: 0.9602\n",
      "Epoch 00044: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1282 - acc: 0.9602 - val_loss: 1.0905 - val_acc: 0.7640\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9661\n",
      "Epoch 00045: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1109 - acc: 0.9661 - val_loss: 1.1253 - val_acc: 0.7549\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1210 - acc: 0.9628\n",
      "Epoch 00046: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1210 - acc: 0.9628 - val_loss: 1.2165 - val_acc: 0.7454\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9656\n",
      "Epoch 00047: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1104 - acc: 0.9655 - val_loss: 1.1152 - val_acc: 0.7629\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9638\n",
      "Epoch 00048: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1154 - acc: 0.9637 - val_loss: 1.1147 - val_acc: 0.7738\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9630\n",
      "Epoch 00049: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1192 - acc: 0.9630 - val_loss: 1.1688 - val_acc: 0.7596\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9668\n",
      "Epoch 00050: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1063 - acc: 0.9668 - val_loss: 1.0806 - val_acc: 0.7789\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9678\n",
      "Epoch 00051: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1020 - acc: 0.9678 - val_loss: 1.1601 - val_acc: 0.7638\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9683\n",
      "Epoch 00052: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1023 - acc: 0.9682 - val_loss: 1.1102 - val_acc: 0.7631\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9671\n",
      "Epoch 00053: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1068 - acc: 0.9671 - val_loss: 1.0705 - val_acc: 0.7778\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9657\n",
      "Epoch 00054: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.1138 - acc: 0.9657 - val_loss: 1.1268 - val_acc: 0.7729\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9700\n",
      "Epoch 00055: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0993 - acc: 0.9700 - val_loss: 1.1303 - val_acc: 0.7673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9736\n",
      "Epoch 00056: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0891 - acc: 0.9736 - val_loss: 1.0939 - val_acc: 0.7764\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9727\n",
      "Epoch 00057: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0898 - acc: 0.9727 - val_loss: 1.1722 - val_acc: 0.7682\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0983 - acc: 0.9695\n",
      "Epoch 00058: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0983 - acc: 0.9695 - val_loss: 1.1316 - val_acc: 0.7701\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9724\n",
      "Epoch 00059: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0886 - acc: 0.9723 - val_loss: 1.1717 - val_acc: 0.7561\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9696\n",
      "Epoch 00060: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0973 - acc: 0.9696 - val_loss: 1.1010 - val_acc: 0.7699\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9730\n",
      "Epoch 00061: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0865 - acc: 0.9730 - val_loss: 1.1596 - val_acc: 0.7626\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9730\n",
      "Epoch 00062: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0875 - acc: 0.9730 - val_loss: 1.1548 - val_acc: 0.7687\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9738\n",
      "Epoch 00063: val_loss did not improve from 0.89820\n",
      "36805/36805 [==============================] - 156s 4ms/sample - loss: 0.0845 - acc: 0.9738 - val_loss: 1.0692 - val_acc: 0.7764\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.9801 - acc: 0.7254\n",
      "Loss: 0.9800655689194938 Accuracy: 0.72544134\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2257 - acc: 0.3634\n",
      "Epoch 00001: val_loss improved from inf to 1.58461, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_6_conv_checkpoint/001-1.5846.hdf5\n",
      "36805/36805 [==============================] - 179s 5ms/sample - loss: 2.2254 - acc: 0.3635 - val_loss: 1.5846 - val_acc: 0.4694\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5039 - acc: 0.5449\n",
      "Epoch 00002: val_loss improved from 1.58461 to 1.10763, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_6_conv_checkpoint/002-1.1076.hdf5\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 1.5040 - acc: 0.5448 - val_loss: 1.1076 - val_acc: 0.6590\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2898 - acc: 0.6108\n",
      "Epoch 00003: val_loss did not improve from 1.10763\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 1.2899 - acc: 0.6108 - val_loss: 1.1920 - val_acc: 0.6403\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1587 - acc: 0.6498\n",
      "Epoch 00004: val_loss improved from 1.10763 to 1.07664, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_6_conv_checkpoint/004-1.0766.hdf5\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 1.1588 - acc: 0.6497 - val_loss: 1.0766 - val_acc: 0.6811\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0556 - acc: 0.6818\n",
      "Epoch 00005: val_loss improved from 1.07664 to 0.92587, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_6_conv_checkpoint/005-0.9259.hdf5\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 1.0555 - acc: 0.6818 - val_loss: 0.9259 - val_acc: 0.7240\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9584 - acc: 0.7098\n",
      "Epoch 00006: val_loss did not improve from 0.92587\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.9585 - acc: 0.7098 - val_loss: 0.9758 - val_acc: 0.7063\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8878 - acc: 0.7286\n",
      "Epoch 00007: val_loss did not improve from 0.92587\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.8877 - acc: 0.7287 - val_loss: 1.0035 - val_acc: 0.7060\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8283 - acc: 0.7449\n",
      "Epoch 00008: val_loss improved from 0.92587 to 0.89397, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_6_conv_checkpoint/008-0.8940.hdf5\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.8284 - acc: 0.7449 - val_loss: 0.8940 - val_acc: 0.7498\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7769 - acc: 0.7642\n",
      "Epoch 00009: val_loss did not improve from 0.89397\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.7771 - acc: 0.7642 - val_loss: 1.0712 - val_acc: 0.6953\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7255 - acc: 0.7792\n",
      "Epoch 00010: val_loss improved from 0.89397 to 0.83137, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_6_conv_checkpoint/010-0.8314.hdf5\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.7255 - acc: 0.7792 - val_loss: 0.8314 - val_acc: 0.7591\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6852 - acc: 0.7902\n",
      "Epoch 00011: val_loss did not improve from 0.83137\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.6851 - acc: 0.7902 - val_loss: 0.9069 - val_acc: 0.7410\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6429 - acc: 0.8030\n",
      "Epoch 00012: val_loss did not improve from 0.83137\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.6429 - acc: 0.8030 - val_loss: 0.8640 - val_acc: 0.7531\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6225 - acc: 0.8080\n",
      "Epoch 00013: val_loss did not improve from 0.83137\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.6226 - acc: 0.8079 - val_loss: 0.9370 - val_acc: 0.7389\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5861 - acc: 0.8203\n",
      "Epoch 00014: val_loss improved from 0.83137 to 0.74614, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_6_conv_checkpoint/014-0.7461.hdf5\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.5861 - acc: 0.8203 - val_loss: 0.7461 - val_acc: 0.7922\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5470 - acc: 0.8306\n",
      "Epoch 00015: val_loss did not improve from 0.74614\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.5472 - acc: 0.8306 - val_loss: 0.9482 - val_acc: 0.7289\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5277 - acc: 0.8332\n",
      "Epoch 00016: val_loss did not improve from 0.74614\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.5277 - acc: 0.8332 - val_loss: 0.7863 - val_acc: 0.7745\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4974 - acc: 0.8457\n",
      "Epoch 00017: val_loss did not improve from 0.74614\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.4975 - acc: 0.8456 - val_loss: 0.8414 - val_acc: 0.7608\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4774 - acc: 0.8516\n",
      "Epoch 00018: val_loss did not improve from 0.74614\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.4774 - acc: 0.8516 - val_loss: 0.8947 - val_acc: 0.7414\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4595 - acc: 0.8579\n",
      "Epoch 00019: val_loss did not improve from 0.74614\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.4595 - acc: 0.8579 - val_loss: 0.9090 - val_acc: 0.7505\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4290 - acc: 0.8665\n",
      "Epoch 00020: val_loss did not improve from 0.74614\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.4292 - acc: 0.8665 - val_loss: 0.9427 - val_acc: 0.7431\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4247 - acc: 0.8672\n",
      "Epoch 00021: val_loss did not improve from 0.74614\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.4248 - acc: 0.8672 - val_loss: 0.9047 - val_acc: 0.7454\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4063 - acc: 0.8741\n",
      "Epoch 00022: val_loss improved from 0.74614 to 0.73750, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_6_conv_checkpoint/022-0.7375.hdf5\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.4064 - acc: 0.8741 - val_loss: 0.7375 - val_acc: 0.7827\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3851 - acc: 0.8809\n",
      "Epoch 00023: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.3851 - acc: 0.8809 - val_loss: 0.7603 - val_acc: 0.7803\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3632 - acc: 0.8851\n",
      "Epoch 00024: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.3632 - acc: 0.8851 - val_loss: 0.8961 - val_acc: 0.7622\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3534 - acc: 0.8881\n",
      "Epoch 00025: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.3534 - acc: 0.8881 - val_loss: 0.9220 - val_acc: 0.7536\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3388 - acc: 0.8935\n",
      "Epoch 00026: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.3388 - acc: 0.8935 - val_loss: 0.8369 - val_acc: 0.7745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3287 - acc: 0.8974\n",
      "Epoch 00027: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.3287 - acc: 0.8974 - val_loss: 0.9861 - val_acc: 0.7393\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3164 - acc: 0.8987\n",
      "Epoch 00028: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.3164 - acc: 0.8987 - val_loss: 0.8239 - val_acc: 0.7713\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3075 - acc: 0.9028\n",
      "Epoch 00029: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.3075 - acc: 0.9028 - val_loss: 0.8586 - val_acc: 0.7622\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2924 - acc: 0.9082\n",
      "Epoch 00030: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2924 - acc: 0.9082 - val_loss: 0.7696 - val_acc: 0.7932\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2807 - acc: 0.9102\n",
      "Epoch 00031: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2807 - acc: 0.9102 - val_loss: 0.7580 - val_acc: 0.7941\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2663 - acc: 0.9163\n",
      "Epoch 00032: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2664 - acc: 0.9162 - val_loss: 0.8990 - val_acc: 0.7601\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2718 - acc: 0.9142\n",
      "Epoch 00033: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.2718 - acc: 0.9142 - val_loss: 0.7758 - val_acc: 0.7925\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2510 - acc: 0.9201\n",
      "Epoch 00034: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.2510 - acc: 0.9201 - val_loss: 0.9089 - val_acc: 0.7678\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2398 - acc: 0.9241\n",
      "Epoch 00035: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.2398 - acc: 0.9241 - val_loss: 0.8051 - val_acc: 0.7852\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2399 - acc: 0.9243\n",
      "Epoch 00036: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2399 - acc: 0.9243 - val_loss: 0.9329 - val_acc: 0.7556\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2383 - acc: 0.9253\n",
      "Epoch 00037: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2383 - acc: 0.9253 - val_loss: 0.8896 - val_acc: 0.7789\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2345 - acc: 0.9267\n",
      "Epoch 00038: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2345 - acc: 0.9267 - val_loss: 0.8408 - val_acc: 0.7897\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9283\n",
      "Epoch 00039: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2263 - acc: 0.9283 - val_loss: 0.8133 - val_acc: 0.7883\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2149 - acc: 0.9323\n",
      "Epoch 00040: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2149 - acc: 0.9323 - val_loss: 0.9310 - val_acc: 0.7638\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2099 - acc: 0.9339\n",
      "Epoch 00041: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2100 - acc: 0.9338 - val_loss: 0.8335 - val_acc: 0.7794\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2008 - acc: 0.9372\n",
      "Epoch 00042: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.2009 - acc: 0.9372 - val_loss: 0.8988 - val_acc: 0.7780\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2031 - acc: 0.9367\n",
      "Epoch 00043: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.2031 - acc: 0.9367 - val_loss: 0.8888 - val_acc: 0.7624\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1886 - acc: 0.9415\n",
      "Epoch 00044: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1886 - acc: 0.9416 - val_loss: 0.9713 - val_acc: 0.7612\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1821 - acc: 0.9427\n",
      "Epoch 00045: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1821 - acc: 0.9427 - val_loss: 0.9217 - val_acc: 0.7708\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1823 - acc: 0.9424\n",
      "Epoch 00046: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1823 - acc: 0.9424 - val_loss: 0.8309 - val_acc: 0.7943\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1817 - acc: 0.9416\n",
      "Epoch 00047: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1817 - acc: 0.9416 - val_loss: 0.8642 - val_acc: 0.7883\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1718 - acc: 0.9456\n",
      "Epoch 00048: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1718 - acc: 0.9456 - val_loss: 0.8619 - val_acc: 0.7871\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1663 - acc: 0.9483\n",
      "Epoch 00049: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1663 - acc: 0.9483 - val_loss: 0.8404 - val_acc: 0.7932\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9453\n",
      "Epoch 00050: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1696 - acc: 0.9453 - val_loss: 0.9169 - val_acc: 0.7778\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1636 - acc: 0.9481\n",
      "Epoch 00051: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1636 - acc: 0.9481 - val_loss: 0.9628 - val_acc: 0.7780\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1589 - acc: 0.9490\n",
      "Epoch 00052: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1589 - acc: 0.9489 - val_loss: 0.9801 - val_acc: 0.7650\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1590 - acc: 0.9494\n",
      "Epoch 00053: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1590 - acc: 0.9494 - val_loss: 0.8889 - val_acc: 0.7855\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9506\n",
      "Epoch 00054: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1573 - acc: 0.9505 - val_loss: 0.9692 - val_acc: 0.7757\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9513\n",
      "Epoch 00055: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1548 - acc: 0.9513 - val_loss: 1.0787 - val_acc: 0.7449\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9533\n",
      "Epoch 00056: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1468 - acc: 0.9533 - val_loss: 0.8495 - val_acc: 0.7964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1365 - acc: 0.9568\n",
      "Epoch 00057: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1365 - acc: 0.9568 - val_loss: 0.9192 - val_acc: 0.7871\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9543\n",
      "Epoch 00058: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1443 - acc: 0.9543 - val_loss: 0.8835 - val_acc: 0.7971\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9521\n",
      "Epoch 00059: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1530 - acc: 0.9522 - val_loss: 0.9350 - val_acc: 0.7820\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9580\n",
      "Epoch 00060: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1345 - acc: 0.9579 - val_loss: 0.9414 - val_acc: 0.7892\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9561\n",
      "Epoch 00061: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1384 - acc: 0.9560 - val_loss: 1.2279 - val_acc: 0.7363\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9566\n",
      "Epoch 00062: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1392 - acc: 0.9566 - val_loss: 0.9408 - val_acc: 0.7764\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9603\n",
      "Epoch 00063: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1281 - acc: 0.9603 - val_loss: 1.0875 - val_acc: 0.7661\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9598\n",
      "Epoch 00064: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1273 - acc: 0.9598 - val_loss: 0.9804 - val_acc: 0.7671\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9594\n",
      "Epoch 00065: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1286 - acc: 0.9593 - val_loss: 0.9542 - val_acc: 0.7911\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9563\n",
      "Epoch 00066: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1390 - acc: 0.9563 - val_loss: 0.9836 - val_acc: 0.7773\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1186 - acc: 0.9631\n",
      "Epoch 00067: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1186 - acc: 0.9630 - val_loss: 0.9247 - val_acc: 0.7922\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9623\n",
      "Epoch 00068: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1211 - acc: 0.9623 - val_loss: 0.8660 - val_acc: 0.8006\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9634\n",
      "Epoch 00069: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1165 - acc: 0.9633 - val_loss: 0.9503 - val_acc: 0.7855\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1404 - acc: 0.9558\n",
      "Epoch 00070: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1409 - acc: 0.9558 - val_loss: 0.8491 - val_acc: 0.8043\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9655\n",
      "Epoch 00071: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1105 - acc: 0.9655 - val_loss: 0.8137 - val_acc: 0.8095\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1092 - acc: 0.9656\n",
      "Epoch 00072: val_loss did not improve from 0.73750\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1092 - acc: 0.9656 - val_loss: 1.1475 - val_acc: 0.7601\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.8075 - acc: 0.7568\n",
      "Loss: 0.8075062907373423 Accuracy: 0.75680166\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3304 - acc: 0.3326\n",
      "Epoch 00001: val_loss improved from inf to 1.63511, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_7_conv_checkpoint/001-1.6351.hdf5\n",
      "36805/36805 [==============================] - 188s 5ms/sample - loss: 2.3305 - acc: 0.3326 - val_loss: 1.6351 - val_acc: 0.4698\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5555 - acc: 0.5203\n",
      "Epoch 00002: val_loss improved from 1.63511 to 1.19226, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_7_conv_checkpoint/002-1.1923.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 1.5555 - acc: 0.5203 - val_loss: 1.1923 - val_acc: 0.6280\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2999 - acc: 0.5974\n",
      "Epoch 00003: val_loss did not improve from 1.19226\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 1.3000 - acc: 0.5974 - val_loss: 1.2566 - val_acc: 0.6352\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1592 - acc: 0.6441\n",
      "Epoch 00004: val_loss improved from 1.19226 to 0.90960, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_7_conv_checkpoint/004-0.9096.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 1.1592 - acc: 0.6441 - val_loss: 0.9096 - val_acc: 0.7307\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0440 - acc: 0.6826\n",
      "Epoch 00005: val_loss did not improve from 0.90960\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 1.0441 - acc: 0.6826 - val_loss: 1.1280 - val_acc: 0.6741\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9615 - acc: 0.7079\n",
      "Epoch 00006: val_loss did not improve from 0.90960\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.9614 - acc: 0.7078 - val_loss: 0.9172 - val_acc: 0.7319\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8856 - acc: 0.7302\n",
      "Epoch 00007: val_loss improved from 0.90960 to 0.86720, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_7_conv_checkpoint/007-0.8672.hdf5\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.8856 - acc: 0.7303 - val_loss: 0.8672 - val_acc: 0.7508\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8246 - acc: 0.7491\n",
      "Epoch 00008: val_loss improved from 0.86720 to 0.81298, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_7_conv_checkpoint/008-0.8130.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.8248 - acc: 0.7491 - val_loss: 0.8130 - val_acc: 0.7706\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7730 - acc: 0.7643\n",
      "Epoch 00009: val_loss improved from 0.81298 to 0.70853, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_7_conv_checkpoint/009-0.7085.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.7730 - acc: 0.7643 - val_loss: 0.7085 - val_acc: 0.8032\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7266 - acc: 0.7789\n",
      "Epoch 00010: val_loss did not improve from 0.70853\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.7267 - acc: 0.7789 - val_loss: 0.7792 - val_acc: 0.7654\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6866 - acc: 0.7928\n",
      "Epoch 00011: val_loss did not improve from 0.70853\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.6865 - acc: 0.7928 - val_loss: 0.8918 - val_acc: 0.7347\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6512 - acc: 0.8047\n",
      "Epoch 00012: val_loss did not improve from 0.70853\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.6512 - acc: 0.8047 - val_loss: 0.7187 - val_acc: 0.7864\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6164 - acc: 0.8152\n",
      "Epoch 00013: val_loss did not improve from 0.70853\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.6167 - acc: 0.8152 - val_loss: 0.8274 - val_acc: 0.7666\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5959 - acc: 0.8226\n",
      "Epoch 00014: val_loss did not improve from 0.70853\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.5960 - acc: 0.8226 - val_loss: 0.7095 - val_acc: 0.7971\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5673 - acc: 0.8281\n",
      "Epoch 00015: val_loss improved from 0.70853 to 0.70526, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_7_conv_checkpoint/015-0.7053.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.5673 - acc: 0.8281 - val_loss: 0.7053 - val_acc: 0.8020\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5374 - acc: 0.8391\n",
      "Epoch 00016: val_loss improved from 0.70526 to 0.64171, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_7_conv_checkpoint/016-0.6417.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.5373 - acc: 0.8391 - val_loss: 0.6417 - val_acc: 0.8255\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5146 - acc: 0.8450\n",
      "Epoch 00017: val_loss did not improve from 0.64171\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.5146 - acc: 0.8450 - val_loss: 0.6561 - val_acc: 0.8206\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4865 - acc: 0.8517\n",
      "Epoch 00018: val_loss did not improve from 0.64171\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.4865 - acc: 0.8517 - val_loss: 0.7026 - val_acc: 0.8097\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4675 - acc: 0.8593\n",
      "Epoch 00019: val_loss did not improve from 0.64171\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.4676 - acc: 0.8593 - val_loss: 0.7370 - val_acc: 0.8104\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4501 - acc: 0.8619\n",
      "Epoch 00020: val_loss did not improve from 0.64171\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.4502 - acc: 0.8618 - val_loss: 0.6516 - val_acc: 0.8300\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4316 - acc: 0.8694\n",
      "Epoch 00021: val_loss did not improve from 0.64171\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.4316 - acc: 0.8694 - val_loss: 0.7607 - val_acc: 0.7803\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4131 - acc: 0.8749\n",
      "Epoch 00022: val_loss improved from 0.64171 to 0.63239, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_7_conv_checkpoint/022-0.6324.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.4131 - acc: 0.8749 - val_loss: 0.6324 - val_acc: 0.8248\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4020 - acc: 0.8753\n",
      "Epoch 00023: val_loss did not improve from 0.63239\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.4021 - acc: 0.8752 - val_loss: 0.7534 - val_acc: 0.7978\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3792 - acc: 0.8843\n",
      "Epoch 00024: val_loss did not improve from 0.63239\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.3792 - acc: 0.8843 - val_loss: 0.6738 - val_acc: 0.8197\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3643 - acc: 0.8892\n",
      "Epoch 00025: val_loss did not improve from 0.63239\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.3646 - acc: 0.8891 - val_loss: 0.6655 - val_acc: 0.8255\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3559 - acc: 0.8907\n",
      "Epoch 00026: val_loss did not improve from 0.63239\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.3559 - acc: 0.8906 - val_loss: 0.6755 - val_acc: 0.8183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3324 - acc: 0.8986\n",
      "Epoch 00027: val_loss improved from 0.63239 to 0.59895, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_7_conv_checkpoint/027-0.5990.hdf5\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.3325 - acc: 0.8985 - val_loss: 0.5990 - val_acc: 0.8409\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3206 - acc: 0.9021\n",
      "Epoch 00028: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.3207 - acc: 0.9021 - val_loss: 0.6097 - val_acc: 0.8318\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2997 - acc: 0.9083\n",
      "Epoch 00029: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.2998 - acc: 0.9082 - val_loss: 0.5994 - val_acc: 0.8388\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3036 - acc: 0.9075\n",
      "Epoch 00030: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.3035 - acc: 0.9075 - val_loss: 0.7412 - val_acc: 0.8167\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2800 - acc: 0.9138\n",
      "Epoch 00031: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2801 - acc: 0.9138 - val_loss: 0.8218 - val_acc: 0.7906\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2731 - acc: 0.9147\n",
      "Epoch 00032: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2730 - acc: 0.9147 - val_loss: 0.7676 - val_acc: 0.8043\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2598 - acc: 0.9197\n",
      "Epoch 00033: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.2599 - acc: 0.9197 - val_loss: 0.6422 - val_acc: 0.8325\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2491 - acc: 0.9232\n",
      "Epoch 00034: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.2491 - acc: 0.9232 - val_loss: 0.6606 - val_acc: 0.8300\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2421 - acc: 0.9221\n",
      "Epoch 00035: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.2421 - acc: 0.9221 - val_loss: 0.6122 - val_acc: 0.8439\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2307 - acc: 0.9299\n",
      "Epoch 00036: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2306 - acc: 0.9299 - val_loss: 0.6144 - val_acc: 0.8435\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2137 - acc: 0.9324\n",
      "Epoch 00037: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2137 - acc: 0.9323 - val_loss: 0.6515 - val_acc: 0.8477\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9333\n",
      "Epoch 00038: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2129 - acc: 0.9332 - val_loss: 0.8158 - val_acc: 0.8067\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2208 - acc: 0.9332\n",
      "Epoch 00039: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2209 - acc: 0.9331 - val_loss: 0.8038 - val_acc: 0.8048\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1959 - acc: 0.9385\n",
      "Epoch 00040: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.1959 - acc: 0.9385 - val_loss: 0.7247 - val_acc: 0.8279\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9434\n",
      "Epoch 00041: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1818 - acc: 0.9434 - val_loss: 0.7864 - val_acc: 0.8116\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9465\n",
      "Epoch 00042: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1751 - acc: 0.9466 - val_loss: 0.6766 - val_acc: 0.8416\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9480\n",
      "Epoch 00043: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1689 - acc: 0.9480 - val_loss: 0.7630 - val_acc: 0.8167\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9483\n",
      "Epoch 00044: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1694 - acc: 0.9483 - val_loss: 0.7310 - val_acc: 0.8300\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9483\n",
      "Epoch 00045: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1672 - acc: 0.9483 - val_loss: 0.7527 - val_acc: 0.8253\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1600 - acc: 0.9499\n",
      "Epoch 00046: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1600 - acc: 0.9499 - val_loss: 0.6299 - val_acc: 0.8491\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9524\n",
      "Epoch 00047: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1508 - acc: 0.9524 - val_loss: 0.9012 - val_acc: 0.8006\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1453 - acc: 0.9541\n",
      "Epoch 00048: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1453 - acc: 0.9541 - val_loss: 0.8829 - val_acc: 0.7906\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9557\n",
      "Epoch 00049: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1444 - acc: 0.9557 - val_loss: 0.7614 - val_acc: 0.8283\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9537\n",
      "Epoch 00050: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1496 - acc: 0.9537 - val_loss: 0.7148 - val_acc: 0.8402\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9583\n",
      "Epoch 00051: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1322 - acc: 0.9583 - val_loss: 0.7823 - val_acc: 0.8218\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9596\n",
      "Epoch 00052: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1330 - acc: 0.9596 - val_loss: 0.7027 - val_acc: 0.8358\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9642\n",
      "Epoch 00053: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1183 - acc: 0.9642 - val_loss: 0.7912 - val_acc: 0.8258\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9620\n",
      "Epoch 00054: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1216 - acc: 0.9620 - val_loss: 0.7476 - val_acc: 0.8341\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9601\n",
      "Epoch 00055: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1296 - acc: 0.9601 - val_loss: 0.7396 - val_acc: 0.8344\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9661\n",
      "Epoch 00056: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1093 - acc: 0.9661 - val_loss: 0.7172 - val_acc: 0.8458\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9668\n",
      "Epoch 00057: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1101 - acc: 0.9668 - val_loss: 0.7723 - val_acc: 0.8346\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9663\n",
      "Epoch 00058: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 160s 4ms/sample - loss: 0.1132 - acc: 0.9663 - val_loss: 0.7085 - val_acc: 0.8404\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9660\n",
      "Epoch 00059: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1069 - acc: 0.9660 - val_loss: 1.0762 - val_acc: 0.7859\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9669\n",
      "Epoch 00060: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1056 - acc: 0.9669 - val_loss: 0.9757 - val_acc: 0.7999\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9690\n",
      "Epoch 00061: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1038 - acc: 0.9689 - val_loss: 0.7640 - val_acc: 0.8369\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9655\n",
      "Epoch 00062: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1157 - acc: 0.9654 - val_loss: 0.7627 - val_acc: 0.8379\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9698\n",
      "Epoch 00063: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0976 - acc: 0.9698 - val_loss: 0.9134 - val_acc: 0.8160\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9667\n",
      "Epoch 00064: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1071 - acc: 0.9667 - val_loss: 0.8699 - val_acc: 0.8174\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9715\n",
      "Epoch 00065: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0904 - acc: 0.9715 - val_loss: 0.7352 - val_acc: 0.8416\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9731\n",
      "Epoch 00066: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0882 - acc: 0.9731 - val_loss: 0.8110 - val_acc: 0.8416\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0862 - acc: 0.9737\n",
      "Epoch 00067: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0862 - acc: 0.9737 - val_loss: 0.8617 - val_acc: 0.8297\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9736\n",
      "Epoch 00068: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0845 - acc: 0.9736 - val_loss: 0.8369 - val_acc: 0.8295\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9681\n",
      "Epoch 00069: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.1007 - acc: 0.9681 - val_loss: 0.7685 - val_acc: 0.8346\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9771\n",
      "Epoch 00070: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0748 - acc: 0.9771 - val_loss: 0.8353 - val_acc: 0.8332\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9750\n",
      "Epoch 00071: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0814 - acc: 0.9749 - val_loss: 0.8355 - val_acc: 0.8358\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9705\n",
      "Epoch 00072: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0939 - acc: 0.9705 - val_loss: 0.8123 - val_acc: 0.8337\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9751\n",
      "Epoch 00073: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0784 - acc: 0.9751 - val_loss: 0.8101 - val_acc: 0.8393\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9743\n",
      "Epoch 00074: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0807 - acc: 0.9743 - val_loss: 0.8494 - val_acc: 0.8253\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9733\n",
      "Epoch 00075: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0849 - acc: 0.9733 - val_loss: 0.7754 - val_acc: 0.8402\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9759\n",
      "Epoch 00076: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0785 - acc: 0.9759 - val_loss: 0.9592 - val_acc: 0.8143\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9787\n",
      "Epoch 00077: val_loss did not improve from 0.59895\n",
      "36805/36805 [==============================] - 159s 4ms/sample - loss: 0.0710 - acc: 0.9787 - val_loss: 0.9285 - val_acc: 0.8218\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.6624 - acc: 0.8098\n",
      "Loss: 0.6623675947124961 Accuracy: 0.80976117\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2558 - acc: 0.3349\n",
      "Epoch 00001: val_loss improved from inf to 1.50435, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/001-1.5044.hdf5\n",
      "36805/36805 [==============================] - 206s 6ms/sample - loss: 2.2558 - acc: 0.3349 - val_loss: 1.5044 - val_acc: 0.5495\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4426 - acc: 0.5476\n",
      "Epoch 00002: val_loss improved from 1.50435 to 0.93276, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/002-0.9328.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 1.4427 - acc: 0.5476 - val_loss: 0.9328 - val_acc: 0.7144\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1458 - acc: 0.6432\n",
      "Epoch 00003: val_loss improved from 0.93276 to 0.82110, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/003-0.8211.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 1.1459 - acc: 0.6432 - val_loss: 0.8211 - val_acc: 0.7459\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9649 - acc: 0.6994\n",
      "Epoch 00004: val_loss improved from 0.82110 to 0.81250, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/004-0.8125.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.9649 - acc: 0.6994 - val_loss: 0.8125 - val_acc: 0.7452\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8307 - acc: 0.7437\n",
      "Epoch 00005: val_loss improved from 0.81250 to 0.62686, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/005-0.6269.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.8308 - acc: 0.7437 - val_loss: 0.6269 - val_acc: 0.8162\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7222 - acc: 0.7796\n",
      "Epoch 00006: val_loss improved from 0.62686 to 0.50835, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/006-0.5083.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.7224 - acc: 0.7796 - val_loss: 0.5083 - val_acc: 0.8509\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6280 - acc: 0.8111\n",
      "Epoch 00007: val_loss did not improve from 0.50835\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.6279 - acc: 0.8111 - val_loss: 0.5269 - val_acc: 0.8449\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5613 - acc: 0.8275\n",
      "Epoch 00008: val_loss improved from 0.50835 to 0.43532, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/008-0.4353.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.5613 - acc: 0.8275 - val_loss: 0.4353 - val_acc: 0.8689\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4949 - acc: 0.8510\n",
      "Epoch 00009: val_loss improved from 0.43532 to 0.39393, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/009-0.3939.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.4948 - acc: 0.8510 - val_loss: 0.3939 - val_acc: 0.8896\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4533 - acc: 0.8624\n",
      "Epoch 00010: val_loss improved from 0.39393 to 0.38198, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/010-0.3820.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.4534 - acc: 0.8623 - val_loss: 0.3820 - val_acc: 0.8928\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4145 - acc: 0.8752\n",
      "Epoch 00011: val_loss improved from 0.38198 to 0.38035, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/011-0.3803.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.4146 - acc: 0.8752 - val_loss: 0.3803 - val_acc: 0.8954\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3861 - acc: 0.8825\n",
      "Epoch 00012: val_loss did not improve from 0.38035\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.3861 - acc: 0.8825 - val_loss: 0.3942 - val_acc: 0.8887\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3535 - acc: 0.8931\n",
      "Epoch 00013: val_loss improved from 0.38035 to 0.35889, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/013-0.3589.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.3538 - acc: 0.8931 - val_loss: 0.3589 - val_acc: 0.8980\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3258 - acc: 0.9010\n",
      "Epoch 00014: val_loss improved from 0.35889 to 0.28680, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/014-0.2868.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.3259 - acc: 0.9010 - val_loss: 0.2868 - val_acc: 0.9182\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3064 - acc: 0.9051\n",
      "Epoch 00015: val_loss did not improve from 0.28680\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.3064 - acc: 0.9051 - val_loss: 0.2987 - val_acc: 0.9159\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2872 - acc: 0.9132\n",
      "Epoch 00016: val_loss improved from 0.28680 to 0.26640, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/016-0.2664.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.2872 - acc: 0.9132 - val_loss: 0.2664 - val_acc: 0.9250\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2672 - acc: 0.9197\n",
      "Epoch 00017: val_loss did not improve from 0.26640\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.2672 - acc: 0.9197 - val_loss: 0.2984 - val_acc: 0.9171\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2502 - acc: 0.9244\n",
      "Epoch 00018: val_loss did not improve from 0.26640\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.2502 - acc: 0.9244 - val_loss: 0.3303 - val_acc: 0.9131\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2363 - acc: 0.9283\n",
      "Epoch 00019: val_loss did not improve from 0.26640\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2365 - acc: 0.9283 - val_loss: 0.3060 - val_acc: 0.9122\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2442 - acc: 0.9251\n",
      "Epoch 00020: val_loss did not improve from 0.26640\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.2442 - acc: 0.9251 - val_loss: 0.2931 - val_acc: 0.9178\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2071 - acc: 0.9363\n",
      "Epoch 00021: val_loss did not improve from 0.26640\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.2071 - acc: 0.9363 - val_loss: 0.2764 - val_acc: 0.9215\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1983 - acc: 0.9389\n",
      "Epoch 00022: val_loss did not improve from 0.26640\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.1984 - acc: 0.9389 - val_loss: 0.2850 - val_acc: 0.9180\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1876 - acc: 0.9433\n",
      "Epoch 00023: val_loss did not improve from 0.26640\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1876 - acc: 0.9433 - val_loss: 0.2887 - val_acc: 0.9199\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1736 - acc: 0.9464\n",
      "Epoch 00024: val_loss did not improve from 0.26640\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.1736 - acc: 0.9464 - val_loss: 0.3136 - val_acc: 0.9187\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1682 - acc: 0.9485\n",
      "Epoch 00025: val_loss did not improve from 0.26640\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.1683 - acc: 0.9485 - val_loss: 0.2756 - val_acc: 0.9215\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9495\n",
      "Epoch 00026: val_loss improved from 0.26640 to 0.26416, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/026-0.2642.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.1619 - acc: 0.9495 - val_loss: 0.2642 - val_acc: 0.9290\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9544\n",
      "Epoch 00027: val_loss did not improve from 0.26416\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.1492 - acc: 0.9544 - val_loss: 0.2801 - val_acc: 0.9208\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9559\n",
      "Epoch 00028: val_loss did not improve from 0.26416\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.1415 - acc: 0.9559 - val_loss: 0.2882 - val_acc: 0.9250\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9582\n",
      "Epoch 00029: val_loss improved from 0.26416 to 0.25418, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_8_conv_checkpoint/029-0.2542.hdf5\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.1336 - acc: 0.9581 - val_loss: 0.2542 - val_acc: 0.9341\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9601\n",
      "Epoch 00030: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1274 - acc: 0.9601 - val_loss: 0.2902 - val_acc: 0.9245\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9638\n",
      "Epoch 00031: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.1190 - acc: 0.9638 - val_loss: 0.2979 - val_acc: 0.9187\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9660\n",
      "Epoch 00032: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.1105 - acc: 0.9660 - val_loss: 0.3151 - val_acc: 0.9231\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9655\n",
      "Epoch 00033: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.1093 - acc: 0.9655 - val_loss: 0.3272 - val_acc: 0.9145\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9697\n",
      "Epoch 00034: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.1020 - acc: 0.9697 - val_loss: 0.2749 - val_acc: 0.9297\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9691\n",
      "Epoch 00035: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0993 - acc: 0.9691 - val_loss: 0.3358 - val_acc: 0.9108\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9695\n",
      "Epoch 00036: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0990 - acc: 0.9694 - val_loss: 0.3436 - val_acc: 0.9173\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9747\n",
      "Epoch 00037: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0830 - acc: 0.9747 - val_loss: 0.3318 - val_acc: 0.9173\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9733\n",
      "Epoch 00038: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0878 - acc: 0.9733 - val_loss: 0.3716 - val_acc: 0.9138\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9741\n",
      "Epoch 00039: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0835 - acc: 0.9741 - val_loss: 0.2837 - val_acc: 0.9255\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9750\n",
      "Epoch 00040: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0780 - acc: 0.9750 - val_loss: 0.3544 - val_acc: 0.9159\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9770\n",
      "Epoch 00041: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0737 - acc: 0.9770 - val_loss: 0.3088 - val_acc: 0.9271\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9783\n",
      "Epoch 00042: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0693 - acc: 0.9783 - val_loss: 0.3444 - val_acc: 0.9161\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9773\n",
      "Epoch 00043: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0722 - acc: 0.9773 - val_loss: 0.4011 - val_acc: 0.9012\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9772\n",
      "Epoch 00044: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0718 - acc: 0.9772 - val_loss: 0.3216 - val_acc: 0.9238\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9802\n",
      "Epoch 00045: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0632 - acc: 0.9802 - val_loss: 0.3432 - val_acc: 0.9227\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9806\n",
      "Epoch 00046: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0607 - acc: 0.9806 - val_loss: 0.3251 - val_acc: 0.9194\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9808\n",
      "Epoch 00047: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0594 - acc: 0.9808 - val_loss: 0.3345 - val_acc: 0.9208\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9800\n",
      "Epoch 00048: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0658 - acc: 0.9800 - val_loss: 0.3428 - val_acc: 0.9194\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9842\n",
      "Epoch 00049: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0515 - acc: 0.9842 - val_loss: 0.3374 - val_acc: 0.9206\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9847\n",
      "Epoch 00050: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0523 - acc: 0.9847 - val_loss: 0.4411 - val_acc: 0.9005\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9801\n",
      "Epoch 00051: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0647 - acc: 0.9801 - val_loss: 0.3285 - val_acc: 0.9243\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9817\n",
      "Epoch 00052: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0575 - acc: 0.9817 - val_loss: 0.3601 - val_acc: 0.9185\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9883\n",
      "Epoch 00053: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0390 - acc: 0.9883 - val_loss: 0.4170 - val_acc: 0.9117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9795\n",
      "Epoch 00054: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0661 - acc: 0.9795 - val_loss: 0.3265 - val_acc: 0.9271\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9849\n",
      "Epoch 00055: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0500 - acc: 0.9849 - val_loss: 0.3324 - val_acc: 0.9236\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9868\n",
      "Epoch 00056: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0424 - acc: 0.9868 - val_loss: 0.4343 - val_acc: 0.9133\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9827\n",
      "Epoch 00057: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0590 - acc: 0.9827 - val_loss: 0.3551 - val_acc: 0.9189\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9863\n",
      "Epoch 00058: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0445 - acc: 0.9863 - val_loss: 0.3798 - val_acc: 0.9159\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9881\n",
      "Epoch 00059: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0376 - acc: 0.9881 - val_loss: 0.3588 - val_acc: 0.9182\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9864\n",
      "Epoch 00060: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0440 - acc: 0.9864 - val_loss: 0.3458 - val_acc: 0.9248\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9879\n",
      "Epoch 00061: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0401 - acc: 0.9879 - val_loss: 0.3775 - val_acc: 0.9187\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9870\n",
      "Epoch 00062: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0425 - acc: 0.9870 - val_loss: 0.3794 - val_acc: 0.9187\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9881\n",
      "Epoch 00063: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0383 - acc: 0.9881 - val_loss: 0.3532 - val_acc: 0.9234\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9874\n",
      "Epoch 00064: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0411 - acc: 0.9874 - val_loss: 0.4170 - val_acc: 0.9101\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9879\n",
      "Epoch 00065: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0383 - acc: 0.9878 - val_loss: 0.5521 - val_acc: 0.8973\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9825\n",
      "Epoch 00066: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0575 - acc: 0.9825 - val_loss: 0.3596 - val_acc: 0.9194\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9868\n",
      "Epoch 00067: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0419 - acc: 0.9868 - val_loss: 0.3705 - val_acc: 0.9173\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9858\n",
      "Epoch 00068: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0448 - acc: 0.9858 - val_loss: 0.3925 - val_acc: 0.9178\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9897\n",
      "Epoch 00069: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0339 - acc: 0.9897 - val_loss: 0.3738 - val_acc: 0.9208\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9909\n",
      "Epoch 00070: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0307 - acc: 0.9909 - val_loss: 0.4192 - val_acc: 0.9136\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9887\n",
      "Epoch 00071: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0365 - acc: 0.9886 - val_loss: 0.3951 - val_acc: 0.9199\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9864\n",
      "Epoch 00072: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0447 - acc: 0.9864 - val_loss: 0.3591 - val_acc: 0.9241\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9906\n",
      "Epoch 00073: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0302 - acc: 0.9906 - val_loss: 0.4217 - val_acc: 0.9147\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9891\n",
      "Epoch 00074: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0352 - acc: 0.9891 - val_loss: 0.3425 - val_acc: 0.9248\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9910\n",
      "Epoch 00075: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0279 - acc: 0.9910 - val_loss: 0.3596 - val_acc: 0.9217\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9920\n",
      "Epoch 00076: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0253 - acc: 0.9920 - val_loss: 0.3872 - val_acc: 0.9215\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9892\n",
      "Epoch 00077: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0340 - acc: 0.9892 - val_loss: 0.4108 - val_acc: 0.9143\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9905\n",
      "Epoch 00078: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 0.0312 - acc: 0.9905 - val_loss: 0.4459 - val_acc: 0.9087\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9877\n",
      "Epoch 00079: val_loss did not improve from 0.25418\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0385 - acc: 0.9877 - val_loss: 0.4163 - val_acc: 0.9194\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd8VfX9+PHX547ckb0Im4S9N4iiIHXUUamjCFbrau1Xq7bW1krHT/l+q61VW1vUatVq3aOgRauCoiC4UEC2yB4JCWTPmzs/vz8+uRnkJoSQSyD3/Xw8ziPJmZ9zcu/nfT7jfI7SWiOEEEIAWDo7AUIIIU4cEhSEEELUk6AghBCingQFIYQQ9SQoCCGEqCdBQQghRD0JCkIIIepJUBBCCFFPgoIQQoh6ts5OwNHKyMjQ2dnZnZ0MIYQ4qaxZs6ZIa515pPVOuqCQnZ3N6tWrOzsZQghxUlFK7W3LelJ9JIQQop4EBSGEEPUkKAghhKh30rUpROL3+8nNzaW2trazk3LScjqd9O7dG7vd3tlJEUJ0oi4RFHJzc0lMTCQ7OxulVGcn56Sjtaa4uJjc3FxycnI6OzlCiE7UJaqPamtrSU9Pl4DQTkop0tPTpaQlhOgaQQGQgHCM5PoJIaALBYUjCQY9eL15hEL+zk6KEEKcsGImKIRCtfh8+Wjd8UGhrKyMv//97+3a9oILLqCsrKzN68+bN48HH3ywXccSQogjiZmgoJQVAK2DHb7v1oJCIBBoddt33nmHlJSUDk+TEEK0R8wFBQh1+L7nzp3Lzp07GTt2LHfccQfLly/njDPOYObMmQwfPhyAiy++mAkTJjBixAieeOKJ+m2zs7MpKipiz549DBs2jBtuuIERI0Zw7rnn4vF4Wj3uunXrmDJlCqNHj+aSSy6htLQUgPnz5zN8+HBGjx7NnDlzAPjoo48YO3YsY8eOZdy4cVRWVnb4dRBCnPy6RJfUxrZvv42qqnURloQIBquxWFwodXSnnZAwlkGD/tri8vvuu49Nmzaxbp057vLly1m7di2bNm2q7+L59NNPk5aWhsfjYdKkSVx22WWkp6cflvbtvPzyyzz55JNcfvnlLFy4kKuuuqrF41599dU8/PDDTJ8+nbvuuov//d//5a9//Sv33Xcfu3fvxuFw1FdNPfjggzz66KNMnTqVqqoqnE7nUV0DIURsiJmSAoR71+jjcrTJkyc36fM/f/58xowZw5QpU9i/fz/bt29vtk1OTg5jx44FYMKECezZs6fF/ZeXl1NWVsb06dMBuOaaa1ixYgUAo0eP5sorr+SFF17AZjMBcOrUqdx+++3Mnz+fsrKy+vlCCNFYl8sZWrqj1zpIVdVXOBy9iYvrHvV0xMfH1/++fPlyli5dymeffYbb7ebMM8+M+EyAw+Go/91qtR6x+qglb7/9NitWrOCtt97i3nvvZePGjcydO5cLL7yQd955h6lTp7JkyRKGDh3arv0LIbquGCopmFONRkNzYmJiq3X05eXlpKam4na72bp1K59//vkxHzM5OZnU1FRWrlwJwPPPP8/06dMJhULs37+fGTNm8Kc//Yny8nKqqqrYuXMno0aN4s4772TSpEls3br1mNMghOh6ulxJoSXm4SwrWnd8Q3N6ejpTp05l5MiRnH/++Vx44YVNlp933nk8/vjjDBs2jCFDhjBlypQOOe6zzz7LjTfeSE1NDf379+eZZ54hGAxy1VVXUV5ejtaan/70p6SkpPD//t//Y9myZVgsFkaMGMH555/fIWkQQnQtSuvjU8feUSZOnKgPf8nO119/zbBhw464bVXVBqzWJFyu7Cil7uTW1usohDj5KKXWaK0nHmm9GKo+AqUsQMdXHwkhRFcRU0HBVB9JUBBCiJbEVFBQSoKCEEK0JuaCQjSeaBZCiK4ipoKCVB8JIUTrYiooKGWRoCCEEK2IsaBgBYKcCN1wExISjmq+EEIcDzEVFCB6I6UKIURXEFNBIVrvVJg7dy6PPvpo/d/hF+FUVVVx1llnMX78eEaNGsWiRYvavE+tNXfccQcjR45k1KhRvPrqqwDk5+czbdo0xo4dy8iRI1m5ciXBYJBrr722ft2HHnqoQ89PCBE7ut4wF7fdBusiDZ0NNu3HEqpFWeJBHUU8HDsW/try0NmzZ8/mtttu4+abbwbgtddeY8mSJTidTt544w2SkpIoKipiypQpzJw5s03vQ3799ddZt24d69evp6ioiEmTJjFt2jReeuklvv3tb/Pb3/6WYDBITU0N69atIy8vj02bNgEc1ZvchBCisaiVFJRSfZRSy5RSW5RSm5VSP4uwjlJKzVdK7VBKbVBKjY9WegBUlIbPHjduHIcOHeLAgQOsX7+e1NRU+vTpg9aa3/zmN4wePZqzzz6bvLw8Dh482KZ9fvzxx1xxxRVYrVaysrKYPn06X375JZMmTeKZZ55h3rx5bNy4kcTERPr378+uXbu49dZbWbx4MUlJSR16fkKI2BHNkkIA+IXWeq1SKhFYo5R6X2u9pdE65wOD6qZTgMfqfrZfK3f0wUAlHs83uFyDsdk6NuOcNWsWCxYsoKCggNmzZwPw4osvUlhYyJo1a7Db7WRnZ0ccMvtoTJs2jRUrVvD2229z7bXXcvvtt3P11Vezfv16lixZwuOPP85rr73G008/3RGnJYSIMVErKWit87XWa+t+rwS+Bnodttp3gee08TmQopTqEa00RfM9zbNnz+aVV15hwYIFzJo1CzBDZnfr1g273c6yZcvYu3dvm/d3xhln8OqrrxIMBiksLGTFihVMnjyZvXv3kpWVxQ033MCPfvQj1q5dS1FREaFQiMsuu4x77rmHtWvXdvj5CSFiw3FpU1BKZQPjgFWHLeoF7G/0d27dvPzopCPc+6jjg8KIESOorKykV69e9Ohh4tqVV17JRRddxKhRo5g4ceJRvdTmkksu4bPPPmPMmDEopbj//vvp3r07zz77LA888AB2u52EhASee+458vLyuO666wiFTK+qP/7xjx1+fkKI2BD1obOVUgnAR8C9WuvXD1v2X+A+rfXHdX9/ANyptV592Ho/Bn4M0Ldv3wmH33G3dcjnUChAdfU6HI4+xMVlHcNZdU0ydLYQXdcJMXS2UsoOLARePDwg1MkD+jT6u3fdvCa01k9orSdqrSdmZmYeQ3rCb1+T5xSEECKSaPY+UsA/ga+11n9pYbU3gavreiFNAcq11lGpOjJpsgBKhroQQogWRLNNYSrwA2CjUir84MBvgL4AWuvHgXeAC4AdQA1wXRTTAzQMdSGEEKK5qAWFunaCVp/S0qZB4+ZopSEyGSlVCCFaElPDXIC8aEcIIVoTk0FBBsQTQojIYi4oQMe/U6GsrIy///3v7dr2ggsukLGKhBAnjJgLCtGoPmotKAQCgVa3feedd0hJSenQ9AghRHvFZFDo6N5Hc+fOZefOnYwdO5Y77riD5cuXc8YZZzBz5kyGDx8OwMUXX8yECRMYMWIETzzxRP222dnZFBUVsWfPHoYNG8YNN9zAiBEjOPfcc/F4PM2O9dZbb3HKKacwbtw4zj777PoB9qqqqrjuuusYNWoUo0ePZuHChQAsXryY8ePHM2bMGM4666wOPW8hRNfT5YbObmXkbABCoe5onYbV2vI6hzvCyNncd999bNq0iXV1B16+fDlr165l06ZN5OTkAPD000+TlpaGx+Nh0qRJXHbZZaSnpzfZz/bt23n55Zd58sknufzyy1m4cCFXXXVVk3VOP/10Pv/8c5RSPPXUU9x///38+c9/5ve//z3Jycls3LgRgNLSUgoLC7nhhhtYsWIFOTk5lJSUtP2khRAxqcsFhbbTHKHH7DGZPHlyfUAAmD9/Pm+88QYA+/fvZ/v27c2CQk5ODmPHjgVgwoQJ7Nmzp9l+c3NzmT17Nvn5+fh8vvpjLF26lFdeeaV+vdTUVN566y2mTZtWv05aWlqHnqMQouvpckGhtTt6AJ+vDK93P/HxY7FYonf68fHx9b8vX76cpUuX8tlnn+F2uznzzDMjDqHtcDjqf7darRGrj2699VZuv/12Zs6cyfLly5k3b15U0i+EiE0x2qYAHdmukJiYSGVlZYvLy8vLSU1Nxe12s3XrVj7//PN2H6u8vJxevcwI5M8++2z9/HPOOafJK0FLS0uZMmUKK1asYPfu3QBSfSSEOKKYCwrQ8e9USE9PZ+rUqYwcOZI77rij2fLzzjuPQCDAsGHDmDt3LlOmTGn3sebNm8esWbOYMGECGRkZ9fN/97vfUVpaysiRIxkzZgzLli0jMzOTJ554gksvvZQxY8bUv/xHCCFaEvWhszvaxIkT9erVTUbWPqohnwOBCjyebbhcQ7DZEqORxJOWDJ0tRNd1QgydfSKK5ot2hBDiZBdzQSF8yjL+kRBCNBdzQaHhPc0y/pEQQhwuhoOClBSEEOJwMRcUGk5ZgoIQQhwu5oKCeUuovFNBCCEiibmgAOGRUju3TSEhIaFTjy+EEJHEaFCwINVHQgjRXEwGhY6uPpo7d26TISbmzZvHgw8+SFVVFWeddRbjx49n1KhRLFq06Ij7ammI7UhDYLc0XLYQQrRXlxsQ77bFt7GuoJWxs4FQyIPWGqvV3aZ9ju0+lr+e1/JIe7Nnz+a2227j5ptvBuC1115jyZIlOJ1O3njjDZKSkigqKmLKlCnMnDmzrl0jskhDbIdCoYhDYEcaLlsIIY5FlwsKbddxw3uMGzeOQ4cOceDAAQoLC0lNTaVPnz74/X5+85vfsGLFCiwWC3l5eRw8eJDu3bu3uK9IQ2wXFhZGHAI70nDZQghxLLpcUGjtjj7M49lDMFhBQsLoDjvurFmzWLBgAQUFBfUDz7344osUFhayZs0a7HY72dnZEYfMDmvrENtCCBEtMdmmEI33NM+ePZtXXnmFBQsWMGvWLMAMc92tWzfsdjvLli1j7969re6jpSG2WxoCO9Jw2UIIcSxiNCiY3kcdOULsiBEjqKyspFevXvTo0QOAK6+8ktWrVzNq1Ciee+45hg4d2uo+Whpiu6UhsCMNly2EEMci5obOBvB6C/D5cklIGNdo1FQhQ2cL0XXJ0NmtkPGPhBAiMgkKQggh6nWZoHA01WDyop3mTrZqRCFEdHSJoOB0OikuLj6KjC38oh15pwKYgFBcXIzT6ezspAghOlmXeE6hd+/e5ObmUlhY2Kb1QyEfPl8Rdrtq81PNXZ3T6aR3796dnQwhRCfrEkHBbrfXP+3bFh7PblatGsuQIc/Qo8e10UuYEEKcZLpE9dHRstmSAAgGKzo5JUIIcWKJyaBgtSYCEAhIUBBCiMZiMihYLHFYLE4pKQghxGFiMigAWK1JUlIQQojDRC0oKKWeVkodUkptamH5mUqpcqXUurrprmilJRKbLYlgsPJ4HlIIIU540ex99C/gEeC5VtZZqbX+ThTT0CKrNUmqj4QQ4jBRKylorVcAJdHa/1FbtAgyM2H7dsA0Nkv1kRBCNNXZbQqnKqXWK6XeVUqNaGklpdSPlVKrlVKr2/qAWjNxcVBUZCbC1UcSFIQQorHODAprgX5a6zHAw8B/WlpRa/2E1nqi1npiZmZm+46WkWF+FhcD0tAshBCRdFpQ0FpXaK2r6n5/B7ArpTKidsD0dPNTSgpCCNGiTgsKSqnuSilV9/vkurQUR+2A4ZJCXVCQkoIQQjQXtd5HSqmXgTOBDKVULnA3YAfQWj8OfA+4SSkVADzAHB3N8ZsTE8Fur68+stmS0NpHKOTFYnFE7bBCCHEyiVpQ0FpfcYTlj2C6rB4fSpnSQn31URoAPl8hTqeMDiqEEND5vY+Or/T0+qDgdg8CwOPZ3pkpEkKIE0psBYVGJQWXazAAHs+2zkyREEKcUGIvKNS1KTgcvbBYXNTUSFAQQoiw2AoKjaqPlLLgcg2SkoIQQjQSW0EhXFIImXczu92DpaQghBCNxF5QCIWgvBww7Qq1tbsIhfydnDAhhDgxxF5QgEY9kAajdYDa2j2dlyYhhDiBxFZQOGyoC+mBJIQQTcVWUDhsUDy32wQFaVcQQggjNoNCXUnBbk/HZkuTkoIQQtSJ6aAA0gNJCCEai62gkJBgBsVrFBRcrsFSUhBCiDqxFRTCg+IVN4zQ7XYPxuvNJRis7sSECSHEiSG2ggI0Gf8IGvdA2tFZKRJCiBNG7AWFRkNdgPRAEkKIxmIvKBxWfeRyDQTkWQUhhIBYDQqNSgpWazxxcb2kpCCEEMRqUGg0KB6YKiQpKQghRCwGhfR0ExDKyupnuVzyrIIQQkAbg4JS6mdKqSRl/FMptVYpdW60ExcVhw11AaakEAiU4PcXt7CREELEhraWFK7XWlcA5wKpwA+A+6KWqmiK8FRzuFuqlBaEELGurUFB1f28AHhea7250byTSwtDXYD0QBJCiLYGhTVKqfcwQWGJUioRCB1hmxNTePjsRtVHTmcOYJWSghAi5tnauN4PgbHALq11jVIqDbguesmKogglBYvFjsvVX0oKQoiY19aSwqnAN1rrMqXUVcDvgPLoJSuKEhIgLq5JUADpgSSEEND2oPAYUKOUGgP8AtgJPBe1VEWTUs2GugBwu4fg8WyT9zULIWJaW4NCQGutge8Cj2itHwUSo5esKDtsqAuApKRTCIVqqar6qpMSJYQQna+tQaFSKfVrTFfUt5VSFsAevWRF2WFDXQAkJ08DoKzso85IkRBCnBDaGhRmA17M8woFQG/ggailKtoiBAWHozsu12DKy1d0UqKEEKLztSko1AWCF4FkpdR3gFqt9cnZpgCmTaG4+dPLKSnTKCtbidbBTkiUEEJ0vrYOc3E58AUwC7gcWKWU+l40ExZVEQbFA1OFFAyWU129qZMSJoQQnautzyn8FpiktT4EoJTKBJYCC6KVsKjKyGgYFC8trX52Ssp0wLQrJCSM6azUCSFEp2lrm4IlHBDqFB/FtieeCA+wATidfXE4+lFWJu0KQojY1NaSwmKl1BLg5bq/ZwPvRCdJx0GEoS7CUlKmUVKyGK01Sp2cwzsJIUR7tbWh+Q7gCWB03fSE1vrOaCYsqlooKYBpV/D7C6mp+eY4J0oIITpfW0sKaK0XAgvbur5S6mngO8AhrfXICMsV8DfMIHs1wLVa67Vt3f8xaSUohNsVyss/Ij5+6HFJjhBCnChaLSkopSqVUhURpkqlVMUR9v0v4LxWlp8PDKqbfowZSuP4aKX6yOUaSFxcd2lXEELEpFZLClrrdg9lobVeoZTKbmWV7wLP1Q2f8blSKkUp1UNrnd/eY7ZZC4PiASilSE6eRlnZR9KuIISIOW2uPoqCXsD+Rn/n1s2LflBQKuJTzWEpKdMpLHyN2to9uFw5UU+OECeSsjIoKYHsbLAcodVRa/D7zXq2FnITrcHrhZoaqK42P+12cLshPh5cLrMPj8dMXi9YrWYdm81Mfr+Z7/NBIGCWh5dZrRAMml7moRA4nZCVFTntgYDZV1yc2Q7MPg8dapiqq6G21hzP7zf7S0yEpCTzs/HkcJhspKDATCUlZp7Tac7LajXnGz53j8ccLzxZrZCS0jBZrea44cnhaLo8KwuSk4/p33tEnRkU2kwp9WNMFRN9+/btmJ22EhQaj4MkQUG0VSjU8OWvqmqaudTWmgzJZjMZUlyc+V2phsnng9JSk7GUlpp9hDO6xpPW5ngWS9OMs7y8IXM6eLDhmMGg2SYjA3r1gp49TeYSCDRkxOXlsGMHbNtmMkYwBepx42D8eOjTB/bvhz17zBTOPKurzf7D91ndu0OPHiadhYUNk/84Dz4cF2fSnJ1tfs/PhwMHTFoOv35e7/FN27G44w64//7oHqMzg0Ie0KfR373r5jWjtX4C0/uJiRMn6g45egtDXQDExw/HZkujvHwFPXpc2yGHE9ERCJjMs7LSTB6P+bJbrWby+00GmZ9vpoqKpneZFovJwMJ3miUlsG8f7N1rfnq9DXd9TmfDnXH4jtPvN5l5eN7xEA4ihz2Qj8UC3bqZjDkry6Q5fCcNJkPcuBEWLzbXDEymGL4THjAAZs6EwYMhNRXWr4e1a+HJJ02wi4+HnBzo1w8mTTJ/hyevt+E6FxSYtPTtCxMmQGamubsNlwzcbnOtwqWGmhqTcYevs8Nh/h/haxwINARSh8OcU3h5OOiF/+cWizm38P9wzx6zj969TZp79GgomYTv1hMSzPXKyjJpDZcAHA5zTI/HfG4qK83Pxp+32tqGYNi9u7lufr+ZHw7Kjc/b6WzYt91ulpeXm9JZaan5n4aXOxzmupaVNUxDhkT/89WZQeFN4Bal1CvAKUD5cWlPCMvIMN+QCJSykJx8BqWlH0q7QhTV1kJenvlSeDzmb4+n4UsX/iKG77qrqswUvvs8dMh8UY6G3d4QACJJSjKZXr9+MHWqyUDCX3CPx2TGdnvDHbrdbjKO8M9wJpmQYH42zgRstoaMLlwNonXDnavNZh6wT001P+PjG4KbxdIQDMK0NucSDk7h9dvC42k4hyMJBs3/IiWl6fHFsbNaTSDv1q2zU9IgakFBKfUycCaQoZTKBe6mbrhtrfXjmIffLgB2YLqkHt/Xe7ZSfWQWX0Rx8SKqqtaRmDjuOCbs5OHzNVRVFBebu+ySEpNRhzPwqqqm9ah+v7nsubkmY2+L8J1WQoKZMjJMtUZmpvm9cV2vy9WQWYbrnsNVGt27m31BwzrBYMuZ7olOqYYSj8t1dNsezfpWqwlUIjZELShora84wnIN3Byt4x9RRobJwUKhiC1S6enfBf6HwsIFMRsU8vNh2TL48kuT6ZeXm6mkxCxrJaYSF9eQibtcDcV/u91kzpMmmTrfPn1MhhOunnE66+6yE0IUBnews2oD/VL6MLb7WBw2R4edW+MMVQjRIHa/Et27m4CwcycMGtRscVxcBqmpMygs/Dc5OfecFFVIhdWFrD6wmtUHVmNRFkZnjWZ01mhSVF/271fk5Zk79Lw8c4d/6JC5yy8qMnfQaWlmcjrh8y8CbMstgvhDOJLLSHOnkOrIIM2ZQf/+cZx6WojMHh5Ss6pJz/STmR5HVrqDrAwHSUkhakJllNWWUVpbyr7yfWw6tInNhZvZUriFcmUlufsY7Fljyeo+BrvFTkFVAQVVBRwoOcD6r9ez+sBqyr0NrwGPs8Yxrvs4Tul1CkMyhtA/tT/9U/vTM7EnxTXF5Fflc6DyAFW+KkZkjmBkt5H1QSS3IpfXNr/GK5teoaimiOvHXc+PJ/yYbvHtK7OXekpZtmcZn+z7hB6JPZjSewrje4zHbXdT7avmk/2fsGz3MjYc2sCobqM4M/tMpvaZSqKj5R7ea/PXsmz3MuxWO3HWOBxWB/Fx8aS70kl3p5PuSifOGkdtoLZ+UkrhtDlx2Vw4bA5COoQ34MUb9BIIBRicPhibpflXPL8yn5c2vkSqK7X+OvZK7IXV0rTuSWvNVwVf8dLGl9hwcANprjQy3BlkuDPITslmap+pDEwb2Oy7EdKmbs6iIndd0lpzqPoQ24q3sa14G7vLdpPhzmBA6gAGpg0kOyW7yQ2AL+gjvzKfvMo88iryqA3U8q2cb9EnuU/E/R+elmpfNW67u9n5NU5Pjb+GEk8JZbVlZCVkRfxshHSI/ErzOSuoKiC/Kp8KbwUjMkcwqdckMtwZ9ettLdrKp/s/ZWfJTlKcKaS6UklzpZEYl4hSCoVCKUWqM5WhGUOJj4s/4rlU+arwBX2kudKOuO6xUFp3TLvt8TJx4kS9evXqY99Rbq6pOL7zTvjDHyKucuDAP9i27UYmTtxAQsKoYz/mMdJa8+6Od3ng0wdYfWA1iXGJJDoSSXIkUVhdyN7yvQAoFJpG/9faJCjLgaosqM6CqiyctngSXXYS4+0kuK1UqnzK2U113B58rr1oV+RGeACnzUltoPao0m5VVgalD2JE5gj8IT/rCtaxr3xfxH0PzxzOpJ6TmNRzEmO6j2Fv2V5W5a3i89zPWX1gNZ6A54jHs1lsjOw2EpfNxWe5nwEwoccEUl2pLN21lDhrHHNGzuGMvmews2Qn20pMBlVW27SRIt4eT2Z8JhnuDFKdqWw6tIk1+WsI6RBx1jh8QV/9+Q1MG8iu0l34Q35sFhuD0wezvXg7/pAfq7IysedELht2GZePuJx+Kf0A2HhwI3ctv4v/bP3PUV3Ptuib3JefT/k5Pxz3QxIdiZTXlvPApw/wl8/+0uwa2i12BqYNZEjGEIakD8FmsfHvLf9mW/E27BY7o7NGU+GtoKimiNLa0vrtMt2ZTO07lQxXBnvK97CnbA97y/YS1EFSnCmkudJIdaYS1EEqvZVUeCuo8FY0OX6zz2sbjckaw8whM7lo8EVM6DmhSRDyB/08v+F57llxD7vLdgPgtrtJiEvAZrERDAUJ6VB9uvyHvZs93ZXO8MzhDE4fTLGnmO3F29lZurPVz/2A1AH0S+nH2vy19Z8ji7LUB8nWZKdkm+OlDSY7JZuc1Bz6Jfdjf8V+VuxdwUd7P2LNgTX85ozf8H8z/u+orxWAUmqN1nriEdeL2aAAcNFFsHq16apgb/52UZ/vIJ9+2pN+/X5HTs7/dswx26HKV8XrX7/O/Z88wObCTaTZejM4dDEVNbVUeCuo9lfiKUukdtckODAR8seTkaHoNXYTCQM2EMzcgN+1nxrLQSqCByn2Hmz24XbanGSnZJspOZvuCd3pFt+NzPhMUpwplNWWUVRTRFFNERXeClw2F/Fx8cTb47Fb7fiCPrwBL76gD6UUKc6U+qlnYk+GpA9pVv1T6illw8ENAHRP6E6PxB71d1ItCekQBVUF7Crdxa7SXRyoPECGO4OeiT3pmdgTl83FxkMbWZu/lrX5aynxlDBzyExmj5jNoHRTItxatJVHvniEf637F9X+auwWOwPSBjA4fTDprnQU5vgaTZWvqv68i2qKGJA2gLNzzuas/mcxuddkymrLWJW7ilV5q9hwcAPDM4czI3sGU/tOJSEugWpfNZ/lfsbyPctZvGMxa/LXAHBKr1PokdiDRVsXkehI5Ben/oIbJ96IzWKrv9uv8lVRXFNMsaeY4ppifEEfLrurvmQA4PF76ksOFmUxpQybA3/QzzPrnmHlvpWkOFO4dOilLPpmEcWeYr7njgl7AAAgAElEQVQ/6vvcPf1u7BZ7/XXcUbKDbSXb2Fq0lZ0lOwmEAkzPns73R36fy4Zf1uTuNBAKsK14G5/s+4SP93/MJ/s+ocJbQU5qDjkpOWSnZBNnjaPEU1I/2Sw2cwMTl0SiI5F+yf0YnD6YwemD6Zvcl9LaUnaW7GRHyQ72lu8lEGroymVVVnok9qBXYi96JfUC4N3t7/LWtrf4ZP8nhHSIbvHdOH/g+Vww6AKqfFXcu/JedpXuYmLPiXxv2PeoDdRS5aui0ldJMBTEoixYLVYsykJCXAJprjTSXGkkO5I5UHmALYVb2FK0hW3F28hwZzAwbSCD0gYxMG0gvRJ71X9e3XY3Gw5u4Iu8L/gi7wv2lO1hfI/xnNbnNE7rcxqD0gbhCXgo8ZRQ6iml0leJ1hqNri8xfV30NVsKt7C5cDM7SnZQ469p8pmPs8YxuddkpvebzswhM5nca3LbM49GJCi0xZtvwne/C2+8ARdfHHGVdetm4PMdYvLkze0+TJWvin9v/jf7yveZL7inuL6oWl5bTrm3nNpALTkpOQzNGMqQ9CGkudL4ZNdXfLz7C3K9m9EqhDo0Ev3xr2DTHAjZ6x9m6d7d9MceM8ZMo0c3DO/UEq01/pAff9BPIBQgyZF0UlSRdaRKbyWFNYX0Te4bsZolGnaV7uK1za/x6uZX2VW6i1sm3cIvTvtF1KoEVuWu4sHPHuT1r1/nrJyzuO/s+xjfY3yr2wRCAap91SQ7o/yUVAcorinm3R3v8s72d1i8Y3F9KWZCjwnMO3MeFw668KT6XGutKaopYk+ZKXVlxmdySq9TcNmPsidBBBIU2iIQMJ2px42Dt9+OuEpe3qNs334LkyZtJj5++FHtvqimiIdXPczDXzxc/2FNcaaQ7konzZVGijOFZGcySXHJVJbb2HpwF/uqv6Fc1VWr1KRD3mTiCiczMnEaM3JmMGa0YvRo05f8aHuciNjlD/qxW5uXhruSQCjAqtxV+II+zsw+86QKBsdDW4NC7DY0g+l6ct11cN995nHNPs0brjIyLmH79lspLFxAfPxdbdrtoepD/HHlH/nHmn/gCXi4eOjF3Dn1Tib2nFh/R1peDu+/b2LR2++aBl8wHaEGDqlm4OhSzpnci+mXK8aMkV4y4th09YAAph1pat+pnZ2Mk55kNT/8oWlofuYZuKt5pu9w9CQ5eSqFhQvIzm49KFT7qnno84e4/5P7qfHXcOXoK7lz6p0MzxyOxwMfLTNdPD/80HTzDATMA0HnnWemceNMCcDpjAeO3BtBCCE6mgSF/v3h7LPhn/+E3/424iOhmZnfY8eO26ip+Qa3ewjbi7dzxcIr2Fm6kwGpAxiQNoBeib14ZdMr5Fflc/HQi/njWX9kaMZQKipMrPnLX8xTuVar6aP/q1+ZQHDqqVIKEEKcOCQ7ArjhBpg929TnnNf8FRAZGZeyY8dtFBYuZEPtKK564yrsFjuzR8xmd9lu1hxYw+vlrzO512T+PevfTO07Fa8XHnoI7r3XPPg1axZcey2ccYZ58lYIIU5EEhTA9EDKyIC//hWGDjXPLzRqpHI6+xCfeAq///iv/HNHIRN6TGDh5Qvr+5qD6SppURa2bTMFjmefNQ+JnX22abKYMKEzTkwIIY5Om97R3OU5HHDzzbBkiRkGMj3d5OZPPVW/yoPbrPxzRyFXDr+Qj6//uElA0BpeetHCaaeZUQzvu890C33vPVP4kIAghDhZSFAIu/tuWLUKHn/c1PXs2gU//Sn4/SzZsYTXtn3Klf3i+M2IVJw2Z/1mRUXmEYcf/MAMBHf//aYj0zvvwDnndOL5CCFEO0j1UZhSMHmymQAWLIBZs/B8+Sk/Wf0ThqQPYe4pMyg89Ax+/1+x29N5/324+mozQNxDD5kYcqQ3VQkhxIlMsrCWnH46APcu/z27Snfx2IWPkd3nJ2jtJTf3Oe68E8491wwg98UXcNttEhCEECc/KSm0pHt3vh7fl/u9H3L1uKuZkTOjbsF5XHHFRFatghtvhD//uWGMfiGEONlJUGiB1pobz/WS4IMHzvoTAFu2wPXXv8r+/U7+9rev+elPh3VyKoUQomNJUKjz6qZXeXXzq1iUBZvFRqWvkhXOgzz5JnT7QQnv7OnOnDngdicyf/75TJuWBLzW2ckWQogOFfNBoby2nFvevYUXNrxA3+S+JMYlEggFCIQCXJNzCdd/9QZvPrKP7z01nFGjYNEiRW3tSPLy/obXW4DD0b2zT0EIITpMTAeFT/d/ypWvX8m+8n3Mmz6P3077bdMhlLXmrZ9dzff+cTbjJprnDpKToabmx+Tm/pmCgn/Sr99vO+8EhBCig8Vsf5n3dr7HtGemoVCsvG4ld595d7Mx9f/7tuKy8mcYa9vEkiUmIAC43YNJTT2HvLxHCYW8nZB6IYSIjpgNCs9veJ5UVyrrblzHaX1Oa7Z8yRK47DIY07uY93xnklK5v8nyPn1+hc+XT0HB88cryUIIEXUxGRS01izdtZSz+59NkiOp2fLt2+Hyy2H4cHjvuQJSKIePP26yTmrqWSQkjGf//gfQOni8ki6EEFEVk0FhS+EWCqoKODvn7GbLqqvh0kvNK5v/8x9IPWOkGdZ05com6yml6Nt3Lh7PNoqKOv6l60II0RliMii8v+t9AM7u3zQoaG1G0d6yBV5+2QyWitUKp53WLCgAZGZeiss1kH37/sTJ9lpTIYSIJCaDwtJdSxmUNqjJSKcA8+ebYHDPPYcNZnf66bBpkxnkqBGlrPTp80sqK7+krGzZcUi5EEJEV8wFBX/Qz/I9y5uVEj79FH75S/NqhTvvPGyjM85oWOkwWVnXYLdnsW/fn6KUYiGEOH5iLiisyltFtb+6WVC4807o0cO8HKfZwHaTJ5tGhghVSFark969b6O09D0qK7+KYsqFECL6Yi4ovL/zfSzKwozsGfXzPv3UdC765S8bnkVowuUyL1ZeujTiPnv1ugmrNYldu+6UtgUhxEkt5oLC0t1LmdhzIqmu1Pp5DzxghsD+4Q9b2fCyy2DtWvj662aLbLZk+vf/A6Wl71NQ8HQUUi2EEMdHTAWFCm8Fq3JXNemKunUrLFpk3sYZH9/KxldeaXoiPftsxMU9e95EcvJ0duy4ndra3A5OuRBCHB8xFRSW71lOUAc5Z0BD16I//9m8ovmWW46wcVYWnH8+PP88BJs/rKaUhSFDnkJrP9u2/Y9UIwkhTkoxFRSW7lqK2+7m1N6nApCfD889B9ddB926tWEH11wDBw7ABx9EXOx2DyQn5w+UlLzDwYMy/IUQ4uQTc0FhWr9pOGwOwDyXEAjA7be3cQcXXQSpqS1WIQH07n0rSUmnsWPHz/B68zsg1UIIcfzETFDIrcjl66Kv69sTKirgscdM+/HAgW3cicMBc+bAG2+YHUSglJWhQ58mFKpl27YbpRpJiOPp66/h7bc7OxUntZgJCh/sMlU+4ecTXn4ZysvhjjuOckfXXAMeD/z73y2u4nYPITv79xQXv8mhQy+3N8lCiKP1s5/BrFng83V2Sk5aUQ0KSqnzlFLfKKV2KKXmRlh+rVKqUCm1rm76UbTSMnvkbD68+kNGZY0CzLMJWVkwceJR7mjyZBgyBP71r4Z5WpthMBqVHvr0+TlJSVPYvv1WfL6Dx34CQojWFRfDhx+am7Z16zo7NSetqAUFpZQVeBQ4HxgOXKGUGh5h1Ve11mPrpqeilR6nzcmMnBlYlDnlL780z6MpdZQ7UsqUFj7+GDZvNu0LkyfDqFFw7bWNVrMyZMjTBIPVbNv2E6lGEiLa3nyzoWdghCFpRNtEs6QwGdihtd6ltfYBrwDfjeLx2qyy0jyfMGlSO3fwgx+Y4DBmjAkE1dVw4YWmrWHTpvrV4uOHkZPzvxQVvU5hYcvVTUKIDrBgAfTtC9nZ8MknnZ2ak1Y0g0IvoPHrynLr5h3uMqXUBqXUAqVUnyimp96aNabGp91BoXdvuO02uOQSU1wNlxji4+GPfzxs1V+QmDiJ7dtvlmokIaKlvBzefx++9z2YOtUEBSmdt0tnNzS/BWRrrUcD7wMR+3oqpX6slFqtlFpdWFh4zAf98kvzs91BAeAvfzGNzTNmmFJDejrcdBO88grs2FG/msViY+jQZwgGq1i37lt4vXnHlnghRHNvvQV+v+lOeNpp5iGkvXs7O1UnpWgGhTyg8Z1/77p59bTWxVprb92fTwETIu1Ia/2E1nqi1npiZmbmMSfsyy9NCTMj45h31dTtt5vRVP/UdBjt+PgRjB69GK93H199dQYez64OPrAQMW7hQujZE6ZMMSUFkCqkdopmUPgSGKSUylFKxQFzgDcbr6CU6tHoz5lA89HmopGwL4+xlNCSHj3MqHrPPgv79zdZlJIynTFjPiQQKOerr06nunpzFBIgRAyqqoLFi817dC0WGFn3Cl1pbG6XqAUFrXUAuAVYgsnsX9Nab1ZK/Z9Sambdaj9VSm1WSq0HfgpcG630hBUWwp49UQoKAL/6lanLfPDBZouSkiYxduxHAHz11TQqKlZFKRFCxJB33oHaWtOeAGbgyilTTv6SQm0thELH/bBRbVPQWr+jtR6stR6gtb63bt5dWus3637/tdZ6hNZ6jNZ6htZ6azTTA7B6tfkZtaDQrx9cdRU8+SQcOtRscULCSMaNW4nNlsK6dTMoKnozwk6E6EC1tfDTn8KuKFVbhkIRB4k8bhYuNIOXnX56w7zTToONG1sceeCEt3KlqeMeO9YM2X8cdXZD83H35ZemXXhCxNaLDvLrX4PXa55nqKlpttjlGsD48Z8RHz+STZsuIS/v71FMjIh5L70EDz/crK2rw8yaBWee2Sl3tXg8ZliLSy4xJYSwqVNNeladZKVxreGRR+Bb3zJVYEVFcMopcPfdx+0p7ZgMCkOHmusdNYMHwz/+AUuWmOG2I9ytxMV1Y+zYZaSnX8D27Tezc+dctO7Euy3RNWltAgKY4FBVdeRt9u+Hf/6zbV06t26F1183D3O+8sqxpbU9Fi82zwlddlnT+aecYtoXjqUKqbgYrr4annrKjJx5JAsXwujRkNvO96l4PGbI5ltvNfnG6tXmuac5c+D//s88JHs8ntTWWp9U04QJE3R7hUJaZ2VpffXV7d7F0Xn5Za1tNq0nTNC6sDDiKsGgX3/zzY162TL06tWn6KqqTccpcaLTVVdH/xgff6w1aH3VVebn008fOU2jRpl1Fy068v5vvlnruDithw/Xum9frT2ejkl3W9TUaD10qNa9e2vt8zVfPmaM1uec0759l5ZqPX68uQ6g9YgRWv/3vyYTiWTPHq2Tk82611xzdMcKhbT+z3+0HjbMbD9vntbBYNN1Fi3Sunt3rX/963adjtZaA6t1G/LYTs/kj3Y6lqCwb58544cfbvcujt5//6u102n+4W++qXVFRbNVQqGQLih4Qa9cma5XLLHpgifm6OAj84/vF0wcX7/8pdZJSVrv2hXd48yebTKrykqTgZ52WsvrhkJa/+AHWiuldUaG1pMmtZwJam0yzvh4kwl+8IH5ct13X4efQotuu80c8733Ii+/6SatExO1DgQiLw+FTNDcvLnp/IoKrU85RWu73Xx/Fy7UetAgc6wzz9R6586m6wcCWk+frnVCgtZXXGGu39q1bTuHFSvM/wS0HjxY63feaXndoiKta2vbtt8IJChEsHChOePPP2/3Ltpn+XKtU1PNwW02rc84Q+u779b60Ue1fuYZrV95Reunn9bBiy/UQZe1/u4kMHGk1rm5xzmxIupefbXhDnTOnOgdJy/PfN5+/nPz94MPmmMengmGPf54w53qE0+Y3xcvbnn/f/6zWWfNGvP3d75jAt2hQ03X27/fBJC28ni0LijQescOrdev13rTpubBKRyEbrml5f288IJZZ926pvNDIZP5Tp7c8H+YMcNkEGVlWp9+urlub7zRsI3Pp/Ujj2idkqJ1Wpo5ftif/mT28cwz5jzT07X+1rdaD6j792t9ySVmu549zfX2+9t8idpDgkIEc+ea/3Wn3IB7PFovXar1nXeaYqlSDR/I8NSjh9Y33aTLF/xeb70nRftd6EBmkg6tXNkJCRZNhEJaP/ec1tu3H9t+Nm82d9dTp5oPZDTvUu66y3zOduwwfx88aO5+b7+9+bpffGGqgc47z1RdeL2mWmbq1MiZWyCgdU6OyUDDtmzR2mptyKgPHND6+utNGhIStL7jDq3z81tObyCg9R//aNJx+HfjvPO03rbNrFdaqnWfPloPGdJ6FdyuXWbbRx81fxcUaP3SSw3BoF8/Ewjvu89UfYHWDofWFosJ3JHs2GGqyqxWrefPNyUCu13ryy5ruE7z55t9/fe/kc/xb38z18Pl0vree49PNaKWoBDRWWeZ/PiEUF1tPqS7dpmMYvPmJvWIXu9B/fXCqbq6FzpoU9r/+N86MbExzu83mRuYon5rd4CtqagwVTjdupkSYEWFaeQ6/fT277MlXq/Z94UXNp3/ve+ZqqHG1RC5uSZT7NvXVFGEPfywOedly5rv/z//Mcv+/e+m82+6yWSYt99ugp/dbqp5vv99k9k6HFr/5CemdNH4nHNzzd06aH3ppSYjf/ZZc/d+//2mBBIXZ+rUr7jCHOOLL1q/BqGQudEaONBc93CA6ddP6yefNNcoLBAwJYPvfteU3FtTXq71zJlmX4mJ5hiNr5vXa6qbhg1ruPsPBrX+8ENTJQdaf/vb0a86PIwEhcMEg6Zq9X/+p12bd4pQKKj3bfhfXTzJlCrKFv+5s5PUtQWDzRv4qqtNtQhoPW2abrEO++uvG+48IwmFTIZstTbNZMNVNq+/3lFnYbz4otnvu+82nb94sZn/2mvm70WLTHWH2908k62pMY2b3/pW8/3PmGHu1g+v8jh40GSUYM43XErR2pSybrjBBIpwyfhHP9L6oYdMlUx8vGkIjxQgCwpM20U4Y7/77rZdh5tuMgHlggtMcFm1qmOqaYJBrX/3O3O3v2RJ8+VvvGHS+fvfa33PPVr372/+zsoyHVA6+iagDSQoHOabb8zZPvVUuzbvVOW5H2pvpk1XDERvXn+59noLOjtJXcP+/SZDuu46rSdONF/wtDStZ83S+h//MHXRp51mqj8ee8zcXffpo/Wppzb9UodCpqExnGEd3sOnttZkfmAypsb8fnNHOXCgucMM90SZPNncud99d/N2pWDQlCyff17rX/zCZNoZGaZu+tRTzZ30oEFmOjzIBQJmv2eeae7YQetx40xQiyTcbvDJJw3zNmzQrTYqf/5561Vihw6ZUsCsWSbDBlOE/+ablrcJ++QTk9FG6m3UkmhmwC2lIxQybYeN2yxeeMEE2k4iQeEw4Tan9evbtXmnC776ktagt99i1StXpujc3Ed1INCOxpGNG80d789+1mI32S5h506Tkd97b+TeJ+XlDXdv3bqZusXbbtP62mu17tWr4cscF6f1ggUN2z32mJnf+O7wmWd0fbe2c84xQeSll8yyAwcaepf85jeRM6j//tcsv/56040STNrOPdfsy2o1VSpz55oAEL4TB9OzbdIkrX/4QxPcZsww27pcWv/zn5Gvzbx5Ddv/4het92ipqjIBZ9gwc7c9ZIi5Jk5n0yqT9vL5zJeycVVOV7FjhwmcjUtLnUiCwmHKy007b5Qb+KMnFNL6vPN0KDFeb1gyRS9bhv7440y9a9fdbSs5hEKmntbpND2hLBZTn3b//R3b8r5jh+nmd7yFQlqvXGmqCwYMaMj0IHLD6lVXmWsQqb48FDKNpo89pvXq1U2XHV5aKCw01S9Tp5q78upqU2qwWrX+wx/M3bvb3VBd01Lav/UtXd8t8bnnGj6oO3dq/atfmWOEn3n5yU+0/te/TK+c9nygCwpMz5eWunIe7pFHTAlq3DjToHrHHeZai5OKBIWuaPt2rR0OHZozR5eUfKg3bPiOXrYMvfxDu/56y7W6snJd5O2KikwDWrgXx8GDJkO54AJd3/A2b56pUz68uqGtSkrMnbbNZvb5hz8cn3rTQ4dMV8twQ6LbbdoA5s831RG33mrmP/FEwzbPPafru162R7gdYMkSU7Kw2UwJLKyiwgQN0Do7u3mXyEjy802JoaU+9T6fPLcijokEha4qXPR/7jmtH3tM+797jg4kxenqPkqvfhz91Vdn6kOH3tChUF3msny56Vpot2v9l780z/Q/+MDUfYa7yGZlmWqI998/coCorjZPcs6fb+4klTJ153PmmH398IdHX/dbXNxyMAmFTEPp73+v9eWXmyoNa91zHaedZqpxqqqabuP3m54eNpvp/bF9u+kOePrp7S82er2mtNCvnzn23LnN1yktNfXxXbmKTpxUJCh0VR6PaZQMV4307av1ddfpUJ9eOmS36t23puhlH6A/W5mjy392ng5ZLKbB8fBqkMMdOmQCTfgJWDAZ3+9+Z7oP/uc/pt/7hRea/unx8bpJFc1ZZzXcEYdCZjswdexlZS2fy4IFpnrnrLNM3TWYIHXgQNN1q6tNA2r4eDk5plvgXXe1/DBWWFmZ6Vuemmrq7FNStN67t23XuyXh0kJOznHrZy7EsZCg0JVt2mQypa1bG+6qi4vrn5CsPWucrhyToDXogvMdevfGO3Vt7YHW99mYx2O6zYUbOsMZscVixoCZM8c8JfuHP5juXCtWRL67f/ppc4eelmbqov/+d9PLZflyU4oI9zxxOExd+fXXa/3b35oqoKwss57WppfQhAkmLffcE3GokCPatash6Bzet749vF7Tv/nTT499X0IcB20NCsqse/KYOHGiXh1+KYJoSmt47DG4/XZ0XBw1f/45u6asp7j4TcBCevqF9OhxPWlpF2Cx2Nu2z/37YflyGDgQxowBt/vo0vTJJ2aUyQ8+aPo2uvh4M7LlD35ghl222RqWbdpklu3cCbfdBi+8YIYgf/FFuOiiozt+Yxs3wvr15n0XQsQYpdQarfXEI64nQaEL2rULnE7zzlqgpmY7+fn/5ODBZ/H5CrDbs+jWbRYZGReTnDytSYDw+8vw+fJxu4egVAeOrK61yeSXLYOEBJg50wSGllRUwPXXm+GIBwyAN9+E4cM7Lj1CxBgJCqKZUMhPScliCgqeoaTkXUKhWmy2FFJTzyUYrKS6eiNerxkLPjNzFkOH/gur9ShLBh1Ja3jvPTOOfGpq56VDiC6grUHBdqQVRNdhsdjJyLiIjIyLCAarKSl5n+LiRZSUvI/dnkFKypnEx48kGKxi7957qa3dzciRi3A4enZOgpWCb3+7c44tRIySoBCjrNZ4MjMvJjPz4ojLExMnsWXL91mzZjKjRr1JYuL445xCIURnkKAgIsrImMn48Z+wceNFrF17KklJk0lImEBi4kQSEyfWtTmozk6mEKKDSVAQLUpIGMP48V+wf/+fqKhYRX7+E+Tl/Q0Auz2T5ORppKRMJyVlBvHxIyRICNEFSFAQrXI4ujNw4EMAhEIBamq2Ulm5irKyFZSVfURR0UIAnM7+ZGRcQmbmJSQlTUEpa2cmWwjRTtL7SByT2tq9lJQsoajoDUpLP0BrPxZLPE5nNk5nv7opB5drEG73IJzOAVitzs5OthAxR3ofiePC6exHz54/pmfPHxMIVFBc/A4VFZ/j9e6ltnYvFRWfEwiUNNpCER8/grS0C0hPv5CkpFPb/iCdECLqpKQgos7vL8Pj2Y7Hs52amm2Ul6+kvHwFWgewWpNJTj6V+PiRxMePIj5+JG73cClNCNHBpKQgThh2ewp2+ySSkibVzwsEKigtXUpJybtUVq6htHQZWnvrllpxuwcTHz+ahIRRuN1DcbkG4nQOwGZL6JyTECJGSFAQncJmSyIz81IyMy8FTCO2x7OD6uqNVFdvpKpqA5WVX1BY+GqT7eLiutcFi7EkJIwjIWEsbvcgadgWooNIUBAnBIvFRnz8UOLjhwKz6ucHApV4PDvqp5qab6iuXk9u7kNo7a/bNp6EhDEkJo7H7R6B1RqPxeLAYnFgtSbjdg8lLi5LuswK0QYSFMQJzWZLJDFxHImJ45rMD4V8VFdvoarqq/qpoOBfBINVLewnjfj44bhcA7HZUrBak+t+uutKGRaUsuByDa7rUisBRMQmCQripGSxxJGYOJbExLHAdQBoHcLnyycY9KC1l1DIi99fQk3NFqqrN1NdvZmSkvcJBstbDB4ATmcOWVlXkZX1A5zOvni9efWTxeLE4ehBXFxP4uK6S88p0eVIUBBdhlIWHI5ezeanpZ3dbJ7WQQKBCkKhGrQOASG0DlBe/jEFBc+zd+897N37+yMeMy6uR90zGea5DBMsetQFju7ExfXo3JFmhThKEhRETFLKit2eCjQdktvlGkD37tfg9eZx6NBrBINVOBy966aehEK1eL35+Hz5daWHfdTW7qGiYhWFhf9G60CzY1mtyTgcPbHZ0ggGKwkEyggESutKK6baSikrVmsyCQljSUwcT0LCeNzuIdhsyVitSdhsic0a07XW+HwFdd19d+Jy9Sc5+fQjNrr7fEVUVn6Jw9ELt3sIFouj1fWrq7dSVbWWtLTzsNvT2nR9xclLgoIQETgcvejT5+cRlyUmRt5G6xB+f1FdwDCBIzx5vQcIBEqw27Ox2VKw2VKxWsPda4N12xZSVfUV+/c/EDG4WCwuLBZn3eTA7y9qVg1mt3cjI+NiMjMvJS6uJ1r70TpAMFhJWdlHlJQsprJyNRB+PsmCyzWQhITRZGVdTXr6BfVBJRisYe/ee+rTo1Qc6enfoXv3q0lLOx+LJa7JsYPBWoqL3+TgwRdRyk5m5mWkp1+IzZbU1sveobzePA4ceJxAoJJu3S4nKelUaStqA3l4TYgTTCjkpapqI7W1uwkGKwgEKggEygmFqgmFausnmy0Vl2swbvdgnM4cqqrWUVi4kOLi/xIKVUfYs4WkpFNISzuf5OTT8fkO1rW3bKGi4hN8vgKczmx69lj4Yf8AAArOSURBVLwRl2sgO3f+ktraPWRlXUOPHtdTVPQGBw++hN9/CIvFids9vO6hw5HU1u7h0KGXCQRKcTh6o3UQny8fpRykpX2blJTpuN1DcbuH4nT2IxisqetRtp3a2t1YLPHExWURF9cNmy2dUKiWYLCSYLCCYNCD3Z5BXFx3HI4eWK3JjUpcZYRCXmy25Lpgm0J19UZyc/9aV3ILYbHEEQrV4nTm0K3b94mPH0EgUFo3leFw9CY5eToJCaPb9LbBYNBDdfUmqqrW4/XuIyVlBsnJZ2CxRPceW+sgoZC33dWRJ8Sb15RS5wF/A6zAU1rr+w5b7gCeAyYAxcBsrfWe1vYpQUGI1gWDHsrKPiIUqkYpW93kIDFxfIvVP6GQn6Ki/5CX9yjl5R8B4HYPY/Dgx0hJmd5ovQClpe9RWvoh1dWbqK7ehM9nGuAzMi6le/frSE2dASgqKj6jsHABhYUL8Xob3s+tlL2+O3G0WK1J9OjxI3r1ugW7PaMuoL1AaekHQKh+PYvFSShUC4DNlkpy8hm4XAOx29Ox29OxWpPx+w/i8eyitnZ3/VP5jfcBZtTgjIxLSE09C7+/BK93P17vfoLBGtzuIcTHj8DtHo7LNQCrNaG+xKK1prZ2N5WVa6iqWkswWNWod1wyfv8hqqu3UFOzhZqarfTpcyc5OfPadU06PSgoUwbdBpwD5AJfAldorbc0WucnwGit9Y1KqTnAJVrr2a3tV4KCENFVVbWJmprNZGRc0qyKKBK/vwSl4lp92tznK8Lj+Yaamq3U1GzDZktpNEhiDqGQB5/vED7fQQKBYiwWV11bShIWi7OuWq4An6+AQKCsbpkpGVgsDgKB8vq2Grs9jW7dvo/N1ryez+c7iN9fjM2Wht2eisXioLZ2P2VlH1Fe/hFlZSvwenMJhWqabGexxONyDcDl6k98/Ki6hyfHYLdnUVKymMLCBYeV0Kw4HD2xWFx4PDuBYOO9YbMl1ZV4TLoBlLJhtSYQCFTQOOg4HH2Jjx+O2z2C9PQLSE391hH/J5GcCEHhVGCe1vrbdX//GkBr/cdG6yypW+czpZQNKAAydSuJkqAghIi2YLCWQKCYQKAMu70bdnvGEdsjgkEPNTVbsNuzcDh61LfNhEI+amq2UVOzhdravQQC5XXBoByLxV3fsSAhYRQWiwOtQwSDVQQCZdhsqRGDW3ucCGMf9QL2N/o7FzilpXW01gGlVDmQDhRFMV1CCNEqq9WJ1dorYhfnlrdxkZg4odl8iyWOhISRJCSMbNN+lDIlic5qoD9yq8oJQCn1Y6XUaqXU6sLCws5OjhBCdFnRDAp5QJ9Gf/eumxdxnbrqo2RMg3MTWusntNYTtdYTMzMzo5RcIYQQ0QwKXwKDlFI5Sqk4YA7w5mHrvAlcU/f794APW2tPEEIIEV1Ra1OoayO4BViC6ZL6tNZ6s/r/7d1tiFzVHcfx789GUpOIMfWB1BSjtWjToquUEKstPqFRiu0LS7VWShH6JqARwRq0Fn0nlFpfiFpan0MUNdESpD5sJWChSTdx1TUxNdXURtSNVaO2KJr+fXHO3NxOYrJMkj1nM78PDHvvmdnht3Pv3f/cc2fOkW4AhiLij8AfgHslbQDeIRUOMzMrZK9+2yIiHgMe62q7rrX8Ee1xks3MrKgJcaHZzMzGh4uCmZk1XBTMzKwx4QbEk7QZ+GePv34I9X4xztl6U3M2qDufs/VmomY7MiJ2+Zn+CVcUdoekobF8zbsEZ+tNzdmg7nzO1pt9PZu7j8zMrOGiYGZmjX4rCr8rHWAnnK03NWeDuvM5W2/26Wx9dU3BzMx2rt/OFMzMbCf6pihImi9pvaQNkq4unOUOSaOSRlptMyQ9Kenl/PPgQtm+IulpSWslvSjp8lrySfqipFWSnsvZrs/tR0lambftA3kAxiIkfUHSs5KW15RN0kZJL0galjSU24pv05xjuqSHJL0kaZ2kk2vIJunY/Hp1bu9LWlhDtpzvinwcjEhako+P3d7f+qIo5KlBbwHOBeYAF0maUzDSXcD8rrargcGI+BowmNdL+BS4MiLmAPOABfm1qiHfx8AZEXECMADMlzQPuBG4KSKOAd4FLi2QreNyYF1rvaZsp0fEQOsjizVsU0jzuP8pIo4DTiC9fsWzRcT6/HoNkOaR/y+wrIZsko4ALgO+FRHfJA06eiF7Yn+LiH3+BpwMPN5aXwQsKpxpNjDSWl8PzMzLM4H1pV+3nOVR0jzbVeUDpgBrSLP5vQ1M2tG2HudMs0j/JM4AlgOqKNtG4JCutuLblDSHyqvk65s1ZevKczbwl1qysW3WyhmkgU2XA+fsif2tL84U2PHUoGOfZ298HB4Rb+TlN4HDS4YBkDQbOBFYSSX5cvfMMDAKPAn8A3gvIj7NDym5bX8LXMW2Wde/RD3ZAnhC0mpJP89tNWzTo4DNwJ252+33kqZWkq3tQmBJXi6eLSJeB34NvAa8AWwBVrMH9rd+KQoTSqQyX/RjYZKmAQ8DCyPi/fZ9JfNFxNZIp/OzgLnAcSVydJP0PWA0IlaXzvI5To2Ik0hdqAskfbd9Z8FtOgk4Cbg1Ik4E/kNXd0zp4yH3y58PPNh9X6ls+TrG90lF9cvAVLbvku5JvxSFsUwNWtpbkmYC5J+jpYJI2p9UEBZHxNLa8gFExHvA06RT5Ol5Olcot21PAc6XtBG4n9SFdHMl2TrvLImIUVK/+Fzq2KabgE0RsTKvP0QqEjVk6zgXWBMRb+X1GrKdBbwaEZsj4hNgKWkf3O39rV+KwlimBi2tPTXpT0l9+eNOkkgz4q2LiN+07iqeT9Khkqbn5QNI1zrWkYrDBSWzRcSiiJgVEbNJ+9efI+LiGrJJmirpwM4yqX98hAq2aUS8CfxL0rG56UxgbQ3ZWi5iW9cR1JHtNWCepCn5mO28bru/v5W8eDPOF2bOA/5O6oO+pnCWJaR+wE9I75QuJfU/DwIvA08BMwplO5V0Ovw8MJxv59WQDzgeeDZnGwGuy+1HA6uADaRT/MmFt+9pwPJasuUMz+Xbi539v4ZtmnMMAEN5uz4CHFxRtqnAv4GDWm21ZLseeCkfC/cCk/fE/uZvNJuZWaNfuo/MzGwMXBTMzKzhomBmZg0XBTMza7gomJlZw0XBbBxJOq0zgqpZjVwUzMys4aJgtgOSfpLnbhiWdHseiO9DSTflMewHJR2aHzsg6a+Snpe0rDO+vqRjJD2V539YI+mr+emnteYPWJy/kWpWBRcFsy6Svg78CDgl0uB7W4GLSd9uHYqIbwArgF/lX7kH+EVEHA+80GpfDNwSaf6Hb5O+xQ5p5NmFpLk9jiaNWWNWhUm7fohZ3zmTNKnK3/Kb+ANIg579D3ggP+Y+YKmkg4DpEbEit98NPJjHGjoiIpYBRMRHAPn5VkXEprw+TJpb45m9/2eZ7ZqLgtn2BNwdEYv+r1H6Zdfjeh0j5uPW8lZ8HFpF3H1ktr1B4AJJh0Ezl/GRpOOlMwLlj4FnImIL8K6k7+T2S4AVEfEBsEnSD/JzTJY0ZVz/CrMe+B2KWZeIWCvpWtJMZfuRRrNdQJoAZm6+b5R03QHSEMW35X/6rwA/y+2XALdLuiE/xw/H8c8w64lHSTUbI0kfRsS00jnM9iZ3H5mZWcNnCmZm1vCZgpmZNVwUzMys4aJgZmYNFwUzM2u4KJiZWcNFwczMGp8BdOfwkxq3Fi0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.3440 - acc: 0.9043\n",
      "Loss: 0.3440394027087052 Accuracy: 0.90425754\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6940 - acc: 0.5038\n",
      "Epoch 00001: val_loss improved from inf to 1.07241, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/001-1.0724.hdf5\n",
      "36805/36805 [==============================] - 223s 6ms/sample - loss: 1.6938 - acc: 0.5038 - val_loss: 1.0724 - val_acc: 0.6685\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8171 - acc: 0.7521\n",
      "Epoch 00002: val_loss improved from 1.07241 to 0.52664, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/002-0.5266.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.8170 - acc: 0.7521 - val_loss: 0.5266 - val_acc: 0.8430\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5678 - acc: 0.8251\n",
      "Epoch 00003: val_loss improved from 0.52664 to 0.49969, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/003-0.4997.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.5678 - acc: 0.8251 - val_loss: 0.4997 - val_acc: 0.8542\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4400 - acc: 0.8652\n",
      "Epoch 00004: val_loss improved from 0.49969 to 0.26057, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/004-0.2606.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.4401 - acc: 0.8651 - val_loss: 0.2606 - val_acc: 0.9280\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3676 - acc: 0.8882\n",
      "Epoch 00005: val_loss did not improve from 0.26057\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.3676 - acc: 0.8882 - val_loss: 0.2626 - val_acc: 0.9243\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3124 - acc: 0.9052\n",
      "Epoch 00006: val_loss improved from 0.26057 to 0.24787, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/006-0.2479.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.3125 - acc: 0.9051 - val_loss: 0.2479 - val_acc: 0.9266\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2851 - acc: 0.9124\n",
      "Epoch 00007: val_loss improved from 0.24787 to 0.20064, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/007-0.2006.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.2852 - acc: 0.9123 - val_loss: 0.2006 - val_acc: 0.9406\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2573 - acc: 0.9210\n",
      "Epoch 00008: val_loss improved from 0.20064 to 0.19475, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/008-0.1948.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.2574 - acc: 0.9209 - val_loss: 0.1948 - val_acc: 0.9397\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9293\n",
      "Epoch 00009: val_loss improved from 0.19475 to 0.19011, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/009-0.1901.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.2264 - acc: 0.9293 - val_loss: 0.1901 - val_acc: 0.9471\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2045 - acc: 0.9361\n",
      "Epoch 00010: val_loss did not improve from 0.19011\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.2045 - acc: 0.9360 - val_loss: 0.1994 - val_acc: 0.9422\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1930 - acc: 0.9396\n",
      "Epoch 00011: val_loss did not improve from 0.19011\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.1930 - acc: 0.9396 - val_loss: 0.1979 - val_acc: 0.9427\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9459\n",
      "Epoch 00012: val_loss did not improve from 0.19011\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.1705 - acc: 0.9459 - val_loss: 0.2168 - val_acc: 0.9408\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1674 - acc: 0.9474\n",
      "Epoch 00013: val_loss improved from 0.19011 to 0.17908, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/013-0.1791.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.1674 - acc: 0.9474 - val_loss: 0.1791 - val_acc: 0.9443\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9538\n",
      "Epoch 00014: val_loss improved from 0.17908 to 0.17252, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/014-0.1725.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.1443 - acc: 0.9538 - val_loss: 0.1725 - val_acc: 0.9527\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9578\n",
      "Epoch 00015: val_loss improved from 0.17252 to 0.16120, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/015-0.1612.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.1352 - acc: 0.9578 - val_loss: 0.1612 - val_acc: 0.9541\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9564\n",
      "Epoch 00016: val_loss improved from 0.16120 to 0.15725, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/016-0.1572.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.1399 - acc: 0.9564 - val_loss: 0.1572 - val_acc: 0.9520\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9655\n",
      "Epoch 00017: val_loss did not improve from 0.15725\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.1088 - acc: 0.9655 - val_loss: 0.2003 - val_acc: 0.9420\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9654\n",
      "Epoch 00018: val_loss did not improve from 0.15725\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.1098 - acc: 0.9654 - val_loss: 0.1736 - val_acc: 0.9534\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9693\n",
      "Epoch 00019: val_loss did not improve from 0.15725\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0983 - acc: 0.9693 - val_loss: 0.1920 - val_acc: 0.9422\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9675\n",
      "Epoch 00020: val_loss did not improve from 0.15725\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.1014 - acc: 0.9675 - val_loss: 0.1632 - val_acc: 0.9548\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9709\n",
      "Epoch 00021: val_loss improved from 0.15725 to 0.15564, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/021-0.1556.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0930 - acc: 0.9709 - val_loss: 0.1556 - val_acc: 0.9585\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9758\n",
      "Epoch 00022: val_loss did not improve from 0.15564\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0753 - acc: 0.9758 - val_loss: 0.1724 - val_acc: 0.9490\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9781\n",
      "Epoch 00023: val_loss did not improve from 0.15564\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0708 - acc: 0.9781 - val_loss: 0.1881 - val_acc: 0.9525\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9746\n",
      "Epoch 00024: val_loss did not improve from 0.15564\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0800 - acc: 0.9746 - val_loss: 0.1601 - val_acc: 0.9569\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9812\n",
      "Epoch 00025: val_loss improved from 0.15564 to 0.15096, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/025-0.1510.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0620 - acc: 0.9813 - val_loss: 0.1510 - val_acc: 0.9560\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9815\n",
      "Epoch 00026: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0587 - acc: 0.9815 - val_loss: 0.2056 - val_acc: 0.9499\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9834\n",
      "Epoch 00027: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0554 - acc: 0.9834 - val_loss: 0.1623 - val_acc: 0.9555\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9855\n",
      "Epoch 00028: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0491 - acc: 0.9855 - val_loss: 0.2082 - val_acc: 0.9411\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9831\n",
      "Epoch 00029: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0534 - acc: 0.9831 - val_loss: 0.1779 - val_acc: 0.9539\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9858\n",
      "Epoch 00030: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0469 - acc: 0.9858 - val_loss: 0.2222 - val_acc: 0.9441\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9869\n",
      "Epoch 00031: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0432 - acc: 0.9869 - val_loss: 0.2202 - val_acc: 0.9413\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9837\n",
      "Epoch 00032: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0513 - acc: 0.9838 - val_loss: 0.1797 - val_acc: 0.9536\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9900\n",
      "Epoch 00033: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0335 - acc: 0.9900 - val_loss: 0.1794 - val_acc: 0.9520\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9889\n",
      "Epoch 00034: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0365 - acc: 0.9889 - val_loss: 0.2165 - val_acc: 0.9485\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9869\n",
      "Epoch 00035: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0418 - acc: 0.9869 - val_loss: 0.2195 - val_acc: 0.9434\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9868\n",
      "Epoch 00036: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0405 - acc: 0.9868 - val_loss: 0.2211 - val_acc: 0.9436\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9885\n",
      "Epoch 00037: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0399 - acc: 0.9885 - val_loss: 0.2021 - val_acc: 0.9476\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9926\n",
      "Epoch 00038: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0264 - acc: 0.9926 - val_loss: 0.2796 - val_acc: 0.9397\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9914\n",
      "Epoch 00039: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0290 - acc: 0.9914 - val_loss: 0.2205 - val_acc: 0.9478\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9914\n",
      "Epoch 00040: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0287 - acc: 0.9914 - val_loss: 0.2137 - val_acc: 0.9499\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9917\n",
      "Epoch 00041: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0271 - acc: 0.9917 - val_loss: 0.2610 - val_acc: 0.9415\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9916\n",
      "Epoch 00042: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0285 - acc: 0.9916 - val_loss: 0.1993 - val_acc: 0.9525\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9916\n",
      "Epoch 00043: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0264 - acc: 0.9916 - val_loss: 0.2075 - val_acc: 0.9497\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9933\n",
      "Epoch 00044: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.0222 - acc: 0.9933 - val_loss: 0.2535 - val_acc: 0.9401\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9900\n",
      "Epoch 00045: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.0320 - acc: 0.9900 - val_loss: 0.2035 - val_acc: 0.9529\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9937\n",
      "Epoch 00046: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0211 - acc: 0.9936 - val_loss: 0.2211 - val_acc: 0.9485\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9859\n",
      "Epoch 00047: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0435 - acc: 0.9859 - val_loss: 0.1946 - val_acc: 0.9529\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9923\n",
      "Epoch 00048: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0262 - acc: 0.9923 - val_loss: 0.2248 - val_acc: 0.9443\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9955\n",
      "Epoch 00049: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0158 - acc: 0.9955 - val_loss: 0.2023 - val_acc: 0.9539\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9943\n",
      "Epoch 00050: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0194 - acc: 0.9943 - val_loss: 0.2152 - val_acc: 0.9460\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9935\n",
      "Epoch 00051: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0216 - acc: 0.9935 - val_loss: 0.2457 - val_acc: 0.9441\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9954\n",
      "Epoch 00052: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.0158 - acc: 0.9954 - val_loss: 0.2437 - val_acc: 0.9415\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9930\n",
      "Epoch 00053: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.0223 - acc: 0.9930 - val_loss: 0.2148 - val_acc: 0.9527\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9937\n",
      "Epoch 00054: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0196 - acc: 0.9937 - val_loss: 0.2488 - val_acc: 0.9499\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9944\n",
      "Epoch 00055: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0192 - acc: 0.9944 - val_loss: 0.2403 - val_acc: 0.9471\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9940\n",
      "Epoch 00056: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0199 - acc: 0.9940 - val_loss: 0.2741 - val_acc: 0.9383\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9921\n",
      "Epoch 00057: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0248 - acc: 0.9921 - val_loss: 0.2196 - val_acc: 0.9502\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9942\n",
      "Epoch 00058: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0195 - acc: 0.9942 - val_loss: 0.2259 - val_acc: 0.9478\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9948\n",
      "Epoch 00059: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0172 - acc: 0.9948 - val_loss: 0.2188 - val_acc: 0.9509\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9954\n",
      "Epoch 00060: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0162 - acc: 0.9954 - val_loss: 0.2209 - val_acc: 0.9490\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9890\n",
      "Epoch 00061: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0344 - acc: 0.9890 - val_loss: 0.1972 - val_acc: 0.9539\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9938\n",
      "Epoch 00062: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0205 - acc: 0.9938 - val_loss: 0.1917 - val_acc: 0.9588\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9969\n",
      "Epoch 00063: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0116 - acc: 0.9969 - val_loss: 0.2247 - val_acc: 0.9543\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9915\n",
      "Epoch 00064: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0267 - acc: 0.9915 - val_loss: 0.2038 - val_acc: 0.9490\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9910\n",
      "Epoch 00065: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.0302 - acc: 0.9910 - val_loss: 0.2148 - val_acc: 0.9529\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9935\n",
      "Epoch 00066: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0216 - acc: 0.9935 - val_loss: 0.1985 - val_acc: 0.9557\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9971\n",
      "Epoch 00067: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0102 - acc: 0.9971 - val_loss: 0.2003 - val_acc: 0.9567\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9979\n",
      "Epoch 00068: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.0080 - acc: 0.9979 - val_loss: 0.2176 - val_acc: 0.9571\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9951\n",
      "Epoch 00069: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.0159 - acc: 0.9951 - val_loss: 0.2391 - val_acc: 0.9513\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9934\n",
      "Epoch 00070: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.0208 - acc: 0.9934 - val_loss: 0.2250 - val_acc: 0.9502\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9965\n",
      "Epoch 00071: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.0124 - acc: 0.9965 - val_loss: 0.2056 - val_acc: 0.9569\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9941\n",
      "Epoch 00072: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0162 - acc: 0.9941 - val_loss: 0.2295 - val_acc: 0.9569\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9972\n",
      "Epoch 00073: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0099 - acc: 0.9972 - val_loss: 0.2451 - val_acc: 0.9483\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9957\n",
      "Epoch 00074: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 166s 4ms/sample - loss: 0.0147 - acc: 0.9957 - val_loss: 0.3041 - val_acc: 0.9392\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9949\n",
      "Epoch 00075: val_loss did not improve from 0.15096\n",
      "36805/36805 [==============================] - 165s 4ms/sample - loss: 0.0162 - acc: 0.9949 - val_loss: 0.2189 - val_acc: 0.9520\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2280 - acc: 0.9317\n",
      "Loss: 0.22803634875381476 Accuracy: 0.93167186\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_conv_3_VGG_DO_BN'\n",
    "\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,397,136\n",
      "Trainable params: 16,396,880\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 5.3634 - acc: 0.3448\n",
      "Loss: 5.3634026266951675 Accuracy: 0.34475598\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,499,344\n",
      "Trainable params: 5,498,832\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 3.0365 - acc: 0.3452\n",
      "Loss: 3.036466135092366 Accuracy: 0.34517133\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,883,216\n",
      "Trainable params: 1,882,448\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 1.7968 - acc: 0.5221\n",
      "Loss: 1.7968388077625976 Accuracy: 0.5221184\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 694,992\n",
      "Trainable params: 693,968\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 1.2333 - acc: 0.6496\n",
      "Loss: 1.2332667967240758 Accuracy: 0.64963657\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 567,248\n",
      "Trainable params: 565,712\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.9801 - acc: 0.7254\n",
      "Loss: 0.9800655689194938 Accuracy: 0.72544134\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 396,496\n",
      "Trainable params: 394,448\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.8075 - acc: 0.7568\n",
      "Loss: 0.8075062907373423 Accuracy: 0.75680166\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 405,968\n",
      "Trainable params: 403,408\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.6624 - acc: 0.8098\n",
      "Loss: 0.6623675947124961 Accuracy: 0.80976117\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 476,880\n",
      "Trainable params: 473,808\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.3440 - acc: 0.9043\n",
      "Loss: 0.3440394027087052 Accuracy: 0.90425754\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 768,208\n",
      "Trainable params: 764,112\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.2280 - acc: 0.9317\n",
      "Loss: 0.22803634875381476 Accuracy: 0.93167186\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,397,136\n",
      "Trainable params: 16,396,880\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 6.5744 - acc: 0.3244\n",
      "Loss: 6.574351079788287 Accuracy: 0.3244029\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,499,344\n",
      "Trainable params: 5,498,832\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 6.3917 - acc: 0.3763\n",
      "Loss: 6.391710601541236 Accuracy: 0.376324\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,883,216\n",
      "Trainable params: 1,882,448\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 3.1957 - acc: 0.5597\n",
      "Loss: 3.195725470688484 Accuracy: 0.55970925\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 694,992\n",
      "Trainable params: 693,968\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 1.6296 - acc: 0.6804\n",
      "Loss: 1.6296311777823935 Accuracy: 0.68037385\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 567,248\n",
      "Trainable params: 565,712\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 1.2726 - acc: 0.7394\n",
      "Loss: 1.2725856440089574 Accuracy: 0.73935616\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 396,496\n",
      "Trainable params: 394,448\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 1.2641 - acc: 0.7358\n",
      "Loss: 1.2641129458123896 Accuracy: 0.73582554\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 405,968\n",
      "Trainable params: 403,408\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 1.0395 - acc: 0.7865\n",
      "Loss: 1.039489242938944 Accuracy: 0.7865005\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 476,880\n",
      "Trainable params: 473,808\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.4613 - acc: 0.9026\n",
      "Loss: 0.4612602666531025 Accuracy: 0.90259606\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 768,208\n",
      "Trainable params: 764,112\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.3073 - acc: 0.9331\n",
      "Loss: 0.30725462786381363 Accuracy: 0.9331257\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
