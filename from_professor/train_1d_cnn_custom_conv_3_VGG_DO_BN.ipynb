{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_VGG_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same')) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))    \n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())        \n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,397,136\n",
      "Trainable params: 16,396,880\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,499,344\n",
      "Trainable params: 5,498,832\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,883,216\n",
      "Trainable params: 1,882,448\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 694,992\n",
      "Trainable params: 693,968\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 567,248\n",
      "Trainable params: 565,712\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 396,496\n",
      "Trainable params: 394,448\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 405,968\n",
      "Trainable params: 403,408\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 476,880\n",
      "Trainable params: 473,808\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 768,208\n",
      "Trainable params: 764,112\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7513 - acc: 0.4909\n",
      "Epoch 00001: val_loss improved from inf to 1.02341, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/001-1.0234.hdf5\n",
      "36805/36805 [==============================] - 177s 5ms/sample - loss: 1.7513 - acc: 0.4909 - val_loss: 1.0234 - val_acc: 0.6823\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8678 - acc: 0.7349\n",
      "Epoch 00002: val_loss improved from 1.02341 to 0.74881, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/002-0.7488.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.8678 - acc: 0.7350 - val_loss: 0.7488 - val_acc: 0.7829\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6031 - acc: 0.8161\n",
      "Epoch 00003: val_loss improved from 0.74881 to 0.33459, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/003-0.3346.hdf5\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.6032 - acc: 0.8161 - val_loss: 0.3346 - val_acc: 0.8994\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4651 - acc: 0.8586\n",
      "Epoch 00004: val_loss did not improve from 0.33459\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.4651 - acc: 0.8586 - val_loss: 0.5072 - val_acc: 0.8465\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3751 - acc: 0.8843\n",
      "Epoch 00005: val_loss improved from 0.33459 to 0.28097, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/005-0.2810.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.3753 - acc: 0.8842 - val_loss: 0.2810 - val_acc: 0.9194\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3256 - acc: 0.9004\n",
      "Epoch 00006: val_loss improved from 0.28097 to 0.25956, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/006-0.2596.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.3256 - acc: 0.9004 - val_loss: 0.2596 - val_acc: 0.9283\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2785 - acc: 0.9132\n",
      "Epoch 00007: val_loss improved from 0.25956 to 0.24449, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/007-0.2445.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2784 - acc: 0.9132 - val_loss: 0.2445 - val_acc: 0.9290\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2463 - acc: 0.9232\n",
      "Epoch 00008: val_loss improved from 0.24449 to 0.19501, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/008-0.1950.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2463 - acc: 0.9232 - val_loss: 0.1950 - val_acc: 0.9425\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9310\n",
      "Epoch 00009: val_loss did not improve from 0.19501\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2242 - acc: 0.9310 - val_loss: 0.2329 - val_acc: 0.9311\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9368\n",
      "Epoch 00010: val_loss improved from 0.19501 to 0.16763, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/010-0.1676.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2035 - acc: 0.9368 - val_loss: 0.1676 - val_acc: 0.9513\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9434\n",
      "Epoch 00011: val_loss did not improve from 0.16763\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1829 - acc: 0.9434 - val_loss: 0.1959 - val_acc: 0.9418\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1742 - acc: 0.9445\n",
      "Epoch 00012: val_loss did not improve from 0.16763\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1742 - acc: 0.9445 - val_loss: 0.2049 - val_acc: 0.9394\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9511\n",
      "Epoch 00013: val_loss did not improve from 0.16763\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1549 - acc: 0.9510 - val_loss: 0.1825 - val_acc: 0.9476\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9496\n",
      "Epoch 00014: val_loss did not improve from 0.16763\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1591 - acc: 0.9496 - val_loss: 0.1805 - val_acc: 0.9464\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9592\n",
      "Epoch 00015: val_loss improved from 0.16763 to 0.15682, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/015-0.1568.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1281 - acc: 0.9592 - val_loss: 0.1568 - val_acc: 0.9564\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9628\n",
      "Epoch 00016: val_loss did not improve from 0.15682\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1187 - acc: 0.9627 - val_loss: 0.1795 - val_acc: 0.9495\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1094 - acc: 0.9649\n",
      "Epoch 00017: val_loss improved from 0.15682 to 0.15576, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_DO_BN_9_conv_checkpoint/017-0.1558.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1094 - acc: 0.9648 - val_loss: 0.1558 - val_acc: 0.9564\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1081 - acc: 0.9661\n",
      "Epoch 00018: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.1082 - acc: 0.9660 - val_loss: 0.1878 - val_acc: 0.9527\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9656\n",
      "Epoch 00019: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1059 - acc: 0.9656 - val_loss: 0.1786 - val_acc: 0.9534\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9696\n",
      "Epoch 00020: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0960 - acc: 0.9695 - val_loss: 0.1741 - val_acc: 0.9476\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9750\n",
      "Epoch 00021: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0817 - acc: 0.9750 - val_loss: 0.2109 - val_acc: 0.9413\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9740\n",
      "Epoch 00022: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0828 - acc: 0.9739 - val_loss: 0.1844 - val_acc: 0.9478\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9728\n",
      "Epoch 00023: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0886 - acc: 0.9728 - val_loss: 0.1772 - val_acc: 0.9509\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9820\n",
      "Epoch 00024: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0580 - acc: 0.9820 - val_loss: 0.1607 - val_acc: 0.9550\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9783\n",
      "Epoch 00025: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0679 - acc: 0.9783 - val_loss: 0.1941 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9830\n",
      "Epoch 00026: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0567 - acc: 0.9829 - val_loss: 0.1974 - val_acc: 0.9457\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9807\n",
      "Epoch 00027: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0615 - acc: 0.9807 - val_loss: 0.1743 - val_acc: 0.9529\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9842\n",
      "Epoch 00028: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0513 - acc: 0.9842 - val_loss: 0.1666 - val_acc: 0.9541\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9868\n",
      "Epoch 00029: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0441 - acc: 0.9868 - val_loss: 0.1861 - val_acc: 0.9509\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9860\n",
      "Epoch 00030: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0459 - acc: 0.9859 - val_loss: 0.2542 - val_acc: 0.9292\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9785\n",
      "Epoch 00031: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0671 - acc: 0.9785 - val_loss: 0.1973 - val_acc: 0.9481\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9884\n",
      "Epoch 00032: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 164s 4ms/sample - loss: 0.0392 - acc: 0.9884 - val_loss: 0.1925 - val_acc: 0.9497\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9875\n",
      "Epoch 00033: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0439 - acc: 0.9874 - val_loss: 0.1821 - val_acc: 0.9553\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9836\n",
      "Epoch 00034: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0524 - acc: 0.9835 - val_loss: 0.1960 - val_acc: 0.9504\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9857\n",
      "Epoch 00035: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0455 - acc: 0.9857 - val_loss: 0.1810 - val_acc: 0.9532\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9931\n",
      "Epoch 00036: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0261 - acc: 0.9931 - val_loss: 0.1772 - val_acc: 0.9602\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9923\n",
      "Epoch 00037: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0266 - acc: 0.9923 - val_loss: 0.2091 - val_acc: 0.9497\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9904\n",
      "Epoch 00038: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0314 - acc: 0.9904 - val_loss: 0.2015 - val_acc: 0.9541\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9902\n",
      "Epoch 00039: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0326 - acc: 0.9902 - val_loss: 0.2261 - val_acc: 0.9469\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9895\n",
      "Epoch 00040: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0332 - acc: 0.9894 - val_loss: 0.2914 - val_acc: 0.9311\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9876\n",
      "Epoch 00041: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0412 - acc: 0.9876 - val_loss: 0.2134 - val_acc: 0.9495\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9887\n",
      "Epoch 00042: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0370 - acc: 0.9887 - val_loss: 0.1851 - val_acc: 0.9539\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9914\n",
      "Epoch 00043: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0294 - acc: 0.9914 - val_loss: 0.1825 - val_acc: 0.9581\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9956\n",
      "Epoch 00044: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0173 - acc: 0.9956 - val_loss: 0.2180 - val_acc: 0.9511\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9914\n",
      "Epoch 00045: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0290 - acc: 0.9914 - val_loss: 0.1906 - val_acc: 0.9555\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9933\n",
      "Epoch 00046: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0230 - acc: 0.9933 - val_loss: 0.2578 - val_acc: 0.9441\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9890\n",
      "Epoch 00047: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0357 - acc: 0.9890 - val_loss: 0.2042 - val_acc: 0.9513\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9955\n",
      "Epoch 00048: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0165 - acc: 0.9955 - val_loss: 0.2047 - val_acc: 0.9534\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9943\n",
      "Epoch 00049: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0197 - acc: 0.9943 - val_loss: 0.1982 - val_acc: 0.9569\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9926\n",
      "Epoch 00050: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0251 - acc: 0.9926 - val_loss: 0.2530 - val_acc: 0.9401\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9886\n",
      "Epoch 00051: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0367 - acc: 0.9886 - val_loss: 0.1966 - val_acc: 0.9539\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9952\n",
      "Epoch 00052: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0168 - acc: 0.9952 - val_loss: 0.1839 - val_acc: 0.9567\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9959\n",
      "Epoch 00053: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0135 - acc: 0.9959 - val_loss: 0.1896 - val_acc: 0.9562\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9933\n",
      "Epoch 00054: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0221 - acc: 0.9933 - val_loss: 0.2624 - val_acc: 0.9427\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9946\n",
      "Epoch 00055: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0188 - acc: 0.9945 - val_loss: 0.2144 - val_acc: 0.9509\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9879\n",
      "Epoch 00056: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0384 - acc: 0.9879 - val_loss: 0.2224 - val_acc: 0.9513\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9933\n",
      "Epoch 00057: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0220 - acc: 0.9932 - val_loss: 0.1975 - val_acc: 0.9536\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9942\n",
      "Epoch 00058: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0177 - acc: 0.9942 - val_loss: 0.2100 - val_acc: 0.9520\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9960\n",
      "Epoch 00059: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0160 - acc: 0.9960 - val_loss: 0.2035 - val_acc: 0.9557\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9957\n",
      "Epoch 00060: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0146 - acc: 0.9957 - val_loss: 0.2141 - val_acc: 0.9520\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9945\n",
      "Epoch 00061: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0179 - acc: 0.9945 - val_loss: 0.2978 - val_acc: 0.9331\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9942\n",
      "Epoch 00062: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0175 - acc: 0.9942 - val_loss: 0.2252 - val_acc: 0.9515\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9945\n",
      "Epoch 00063: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0173 - acc: 0.9945 - val_loss: 0.2262 - val_acc: 0.9518\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9933\n",
      "Epoch 00064: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0218 - acc: 0.9933 - val_loss: 0.2529 - val_acc: 0.9488\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9931\n",
      "Epoch 00065: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0212 - acc: 0.9930 - val_loss: 0.2123 - val_acc: 0.9525\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9905\n",
      "Epoch 00066: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 162s 4ms/sample - loss: 0.0309 - acc: 0.9905 - val_loss: 0.2139 - val_acc: 0.9499\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9964\n",
      "Epoch 00067: val_loss did not improve from 0.15576\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0121 - acc: 0.9964 - val_loss: 0.2059 - val_acc: 0.9550\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.2176 - acc: 0.9418\n",
      "Loss: 0.21759956766264213 Accuracy: 0.9418484\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(9, 10):\n",
    "    model_name = '1D_CNN_custom_conv_3_VGG_DO_BN_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,397,136\n",
      "Trainable params: 16,396,880\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 723us/sample - loss: 5.5422 - acc: 0.3171\n",
      "Loss: 5.542177775393889 Accuracy: 0.31713396\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,499,344\n",
      "Trainable params: 5,498,832\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.9564 - acc: 0.3389\n",
      "Loss: 2.9564274548741514 Accuracy: 0.3389408\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,883,216\n",
      "Trainable params: 1,882,448\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 1.7631 - acc: 0.4984\n",
      "Loss: 1.7630936730316495 Accuracy: 0.49844238\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 694,992\n",
      "Trainable params: 693,968\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 1.2412 - acc: 0.6544\n",
      "Loss: 1.241225696191857 Accuracy: 0.6544133\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 567,248\n",
      "Trainable params: 565,712\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.9833 - acc: 0.7344\n",
      "Loss: 0.9832576593753581 Accuracy: 0.7343718\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_120 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_121 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_122 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_123 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_124 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_125 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_126 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_127 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_128 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_129 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_130 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_131 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 396,496\n",
      "Trainable params: 394,448\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.8658 - acc: 0.7502\n",
      "Loss: 0.8657846676350135 Accuracy: 0.75015575\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_132 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_133 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_134 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_135 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_136 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_137 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_138 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_139 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_140 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_141 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_142 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_143 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_144 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_145 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 405,968\n",
      "Trainable params: 403,408\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.7129 - acc: 0.8044\n",
      "Loss: 0.7128525783711134 Accuracy: 0.80436134\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_146 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_147 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_148 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_149 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_150 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_151 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_152 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_153 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_154 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_155 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_156 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_157 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_158 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_159 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_160 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_161 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 476,880\n",
      "Trainable params: 473,808\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.3030 - acc: 0.9136\n",
      "Loss: 0.3030172028769338 Accuracy: 0.9136033\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_162 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_163 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_164 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_165 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_166 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_167 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_168 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_169 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_170 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_171 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_172 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_173 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_174 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_175 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_176 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_177 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_178 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_179 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 768,208\n",
      "Trainable params: 764,112\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2176 - acc: 0.9418\n",
      "Loss: 0.21759956766264213 Accuracy: 0.9418484\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
