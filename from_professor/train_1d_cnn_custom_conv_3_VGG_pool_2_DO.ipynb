{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_VGG_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                      input_shape=input_shape))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, \n",
    "                          padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, \n",
    "                          padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                8192016   \n",
      "=================================================================\n",
      "Total params: 8,229,328\n",
      "Trainable params: 8,229,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                4096016   \n",
      "=================================================================\n",
      "Total params: 4,158,032\n",
      "Trainable params: 4,158,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,134,736\n",
      "Trainable params: 2,134,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,208,720\n",
      "Trainable params: 2,208,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,283,280\n",
      "Trainable params: 1,283,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 869,840\n",
      "Trainable params: 869,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 712,400\n",
      "Trainable params: 712,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                253968    \n",
      "=================================================================\n",
      "Total params: 1,005,776\n",
      "Trainable params: 1,005,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 1,272,528\n",
      "Trainable params: 1,272,528\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                61456     \n",
      "=================================================================\n",
      "Total params: 1,600,720\n",
      "Trainable params: 1,600,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,961,680\n",
      "Trainable params: 1,961,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_156 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_179 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_180 (Conv1D)          (None, 7, 512)            393728    \n",
      "_________________________________________________________________\n",
      "activation_180 (Activation)  (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_181 (Conv1D)          (None, 7, 512)            786944    \n",
      "_________________________________________________________________\n",
      "activation_181 (Activation)  (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                24592     \n",
      "=================================================================\n",
      "Total params: 3,138,256\n",
      "Trainable params: 3,138,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 14):\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2398 - acc: 0.2848\n",
      "Epoch 00001: val_loss improved from inf to 1.96867, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_3_conv_checkpoint/001-1.9687.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 2.2397 - acc: 0.2848 - val_loss: 1.9687 - val_acc: 0.3564\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7846 - acc: 0.4557\n",
      "Epoch 00002: val_loss improved from 1.96867 to 1.65423, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_3_conv_checkpoint/002-1.6542.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.7845 - acc: 0.4557 - val_loss: 1.6542 - val_acc: 0.5038\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5133 - acc: 0.5477\n",
      "Epoch 00003: val_loss improved from 1.65423 to 1.55064, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_3_conv_checkpoint/003-1.5506.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.5133 - acc: 0.5477 - val_loss: 1.5506 - val_acc: 0.5246\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2385 - acc: 0.6331\n",
      "Epoch 00004: val_loss improved from 1.55064 to 1.53850, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_3_conv_checkpoint/004-1.5385.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.2386 - acc: 0.6330 - val_loss: 1.5385 - val_acc: 0.5285\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9575 - acc: 0.7150\n",
      "Epoch 00005: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9575 - acc: 0.7150 - val_loss: 1.5696 - val_acc: 0.5348\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7243 - acc: 0.7849\n",
      "Epoch 00006: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7243 - acc: 0.7849 - val_loss: 1.7109 - val_acc: 0.5311\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5506 - acc: 0.8339\n",
      "Epoch 00007: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5505 - acc: 0.8339 - val_loss: 1.9232 - val_acc: 0.5080\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4205 - acc: 0.8745\n",
      "Epoch 00008: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4205 - acc: 0.8745 - val_loss: 2.0962 - val_acc: 0.5020\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3307 - acc: 0.9017\n",
      "Epoch 00009: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3309 - acc: 0.9016 - val_loss: 2.2960 - val_acc: 0.5073\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2691 - acc: 0.9190\n",
      "Epoch 00010: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2691 - acc: 0.9190 - val_loss: 2.3798 - val_acc: 0.5178\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2050 - acc: 0.9395\n",
      "Epoch 00011: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2050 - acc: 0.9395 - val_loss: 2.5887 - val_acc: 0.5204\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9508\n",
      "Epoch 00012: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1747 - acc: 0.9508 - val_loss: 2.6813 - val_acc: 0.5234\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1555 - acc: 0.9552\n",
      "Epoch 00013: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1554 - acc: 0.9552 - val_loss: 2.8024 - val_acc: 0.5148\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9602\n",
      "Epoch 00014: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1397 - acc: 0.9602 - val_loss: 2.8640 - val_acc: 0.5255\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9642\n",
      "Epoch 00015: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1297 - acc: 0.9642 - val_loss: 2.8766 - val_acc: 0.5299\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9698\n",
      "Epoch 00016: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1145 - acc: 0.9698 - val_loss: 2.9574 - val_acc: 0.5297\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9732\n",
      "Epoch 00017: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1002 - acc: 0.9732 - val_loss: 3.1156 - val_acc: 0.5192\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9730\n",
      "Epoch 00018: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1032 - acc: 0.9730 - val_loss: 2.9747 - val_acc: 0.5351\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9753\n",
      "Epoch 00019: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0921 - acc: 0.9753 - val_loss: 3.1561 - val_acc: 0.5232\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9753\n",
      "Epoch 00020: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0974 - acc: 0.9753 - val_loss: 3.1171 - val_acc: 0.5269\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9798\n",
      "Epoch 00021: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0803 - acc: 0.9798 - val_loss: 3.1472 - val_acc: 0.5379\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9789\n",
      "Epoch 00022: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0827 - acc: 0.9789 - val_loss: 3.1524 - val_acc: 0.5348\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9804\n",
      "Epoch 00023: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0785 - acc: 0.9804 - val_loss: 3.1084 - val_acc: 0.5437\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9820\n",
      "Epoch 00024: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0736 - acc: 0.9820 - val_loss: 3.2226 - val_acc: 0.5374\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9821\n",
      "Epoch 00025: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0736 - acc: 0.9821 - val_loss: 3.1477 - val_acc: 0.5460\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9845\n",
      "Epoch 00026: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0679 - acc: 0.9845 - val_loss: 3.1940 - val_acc: 0.5376\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9851\n",
      "Epoch 00027: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0647 - acc: 0.9851 - val_loss: 3.2952 - val_acc: 0.5430\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9848\n",
      "Epoch 00028: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0638 - acc: 0.9848 - val_loss: 3.3138 - val_acc: 0.5367\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9870\n",
      "Epoch 00029: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0580 - acc: 0.9870 - val_loss: 3.2559 - val_acc: 0.5460\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9856\n",
      "Epoch 00030: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0612 - acc: 0.9856 - val_loss: 3.3870 - val_acc: 0.5486\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9864\n",
      "Epoch 00031: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0595 - acc: 0.9864 - val_loss: 3.3154 - val_acc: 0.5448\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9857\n",
      "Epoch 00032: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0603 - acc: 0.9857 - val_loss: 3.3602 - val_acc: 0.5504\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9869\n",
      "Epoch 00033: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0562 - acc: 0.9869 - val_loss: 3.4042 - val_acc: 0.5446\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9868\n",
      "Epoch 00034: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0578 - acc: 0.9868 - val_loss: 3.2483 - val_acc: 0.5579\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9892\n",
      "Epoch 00035: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0515 - acc: 0.9892 - val_loss: 3.2835 - val_acc: 0.5556\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9875\n",
      "Epoch 00036: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0540 - acc: 0.9875 - val_loss: 3.2550 - val_acc: 0.5476\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9894\n",
      "Epoch 00037: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0488 - acc: 0.9894 - val_loss: 3.5594 - val_acc: 0.5404\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9898\n",
      "Epoch 00038: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0488 - acc: 0.9898 - val_loss: 3.4319 - val_acc: 0.5446\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9896\n",
      "Epoch 00039: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0501 - acc: 0.9896 - val_loss: 3.4861 - val_acc: 0.5493\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9893\n",
      "Epoch 00040: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0475 - acc: 0.9893 - val_loss: 3.4378 - val_acc: 0.5530\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9902\n",
      "Epoch 00041: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0460 - acc: 0.9902 - val_loss: 3.4068 - val_acc: 0.5397\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9904\n",
      "Epoch 00042: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0469 - acc: 0.9904 - val_loss: 3.4177 - val_acc: 0.5686\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9902\n",
      "Epoch 00043: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0454 - acc: 0.9902 - val_loss: 3.4379 - val_acc: 0.5476\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9910\n",
      "Epoch 00044: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0436 - acc: 0.9910 - val_loss: 3.3066 - val_acc: 0.5539\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9917\n",
      "Epoch 00045: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0420 - acc: 0.9917 - val_loss: 3.4246 - val_acc: 0.5486\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9899\n",
      "Epoch 00046: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0463 - acc: 0.9899 - val_loss: 3.3586 - val_acc: 0.5563\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9920\n",
      "Epoch 00047: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0399 - acc: 0.9920 - val_loss: 3.3480 - val_acc: 0.5621\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9914\n",
      "Epoch 00048: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0423 - acc: 0.9914 - val_loss: 3.6710 - val_acc: 0.5376\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9913\n",
      "Epoch 00049: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0431 - acc: 0.9913 - val_loss: 3.4656 - val_acc: 0.5542\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9926\n",
      "Epoch 00050: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0390 - acc: 0.9926 - val_loss: 3.4200 - val_acc: 0.5639\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9933\n",
      "Epoch 00051: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0360 - acc: 0.9932 - val_loss: 3.4410 - val_acc: 0.5511\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9920\n",
      "Epoch 00052: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0388 - acc: 0.9920 - val_loss: 3.4044 - val_acc: 0.5709\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9930\n",
      "Epoch 00053: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0368 - acc: 0.9930 - val_loss: 3.3677 - val_acc: 0.5621\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9938\n",
      "Epoch 00054: val_loss did not improve from 1.53850\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0341 - acc: 0.9938 - val_loss: 3.4559 - val_acc: 0.5560\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 933us/sample - loss: 1.6931 - acc: 0.4916\n",
      "Loss: 1.6931262289376026 Accuracy: 0.49158877\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2054 - acc: 0.3004\n",
      "Epoch 00001: val_loss improved from inf to 1.77225, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_4_conv_checkpoint/001-1.7722.hdf5\n",
      "36805/36805 [==============================] - 99s 3ms/sample - loss: 2.2053 - acc: 0.3004 - val_loss: 1.7722 - val_acc: 0.4493\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5834 - acc: 0.5095\n",
      "Epoch 00002: val_loss improved from 1.77225 to 1.45734, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_4_conv_checkpoint/002-1.4573.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 1.5834 - acc: 0.5095 - val_loss: 1.4573 - val_acc: 0.5367\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2468 - acc: 0.6177\n",
      "Epoch 00003: val_loss improved from 1.45734 to 1.34003, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_4_conv_checkpoint/003-1.3400.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 1.2468 - acc: 0.6176 - val_loss: 1.3400 - val_acc: 0.5826\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0130 - acc: 0.6903\n",
      "Epoch 00004: val_loss improved from 1.34003 to 1.31656, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_4_conv_checkpoint/004-1.3166.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 1.0129 - acc: 0.6903 - val_loss: 1.3166 - val_acc: 0.5935\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8177 - acc: 0.7514\n",
      "Epoch 00005: val_loss improved from 1.31656 to 1.29775, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_4_conv_checkpoint/005-1.2978.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.8178 - acc: 0.7514 - val_loss: 1.2978 - val_acc: 0.6031\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6505 - acc: 0.8014\n",
      "Epoch 00006: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.6504 - acc: 0.8014 - val_loss: 1.4176 - val_acc: 0.6003\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5126 - acc: 0.8408\n",
      "Epoch 00007: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.5125 - acc: 0.8408 - val_loss: 1.5266 - val_acc: 0.5998\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4029 - acc: 0.8787\n",
      "Epoch 00008: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.4029 - acc: 0.8787 - val_loss: 1.6421 - val_acc: 0.6000\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3158 - acc: 0.9027\n",
      "Epoch 00009: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.3158 - acc: 0.9027 - val_loss: 1.7361 - val_acc: 0.6070\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2584 - acc: 0.9234\n",
      "Epoch 00010: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.2583 - acc: 0.9234 - val_loss: 1.8518 - val_acc: 0.6094\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2219 - acc: 0.9331\n",
      "Epoch 00011: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.2219 - acc: 0.9331 - val_loss: 1.9683 - val_acc: 0.6096\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1847 - acc: 0.9443\n",
      "Epoch 00012: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1847 - acc: 0.9443 - val_loss: 1.9952 - val_acc: 0.6047\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1572 - acc: 0.9527\n",
      "Epoch 00013: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.1573 - acc: 0.9527 - val_loss: 2.1924 - val_acc: 0.6000\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1793 - acc: 0.9462\n",
      "Epoch 00014: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.1793 - acc: 0.9462 - val_loss: 2.0689 - val_acc: 0.6124\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9664\n",
      "Epoch 00015: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.1208 - acc: 0.9664 - val_loss: 2.1614 - val_acc: 0.6110\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9674\n",
      "Epoch 00016: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.1169 - acc: 0.9674 - val_loss: 2.1981 - val_acc: 0.6236\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9663\n",
      "Epoch 00017: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.1156 - acc: 0.9663 - val_loss: 2.1932 - val_acc: 0.6215\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9703\n",
      "Epoch 00018: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.1054 - acc: 0.9703 - val_loss: 2.2578 - val_acc: 0.6108\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9721\n",
      "Epoch 00019: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0962 - acc: 0.9722 - val_loss: 2.3677 - val_acc: 0.6189\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9746\n",
      "Epoch 00020: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0923 - acc: 0.9747 - val_loss: 2.2601 - val_acc: 0.6299\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9764\n",
      "Epoch 00021: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0864 - acc: 0.9764 - val_loss: 2.2799 - val_acc: 0.6322\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9772\n",
      "Epoch 00022: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0855 - acc: 0.9772 - val_loss: 2.3506 - val_acc: 0.6247\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9786\n",
      "Epoch 00023: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0790 - acc: 0.9786 - val_loss: 2.3982 - val_acc: 0.6259\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9775\n",
      "Epoch 00024: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0820 - acc: 0.9775 - val_loss: 2.1986 - val_acc: 0.6394\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9792\n",
      "Epoch 00025: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0769 - acc: 0.9792 - val_loss: 2.2091 - val_acc: 0.6373\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9810\n",
      "Epoch 00026: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0714 - acc: 0.9810 - val_loss: 2.2939 - val_acc: 0.6427\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9814\n",
      "Epoch 00027: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0704 - acc: 0.9814 - val_loss: 2.4967 - val_acc: 0.6217\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9817\n",
      "Epoch 00028: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0713 - acc: 0.9817 - val_loss: 2.3382 - val_acc: 0.6401\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9847\n",
      "Epoch 00029: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0626 - acc: 0.9847 - val_loss: 2.3842 - val_acc: 0.6357\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9845\n",
      "Epoch 00030: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0638 - acc: 0.9845 - val_loss: 2.4535 - val_acc: 0.6394\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9847\n",
      "Epoch 00031: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0615 - acc: 0.9847 - val_loss: 2.4279 - val_acc: 0.6375\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9843\n",
      "Epoch 00032: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0619 - acc: 0.9843 - val_loss: 2.3837 - val_acc: 0.6441\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9845\n",
      "Epoch 00033: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0605 - acc: 0.9845 - val_loss: 2.3358 - val_acc: 0.6497\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9854\n",
      "Epoch 00034: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0622 - acc: 0.9854 - val_loss: 2.2946 - val_acc: 0.6511\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9861\n",
      "Epoch 00035: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0556 - acc: 0.9861 - val_loss: 2.4567 - val_acc: 0.6422\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9863\n",
      "Epoch 00036: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0563 - acc: 0.9863 - val_loss: 2.3176 - val_acc: 0.6441\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9855\n",
      "Epoch 00037: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0576 - acc: 0.9855 - val_loss: 2.4402 - val_acc: 0.6434\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9868\n",
      "Epoch 00038: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0546 - acc: 0.9868 - val_loss: 2.3901 - val_acc: 0.6343\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9867\n",
      "Epoch 00039: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0539 - acc: 0.9867 - val_loss: 2.4516 - val_acc: 0.6490\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9877\n",
      "Epoch 00040: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0504 - acc: 0.9877 - val_loss: 2.4534 - val_acc: 0.6422\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9865\n",
      "Epoch 00041: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0560 - acc: 0.9865 - val_loss: 2.3909 - val_acc: 0.6553\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9880\n",
      "Epoch 00042: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0505 - acc: 0.9879 - val_loss: 2.3736 - val_acc: 0.6504\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9886\n",
      "Epoch 00043: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0472 - acc: 0.9886 - val_loss: 2.3703 - val_acc: 0.6546\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9895\n",
      "Epoch 00044: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0445 - acc: 0.9895 - val_loss: 2.4184 - val_acc: 0.6518\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9892\n",
      "Epoch 00045: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0477 - acc: 0.9892 - val_loss: 2.3954 - val_acc: 0.6546\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9893\n",
      "Epoch 00046: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0449 - acc: 0.9893 - val_loss: 2.4344 - val_acc: 0.6452\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9881\n",
      "Epoch 00047: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0499 - acc: 0.9881 - val_loss: 2.2881 - val_acc: 0.6604\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9894\n",
      "Epoch 00048: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 0.0452 - acc: 0.9894 - val_loss: 2.4008 - val_acc: 0.6497\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9903\n",
      "Epoch 00049: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0447 - acc: 0.9903 - val_loss: 2.3226 - val_acc: 0.6604\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9911\n",
      "Epoch 00050: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0401 - acc: 0.9911 - val_loss: 2.4461 - val_acc: 0.6518\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9902\n",
      "Epoch 00051: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0440 - acc: 0.9902 - val_loss: 2.3416 - val_acc: 0.6548\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9909\n",
      "Epoch 00052: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0430 - acc: 0.9909 - val_loss: 2.3971 - val_acc: 0.6385\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9911\n",
      "Epoch 00053: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0404 - acc: 0.9911 - val_loss: 2.4634 - val_acc: 0.6522\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9908\n",
      "Epoch 00054: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0417 - acc: 0.9908 - val_loss: 2.4586 - val_acc: 0.6485\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9912\n",
      "Epoch 00055: val_loss did not improve from 1.29775\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0409 - acc: 0.9913 - val_loss: 2.4347 - val_acc: 0.6667\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.3789 - acc: 0.5786\n",
      "Loss: 1.3788966798584286 Accuracy: 0.5786085\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2220 - acc: 0.2878\n",
      "Epoch 00001: val_loss improved from inf to 1.71748, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_5_conv_checkpoint/001-1.7175.hdf5\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 2.2219 - acc: 0.2878 - val_loss: 1.7175 - val_acc: 0.4570\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5387 - acc: 0.5159\n",
      "Epoch 00002: val_loss improved from 1.71748 to 1.32899, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_5_conv_checkpoint/002-1.3290.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 1.5387 - acc: 0.5159 - val_loss: 1.3290 - val_acc: 0.5819\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2207 - acc: 0.6299\n",
      "Epoch 00003: val_loss improved from 1.32899 to 1.26913, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_5_conv_checkpoint/003-1.2691.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 1.2207 - acc: 0.6299 - val_loss: 1.2691 - val_acc: 0.6061\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0004 - acc: 0.7022\n",
      "Epoch 00004: val_loss improved from 1.26913 to 1.13771, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_5_conv_checkpoint/004-1.1377.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 1.0005 - acc: 0.7022 - val_loss: 1.1377 - val_acc: 0.6513\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8199 - acc: 0.7523\n",
      "Epoch 00005: val_loss improved from 1.13771 to 1.00672, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_5_conv_checkpoint/005-1.0067.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.8198 - acc: 0.7523 - val_loss: 1.0067 - val_acc: 0.6953\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6582 - acc: 0.8017\n",
      "Epoch 00006: val_loss improved from 1.00672 to 0.97498, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_5_conv_checkpoint/006-0.9750.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.6581 - acc: 0.8017 - val_loss: 0.9750 - val_acc: 0.7081\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5151 - acc: 0.8460\n",
      "Epoch 00007: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.5151 - acc: 0.8460 - val_loss: 0.9873 - val_acc: 0.7165\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3893 - acc: 0.8840\n",
      "Epoch 00008: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.3894 - acc: 0.8839 - val_loss: 1.1167 - val_acc: 0.7025\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2966 - acc: 0.9127\n",
      "Epoch 00009: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.2966 - acc: 0.9128 - val_loss: 1.1286 - val_acc: 0.7088\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2305 - acc: 0.9298\n",
      "Epoch 00010: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.2305 - acc: 0.9298 - val_loss: 1.1772 - val_acc: 0.7181\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1827 - acc: 0.9442\n",
      "Epoch 00011: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1826 - acc: 0.9442 - val_loss: 1.3261 - val_acc: 0.7135\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1554 - acc: 0.9538\n",
      "Epoch 00012: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1554 - acc: 0.9538 - val_loss: 1.3403 - val_acc: 0.7207\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9623\n",
      "Epoch 00013: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1267 - acc: 0.9623 - val_loss: 1.4144 - val_acc: 0.7156\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9664\n",
      "Epoch 00014: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1137 - acc: 0.9664 - val_loss: 1.4677 - val_acc: 0.7235\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9699\n",
      "Epoch 00015: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1031 - acc: 0.9699 - val_loss: 1.4963 - val_acc: 0.7195\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9739\n",
      "Epoch 00016: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0912 - acc: 0.9739 - val_loss: 1.6177 - val_acc: 0.7195\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9727\n",
      "Epoch 00017: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0942 - acc: 0.9727 - val_loss: 1.4608 - val_acc: 0.7256\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9765\n",
      "Epoch 00018: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0818 - acc: 0.9765 - val_loss: 1.6084 - val_acc: 0.7119\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9784\n",
      "Epoch 00019: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0771 - acc: 0.9784 - val_loss: 1.6214 - val_acc: 0.7154\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9790\n",
      "Epoch 00020: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0740 - acc: 0.9791 - val_loss: 1.5102 - val_acc: 0.7307\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9805\n",
      "Epoch 00021: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0720 - acc: 0.9805 - val_loss: 1.6078 - val_acc: 0.7340\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9818\n",
      "Epoch 00022: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0681 - acc: 0.9818 - val_loss: 1.5491 - val_acc: 0.7310\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9799\n",
      "Epoch 00023: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0707 - acc: 0.9799 - val_loss: 1.6033 - val_acc: 0.7384\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9853\n",
      "Epoch 00024: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0580 - acc: 0.9853 - val_loss: 1.5617 - val_acc: 0.7382\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9848\n",
      "Epoch 00025: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0590 - acc: 0.9848 - val_loss: 1.6707 - val_acc: 0.7331\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9836\n",
      "Epoch 00026: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0602 - acc: 0.9836 - val_loss: 1.8327 - val_acc: 0.7172\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9860\n",
      "Epoch 00027: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0554 - acc: 0.9860 - val_loss: 1.6761 - val_acc: 0.7312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9864\n",
      "Epoch 00028: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0541 - acc: 0.9864 - val_loss: 1.5507 - val_acc: 0.7459\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9874\n",
      "Epoch 00029: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0481 - acc: 0.9874 - val_loss: 1.6789 - val_acc: 0.7438\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9857\n",
      "Epoch 00030: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0540 - acc: 0.9857 - val_loss: 1.6261 - val_acc: 0.7375\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9877\n",
      "Epoch 00031: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0482 - acc: 0.9877 - val_loss: 1.7170 - val_acc: 0.7319\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9877\n",
      "Epoch 00032: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0504 - acc: 0.9877 - val_loss: 1.6227 - val_acc: 0.7459\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9874\n",
      "Epoch 00033: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0504 - acc: 0.9874 - val_loss: 1.6118 - val_acc: 0.7477\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9895\n",
      "Epoch 00034: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0448 - acc: 0.9895 - val_loss: 1.6950 - val_acc: 0.7421\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9891\n",
      "Epoch 00035: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0451 - acc: 0.9891 - val_loss: 1.6079 - val_acc: 0.7480\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9893\n",
      "Epoch 00036: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0459 - acc: 0.9893 - val_loss: 1.7052 - val_acc: 0.7396\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9898\n",
      "Epoch 00037: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0432 - acc: 0.9898 - val_loss: 1.6391 - val_acc: 0.7480\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9899\n",
      "Epoch 00038: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0430 - acc: 0.9899 - val_loss: 1.7155 - val_acc: 0.7456\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9905\n",
      "Epoch 00039: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0415 - acc: 0.9905 - val_loss: 1.6968 - val_acc: 0.7405\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9885\n",
      "Epoch 00040: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0476 - acc: 0.9885 - val_loss: 1.5995 - val_acc: 0.7498\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9911\n",
      "Epoch 00041: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0380 - acc: 0.9911 - val_loss: 1.7133 - val_acc: 0.7270\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9903\n",
      "Epoch 00042: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0409 - acc: 0.9903 - val_loss: 1.7151 - val_acc: 0.7468\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9913\n",
      "Epoch 00043: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0398 - acc: 0.9913 - val_loss: 1.7273 - val_acc: 0.7279\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9911\n",
      "Epoch 00044: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0393 - acc: 0.9911 - val_loss: 1.6433 - val_acc: 0.7466\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9918\n",
      "Epoch 00045: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0383 - acc: 0.9918 - val_loss: 1.6885 - val_acc: 0.7382\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9909\n",
      "Epoch 00046: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0380 - acc: 0.9909 - val_loss: 1.8636 - val_acc: 0.7342\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9916\n",
      "Epoch 00047: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0376 - acc: 0.9916 - val_loss: 1.6169 - val_acc: 0.7515\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9905\n",
      "Epoch 00048: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0402 - acc: 0.9905 - val_loss: 1.6020 - val_acc: 0.7526\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9923\n",
      "Epoch 00049: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0350 - acc: 0.9923 - val_loss: 1.6488 - val_acc: 0.7501\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9917\n",
      "Epoch 00050: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0354 - acc: 0.9917 - val_loss: 1.6964 - val_acc: 0.7563\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9927\n",
      "Epoch 00051: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0355 - acc: 0.9927 - val_loss: 1.6466 - val_acc: 0.7491\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9928\n",
      "Epoch 00052: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0353 - acc: 0.9928 - val_loss: 1.7983 - val_acc: 0.7526\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9929\n",
      "Epoch 00053: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0344 - acc: 0.9929 - val_loss: 1.7102 - val_acc: 0.7496\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9931\n",
      "Epoch 00054: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0329 - acc: 0.9931 - val_loss: 1.6886 - val_acc: 0.7491\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9934\n",
      "Epoch 00055: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0317 - acc: 0.9934 - val_loss: 1.7548 - val_acc: 0.7386\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9907\n",
      "Epoch 00056: val_loss did not improve from 0.97498\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0400 - acc: 0.9907 - val_loss: 1.5552 - val_acc: 0.7566\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.0985 - acc: 0.6766\n",
      "Loss: 1.0985290856623824 Accuracy: 0.6766355\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3425 - acc: 0.2413\n",
      "Epoch 00001: val_loss improved from inf to 1.95947, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_6_conv_checkpoint/001-1.9595.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 2.3424 - acc: 0.2414 - val_loss: 1.9595 - val_acc: 0.3611\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7210 - acc: 0.4505\n",
      "Epoch 00002: val_loss improved from 1.95947 to 1.51117, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_6_conv_checkpoint/002-1.5112.hdf5\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 1.7209 - acc: 0.4506 - val_loss: 1.5112 - val_acc: 0.5164\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3984 - acc: 0.5630\n",
      "Epoch 00003: val_loss improved from 1.51117 to 1.22458, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_6_conv_checkpoint/003-1.2246.hdf5\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 1.3984 - acc: 0.5630 - val_loss: 1.2246 - val_acc: 0.6271\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1839 - acc: 0.6389\n",
      "Epoch 00004: val_loss improved from 1.22458 to 1.14536, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_6_conv_checkpoint/004-1.1454.hdf5\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 1.1838 - acc: 0.6389 - val_loss: 1.1454 - val_acc: 0.6541\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0288 - acc: 0.6887\n",
      "Epoch 00005: val_loss improved from 1.14536 to 1.01067, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_6_conv_checkpoint/005-1.0107.hdf5\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 1.0287 - acc: 0.6887 - val_loss: 1.0107 - val_acc: 0.6988\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9091 - acc: 0.7282\n",
      "Epoch 00006: val_loss improved from 1.01067 to 0.98098, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_6_conv_checkpoint/006-0.9810.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.9091 - acc: 0.7282 - val_loss: 0.9810 - val_acc: 0.6981\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8021 - acc: 0.7608\n",
      "Epoch 00007: val_loss improved from 0.98098 to 0.90869, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_6_conv_checkpoint/007-0.9087.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.8021 - acc: 0.7608 - val_loss: 0.9087 - val_acc: 0.7291\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7202 - acc: 0.7853\n",
      "Epoch 00008: val_loss did not improve from 0.90869\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.7202 - acc: 0.7853 - val_loss: 0.9792 - val_acc: 0.7140\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6307 - acc: 0.8131\n",
      "Epoch 00009: val_loss improved from 0.90869 to 0.89542, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_6_conv_checkpoint/009-0.8954.hdf5\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.6308 - acc: 0.8130 - val_loss: 0.8954 - val_acc: 0.7363\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5515 - acc: 0.8358\n",
      "Epoch 00010: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.5515 - acc: 0.8358 - val_loss: 0.9190 - val_acc: 0.7307\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4755 - acc: 0.8548\n",
      "Epoch 00011: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.4755 - acc: 0.8548 - val_loss: 0.9378 - val_acc: 0.7412\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4184 - acc: 0.8742\n",
      "Epoch 00012: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.4184 - acc: 0.8742 - val_loss: 1.0630 - val_acc: 0.7214\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3501 - acc: 0.8918\n",
      "Epoch 00013: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.3501 - acc: 0.8919 - val_loss: 0.9844 - val_acc: 0.7461\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2866 - acc: 0.9132\n",
      "Epoch 00014: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2866 - acc: 0.9132 - val_loss: 1.0728 - val_acc: 0.7419\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2564 - acc: 0.9212\n",
      "Epoch 00015: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.2564 - acc: 0.9212 - val_loss: 1.1260 - val_acc: 0.7251\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2268 - acc: 0.9311\n",
      "Epoch 00016: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2268 - acc: 0.9312 - val_loss: 1.1325 - val_acc: 0.7463\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1941 - acc: 0.9412\n",
      "Epoch 00017: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1941 - acc: 0.9412 - val_loss: 1.1563 - val_acc: 0.7333\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1791 - acc: 0.9439\n",
      "Epoch 00018: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1791 - acc: 0.9439 - val_loss: 1.1848 - val_acc: 0.7561\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9469\n",
      "Epoch 00019: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1704 - acc: 0.9469 - val_loss: 1.3071 - val_acc: 0.7375\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1560 - acc: 0.9527\n",
      "Epoch 00020: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.1560 - acc: 0.9527 - val_loss: 1.2710 - val_acc: 0.7461\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9571\n",
      "Epoch 00021: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.1428 - acc: 0.9571 - val_loss: 1.2660 - val_acc: 0.7433\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9635\n",
      "Epoch 00022: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.1242 - acc: 0.9635 - val_loss: 1.2405 - val_acc: 0.7475\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1290 - acc: 0.9604\n",
      "Epoch 00023: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1290 - acc: 0.9604 - val_loss: 1.2895 - val_acc: 0.7554\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9634\n",
      "Epoch 00024: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1220 - acc: 0.9634 - val_loss: 1.2898 - val_acc: 0.7556\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9683\n",
      "Epoch 00025: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1079 - acc: 0.9683 - val_loss: 1.4149 - val_acc: 0.7498\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9682\n",
      "Epoch 00026: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.1045 - acc: 0.9682 - val_loss: 1.2942 - val_acc: 0.7626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9674\n",
      "Epoch 00027: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.1102 - acc: 0.9674 - val_loss: 1.3769 - val_acc: 0.7456\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9727\n",
      "Epoch 00028: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0949 - acc: 0.9727 - val_loss: 1.3492 - val_acc: 0.7536\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9729\n",
      "Epoch 00029: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0899 - acc: 0.9729 - val_loss: 1.3960 - val_acc: 0.7473\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9752\n",
      "Epoch 00030: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0838 - acc: 0.9752 - val_loss: 1.2645 - val_acc: 0.7699\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9754\n",
      "Epoch 00031: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0869 - acc: 0.9754 - val_loss: 1.3113 - val_acc: 0.7680\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9765\n",
      "Epoch 00032: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0818 - acc: 0.9765 - val_loss: 1.3855 - val_acc: 0.7699\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9755\n",
      "Epoch 00033: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0817 - acc: 0.9754 - val_loss: 1.3864 - val_acc: 0.7673\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9776\n",
      "Epoch 00034: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0793 - acc: 0.9776 - val_loss: 1.3248 - val_acc: 0.7659\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9776\n",
      "Epoch 00035: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0793 - acc: 0.9776 - val_loss: 1.3977 - val_acc: 0.7661\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9790\n",
      "Epoch 00036: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0757 - acc: 0.9790 - val_loss: 1.3801 - val_acc: 0.7617\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9801\n",
      "Epoch 00037: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0716 - acc: 0.9801 - val_loss: 1.4277 - val_acc: 0.7566\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9801\n",
      "Epoch 00038: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0696 - acc: 0.9801 - val_loss: 1.3949 - val_acc: 0.7633\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9796\n",
      "Epoch 00039: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0739 - acc: 0.9796 - val_loss: 1.3301 - val_acc: 0.7601\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9829\n",
      "Epoch 00040: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0631 - acc: 0.9829 - val_loss: 1.5068 - val_acc: 0.7536\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9834\n",
      "Epoch 00041: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0629 - acc: 0.9834 - val_loss: 1.3478 - val_acc: 0.7563\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9826\n",
      "Epoch 00042: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0641 - acc: 0.9826 - val_loss: 1.5011 - val_acc: 0.7626\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9832\n",
      "Epoch 00043: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0637 - acc: 0.9832 - val_loss: 1.3959 - val_acc: 0.7652\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9839\n",
      "Epoch 00044: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0620 - acc: 0.9839 - val_loss: 1.3638 - val_acc: 0.7678\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9841\n",
      "Epoch 00045: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0593 - acc: 0.9841 - val_loss: 1.3829 - val_acc: 0.7591\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9816\n",
      "Epoch 00046: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0669 - acc: 0.9816 - val_loss: 1.3416 - val_acc: 0.7759\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9856\n",
      "Epoch 00047: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0567 - acc: 0.9856 - val_loss: 1.3632 - val_acc: 0.7612\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9846\n",
      "Epoch 00048: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0591 - acc: 0.9846 - val_loss: 1.3104 - val_acc: 0.7731\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9845\n",
      "Epoch 00049: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0579 - acc: 0.9845 - val_loss: 1.3723 - val_acc: 0.7745\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9869\n",
      "Epoch 00050: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0516 - acc: 0.9869 - val_loss: 1.3741 - val_acc: 0.7759\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9867\n",
      "Epoch 00051: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0514 - acc: 0.9867 - val_loss: 1.3550 - val_acc: 0.7706\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9856\n",
      "Epoch 00052: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0560 - acc: 0.9856 - val_loss: 1.4547 - val_acc: 0.7710\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9862\n",
      "Epoch 00053: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0552 - acc: 0.9862 - val_loss: 1.5239 - val_acc: 0.7603\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9867\n",
      "Epoch 00054: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0523 - acc: 0.9867 - val_loss: 1.4009 - val_acc: 0.7743\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9863\n",
      "Epoch 00055: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0515 - acc: 0.9863 - val_loss: 1.5014 - val_acc: 0.7708\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9871\n",
      "Epoch 00056: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0504 - acc: 0.9871 - val_loss: 1.3414 - val_acc: 0.7741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9871\n",
      "Epoch 00057: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0532 - acc: 0.9871 - val_loss: 1.3897 - val_acc: 0.7768\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9868\n",
      "Epoch 00058: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0513 - acc: 0.9868 - val_loss: 1.4773 - val_acc: 0.7626\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9862\n",
      "Epoch 00059: val_loss did not improve from 0.89542\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0550 - acc: 0.9863 - val_loss: 1.3644 - val_acc: 0.7734\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.9917 - acc: 0.7043\n",
      "Loss: 0.9917499873001875 Accuracy: 0.70425755\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2737 - acc: 0.2551\n",
      "Epoch 00001: val_loss improved from inf to 1.55193, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv_checkpoint/001-1.5519.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 2.2735 - acc: 0.2551 - val_loss: 1.5519 - val_acc: 0.4833\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4234 - acc: 0.5455\n",
      "Epoch 00002: val_loss improved from 1.55193 to 1.29604, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv_checkpoint/002-1.2960.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 1.4233 - acc: 0.5455 - val_loss: 1.2960 - val_acc: 0.5935\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2391 - acc: 0.6124\n",
      "Epoch 00003: val_loss improved from 1.29604 to 1.10198, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv_checkpoint/003-1.1020.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 1.2390 - acc: 0.6125 - val_loss: 1.1020 - val_acc: 0.6580\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0916 - acc: 0.6605\n",
      "Epoch 00004: val_loss improved from 1.10198 to 0.99967, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv_checkpoint/004-0.9997.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 1.0915 - acc: 0.6605 - val_loss: 0.9997 - val_acc: 0.7018\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9395 - acc: 0.7130\n",
      "Epoch 00005: val_loss improved from 0.99967 to 0.84862, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv_checkpoint/005-0.8486.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.9395 - acc: 0.7130 - val_loss: 0.8486 - val_acc: 0.7496\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8082 - acc: 0.7555\n",
      "Epoch 00006: val_loss improved from 0.84862 to 0.75164, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv_checkpoint/006-0.7516.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.8082 - acc: 0.7555 - val_loss: 0.7516 - val_acc: 0.7838\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7065 - acc: 0.7880\n",
      "Epoch 00007: val_loss improved from 0.75164 to 0.68627, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv_checkpoint/007-0.6863.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.7066 - acc: 0.7880 - val_loss: 0.6863 - val_acc: 0.8064\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6260 - acc: 0.8113\n",
      "Epoch 00008: val_loss did not improve from 0.68627\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.6260 - acc: 0.8113 - val_loss: 0.6977 - val_acc: 0.7941\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5597 - acc: 0.8336\n",
      "Epoch 00009: val_loss improved from 0.68627 to 0.62464, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv_checkpoint/009-0.6246.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.5597 - acc: 0.8336 - val_loss: 0.6246 - val_acc: 0.8181\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4910 - acc: 0.8564\n",
      "Epoch 00010: val_loss improved from 0.62464 to 0.61131, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv_checkpoint/010-0.6113.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4910 - acc: 0.8565 - val_loss: 0.6113 - val_acc: 0.8262\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4365 - acc: 0.8712\n",
      "Epoch 00011: val_loss improved from 0.61131 to 0.60417, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv_checkpoint/011-0.6042.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.4366 - acc: 0.8712 - val_loss: 0.6042 - val_acc: 0.8309\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3878 - acc: 0.8852\n",
      "Epoch 00012: val_loss did not improve from 0.60417\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.3878 - acc: 0.8852 - val_loss: 0.6050 - val_acc: 0.8353\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3417 - acc: 0.8963\n",
      "Epoch 00013: val_loss improved from 0.60417 to 0.59339, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv_checkpoint/013-0.5934.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.3416 - acc: 0.8963 - val_loss: 0.5934 - val_acc: 0.8321\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3097 - acc: 0.9053\n",
      "Epoch 00014: val_loss did not improve from 0.59339\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.3097 - acc: 0.9053 - val_loss: 0.5938 - val_acc: 0.8372\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2651 - acc: 0.9196\n",
      "Epoch 00015: val_loss did not improve from 0.59339\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.2651 - acc: 0.9196 - val_loss: 0.6041 - val_acc: 0.8474\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2356 - acc: 0.9269\n",
      "Epoch 00016: val_loss improved from 0.59339 to 0.59273, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv_checkpoint/016-0.5927.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.2356 - acc: 0.9269 - val_loss: 0.5927 - val_acc: 0.8472\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9348\n",
      "Epoch 00017: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.2106 - acc: 0.9348 - val_loss: 0.6554 - val_acc: 0.8395\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1877 - acc: 0.9424\n",
      "Epoch 00018: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1877 - acc: 0.9424 - val_loss: 0.6263 - val_acc: 0.8472\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1729 - acc: 0.9461\n",
      "Epoch 00019: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1729 - acc: 0.9461 - val_loss: 0.6009 - val_acc: 0.8493\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9511\n",
      "Epoch 00020: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1548 - acc: 0.9511 - val_loss: 0.6714 - val_acc: 0.8428\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9567\n",
      "Epoch 00021: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1387 - acc: 0.9567 - val_loss: 0.7665 - val_acc: 0.8397\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9576\n",
      "Epoch 00022: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1323 - acc: 0.9576 - val_loss: 0.6962 - val_acc: 0.8502\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9622\n",
      "Epoch 00023: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1216 - acc: 0.9622 - val_loss: 0.6602 - val_acc: 0.8418\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9636\n",
      "Epoch 00024: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1171 - acc: 0.9636 - val_loss: 0.6653 - val_acc: 0.8523\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9683\n",
      "Epoch 00025: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1036 - acc: 0.9683 - val_loss: 0.7791 - val_acc: 0.8344\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9686\n",
      "Epoch 00026: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1038 - acc: 0.9686 - val_loss: 0.8150 - val_acc: 0.8512\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9710\n",
      "Epoch 00027: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0958 - acc: 0.9710 - val_loss: 0.7748 - val_acc: 0.8341\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9722\n",
      "Epoch 00028: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0961 - acc: 0.9722 - val_loss: 0.7630 - val_acc: 0.8418\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9712\n",
      "Epoch 00029: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0940 - acc: 0.9712 - val_loss: 0.6675 - val_acc: 0.8595\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9752\n",
      "Epoch 00030: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0806 - acc: 0.9752 - val_loss: 0.7668 - val_acc: 0.8502\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9754\n",
      "Epoch 00031: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0815 - acc: 0.9754 - val_loss: 0.7787 - val_acc: 0.8530\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9752\n",
      "Epoch 00032: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0819 - acc: 0.9752 - val_loss: 0.7107 - val_acc: 0.8619\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9760\n",
      "Epoch 00033: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0809 - acc: 0.9760 - val_loss: 0.8012 - val_acc: 0.8528\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9767\n",
      "Epoch 00034: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0783 - acc: 0.9767 - val_loss: 0.7783 - val_acc: 0.8532\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9782\n",
      "Epoch 00035: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0713 - acc: 0.9782 - val_loss: 0.7681 - val_acc: 0.8565\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9793\n",
      "Epoch 00036: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0695 - acc: 0.9793 - val_loss: 0.6903 - val_acc: 0.8635\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9800\n",
      "Epoch 00037: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0666 - acc: 0.9800 - val_loss: 0.8053 - val_acc: 0.8532\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9808\n",
      "Epoch 00038: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0658 - acc: 0.9808 - val_loss: 0.7388 - val_acc: 0.8574\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9815\n",
      "Epoch 00039: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0642 - acc: 0.9815 - val_loss: 0.8432 - val_acc: 0.8416\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9808\n",
      "Epoch 00040: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0675 - acc: 0.9808 - val_loss: 0.8137 - val_acc: 0.8567\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9816\n",
      "Epoch 00041: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0647 - acc: 0.9816 - val_loss: 0.8207 - val_acc: 0.8537\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9840\n",
      "Epoch 00042: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0546 - acc: 0.9840 - val_loss: 0.7891 - val_acc: 0.8595\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9822\n",
      "Epoch 00043: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0603 - acc: 0.9822 - val_loss: 0.7313 - val_acc: 0.8598\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9848\n",
      "Epoch 00044: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0544 - acc: 0.9848 - val_loss: 0.8160 - val_acc: 0.8514\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9833\n",
      "Epoch 00045: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0571 - acc: 0.9833 - val_loss: 0.7714 - val_acc: 0.8647\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9843\n",
      "Epoch 00046: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0540 - acc: 0.9843 - val_loss: 0.7591 - val_acc: 0.8579\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9852\n",
      "Epoch 00047: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0520 - acc: 0.9852 - val_loss: 0.7679 - val_acc: 0.8628\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9820\n",
      "Epoch 00048: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0642 - acc: 0.9820 - val_loss: 0.6935 - val_acc: 0.8628\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9852\n",
      "Epoch 00049: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0522 - acc: 0.9852 - val_loss: 0.7092 - val_acc: 0.8630\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9855\n",
      "Epoch 00050: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0513 - acc: 0.9855 - val_loss: 0.7434 - val_acc: 0.8789\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9870\n",
      "Epoch 00051: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0475 - acc: 0.9870 - val_loss: 0.7988 - val_acc: 0.8539\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9852\n",
      "Epoch 00052: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0541 - acc: 0.9852 - val_loss: 0.8558 - val_acc: 0.8595\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9865\n",
      "Epoch 00053: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0486 - acc: 0.9865 - val_loss: 0.7279 - val_acc: 0.8733\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9854\n",
      "Epoch 00054: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0524 - acc: 0.9854 - val_loss: 0.7687 - val_acc: 0.8633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9870\n",
      "Epoch 00055: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0482 - acc: 0.9870 - val_loss: 0.7088 - val_acc: 0.8689\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9882\n",
      "Epoch 00056: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0431 - acc: 0.9882 - val_loss: 0.7401 - val_acc: 0.8747\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9856\n",
      "Epoch 00057: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0509 - acc: 0.9856 - val_loss: 0.7582 - val_acc: 0.8665\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9880\n",
      "Epoch 00058: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0443 - acc: 0.9880 - val_loss: 0.7428 - val_acc: 0.8728\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9898\n",
      "Epoch 00059: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0416 - acc: 0.9898 - val_loss: 0.7552 - val_acc: 0.8654\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9879\n",
      "Epoch 00060: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0461 - acc: 0.9879 - val_loss: 0.6784 - val_acc: 0.8775\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9896\n",
      "Epoch 00061: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0407 - acc: 0.9896 - val_loss: 0.7470 - val_acc: 0.8656\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9851\n",
      "Epoch 00062: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0537 - acc: 0.9851 - val_loss: 0.7631 - val_acc: 0.8665\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9881\n",
      "Epoch 00063: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0420 - acc: 0.9881 - val_loss: 0.7003 - val_acc: 0.8700\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9895\n",
      "Epoch 00064: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0399 - acc: 0.9895 - val_loss: 0.8520 - val_acc: 0.8588\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9893\n",
      "Epoch 00065: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0412 - acc: 0.9893 - val_loss: 0.7580 - val_acc: 0.8742\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9888\n",
      "Epoch 00066: val_loss did not improve from 0.59273\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0420 - acc: 0.9888 - val_loss: 0.7923 - val_acc: 0.8686\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl4lNXZ+PHvmclksu8JgSRA2ATCElZRFFwRcdci+rq3YvfW2tqitn2x1lar/ura12Kr1VZB61YX6oKCuIAsIWyyQ4CE7PueWc7vjzOTBEhCAplMkrk/1/Vcycw8yz2TybmfszznUVprhBBCCACLvwMQQgjRe0hSEEII0UySghBCiGaSFIQQQjSTpCCEEKKZJAUhhBDNJCkIIYRoJklBCCFEM0kKQgghmgX5O4CuSkhI0EOHDvV3GEII0ads3LixRGudeKL1+lxSGDp0KBs2bPB3GEII0acopQ52Zj1pPhJCCNFMkoIQQohmkhSEEEI063N9Cm1xOBzk5ubS0NDg71D6rJCQEFJTU7HZbP4ORQjhR/0iKeTm5hIZGcnQoUNRSvk7nD5Ha01paSm5ubmkp6f7OxwhhB/1i+ajhoYG4uPjJSGcJKUU8fHxUtMSQvSPpABIQjhF8vkJIaAfJYUTcbnqaGzMw+12+DsUIYTotQImKbjdjTQ15aN19yeFiooK/vKXv5zUtvPmzaOioqLT6y9evJhHH330pI4lhBAnEjBJQSkrAFq7un3fHSUFp9PZ4bbLly8nJiam22MSQoiTIUmhGyxatIh9+/aRmZnJ3XffzapVqzj77LO5/PLLGTt2LABXXnklU6ZMISMjgyVLljRvO3ToUEpKSsjJyWHMmDEsXLiQjIwM5syZQ319fYfHzc7OZsaMGUyYMIGrrrqK8vJyAJ588knGjh3LhAkTuO666wD47LPPyMzMJDMzk0mTJlFdXd3tn4MQou/rF0NSW9uz505qarLbeMWNy1WLxRKCUl0bix8RkcnIkY+3+/pDDz3Etm3byM42x121ahVZWVls27ateYjn888/T1xcHPX19UybNo1rrrmG+Pj4Y2Lfw9KlS3nuuee49tpreeONN7jxxhvbPe7NN9/MU089xezZs/ntb3/L/fffz+OPP85DDz3EgQMHsNvtzU1Tjz76KM888wwzZ86kpqaGkJCQLn0GQojAEDA1BfCOrtE9crTp06cfNeb/ySefZOLEicyYMYPDhw+zZ8+e47ZJT08nMzMTgClTppCTk9Pu/isrK6moqGD27NkA3HLLLaxevRqACRMmcMMNN/Cvf/2LoCCT92fOnMldd93Fk08+SUVFRfPzQgjRWr8rGdo7o9daU1OzkeDgQdjtg3weR3h4ePPvq1atYsWKFaxZs4awsDDOOeecNq8JsNvtzb9brdYTNh+15/3332f16tW8++67PPjgg2zdupVFixZxySWXsHz5cmbOnMmHH37I6NGjT2r/Qoj+K2BqCmYcvsUnfQqRkZEdttFXVlYSGxtLWFgYO3fuZO3atad8zOjoaGJjY/n8888B+Oc//8ns2bNxu90cPnyYc889l4cffpjKykpqamrYt28f48eP51e/+hXTpk1j586dpxyDEKL/6Xc1hY4oFYTWHY8GOhnx8fHMnDmTcePGcfHFF3PJJZcc9frcuXN59tlnGTNmDKeddhozZszoluO++OKLfO9736Ouro5hw4bxwgsv4HK5uPHGG6msrERrzU9+8hNiYmL4zW9+w8qVK7FYLGRkZHDxxRd3SwxCiP5Fad0zbezdZerUqfrYm+zs2LGDMWPGnHDb2trtWCx2QkNH+Cq8Pq2zn6MQou9RSm3UWk890XoB03wEZliqL5qPhBCivwiopACSFIQQoiMBlRSkpiCEEB0LsKTgm45mIYToLwIsKVgBF32tc10IIXpKACYFALdf4xBCiN4qoJICeCfF838TUkRERJeeF0KInhBQSUEpc62edDYLIUTbAiwp+Gb67EWLFvHMM880P/beCKempobzzz+fyZMnM378eP7zn/90ep9aa+6++27GjRvH+PHjefXVVwHIz89n1qxZZGZmMm7cOD7//HNcLhe33npr87p//vOfu/X9CSECR/+b5uLOOyG7ramzwapdhLrrsFhCQXXhrWdmwuPtT529YMEC7rzzTn74wx8C8Nprr/Hhhx8SEhLCW2+9RVRUFCUlJcyYMYPLL7+8U/dDfvPNN8nOzmbz5s2UlJQwbdo0Zs2axSuvvMJFF13Efffdh8vloq6ujuzsbPLy8ti2bRtAl+7kJoQQrfW/pNAR5ZvpsydNmkRRURFHjhyhuLiY2NhY0tLScDgc3HvvvaxevRqLxUJeXh6FhYUkJyefcJ9ffPEF119/PVarlQEDBjB79mzWr1/PtGnT+Pa3v43D4eDKK68kMzOTYcOGsX//fn784x9zySWXMGfOnG59f0KIwNH/kkIHZ/Ta7aC+djN2exrBwQO69bDz58/n9ddfp6CggAULFgDw8ssvU1xczMaNG7HZbAwdOrTNKbO7YtasWaxevZr333+fW2+9lbvuuoubb76ZzZs38+GHH/Lss8/y2muv8fzzz3fH2xJCBBif9SkopdKUUiuVUt8opbYrpX7axjpKKfWkUmqvUmqLUmqyr+Ixx/PdLTkXLFjAsmXLeP3115k/fz5gpsxOSkrCZrOxcuVKDh482On9nX322bz66qu4XC6Ki4tZvXo106dP5+DBgwwYMICFCxdy++23k5WVRUlJCW63m2uuuYbf//73ZGVldfv7E0IEBl/WFJzAz7XWWUqpSGCjUupjrfU3rda5GBjpWU4H/s/z0yeUsuCreypkZGRQXV1NSkoKAwcOBOCGG27gsssuY/z48UydOrVLN7W56qqrWLNmDRMnTkQpxZ/+9CeSk5N58cUXeeSRR7DZbERERPDSSy+Rl5fHbbfdhtttrr/44x//2O3vTwgRGHps6myl1H+Ap7XWH7d67q/AKq31Us/jXcA5Wuv89vZzKlNnA9TUbMZqjSY0dGjX30Q/J1NnC9F/9aqps5VSQ4FJwNfHvJQCHG71ONfz3LHb36GU2qCU2lBcXHyKsQRhKjFCCCGO5fOkoJSKAN4A7tRaV53MPrTWS7TWU7XWUxMTE08xIpkpVQgh2uPTpKCUsmESwsta6zfbWCUPSGv1ONXznA9jkqQghBDt8eXoIwX8Hdihtf5/7az2DnCzZxTSDKCyo/6E7olLkoIQQrTHl6OPZgI3AVuVUt5LjO8FBgNorZ8FlgPzgL1AHXCbD+MBvPdUkKQghBBt8VlS0Fp/AXQ4n4M2Q59+6KsY2mKuVXCite7UdBNCCBFIAmpCPKP776lQUVHBX/7yl5Padt68eTJXkRCi1wi4pOCLq5o7SgpOZ8fDX5cvX05MTEy3xSKEEKcigJNC912rsGjRIvbt20dmZiZ33303q1at4uyzz+byyy9n7NixAFx55ZVMmTKFjIwMlixZ0rzt0KFDKSkpIScnhzFjxrBw4UIyMjKYM2cO9fX1xx3r3Xff5fTTT2fSpElccMEFFBYWAlBTU8Ntt93G+PHjmTBhAm+88QYAH3zwAZMnT2bixImcf/753faehRD9U7+bEK+DmbMB0DoKt/s0LJZgOtulcIKZs3nooYfYtm0b2Z4Dr1q1iqysLLZt20Z6ejoAzz//PHFxcdTX1zNt2jSuueYa4uPjj9rPnj17WLp0Kc899xzXXnstb7zxBjfeeONR65x11lmsXbsWpRR/+9vf+NOf/sRjjz3GAw88QHR0NFu3bgWgvLyc4uJiFi5cyOrVq0lPT6esrKxzb1gIEbD6XVI4sZ7pXJ4+fXpzQgB48skneeuttwA4fPgwe/bsOS4ppKenk5mZCcCUKVPIyck5br+5ubksWLCA/Px8mpqamo+xYsUKli1b1rxebGws7777LrNmzWpeJy4urlvfoxCi/+l3SaGjM3oAl8tBXd0uQkLSsdniO175FISHhzf/vmrVKlasWMGaNWsICwvjnHPOaXMKbbvd3vy71Wpts/noxz/+MXfddReXX345q1atYvHixT6JXwgRmKRPoRtERkZSXV3d7uuVlZXExsYSFhbGzp07Wbt27Ukfq7KykpQUMz3Uiy++2Pz8hRdeeNQtQcvLy5kxYwarV6/mwIEDANJ8JIQ4oQBOCt03+ig+Pp6ZM2cybtw47r777uNenzt3Lk6nkzFjxrBo0SJmzJhx0sdavHgx8+fPZ8qUKSQkJDQ//+tf/5ry8nLGjRvHxIkTWblyJYmJiSxZsoSrr76aiRMnNt/8Rwgh2tNjU2d3l1OdOhugujoLmy2RkJC0E68cQGTqbCH6r141dXZvI/MfCSFE2wI2KYAkBSGEOFZAJgUI6taOZiGE6C8CMilI85EQQrRNkoIQQohmkhSEEEI0C9CkEIT3ngr+EhER4bdjCyFEewIyKfjingpCCNEfBGRS6O6rmhctWnTUFBOLFy/m0UcfpaamhvPPP5/Jkyczfvx4/vOf/5xwX+1Nsd3WFNjtTZcthBAnq99NiHfnB3eSXdDB3NmYeY/c7noslnCUOnFezEzO5PG57c+0t2DBAu68805++ENzZ9HXXnuNDz/8kJCQEN566y2ioqIoKSlhxowZXH755R3eBrStKbbdbnebU2C3NV22EEKcin6XFDrHWyh3T5/CpEmTKCoq4siRIxQXFxMbG0taWhoOh4N7772X1atXY7FYyMvLo7CwkOTk5Hb31dYU28XFxW1Ogd3WdNlCCHEq+l1S6OiM3svlqqWubgchISOw2brnVpjz58/n9ddfp6CgoHniuZdffpni4mI2btyIzWZj6NChbU6Z7dXZKbaFEMJXArJPoaWjufuGpS5YsIBly5bx+uuvM3/+fMBMc52UlITNZmPlypUcPHiww320N8V2e1NgtzVdthBCnIqATAq+mD47IyOD6upqUlJSGDhwIAA33HADGzZsYPz48bz00kuMHj26w320N8V2e1NgtzVdthBCnIqAnDpbazc1NVkEB6dgtw/s7hD7LJk6W4j+S6bO7oAZcWSRSfGEEOIYAZkUQKbPFkKItvSbpNDVZjCZ/+hofa0ZUQjhG/0iKYSEhFBaWtrFgk2SgpfWmtLSUkJCQvwdihDCz/rFdQqpqank5uZSXFzc6W2amooAF8HBkhjAJNbU1FR/hyGE8LN+kRRsNlvz1b6d9c03D1BdvZ6JE/f4KCohhOh7+kXz0ckICorB6azwdxhCCNGrBHxSkA5WIYRoEdBJwcyWWufvUIQQotcInKTw1Vdw1VXgmR8oKMhMhCdNSEII0SJwkkJtLbz9NmzcCEhSEEKItvgsKSilnldKFSmltrXz+jlKqUqlVLZn+a2vYgFgqmfKj/XrAUkKQgjRFl8OSf0H8DTwUgfrfK61vtSHMbSIjYURI1olhWgAnM7KHjm8EEL0BT6rKWitVwNlvtr/SZk2TWoKQgjRAX/3KZyhlNqslPqvUirD50ebNg1yc6GgQJKCEEK0wZ9JIQsYorWeCDwFvN3eikqpO5RSG5RSG7oylcVxpk0zP9evx2r1Nh9JUhBCCC+/JQWtdZXWusbz+3LAppRKaGfdJVrrqVrrqYmJiSd/0EmTwGLxJIUQLJYQSQpCCNGK35KCUipZKaU8v0/3xFLq04OGh0NGxlH9CpIUhBCihc9GHymllgLnAAlKqVzgfwEbgNb6WeBbwPeVUk6gHrhO98ScE1OnwjvvgNaSFIQQ4hg+Swpa6+tP8PrTmCGrPWvaNHjhBcjJkaQghBDH8Pfoo57XqrNZkoIQQhwt8JLChAkQHAzr12OzJdDYmCszpQohhEfgJYXgYJg4ETZsIDp6Fk1N+dTWbvd3VEII0SsEXlIA04S0cSNxMRcBUFb2Xz8HJIQQvUPgJoXqakIO1hIePp6ysuX+jkgIIXqFwE0KAOvXExc3j8rKL3A6q/wbkxBC9AKBmRRGjzYXsq1fT3z8xWjtpLz8E39HJYQQfheYScFqhSlTYP16oqLOxGqNkiYkIYQgUJMCmCak7GwsTk1c3BxKS/8rQ1OFEAEvsJNCYyNs20Zc3MU0NeVRW7vV31EJIYRfBXZSAE9n81xAhqYKIUTgJoX0dIiPh/XrsdsHERGRSWmp9CsIIQJb4CYFpcyMqV9/DeAZmvql3LNZCBHQAjcpAMyeDdu2QWEhcXEXAy7Kyj72d1RCCOE3gZ0ULrzQ/FyxgqioGQQFxUi/ghAioAV2Upg0yfQrfPQRFksQsbFzKCuToalCiMAV2EnBaoULLoCPPwatiY+fR1NTPjU1m/0dmRBC+EVgJwWAOXMgPx+2b28emlpa+p6fgxJCCP/oVFJQSv1UKRWljL8rpbKUUnN8HVyP8PYrfPQRwcEDiIqaSVHRUmlCEkIEpM7WFL6tta4C5gCxwE3AQz6LqielpZkJ8j76CIABA26kru4baUISQgSkziYF5fk5D/in1np7q+f6vjlzYPVqaGggKWk+StkoLPyXv6MSQoge19mksFEp9REmKXyolIoE3L4Lq4fNmQP19fDll9hs8cTFzaOo6BW0dvk7MiGE6FGdTQrfARYB07TWdYANuM1nUfW02bPBZjuqCampKZ/y8pV+DkwIIXpWZ5PCGcAurXWFUupG4NdA/5kPIiICzjyzOSnEx1+K1RpFUdHLfg5MCCF6VmeTwv8BdUqpicDPgX3ASz6Lyh/mzIHsbCgqwmoNITFxPsXFb+By1fk7MiGE6DGdTQpObcZoXgE8rbV+Boj0XVh+MMczwnbFCgAGDLgBl6ua0tJ3/RiUEEL0rM4mhWql1D2YoajvK6UsmH6F/qPVlBcAMTGzsdtTZRSSECKgdDYpLAAaMdcrFACpwCM+i8ofvFNefPQRaI1SFpKS/oeysg9oair2d3RCCNEjOpUUPIngZSBaKXUp0KC17l99CmCubvZMeQFmFJLWToqLX/NzYEII0TM6O83FtcA6YD5wLfC1UupbvgzML7xTXiw3d2CLiBhPePgEaUISQgSMzjYf3Ye5RuEWrfXNwHTgN74Ly08GD4azz4YnnjAXs2FqC1VVa6mr2+vn4IQQwvc6mxQsWuuiVo9Lu7Bt3/LAA3DkCDz7LABJSdcBUFS0zJ9RCSFEj+hswf6BUupDpdStSqlbgfeB/nmX+9mzTYfzH/8INTWEhKQRHX22Z9oLmTlVCNG/dbaj+W5gCTDBsyzRWv/Kl4H51e9/D8XF8OSTACQlXU9d3Q5qa7f4OTAhhPCtTjcBaa3f0Frf5Vne8mVQfnf66XDZZfDII1BRQWLitwArhYVL/R2ZEEL4VIdJQSlVrZSqamOpVkpVnWDb55VSRUqpbe28rpRSTyql9iqltiilJp/KG+l2v/sdVFTAY48RHJxIXNyFFBUtkyYkIUS/1mFS0FpHaq2j2lgitdZRJ9j3P4C5Hbx+MTDSs9yBmV+p98jMhPnz4fHHobiYpKTraWw8SFXVGn9HJoQQPuOzEURa69VAWQerXAG8pI21QIxSaqCv4jkp998PdXXw8MMkJFyJxRJCUZE0IQkh+i9/DitNAQ63epzrea73GDMGbrwRnnmGoJI64uMvpajoNdxup78jE0IInwjydwCdoZS6A9PExODBg3v24PfcAy+9BEuXknTj9RQXv05FxUri4i7s2ThEv6U1uFxmcTrbXryvu1zgdpupuoKCzE+rFZQ6fpu6OqithZoa87OhAex2CAmB0FDzE6C62qzj/amUWc+7BAeb/TkcHf8MDYWYmJYlIsLsr6ICKivNz7o6E3/rxeGAxsaWxeEwx/TGGBJi3qt3vaYms4C5N1brxeEw77P1/rzrOxzmZ1CQiS0iAiIjISzMrFdbe/znVV9vloYGc7zQ0KMXp7Pl9fp6834SEiAxEZKSzBIcbN5/ZSVUVZmlvv749wzms2+9WK1gsZjFaoXvfAd++lPffh/9mRTygLRWj1M9zx1Ha70EMySWqVOn9mxP7+jRMHkyLF1K3E9We26+84okBT/RumXxFirH/jPX1bUUBG0VIEFB5p+sogJKS81SUmIKRe84gmPHE7T+Rz228HU4ji60vc81Nh5dQHkLJm/h5N0+EMcuKGX+BkqZv0nrJGSzmc+noaGlsHU6TeHqTVI2zxzN3s/Tu3jXOTapeRfvvgsLzffF+52x2yE83CSK8HCzxMRAcvLRCdSbJLyLzWYSgHcdi8V8lwoKYMsWKCoysUdFQXR0y8+ICDMpszde7/vxfrfh6MTpPRmIi/P938afSeEd4EdKqWXA6UCl1jrfj/G073/+B37xC6z7D5OQcBXFxW8ycuT/YbWG+DuyPsN7NuwtMMvKzD9mUZH5WVp6/BledXXLOt7FW8B3t8hIs3gLKmj52ToRaW2Sije5eM/WW5+1W63mnz0ysuXM3PuP7y2YWm/fetvWz7W3b4vl6ATkcpm4jo0pLKylkIuIMDE0NR19Ztv6vXvPnrU+/ky79Xtu/bP1MevrTaL11gyqq83+oqNNARsdbWJp/Rl3ltZd36Y38BbwfSl2nyUFpdRS4BwgQSmVC/wvnnswaK2fxVwRPQ/YC9TRm+/5vGAB3H03LF3KgB9dT2Hhi5SV/ZfExKv8HZlfNTaagjo/35wZFRSY3/Pyjl4qKkzh1RlWa8sZXng4DBhgztYmTDBV8dDQo88yLZaWQs9bAIaGHn2G2PqssvWZfUyMOVvznrGJU+P9G6Smdv+++1Kh2lpfjFv1tXH3U6dO1Rs2bOj5A597LuTn496+lTVrU4iJOYeMjP47pXZ5OezZc/Ry5Ih5vqzMLLW1bW+blAQpKS1LXNzxZ5WxsabA97a7JiSYwtxq7dn3KUSgUEpt1FpPPdF6faKjuVe4/nr47nexbNlGUtICjhx5DoejFJst3t+RnbTqati3zyy7dx+9lJS0rKeUmUA2LQ2GDjVdLHFxLQV7cnLL4u1YE0L0TZIUOuuaa+BHP4JXXmHg/95OXt7TFBS8RFraz/wdWadUVMCnn5pbUG/eDHv3mqaf1gYNglGj4OqrYeTIlmXYsJaONiFE/ybNR11x+eWwaRMcPEhW9kwcjnKmT9+B6mUNh2435OTAtm2wbp1JBOvXm+cjImDKFBgxwizDh5tl5EjT2SiE6J+k+cgX/ud/4N134YsvGDjyu+zadRuVlauJiZntt5CamszQt3XrYMMG2LoVvvnGDMsE00Y/fTr8+tfmxnKnn97S8SqEEMeSpNAVl11mxvm98gpJz/w/9u69kyNH/tqjSaG6Gj77DD75BL76CrKzW4ZpJiTAxImwcCGMG2eWjAypAYjey+FyEGQJ6nW17UAmSaErwsPhyivh3//G+uSTJCffzJEjf6WpqYTg4ASfHNLphLVr4eOPTTPQ11+b4ZQhIaYG8JOfmJ/TpsGQIX1zCJwILIcqD/He7vd4b/d7fHrgUwZHD+aXM3/JTRNuwh5k73DbBmcDaw6vYVXOKqwWK5OSJ5GZnElqVOpRiaXJ1UR+dT551XnkVuVyuPIwuVW55FbnYrfaGZ0wmtPiT2N0wmiGxw2noqGCQ5WHOFhxkEOVh6hsrGRozFBGxI1gRNwIBkUOot5Rz7q8dXx1+Cu+PPwlG/M3khaVxhmpZ3Bm2pmckXYGQ6KHHJfgGp2NlDeUU9FQQXl9OZWNlQyJHsJpCadhUUfPNOR0O1lzeA3L9ywnrzqPQZGDSIlMISUqhZTIFIbHDSchzDdljZf0KXTV++/DpZfCu+9Se24669ePY9iwRxg8+BfddojDh+GDD8zyySfmQiCLBaZONTeFO/98OPNM6fw9WUW1RXx+8HNSo1LJSMogIjiiw/VL6kr4pvgbthdtZ3/5ftKi0xiXNI5xSeNICk/qcFutNfXOesrqyzhYcZADFQfYX76f/eX7qWysZHzSeCYlT2LywMkMjh7cXKA0uZoorSulvKGc4bHDOyws6xx1VDRUEGWPItwW3rwPrTVVjVWmMKzKpbC2EJfbhVu70Wi01kSHRDM6YTSj4kcREtTyhTpceZhVOatYlbOKLUVbGBA+gPSYdNJj0xkaM5SI4AgKawoprC2koKaAotoiGl2Nx71373G8P/eX72dz4WYAhscO5+IRF/NV7ldk5WcxKHIQd824izum3EF4cDhFtUXkVeWRV53H9qJtfHLgU748/CUNzgYsytK8X4D40HjGJo6luqmavKo8iuuKj/ucwm3hpEalUu+s51DloQ7/bhZlwa3dzY9Dg0JpcjXh0i4AxiaOZdqgaRyqPMS6vHXUOsz47Gh7NEopnG4nDpcDp9vZvM2xouxRTBs0jekp0xkcPZiVOSv5aN9HVDRUEGQJYmDEQApqCnC4Hc3b/OKMX/DInEc6jL09ne1TkKTQVQ4HDBwIF10EL7/Mpk1n09RUyPTpu06pCux2w0cfwRNPmGQA5iKgiy6CuXNNIoiNPbXQa5tq2VK4hZK6EpRSKBRKKazKSkpUCsNjhxNqCz1uu7L6MnaX7qaotog6R13zUu+oJzE8kSHRQxgaM5TUqFRs1rY7LLTWHKo8xMb8jWwp3EK0PZoxiWMYnTCawdGDsSgLNU01ZBdkk5Wfxcb8jWituWbMNcwdMfe4QrGioYL3dr/H17lfM3PwTC4ZeQmR9vbbyYpri3lzx5u89s1rrMpZddQ//LDYYYxPGk9aVBo1jhqqG6upaqyiqrGKAxUHKKptGaZls9iO+idNCEsgPSYdALd249ZuXNrVXFBXNlQetT6AQpESlUJEcAS7S3c3xxIXGkdsSCwldSVUNlY2rx8RHMGc4XO4bNRlzBs5j8SwRPaU7eG/e/7L8r3L+Szns+YC2aqsRNmjiAiOoLyhnJqmmnY/k2NjSo9NZ2TcSPaW7WVf+T4AYkNimTxwMsV1xRwoP0B1U/Vx24YEhTAgfECb3x2FwqIszd+3hLAE5o2cx6WjLuW0+NNQSqG1ZsX+FTz05UN8euBTQoNCTaF6zOc2PnEc5w+7gPPSz2PWkFlYLVa2FG4huyCbTfmb2FGyg5iQmKPOrFOiUkiLSiM1KpUoe1Tz/2htUy17yvawq2QX+8r3ERsSy+DowQyJGcLg6MGE28I5XHWYvWV72Vu2lz2lewi1hZoaQeoZxIa2/DO9AVb1AAAgAElEQVQ63U62Fm5lTe4avin+BouyYLPYCLIEYbPaCA0KJTY0ltiQWGJDY4kMjmRP2R7W5a1jXd46NhdsxqmdJIcNYN6oS5g3ch4XDr+QKHsUbu2mpK6kOTkOiR7C+AHjO/U3Pe5vIUnBh374Q/j732HXLgrsn7Nz501MnPgJsbHndXlXNTXw4ovw1FOwa5cZ6/+975lbOYwZc3xzUL2jnuK6Yopri1FKERMSQ7Q9muiQaIIsQdQ76imoKSC/Jp/86nwOVBxgU8EmNuVvYlfprqMKw2MpFGnRaYyMG0lieCIHyg+wp2wPZfUdzYDewqIsJEckExsSS5Q9iuiQaKLt0ZQ3lLPxyEZK60vb3C7MFsaA8AHkVOQ0n/kNCB+Aw+2grL6MKHsUV46+km+N+RZ51Xm8ueNNVuasxOl2EmwNpsnVRLA1mDnD53D16KuZMGAC+8v3s6dsD3vK9rCzZCfr8tbh1m5GxY/i2rHXMm/kPIpqi9hatJWtRVvZUriFgpoCIoMjibRHEmWPIjI4krSoNDKSMhibOJaMxAxSo1Ipqi1iW9G25uVQ1SEsyoJVWbEoCxZlIcwWRkxITPPfJyYkhiExQ0iPSWdIzJDms/I6Rx1bC7eSlZ/FpoJN1DTVkBiWSEJYAonhiUQER/DFoS94b/d75FXnoVAk11vJDzWXiI+KH8W8EfM4LeG05kRW2VBJdVM1sSGxpEalNi8DIgZgs9iOOiEoqy9jR/EOdpbsZEfJDnaX7mZw9GDOGXoO5ww9hwkDJjQ3cWitKW8oJ6cih5qmGpIjkkmOSCYyOLLb+gS+zv2al7e+TERwBCmRKQx6ewUpL73NsHJIePYluOmmbjlOb1J/953kPf8Ewxb+EstDD/vsOJIUfOnwYTOG89prcb2whDVrUoiNvYCMjFc7vYvdu+Evf4EXXjCzJk6d5ubGH+QyYsZODlbvJb86n8JaUz0vqi2isKaQ4rriDs/8QoJCaHA2HPd8alQqkwdOZnLyZCYNnMSgyEFHVemdbieHKg+xp2wPu0t3s6dsD8W1xc1njiPjRjIyfiSDIgcRbgsnzBZGmC2MkKAQimqLyKnI4WDlQXIqcsityqWysZLKhkpTQDVWEmYLY3LyZKYMmsKUgVOYMGACNU017CzZ2VwYHak+wpiEMUweaNYbFDkIh8vBpwc+5dXtr/LWzreoaKgAYGTcSK4afRVXj7maKYOmsDZ3LW/ueJM3drxxXLPAwIiBjIwfyVlpZ7Fg3ALGJ43vk52aWmuyj2Tx7p0X840q4ewczcVqJMMWP2Gqkn3wPZ3Qww/DokXmLGnlSlNVXtPPbnLldpvOwLw8Myxw505IT/fJoSQp+NqvfmXu4ZyVxd6Il8jLe4ozzsglOHhAu5u4XPDf/8LTT8OHH0JQ8g6GXvckKm0NufW7qXfWN69rURYSwxJJCk9iQMQAksKTSApLIjHcPJcYlghAZWMlFQ0VVDRUUN1YTWxoLAMjBjIwciADIwaSGpVKfFjfveraq8nVxOcHPyc5IpmxiWNNwV5VZYYIX301hIaitWZj/kYOVhxkeNxwRsSNOGF/QZ/y6qtw3XXwyitmcqdf/tJcjn7hhfCtb8HBg3DgAOzfbwqZyy6D3/++a1NrvvKKGcKWkeG799EZzz0Hd9xhZhL4179MVfrOOyErCyZN8m9s3enzz2HWLJMAFy8210ItW+aTQ3U2KZgzxj60TJkyRfcK5eVax8VpPWeOrq3dqVeuROfkPKi11trpcuq3d7ytb3v7Nv3Q5w/pj3Z8oR97vEEPH641uHX8lFV61OJLNYvRIb8P0XP/NVf/7IOf6WfXP6tXHVilj1Qd0U6X089vsJf79FOthwwxE5dOmKD1rl3+icPh0Prgwe7Z18cfm6UtTqfWY8ZoPXas+V1rrRsbtf7zn7WOjTWfg9Wq9bBhWl9wgdbXXGMex8drvWSJ1i7XiY//3ntmP+HhWr/zTve8p5Px2mtaK6X1xRdr3dRknisv1zo0VOuFC/0Xly98//vmfVVXa/2//2s+/6++8smhgA26E2Ws3wv5ri69JilorfX/+3/mI/zoI71581z9/qcx+qHVv9NDHx+qWYyOfDBKsxiz/NquI396lh720BTNYnTinxL1/avu10U1Rf5+F31Lba3WP/mJ+dxHjtT6qadMwRcZaQqTnvaDH5hYzj1X67ffbimwu6qqSuvoaK1tNq2//PL4119+2RynrfdYXa31gQMmQbW2ZYvWZ59ttps2Teuvv27/+DU1JsmOHq311KmmUH7sMa3d7pN7Pyfrv/81n8HMmeZv3drtt2sdFmYSRH/Q1KR1QoLWCxaYxzU1Wg8cqPXppx//ubvdWj/3nNbbtp304SQp9ISGBq2HDtXl08bpO96ar+2/MwngrL/N1pfe/bq2BDm0JbJIn3X7W/qGF3+hZ/xthp74fxP1Xzf8Vdc11fk7+r5n7VqTCEDrn/60pdA4dEjrM84wz//4x+YM+lS53Vrv2WMK3PZkZZnC85xztE5LM8cfNsycLBQUdO14jz1mtk9ONkteXstrDofWo0ZpPX585874j30f//qX2afFovXrr7e93t13m+OvXm0+1299yzy+446Ws3VfW7lS65AQrSdNarvg37jRxPTEEz0Tj68tX27ez9tvtzz3wgvmuaVLW57bu1fr884zz//kJyd9OEkKPeStv/5MD/w52rJY6ateGKJ/cP88nZLi1EqZ/6fDh/0doZ85HN1TSBcXm2aNIUNM09GxGhu1/tnPzFd6xAitv/tdrf/xD9Os1JmzXafTFEoPPqj1JZeY2geYs+b6+uPXd7u1Pussc6ZXXm7e57//bZ7z3o9n0CCt583T+r77Oq5FNDZqnZpqksvWreZ9nnFGy+f24otmf2++2dlP63iVlVqfeabWwcFaf/LJ0a9lZ5umpttvb3nO5TJxg9azZ2v9yism+balosLUQqqqTj6+NWvM+x471vyt23P66Vqfdtrxf1OXyyS07viu9ZSbbtI6JsacXHq5XCYpDh5sag6PPWaalyIjtX722a6fFLQiScHHCqoL9PzX5msWoyf+LFT/Z8JEfdEFFRq0HjMmT69Z4+8IewG3W+vLLjP/xKda5fe2t27f3vF6b7+t9Zw5WkdFtRTO8fEmQXTkRz9qWX/MGK2//e2WQvGOO45ff+lS89qSJce/tmmTqS3cdJPW48aZAhe0vuuuto/tLfSXLzePX33VPP7e90yyGT7cFBSn2pRTVmbiiYjQesMG85zTaQraxEStS0vbjq31Z5mWpvV115ma2pw5WqektLx23nknV2hlZZmms+HDtT5ypON1vZ9V68RWXq715Zeb56+9tmsxFBWZv2VWVsefb2Wl1nVdqN3n5ZlC/JJLzAnKsTHV1Zm/w3e+c/y2n35q3suAAebnJZd0y9mlJAUfevObN3XsQ7Ha/oBdP7j6Qf3vxRt0BFU6IrhBL1r0T/3JJxG6oeEEX+5A4K0eg9ZXX33yhVpNjenUv+yyzm/jcpn21+eeM+3pkZGmAGjLrl2m4L7tNlNwtrZokYn/hReOjiclRevJkzvXh1BXZxKLUlp/9tnRr7ndWmdkmMK69efzy1+2FAig9X/+06m3fUK5uaa2lZho3vczz5j9/+tf7W/jcJimmyefNIXuoEHm7HXKFJP4HnqoJYE+8kjX4tm+3dS20tK0zsk58fr19ea7cM015vGmTabJLijIfMdA65//vON9lJdr/fzzWl90UUvCBtOe/53vmBrZ3r1aL1tmThYyM03TW2bm0Wf1x6qq0vqBB0ztsnVtEcz3qLV//9s8v2JF2/u69lpzMvPyy93WryNJwUee+voprRYrPf256Xp74Q79m9+YT3F63B59UA3RDe+8oFetCtK7dv3Qr3H6ncNhmgJGjND6D3/Qp9QW/MQTZvsvvji57XfsMP/8P2znb3Lttabpoq1+AIfDnAGHhJgCSGutf/3rrsdTU2POhNPTj+6neP99s6+XXjp6fadT6wsvNK9NmdK9Hb67d5ukMGSIqQVccEHX999WR+g115hO4qyszm3/0kumgE9ONjF11t13m7/nww+bv0tKiumcd7tbBiE8/vjx2x06pPUNN5gmNDB/i3vuMU1XL7yg9fz5R9eKvCOxLrzQjBJqq3D3crm0vvRSs86MGeY7v22biem73zXPt66tXnWVed/tnVQ4HN3elyNJoZu53W593yf3aRajr1h6hc4vqWv+Dnz721rXF1ebjsDYWL3vw+v0qlU2XVd3wC+x9gp//av5cN54o6UZyWbreARMW5qaTPvqzJmnFs/3v28Kkp07j35+wwYT529/2/62hYWm4ElPN2fMdrspXLrqiy9MbeF732t5bvZsc5bcVgFQUmI6fH3RFrlxo6k92e2mQ707lJSYM+PRo48fOdRaTo7Wc+eaz/3MM7uWELQ2Z/FKme3PP9/8fbycTlNjUKqlU72hwfQVhYWZJPLTn2q9bl3bibCpSetVq0zTz4YNR4/ouv12U2No62TAe+Lz1FNt7/P88833f/Vq0wdjt5s4epAkhW7kcDn0t9/+tmYxeuE7C/W2bxz6tNNMjfXpp1t9t/bt0zouTrvGjNKfLw/WO3bc2uOx9gpVVaY99KyzWj6c0lJzZjpkyPFNNB355z/N1/RUx80XFppC8Iorjn7+wgtNNb2ysuPt16wx/9R2uzl7zM09uTi8o3w++MAkSDD9D/6wZcvxzVmnasUK856+//3jX3O5zD9MRIT5DJ966uQ7Thcv1vr3v2/7TLuuziQbu9101I4YoZubMA8cOLnjaW2+1+npprmqdW1vxQqTLK6/vv0aV1mZGUEWH6+bmxfWrj35WE6CJIVuUtNYoy975TLNYvRvPv2N3rrVrZOSTO27zf+nFSu0tlp19YXD9cpPlK6u3trymtt98uPY+xJv88qxX/q1a03BesUVnWuucLtN7Wvs2FMaddHswQdNXN4/nLcA62yh7G1//+MfTz6G+nrzflJSTJt2dPSpjdrpjX7xi5ZEXlNj+kMWLmxpX7/oos71H5yK4mJTCIMZ6PDhh92z39WrdfPQQq1NB3BiovmbdjR8WWtTI4qL081Dl3v4GhBJCt3gUMUhPenZSVotVvqZdc/orVvN33/QoBNcQPvnP2sN+tBNoXrX06dp9/2LTYeht0OtvQ7P/uDwYdMJed11bb/u+Wz0d7/bcROD1i3t7ScaOdRZtbVm6Oe0aSY5T51qmqbaGnLaFrfbdIye6j/zhg0tHZz33HNq++qNGhpMp2x4uDlbB1NLmz/fNOn0VGGYm2tqmt09TNVb23vrLTN0OCLC9Ft1xqpV5sTogQe6N6ZOkKRwitYcXqMHPDJAR/4hUr+/+329ZYsp01NSOtEE6nZrfcst2ttZ5VbKnEncfLPp5Lrkkp6/UrSn3HKLeY/tVdPdbjM003tFckeX9M+aZQrx7vyn9g5pvO46fdyoop70hz9onZSkdX6+f47vazt2mL/fnXea4aN96fqBE6mvN6PFLBbzHXr11a5tX1TUPTXfLpKkcApeyn5JBz8QrIc9MUxvL9qus7NNU2Bqahf65OrrtfvZZ/W+JWfoL96369paTybxjqR58kmfxe8369ebqvXdd5943U8+MWfpFosZ0dF6qF99vZnuwBft7S6XOYuFo+cR8oeeulJYdL/sbFMjbu/ak15IksJJcLvd+t4V92oWo8/5xzm6pLZEr19vmgHT0sygh65qaMjTn38eo7OyztZut8ucKV9yialWZ2d3/5voDg0Npv2/K7WZykrToZeS0vkL1Sorzbhw0HroUHPRWExMcw1Lx8WduJ32ZHz6qanyv/9+9+9bBI4+1hfU2aRgaWvm1ED19Lqn+cMXf2Dh5IV8dONHZH0Zz7nnQlQUrFoFw4d3fZ92+yCGD/8zlZWfc+TI/5l57194wcwNf911UFfX7e/jlLjdsGABzJgBZ50FX3114m20hoULzbTNy5ZBTEznjhUVBX/7G7z3nrk/xdixcOON8OCD8PzzsH49RPhg6utzz4WSEpg3r/v3LQJHZPt3+uvTOpM5etPiq5rCx/s+1tb7rfqKpVdol9ully41/UETJpz4yvsTcbvdOjv7Iv3ZZ+Et1y58/PHRoxh6C++VtLfeaq7wBHNRUkcdKX/5iz7lUTlCCJ9Cmo86b3fJbh37UKwe95dxuqqhqrnZf9as7pult77+oF69OkJv2nS+drs97djeAvjXvzbt8f4ervq3v5l4fvAD03RUU6P1735nRpEEBZmx58cOJczKMh3LF1/sl84zIUTnSFLopIr6Cj3m6TE6/uF4vb9sf/N1JVdd1fmRip2Vl/ecXrkSvW/ffeaJxsaWKzvBXGJ/6aVaP/qomTdo586O51rpTitXmoJ/zpzj5+UvKDAJwWYz69xyi4mtstJM3ZCS0vHMlkIIv+tsUgjo23G63C6uWHYFH+z9gI9v+pgDK8/lO9+B73wH/vpXsFq75TDNtNbs2rWQgoK/k5HxBomJV5sX8vNNp8WqVeZetHv2tGykFKSmwsCB5n6eTmfLMmiQafv3LklJbR0UjhwxtzHctMn8DAqC6dPh9NNh6lTz+umnQ3Ky6UNor08gNxcefRSWLIGGBnMv2YMHTdxnndW9H5YQolvJPZo74YHPHuC3q37LM/OeYbr6AWedBWefbe6jHBTULYc4jtvdyKZNs6mr287kyV8THj72+JWKimDvXnP/3f37zc+iIhOUd7FazWvZ2SZBgLkBeESE6Sx2u01CKC+H4mLzulIwahQ4HGZbAIsFwsMhOBjWrYNhw078JoqL4fHHTea87z742c+658MRQviMJIUTKK8vZ8jjQ5gzfA5/OeffTJ2qUAo2boSEhG4ItAONjXls2DCFoKAoJk9eh83WydE6bamrM2f/a9ean01NpqBXqqXAz8yEyZNhwoSW0TzFxSYJfP21qZnceaepLQgh+qXOJgUfnQ/3fk+te4rqpmrunflbrr9eUVQEX37p+4QAYLenkJHxbzZvPo8dO25k/Ph3UOokRweHhZmmm6423yQmwiWXmEUIITwC8jqFmqYanvj6CS4bdRnLnpjAp5+alpApU3ouhpiYsxkx4gnKyt4nJ+f+njuwEEJ0ICCTwrMbnqWsvoyZ7vt45BH4wQ/gllt6Po5Bg75PcvKtHDz4AKWl/+35AIQQ4hgBlxQanA08tuYxzk8/n09ePJ0RI+DPf/ZPLEopRo58hvDw8ezYcSMNDQf9E4gQQnj4NCkopeYqpXYppfYqpRa18fqtSqlipVS2Z7ndl/EAPL/peQpqCrjv7PvYssU0xQcH+/qo7bNaw8jIeAOtnWzf/i3c7kb/BSOECHg+SwpKKSvwDHAxMBa4XinVxvhLXtVaZ3qWv/kqHgCHy8GfvvwTZ6SewZjQcygshIkTfXnEzgkLG8Ho0S9SXb2BvXtleKcQwn98WVOYDuzVWu/XWjcBy4ArfHi8E3p568scrDzIfWffx9atCugdSQEgMfFK0tLu5siR/6Og4F/+DkcIEaB8mRRSgMOtHud6njvWNUqpLUqp15VSaW3tSCl1h1Jqg1JqQ7H3Qqwucrld/PGLP5KZnMm8kfPYvNk8P2HCSe3OJ9LT/0B09Cx2776D6uqN/g5HCBGA/N3R/C4wVGs9AfgYeLGtlbTWS7TWU7XWUxMTE0/qQG/seIPdpbu596x7UUqxeTOkpEB8/MkH390sliDGjl2GzZbE5s1zqKnZ4u+QhBABxpdJIQ9ofeaf6nmumda6VGvt7Vn9G+CzKwVmDZnFH877A1ePMfMNbdnSe5qOWrPbB5KZ+SkWSyibN19Abe03/g5JCBFAfJkU1gMjlVLpSqlg4DrgndYrKKUGtnp4ObDDV8EkRyRzz9n3YLVYaWqCHTt6V9NRa6Ghw8jM/BSlrGzefD51dbv9HZIQIkD4LClorZ3Aj4APMYX9a1rr7Uqp3ymlLves9hOl1Hal1GbgJ8CtvoqntR07zJxwvbGm4BUWNoqJEz9BaxfZ2edRX7/f3yEJIQJAQE6I989/ws03w/bt5g6QvVlNzRays8/Fao1g4sSPCQsb5e+QhBB9UGcnxPN3R7NfbN4MdruZRbq3i4iYwMSJK3C769m06Syqqzf5OyQhRD8WsElh3Djf3TOhu0VGTmLSpC+wWELJzp5NRcVn/g5JCNFPBWRS2LKl93YytycsbBSTJn2J3Z7K5s0XUVLyzok3EkKILgq4pFBQYG5i1ps7mdsTEpLKpEmfExExkW3briY//wV/hySE6GcCLil4r2Tui0kBwGaLZ+LET4iNPY9du75NTs799LXBAkKI3ivgksIWz0XCfa35qLWgoAjGj3+P5ORbyclZzK5d38btbvJ3WEKIfqCPdLV2n82bITUV4uL8HcmpsViCOe205wkJSScn539pbMwlI+N1goKi/R2aEKIPC8iaQl+uJbSmlGLo0N8yevQ/qKhYxaZNZ1NXt8vfYQkh+rCASgqNjeZq5r7an9Ce5ORbmDDhAxobD7N+/Xj2778Xl6vW32EJIfqggEoKO3aA09n/kgJAbOz5TJ++k6Sk/+HQoT+ybt1Yiovfkk5oIUSXBFRS6A+dzB0JDh7AmDH/IDNzNUFB0WzffjVbt16Kw1Hq79CEEH1EQCWFzZshJARGjvR3JL4VE3M2U6ZkMXz4/6O8fAVZWTOkr0EI0SkBlxT60vQWp8JiCSIt7WdkZn6K01lJVtYMyss/8XdYQoheLmCSgtYmKfTXpqP2REfPZPLkdQQHp7B580UcObLE3yEJIXqxgEkKBQVQUtI/O5lPJDR0KJMnf0Vc3Bx27/4uO3feTlNTkb/DEkL0QgGTFLzTWwRaTcErKCiKcePeIS3tlxQU/IOvvx7BwYMP4XLV+zs0IUQvEjBJITYWbrghMGsKXhZLEMOHP8z06duJiTmXAwfuYd260RQWvozWbn+HJ4ToBQLyzmvCKC9fyb59P6emZhNhYWMZPPhXJCVdj8Vi83doQohuJndeEycUG3suU6ZsYMyYV1DKys6dt/D11yPJzX1ampWECFCSFAKcUhYGDLieqVM3M27cu9jtKezd+2PWrh3CgQO/obHxiL9DFEL0IEkKAjCT6yUkXMqkSV+QmfkZUVEzOHjwQdauHcI339xAVdU6f4cohOgBAXAZl+gKpRQxMbOIiZlFXd1ejhx5hvz8v1NU9Arh4eOJi7uYuLi5REfPxGIJ9ne4QohuJh3N4oSczmoKCl6kpORNKiu/QGsHFks4sbHnkZBwFQkJV2Gzxfg7TCFEBzrb0SxJQXSJ01lNRcVKyso+pKxsOQ0NOShlIy5uLklJ1xEffxlBQZH+DlMIcYzOJgVpPhJdEhQUSULC5SQkXI7WmurqDRQVLaO4+DVKS99FKTuxsReQkHA58fGXYrcP8nfIQogukJqC6BZau6ms/Iri4tcpLX2HhoYDAERGTiMm5hxCQoYSEjIEu30IISFDpDYhRA+T5iPhN1pr6uq+oaTkHUpK/kNNzSa0bjpqHbt9MJGRU4mMnEJk5FQiIjKx2RJRSvkpaiH6N2k+En6jlCI8PIPw8AyGDLkHrd00NRXS0JBDQ8NBGhpyqK3dTHX1BkpK3my1XRA2WyI2WyLBwUmEhAwjJuZcYmPPJTh4gB/fkRCBQ5KC8DmlLNjtA7HbBxIdfcZRrzkcFdTUZFFbu5WmpkKamopwOIppaiqkqGgZ+flmqu+wsLHExJzr6aPQntuMapSyEhKSTljYKEJDR0mzlBCnSJKC8CubLYbY2POIjT3vuNfcbic1NZuoqFhJefmnFBS8gNtd1+H+goMHEhzs7dzWngWUCsZqDcNiCcNqDcNqjSIqahoxMecSGjpSmq2E8JA+BdFnaO1CaxfgLcAVWjdRX7+f+vrd1NXtpr5+F01NBZ51LM2FvdvtwO2uw+Wqw+2uw+EoweEoBiA4eBAxMecSETERUwtxoLUTt9sBuDy1ErdnJlmNUkGexYbFYkMpO1ZrBEFBkVitEVitEdhsAwgNTcdqDe/pj0mINkmfguh3lLKilPWYZ4OIiBhHRMS4Lu1La019/R4qKlZ5aiIrKCp6+Zi1LJ7jWVDKgndWGK2daO0EXCc8jjc5hISkY7VGYbWGYrGYxWoNx2qN8iSTKIKCorBYQlslHbNYLHaUsmOxhGCxhKCUBaezCqezonkBN1ZrJEFBUVit3v1FdOkzEQIkKYgApZQiLGwUYWGjGDToDrTWuFzVxxTIHU8NprXbU6NowOWqxeWq8SzVNDXlU1+/n4aG/dTX76eq6mtcrhrc7npcrjo6k1BOVXBwMhERk5qX0NAROBwlNDXl0dhoFq2d2O2pniUNuz0FAJerGperGqezGre73lMTiiYoKBqrNbo5gZkkZWpjTU2FVFZ+6Vm+oK7uG8LCxhIdfSZRUWcSHT3zpK5bcbubcLlqCAqK7XPNfC21y2NPZnovSQpCYJJEUFBUF7exoFQwFktwl7d1ux2eROItfKtwuSpxuxs8zWROz+LA7W7C7W7wLI1o7fQU0DHNi6k9VONyVXn2V0Ft7Q5qajZRXv6xp2ZzNFPIBjU3o50skxzsnhoLKGUnKmo6AwbcRG3tdo4ceZbc3Mc9x4xBKXurWpDNk3DisdnisNnisVojaGzM94xWy6Gp6QimYLVjtw8iOHiQJ3kpnM4yHI4ynM4ynM5KgoKisNkSWi2JBAcne/qazE+3u87T1Lib+vo91NcfwGaL81xLYxa7PbVVLc4sWjs8gyCKcTiKcDhKCQqK8sQzCJttAKCpqcmiomI1FRWfeaaFaSIycipRUTOal+Dg5BOedLRmTkBcns/bt/c7kT4FIfo5l6uBurrt1NfvJzg4ieDgFOz2QVitYc2vNzUdobExl8bGXMByVGFosYR4akBVOJ2VOJ2VuFzVzbUeb19NSEg60dEziYycjMVibz6+27JuGKEAAAg9SURBVN1ETU02lZVfUV+/t1XCM0nP5arG4SjF4Sj1FO5VBAcnExIy1NP0NhSrNYqmpnwaG48013QAgoJMIrHZ4rBaozz7KmlempoKOxicYPEkgXScznIaGnJwOstO4ZNWKBWM1o0AhIaeRkzMbKzWMKqq1lJdnXXU9TreQQ8WSzgWi91T62xE6ybc7qbmvi2T0M2dEQcPXsSwYX88ueh6Q5+CUmou8ARgBf6mtX7omNftwEvAFKAUWKC1zvFlTEIEGqs1xHOR4JR2Xw8NHUZo6DCfHN9iCSYqajpRUdN9sv8TcTpNc55JKvlYraGEhp5GaGj6UcnLrFtFQ8NBGhtzPbW4muZmNKWsBAcnea6lScJmi8PprKKp6UhzwnK5aomKOp2YmFnHXVvjdjdSXb2J6up1OByluFy1uN21nsTa4Bm4YMdiCUap4FYDGVqaNKOizvT55+WzmoIyjWi7gQuBXGA9cL3W+ptW6/wAmKC1/p5S6jrgKq31go72KzUFIYTout5wO87pwF6t9X5t6kzLgCuOWecK4EXP768D56u+1pMkhBD9iC+TQgpwuNXjXM9zba6jTcNZJRB/7I6UUncopTYopTYUF59ap5gQQoj29YnbcWqtl2itp2qtpyYmJvo7HCGE6Ld8mRTygLRWj1M9z7W5jlIqCIjGdDgLIYTwA18mhfXASKVUulIqGLgOeOeYdd4BbvH8/i3gU93XxsgKIUQ/4rMhqVprp1LqR8CHmCGpz2uttyulfgds0Fq/A/wd+KdSai9QhkkcQggh/MSn1ylorZcDy4957retfm8A5vsyBiGEEJ3XJzqahRBC9Iw+N82FUqoYOHiSmycAJd0YTk+S2P1DYvePvhp7b457iNb6hMM3+1xSOBVKqQ2duaKvN5LY/UNi94++Gntfjbs1aT4SQgjRTJKCEEKIZoGWFJb4O4BTILH7h8TuH3019r4ad7OA6lMQQgjRsUCrKQghhOhAwCQFpdRcpdQupdRepdQif8fTEaXU80qpIqXUtlbPxSmlPlZK7fH8jPVnjO1RSqUppVYqpb5RSm1XSv3U83yvjl8pFaKUWqeU2uyJ+37P8+lKqa8935tXPVO29EpKKatSapNS6j3P4z4Ru1IqRym1VSmVrZTa4HmuV39fvJRSMUqp15VSO5VSO5RSZ/SV2NsTEEnBc8OfZ4CLgbHA9Uqpsf6NqkP/AOYe89wi4BOt9UjgE8/j3sgJ/FxrPRaYAfzQ81n39vgbgfO01hOBTGCuUmoG8DDwZ631CKAc+I4fYzyRnwI7Wj3uS7Gfq7XObDWcs7d/X7yeAD7QWo8GJmI+/74Se9u01v1+Ac4APmz1+B7gHn/HdYKYhwLbWj3eBQz0/D4Q2OXvGDv5Pv6Duften4kfCAOygNMxFyIFtfU96k0LZhbiT4DzgPcA1YdizwESjnmu139fMLM6H8DTN9uXYu9oCYiaAp274U9vN0Brne/5vQAY0NHKvYFSaigwCfj/7d3Pa1xVGMbx7yNKqYkYhQqioFZBRSixQhe2SrHgooi4qAjWIiK46aYrpfgL/APUjWhBkIpBpNq4cKWNEujC1lZjrS34C8GIOi6sWkGR+Lg4Zy5j6pgQaOaOeT5wycy5N5f3wpm8d85k3vcQQxB/XX6ZATrAO8CXwCmXBlDQ7nnzLPAw3Q7vpVnVsMRu4G1JRyU9VMdaP1+Aq4AfgZfqst2LkkYYjtj7WilJ4X/F5Rak1f82JmkUeAPYZfuX3n1tjd/2nO1xyl33BuC6AYe0KJLuADq2jw46liXaZHs9ZXl3p6Rbe3e2db5QCoquB563fSPwG/OWiloce18rJSkspuFP2/0g6VKA+rMz4Hj6knQeJSFM2N5fh4cmftungPcoSy5jtQEUtHfebATulPQ1pRf6bZS17mGIHdvf1p8dYJKSkIdhvswCs7YP1eevU5LEMMTe10pJCotp+NN2vQ2J7qes1beOJFH6ZJy0/XTPrlbHL2mNpLH6eDXlc5CTlOSwrR7WurgBbO+2fbntKylz+13b2xmC2CWNSLqg+xi4HThOy+cLgO3vgW8kXVuHtgAnGILY/9OgP9RYrg3YCnxGWSd+dNDxLBDrq8B3wJ+Uu5EHKWvEU8DnwAHg4kHH2Sf2TZS3y8eAmbptbXv8wDrgoxr3ceCJOr4WOAx8AewDVg061gWuYzPw1rDEXmP8uG6fdl+bbZ8vPfGPA0fqvHkTuGhYYu+35RvNERHRWCnLRxERsQhJChER0UhSiIiIRpJCREQ0khQiIqKRpBCxjCRt7lYxjWijJIWIiGgkKUT8C0n31f4KM5L21GJ5pyU9U/stTElaU48dl/S+pGOSJrv18yVdI+lA7dHwoaSr6+lHe2rwT9RvgUe0QpJCxDySrgfuATa6FMibA7YDI8AR2zcA08CT9VdeBh6xvQ74pGd8AnjOpUfDzZRvqUOpHLuL0ttjLaV2UUQrnLvwIRErzhbgJuCDehO/mlLU7C/gtXrMK8B+SRcCY7an6/heYF+t53OZ7UkA278D1PMdtj1bn89QemccPPuXFbGwJIWIMwnYa3v3Pwalx+cdt9QaMX/0PJ4jr8NokSwfRZxpCtgm6RJo+gVfQXm9dKuO3gsctP0z8JOkW+r4DmDa9q/ArKS76jlWSTp/Wa8iYglyhxIxj+0Tkh6jdAM7h1KtdielicqGuq9D+dwBSnnkF+of/a+AB+r4DmCPpKfqOe5exsuIWJJUSY1YJEmnbY8OOo6IsynLRxER0cg7hYiIaOSdQkRENJIUIiKikaQQERGNJIWIiGgkKURERCNJISIiGn8D8SxjXNQHA/UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.6946 - acc: 0.8177\n",
      "Loss: 0.6946397333749235 Accuracy: 0.8176532\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3730 - acc: 0.2145\n",
      "Epoch 00001: val_loss improved from inf to 1.67105, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/001-1.6710.hdf5\n",
      "36805/36805 [==============================] - 126s 3ms/sample - loss: 2.3728 - acc: 0.2145 - val_loss: 1.6710 - val_acc: 0.4647\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5193 - acc: 0.5088\n",
      "Epoch 00002: val_loss improved from 1.67105 to 1.25256, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/002-1.2526.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 1.5192 - acc: 0.5088 - val_loss: 1.2526 - val_acc: 0.6056\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3020 - acc: 0.5827\n",
      "Epoch 00003: val_loss did not improve from 1.25256\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 1.3021 - acc: 0.5826 - val_loss: 1.2764 - val_acc: 0.5823\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1879 - acc: 0.6160\n",
      "Epoch 00004: val_loss improved from 1.25256 to 1.14117, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/004-1.1412.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 1.1878 - acc: 0.6160 - val_loss: 1.1412 - val_acc: 0.6436\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0643 - acc: 0.6618\n",
      "Epoch 00005: val_loss improved from 1.14117 to 0.98725, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/005-0.9873.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 1.0643 - acc: 0.6618 - val_loss: 0.9873 - val_acc: 0.7004\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9281 - acc: 0.7071\n",
      "Epoch 00006: val_loss improved from 0.98725 to 0.86614, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/006-0.8661.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.9281 - acc: 0.7072 - val_loss: 0.8661 - val_acc: 0.7389\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8112 - acc: 0.7521\n",
      "Epoch 00007: val_loss improved from 0.86614 to 0.72626, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/007-0.7263.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.8112 - acc: 0.7521 - val_loss: 0.7263 - val_acc: 0.7810\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7052 - acc: 0.7863\n",
      "Epoch 00008: val_loss improved from 0.72626 to 0.63357, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/008-0.6336.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.7052 - acc: 0.7863 - val_loss: 0.6336 - val_acc: 0.8132\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6044 - acc: 0.8152\n",
      "Epoch 00009: val_loss improved from 0.63357 to 0.58413, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/009-0.5841.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.6044 - acc: 0.8152 - val_loss: 0.5841 - val_acc: 0.8346\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5360 - acc: 0.8395- ETA: 0s - loss: 0.5361 - acc: 0.83\n",
      "Epoch 00010: val_loss improved from 0.58413 to 0.55312, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/010-0.5531.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.5360 - acc: 0.8395 - val_loss: 0.5531 - val_acc: 0.8339\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4831 - acc: 0.8546\n",
      "Epoch 00011: val_loss improved from 0.55312 to 0.50064, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/011-0.5006.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.4831 - acc: 0.8545 - val_loss: 0.5006 - val_acc: 0.8612\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4338 - acc: 0.8695\n",
      "Epoch 00012: val_loss improved from 0.50064 to 0.46164, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/012-0.4616.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.4338 - acc: 0.8695 - val_loss: 0.4616 - val_acc: 0.8714\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3898 - acc: 0.8838\n",
      "Epoch 00013: val_loss improved from 0.46164 to 0.44271, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/013-0.4427.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.3898 - acc: 0.8838 - val_loss: 0.4427 - val_acc: 0.8721\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3679 - acc: 0.8888\n",
      "Epoch 00014: val_loss did not improve from 0.44271\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.3679 - acc: 0.8888 - val_loss: 0.4799 - val_acc: 0.8668\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3335 - acc: 0.8992\n",
      "Epoch 00015: val_loss did not improve from 0.44271\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.3335 - acc: 0.8992 - val_loss: 0.4462 - val_acc: 0.8812\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3095 - acc: 0.9063\n",
      "Epoch 00016: val_loss did not improve from 0.44271\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.3096 - acc: 0.9063 - val_loss: 0.4755 - val_acc: 0.8782\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2860 - acc: 0.9142\n",
      "Epoch 00017: val_loss improved from 0.44271 to 0.44179, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/017-0.4418.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.2859 - acc: 0.9143 - val_loss: 0.4418 - val_acc: 0.8814\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2622 - acc: 0.9188\n",
      "Epoch 00018: val_loss improved from 0.44179 to 0.40024, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/018-0.4002.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.2623 - acc: 0.9187 - val_loss: 0.4002 - val_acc: 0.8880\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2468 - acc: 0.9230\n",
      "Epoch 00019: val_loss did not improve from 0.40024\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.2467 - acc: 0.9230 - val_loss: 0.4895 - val_acc: 0.8637\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2198 - acc: 0.9328\n",
      "Epoch 00020: val_loss improved from 0.40024 to 0.37764, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv_checkpoint/020-0.3776.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.2198 - acc: 0.9328 - val_loss: 0.3776 - val_acc: 0.9031\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2130 - acc: 0.9343\n",
      "Epoch 00021: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.2130 - acc: 0.9343 - val_loss: 0.4191 - val_acc: 0.8926\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1922 - acc: 0.9399\n",
      "Epoch 00022: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1922 - acc: 0.9399 - val_loss: 0.4130 - val_acc: 0.9003\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1761 - acc: 0.9448\n",
      "Epoch 00023: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1761 - acc: 0.9448 - val_loss: 0.3913 - val_acc: 0.9022\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1662 - acc: 0.9489\n",
      "Epoch 00024: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1663 - acc: 0.9489 - val_loss: 0.4423 - val_acc: 0.8942\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9497\n",
      "Epoch 00025: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1622 - acc: 0.9497 - val_loss: 0.4205 - val_acc: 0.8935\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1467 - acc: 0.9539\n",
      "Epoch 00026: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1467 - acc: 0.9539 - val_loss: 0.4684 - val_acc: 0.8859\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9546\n",
      "Epoch 00027: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1449 - acc: 0.9546 - val_loss: 0.4811 - val_acc: 0.8880\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9566\n",
      "Epoch 00028: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.1356 - acc: 0.9566 - val_loss: 0.4407 - val_acc: 0.8928\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9586\n",
      "Epoch 00029: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.1295 - acc: 0.9586 - val_loss: 0.5242 - val_acc: 0.8982\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9610\n",
      "Epoch 00030: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1234 - acc: 0.9610 - val_loss: 0.4296 - val_acc: 0.9057\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9620\n",
      "Epoch 00031: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1175 - acc: 0.9620 - val_loss: 0.4475 - val_acc: 0.9064\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1103 - acc: 0.9642\n",
      "Epoch 00032: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1103 - acc: 0.9641 - val_loss: 0.4379 - val_acc: 0.9073\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9673\n",
      "Epoch 00033: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1021 - acc: 0.9673 - val_loss: 0.4634 - val_acc: 0.9068\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9660\n",
      "Epoch 00034: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1044 - acc: 0.9660 - val_loss: 0.4845 - val_acc: 0.9052\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9705\n",
      "Epoch 00035: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0925 - acc: 0.9705 - val_loss: 0.4545 - val_acc: 0.9071\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0969 - acc: 0.9690\n",
      "Epoch 00036: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0970 - acc: 0.9690 - val_loss: 0.4649 - val_acc: 0.9022\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9704\n",
      "Epoch 00037: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0940 - acc: 0.9704 - val_loss: 0.4863 - val_acc: 0.9010\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9716\n",
      "Epoch 00038: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0902 - acc: 0.9716 - val_loss: 0.4949 - val_acc: 0.9024\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9739\n",
      "Epoch 00039: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0835 - acc: 0.9739 - val_loss: 0.4869 - val_acc: 0.9015\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9741\n",
      "Epoch 00040: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0829 - acc: 0.9741 - val_loss: 0.4747 - val_acc: 0.9101\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9767\n",
      "Epoch 00041: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0758 - acc: 0.9767 - val_loss: 0.5532 - val_acc: 0.8963\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9745\n",
      "Epoch 00042: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0805 - acc: 0.9745 - val_loss: 0.4352 - val_acc: 0.9087\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9749\n",
      "Epoch 00043: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0811 - acc: 0.9749 - val_loss: 0.4488 - val_acc: 0.9110\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9777\n",
      "Epoch 00044: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0730 - acc: 0.9777 - val_loss: 0.4702 - val_acc: 0.9057\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9787\n",
      "Epoch 00045: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0682 - acc: 0.9787 - val_loss: 0.4698 - val_acc: 0.9143\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9785\n",
      "Epoch 00046: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0699 - acc: 0.9784 - val_loss: 0.5240 - val_acc: 0.9087\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9775\n",
      "Epoch 00047: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0736 - acc: 0.9775 - val_loss: 0.5023 - val_acc: 0.9064\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9798\n",
      "Epoch 00048: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0664 - acc: 0.9798 - val_loss: 0.4890 - val_acc: 0.9129\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9784\n",
      "Epoch 00049: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0688 - acc: 0.9784 - val_loss: 0.4378 - val_acc: 0.9092\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9782\n",
      "Epoch 00050: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0691 - acc: 0.9782 - val_loss: 0.4637 - val_acc: 0.9099\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9801\n",
      "Epoch 00051: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0608 - acc: 0.9801 - val_loss: 0.4595 - val_acc: 0.9117\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9813\n",
      "Epoch 00052: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0600 - acc: 0.9813 - val_loss: 0.4960 - val_acc: 0.9124\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9803\n",
      "Epoch 00053: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0625 - acc: 0.9803 - val_loss: 0.4641 - val_acc: 0.9119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9807\n",
      "Epoch 00054: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0615 - acc: 0.9807 - val_loss: 0.4456 - val_acc: 0.9133\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9832\n",
      "Epoch 00055: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0536 - acc: 0.9832 - val_loss: 0.4682 - val_acc: 0.9119\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9820\n",
      "Epoch 00056: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0555 - acc: 0.9820 - val_loss: 0.4849 - val_acc: 0.9061\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9805\n",
      "Epoch 00057: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0649 - acc: 0.9805 - val_loss: 0.4471 - val_acc: 0.9136\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9803\n",
      "Epoch 00058: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0650 - acc: 0.9803 - val_loss: 0.5050 - val_acc: 0.9057\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9832\n",
      "Epoch 00059: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0552 - acc: 0.9832 - val_loss: 0.4732 - val_acc: 0.9175\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9854\n",
      "Epoch 00060: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0497 - acc: 0.9854 - val_loss: 0.4588 - val_acc: 0.9199\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9863\n",
      "Epoch 00061: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0466 - acc: 0.9863 - val_loss: 0.5235 - val_acc: 0.8984\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9834\n",
      "Epoch 00062: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0562 - acc: 0.9834 - val_loss: 0.4846 - val_acc: 0.9168\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9860\n",
      "Epoch 00063: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0453 - acc: 0.9860 - val_loss: 0.4885 - val_acc: 0.9138\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9841\n",
      "Epoch 00064: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0541 - acc: 0.9841 - val_loss: 0.5301 - val_acc: 0.9071\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9860\n",
      "Epoch 00065: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0469 - acc: 0.9860 - val_loss: 0.5077 - val_acc: 0.9133\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9870\n",
      "Epoch 00066: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0458 - acc: 0.9870 - val_loss: 0.5280 - val_acc: 0.9168\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9877\n",
      "Epoch 00067: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0425 - acc: 0.9877 - val_loss: 0.5282 - val_acc: 0.9117\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9849\n",
      "Epoch 00068: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0490 - acc: 0.9849 - val_loss: 0.5201 - val_acc: 0.9143\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9869\n",
      "Epoch 00069: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0425 - acc: 0.9869 - val_loss: 0.4996 - val_acc: 0.9171\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9868\n",
      "Epoch 00070: val_loss did not improve from 0.37764\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0433 - acc: 0.9868 - val_loss: 0.4916 - val_acc: 0.9178\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4438 - acc: 0.8756\n",
      "Loss: 0.44378786629234146 Accuracy: 0.8755971\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3772 - acc: 0.2058\n",
      "Epoch 00001: val_loss improved from inf to 1.68807, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/001-1.6881.hdf5\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 2.3771 - acc: 0.2058 - val_loss: 1.6881 - val_acc: 0.4631\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4522 - acc: 0.5259\n",
      "Epoch 00002: val_loss improved from 1.68807 to 1.22575, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/002-1.2258.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 1.4521 - acc: 0.5259 - val_loss: 1.2258 - val_acc: 0.6205\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1024 - acc: 0.6457\n",
      "Epoch 00003: val_loss improved from 1.22575 to 0.92305, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/003-0.9230.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 1.1023 - acc: 0.6457 - val_loss: 0.9230 - val_acc: 0.7205\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9316 - acc: 0.7039\n",
      "Epoch 00004: val_loss improved from 0.92305 to 0.81493, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/004-0.8149.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.9317 - acc: 0.7039 - val_loss: 0.8149 - val_acc: 0.7494\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8027 - acc: 0.7437\n",
      "Epoch 00005: val_loss improved from 0.81493 to 0.66712, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/005-0.6671.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.8026 - acc: 0.7438 - val_loss: 0.6671 - val_acc: 0.8032\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6727 - acc: 0.7901\n",
      "Epoch 00006: val_loss improved from 0.66712 to 0.63444, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/006-0.6344.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.6726 - acc: 0.7901 - val_loss: 0.6344 - val_acc: 0.8092\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5641 - acc: 0.8237\n",
      "Epoch 00007: val_loss improved from 0.63444 to 0.46888, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/007-0.4689.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.5640 - acc: 0.8237 - val_loss: 0.4689 - val_acc: 0.8605\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4881 - acc: 0.8463\n",
      "Epoch 00008: val_loss improved from 0.46888 to 0.40103, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/008-0.4010.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.4881 - acc: 0.8463 - val_loss: 0.4010 - val_acc: 0.8856\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4210 - acc: 0.8700\n",
      "Epoch 00009: val_loss improved from 0.40103 to 0.35621, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/009-0.3562.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.4209 - acc: 0.8700 - val_loss: 0.3562 - val_acc: 0.9024\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3756 - acc: 0.8870\n",
      "Epoch 00010: val_loss did not improve from 0.35621\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.3756 - acc: 0.8869 - val_loss: 0.3872 - val_acc: 0.8942\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3367 - acc: 0.8968\n",
      "Epoch 00011: val_loss did not improve from 0.35621\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.3367 - acc: 0.8968 - val_loss: 0.3583 - val_acc: 0.8938\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3025 - acc: 0.9065\n",
      "Epoch 00012: val_loss improved from 0.35621 to 0.33958, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/012-0.3396.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.3024 - acc: 0.9065 - val_loss: 0.3396 - val_acc: 0.9033\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2711 - acc: 0.9168\n",
      "Epoch 00013: val_loss improved from 0.33958 to 0.32381, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/013-0.3238.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2712 - acc: 0.9168 - val_loss: 0.3238 - val_acc: 0.9101\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2633 - acc: 0.9161\n",
      "Epoch 00014: val_loss improved from 0.32381 to 0.28123, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/014-0.2812.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2633 - acc: 0.9161 - val_loss: 0.2812 - val_acc: 0.9208\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2326 - acc: 0.9274\n",
      "Epoch 00015: val_loss improved from 0.28123 to 0.26853, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/015-0.2685.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2326 - acc: 0.9274 - val_loss: 0.2685 - val_acc: 0.9259\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2166 - acc: 0.9322\n",
      "Epoch 00016: val_loss did not improve from 0.26853\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2167 - acc: 0.9322 - val_loss: 0.2686 - val_acc: 0.9313\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1983 - acc: 0.9380\n",
      "Epoch 00017: val_loss improved from 0.26853 to 0.25936, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/017-0.2594.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1984 - acc: 0.9379 - val_loss: 0.2594 - val_acc: 0.9308\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1878 - acc: 0.9421\n",
      "Epoch 00018: val_loss did not improve from 0.25936\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1878 - acc: 0.9420 - val_loss: 0.2872 - val_acc: 0.9238\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9451\n",
      "Epoch 00019: val_loss did not improve from 0.25936\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1716 - acc: 0.9451 - val_loss: 0.2716 - val_acc: 0.9320\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1611 - acc: 0.9497\n",
      "Epoch 00020: val_loss did not improve from 0.25936\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1611 - acc: 0.9497 - val_loss: 0.2767 - val_acc: 0.9273\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1521 - acc: 0.9518\n",
      "Epoch 00021: val_loss did not improve from 0.25936\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1521 - acc: 0.9519 - val_loss: 0.2645 - val_acc: 0.9271\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1410 - acc: 0.9541\n",
      "Epoch 00022: val_loss improved from 0.25936 to 0.25415, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv_checkpoint/022-0.2542.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1410 - acc: 0.9541 - val_loss: 0.2542 - val_acc: 0.9359\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9574\n",
      "Epoch 00023: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1320 - acc: 0.9575 - val_loss: 0.2755 - val_acc: 0.9320\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9604\n",
      "Epoch 00024: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1234 - acc: 0.9604 - val_loss: 0.2969 - val_acc: 0.9290\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9629\n",
      "Epoch 00025: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1174 - acc: 0.9629 - val_loss: 0.2618 - val_acc: 0.9355\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9639\n",
      "Epoch 00026: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1113 - acc: 0.9639 - val_loss: 0.2963 - val_acc: 0.9324\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9664\n",
      "Epoch 00027: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1059 - acc: 0.9664 - val_loss: 0.2822 - val_acc: 0.9366\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9691\n",
      "Epoch 00028: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0959 - acc: 0.9691 - val_loss: 0.2594 - val_acc: 0.9397\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9713\n",
      "Epoch 00029: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0911 - acc: 0.9713 - val_loss: 0.2786 - val_acc: 0.9357\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9724\n",
      "Epoch 00030: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0866 - acc: 0.9724 - val_loss: 0.2863 - val_acc: 0.9406\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9729\n",
      "Epoch 00031: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0812 - acc: 0.9729 - val_loss: 0.2849 - val_acc: 0.9390\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9734\n",
      "Epoch 00032: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0820 - acc: 0.9733 - val_loss: 0.2988 - val_acc: 0.9427\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9736\n",
      "Epoch 00033: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0792 - acc: 0.9736 - val_loss: 0.2800 - val_acc: 0.9338\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9764\n",
      "Epoch 00034: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0697 - acc: 0.9764 - val_loss: 0.2656 - val_acc: 0.9434\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9781\n",
      "Epoch 00035: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0663 - acc: 0.9781 - val_loss: 0.2662 - val_acc: 0.9336\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9761\n",
      "Epoch 00036: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0740 - acc: 0.9761 - val_loss: 0.2931 - val_acc: 0.9383\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9793\n",
      "Epoch 00037: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0629 - acc: 0.9793 - val_loss: 0.2786 - val_acc: 0.9322\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9795\n",
      "Epoch 00038: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0592 - acc: 0.9795 - val_loss: 0.3168 - val_acc: 0.9348\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9797\n",
      "Epoch 00039: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0592 - acc: 0.9797 - val_loss: 0.2927 - val_acc: 0.9448\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9805- ETA: 2s - loss: 0.0579 - \n",
      "Epoch 00040: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0584 - acc: 0.9805 - val_loss: 0.3157 - val_acc: 0.9383\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9821\n",
      "Epoch 00041: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0560 - acc: 0.9821 - val_loss: 0.3152 - val_acc: 0.9415\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9830\n",
      "Epoch 00042: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0517 - acc: 0.9830 - val_loss: 0.3635 - val_acc: 0.9285\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9823\n",
      "Epoch 00043: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0537 - acc: 0.9823 - val_loss: 0.2746 - val_acc: 0.9411\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9843\n",
      "Epoch 00044: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0480 - acc: 0.9843 - val_loss: 0.3180 - val_acc: 0.9404\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9846\n",
      "Epoch 00045: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0495 - acc: 0.9846 - val_loss: 0.3503 - val_acc: 0.9336\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9843\n",
      "Epoch 00046: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0477 - acc: 0.9843 - val_loss: 0.2770 - val_acc: 0.9392\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9869\n",
      "Epoch 00047: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0424 - acc: 0.9869 - val_loss: 0.3089 - val_acc: 0.9420\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9851\n",
      "Epoch 00048: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0448 - acc: 0.9850 - val_loss: 0.3360 - val_acc: 0.9427\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9847\n",
      "Epoch 00049: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0439 - acc: 0.9847 - val_loss: 0.3219 - val_acc: 0.9429\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9848\n",
      "Epoch 00050: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0444 - acc: 0.9848 - val_loss: 0.3360 - val_acc: 0.9376\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9868\n",
      "Epoch 00051: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0401 - acc: 0.9867 - val_loss: 0.3349 - val_acc: 0.9324\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9861\n",
      "Epoch 00052: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0412 - acc: 0.9861 - val_loss: 0.3307 - val_acc: 0.9401\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9880\n",
      "Epoch 00053: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0359 - acc: 0.9880 - val_loss: 0.3435 - val_acc: 0.9404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9879\n",
      "Epoch 00054: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0376 - acc: 0.9879 - val_loss: 0.2922 - val_acc: 0.9429\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9898\n",
      "Epoch 00055: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0324 - acc: 0.9898 - val_loss: 0.3197 - val_acc: 0.9359\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9879\n",
      "Epoch 00056: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0389 - acc: 0.9879 - val_loss: 0.3717 - val_acc: 0.9350\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9880\n",
      "Epoch 00057: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0354 - acc: 0.9880 - val_loss: 0.3062 - val_acc: 0.9425\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9889\n",
      "Epoch 00058: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0343 - acc: 0.9889 - val_loss: 0.3457 - val_acc: 0.9413\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9905\n",
      "Epoch 00059: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0291 - acc: 0.9905 - val_loss: 0.3310 - val_acc: 0.9404\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9893\n",
      "Epoch 00060: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0313 - acc: 0.9893 - val_loss: 0.4256 - val_acc: 0.9262\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9871\n",
      "Epoch 00061: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0362 - acc: 0.9871 - val_loss: 0.3216 - val_acc: 0.9422\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9903\n",
      "Epoch 00062: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0286 - acc: 0.9903 - val_loss: 0.3270 - val_acc: 0.9413\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9896\n",
      "Epoch 00063: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0311 - acc: 0.9896 - val_loss: 0.3307 - val_acc: 0.9369\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9900\n",
      "Epoch 00064: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0291 - acc: 0.9900 - val_loss: 0.2903 - val_acc: 0.9390\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9904\n",
      "Epoch 00065: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0302 - acc: 0.9904 - val_loss: 0.3184 - val_acc: 0.9408\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9901\n",
      "Epoch 00066: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0312 - acc: 0.9901 - val_loss: 0.3092 - val_acc: 0.9401\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9909\n",
      "Epoch 00067: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0284 - acc: 0.9909 - val_loss: 0.3056 - val_acc: 0.9422\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9904\n",
      "Epoch 00068: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0284 - acc: 0.9904 - val_loss: 0.3012 - val_acc: 0.9432\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9918\n",
      "Epoch 00069: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0253 - acc: 0.9918 - val_loss: 0.3646 - val_acc: 0.9404\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9917\n",
      "Epoch 00070: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0241 - acc: 0.9917 - val_loss: 0.3188 - val_acc: 0.9429\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9923\n",
      "Epoch 00071: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0248 - acc: 0.9923 - val_loss: 0.3460 - val_acc: 0.9415\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9906\n",
      "Epoch 00072: val_loss did not improve from 0.25415\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0289 - acc: 0.9906 - val_loss: 0.3182 - val_acc: 0.9401\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2968 - acc: 0.9119\n",
      "Loss: 0.29676123994904513 Accuracy: 0.9119418\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4760 - acc: 0.1814\n",
      "Epoch 00001: val_loss improved from inf to 1.79546, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/001-1.7955.hdf5\n",
      "36805/36805 [==============================] - 138s 4ms/sample - loss: 2.4761 - acc: 0.1813 - val_loss: 1.7955 - val_acc: 0.4396\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5587 - acc: 0.4873\n",
      "Epoch 00002: val_loss improved from 1.79546 to 1.28443, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/002-1.2844.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 1.5586 - acc: 0.4874 - val_loss: 1.2844 - val_acc: 0.5775\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0332 - acc: 0.6675\n",
      "Epoch 00003: val_loss improved from 1.28443 to 0.85090, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/003-0.8509.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 1.0333 - acc: 0.6675 - val_loss: 0.8509 - val_acc: 0.7407\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8086 - acc: 0.7430\n",
      "Epoch 00004: val_loss improved from 0.85090 to 0.63082, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/004-0.6308.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.8087 - acc: 0.7430 - val_loss: 0.6308 - val_acc: 0.8006\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6684 - acc: 0.7847\n",
      "Epoch 00005: val_loss did not improve from 0.63082\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.6686 - acc: 0.7846 - val_loss: 0.6398 - val_acc: 0.8008\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5729 - acc: 0.8171\n",
      "Epoch 00006: val_loss improved from 0.63082 to 0.43888, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/006-0.4389.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.5729 - acc: 0.8171 - val_loss: 0.4389 - val_acc: 0.8742\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4744 - acc: 0.8479\n",
      "Epoch 00007: val_loss improved from 0.43888 to 0.36142, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/007-0.3614.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.4743 - acc: 0.8479 - val_loss: 0.3614 - val_acc: 0.8868\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4142 - acc: 0.8685\n",
      "Epoch 00008: val_loss improved from 0.36142 to 0.35172, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/008-0.3517.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.4142 - acc: 0.8685 - val_loss: 0.3517 - val_acc: 0.8980\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3574 - acc: 0.8868\n",
      "Epoch 00009: val_loss improved from 0.35172 to 0.26434, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/009-0.2643.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.3575 - acc: 0.8868 - val_loss: 0.2643 - val_acc: 0.9213\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3188 - acc: 0.8975\n",
      "Epoch 00010: val_loss did not improve from 0.26434\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.3188 - acc: 0.8975 - val_loss: 0.2671 - val_acc: 0.9213\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2902 - acc: 0.9084\n",
      "Epoch 00011: val_loss improved from 0.26434 to 0.24116, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/011-0.2412.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.2902 - acc: 0.9084 - val_loss: 0.2412 - val_acc: 0.9320\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2598 - acc: 0.9171\n",
      "Epoch 00012: val_loss improved from 0.24116 to 0.21972, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/012-0.2197.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.2598 - acc: 0.9171 - val_loss: 0.2197 - val_acc: 0.9413\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2355 - acc: 0.9261\n",
      "Epoch 00013: val_loss did not improve from 0.21972\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2355 - acc: 0.9261 - val_loss: 0.2258 - val_acc: 0.9308\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2218 - acc: 0.9281\n",
      "Epoch 00014: val_loss did not improve from 0.21972\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2218 - acc: 0.9281 - val_loss: 0.2247 - val_acc: 0.9322\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2062 - acc: 0.9336\n",
      "Epoch 00015: val_loss improved from 0.21972 to 0.20153, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/015-0.2015.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2062 - acc: 0.9337 - val_loss: 0.2015 - val_acc: 0.9411\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9387\n",
      "Epoch 00016: val_loss improved from 0.20153 to 0.18695, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/016-0.1869.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1920 - acc: 0.9387 - val_loss: 0.1869 - val_acc: 0.9453\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9438\n",
      "Epoch 00017: val_loss improved from 0.18695 to 0.18621, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/017-0.1862.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1722 - acc: 0.9438 - val_loss: 0.1862 - val_acc: 0.9446\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9486\n",
      "Epoch 00018: val_loss improved from 0.18621 to 0.17280, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/018-0.1728.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1598 - acc: 0.9486 - val_loss: 0.1728 - val_acc: 0.9504\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9514\n",
      "Epoch 00019: val_loss did not improve from 0.17280\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1465 - acc: 0.9514 - val_loss: 0.1838 - val_acc: 0.9495\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.9529\n",
      "Epoch 00020: val_loss did not improve from 0.17280\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1430 - acc: 0.9529 - val_loss: 0.1833 - val_acc: 0.9488\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9560\n",
      "Epoch 00021: val_loss improved from 0.17280 to 0.16787, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/021-0.1679.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1328 - acc: 0.9560 - val_loss: 0.1679 - val_acc: 0.9476\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9595\n",
      "Epoch 00022: val_loss did not improve from 0.16787\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1239 - acc: 0.9595 - val_loss: 0.2144 - val_acc: 0.9392\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9623\n",
      "Epoch 00023: val_loss did not improve from 0.16787\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1193 - acc: 0.9623 - val_loss: 0.2057 - val_acc: 0.9443\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9608\n",
      "Epoch 00024: val_loss did not improve from 0.16787\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1161 - acc: 0.9608 - val_loss: 0.1908 - val_acc: 0.9467\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9663\n",
      "Epoch 00025: val_loss improved from 0.16787 to 0.16447, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv_checkpoint/025-0.1645.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1028 - acc: 0.9663 - val_loss: 0.1645 - val_acc: 0.9543\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9675\n",
      "Epoch 00026: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0996 - acc: 0.9675 - val_loss: 0.1897 - val_acc: 0.9499\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9685\n",
      "Epoch 00027: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0918 - acc: 0.9685 - val_loss: 0.2325 - val_acc: 0.9392\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9693\n",
      "Epoch 00028: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0937 - acc: 0.9693 - val_loss: 0.2189 - val_acc: 0.9401\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9730\n",
      "Epoch 00029: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0799 - acc: 0.9730 - val_loss: 0.2005 - val_acc: 0.9509\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9726\n",
      "Epoch 00030: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0814 - acc: 0.9726 - val_loss: 0.2164 - val_acc: 0.9441\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9766\n",
      "Epoch 00031: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0712 - acc: 0.9766 - val_loss: 0.1917 - val_acc: 0.9529\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9757\n",
      "Epoch 00032: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0737 - acc: 0.9757 - val_loss: 0.1931 - val_acc: 0.9520\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9778\n",
      "Epoch 00033: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0676 - acc: 0.9777 - val_loss: 0.1933 - val_acc: 0.9529\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9782\n",
      "Epoch 00034: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0674 - acc: 0.9782 - val_loss: 0.1779 - val_acc: 0.9534\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9790\n",
      "Epoch 00035: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0614 - acc: 0.9790 - val_loss: 0.2026 - val_acc: 0.9571\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9789\n",
      "Epoch 00036: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0619 - acc: 0.9789 - val_loss: 0.2010 - val_acc: 0.9555\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9810\n",
      "Epoch 00037: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0559 - acc: 0.9810 - val_loss: 0.2139 - val_acc: 0.9485\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9814\n",
      "Epoch 00038: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0551 - acc: 0.9814 - val_loss: 0.1901 - val_acc: 0.9522\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9805\n",
      "Epoch 00039: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0593 - acc: 0.9805 - val_loss: 0.1831 - val_acc: 0.9571\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9836\n",
      "Epoch 00040: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0488 - acc: 0.9836 - val_loss: 0.1894 - val_acc: 0.9576\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9809\n",
      "Epoch 00041: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0558 - acc: 0.9809 - val_loss: 0.1888 - val_acc: 0.9527\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9836\n",
      "Epoch 00042: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0499 - acc: 0.9836 - val_loss: 0.2169 - val_acc: 0.9492\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9865\n",
      "Epoch 00043: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0420 - acc: 0.9865 - val_loss: 0.1860 - val_acc: 0.9562\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9843\n",
      "Epoch 00044: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0479 - acc: 0.9843 - val_loss: 0.2805 - val_acc: 0.9390\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9840\n",
      "Epoch 00045: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0473 - acc: 0.9840 - val_loss: 0.1771 - val_acc: 0.9550\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9857\n",
      "Epoch 00046: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0439 - acc: 0.9857 - val_loss: 0.2036 - val_acc: 0.9543\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9857\n",
      "Epoch 00047: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0416 - acc: 0.9857 - val_loss: 0.1914 - val_acc: 0.9562\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9879\n",
      "Epoch 00048: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0368 - acc: 0.9879 - val_loss: 0.2504 - val_acc: 0.9525\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9851\n",
      "Epoch 00049: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0450 - acc: 0.9851 - val_loss: 0.1914 - val_acc: 0.9546\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9877\n",
      "Epoch 00050: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0360 - acc: 0.9877 - val_loss: 0.2188 - val_acc: 0.9534\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9858\n",
      "Epoch 00051: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0424 - acc: 0.9858 - val_loss: 0.1975 - val_acc: 0.9520\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9882\n",
      "Epoch 00052: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0350 - acc: 0.9882 - val_loss: 0.2679 - val_acc: 0.9527\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9880\n",
      "Epoch 00053: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0360 - acc: 0.9880 - val_loss: 0.2125 - val_acc: 0.9548\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9890\n",
      "Epoch 00054: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0353 - acc: 0.9891 - val_loss: 0.1761 - val_acc: 0.9597\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9888\n",
      "Epoch 00055: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0355 - acc: 0.9888 - val_loss: 0.2226 - val_acc: 0.9502\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9895\n",
      "Epoch 00056: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0336 - acc: 0.9895 - val_loss: 0.1948 - val_acc: 0.9569\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9901\n",
      "Epoch 00057: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0299 - acc: 0.9901 - val_loss: 0.2141 - val_acc: 0.9590\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9902\n",
      "Epoch 00058: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0295 - acc: 0.9902 - val_loss: 0.2279 - val_acc: 0.9527\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9886\n",
      "Epoch 00059: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0333 - acc: 0.9886 - val_loss: 0.2357 - val_acc: 0.9567\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9905\n",
      "Epoch 00060: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0293 - acc: 0.9905 - val_loss: 0.2388 - val_acc: 0.9460\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9899\n",
      "Epoch 00061: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0329 - acc: 0.9899 - val_loss: 0.2466 - val_acc: 0.9453\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9901\n",
      "Epoch 00062: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0305 - acc: 0.9901 - val_loss: 0.2439 - val_acc: 0.9557\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9905\n",
      "Epoch 00063: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0289 - acc: 0.9905 - val_loss: 0.1794 - val_acc: 0.9613\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9917\n",
      "Epoch 00064: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0249 - acc: 0.9917 - val_loss: 0.1934 - val_acc: 0.9557\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9918\n",
      "Epoch 00065: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0258 - acc: 0.9918 - val_loss: 0.2060 - val_acc: 0.9564\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9908\n",
      "Epoch 00066: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0288 - acc: 0.9908 - val_loss: 0.1980 - val_acc: 0.9595\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9915\n",
      "Epoch 00067: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0263 - acc: 0.9915 - val_loss: 0.2142 - val_acc: 0.9581\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9913- ETA: 1s - loss: 0.0278 - acc: 0\n",
      "Epoch 00068: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0278 - acc: 0.9913 - val_loss: 0.2224 - val_acc: 0.9562\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9919\n",
      "Epoch 00069: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0252 - acc: 0.9919 - val_loss: 0.2071 - val_acc: 0.9595\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9923\n",
      "Epoch 00070: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0246 - acc: 0.9923 - val_loss: 0.2162 - val_acc: 0.9567\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9926\n",
      "Epoch 00071: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0244 - acc: 0.9926 - val_loss: 0.2096 - val_acc: 0.9536\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9929\n",
      "Epoch 00072: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0232 - acc: 0.9929 - val_loss: 0.2263 - val_acc: 0.9613\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9918\n",
      "Epoch 00073: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0248 - acc: 0.9918 - val_loss: 0.2148 - val_acc: 0.9625\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9917\n",
      "Epoch 00074: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0277 - acc: 0.9917 - val_loss: 0.2419 - val_acc: 0.9574\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9935\n",
      "Epoch 00075: val_loss did not improve from 0.16447\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0203 - acc: 0.9935 - val_loss: 0.2086 - val_acc: 0.9623\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.2207 - acc: 0.9352\n",
      "Loss: 0.22074207322495995 Accuracy: 0.9352025\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4660 - acc: 0.1793\n",
      "Epoch 00001: val_loss improved from inf to 1.80651, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/001-1.8065.hdf5\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 2.4660 - acc: 0.1794 - val_loss: 1.8065 - val_acc: 0.4093\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4661 - acc: 0.5082\n",
      "Epoch 00002: val_loss improved from 1.80651 to 1.08256, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/002-1.0826.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 1.4662 - acc: 0.5082 - val_loss: 1.0826 - val_acc: 0.6557\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9380 - acc: 0.6925\n",
      "Epoch 00003: val_loss improved from 1.08256 to 0.68645, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/003-0.6864.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.9380 - acc: 0.6925 - val_loss: 0.6864 - val_acc: 0.7792\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7104 - acc: 0.7721\n",
      "Epoch 00004: val_loss improved from 0.68645 to 0.60608, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/004-0.6061.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.7104 - acc: 0.7722 - val_loss: 0.6061 - val_acc: 0.8132\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5832 - acc: 0.8094\n",
      "Epoch 00005: val_loss improved from 0.60608 to 0.40320, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/005-0.4032.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.5832 - acc: 0.8094 - val_loss: 0.4032 - val_acc: 0.8737\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4781 - acc: 0.8455\n",
      "Epoch 00006: val_loss improved from 0.40320 to 0.36003, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/006-0.3600.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.4781 - acc: 0.8455 - val_loss: 0.3600 - val_acc: 0.8966\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4058 - acc: 0.8684\n",
      "Epoch 00007: val_loss improved from 0.36003 to 0.27686, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/007-0.2769.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.4058 - acc: 0.8684 - val_loss: 0.2769 - val_acc: 0.9159\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3552 - acc: 0.8858\n",
      "Epoch 00008: val_loss improved from 0.27686 to 0.25151, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/008-0.2515.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.3551 - acc: 0.8858 - val_loss: 0.2515 - val_acc: 0.9203\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3104 - acc: 0.9006\n",
      "Epoch 00009: val_loss improved from 0.25151 to 0.24743, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/009-0.2474.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.3106 - acc: 0.9005 - val_loss: 0.2474 - val_acc: 0.9250\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2811 - acc: 0.9103\n",
      "Epoch 00010: val_loss did not improve from 0.24743\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.2810 - acc: 0.9103 - val_loss: 0.2497 - val_acc: 0.9213\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2494 - acc: 0.9184\n",
      "Epoch 00011: val_loss improved from 0.24743 to 0.20291, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/011-0.2029.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.2494 - acc: 0.9184 - val_loss: 0.2029 - val_acc: 0.9392\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2311 - acc: 0.9255\n",
      "Epoch 00012: val_loss improved from 0.20291 to 0.18418, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/012-0.1842.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.2311 - acc: 0.9256 - val_loss: 0.1842 - val_acc: 0.9467\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9317\n",
      "Epoch 00013: val_loss improved from 0.18418 to 0.17481, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/013-0.1748.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.2108 - acc: 0.9317 - val_loss: 0.1748 - val_acc: 0.9485\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1950 - acc: 0.9385\n",
      "Epoch 00014: val_loss did not improve from 0.17481\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1949 - acc: 0.9385 - val_loss: 0.1868 - val_acc: 0.9432\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9385\n",
      "Epoch 00015: val_loss did not improve from 0.17481\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1847 - acc: 0.9385 - val_loss: 0.1942 - val_acc: 0.9432\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9457\n",
      "Epoch 00016: val_loss improved from 0.17481 to 0.15657, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/016-0.1566.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1724 - acc: 0.9457 - val_loss: 0.1566 - val_acc: 0.9522\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9513\n",
      "Epoch 00017: val_loss did not improve from 0.15657\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1556 - acc: 0.9513 - val_loss: 0.1944 - val_acc: 0.9373\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9533\n",
      "Epoch 00018: val_loss improved from 0.15657 to 0.14726, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/018-0.1473.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1448 - acc: 0.9533 - val_loss: 0.1473 - val_acc: 0.9567\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1391 - acc: 0.9537\n",
      "Epoch 00019: val_loss improved from 0.14726 to 0.14437, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/019-0.1444.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1391 - acc: 0.9537 - val_loss: 0.1444 - val_acc: 0.9571\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9575\n",
      "Epoch 00020: val_loss did not improve from 0.14437\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1305 - acc: 0.9575 - val_loss: 0.1747 - val_acc: 0.9460\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9596- ETA: 1s - loss: 0.1231 - acc\n",
      "Epoch 00021: val_loss did not improve from 0.14437\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1234 - acc: 0.9596 - val_loss: 0.1909 - val_acc: 0.9469\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9633- ETA: 2s - loss: 0.1115 - a\n",
      "Epoch 00022: val_loss did not improve from 0.14437\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1115 - acc: 0.9633 - val_loss: 0.1585 - val_acc: 0.9581\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9652\n",
      "Epoch 00023: val_loss did not improve from 0.14437\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1064 - acc: 0.9652 - val_loss: 0.1811 - val_acc: 0.9478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9666\n",
      "Epoch 00024: val_loss did not improve from 0.14437\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1015 - acc: 0.9666 - val_loss: 0.1550 - val_acc: 0.9541\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9671\n",
      "Epoch 00025: val_loss improved from 0.14437 to 0.14430, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv_checkpoint/025-0.1443.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0985 - acc: 0.9671 - val_loss: 0.1443 - val_acc: 0.9583\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9692\n",
      "Epoch 00026: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0932 - acc: 0.9692 - val_loss: 0.1519 - val_acc: 0.9564\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9710\n",
      "Epoch 00027: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0857 - acc: 0.9710 - val_loss: 0.1462 - val_acc: 0.9578\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9722\n",
      "Epoch 00028: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0828 - acc: 0.9722 - val_loss: 0.1589 - val_acc: 0.9567\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9756\n",
      "Epoch 00029: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0749 - acc: 0.9756 - val_loss: 0.1736 - val_acc: 0.9560\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9733\n",
      "Epoch 00030: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0773 - acc: 0.9733 - val_loss: 0.1477 - val_acc: 0.9616\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9768\n",
      "Epoch 00031: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0714 - acc: 0.9768 - val_loss: 0.1557 - val_acc: 0.9599\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9764\n",
      "Epoch 00032: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0701 - acc: 0.9763 - val_loss: 0.1465 - val_acc: 0.9616\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9785\n",
      "Epoch 00033: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0640 - acc: 0.9785 - val_loss: 0.1929 - val_acc: 0.9518\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9790- ETA: 4s - loss:\n",
      "Epoch 00034: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0626 - acc: 0.9790 - val_loss: 0.1770 - val_acc: 0.9562\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9799\n",
      "Epoch 00035: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0582 - acc: 0.9799 - val_loss: 0.1467 - val_acc: 0.9625\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9805\n",
      "Epoch 00036: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0605 - acc: 0.9805 - val_loss: 0.1786 - val_acc: 0.9541\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9821\n",
      "Epoch 00037: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0543 - acc: 0.9821 - val_loss: 0.1564 - val_acc: 0.9606\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9829\n",
      "Epoch 00038: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0501 - acc: 0.9829 - val_loss: 0.1765 - val_acc: 0.9578\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9839\n",
      "Epoch 00039: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0483 - acc: 0.9839 - val_loss: 0.1743 - val_acc: 0.9585\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9821\n",
      "Epoch 00040: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0529 - acc: 0.9821 - val_loss: 0.1468 - val_acc: 0.9604\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9847\n",
      "Epoch 00041: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0460 - acc: 0.9847 - val_loss: 0.1802 - val_acc: 0.9585\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9848\n",
      "Epoch 00042: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0459 - acc: 0.9848 - val_loss: 0.1617 - val_acc: 0.9585\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9854\n",
      "Epoch 00043: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0433 - acc: 0.9854 - val_loss: 0.1552 - val_acc: 0.9611\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9851\n",
      "Epoch 00044: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0416 - acc: 0.9851 - val_loss: 0.1590 - val_acc: 0.9625\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9863\n",
      "Epoch 00045: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0419 - acc: 0.9863 - val_loss: 0.1684 - val_acc: 0.9604\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9867\n",
      "Epoch 00046: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0409 - acc: 0.9867 - val_loss: 0.2096 - val_acc: 0.9522\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9868\n",
      "Epoch 00047: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0399 - acc: 0.9868 - val_loss: 0.1617 - val_acc: 0.9606\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9869\n",
      "Epoch 00048: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0395 - acc: 0.9869 - val_loss: 0.1778 - val_acc: 0.9574\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9877\n",
      "Epoch 00049: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0362 - acc: 0.9877 - val_loss: 0.1926 - val_acc: 0.9546\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9882\n",
      "Epoch 00050: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0362 - acc: 0.9882 - val_loss: 0.1852 - val_acc: 0.9576\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9880\n",
      "Epoch 00051: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0364 - acc: 0.9880 - val_loss: 0.1776 - val_acc: 0.9618\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9889\n",
      "Epoch 00052: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0349 - acc: 0.9889 - val_loss: 0.1824 - val_acc: 0.9630\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9882\n",
      "Epoch 00053: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0353 - acc: 0.9882 - val_loss: 0.1833 - val_acc: 0.9585\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9897\n",
      "Epoch 00054: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0311 - acc: 0.9897 - val_loss: 0.1865 - val_acc: 0.9562\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9899\n",
      "Epoch 00055: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0296 - acc: 0.9899 - val_loss: 0.1787 - val_acc: 0.9611\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9889\n",
      "Epoch 00056: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0345 - acc: 0.9889 - val_loss: 0.1850 - val_acc: 0.9625\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9905\n",
      "Epoch 00057: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0290 - acc: 0.9905 - val_loss: 0.1779 - val_acc: 0.9672\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9902\n",
      "Epoch 00058: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0319 - acc: 0.9902 - val_loss: 0.1999 - val_acc: 0.9592\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9907\n",
      "Epoch 00059: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0295 - acc: 0.9907 - val_loss: 0.1870 - val_acc: 0.9613\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9915\n",
      "Epoch 00060: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0275 - acc: 0.9915 - val_loss: 0.1737 - val_acc: 0.9651\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9913\n",
      "Epoch 00061: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0272 - acc: 0.9913 - val_loss: 0.1733 - val_acc: 0.9604\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9908\n",
      "Epoch 00062: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0274 - acc: 0.9908 - val_loss: 0.1983 - val_acc: 0.9641\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9911\n",
      "Epoch 00063: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0274 - acc: 0.9911 - val_loss: 0.1697 - val_acc: 0.9634\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9913\n",
      "Epoch 00064: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0286 - acc: 0.9913 - val_loss: 0.1722 - val_acc: 0.9634\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9920\n",
      "Epoch 00065: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0246 - acc: 0.9920 - val_loss: 0.2111 - val_acc: 0.9592\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9925\n",
      "Epoch 00066: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0228 - acc: 0.9925 - val_loss: 0.2048 - val_acc: 0.9653\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9901\n",
      "Epoch 00067: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0308 - acc: 0.9901 - val_loss: 0.1909 - val_acc: 0.9595\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9924\n",
      "Epoch 00068: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0235 - acc: 0.9924 - val_loss: 0.1660 - val_acc: 0.9667\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9937\n",
      "Epoch 00069: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0195 - acc: 0.9937 - val_loss: 0.1843 - val_acc: 0.9623\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9927- ETA: 2s - loss: 0.0224 - a\n",
      "Epoch 00070: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0224 - acc: 0.9927 - val_loss: 0.2029 - val_acc: 0.9588\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9922\n",
      "Epoch 00071: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0237 - acc: 0.9922 - val_loss: 0.2057 - val_acc: 0.9641\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9924\n",
      "Epoch 00072: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0246 - acc: 0.9924 - val_loss: 0.1966 - val_acc: 0.9616\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9932\n",
      "Epoch 00073: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0226 - acc: 0.9932 - val_loss: 0.2087 - val_acc: 0.9611\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9941\n",
      "Epoch 00074: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0193 - acc: 0.9941 - val_loss: 0.1748 - val_acc: 0.9641\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9930\n",
      "Epoch 00075: val_loss did not improve from 0.14430\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0229 - acc: 0.9930 - val_loss: 0.1869 - val_acc: 0.9639\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3XmcFNW5+P/P6X169o1hh1FBh3WQJShRSVzikrgG0WiMJnHJNSZeb4zEJF5j4jdq9CZxi0Fjol7i8lNxRTEYEL0RwyIoq4iALMOszL709vz+ON09CzMw4PTMQD/v16tevdTpqqequ+upOqfqlBERlFJKKQBHXweglFKq/9CkoJRSKk6TglJKqThNCkoppeI0KSillIrTpKCUUipOk4JSSqk4TQpKKaXiNCkopZSKc/V1AAcrLy9PRo4c2ddhKKXUYWXlypUVIpJ/oHKHXVIYOXIkK1as6OswlFLqsGKM2d6dclp9pJRSKk6TglJKqbiEJQVjzDBjzGJjzHpjzDpjzI87KTPTGFNjjFkdHW5LVDxKKaUOLJFtCiHgv0RklTEmHVhpjPmHiKzvUO5dEfn6F5lRMBhk586dNDc3f5HJJDWfz8fQoUNxu919HYpSqg8lLCmISAlQEn1eZ4zZAAwBOiaFL2znzp2kp6czcuRIjDE9PfkjnohQWVnJzp07KSws7OtwlFJ9qFfaFIwxI4FJwAedjD7BGLPGGPOGMWZsF5+/xhizwhizory8fJ/xzc3N5ObmakI4RMYYcnNz9UhLKZX4pGCMSQNeAG4UkdoOo1cBI0RkIvAA8FJn0xCRuSIyRUSm5Od3fpqtJoQvRtefUgoSnBSMMW5sQpgnIi92HC8itSJSH32+AHAbY/ISEUs43ERLyy4ikWAiJq+UUkeERJ59ZIC/ABtE5H+6KDMwWg5jzLRoPJWJiCcSaSYQKEGk55NCdXU1Dz/88CF99uyzz6a6urrb5W+//XbuvffeQ5qXUkodSCKPFGYA3wa+2uaU07ONMdcZY66LlvkmsNYYswa4H7hERCQRwRjjBEAk3OPT3l9SCIVC+/3sggULyMrK6vGYlFLqUCQsKYjIeyJiRGSCiBRHhwUi8oiIPBIt86CIjBWRiSIyXUT+lah4Whc10uNTnjNnDlu2bKG4uJibb76ZJUuWcNJJJ3HuuecyZswYAM4//3wmT57M2LFjmTt3bvyzI0eOpKKigm3btlFUVMTVV1/N2LFjOeOMM2hqatrvfFevXs306dOZMGECF1xwAXv37gXg/vvvZ8yYMUyYMIFLLrkEgHfeeYfi4mKKi4uZNGkSdXV1Pb4elFKHv8Ou76MD2bz5RurrV3cyJkI43IDDkYIxB7fYaWnFjBr1hy7H33XXXaxdu5bVq+18lyxZwqpVq1i7dm38FM/HH3+cnJwcmpqamDp1KhdddBG5ubkdYt/M008/zaOPPsrFF1/MCy+8wOWXX97lfK+44goeeOABTjnlFG677TZ+9atf8Yc//IG77rqLrVu34vV641VT9957Lw899BAzZsygvr4en893UOtAKZUckrCbi4TUTu1j2rRp7c75v//++5k4cSLTp09nx44dbN68eZ/PFBYWUlxcDMDkyZPZtm1bl9OvqamhurqaU045BYDvfOc7LF26FIAJEyZw2WWX8b//+7+4XDYBzpgxg5tuuon777+f6urq+PtKKdXWEbdl6GqPPhIJ0dCwGq93GB5PQcLjSE1NjT9fsmQJixYt4v3338fv9zNz5sxOrwnwer3x506n84DVR115/fXXWbp0Ka+++ip33nknH3/8MXPmzOGcc85hwYIFzJgxg4ULF3Lccccd0vSVUkeupDlSSGRDc3p6+n7r6GtqasjOzsbv97Nx40aWLVv2heeZmZlJdnY27777LgBPPfUUp5xyCpFIhB07dvCVr3yFu+++m5qaGurr69myZQvjx4/nlltuYerUqWzcuPELx6CUOvIccUcKXbFnvhpEer6hOTc3lxkzZjBu3DjOOusszjnnnHbjzzzzTB555BGKioo49thjmT59eo/M94knnuC6666jsbGRo446ir/+9a+Ew2Euv/xyampqEBF+9KMfkZWVxS9/+UsWL16Mw+Fg7NixnHXWWT0Sg1LqyGISdAZowkyZMkU63mRnw4YNFBUVHfCz9fWrcbmy8flGJCq8w1p316NS6vBjjFkpIlMOVC5pqo8sZ0Kqj5RS6kiRVEnBGEdCqo+UUupIkWRJwQnokYJSSnUlqZKCVh8ppdT+JVVS0OojpZTav6RKCqDVR0optT9JlRSM6T/VR2lpaQf1vlJK9YYkSwoOIMLhdm2GUkr1lqRKCrb6CHq6++w5c+bw0EMPxV/HboRTX1/PqaeeyvHHH8/48eN5+eWXuz1NEeHmm29m3LhxjB8/nmeffRaAkpISTj75ZIqLixk3bhzvvvsu4XCYK6+8Ml7297//fY8un1IqeRx53VzceCOs7qzrbHBLEGekGZxpwEHck7i4GP7QddfZs2fP5sYbb+T6668H4LnnnmPhwoX4fD7mz59PRkYGFRUVTJ8+nXPPPbdb90N+8cUXWb16NWvWrKGiooKpU6dy8skn8/e//52vfe1r/PznPyccDtPY2Mjq1avZtWsXa9euBTioO7kppVRbR15S6A4R6MEb1U+aNImysjJ2795NeXk52dnZDBs2jGAwyK233srSpUtxOBzs2rWL0tJSBg4ceMBpvvfee1x66aU4nU4KCgo45ZRTWL58OVOnTuW73/0uwWCQ888/n+LiYo466ig+++wzbrjhBs455xzOOOOMHls2pVRyOfKSwn726MPBapqbP8XvL8LpTO2y3KGYNWsWzz//PHv27GH27NkAzJs3j/LyclauXInb7WbkyJGddpl9ME4++WSWLl3K66+/zpVXXslNN93EFVdcwZo1a1i4cCGPPPIIzz33HI8//nhPLJZSKskkVZuCbWgmIdcqzJ49m2eeeYbnn3+eWbNmAbbL7AEDBuB2u1m8eDHbt2/v9vROOukknn32WcLhMOXl5SxdupRp06axfft2CgoKuPrqq/n+97/PqlWrqKioIBKJcNFFF/Gb3/yGVatW9fjyKaWSw5F3pLAfibynwtixY6mrq2PIkCEMGjQIgMsuu4xvfOMbjB8/nilTphzUTW0uuOAC3n//fSZOnIgxhnvuuYeBAwfyxBNP8Lvf/Q63201aWhpPPvkku3bt4qqrriISscnut7/9bY8vn1IqOSRV19nhcDONjWvx+Qpxu3MPWD7ZaNfZSh25tOvsTrRWH/WPC9iUUqq/SbKkEKs+0v6PlFKqM0mVFFoXV48UlFKqM0mVFOxFY9pTqlJKdSWpkgL0r07xlFKqv0m6pKDdZyulVNeSLikk4kY71dXVPPzww4f02bPPPlv7KlJK9RtJmBR6/khhf0khFArt97MLFiwgKyurR+NRSqlDlXRJwTY092xSmDNnDlu2bKG4uJibb76ZJUuWcNJJJ3HuuecyZswYAM4//3wmT57M2LFjmTt3bvyzI0eOpKKigm3btlFUVMTVV1/N2LFjOeOMM2hqatpnXq+++ipf+tKXmDRpEqeddhqlpaUA1NfXc9VVVzF+/HgmTJjACy+8AMCbb77J8ccfz8SJEzn11FN7dLmVUkeeI66bi/30nA1AJDIUkTBOZ9dlOjpAz9ncddddrF27ltXRGS9ZsoRVq1axdu1aCgsLAXj88cfJycmhqamJqVOnctFFF5Gb2/6q6s2bN/P000/z6KOPcvHFF/PCCy9w+eWXtyvz5S9/mWXLlmGM4bHHHuOee+7hvvvu49e//jWZmZl8/PHHAOzdu5fy8nKuvvpqli5dSmFhIVVVVd1faKVUUkpYUjDGDAOeBAoAAeaKyB87lDHAH4GzgUbgShFJcG9uPddl9v5MmzYtnhAA7r//fubPnw/Ajh072Lx58z5JobCwkOLiYgAmT57Mtm3b9pnuzp07mT17NiUlJQQCgfg8Fi1axDPPPBMvl52dzauvvsrJJ58cL5OTk9Ojy6iUOvIk8kghBPyXiKwyxqQDK40x/xCR9W3KnAWMig5fAv4UfTxk+9ujB2huLicYLCM9ffIXmc0Bpaa2ds29ZMkSFi1axPvvv4/f72fmzJmddqHt9Xrjz51OZ6fVRzfccAM33XQT5557LkuWLOH2229PSPxKqeSUsDYFESmJ7fWLSB2wARjSodh5wJNiLQOyjDGDEhUTxBqapUfv05yenk5dXV2X42tqasjOzsbv97Nx40aWLVt2yPOqqalhyBC7Gp944on4+6effnq7W4Lu3buX6dOns3TpUrZu3Qqg1UdKqQPqlYZmY8xIYBLwQYdRQ4AdbV7vZN/E0cOx9Hz32bm5ucyYMYNx48Zx88037zP+zDPPJBQKUVRUxJw5c5g+ffohz+v2229n1qxZTJ48mby8vPj7v/jFL9i7dy/jxo1j4sSJLF68mPz8fObOncuFF17IxIkT4zf/UUqpriS862xjTBrwDnCniLzYYdxrwF0i8l709dvALSKyokO5a4BrAIYPHz65481qDqbL50CgnJaW7aSmjsfh8B74A0lEu85W6sjVL7rONsa4gReAeR0TQtQuYFib10Oj77UjInNFZIqITMnPz/+CMWlPqUop1ZWEJYXomUV/ATaIyP90UewV4ApjTQdqRKQkUTHZuBJ39zWllDrcJfLsoxnAt4GPjTGxKwduBYYDiMgjwALs6aifYk9JvSqB8UTF8qAeKSilVEcJSwrRdoL9XhQgtkHj+kTF0Bk9UlBKqa4lXTcXsaSgPaUqpdS+ki4pxBZZG5qVUmpfSZcU+kv1UVpaWp/OXymlOpN0ScE2cxi0+kgppfaVdEkhEfdpnjNnTrsuJm6//Xbuvfde6uvrOfXUUzn++OMZP348L7/88gGn1VUX2511gd1Vd9lKKXWojryus9+8kdV79tN3NhAON2CME4fD161pFg8s5g9ndt3T3uzZs7nxxhu5/np7ItVzzz3HwoUL8fl8zJ8/n4yMDCoqKpg+fTrnnntuNDF1rrMutiORSKddYHfWXbZSSn0RR1xS6L6e695j0qRJlJWVsXv3bsrLy8nOzmbYsGEEg0FuvfVWli5disPhYNeuXZSWljJw4MAup9VZF9vl5eWddoHdWXfZSin1RRxxSWF/e/QxDQ0bMMaJ3z+6x+Y7a9Ysnn/+efbs2RPveG7evHmUl5ezcuVK3G43I0eO7LTL7JjudrGtlFKJknRtCmDPQOrps49mz57NM888w/PPP8+sWbMA2831gAEDcLvdLF68mI4d+XXUVRfbXXWB3Vl32Uop9UUkT1IIhaCuDiIRjHHQ02cfjR07lrq6OoYMGcKgQfaWEJdddhkrVqxg/PjxPPnkkxx33HH7nUZXXWx31QV2Z91lK6XUF5HwrrN72pQpU2TFinY9a3evy+eqKvjsMxg7lib2EA7XkZY2IYGRHn6062yljlz9ouvsfsUVbT4JhRJSfaSUUkeC5EkKzmifR+FwvProcDtKUkqpRDtiksIBN/BtjhQg1imeJoUYTZBKKThCkoLP56OysnL/G7YO1UfQ9/0f9RciQmVlJT5f9y7mU0oduY6I6xSGDh3Kzp07KS8v33/BigoIBglXuAgGK/F6N2DvGKp8Ph9Dhw7t6zCUUn3siEgKbrc7frXvfp1yClx0EeV3nM66dRcxefKHpKfr2TZKKRVzRFQfdVtODlRV4XSmAxAO1/VxQEop1b9oUlBKKRWXlEnB5dKkoJRSnUnKpBA7UgiFNCkopVRbSZ0U9EhBKaXaS76kUFuLM2LPx9ekoJRS7SVfUgActfU4HD5NCkop1UFSJoVYFZK2KSilVHtJnRT0SEEppdpL8qRQ27fxKKVUP5O0ScHl0uojpZTqKGmTglYfKaXUvpIrKWRmgjGaFJRSqgvJlRScTsjK0qSglFJdSK6kAO36P9I2BaWUai9hScEY87gxpswYs7aL8TONMTXGmNXR4bZExdJOm64uIpEGRCK9MlullDocJPJI4W/AmQco866IFEeHOxIYS6t9+j+q75XZKqXU4SBhSUFElgJViZr+IYtXH2UA2v+RUkq11ddtCicYY9YYY94wxoztqpAx5hpjzApjzIoD3of5QLT7bKWU6lJfJoVVwAgRmQg8ALzUVUERmSsiU0RkSn5+/heba04O7N2L06QCeqSglFJt9VlSEJFaEamPPl8AuI0xeQmfcU4OiOBqsIuuSUEppVr1WVIwxgw0xpjo82nRWCoTPuPoVc3uOrvowWDiZ6mUUocLV6ImbIx5GpgJ5BljdgL/DbgBROQR4JvAD4wxIaAJuEREJFHxxEWTgqfeLnogUJLwWSql1OEiYUlBRC49wPgHgQcTNf8uRZOCqzaCSXERCOzp9RCUUqq/6uuzj3pfNCmYvdW43QV6pKCUUm0kbVKgqgqvdxAtLZoUlFIqJvmSQna2fayqwuMZqNVHSinVRvIlBbcb0tOjSWGQVh8ppVQbyZcUIH5Vs8cziGCwnEgk1NcRKaVUv5DkSWEgIASDZX0dkVJK9QtJnhQGAXqtglJKxSR1UvB6bVLQM5CUUsrqVlIwxvzYGJNhrL8YY1YZY85IdHAJ0676CD0DSSmlorp7pPBdEakFzgCygW8DdyUsqkSLJQV3AaDVR0opFdPdpGCij2cDT4nIujbvHX5yciAUwtEYxOXK0aSglFJR3U0KK40xb2GTwkJjTDpw+N7cuM1VzXoBm1JKtepuh3jfA4qBz0Sk0RiTA1yVuLASrF1S0AvYlFIqprtHCicAm0Sk2hhzOfALoCZxYSWY9n+klFKd6m5S+BPQaIyZCPwXsAV4MmFRJVon1Ue9cSsHpZTq77qbFELRG+CcBzwoIg8B6YkLK8E6VB+JtBAKVfdtTEop1Q90NynUGWN+hj0V9XVjjIPoXdQOS+16StWrmpVSKqa7SWE20IK9XmEPMBT4XcKiSrSUFDu0Swp6BpJSSnUrKUQTwTwg0xjzdaBZRA7fNgXo5KpmPVJQSqnudnNxMfBvYBZwMfCBMeabiQws4bT/I6WU2kd3r1P4OTBVRMoAjDH5wCLg+UQFlnDRpOB0ZuBwpGj1kVJK0f02BUcsIURVHsRn+6doUjDGRE9L1SMFpZTq7pHCm8aYhcDT0dezgQWJCamXRJMCoFc1K6VUVLeSgojcbIy5CJgRfWuuiMxPXFi9oENSaGxc38cBKaVU3+vukQIi8gLwQgJj6V05OdDcDE1NeDwDqa5+u68jUkqpPrffpGCMqQM66//BACIiGQmJqjd06P8oFKomHG7C6Uzp27iUUqoP7TcpiMjh25XFgbTt6iIvdgFbKSkpI/suJqWU6mOH9xlEX0QsKVRW6gVsSikVlbxJYaBNBJSUaP9HSikVlbxJYeRI+7h1q/Z/pJRSUcmbFPx+GDAgmhTyAYceKSilkl7CkoIx5nFjTJkxZm0X440x5n5jzKfGmI+MMccnKpYuFRbC1q0Y48TjGaD9Hymlkl4ijxT+Bpy5n/FnAaOiwzXYu7v1rmhSgNhVzVp9pJRKbglLCiKyFKjaT5HzgCfFWgZkGWMGJSqeThUWwuefQzisXV0opRQHcUVzAgwBdrR5vTP6Xu9tmQsLIRSCnTvxeAZSX/9hr81aqd4gYoe2z8Nh+7OPDeGwHSIR+whgDDgc9lEEgsHWIRIBlwucTvsI0NLSOgQCtkzbebtcdnC77WMwaDsUiA1t5+lwtMYZiykWczBoHyMRWz42xD7ncNi4jGkfQ+x5x/UQm27seWyekQh4vZCWBunp9jEchvp6aGiwj01Nrcvb0mI/43a3H2LxtF2utkPb7yG2bLHHUMh+1uOxg9sNJ58Mp5+e2N9MXyaFbjPGXIOtYmL48OE9N+HCQvu4dSue4YMIBMoQCWOMs+fmoXpcSwvU1Ng/Slpa64ZJxP5Rq6qgutr+qdpuKAIB+4eODbE/cmzo7I/ZdmMRDsd7RqGpyT6PlYl9pu0QCtk/cuxGfykpNoa6OjvU19vX0qbPgLYbwXDYjottnB3R4/rYRigQaN0Atx1U73K57G/R4WifOA+W09k+oTiddjqx7zkQsL+pIzkp7AKGtXk9NPrePkRkLjAXYMqUKZ11u3Fo2iQF76hBQJhgsAKPp6DHZnGkC4Vg7167gWtstBvLxsbWPcDY3mPsjxLbEwsEbLmGBvsYG2Ib26am9n+G5ma7od+7145ry+u1J5M1NNiyPUPAEYZI+7+IxwM+n93Ae72te76xPefYHp3bbccHg1Be3rpsHo/d80xPhxEjbJmY2F6v09k6xPbUwxEhLEGECCkeL16Pic+/7Z5o2+TRcbqx57F42+7tt92jhfZ72CA43WGMK4BxBXA5nLgljXDYEArZcl6vXS9eb+sGsu18w2G7LloCEZqCzTSZchoce2iglDopI8eTz3D/cQxOOQoj7nbJ3D4KzVJLXaSS+nAlIOT6CsjzFeBx+KIJUagPNFLVXEl9oA6Xw4nT4cTjdOF0OHEY02Y9GHL9OaT7/O3Wt5gQpU272F2/E7ekkmWG4QrmUF9vbBlfI5WRLewJfgrOAEMyCxiYPoCC1AKyU7JxGLsCI5HW33woHKG0rpyqpr2kelJJ96ST7k3D7XTFfz+tR2VCQ7CBmuYaaltqiUgEYwwGAxhyfLlAfk/9yDvVl0nhFeCHxphngC8BNSLSu5X6w4bZb2PrVjyeiYC9A9uRkhREhB21toZueOZwRKC2FsrK7Eaqpi7Ikl1vsLJqMcFIgEgkQkQiIC7yw8VkN0zHWTWG6ipnuz3shgaoqg5S4fyI+qxlMHgFNGfD7smwewpUjQJxgLcGsrZD1jZI3w3+ckgtt4/uJgimQCgFFym4HW6cngBOXwuOjBYcrhBO48ZlPLiMB7fDTbbHxWCfE7/XhdcL1aFSqkI7qY7spI7dGANpxofX6cPj9AIRAtJMINJMUJrJcOYzKn0SRVmTGJ8/ifzUXKqDZVS2lLK3pYyy5t3sbtzGrvrt7KzfRnOomaOyj6Eobwxj8sYwLGsou+t2srV6K1v3bqWkvgSPK4UMbwaZvkzSPGkAhCIhwpGwfQw1Y4KNOEJNOIJNiMNJyO2n2ZWCcafQ4nC3+85awi3UtdRRF6ijrqWOxmAjzaFmAuEAEu2GzGEc+N1+/G4/md5MRueOpiiviKL8IkZkjmBb9TbWl69nfcV6NlduxuP0kJ2STZYvi2xfNpneTDK8GWR4M0j3ptMSDlLTUkNNcw3VLdVUNlZS3lgeH+pa6uLzjvG5fAxIHcCA1AHk+fNId6eT6kwlzaThjrgpqyujpL6EkroSyhrKaAo10RJqISzh/f5mXQ4XR2cfjd/tpzHYSEOwgcZgIzXNNV1+NtObid/tp6qpipZwy0H9R/xuP/n+fHJScqhorGBX3S77H+hQZmjGUOoD9eyu293ltBzGEV/HOSk5OB1OdtftpqSuhGAkuE95r9OLy+HCYRzxZFIfqN/vOrplxi3cddpdB7WMB8uI9NyOd7sJG/M0MBPIA0qB/wbcACLyiDHGAA9iz1BqBK4SkRUHmu6UKVNkxYoDFuu+4cPhlFOoefAHfPjhDMaPf4Pc3P2dNJU4IsKnVZ+yoWIDn1R+wubKzWzZu4Walhqagk3xDUSmL5Mh6UMYkjGEPM8Q3JLWOg2E7ZW7+aj0Y7Y2fkQzNQB4ao5DPjmH4LpzoCkXJj4JE56CtDII+CHotxtycdgNts9+jpZ0vFXH4zJeHK4gDlcQ3E3Up6wj7LCVwelmAM3UEhT72u9Mx2Ec1Idq9lnGDE8mub58/G4/LZEmmsN2uYLhIF6XF6/Ti9dl/yyhSIhAOBAf4htaCRORCAWpBQzNGMrQjKEMTh+MwzhoDjXHB6fDic/pw+fy4XV52VW3iw9LPmRz1eZO13+2L5uRWSMZkTWCkZkj8bv9bKzcyPpyu3ENSxincTIscxgjs0YyJH0ILeEWaltqqW2ppa6lDmMMTuPE5bB7pz6XD7/bT4orhRR3CuFImKaQXeamYBOhSKhdDG6nO7onmU66J51Ud2p8vfhcPhzGQWOwMb7BrGqqYmPFRj6p/KTdBtHn8lGUV8To3NGEIiGqm6upbq5mb/NealtqqWmu2WdDle5JJ9OXSU5KDvn+fPJT88n355PpzcTr8uJxevA4PQTDQcobyyltKKWsoYyKxgoaAg3UB+qpD9QTCAcYkDqAQemDGJg2kILUAvxuf/y79Tq95KfmU5BawMC0geT58yhtKGVTxSY2VmxkY+VGAuEAfrefVHcqqe5UMrwZ5PpzyU3JJSclB2MMpfWl7KnfQ2lDKY3BRnJScshNySXXn0u6J52IRAhLOJ6k2wpLmKqmKsobbOKraqoi15/LiMwRDM8cztCMoTQEGvi85nN21O5gR+0OUt2pHJNzDKNyRnFMzjF4XV7KGsriQ3lDOXub91LVVMXe5r0Ew0EGpw+O/1dzUnJoDDbGk359oJ6IROKDiJDmSSPTlxlP3E6HExFBEESEovwiigcWd2dzsg9jzEoRmXKgcgk7UhCRSw8wXoDrEzX/bisshG3b8HgGA9DSsjOhsxMRTOwYNuqzvZ/x9MdPM+/jeWyo2BB/P8+fx1GZx5Ai+XhCKaQ2+2mp91HZuJdl4V00uRYT8ZeAs/2GhZZ0KJ0Apd8irWE8OQUtNA9bQMWU+2HqfQA4cTE95xt8Y+hVzBx6Jh6Xu01jnVDj3MKmhmWs2PM+q0tXE44043a6cTvcuJ1+xuRdx/Sh05k+dDrDM4cTljDry9ezcvdKVpasBLAb2MwRjMwayeD0weSn5uNxehK6frujtqWWNXvWUBeooyC1gAGpA8hPzcfn8nX5mUA4QFlDGQWpBbid7i7L9ZVwJMzW6q18XvN5fJ07HftvG2sJtVDTUoPH6SHdk37A8ok0ImsE04ZM67P5q1YJO1JIlB4/UrjySli0CNnxOe+9l8OAAZdw7LGPHNKkdtTsYGXJSkrrS+N7D6UNpZQ2RPdo6kupbakly5cV3+sJRoKsKlkFwBj/yRzdPJvIzilUfjKK7ZuyKelQoeZy2broo46Co4+GkYUR0jNbk4II5GS6GT3acMwxkJnZ+tm/TSaVAAAgAElEQVS6ljre3vo2pfWlXFB0AQNSBxzSciqlDj99fqRw2CgshN27MYEgGRlforb2/YP6eFOwiZc2vsRfV/+VRZ8talf3muXLYkDqAAamDWRiwUQGHj0QRyidLbuq+by8km2fV1HbGMDx8d1EPrqE9TXDWQ8MHmw3+GeeaR8LC20iGDECBg2yDWKtHED39r7Tvemcf9z5B7V8SqnkokmhsNDuXm/fTkbGCWzffgehUC0u1/7vH7Slagt//OCPPPXRU1Q3VzM8czi/PPmXfH3019tVlQSD8K9/wYIFdljbptOPkSPhhGIYcxIUXQNFRXDssfY0S6WU6guaFNqclpo59URAqK39Nzk5p3Va/F87/sV979/H/A3zcTlcfHPMN/nepO/xlcKvxM8gaGmBN1+HZ5+F116zZ/zELjz59rdhyhQoLm69pYNSSvUXmhTaJIWMUy8FDLW17++TFFpCLVz43IUs2LyAbF82c748hx9O+yGD020DtQgsXQp//SvMn28vrsrJgVmz4Otfh1NPteemK6VUf6ZJYfBge7XN1q24XJn4/WP2aVcQEa5+9WoWbF7A3afdzfVTryfVkwrYC1Sefx7uuw9WroSMDLjgApg9G047zR4hKKXU4UKTgsNhW3CjvaVmZp5AefnziEQw0eqgu967i6c+eoo7Zt7BT2f8FLBHBo8+Cr/5DezYAaNHwyOPwBVX2KtdlVLqcJS8N9lpa+TIeFLIyDiRUKiaxsZNALyw/gVu/eetfGv8t/jFyb8AoLTUVglde629KPqVV2DDBvtaE4JS6nCmRwpg2xVW2WsFMjJOAKC29n021jTy7fnfZvrQ6fzl3L9gjGHBArjqKttm8MADcP31rf27KKXU4U6PFMAmhcpKqKvD7x+Ny5XNKxuf5ey/n01+aj4vzX4JQj5uuAHOOQcGDoQVK+CHP9SEoJQ6smhSgNYzkLZto6allt9t9nPd0rcYkDqANy97k6odBUybBg8+CDfeCB98AOPG9W3ISimVCJoUIJ4U3lj9PGMfHsvrO0q4fDj86zuL+L+Xi5g8GfbssRef/f73totgpZQ6EmlSACgsZH0+fP2zX5Pty+atix/gqhGG718V4uqr4cQTYc0aOOusvg5UKaUSSxuaAfLy+NMJLlwiLP7OYrK9Pm559COee24Iv/gF3H57x/6GlFLqyKRHCkB9sIEnxke4uGoQ+an5lJWlM3fuPUyb9iF33KEJQSmVPDQpAH//+O/UuSP84CPb2+gNN0Aw6OPGG78L6E1vlVLJI+mTgojw8PKHmRjK44SVpcx/UXjxRfjJTz5m0KDVNDSs7+sQlVKq1yR9Uli2cxlrStfwg7SZ1NS7uP4/IhQXw803266za2v/r48jVEqp3pP0SeHhFQ+T7knnsmMuZA53UVru4LHHICPjGLzeEZSV/X99HaJSSvWapE4KFY0VPLfuOa6YeAUVKRP5M9fx469tYvJkMMYwaND3qa5+m8bGT/s6VKWU6hVJnRQe//BxAuEAP5jyA978bBQA1275qe0PGxg06LuAk5KSR/swSqWU6j1JmxQiEuGRFY9wyohTGDtgLAvfdjNiQCOjP3kV7r0XAK93MHl532DPnr8SiQT6OGKllEq8pE0K7+94n63VW7l28rUEg/DPf8LXzvdjLroIfvUr2LwZgEGDriUYLKei4qU+jlgppRIvaZPCB7s+AOCrhV/lgw/sfZTPOAO4/37weuG660CEnJzT8XpHsHv33L4NWCmlekHSJoXlu5czLGMYBWkFLFxor1o+9VTs7TnvvtseOjz5JMY4tcFZKZU0kjcp7FrO1CFTAXjrLfjSlyArKzrymmtsL3g33QTl5drgrJRKGkmZFKqaqtiydwtTB0+lshKWL49WHcU4HPYGzDU18Ic/aIOzUippJGVSWLF7BQBTB09l0SIQga99rUOhMWPs4cM//wlog7NSKjkkZVJYvms5AJMHT2bhQsjOhqlTOyk4c6Y9jKivJyfndHy+kezc+XtEpFfjVUqp3pKUSWFFyQpG544m05vFW2/Baad10T32zJkQDsN772GMk2HDfkpt7TKqqxf3dshKKdUrkjIpLN+1nKmDp7J+Peza1aE9oa0TTwS3G5YsAWDgwKvweAaxfftvei1WpZTqTQlNCsaYM40xm4wxnxpj5nQy/kpjTLkxZnV0+H4i4wEoqSthV90upgyewsKF9r192hNiUlNh2rR4UnA6fQwbdjPV1YupqdHeU5VSR56EJQVjjBN4CDgLGANcaowZ00nRZ0WkODo8lqh4Ypbvtu0JUwdP5a23oKgIhg3bzwdmzoQVK6CuDoDBg6/B7c5j+/Y7Ex2qUkr1ukQeKUwDPhWRz0QkADwDnJfA+XXL8l3LcRonx2VN4p139lN1FNOmXQHA6Uxl6NCbqKp6g7q6lQmPVymlelMik8IQYEeb1zuj73V0kTHmI2PM88aY/e2z94jlu5czdsBY1q/x09xsG5n3q0O7AsCQIdfjcmWxffv/S2isSinV2/q6oflVYKSITAD+ATzRWSFjzDXGmBXGmBXl5eWHPDMRYflu28i8YYN9b/z4A3zI77fXK7RJCi5XBkOG/IiKihdpaFh3yPEopVR/k8iksAtou+c/NPpenIhUikhL9OVjwOTOJiQic0VkiohMyc/PP+SAtlZvpaqpiqmDp7JxI6SkHKA9IWbmTFi50vaaFzV06I9wOtPYuvWXet2CUuqIkciksBwYZYwpNMZ4gEuAV9oWMMYMavPyXGBDAuNpvZJ5yFQ2bYLRo22PFgf0la/YdoX/az3jyO3OZfjwW6momE9p6bwERayUUr0rYUlBRELAD4GF2I39cyKyzhhzhzHm3GixHxlj1hlj1gA/Aq5MVDxgG5m9Ti/jBoxj40Y47rhufnD6dPB4YHH7i9aGD/8pGRkz2Lz5epqatvV4vEop1dsS2qYgIgtEZLSIHC0id0bfu01EXok+/5mIjBWRiSLyFRHZmMh4lu9ezsSBE4kEPWzdehBJoZN2BQBjnBQVPQUIGzdegUi4p0NWSqle1dcNzb0mHAmzsmQlUwdP5dNPbSd4xx57EBPopF0BICWlkFGjHqKm5l0+//yeHo1ZKaV6W9IkhU2Vm6gP1McbmeEgjhTAtitEIvHrFdoqKLic/PyL2bbtNr12QSl1WEuapBDrGTXWyAy2obnbYu0KTzxhG53bMMYwevSfcLsLWLduFs3NO7qYiFJK9W9JkxS+Nf5brLpmFcfmHsvGjfZU1NTUg5hASgr85Cfw3HNw4YVQX99utNudw7hxLxIMVrJ69Uyamz/v2QVQSqlekDRJwe10M2nQJJwO58GdedTWnXfCAw/Aa6/BSSfBzp3tRmdkTGPixH9oYlBKHbaSJinEiMCmTQfZyNzWD39ok8KWLbYH1VWr2o1uTQxV0cSw/YsHrZRSvSTpkkJJie3w9JCOFGLOOgv+9S/bJ9J55+1TlZSRMTWeGD788BQaGhJ6TZ5SSvWYpEsKh3TmUWfGjYOnn7ZVSL/61T6jMzKmUlz8TyKRJj788ESqq5d+wRkqpVTiJV1SiJ15dMjVR22deCJ8//vw+9/Dxx/vMzo9/XiOP34ZHs9A1qw5ndLSZ3pgpkoplThJlxQ2brRnHQ3prBPvQ3HXXZCVBT/4gb2OoYOUlEImTfo/MjKms2HDpWzf/lu98lkp1W8lXVLYtMlWHRnTQxPMzYV77rGd5T3Rac/fuN05TJz4FgMGXMrWrbeycuU0vZ2nUqpfSrqksHFjD1UdtXXllTBjBtx8M1RWdlrE4fBSVDSPoqK/EwiU8uGHX2b9+stobt7ZaXmllOoLSZUUGhth+/YeaGTuyOGAP/0Jqqvh6quhixsBGWMoKLiUL31pEyNG/ILy8hf497+P5fPP7yUSCfZwUEopdfCSKils3mwfezwpgL2F269/DS+9BIWF8NOfQllZp0WdzlQKC3/NtGkbyM7+Kp99djMrV06hpmZZAgJTSqnuM4fbXcOmTJkiK1asOKTPPvssXHIJrFkDEyb0cGAxGzbAb34DzzwDPp+d4bBhkJ8PeXmQkWEPWRoaoL4e8XqpODOdzdtvIhDYzeDB1zJs2M2kpByVoACVUsnIGLNSRKYcqJyrN4LpLzZutA3Mo0YlcCZFRTBvHtx2m00O8+fD3r1dFjdA/te+RvazK9hWfjc7d97P7t2PkJFxIgUFlzNgwMW43bkJDFgppVol1ZHCt74Fy5bBZ5/1cFAHEgrZBuiKCns/Br/fnheblgavvgrXXWe7zHj9dZr9DZSV/Z09e56isXEdxrjIzT2PwYOvJTv7VIxJqho/pVQP6e6RQlIlheOPh4ICeOONHg7qi5o/Hy69FI4+GhYuhKFDEREaGj5iz54n2LPnSUKhSny+QgYNupqCgsvw+Yb3ddSqvxGBHTtsdWWPnXOdBETg3XftCSMjRsDgweB09n4MNTX2mqcE0aTQQSQC6elwzTX2AuR+Z8kSOPdcyM6GO+6w3XOnpwMQibRQXj6fkpK5VFfb+0SnpU0iL+888vLOJzV1AkY3AsmtuRn+4z/gr3+F//xPuO++wzMxBIN2r83lsj0RR/8DB6WmBrZtsw2HB1oHdXV2o/BMm94GXC4YPtwevZ9xBpx+Ogwd2v3579oFf/+77R+tpsbWDtTW2vuwFBXZuCZMsNNcudImpPfeg9JSuPhiePBB2wbZwzQpdLBjh/2eH3kErr02AYH1hA8/hNmz7WlSfr9NDFdcAV/+sr2fA9DUtIXy8vlUVLxE487/I3MdpG/3k16ajX+XA8/n9Zix43D8bZ7dY2yrvh5+9CN4/317dHKwp2FVV9seYpcsga9/Hc4/v2eWu7cFg/bssI8/tstx3nn2jLHD1e7d9rfywQd2Q/ruu/C978Gf/9z5Hq8IrF4Nr78Ob71lN5yjR9vGttGj7XD00eD1dj6/YLB1CIVsQqqpsW1n1dXQ0mLX5+jR7W9aImI3fLt2wYABtlsBR7Q6tLwcHn0UHn7Yjgcb+5Qp9la4X/2q/R/4/V2vh7174Y9/tEN1tb1b4v/8DxQXd15+3Tq46CL7f7vjDpg61SaTbdtsL8hLl8KePbbsmDG2/vmHP4TMzH2nVV8PL74ITz0Fb7/der/f/Hx7cklmpt0zXb/enowSCrV+dsQI+73l5cFDD9mjhYcfhm9+s7XMnj32ez3qKJg8uet1sB/dTQqIyGE1TJ48WQ7FW2+JgMjixYf08d4TiYi8957INdeIZGbaoJ1OkTFjRC69VOTOO0WuvVZk7Fg7LjoEclyydzxScjoSTEGC6Q7Z8dBXZffux6WpaZvImjUixx0nYoxIVpZIXp7I8uUHjqe5WWTuXJEzzhBxuez8fD77eMEFIrt2tZZtaRF56imRGTNEzj9fZNWqxKyj2lqRd98VaWw8+M/W14ucfbaN/5hjWtfhxIkid98t0tTU+edefVXke98TWbBAJBzed/z69SK//rXI7beL3HOPyEMPiTz5pEhpaefT27lT5LLLRC68UOSFF+x6PhTvvy8yaJBIaqqdTiQictttdpkuvth+JyJ2uWLLMGhQ63JPmSLy5S+LDBjQ7vckxoiMHGm/9wsvtN/p0Ufb+bQtd6Bh2DA7/WOPbf3dxAavV6SoSOS00+xzEDn9dBvnokUiP/+5yIkntv7u3G6Rk08W+dWvRF58UeTll23Z11+3ZdPTbbnzz7ffZW6uXY7vftf+TuvrRUpKRD75ROSxx0T8fpGCgq43CpGIyEcfidx7r8hXvmKnnZlp129lpUgwKPLGG/Z79Pvt+MJCkV/+UmTTpq6/s5YW+3989VWRzz9vP+6jj0SOP771/3XllXa9x9bZDTcc2u9ERIAV0o1tbJ9v5A92ONSk8M9/2t9TSckhfbxvNDWJvPSSyC9+IfKNb4gMH26/sowMkTPPFPnNb0TeeUekpkZEREKhRqmpWSa737lVGotsQtlxIbLpRiTsNRLKT5fmBf8rsnmz/cOnpdkV05UFC1o3nKNGidxyi8iyZfZH/dvf2j95RobIgw/a14MH27KjR9vEAyIXXSSydu0XWw+RiN3o3nefyKmn2o0D2Pk9+GD3N6iVlSLTp4s4HCJ//rN9b/Nm+6efMcNO86ijRF55pfUzu3bZZYDWjdOxx4o8/LBIWZnI3/7W+tnOhrQ0myhqa1uX5bHH7HpLSbEbJRDJzha57jq7oVi3TqShoX3s4bCNf80am2xuusmuC4/Hbog++qh9+fvus9M99VSRWbNsHGA3nLNm2bj37Gn/mb17Rf79b5F580T++7/tTsjkyXaH5Ktfta//8z9F7rhD5K677Dz++EeRRx4ReeYZkTfftL+PlStFnnvOJsnLLxc56SSRb35T5Cc/EXngAbtBf+QR+/r880UmTbI7OuvWdf691dXZad98s91gGrPvejbGLteaNe2X5yc/af29dBxOOUVk9+7u/XZE7HJdcEHremz73V17rd1RiUS6P72uBAJ258/jsYntvPPsb/SDD+y4Q6RJ4UhVUyMSCh24XHOzRG64If4HqJ6eIe+9iCxejPz73xNk8zuXS+DYwRLxuCXyv0+J7Nhhpx0Oi3z2mf0hxjbwb77Z+Y9982a7sYj9yU47rXVPeu9eu0eVnm7/sKefbl+/9prdew4E7N7Uq6/ajcutt9q965dftkcYa9faDfell7bfsx071m4c5s2zG5vY3ujDD4s8/bTdmF18sUhxsd27+/GPRf7yF5v8xoyxe6QvvND5Olu0yO65gsg559g9/vR0m/zuvNPuac6bZ/eu225cRo2yZUtL7bLX1dkN7sqVdmMIdk/8vvvsOgKRmTNFPv20dW/zW9+ySaLtdAcMsNPOzbWJrONe9pQpItdfL1JR0fnyPPqo/VxBgT3yfOONQz8i6U8qK+1vZOVKe7T7wQciW7d2Xf7TT22Cuvtu+zt56im7LoLBQ5v/Rx+JfPvbNgnNn5+4ddrU1PlR6SHqblJImjaFpLVggW1Qufpqmlq2U17+PFVVC6mrW4HZW8P4n0Hm+tbiYgBjEJ+H4Jwf4L75Dhy+/TT2icCiRfa0rs6uCKystI2er71m63BjPck6HO17le34OmbQIFunPHMmfO1rtv617bzffht++Ut7rnFsOrH67Koq227Q2GjHZWTAyy/baXUlGLS3XL39dtsIefrptn73mGPaz/f99+26Pf10OPnk/TdofvAB3HILvPOOPQ35d7+zjZuODqcX19XB2rWwdasdtm2zDZS5ua3DwIF2PY8ebRtED6SuztbD9/bZNKrf0YZmtV8iEZqaNlO7ZynyxqtEKkqQ6nKoqSIUqqPkG9CSD+AkJeUY/P5RpKQcEx/S0o7H4znIMyTq621j+gcf2IbAWKPm6NG2ca201CawHTts2RNOsI2fBzqDRARWrLBXkI8aZR9jwmF7YcratTBxom2o6449e+xnTj21Z87iicU4ZIg95VGpXqZJQR2ySKSFxsZPaGhYR0PDWhob19PU9ClNTVuIRBrj5fz+48jM/DIZGTPw+4/D6x2MxzMQh8PTh9ErpTqj3VyoQ+ZweElLG09a2vh274sIgcAempo+obZ2GTU171Fe/gIlJY+1K+d25+HxDMLjGRh/dLvzcbkyo0MWbncuHs9gPJ4BGKNVG0r1F5oUVLcZY/B6B+H1DiIr6xTgFkQiNDZuorn5M1paSggEdtPSsptAYA+BQAmNjZsIBPYgEuhiqk48noH4fMNISRlFSspo/P5R+HxH4XJlR5NIBg5HF+fMK6V6lCYF9YUY4yA1tYjU1KIuy4gI4XA9oVANoVA14XANgUB5mwSym+bm7VRXL6G09KlOp+Fw+KNtG8fh9x9HSsoxQIRwuD46NOB25+L1DsfnG47XOwyXKxNjPHq1t1IHQZOCSjhjDC5XOi5XOrD/7gLC4Uaamj6luXlbNInUEA7XEAxW0Ni4mfr6VZSXPw90cqZSl/N343B4cbly8PlGRBPHCNzufBwOb3xwOtNwuwfg8QzA7R6A05lKJNJEONxAONyASAivdwhO536uqlXqMKdJQfUrTqeftLQJpKV1fcOLSKSF5ubtGOPG6UzD6UzD4fARDFbS0rKDlpbPaW7+nHC4jkgkgEiASKSFYLCM5ubPqal5j7KyZ4DwIcXodufj843E6x2Ox1OA252Px5OP252P05mKw+HD4UjB4fASCtUQCJQSDJYRCJThcmXg8x1FSsrR+HxH4XYnrgM0pQ6FJgV12HE4vPj9o/d53+PJw+PJIz190gGnEYmEokmjhUikGZEWQqE6gsHy6Aa8nHC4FqczNZ54wNDSspPm5m00N2+nsXEd1dWLCYWquhm5k30TkWn33OHw4HSm43Rm4HKlxxOeTTI+jPEAAggiEUCiR0JujGkdWl+7og35jvijPSLKxuXKwuXKwpi27TUSHYjOQzDGEY3BizFeHA53dN6R6HgnbnceTmfKAdeAiBCJNOFwpGi1Xj+V0KRgjDkT+CP23/CYiNzVYbwXeBKYDFQCs0VkWyJjUgrA4XDhcGT3yLQikRDBYAXBYAWRSCORSDORSBORSDNOZyYezwA8ngJcrmzC4Xqam7fS1LSFpqYthMN1tG6E7VFQOFxHKFRLOFwXby+x024mEgkAJnpfDXvxm0gwPkQiwXavRUKdxpwIDkcqHk8+LlcuTmdKNIH4MMZJMFgRPflgD5FII8Z48XqHxAeRcLvqQnDidKa1SYypOJ1+HA4/Tqc/2lbkaLMuDG0TZUcikej6CESPHsPRs+DyokNu9CjPH489ENhFY+PG6LAJh8MbPRniGFJSRuHzDY8mw4x2CS7WhhYO18ePUu08WxAJRb+jEBCOJnu7THYHJBOnM3Wf6UUiTQSDlTgcvoO/PuggJew6BWN3Sz4BTgd2AsuBS0VkfZsy/wFMEJHrjDGXABeIyOz9TVevU1Dq4NgNYmzPPhxNOtXRYS+RSLBdebtBim2UDCJhRFraHFWFsEceNjGJBKNJsZxAoIxQqCqawFrL21OQY6cn5xEK7aWlZRctLTsJBHZjjAunMzN+tpndsMaSYh3hcCORSGP8UaR9zN1hj5o80SMoJ6FQDd2pQnQ4/Pj9o4lEWmhq2rLPmXTGuHC78zDGQzhcSyhUy8G0eXUWp8uVjdOZQSTSSDBYhUgLAMOH/4yjjvp/hzjdvr9OYRrwqYh8Fg3oGeA8oE2nCpwH3B59/jzwoDHGyOF2RZ1S/ZgxsQ245XSm4PEM6MOIvji7iWh7ZBDBHjmZDkmtVce7FopECIVqogmtkkikIZp0mohEmvB4BuL3F+H1Do1/ViRMS8tOGhs3EwjsjidDeyQXiF+L43RmRI9wvO2q3WxSckUTkyN6IkMs4cXO0NsbTdg1OJ2puFw5uN05uFy5pKcfn+A1m9ikMATY0eb1TuBLXZURkZAxpgbIBSraFjLGXANcAzB8uN5xTKlkF9vwf5Hb0xrjwO3Oxu3OBrp343ZjnPh8I/D5Rhy48GHqsLjhr4jMFZEpIjIlPwF3JFJKKWUlMinsAtre+mto9L1OyxhjXEAmtsFZKaVUH0hkUlgOjDLGFBp7Ht0lwCsdyrwCfCf6/JvAP7U9QSml+k7C2hSibQQ/BBZiT0l9XETWGWPuwN7s4RXgL8BTxphPgSps4lBKKdVHEnqdgogsABZ0eO+2Ns+bgVmJjEEppVT3HRYNzUoppXqHJgWllFJxmhSUUkrFHXa34zTGlAPbD/HjeXS4MK6fOhzi1Bh7hsbYMzTGAxshIge80OuwSwpfhDFmRXf6/uhrh0OcGmPP0Bh7hsbYc7T6SCmlVJwmBaWUUnHJlhTm9nUA3XQ4xKkx9gyNsWdojD0kqdoUlFJK7V+yHSkopZTaj6RJCsaYM40xm4wxnxpj5vR1PADGmMeNMWXGmLVt3ssxxvzDGLM5+tgz94w89BiHGWMWG2PWG2PWGWN+3N/iNMb4jDH/Nsasicb4q+j7hcaYD6Lf+bPRjhn7lDHGaYz50BjzWj+OcZsx5mNjzGpjzIroe/3m+47Gk2WMed4Ys9EYs8EYc0J/itEYc2x0/cWGWmPMjf0pxq4kRVKI3hr0IeAsYAxwqTFmTN9GBcDfgDM7vDcHeFtERgFvR1/3pRDwXyIyBpgOXB9dd/0pzhbgqyIyESgGzjTGTAfuBn4vIscAe4Hv9WGMMT8GNrR53R9jBPiKiBS3OYWyP33fYO/9/qaIHAdMxK7TfhOjiGyKrr9i7D3oG4H5/SnGLonIET8AJwAL27z+GfCzvo4rGstIYG2b15uAQdHng4BNfR1jh3hfxt53u1/GCfiBVdi7/FUArs5+A30U21DshuCrwGvYe0b2qxijcWwD8jq812++b+x9V7YSbRPtjzF2iOsM4P/6c4xth6Q4UqDzW4MO6aNYDqRAREqiz/cABX0ZTFvGmJHAJOAD+lmc0WqZ1UAZ8A9gC1At9i7z0D++8z8AP6X1ru659L8Ywd70+C1jzMrorXChf33fhUA58NdoVdxjxphU+leMbV0CPB193l9jjEuWpHBYErs70S9ODzPGpAEvADeKSG3bcf0hThEJiz1UHwpMA47ry3g6MsZ8HSgTkZV9HUs3fFlEjsdWt15vjDm57ch+8H27gOOBP4nIJKCBDtUw/SBGAKJtROcC/1/Hcf0lxo6SJSl059ag/UWpMWYQQPSxrI/jwRjjxiaEeSLyYvTtfhcngIhUA4uxVTFZ0du8Qt9/5zOAc40x24BnsFVIf6R/xQiAiOyKPpZh68Gn0b++753AThH5IPr6eWyS6E8xxpwFrBKR0ujr/hhjO8mSFLpza9D+ou0tSr+DrcPvM8YYg71D3gYR+Z82o/pNnMaYfGNMVvR5CrbNYwM2OXwzWqxPYxSRn4nIUBEZif39/VNELqMfxQhgjEk1xqTHnmPrw9fSj75vEdkD7DDGHBt961RgPf0oxjYupbXqCFWITOgAAAKKSURBVPpnjO31daNGbw3A2cAn2Lrmn/d1PNGYngZKgCB27+d72Hrmt4HNwCIgp49j/DL2EPcjYHV0OLs/xQlMAD6MxrgWuC36/lHAv4FPsYfv3r7+zqNxzQRe648xRuNZEx3Wxf4r/en7jsZTDKyIfucvAdn9MMZUoBLIbPNev4qxs0GvaFZKKRWXLNVHSimlukGTglJKqThNCkoppeI0KSillIrTpKCUUipOk4JSvcgYMzPWQ6pS/ZEmBaWUUnGaFJTqhDHm8ug9GlYbY/4c7XCv3hjz++g9G942xuRHyxYbY5YZYz4yxsyP9ZFvjDnGGLMoep+HVcaYo6OTT2tzL4B50avGleoXNCko1YExpgiYDcwQ28leGLgMe4XqChEZC7wD/Hf0I08Ct4jIBODjNu/PAx6S/7+9u1WJMIjiMP4cEUQRNFkMghdhEEzegEGLYDBbrIIWr0LjgkUEvQLDwiYtJqPJZBHRoEGPYcbBj6As+AE+v7Q7Oww74d3zfrD/U/o8zFL+vQ4laXad0ttjmpKLJP0Jg59Pkf6deUpjlNN6Ej9MCS57AvbrnD3gMCLGgPHM7NbxDnBQ84MmM/MIIDPvAep6J5l5Wd+fUXpq9L5/W9LnLArSRwF0MnPjzWDE1rt5/WbEPLx6/YjHof4Qbx9JHx0DixExAa0/8RTleHlJNF0Gepl5A1xHxFwdXwG6mXkLXEbEQl1jKCJGfnQXUh88Q5HeyczziNikdB8boKTYrlGauczUz64ozx2gRCDv1B/9C2C1jq8AuxGxXddY+sFtSH0xJVX6ooi4y8zR3/4e0nfy9pEkqfFKQZLUeKUgSWosCpKkxqIgSWosCpKkxqIgSWosCpKk5hl8RYQ+1d0TkQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.1974 - acc: 0.9408\n",
      "Loss: 0.19742133211990506 Accuracy: 0.94080997\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5336 - acc: 0.1619\n",
      "Epoch 00001: val_loss improved from inf to 1.92920, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/001-1.9292.hdf5\n",
      "36805/36805 [==============================] - 148s 4ms/sample - loss: 2.5335 - acc: 0.1620 - val_loss: 1.9292 - val_acc: 0.3764\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7384 - acc: 0.4276\n",
      "Epoch 00002: val_loss improved from 1.92920 to 1.37821, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/002-1.3782.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 1.7384 - acc: 0.4276 - val_loss: 1.3782 - val_acc: 0.5570\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2523 - acc: 0.5861\n",
      "Epoch 00003: val_loss improved from 1.37821 to 1.04359, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/003-1.0436.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 1.2524 - acc: 0.5861 - val_loss: 1.0436 - val_acc: 0.6629\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9082 - acc: 0.7010\n",
      "Epoch 00004: val_loss improved from 1.04359 to 0.63219, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/004-0.6322.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.9081 - acc: 0.7010 - val_loss: 0.6322 - val_acc: 0.7983\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6755 - acc: 0.7785\n",
      "Epoch 00005: val_loss improved from 0.63219 to 0.46696, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/005-0.4670.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.6755 - acc: 0.7785 - val_loss: 0.4670 - val_acc: 0.8512\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5494 - acc: 0.8221\n",
      "Epoch 00006: val_loss improved from 0.46696 to 0.40155, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/006-0.4016.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.5494 - acc: 0.8221 - val_loss: 0.4016 - val_acc: 0.8765\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4557 - acc: 0.8550\n",
      "Epoch 00007: val_loss improved from 0.40155 to 0.36732, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/007-0.3673.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.4557 - acc: 0.8550 - val_loss: 0.3673 - val_acc: 0.8873\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4015 - acc: 0.8708\n",
      "Epoch 00008: val_loss improved from 0.36732 to 0.30385, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/008-0.3039.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.4014 - acc: 0.8708 - val_loss: 0.3039 - val_acc: 0.9031\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3648 - acc: 0.8808\n",
      "Epoch 00009: val_loss improved from 0.30385 to 0.28689, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/009-0.2869.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.3647 - acc: 0.8809 - val_loss: 0.2869 - val_acc: 0.9122\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3199 - acc: 0.8975\n",
      "Epoch 00010: val_loss improved from 0.28689 to 0.27078, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/010-0.2708.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.3198 - acc: 0.8975 - val_loss: 0.2708 - val_acc: 0.9161\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2940 - acc: 0.9057\n",
      "Epoch 00011: val_loss improved from 0.27078 to 0.23833, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/011-0.2383.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.2941 - acc: 0.9057 - val_loss: 0.2383 - val_acc: 0.9280\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2742 - acc: 0.9129\n",
      "Epoch 00012: val_loss did not improve from 0.23833\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.2742 - acc: 0.9129 - val_loss: 0.2491 - val_acc: 0.9213\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2513 - acc: 0.9200\n",
      "Epoch 00013: val_loss improved from 0.23833 to 0.22894, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/013-0.2289.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.2513 - acc: 0.9200 - val_loss: 0.2289 - val_acc: 0.9283\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2290 - acc: 0.9263- ETA: 5s \n",
      "Epoch 00014: val_loss improved from 0.22894 to 0.20299, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/014-0.2030.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.2290 - acc: 0.9263 - val_loss: 0.2030 - val_acc: 0.9404\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2186 - acc: 0.9293\n",
      "Epoch 00015: val_loss did not improve from 0.20299\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.2185 - acc: 0.9294 - val_loss: 0.2041 - val_acc: 0.9355\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9347\n",
      "Epoch 00016: val_loss did not improve from 0.20299\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1981 - acc: 0.9347 - val_loss: 0.2166 - val_acc: 0.9383\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9410\n",
      "Epoch 00017: val_loss did not improve from 0.20299\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1811 - acc: 0.9410 - val_loss: 0.2227 - val_acc: 0.9324\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1745 - acc: 0.9430\n",
      "Epoch 00018: val_loss improved from 0.20299 to 0.17262, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/018-0.1726.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1745 - acc: 0.9431 - val_loss: 0.1726 - val_acc: 0.9497\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1629 - acc: 0.9460\n",
      "Epoch 00019: val_loss improved from 0.17262 to 0.16786, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/019-0.1679.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1629 - acc: 0.9460 - val_loss: 0.1679 - val_acc: 0.9485\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9491\n",
      "Epoch 00020: val_loss did not improve from 0.16786\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1538 - acc: 0.9491 - val_loss: 0.1894 - val_acc: 0.9462\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9517\n",
      "Epoch 00021: val_loss improved from 0.16786 to 0.15045, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/021-0.1504.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1451 - acc: 0.9517 - val_loss: 0.1504 - val_acc: 0.9557\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9561\n",
      "Epoch 00022: val_loss did not improve from 0.15045\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1329 - acc: 0.9561 - val_loss: 0.1644 - val_acc: 0.9534\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9567\n",
      "Epoch 00023: val_loss did not improve from 0.15045\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1293 - acc: 0.9567 - val_loss: 0.1596 - val_acc: 0.9502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1184 - acc: 0.9599\n",
      "Epoch 00024: val_loss did not improve from 0.15045\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1184 - acc: 0.9599 - val_loss: 0.1541 - val_acc: 0.9557\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9607\n",
      "Epoch 00025: val_loss did not improve from 0.15045\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1172 - acc: 0.9607 - val_loss: 0.1792 - val_acc: 0.9499\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1112 - acc: 0.9631\n",
      "Epoch 00026: val_loss did not improve from 0.15045\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1112 - acc: 0.9631 - val_loss: 0.1623 - val_acc: 0.9509\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9655\n",
      "Epoch 00027: val_loss did not improve from 0.15045\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1023 - acc: 0.9655 - val_loss: 0.1867 - val_acc: 0.9485\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9676\n",
      "Epoch 00028: val_loss did not improve from 0.15045\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0981 - acc: 0.9676 - val_loss: 0.2084 - val_acc: 0.9448\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9682\n",
      "Epoch 00029: val_loss did not improve from 0.15045\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0953 - acc: 0.9682 - val_loss: 0.1702 - val_acc: 0.9520\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9716\n",
      "Epoch 00030: val_loss did not improve from 0.15045\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0840 - acc: 0.9716 - val_loss: 0.1590 - val_acc: 0.9585\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9713\n",
      "Epoch 00031: val_loss did not improve from 0.15045\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0853 - acc: 0.9713 - val_loss: 0.1613 - val_acc: 0.9553\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9741\n",
      "Epoch 00032: val_loss improved from 0.15045 to 0.14818, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/032-0.1482.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0756 - acc: 0.9741 - val_loss: 0.1482 - val_acc: 0.9588\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9756\n",
      "Epoch 00033: val_loss did not improve from 0.14818\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0737 - acc: 0.9756 - val_loss: 0.1662 - val_acc: 0.9576\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9757\n",
      "Epoch 00034: val_loss did not improve from 0.14818\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0715 - acc: 0.9757 - val_loss: 0.1692 - val_acc: 0.9604\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9757\n",
      "Epoch 00035: val_loss did not improve from 0.14818\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0704 - acc: 0.9757 - val_loss: 0.1639 - val_acc: 0.9599\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9768\n",
      "Epoch 00036: val_loss did not improve from 0.14818\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0665 - acc: 0.9768 - val_loss: 0.1508 - val_acc: 0.9560\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9791\n",
      "Epoch 00037: val_loss did not improve from 0.14818\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0618 - acc: 0.9791 - val_loss: 0.1853 - val_acc: 0.9576\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9783\n",
      "Epoch 00038: val_loss did not improve from 0.14818\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0644 - acc: 0.9783 - val_loss: 0.1674 - val_acc: 0.9578\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9796\n",
      "Epoch 00039: val_loss did not improve from 0.14818\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0603 - acc: 0.9796 - val_loss: 0.1685 - val_acc: 0.9569\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9800- \n",
      "Epoch 00040: val_loss did not improve from 0.14818\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0592 - acc: 0.9800 - val_loss: 0.1802 - val_acc: 0.9536\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9819\n",
      "Epoch 00041: val_loss did not improve from 0.14818\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0538 - acc: 0.9819 - val_loss: 0.2045 - val_acc: 0.9539\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9816\n",
      "Epoch 00042: val_loss did not improve from 0.14818\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0542 - acc: 0.9816 - val_loss: 0.1643 - val_acc: 0.9562\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9833\n",
      "Epoch 00043: val_loss did not improve from 0.14818\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0507 - acc: 0.9833 - val_loss: 0.1942 - val_acc: 0.9527\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9836\n",
      "Epoch 00044: val_loss did not improve from 0.14818\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0492 - acc: 0.9836 - val_loss: 0.1694 - val_acc: 0.9630\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9848- ETA: 4s - loss\n",
      "Epoch 00045: val_loss did not improve from 0.14818\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0459 - acc: 0.9848 - val_loss: 0.1869 - val_acc: 0.9599\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9830\n",
      "Epoch 00046: val_loss improved from 0.14818 to 0.14759, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv_checkpoint/046-0.1476.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0501 - acc: 0.9830 - val_loss: 0.1476 - val_acc: 0.9595\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9856\n",
      "Epoch 00047: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0441 - acc: 0.9856 - val_loss: 0.1696 - val_acc: 0.9576\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9864\n",
      "Epoch 00048: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0422 - acc: 0.9864 - val_loss: 0.1857 - val_acc: 0.9623\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9862\n",
      "Epoch 00049: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0431 - acc: 0.9862 - val_loss: 0.1609 - val_acc: 0.9634\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9869\n",
      "Epoch 00050: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0387 - acc: 0.9869 - val_loss: 0.1619 - val_acc: 0.9620\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9865\n",
      "Epoch 00051: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0418 - acc: 0.9865 - val_loss: 0.1682 - val_acc: 0.9583\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9862\n",
      "Epoch 00052: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0423 - acc: 0.9863 - val_loss: 0.2375 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9887- ETA: 3s - loss: 0\n",
      "Epoch 00053: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0344 - acc: 0.9888 - val_loss: 0.2334 - val_acc: 0.9525\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9890\n",
      "Epoch 00054: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0334 - acc: 0.9890 - val_loss: 0.2009 - val_acc: 0.9609\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9869\n",
      "Epoch 00055: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0409 - acc: 0.9869 - val_loss: 0.1962 - val_acc: 0.9564\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9883\n",
      "Epoch 00056: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0372 - acc: 0.9883 - val_loss: 0.2006 - val_acc: 0.9567\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9897\n",
      "Epoch 00057: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0325 - acc: 0.9897 - val_loss: 0.2039 - val_acc: 0.9590\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9882- ETA: 2s - loss: 0.0373 \n",
      "Epoch 00058: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0378 - acc: 0.9882 - val_loss: 0.1596 - val_acc: 0.9613\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9889\n",
      "Epoch 00059: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0342 - acc: 0.9889 - val_loss: 0.1808 - val_acc: 0.9599\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9885- ETA: 0s - loss: 0.0334 - acc: 0.9\n",
      "Epoch 00060: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0333 - acc: 0.9885 - val_loss: 0.1733 - val_acc: 0.9604\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9893\n",
      "Epoch 00061: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0306 - acc: 0.9893 - val_loss: 0.1878 - val_acc: 0.9583\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9895- ETA: 1s - loss: 0.0327 - ac\n",
      "Epoch 00062: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0327 - acc: 0.9895 - val_loss: 0.2095 - val_acc: 0.9578\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9917\n",
      "Epoch 00063: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0269 - acc: 0.9917 - val_loss: 0.2197 - val_acc: 0.9616\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9906\n",
      "Epoch 00064: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0298 - acc: 0.9906 - val_loss: 0.2093 - val_acc: 0.9602\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9901\n",
      "Epoch 00065: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0311 - acc: 0.9901 - val_loss: 0.1667 - val_acc: 0.9644\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9914\n",
      "Epoch 00066: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0260 - acc: 0.9914 - val_loss: 0.2106 - val_acc: 0.9634\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9907- ETA: 1s - loss: 0.0286 - acc\n",
      "Epoch 00067: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0289 - acc: 0.9907 - val_loss: 0.2119 - val_acc: 0.9527\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9908\n",
      "Epoch 00068: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0292 - acc: 0.9908 - val_loss: 0.1906 - val_acc: 0.9581\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9910\n",
      "Epoch 00069: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0272 - acc: 0.9910 - val_loss: 0.1821 - val_acc: 0.9634\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9926\n",
      "Epoch 00070: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0235 - acc: 0.9926 - val_loss: 0.2069 - val_acc: 0.9655\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9910\n",
      "Epoch 00071: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0290 - acc: 0.9910 - val_loss: 0.1911 - val_acc: 0.9641\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9927\n",
      "Epoch 00072: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0243 - acc: 0.9927 - val_loss: 0.1956 - val_acc: 0.9611\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9931\n",
      "Epoch 00073: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0202 - acc: 0.9931 - val_loss: 0.2103 - val_acc: 0.9604\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9904- ETA: 1s - loss: 0.0319 - acc:\n",
      "Epoch 00074: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0317 - acc: 0.9904 - val_loss: 0.1774 - val_acc: 0.9625\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9928\n",
      "Epoch 00075: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0218 - acc: 0.9928 - val_loss: 0.2283 - val_acc: 0.9550\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9931\n",
      "Epoch 00076: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0237 - acc: 0.9931 - val_loss: 0.1773 - val_acc: 0.9632\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9933\n",
      "Epoch 00077: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0204 - acc: 0.9933 - val_loss: 0.2374 - val_acc: 0.9576\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9925\n",
      "Epoch 00078: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0241 - acc: 0.9925 - val_loss: 0.2235 - val_acc: 0.9578\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9933\n",
      "Epoch 00079: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0221 - acc: 0.9933 - val_loss: 0.2136 - val_acc: 0.9599\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9928- ETA: 3s - loss: 0.022\n",
      "Epoch 00080: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0223 - acc: 0.9928 - val_loss: 0.1864 - val_acc: 0.9625\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9934- ETA: 3s - loss: 0.0\n",
      "Epoch 00081: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0208 - acc: 0.9934 - val_loss: 0.2226 - val_acc: 0.9564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9917\n",
      "Epoch 00082: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0259 - acc: 0.9917 - val_loss: 0.2300 - val_acc: 0.9588\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9942\n",
      "Epoch 00083: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0194 - acc: 0.9942 - val_loss: 0.2134 - val_acc: 0.9625\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9928\n",
      "Epoch 00084: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0246 - acc: 0.9928 - val_loss: 0.1737 - val_acc: 0.9648\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9929- ETA: 0s - loss: 0.0236 - acc: 0.\n",
      "Epoch 00085: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0235 - acc: 0.9929 - val_loss: 0.2076 - val_acc: 0.9602\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9940\n",
      "Epoch 00086: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0189 - acc: 0.9940 - val_loss: 0.1891 - val_acc: 0.9637\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9951\n",
      "Epoch 00087: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0147 - acc: 0.9951 - val_loss: 0.2467 - val_acc: 0.9555\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9933\n",
      "Epoch 00088: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0222 - acc: 0.9933 - val_loss: 0.1878 - val_acc: 0.9637\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9934\n",
      "Epoch 00089: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0194 - acc: 0.9934 - val_loss: 0.1921 - val_acc: 0.9648\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9943\n",
      "Epoch 00090: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0190 - acc: 0.9943 - val_loss: 0.2316 - val_acc: 0.9620\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9937\n",
      "Epoch 00091: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0198 - acc: 0.9937 - val_loss: 0.1963 - val_acc: 0.9623\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9948\n",
      "Epoch 00092: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0179 - acc: 0.9948 - val_loss: 0.2126 - val_acc: 0.9627\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9941\n",
      "Epoch 00093: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0192 - acc: 0.9941 - val_loss: 0.2036 - val_acc: 0.9616\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9932\n",
      "Epoch 00094: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0231 - acc: 0.9932 - val_loss: 0.1861 - val_acc: 0.9599\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9924\n",
      "Epoch 00095: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0233 - acc: 0.9924 - val_loss: 0.2405 - val_acc: 0.9613\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9954\n",
      "Epoch 00096: val_loss did not improve from 0.14759\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0146 - acc: 0.9954 - val_loss: 0.2200 - val_acc: 0.9665\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.2341 - acc: 0.9431\n",
      "Loss: 0.23413542486603448 Accuracy: 0.9430945\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3350 - acc: 0.2278\n",
      "Epoch 00001: val_loss improved from inf to 1.63804, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv_checkpoint/001-1.6380.hdf5\n",
      "36805/36805 [==============================] - 154s 4ms/sample - loss: 2.3349 - acc: 0.2278 - val_loss: 1.6380 - val_acc: 0.4489\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3906 - acc: 0.5399\n",
      "Epoch 00002: val_loss improved from 1.63804 to 0.98090, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv_checkpoint/002-0.9809.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 1.3906 - acc: 0.5399 - val_loss: 0.9809 - val_acc: 0.6662\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8325 - acc: 0.7258\n",
      "Epoch 00003: val_loss improved from 0.98090 to 0.57646, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv_checkpoint/003-0.5765.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.8325 - acc: 0.7259 - val_loss: 0.5765 - val_acc: 0.8150\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5650 - acc: 0.8158\n",
      "Epoch 00004: val_loss improved from 0.57646 to 0.43755, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv_checkpoint/004-0.4375.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.5650 - acc: 0.8158 - val_loss: 0.4375 - val_acc: 0.8656\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4320 - acc: 0.8634\n",
      "Epoch 00005: val_loss improved from 0.43755 to 0.34426, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv_checkpoint/005-0.3443.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.4321 - acc: 0.8634 - val_loss: 0.3443 - val_acc: 0.8896\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3631 - acc: 0.8824\n",
      "Epoch 00006: val_loss improved from 0.34426 to 0.26823, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv_checkpoint/006-0.2682.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.3631 - acc: 0.8824 - val_loss: 0.2682 - val_acc: 0.9150\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3045 - acc: 0.9018\n",
      "Epoch 00007: val_loss did not improve from 0.26823\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.3044 - acc: 0.9018 - val_loss: 0.3906 - val_acc: 0.8835\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2718 - acc: 0.9118\n",
      "Epoch 00008: val_loss improved from 0.26823 to 0.22128, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv_checkpoint/008-0.2213.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.2718 - acc: 0.9118 - val_loss: 0.2213 - val_acc: 0.9329\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2396 - acc: 0.9236\n",
      "Epoch 00009: val_loss improved from 0.22128 to 0.20969, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv_checkpoint/009-0.2097.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.2397 - acc: 0.9236 - val_loss: 0.2097 - val_acc: 0.9350\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2149 - acc: 0.9298\n",
      "Epoch 00010: val_loss did not improve from 0.20969\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.2149 - acc: 0.9298 - val_loss: 0.2112 - val_acc: 0.9306\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1913 - acc: 0.9374\n",
      "Epoch 00011: val_loss did not improve from 0.20969\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1913 - acc: 0.9374 - val_loss: 0.2127 - val_acc: 0.9343\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1786 - acc: 0.9406\n",
      "Epoch 00012: val_loss did not improve from 0.20969\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1786 - acc: 0.9406 - val_loss: 0.2633 - val_acc: 0.9203\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1544 - acc: 0.9490\n",
      "Epoch 00013: val_loss improved from 0.20969 to 0.19197, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv_checkpoint/013-0.1920.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1544 - acc: 0.9490 - val_loss: 0.1920 - val_acc: 0.9373\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9530\n",
      "Epoch 00014: val_loss improved from 0.19197 to 0.17392, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv_checkpoint/014-0.1739.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1408 - acc: 0.9530 - val_loss: 0.1739 - val_acc: 0.9453\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9562\n",
      "Epoch 00015: val_loss did not improve from 0.17392\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1307 - acc: 0.9562 - val_loss: 0.2008 - val_acc: 0.9422\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9600\n",
      "Epoch 00016: val_loss did not improve from 0.17392\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1226 - acc: 0.9600 - val_loss: 0.2050 - val_acc: 0.9439\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9621\n",
      "Epoch 00017: val_loss did not improve from 0.17392\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1118 - acc: 0.9621 - val_loss: 0.1754 - val_acc: 0.9492\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9665\n",
      "Epoch 00018: val_loss improved from 0.17392 to 0.16763, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv_checkpoint/018-0.1676.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1009 - acc: 0.9665 - val_loss: 0.1676 - val_acc: 0.9499\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9678\n",
      "Epoch 00019: val_loss did not improve from 0.16763\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0984 - acc: 0.9678 - val_loss: 0.1782 - val_acc: 0.9511\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9692\n",
      "Epoch 00020: val_loss did not improve from 0.16763\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0924 - acc: 0.9692 - val_loss: 0.1729 - val_acc: 0.9476\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9711\n",
      "Epoch 00021: val_loss did not improve from 0.16763\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0865 - acc: 0.9711 - val_loss: 0.1884 - val_acc: 0.9499\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9744\n",
      "Epoch 00022: val_loss did not improve from 0.16763\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0767 - acc: 0.9744 - val_loss: 0.1877 - val_acc: 0.9513\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9760\n",
      "Epoch 00023: val_loss did not improve from 0.16763\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0720 - acc: 0.9760 - val_loss: 0.1696 - val_acc: 0.9527\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9774\n",
      "Epoch 00024: val_loss improved from 0.16763 to 0.16093, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv_checkpoint/024-0.1609.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0673 - acc: 0.9774 - val_loss: 0.1609 - val_acc: 0.9527\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9775\n",
      "Epoch 00025: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0670 - acc: 0.9775 - val_loss: 0.2377 - val_acc: 0.9415\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9798\n",
      "Epoch 00026: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0598 - acc: 0.9798 - val_loss: 0.1966 - val_acc: 0.9506\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9804\n",
      "Epoch 00027: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0594 - acc: 0.9804 - val_loss: 0.2307 - val_acc: 0.9443\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9831\n",
      "Epoch 00028: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0526 - acc: 0.9831 - val_loss: 0.2035 - val_acc: 0.9504\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9818\n",
      "Epoch 00029: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0530 - acc: 0.9819 - val_loss: 0.2224 - val_acc: 0.9397\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9846\n",
      "Epoch 00030: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0473 - acc: 0.9846 - val_loss: 0.2424 - val_acc: 0.9476\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9833\n",
      "Epoch 00031: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0507 - acc: 0.9833 - val_loss: 0.2127 - val_acc: 0.9536\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9866\n",
      "Epoch 00032: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0420 - acc: 0.9866 - val_loss: 0.2045 - val_acc: 0.9518\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9845\n",
      "Epoch 00033: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0474 - acc: 0.9845 - val_loss: 0.2448 - val_acc: 0.9415\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9882\n",
      "Epoch 00034: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0378 - acc: 0.9882 - val_loss: 0.1849 - val_acc: 0.9599\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9858\n",
      "Epoch 00035: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0452 - acc: 0.9858 - val_loss: 0.2271 - val_acc: 0.9485\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9874\n",
      "Epoch 00036: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0397 - acc: 0.9874 - val_loss: 0.1992 - val_acc: 0.9546\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9898\n",
      "Epoch 00037: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0314 - acc: 0.9898 - val_loss: 0.2480 - val_acc: 0.9488\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9883\n",
      "Epoch 00038: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0375 - acc: 0.9883 - val_loss: 0.2518 - val_acc: 0.9504\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9859\n",
      "Epoch 00039: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0449 - acc: 0.9859 - val_loss: 0.2023 - val_acc: 0.9509\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9898\n",
      "Epoch 00040: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0309 - acc: 0.9898 - val_loss: 0.1896 - val_acc: 0.9585\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9898\n",
      "Epoch 00041: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0349 - acc: 0.9898 - val_loss: 0.1683 - val_acc: 0.9555\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9906\n",
      "Epoch 00042: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0285 - acc: 0.9906 - val_loss: 0.2302 - val_acc: 0.9553\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9882\n",
      "Epoch 00043: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0376 - acc: 0.9882 - val_loss: 0.1818 - val_acc: 0.9595\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9915\n",
      "Epoch 00044: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0261 - acc: 0.9915 - val_loss: 0.2062 - val_acc: 0.9604\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9892\n",
      "Epoch 00045: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0345 - acc: 0.9892 - val_loss: 0.2647 - val_acc: 0.9331\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9912\n",
      "Epoch 00046: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0257 - acc: 0.9912 - val_loss: 0.2110 - val_acc: 0.9597\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9915\n",
      "Epoch 00047: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0289 - acc: 0.9915 - val_loss: 0.2095 - val_acc: 0.9602\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9923\n",
      "Epoch 00048: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0258 - acc: 0.9923 - val_loss: 0.1932 - val_acc: 0.9627\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9906\n",
      "Epoch 00049: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0306 - acc: 0.9906 - val_loss: 0.2008 - val_acc: 0.9583\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9923\n",
      "Epoch 00050: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0249 - acc: 0.9923 - val_loss: 0.2481 - val_acc: 0.9513\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9918\n",
      "Epoch 00051: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0265 - acc: 0.9918 - val_loss: 0.1910 - val_acc: 0.9583\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9933\n",
      "Epoch 00052: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0220 - acc: 0.9933 - val_loss: 0.2062 - val_acc: 0.9627\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9932\n",
      "Epoch 00053: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0220 - acc: 0.9932 - val_loss: 0.3410 - val_acc: 0.9383\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9923\n",
      "Epoch 00054: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0264 - acc: 0.9923 - val_loss: 0.2457 - val_acc: 0.9550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9924\n",
      "Epoch 00055: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0244 - acc: 0.9924 - val_loss: 0.2403 - val_acc: 0.9541\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9916- ETA: 0s - loss: 0.0276 - acc: 0.9\n",
      "Epoch 00056: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0275 - acc: 0.9916 - val_loss: 0.1690 - val_acc: 0.9569\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9939\n",
      "Epoch 00057: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0213 - acc: 0.9939 - val_loss: 0.2021 - val_acc: 0.9639\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9937\n",
      "Epoch 00058: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0199 - acc: 0.9938 - val_loss: 0.2190 - val_acc: 0.9581\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9926\n",
      "Epoch 00059: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0251 - acc: 0.9926 - val_loss: 0.2369 - val_acc: 0.9529\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9938\n",
      "Epoch 00060: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0208 - acc: 0.9938 - val_loss: 0.2026 - val_acc: 0.9583\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9936\n",
      "Epoch 00061: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0208 - acc: 0.9936 - val_loss: 0.2190 - val_acc: 0.9616\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9947\n",
      "Epoch 00062: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0187 - acc: 0.9947 - val_loss: 0.2368 - val_acc: 0.9562\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9945\n",
      "Epoch 00063: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0189 - acc: 0.9945 - val_loss: 0.2516 - val_acc: 0.9539\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9940\n",
      "Epoch 00064: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0203 - acc: 0.9940 - val_loss: 0.1744 - val_acc: 0.9620\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9954\n",
      "Epoch 00065: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0154 - acc: 0.9954 - val_loss: 0.2576 - val_acc: 0.9511\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9936\n",
      "Epoch 00066: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0197 - acc: 0.9936 - val_loss: 0.2089 - val_acc: 0.9585\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9936\n",
      "Epoch 00067: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0226 - acc: 0.9936 - val_loss: 0.1722 - val_acc: 0.9588\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9952\n",
      "Epoch 00068: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0150 - acc: 0.9952 - val_loss: 0.1959 - val_acc: 0.9618\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9948\n",
      "Epoch 00069: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0173 - acc: 0.9948 - val_loss: 0.2174 - val_acc: 0.9522\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9943\n",
      "Epoch 00070: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0183 - acc: 0.9943 - val_loss: 0.2437 - val_acc: 0.9553\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9946\n",
      "Epoch 00071: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0184 - acc: 0.9946 - val_loss: 0.2222 - val_acc: 0.9576\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9957\n",
      "Epoch 00072: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0138 - acc: 0.9957 - val_loss: 0.2126 - val_acc: 0.9590\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9933\n",
      "Epoch 00073: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0224 - acc: 0.9933 - val_loss: 0.2278 - val_acc: 0.9569\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9953\n",
      "Epoch 00074: val_loss did not improve from 0.16093\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0150 - acc: 0.9953 - val_loss: 0.2078 - val_acc: 0.9546\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.2332 - acc: 0.9377\n",
      "Loss: 0.2332433961741897 Accuracy: 0.9376947\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 14):\n",
    "    base = '1D_CNN_custom_conv_3_VGG_pool_2_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_182 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_182 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_183 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_183 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_184 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_184 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_185 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_185 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_186 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_186 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_187 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_187 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                4096016   \n",
      "=================================================================\n",
      "Total params: 4,158,032\n",
      "Trainable params: 4,158,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.6931 - acc: 0.4916\n",
      "Loss: 1.6931262289376026 Accuracy: 0.49158877\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_188 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_188 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_189 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_189 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_190 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_190 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_191 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_191 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_192 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_192 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_193 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_193 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_194 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_194 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_195 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_195 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,134,736\n",
      "Trainable params: 2,134,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.3789 - acc: 0.5786\n",
      "Loss: 1.3788966798584286 Accuracy: 0.5786085\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_196 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_196 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_197 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_197 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_198 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_198 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_199 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_199 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_200 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_200 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_201 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_201 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_202 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_202 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_203 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_203 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_204 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_204 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_205 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_205 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,208,720\n",
      "Trainable params: 2,208,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 1.0985 - acc: 0.6766\n",
      "Loss: 1.0985290856623824 Accuracy: 0.6766355\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_206 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_206 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_207 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_207 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_208 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_208 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_209 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_209 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_210 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_210 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_211 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_211 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_212 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_212 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_213 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_213 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_214 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_214 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_215 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_215 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_216 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_216 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_217 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_217 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,283,280\n",
      "Trainable params: 1,283,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.9917 - acc: 0.7043\n",
      "Loss: 0.9917499873001875 Accuracy: 0.70425755\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_218 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_218 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_219 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_219 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_220 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_220 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_221 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_221 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_222 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_222 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_223 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_223 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_224 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_224 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_225 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_225 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_226 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_226 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_227 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_227 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_228 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_228 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_229 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_229 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_230 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_230 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_231 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_231 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 869,840\n",
      "Trainable params: 869,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.6946 - acc: 0.8177\n",
      "Loss: 0.6946397333749235 Accuracy: 0.8176532\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_232 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_232 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_233 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_233 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_234 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_234 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_235 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_235 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_236 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_236 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_237 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_237 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_238 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_238 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_239 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_239 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_240 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_240 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_241 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_241 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_242 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_242 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_243 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_243 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_244 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_244 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_245 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_245 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_246 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_246 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_247 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_247 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 712,400\n",
      "Trainable params: 712,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.4438 - acc: 0.8756\n",
      "Loss: 0.44378786629234146 Accuracy: 0.8755971\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_248 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_248 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_249 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_249 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_250 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_250 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_251 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_251 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_252 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_252 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_253 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_253 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_254 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_254 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_255 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_255 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_256 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_256 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_257 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_257 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_258 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_258 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_259 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_259 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_260 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_260 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_261 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_261 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_262 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_262 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_263 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_263 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_264 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_264 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_265 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_265 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                253968    \n",
      "=================================================================\n",
      "Total params: 1,005,776\n",
      "Trainable params: 1,005,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2968 - acc: 0.9119\n",
      "Loss: 0.29676123994904513 Accuracy: 0.9119418\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_266 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_266 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_267 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_267 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_268 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_268 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_269 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_269 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_270 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_270 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_271 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_271 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_272 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_272 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_273 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_273 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_274 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_274 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_275 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_275 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_276 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_276 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_277 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_277 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_278 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_278 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_279 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_279 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_280 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_280 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_281 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_281 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_282 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_282 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_283 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_283 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_284 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_284 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_285 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_285 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 1,272,528\n",
      "Trainable params: 1,272,528\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2207 - acc: 0.9352\n",
      "Loss: 0.22074207322495995 Accuracy: 0.9352025\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_286 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_286 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_287 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_287 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_288 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_288 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_289 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_289 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_290 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_290 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_291 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_291 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_292 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_292 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_293 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_293 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_294 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_294 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_295 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_295 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_296 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_296 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_297 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_297 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_126 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_298 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_298 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_299 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_299 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_127 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_300 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_300 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_301 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_301 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_128 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_302 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_302 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_303 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_303 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_129 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_304 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_304 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_305 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_305 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_130 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_306 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_306 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_307 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_307 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_131 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                61456     \n",
      "=================================================================\n",
      "Total params: 1,600,720\n",
      "Trainable params: 1,600,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.1974 - acc: 0.9408\n",
      "Loss: 0.19742133211990506 Accuracy: 0.94080997\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_308 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_308 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_309 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_309 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_310 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_310 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_311 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_311 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_132 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_312 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_312 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_313 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_313 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_314 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_314 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_315 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_315 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_316 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_316 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_317 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_317 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_318 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_318 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_319 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_319 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_320 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_320 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_321 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_321 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_322 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_322 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_323 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_323 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_324 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_324 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_325 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_325 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_326 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_326 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_327 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_327 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_328 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_328 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_329 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_329 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_141 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_330 (Conv1D)          (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_330 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_331 (Conv1D)          (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_331 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_142 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,961,680\n",
      "Trainable params: 1,961,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2341 - acc: 0.9431\n",
      "Loss: 0.23413542486603448 Accuracy: 0.9430945\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_332 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_332 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_333 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_333 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_334 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_334 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_335 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_335 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_336 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_336 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_337 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_337 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_338 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_338 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_339 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_339 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_340 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_340 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_341 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_341 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_342 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_342 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_343 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_343 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_344 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_344 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_345 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_345 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_346 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_346 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_347 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_347 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_149 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_348 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_348 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_349 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_349 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_150 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_350 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_350 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_351 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_351 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_151 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_352 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_352 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_353 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_353 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_152 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_354 (Conv1D)          (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_354 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_355 (Conv1D)          (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_355 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_356 (Conv1D)          (None, 7, 512)            393728    \n",
      "_________________________________________________________________\n",
      "activation_356 (Activation)  (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_357 (Conv1D)          (None, 7, 512)            786944    \n",
      "_________________________________________________________________\n",
      "activation_357 (Activation)  (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_154 (MaxPoolin (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                24592     \n",
      "=================================================================\n",
      "Total params: 3,138,256\n",
      "Trainable params: 3,138,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2332 - acc: 0.9377\n",
      "Loss: 0.2332433961741897 Accuracy: 0.9376947\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_pool_2_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 14):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_182 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_182 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_183 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_183 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_184 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_184 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_185 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_185 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_186 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_186 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_187 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_187 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                4096016   \n",
      "=================================================================\n",
      "Total params: 4,158,032\n",
      "Trainable params: 4,158,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 3.7158 - acc: 0.5304\n",
      "Loss: 3.715766255456958 Accuracy: 0.5304257\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_188 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_188 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_189 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_189 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_190 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_190 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_191 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_191 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_192 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_192 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_193 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_193 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_194 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_194 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_195 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_195 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,134,736\n",
      "Trainable params: 2,134,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 2.6455 - acc: 0.6309\n",
      "Loss: 2.6455272518090616 Accuracy: 0.63094497\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_196 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_196 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_197 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_197 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_198 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_198 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_199 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_199 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_200 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_200 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_201 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_201 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_202 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_202 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_203 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_203 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_204 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_204 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_205 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_205 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,208,720\n",
      "Trainable params: 2,208,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 1.7947 - acc: 0.7205\n",
      "Loss: 1.7947430830011735 Accuracy: 0.7204569\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_206 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_206 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_207 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_207 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_208 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_208 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_209 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_209 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_210 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_210 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_211 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_211 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_212 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_212 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_213 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_213 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_214 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_214 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_215 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_215 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_216 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_216 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_217 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_217 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,283,280\n",
      "Trainable params: 1,283,280\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 1.5473 - acc: 0.7466\n",
      "Loss: 1.5473023600296067 Accuracy: 0.7466251\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_218 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_218 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_219 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_219 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_220 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_220 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_221 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_221 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_222 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_222 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_223 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_223 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_224 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_224 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_225 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_225 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_226 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_226 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_227 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_227 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_228 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_228 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_229 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_229 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_230 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_230 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_231 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_231 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 869,840\n",
      "Trainable params: 869,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.9968 - acc: 0.8388\n",
      "Loss: 0.9967828184892331 Accuracy: 0.83883697\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_232 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_232 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_233 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_233 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_234 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_234 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_235 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_235 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_236 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_236 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_237 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_237 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_238 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_238 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_239 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_239 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_240 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_240 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_241 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_241 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_242 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_242 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_243 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_243 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_244 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_244 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_245 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_245 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_246 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_246 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_247 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_247 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 712,400\n",
      "Trainable params: 712,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.5352 - acc: 0.9013\n",
      "Loss: 0.5351875068397413 Accuracy: 0.90134996\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_248 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_248 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_249 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_249 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_250 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_250 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_251 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_251 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_252 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_252 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_253 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_253 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_254 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_254 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_255 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_255 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_256 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_256 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_257 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_257 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_258 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_258 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_259 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_259 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_260 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_260 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_261 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_261 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_262 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_262 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_263 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_263 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_264 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_264 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_265 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_265 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                253968    \n",
      "=================================================================\n",
      "Total params: 1,005,776\n",
      "Trainable params: 1,005,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.3563 - acc: 0.9232\n",
      "Loss: 0.3563224350397213 Accuracy: 0.9231568\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_10_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_266 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_266 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_267 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_267 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_268 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_268 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_269 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_269 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_270 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_270 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_271 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_271 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_272 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_272 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_273 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_273 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_274 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_274 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_275 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_275 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_276 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_276 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_277 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_277 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_278 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_278 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_279 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_279 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_280 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_280 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_281 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_281 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_282 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_282 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_283 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_283 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_284 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_284 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_285 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_285 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 1,272,528\n",
      "Trainable params: 1,272,528\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2754 - acc: 0.9489\n",
      "Loss: 0.2754059230301893 Accuracy: 0.94890964\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_11_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_286 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_286 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_287 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_287 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_288 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_288 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_289 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_289 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_290 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_290 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_291 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_291 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_292 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_292 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_293 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_293 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_294 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_294 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_295 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_295 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_296 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_296 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_297 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_297 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_126 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_298 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_298 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_299 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_299 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_127 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_300 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_300 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_301 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_301 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_128 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_302 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_302 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_303 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_303 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_129 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_304 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_304 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_305 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_305 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_130 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_306 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_306 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_307 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_307 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_131 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                61456     \n",
      "=================================================================\n",
      "Total params: 1,600,720\n",
      "Trainable params: 1,600,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2505 - acc: 0.9535\n",
      "Loss: 0.25049622560374857 Accuracy: 0.9534787\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_12_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_308 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_308 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_309 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_309 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_310 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_310 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_311 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_311 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_132 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_312 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_312 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_313 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_313 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_314 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_314 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_315 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_315 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_316 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_316 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_317 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_317 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_318 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_318 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_319 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_319 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_320 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_320 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_321 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_321 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_322 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_322 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_323 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_323 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_324 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_324 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_325 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_325 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_326 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_326 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_327 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_327 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_328 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_328 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_329 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_329 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_141 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_330 (Conv1D)          (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_330 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_331 (Conv1D)          (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_331 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_142 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,961,680\n",
      "Trainable params: 1,961,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2741 - acc: 0.9539\n",
      "Loss: 0.2741406687269973 Accuracy: 0.9538941\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_pool_2_DO_13_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_332 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_332 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_333 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_333 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_334 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_334 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_335 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "activation_335 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_336 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_336 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_337 (Conv1D)          (None, 8000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_337 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_338 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_338 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_339 (Conv1D)          (None, 4000, 64)          12352     \n",
      "_________________________________________________________________\n",
      "activation_339 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_340 (Conv1D)          (None, 2000, 128)         24704     \n",
      "_________________________________________________________________\n",
      "activation_340 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_341 (Conv1D)          (None, 2000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_341 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_342 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_342 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_343 (Conv1D)          (None, 1000, 128)         49280     \n",
      "_________________________________________________________________\n",
      "activation_343 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_344 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_344 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_345 (Conv1D)          (None, 500, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_345 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_346 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_346 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_347 (Conv1D)          (None, 250, 128)          49280     \n",
      "_________________________________________________________________\n",
      "activation_347 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_149 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_348 (Conv1D)          (None, 125, 256)          98560     \n",
      "_________________________________________________________________\n",
      "activation_348 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_349 (Conv1D)          (None, 125, 256)          196864    \n",
      "_________________________________________________________________\n",
      "activation_349 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_150 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_350 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_350 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_351 (Conv1D)          (None, 62, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_351 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_151 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_352 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_352 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_353 (Conv1D)          (None, 31, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_353 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_152 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_354 (Conv1D)          (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_354 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_355 (Conv1D)          (None, 15, 256)           196864    \n",
      "_________________________________________________________________\n",
      "activation_355 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_356 (Conv1D)          (None, 7, 512)            393728    \n",
      "_________________________________________________________________\n",
      "activation_356 (Activation)  (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_357 (Conv1D)          (None, 7, 512)            786944    \n",
      "_________________________________________________________________\n",
      "activation_357 (Activation)  (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_154 (MaxPoolin (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                24592     \n",
      "=================================================================\n",
      "Total params: 3,138,256\n",
      "Trainable params: 3,138,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2973 - acc: 0.9398\n",
      "Loss: 0.2973006325814997 Accuracy: 0.93977153\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 14):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
