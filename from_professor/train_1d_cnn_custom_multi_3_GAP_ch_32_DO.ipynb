{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, BatchNormalization, \\\n",
    "                                    Flatten, Conv1D, MaxPooling1D, Dropout, \\\n",
    "                                    Concatenate, GlobalMaxPool1D, GlobalAvgPool1D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cnn(conv_num=1):\n",
    "    filter_size = 32\n",
    "\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    layer_outputs = []\n",
    "    for i in range(conv_num):\n",
    "        x = Conv1D (kernel_size=5, filters=filter_size*(2**(i//4)), \n",
    "                          strides=1, padding='same')(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling1D(pool_size=3, strides=3)(x)\n",
    "        layer_outputs.append(x)    \n",
    "    \n",
    "    x = Concatenate()([GlobalAvgPool1D()(output) for output in layer_outputs[-3:]])\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=x)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 16000, 32)    192         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 16000, 32)    0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D)    (None, 5333, 32)     0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 5333, 32)     5152        max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 5333, 32)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 1777, 32)     0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 1777, 32)     5152        max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 1777, 32)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 592, 32)      0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 32)           0           max_pooling1d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 32)           0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 32)           0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 96)           0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "                                                                 global_average_pooling1d_2[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 96)           0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 16)           1552        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 12,048\n",
      "Trainable params: 12,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 16000, 32)    192         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 16000, 32)    0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 5333, 32)     0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 5333, 32)     5152        max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 5333, 32)     0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 1777, 32)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 1777, 32)     5152        max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 1777, 32)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1D)  (None, 592, 32)      0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 592, 32)      5152        max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 592, 32)      0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1D)  (None, 197, 32)      0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 32)           0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_4 (Glo (None, 32)           0           max_pooling1d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_5 (Glo (None, 32)           0           max_pooling1d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 96)           0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_average_pooling1d_4[0][0] \n",
      "                                                                 global_average_pooling1d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 96)           0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 16)           1552        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,200\n",
      "Trainable params: 17,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 16000, 32)    192         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 16000, 32)    0           conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1D)  (None, 5333, 32)     0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 5333, 32)     5152        max_pooling1d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 5333, 32)     0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1D)  (None, 1777, 32)     0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 1777, 32)     5152        max_pooling1d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 1777, 32)     0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 592, 32)      0           activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 592, 32)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 197, 32)      0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 197, 64)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 65, 64)       0           activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_6 (Glo (None, 32)           0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_7 (Glo (None, 32)           0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_8 (Glo (None, 64)           0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128)          0           global_average_pooling1d_6[0][0] \n",
      "                                                                 global_average_pooling1d_7[0][0] \n",
      "                                                                 global_average_pooling1d_8[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 16)           2064        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,016\n",
      "Trainable params: 28,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 16000, 32)    192         input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 16000, 32)    0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 5333, 32)     0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 5333, 32)     0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling1D) (None, 1777, 32)     0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 1777, 32)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling1D) (None, 592, 32)      0           activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 592, 32)      0           conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling1D) (None, 197, 32)      0           activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 197, 64)      0           conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling1D) (None, 65, 64)       0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 65, 64)       0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling1D) (None, 21, 64)       0           activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_9 (Glo (None, 32)           0           max_pooling1d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_10 (Gl (None, 64)           0           max_pooling1d_16[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_11 (Gl (None, 64)           0           max_pooling1d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 160)          0           global_average_pooling1d_9[0][0] \n",
      "                                                                 global_average_pooling1d_10[0][0]\n",
      "                                                                 global_average_pooling1d_11[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 160)          0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16)           2576        dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 49,072\n",
      "Trainable params: 49,072\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, 16000, 32)    192         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 16000, 32)    0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling1D) (None, 5333, 32)     0           activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 5333, 32)     0           conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling1D) (None, 1777, 32)     0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 1777, 32)     0           conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling1D) (None, 592, 32)      0           activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 592, 32)      0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling1D) (None, 197, 32)      0           activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 197, 64)      0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling1D) (None, 65, 64)       0           activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 65, 64)       0           conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling1D) (None, 21, 64)       0           activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 21, 64)       0           conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling1D) (None, 7, 64)        0           activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_12 (Gl (None, 64)           0           max_pooling1d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_13 (Gl (None, 64)           0           max_pooling1d_23[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_14 (Gl (None, 64)           0           max_pooling1d_24[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 192)          0           global_average_pooling1d_12[0][0]\n",
      "                                                                 global_average_pooling1d_13[0][0]\n",
      "                                                                 global_average_pooling1d_14[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 192)          0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 16)           3088        dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 70,128\n",
      "Trainable params: 70,128\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 16000, 32)    192         input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 16000, 32)    0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling1D) (None, 5333, 32)     0           activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_25[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 5333, 32)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling1D) (None, 1777, 32)     0           activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_26[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 1777, 32)     0           conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling1D) (None, 592, 32)      0           activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 592, 32)      0           conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 197, 32)      0           activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 197, 64)      0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 65, 64)       0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 65, 64)       0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 21, 64)       0           activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 21, 64)       0           conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling1D) (None, 7, 64)        0           activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, 7, 64)        20544       max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 7, 64)        0           conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling1D) (None, 2, 64)        0           activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_15 (Gl (None, 64)           0           max_pooling1d_30[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_16 (Gl (None, 64)           0           max_pooling1d_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_17 (Gl (None, 64)           0           max_pooling1d_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 192)          0           global_average_pooling1d_15[0][0]\n",
      "                                                                 global_average_pooling1d_16[0][0]\n",
      "                                                                 global_average_pooling1d_17[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 192)          0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           3088        dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 90,672\n",
      "Trainable params: 90,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 9):\n",
    "    model = build_cnn(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7384 - acc: 0.0852\n",
      "Epoch 00001: val_loss improved from inf to 2.70404, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/001-2.7040.hdf5\n",
      "36805/36805 [==============================] - 19s 509us/sample - loss: 2.7384 - acc: 0.0852 - val_loss: 2.7040 - val_acc: 0.1281\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6816 - acc: 0.1322\n",
      "Epoch 00002: val_loss improved from 2.70404 to 2.62643, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/002-2.6264.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 2.6816 - acc: 0.1322 - val_loss: 2.6264 - val_acc: 0.1973\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5963 - acc: 0.1683\n",
      "Epoch 00003: val_loss improved from 2.62643 to 2.50406, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/003-2.5041.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 2.5963 - acc: 0.1684 - val_loss: 2.5041 - val_acc: 0.2362\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4867 - acc: 0.1954\n",
      "Epoch 00004: val_loss improved from 2.50406 to 2.37192, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/004-2.3719.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 2.4867 - acc: 0.1954 - val_loss: 2.3719 - val_acc: 0.2614\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3911 - acc: 0.2157\n",
      "Epoch 00005: val_loss improved from 2.37192 to 2.27271, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/005-2.2727.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 2.3911 - acc: 0.2157 - val_loss: 2.2727 - val_acc: 0.3072\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3233 - acc: 0.2338\n",
      "Epoch 00006: val_loss improved from 2.27271 to 2.19850, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/006-2.1985.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 2.3234 - acc: 0.2338 - val_loss: 2.1985 - val_acc: 0.3282\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2707 - acc: 0.2435\n",
      "Epoch 00007: val_loss improved from 2.19850 to 2.13988, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/007-2.1399.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 2.2707 - acc: 0.2435 - val_loss: 2.1399 - val_acc: 0.3380\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2255 - acc: 0.2539\n",
      "Epoch 00008: val_loss improved from 2.13988 to 2.08650, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/008-2.0865.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 2.2255 - acc: 0.2539 - val_loss: 2.0865 - val_acc: 0.3627\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1864 - acc: 0.2690\n",
      "Epoch 00009: val_loss improved from 2.08650 to 2.04976, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/009-2.0498.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 2.1864 - acc: 0.2690 - val_loss: 2.0498 - val_acc: 0.3743\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1531 - acc: 0.2788\n",
      "Epoch 00010: val_loss improved from 2.04976 to 2.01958, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/010-2.0196.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 2.1532 - acc: 0.2788 - val_loss: 2.0196 - val_acc: 0.3848\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1264 - acc: 0.2874\n",
      "Epoch 00011: val_loss improved from 2.01958 to 1.97656, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/011-1.9766.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 2.1264 - acc: 0.2875 - val_loss: 1.9766 - val_acc: 0.3995\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0958 - acc: 0.3021\n",
      "Epoch 00012: val_loss improved from 1.97656 to 1.94712, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/012-1.9471.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 2.0959 - acc: 0.3021 - val_loss: 1.9471 - val_acc: 0.4044\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0696 - acc: 0.3097\n",
      "Epoch 00013: val_loss improved from 1.94712 to 1.92267, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/013-1.9227.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 2.0697 - acc: 0.3097 - val_loss: 1.9227 - val_acc: 0.4156\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0478 - acc: 0.3183\n",
      "Epoch 00014: val_loss improved from 1.92267 to 1.89454, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/014-1.8945.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 2.0479 - acc: 0.3183 - val_loss: 1.8945 - val_acc: 0.4214\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0230 - acc: 0.3257\n",
      "Epoch 00015: val_loss improved from 1.89454 to 1.87288, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/015-1.8729.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 2.0229 - acc: 0.3257 - val_loss: 1.8729 - val_acc: 0.4316\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0092 - acc: 0.3312\n",
      "Epoch 00016: val_loss improved from 1.87288 to 1.84908, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/016-1.8491.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 2.0093 - acc: 0.3312 - val_loss: 1.8491 - val_acc: 0.4361\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9885 - acc: 0.3400\n",
      "Epoch 00017: val_loss improved from 1.84908 to 1.83195, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/017-1.8320.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.9885 - acc: 0.3400 - val_loss: 1.8320 - val_acc: 0.4458\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9751 - acc: 0.3452\n",
      "Epoch 00018: val_loss improved from 1.83195 to 1.81103, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/018-1.8110.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.9751 - acc: 0.3452 - val_loss: 1.8110 - val_acc: 0.4552\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9517 - acc: 0.3540\n",
      "Epoch 00019: val_loss improved from 1.81103 to 1.79453, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/019-1.7945.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.9517 - acc: 0.3541 - val_loss: 1.7945 - val_acc: 0.4605\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9370 - acc: 0.3629\n",
      "Epoch 00020: val_loss improved from 1.79453 to 1.77657, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/020-1.7766.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.9371 - acc: 0.3629 - val_loss: 1.7766 - val_acc: 0.4684\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9258 - acc: 0.3658\n",
      "Epoch 00021: val_loss improved from 1.77657 to 1.75851, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/021-1.7585.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.9258 - acc: 0.3658 - val_loss: 1.7585 - val_acc: 0.4752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9073 - acc: 0.3726\n",
      "Epoch 00022: val_loss improved from 1.75851 to 1.74609, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/022-1.7461.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.9073 - acc: 0.3726 - val_loss: 1.7461 - val_acc: 0.4785\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9008 - acc: 0.3770\n",
      "Epoch 00023: val_loss improved from 1.74609 to 1.73276, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/023-1.7328.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.9007 - acc: 0.3770 - val_loss: 1.7328 - val_acc: 0.4819\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8817 - acc: 0.3807\n",
      "Epoch 00024: val_loss improved from 1.73276 to 1.71696, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/024-1.7170.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.8817 - acc: 0.3807 - val_loss: 1.7170 - val_acc: 0.4857\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8744 - acc: 0.3838\n",
      "Epoch 00025: val_loss improved from 1.71696 to 1.70218, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/025-1.7022.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.8744 - acc: 0.3838 - val_loss: 1.7022 - val_acc: 0.4903\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8621 - acc: 0.3875\n",
      "Epoch 00026: val_loss improved from 1.70218 to 1.69219, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/026-1.6922.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.8621 - acc: 0.3874 - val_loss: 1.6922 - val_acc: 0.4945\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8540 - acc: 0.3930\n",
      "Epoch 00027: val_loss improved from 1.69219 to 1.68044, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/027-1.6804.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.8540 - acc: 0.3930 - val_loss: 1.6804 - val_acc: 0.4983\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8332 - acc: 0.3980\n",
      "Epoch 00028: val_loss improved from 1.68044 to 1.66724, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/028-1.6672.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.8332 - acc: 0.3980 - val_loss: 1.6672 - val_acc: 0.5043\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8301 - acc: 0.4015\n",
      "Epoch 00029: val_loss improved from 1.66724 to 1.65654, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/029-1.6565.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.8301 - acc: 0.4015 - val_loss: 1.6565 - val_acc: 0.5113\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8196 - acc: 0.4060\n",
      "Epoch 00030: val_loss improved from 1.65654 to 1.64760, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/030-1.6476.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.8196 - acc: 0.4061 - val_loss: 1.6476 - val_acc: 0.5164\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8130 - acc: 0.4083\n",
      "Epoch 00031: val_loss improved from 1.64760 to 1.63193, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/031-1.6319.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.8131 - acc: 0.4082 - val_loss: 1.6319 - val_acc: 0.5232\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8000 - acc: 0.4106\n",
      "Epoch 00032: val_loss improved from 1.63193 to 1.62042, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/032-1.6204.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.8000 - acc: 0.4106 - val_loss: 1.6204 - val_acc: 0.5234\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7976 - acc: 0.4126\n",
      "Epoch 00033: val_loss improved from 1.62042 to 1.61194, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/033-1.6119.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.7976 - acc: 0.4127 - val_loss: 1.6119 - val_acc: 0.5260\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7848 - acc: 0.4152\n",
      "Epoch 00034: val_loss improved from 1.61194 to 1.60134, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/034-1.6013.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.7848 - acc: 0.4151 - val_loss: 1.6013 - val_acc: 0.5278\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7760 - acc: 0.4202\n",
      "Epoch 00035: val_loss improved from 1.60134 to 1.59083, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/035-1.5908.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.7760 - acc: 0.4202 - val_loss: 1.5908 - val_acc: 0.5318\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7708 - acc: 0.4229\n",
      "Epoch 00036: val_loss improved from 1.59083 to 1.58399, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/036-1.5840.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.7708 - acc: 0.4229 - val_loss: 1.5840 - val_acc: 0.5320\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7611 - acc: 0.4236\n",
      "Epoch 00037: val_loss improved from 1.58399 to 1.57570, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/037-1.5757.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.7610 - acc: 0.4237 - val_loss: 1.5757 - val_acc: 0.5318\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7552 - acc: 0.4279\n",
      "Epoch 00038: val_loss improved from 1.57570 to 1.56236, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/038-1.5624.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.7552 - acc: 0.4279 - val_loss: 1.5624 - val_acc: 0.5358\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7455 - acc: 0.4299\n",
      "Epoch 00039: val_loss improved from 1.56236 to 1.55634, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/039-1.5563.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.7456 - acc: 0.4299 - val_loss: 1.5563 - val_acc: 0.5413\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7315 - acc: 0.4362\n",
      "Epoch 00040: val_loss improved from 1.55634 to 1.54315, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/040-1.5432.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.7315 - acc: 0.4362 - val_loss: 1.5432 - val_acc: 0.5500\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7304 - acc: 0.4339\n",
      "Epoch 00041: val_loss improved from 1.54315 to 1.53215, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/041-1.5322.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.7304 - acc: 0.4339 - val_loss: 1.5322 - val_acc: 0.5462\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7256 - acc: 0.4369\n",
      "Epoch 00042: val_loss improved from 1.53215 to 1.52343, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/042-1.5234.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.7255 - acc: 0.4369 - val_loss: 1.5234 - val_acc: 0.5563\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7168 - acc: 0.4435\n",
      "Epoch 00043: val_loss improved from 1.52343 to 1.52053, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/043-1.5205.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.7168 - acc: 0.4435 - val_loss: 1.5205 - val_acc: 0.5535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7150 - acc: 0.4462\n",
      "Epoch 00044: val_loss improved from 1.52053 to 1.51065, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/044-1.5107.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.7149 - acc: 0.4463 - val_loss: 1.5107 - val_acc: 0.5565\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7048 - acc: 0.4446\n",
      "Epoch 00045: val_loss improved from 1.51065 to 1.50360, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/045-1.5036.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.7049 - acc: 0.4446 - val_loss: 1.5036 - val_acc: 0.5528\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7000 - acc: 0.4489\n",
      "Epoch 00046: val_loss improved from 1.50360 to 1.49435, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/046-1.4944.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.7000 - acc: 0.4490 - val_loss: 1.4944 - val_acc: 0.5628\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6850 - acc: 0.4543\n",
      "Epoch 00047: val_loss improved from 1.49435 to 1.48065, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/047-1.4806.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.6850 - acc: 0.4544 - val_loss: 1.4806 - val_acc: 0.5639\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6880 - acc: 0.4506\n",
      "Epoch 00048: val_loss did not improve from 1.48065\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.6879 - acc: 0.4506 - val_loss: 1.4835 - val_acc: 0.5600\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6818 - acc: 0.4551\n",
      "Epoch 00049: val_loss improved from 1.48065 to 1.46841, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/049-1.4684.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.6818 - acc: 0.4551 - val_loss: 1.4684 - val_acc: 0.5632\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6760 - acc: 0.4552\n",
      "Epoch 00050: val_loss improved from 1.46841 to 1.46505, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/050-1.4650.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.6760 - acc: 0.4552 - val_loss: 1.4650 - val_acc: 0.5679\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6665 - acc: 0.4615\n",
      "Epoch 00051: val_loss improved from 1.46505 to 1.45591, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/051-1.4559.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.6665 - acc: 0.4615 - val_loss: 1.4559 - val_acc: 0.5705\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6680 - acc: 0.4593\n",
      "Epoch 00052: val_loss improved from 1.45591 to 1.45490, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/052-1.4549.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.6680 - acc: 0.4593 - val_loss: 1.4549 - val_acc: 0.5674\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6536 - acc: 0.4651\n",
      "Epoch 00053: val_loss improved from 1.45490 to 1.44076, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/053-1.4408.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.6535 - acc: 0.4651 - val_loss: 1.4408 - val_acc: 0.5798\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6488 - acc: 0.4656\n",
      "Epoch 00054: val_loss improved from 1.44076 to 1.43443, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/054-1.4344.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.6490 - acc: 0.4656 - val_loss: 1.4344 - val_acc: 0.5812\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6440 - acc: 0.4682\n",
      "Epoch 00055: val_loss improved from 1.43443 to 1.43078, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/055-1.4308.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.6440 - acc: 0.4682 - val_loss: 1.4308 - val_acc: 0.5782\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6363 - acc: 0.4713\n",
      "Epoch 00056: val_loss improved from 1.43078 to 1.42880, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/056-1.4288.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.6363 - acc: 0.4713 - val_loss: 1.4288 - val_acc: 0.5742\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6399 - acc: 0.4686\n",
      "Epoch 00057: val_loss improved from 1.42880 to 1.41566, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/057-1.4157.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.6399 - acc: 0.4686 - val_loss: 1.4157 - val_acc: 0.5837\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6261 - acc: 0.4747\n",
      "Epoch 00058: val_loss improved from 1.41566 to 1.40908, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/058-1.4091.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.6260 - acc: 0.4747 - val_loss: 1.4091 - val_acc: 0.5875\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6249 - acc: 0.4726\n",
      "Epoch 00059: val_loss improved from 1.40908 to 1.40501, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/059-1.4050.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.6249 - acc: 0.4726 - val_loss: 1.4050 - val_acc: 0.5886\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6184 - acc: 0.4748\n",
      "Epoch 00060: val_loss improved from 1.40501 to 1.40396, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/060-1.4040.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.6184 - acc: 0.4749 - val_loss: 1.4040 - val_acc: 0.5891\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6126 - acc: 0.4796\n",
      "Epoch 00061: val_loss improved from 1.40396 to 1.38704, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/061-1.3870.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.6126 - acc: 0.4796 - val_loss: 1.3870 - val_acc: 0.5956\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6149 - acc: 0.4799\n",
      "Epoch 00062: val_loss improved from 1.38704 to 1.38458, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/062-1.3846.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.6148 - acc: 0.4799 - val_loss: 1.3846 - val_acc: 0.5919\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6065 - acc: 0.4839\n",
      "Epoch 00063: val_loss improved from 1.38458 to 1.38309, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/063-1.3831.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.6064 - acc: 0.4839 - val_loss: 1.3831 - val_acc: 0.5975\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6037 - acc: 0.4845\n",
      "Epoch 00064: val_loss improved from 1.38309 to 1.37344, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/064-1.3734.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.6037 - acc: 0.4844 - val_loss: 1.3734 - val_acc: 0.5991\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5996 - acc: 0.4848\n",
      "Epoch 00065: val_loss improved from 1.37344 to 1.36911, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/065-1.3691.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.5996 - acc: 0.4847 - val_loss: 1.3691 - val_acc: 0.6010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5954 - acc: 0.4849\n",
      "Epoch 00066: val_loss did not improve from 1.36911\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.5954 - acc: 0.4850 - val_loss: 1.3693 - val_acc: 0.5998\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5865 - acc: 0.4902\n",
      "Epoch 00067: val_loss improved from 1.36911 to 1.35642, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/067-1.3564.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.5864 - acc: 0.4902 - val_loss: 1.3564 - val_acc: 0.6031\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5807 - acc: 0.4893\n",
      "Epoch 00068: val_loss did not improve from 1.35642\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.5806 - acc: 0.4893 - val_loss: 1.3618 - val_acc: 0.6000\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5828 - acc: 0.4900\n",
      "Epoch 00069: val_loss improved from 1.35642 to 1.34793, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/069-1.3479.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.5829 - acc: 0.4900 - val_loss: 1.3479 - val_acc: 0.6040\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5731 - acc: 0.4948\n",
      "Epoch 00070: val_loss did not improve from 1.34793\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.5734 - acc: 0.4948 - val_loss: 1.3483 - val_acc: 0.6047\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5720 - acc: 0.4954\n",
      "Epoch 00071: val_loss improved from 1.34793 to 1.34125, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/071-1.3413.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.5719 - acc: 0.4955 - val_loss: 1.3413 - val_acc: 0.6066\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5716 - acc: 0.4936\n",
      "Epoch 00072: val_loss improved from 1.34125 to 1.33263, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/072-1.3326.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.5715 - acc: 0.4937 - val_loss: 1.3326 - val_acc: 0.6140\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5601 - acc: 0.4984\n",
      "Epoch 00073: val_loss improved from 1.33263 to 1.32802, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/073-1.3280.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.5601 - acc: 0.4984 - val_loss: 1.3280 - val_acc: 0.6140\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5563 - acc: 0.4982\n",
      "Epoch 00074: val_loss improved from 1.32802 to 1.32651, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/074-1.3265.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.5564 - acc: 0.4982 - val_loss: 1.3265 - val_acc: 0.6157\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5597 - acc: 0.4981\n",
      "Epoch 00075: val_loss improved from 1.32651 to 1.31581, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/075-1.3158.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.5597 - acc: 0.4981 - val_loss: 1.3158 - val_acc: 0.6119\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5518 - acc: 0.5004\n",
      "Epoch 00076: val_loss improved from 1.31581 to 1.31391, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/076-1.3139.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.5520 - acc: 0.5003 - val_loss: 1.3139 - val_acc: 0.6196\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5429 - acc: 0.5044\n",
      "Epoch 00077: val_loss improved from 1.31391 to 1.30457, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/077-1.3046.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.5429 - acc: 0.5044 - val_loss: 1.3046 - val_acc: 0.6212\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5434 - acc: 0.5042\n",
      "Epoch 00078: val_loss did not improve from 1.30457\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.5434 - acc: 0.5043 - val_loss: 1.3086 - val_acc: 0.6194\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5409 - acc: 0.5042\n",
      "Epoch 00079: val_loss did not improve from 1.30457\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.5409 - acc: 0.5043 - val_loss: 1.3101 - val_acc: 0.6143\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5420 - acc: 0.5040\n",
      "Epoch 00080: val_loss improved from 1.30457 to 1.30047, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/080-1.3005.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.5420 - acc: 0.5040 - val_loss: 1.3005 - val_acc: 0.6250\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5355 - acc: 0.5066\n",
      "Epoch 00081: val_loss improved from 1.30047 to 1.29262, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/081-1.2926.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.5354 - acc: 0.5066 - val_loss: 1.2926 - val_acc: 0.6285\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5290 - acc: 0.5088\n",
      "Epoch 00082: val_loss improved from 1.29262 to 1.28696, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/082-1.2870.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.5291 - acc: 0.5087 - val_loss: 1.2870 - val_acc: 0.6301\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5322 - acc: 0.5050\n",
      "Epoch 00083: val_loss improved from 1.28696 to 1.28347, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/083-1.2835.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.5321 - acc: 0.5050 - val_loss: 1.2835 - val_acc: 0.6331\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5171 - acc: 0.5086\n",
      "Epoch 00084: val_loss improved from 1.28347 to 1.27536, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/084-1.2754.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.5172 - acc: 0.5085 - val_loss: 1.2754 - val_acc: 0.6327\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5227 - acc: 0.5106\n",
      "Epoch 00085: val_loss did not improve from 1.27536\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.5231 - acc: 0.5106 - val_loss: 1.2780 - val_acc: 0.6261\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5180 - acc: 0.5120\n",
      "Epoch 00086: val_loss improved from 1.27536 to 1.27166, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/086-1.2717.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.5179 - acc: 0.5120 - val_loss: 1.2717 - val_acc: 0.6310\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5157 - acc: 0.5146\n",
      "Epoch 00087: val_loss improved from 1.27166 to 1.26974, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/087-1.2697.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.5157 - acc: 0.5146 - val_loss: 1.2697 - val_acc: 0.6352\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5106 - acc: 0.5149\n",
      "Epoch 00088: val_loss improved from 1.26974 to 1.26744, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/088-1.2674.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.5106 - acc: 0.5150 - val_loss: 1.2674 - val_acc: 0.6362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5091 - acc: 0.5146\n",
      "Epoch 00089: val_loss improved from 1.26744 to 1.26393, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/089-1.2639.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.5091 - acc: 0.5146 - val_loss: 1.2639 - val_acc: 0.6382\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5007 - acc: 0.5206\n",
      "Epoch 00090: val_loss improved from 1.26393 to 1.25789, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/090-1.2579.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.5007 - acc: 0.5206 - val_loss: 1.2579 - val_acc: 0.6420\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5021 - acc: 0.5209\n",
      "Epoch 00091: val_loss improved from 1.25789 to 1.25653, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/091-1.2565.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.5020 - acc: 0.5209 - val_loss: 1.2565 - val_acc: 0.6415\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4995 - acc: 0.5196\n",
      "Epoch 00092: val_loss improved from 1.25653 to 1.25418, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/092-1.2542.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.4995 - acc: 0.5196 - val_loss: 1.2542 - val_acc: 0.6410\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4980 - acc: 0.5212\n",
      "Epoch 00093: val_loss improved from 1.25418 to 1.24531, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/093-1.2453.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.4979 - acc: 0.5212 - val_loss: 1.2453 - val_acc: 0.6436\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4947 - acc: 0.5214\n",
      "Epoch 00094: val_loss did not improve from 1.24531\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.4947 - acc: 0.5215 - val_loss: 1.2455 - val_acc: 0.6455\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4912 - acc: 0.5222\n",
      "Epoch 00095: val_loss improved from 1.24531 to 1.24098, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/095-1.2410.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.4912 - acc: 0.5222 - val_loss: 1.2410 - val_acc: 0.6457\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4948 - acc: 0.5216\n",
      "Epoch 00096: val_loss did not improve from 1.24098\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.4947 - acc: 0.5216 - val_loss: 1.2432 - val_acc: 0.6487\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4892 - acc: 0.5237\n",
      "Epoch 00097: val_loss improved from 1.24098 to 1.23495, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/097-1.2349.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.4891 - acc: 0.5237 - val_loss: 1.2349 - val_acc: 0.6487\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4822 - acc: 0.5249\n",
      "Epoch 00098: val_loss improved from 1.23495 to 1.23227, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/098-1.2323.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.4821 - acc: 0.5249 - val_loss: 1.2323 - val_acc: 0.6504\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4869 - acc: 0.5245\n",
      "Epoch 00099: val_loss did not improve from 1.23227\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.4869 - acc: 0.5245 - val_loss: 1.2335 - val_acc: 0.6478\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4824 - acc: 0.5262\n",
      "Epoch 00100: val_loss improved from 1.23227 to 1.22948, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/100-1.2295.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.4823 - acc: 0.5262 - val_loss: 1.2295 - val_acc: 0.6455\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4752 - acc: 0.5290\n",
      "Epoch 00101: val_loss improved from 1.22948 to 1.22382, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/101-1.2238.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.4753 - acc: 0.5289 - val_loss: 1.2238 - val_acc: 0.6534\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4717 - acc: 0.5282\n",
      "Epoch 00102: val_loss improved from 1.22382 to 1.22177, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/102-1.2218.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.4717 - acc: 0.5282 - val_loss: 1.2218 - val_acc: 0.6536\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4701 - acc: 0.5292\n",
      "Epoch 00103: val_loss improved from 1.22177 to 1.21385, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/103-1.2138.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.4701 - acc: 0.5292 - val_loss: 1.2138 - val_acc: 0.6536\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4683 - acc: 0.5303\n",
      "Epoch 00104: val_loss did not improve from 1.21385\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.4684 - acc: 0.5303 - val_loss: 1.2154 - val_acc: 0.6543\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4694 - acc: 0.5292\n",
      "Epoch 00105: val_loss improved from 1.21385 to 1.20870, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/105-1.2087.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.4695 - acc: 0.5291 - val_loss: 1.2087 - val_acc: 0.6550\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4615 - acc: 0.5292\n",
      "Epoch 00106: val_loss did not improve from 1.20870\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.4616 - acc: 0.5291 - val_loss: 1.2104 - val_acc: 0.6571\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4593 - acc: 0.5324\n",
      "Epoch 00107: val_loss improved from 1.20870 to 1.20545, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/107-1.2055.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.4593 - acc: 0.5324 - val_loss: 1.2055 - val_acc: 0.6564\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4579 - acc: 0.5359\n",
      "Epoch 00108: val_loss improved from 1.20545 to 1.20039, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/108-1.2004.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.4578 - acc: 0.5359 - val_loss: 1.2004 - val_acc: 0.6585\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4606 - acc: 0.5300\n",
      "Epoch 00109: val_loss improved from 1.20039 to 1.19988, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/109-1.1999.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.4607 - acc: 0.5300 - val_loss: 1.1999 - val_acc: 0.6578\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4493 - acc: 0.5371\n",
      "Epoch 00110: val_loss improved from 1.19988 to 1.18951, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/110-1.1895.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.4494 - acc: 0.5372 - val_loss: 1.1895 - val_acc: 0.6597\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4537 - acc: 0.5374\n",
      "Epoch 00111: val_loss did not improve from 1.18951\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.4537 - acc: 0.5374 - val_loss: 1.1988 - val_acc: 0.6550\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4508 - acc: 0.5354\n",
      "Epoch 00112: val_loss did not improve from 1.18951\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.4508 - acc: 0.5354 - val_loss: 1.1932 - val_acc: 0.6627\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4491 - acc: 0.5368\n",
      "Epoch 00113: val_loss improved from 1.18951 to 1.18907, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/113-1.1891.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.4490 - acc: 0.5368 - val_loss: 1.1891 - val_acc: 0.6580\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4478 - acc: 0.5374\n",
      "Epoch 00114: val_loss improved from 1.18907 to 1.18774, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/114-1.1877.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.4478 - acc: 0.5374 - val_loss: 1.1877 - val_acc: 0.6585\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4405 - acc: 0.5422\n",
      "Epoch 00115: val_loss did not improve from 1.18774\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.4406 - acc: 0.5422 - val_loss: 1.1887 - val_acc: 0.6622\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4419 - acc: 0.5388\n",
      "Epoch 00116: val_loss improved from 1.18774 to 1.17935, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/116-1.1793.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.4418 - acc: 0.5388 - val_loss: 1.1793 - val_acc: 0.6660\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4392 - acc: 0.5414\n",
      "Epoch 00117: val_loss improved from 1.17935 to 1.17929, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/117-1.1793.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.4393 - acc: 0.5414 - val_loss: 1.1793 - val_acc: 0.6639\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4384 - acc: 0.5446\n",
      "Epoch 00118: val_loss did not improve from 1.17929\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.4383 - acc: 0.5447 - val_loss: 1.1796 - val_acc: 0.6613\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4374 - acc: 0.5396\n",
      "Epoch 00119: val_loss improved from 1.17929 to 1.16989, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/119-1.1699.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.4374 - acc: 0.5397 - val_loss: 1.1699 - val_acc: 0.6648\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4246 - acc: 0.5461\n",
      "Epoch 00120: val_loss improved from 1.16989 to 1.16784, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/120-1.1678.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.4246 - acc: 0.5461 - val_loss: 1.1678 - val_acc: 0.6653\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4301 - acc: 0.5447\n",
      "Epoch 00121: val_loss did not improve from 1.16784\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.4302 - acc: 0.5447 - val_loss: 1.1720 - val_acc: 0.6632\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4327 - acc: 0.5432\n",
      "Epoch 00122: val_loss did not improve from 1.16784\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.4327 - acc: 0.5432 - val_loss: 1.1689 - val_acc: 0.6678\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4270 - acc: 0.5476\n",
      "Epoch 00123: val_loss improved from 1.16784 to 1.16599, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/123-1.1660.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.4270 - acc: 0.5475 - val_loss: 1.1660 - val_acc: 0.6692\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4251 - acc: 0.5456\n",
      "Epoch 00124: val_loss improved from 1.16599 to 1.16242, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/124-1.1624.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.4250 - acc: 0.5457 - val_loss: 1.1624 - val_acc: 0.6678\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4143 - acc: 0.5496\n",
      "Epoch 00125: val_loss did not improve from 1.16242\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.4145 - acc: 0.5496 - val_loss: 1.1626 - val_acc: 0.6692\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4228 - acc: 0.5469\n",
      "Epoch 00126: val_loss improved from 1.16242 to 1.16211, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/126-1.1621.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.4227 - acc: 0.5469 - val_loss: 1.1621 - val_acc: 0.6692\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4152 - acc: 0.5502\n",
      "Epoch 00127: val_loss did not improve from 1.16211\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.4151 - acc: 0.5503 - val_loss: 1.1660 - val_acc: 0.6667\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4153 - acc: 0.5507\n",
      "Epoch 00128: val_loss improved from 1.16211 to 1.15451, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/128-1.1545.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.4153 - acc: 0.5507 - val_loss: 1.1545 - val_acc: 0.6683\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4082 - acc: 0.5509\n",
      "Epoch 00129: val_loss improved from 1.15451 to 1.14915, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/129-1.1492.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.4081 - acc: 0.5509 - val_loss: 1.1492 - val_acc: 0.6723\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4161 - acc: 0.5471\n",
      "Epoch 00130: val_loss improved from 1.14915 to 1.14491, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/130-1.1449.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.4160 - acc: 0.5471 - val_loss: 1.1449 - val_acc: 0.6748\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4106 - acc: 0.5502\n",
      "Epoch 00131: val_loss did not improve from 1.14491\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.4108 - acc: 0.5502 - val_loss: 1.1502 - val_acc: 0.6762\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4103 - acc: 0.5502\n",
      "Epoch 00132: val_loss improved from 1.14491 to 1.14445, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/132-1.1445.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.4103 - acc: 0.5502 - val_loss: 1.1445 - val_acc: 0.6781\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4069 - acc: 0.5488\n",
      "Epoch 00133: val_loss did not improve from 1.14445\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.4069 - acc: 0.5488 - val_loss: 1.1452 - val_acc: 0.6760\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4080 - acc: 0.5548\n",
      "Epoch 00134: val_loss improved from 1.14445 to 1.14303, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/134-1.1430.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.4080 - acc: 0.5548 - val_loss: 1.1430 - val_acc: 0.6739\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3989 - acc: 0.5580\n",
      "Epoch 00135: val_loss improved from 1.14303 to 1.13812, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/135-1.1381.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.3989 - acc: 0.5580 - val_loss: 1.1381 - val_acc: 0.6758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3983 - acc: 0.5564\n",
      "Epoch 00136: val_loss improved from 1.13812 to 1.13537, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/136-1.1354.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.3982 - acc: 0.5564 - val_loss: 1.1354 - val_acc: 0.6783\n",
      "Epoch 137/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.4009 - acc: 0.5567\n",
      "Epoch 00137: val_loss improved from 1.13537 to 1.13414, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/137-1.1341.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.4011 - acc: 0.5568 - val_loss: 1.1341 - val_acc: 0.6767\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3960 - acc: 0.5552\n",
      "Epoch 00138: val_loss improved from 1.13414 to 1.13254, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/138-1.1325.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.3960 - acc: 0.5553 - val_loss: 1.1325 - val_acc: 0.6783\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3891 - acc: 0.5587\n",
      "Epoch 00139: val_loss improved from 1.13254 to 1.13219, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/139-1.1322.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.3890 - acc: 0.5588 - val_loss: 1.1322 - val_acc: 0.6809\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3932 - acc: 0.5554\n",
      "Epoch 00140: val_loss improved from 1.13219 to 1.12507, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/140-1.1251.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3933 - acc: 0.5554 - val_loss: 1.1251 - val_acc: 0.6776\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3915 - acc: 0.5598\n",
      "Epoch 00141: val_loss did not improve from 1.12507\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 1.3914 - acc: 0.5598 - val_loss: 1.1283 - val_acc: 0.6776\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3856 - acc: 0.5604\n",
      "Epoch 00142: val_loss improved from 1.12507 to 1.12253, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/142-1.1225.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.3856 - acc: 0.5604 - val_loss: 1.1225 - val_acc: 0.6795\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3916 - acc: 0.5568\n",
      "Epoch 00143: val_loss did not improve from 1.12253\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.3915 - acc: 0.5567 - val_loss: 1.1227 - val_acc: 0.6802\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3841 - acc: 0.5617\n",
      "Epoch 00144: val_loss improved from 1.12253 to 1.12105, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/144-1.1211.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.3841 - acc: 0.5617 - val_loss: 1.1211 - val_acc: 0.6785\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3839 - acc: 0.5600\n",
      "Epoch 00145: val_loss improved from 1.12105 to 1.11793, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/145-1.1179.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.3839 - acc: 0.5600 - val_loss: 1.1179 - val_acc: 0.6820\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3862 - acc: 0.5586\n",
      "Epoch 00146: val_loss improved from 1.11793 to 1.11780, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/146-1.1178.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.3861 - acc: 0.5586 - val_loss: 1.1178 - val_acc: 0.6865\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3857 - acc: 0.5601\n",
      "Epoch 00147: val_loss improved from 1.11780 to 1.11611, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/147-1.1161.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.3856 - acc: 0.5601 - val_loss: 1.1161 - val_acc: 0.6844\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3830 - acc: 0.5588\n",
      "Epoch 00148: val_loss did not improve from 1.11611\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.3830 - acc: 0.5588 - val_loss: 1.1206 - val_acc: 0.6830\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3684 - acc: 0.5628\n",
      "Epoch 00149: val_loss improved from 1.11611 to 1.10802, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/149-1.1080.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.3684 - acc: 0.5627 - val_loss: 1.1080 - val_acc: 0.6895\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3779 - acc: 0.5631\n",
      "Epoch 00150: val_loss improved from 1.10802 to 1.10648, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/150-1.1065.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.3779 - acc: 0.5631 - val_loss: 1.1065 - val_acc: 0.6851\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3710 - acc: 0.5629\n",
      "Epoch 00151: val_loss improved from 1.10648 to 1.10460, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/151-1.1046.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.3710 - acc: 0.5629 - val_loss: 1.1046 - val_acc: 0.6862\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3746 - acc: 0.5610\n",
      "Epoch 00152: val_loss improved from 1.10460 to 1.10311, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/152-1.1031.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.3747 - acc: 0.5610 - val_loss: 1.1031 - val_acc: 0.6869\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3654 - acc: 0.5693\n",
      "Epoch 00153: val_loss improved from 1.10311 to 1.09701, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/153-1.0970.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.3655 - acc: 0.5693 - val_loss: 1.0970 - val_acc: 0.6886\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3673 - acc: 0.5660\n",
      "Epoch 00154: val_loss did not improve from 1.09701\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3673 - acc: 0.5660 - val_loss: 1.0993 - val_acc: 0.6876\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3644 - acc: 0.5677\n",
      "Epoch 00155: val_loss improved from 1.09701 to 1.09584, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/155-1.0958.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3643 - acc: 0.5678 - val_loss: 1.0958 - val_acc: 0.6858\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3644 - acc: 0.5672\n",
      "Epoch 00156: val_loss improved from 1.09584 to 1.09179, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/156-1.0918.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.3643 - acc: 0.5672 - val_loss: 1.0918 - val_acc: 0.6890\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3592 - acc: 0.5695\n",
      "Epoch 00157: val_loss did not improve from 1.09179\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.3592 - acc: 0.5695 - val_loss: 1.0937 - val_acc: 0.6900\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3620 - acc: 0.5674\n",
      "Epoch 00158: val_loss improved from 1.09179 to 1.09003, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/158-1.0900.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3619 - acc: 0.5675 - val_loss: 1.0900 - val_acc: 0.6909\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 159/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3629 - acc: 0.5684\n",
      "Epoch 00159: val_loss improved from 1.09003 to 1.08918, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/159-1.0892.hdf5\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.3628 - acc: 0.5684 - val_loss: 1.0892 - val_acc: 0.6900\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3583 - acc: 0.5707\n",
      "Epoch 00160: val_loss improved from 1.08918 to 1.08415, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/160-1.0841.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3582 - acc: 0.5707 - val_loss: 1.0841 - val_acc: 0.6946\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3554 - acc: 0.5724\n",
      "Epoch 00161: val_loss did not improve from 1.08415\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3554 - acc: 0.5724 - val_loss: 1.0855 - val_acc: 0.6923\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3576 - acc: 0.5703\n",
      "Epoch 00162: val_loss improved from 1.08415 to 1.08068, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/162-1.0807.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3575 - acc: 0.5703 - val_loss: 1.0807 - val_acc: 0.6944\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3546 - acc: 0.5708\n",
      "Epoch 00163: val_loss did not improve from 1.08068\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3546 - acc: 0.5708 - val_loss: 1.0892 - val_acc: 0.6949\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3510 - acc: 0.5746\n",
      "Epoch 00164: val_loss did not improve from 1.08068\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.3510 - acc: 0.5746 - val_loss: 1.0813 - val_acc: 0.6928\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3457 - acc: 0.5734\n",
      "Epoch 00165: val_loss improved from 1.08068 to 1.07442, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/165-1.0744.hdf5\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.3457 - acc: 0.5734 - val_loss: 1.0744 - val_acc: 0.6956\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3475 - acc: 0.5731\n",
      "Epoch 00166: val_loss did not improve from 1.07442\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.3477 - acc: 0.5731 - val_loss: 1.0804 - val_acc: 0.6990\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3421 - acc: 0.5759\n",
      "Epoch 00167: val_loss did not improve from 1.07442\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.3421 - acc: 0.5759 - val_loss: 1.0796 - val_acc: 0.6932\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3384 - acc: 0.5792\n",
      "Epoch 00168: val_loss improved from 1.07442 to 1.06930, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/168-1.0693.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.3384 - acc: 0.5792 - val_loss: 1.0693 - val_acc: 0.6988\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3378 - acc: 0.5786\n",
      "Epoch 00169: val_loss improved from 1.06930 to 1.06858, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/169-1.0686.hdf5\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 1.3379 - acc: 0.5786 - val_loss: 1.0686 - val_acc: 0.6983\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3408 - acc: 0.5800\n",
      "Epoch 00170: val_loss improved from 1.06858 to 1.06652, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/170-1.0665.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3408 - acc: 0.5800 - val_loss: 1.0665 - val_acc: 0.6986\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3349 - acc: 0.5790\n",
      "Epoch 00171: val_loss improved from 1.06652 to 1.06294, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/171-1.0629.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3349 - acc: 0.5789 - val_loss: 1.0629 - val_acc: 0.7023\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3389 - acc: 0.5791\n",
      "Epoch 00172: val_loss did not improve from 1.06294\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 1.3390 - acc: 0.5791 - val_loss: 1.0670 - val_acc: 0.6979\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3363 - acc: 0.5776\n",
      "Epoch 00173: val_loss improved from 1.06294 to 1.06101, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/173-1.0610.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.3362 - acc: 0.5776 - val_loss: 1.0610 - val_acc: 0.7049\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3307 - acc: 0.5799\n",
      "Epoch 00174: val_loss improved from 1.06101 to 1.05784, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/174-1.0578.hdf5\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.3308 - acc: 0.5799 - val_loss: 1.0578 - val_acc: 0.7011\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3297 - acc: 0.5807\n",
      "Epoch 00175: val_loss did not improve from 1.05784\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.3298 - acc: 0.5807 - val_loss: 1.0584 - val_acc: 0.7021\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3354 - acc: 0.5799\n",
      "Epoch 00176: val_loss improved from 1.05784 to 1.05592, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/176-1.0559.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3355 - acc: 0.5799 - val_loss: 1.0559 - val_acc: 0.7035\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3254 - acc: 0.5836\n",
      "Epoch 00177: val_loss improved from 1.05592 to 1.05581, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/177-1.0558.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3253 - acc: 0.5837 - val_loss: 1.0558 - val_acc: 0.7049\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3317 - acc: 0.5810\n",
      "Epoch 00178: val_loss did not improve from 1.05581\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.3316 - acc: 0.5810 - val_loss: 1.0587 - val_acc: 0.6990\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3224 - acc: 0.5823\n",
      "Epoch 00179: val_loss improved from 1.05581 to 1.04997, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/179-1.0500.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3226 - acc: 0.5823 - val_loss: 1.0500 - val_acc: 0.7053\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3219 - acc: 0.5834\n",
      "Epoch 00180: val_loss did not improve from 1.04997\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.3218 - acc: 0.5835 - val_loss: 1.0558 - val_acc: 0.6995\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3163 - acc: 0.5849\n",
      "Epoch 00181: val_loss improved from 1.04997 to 1.04229, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/181-1.0423.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.3162 - acc: 0.5849 - val_loss: 1.0423 - val_acc: 0.7109\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3212 - acc: 0.5848\n",
      "Epoch 00182: val_loss did not improve from 1.04229\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.3212 - acc: 0.5848 - val_loss: 1.0496 - val_acc: 0.7051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3199 - acc: 0.5847\n",
      "Epoch 00183: val_loss did not improve from 1.04229\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.3199 - acc: 0.5847 - val_loss: 1.0437 - val_acc: 0.7042\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3186 - acc: 0.5861\n",
      "Epoch 00184: val_loss did not improve from 1.04229\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 1.3186 - acc: 0.5860 - val_loss: 1.0465 - val_acc: 0.7060\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3183 - acc: 0.5858\n",
      "Epoch 00185: val_loss did not improve from 1.04229\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.3182 - acc: 0.5857 - val_loss: 1.0446 - val_acc: 0.7072\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3105 - acc: 0.5868\n",
      "Epoch 00186: val_loss improved from 1.04229 to 1.03554, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/186-1.0355.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.3105 - acc: 0.5868 - val_loss: 1.0355 - val_acc: 0.7084\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3188 - acc: 0.5836\n",
      "Epoch 00187: val_loss did not improve from 1.03554\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3188 - acc: 0.5836 - val_loss: 1.0367 - val_acc: 0.7077\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3101 - acc: 0.5889\n",
      "Epoch 00188: val_loss improved from 1.03554 to 1.03502, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/188-1.0350.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.3100 - acc: 0.5889 - val_loss: 1.0350 - val_acc: 0.7093\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3036 - acc: 0.5872\n",
      "Epoch 00189: val_loss improved from 1.03502 to 1.03233, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/189-1.0323.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3036 - acc: 0.5872 - val_loss: 1.0323 - val_acc: 0.7077\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3106 - acc: 0.5906\n",
      "Epoch 00190: val_loss did not improve from 1.03233\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.3106 - acc: 0.5906 - val_loss: 1.0364 - val_acc: 0.7088\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3015 - acc: 0.5893\n",
      "Epoch 00191: val_loss improved from 1.03233 to 1.02752, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/191-1.0275.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.3015 - acc: 0.5894 - val_loss: 1.0275 - val_acc: 0.7121\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3051 - acc: 0.5907\n",
      "Epoch 00192: val_loss improved from 1.02752 to 1.02747, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/192-1.0275.hdf5\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 1.3052 - acc: 0.5907 - val_loss: 1.0275 - val_acc: 0.7091\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3007 - acc: 0.5935\n",
      "Epoch 00193: val_loss improved from 1.02747 to 1.02468, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/193-1.0247.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.3008 - acc: 0.5935 - val_loss: 1.0247 - val_acc: 0.7112\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3039 - acc: 0.5921\n",
      "Epoch 00194: val_loss did not improve from 1.02468\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.3040 - acc: 0.5921 - val_loss: 1.0291 - val_acc: 0.7126\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2961 - acc: 0.5943\n",
      "Epoch 00195: val_loss did not improve from 1.02468\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.2961 - acc: 0.5943 - val_loss: 1.0252 - val_acc: 0.7100\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2973 - acc: 0.5919\n",
      "Epoch 00196: val_loss improved from 1.02468 to 1.02212, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/196-1.0221.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2972 - acc: 0.5920 - val_loss: 1.0221 - val_acc: 0.7107\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2961 - acc: 0.5921\n",
      "Epoch 00197: val_loss improved from 1.02212 to 1.02011, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/197-1.0201.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2960 - acc: 0.5921 - val_loss: 1.0201 - val_acc: 0.7147\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2900 - acc: 0.5948\n",
      "Epoch 00198: val_loss improved from 1.02011 to 1.01895, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/198-1.0189.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2899 - acc: 0.5948 - val_loss: 1.0189 - val_acc: 0.7130\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2993 - acc: 0.5930\n",
      "Epoch 00199: val_loss did not improve from 1.01895\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2992 - acc: 0.5930 - val_loss: 1.0234 - val_acc: 0.7095\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2926 - acc: 0.6002\n",
      "Epoch 00200: val_loss did not improve from 1.01895\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2925 - acc: 0.6003 - val_loss: 1.0200 - val_acc: 0.7112\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2928 - acc: 0.5910\n",
      "Epoch 00201: val_loss did not improve from 1.01895\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.2929 - acc: 0.5910 - val_loss: 1.0197 - val_acc: 0.7133\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2867 - acc: 0.5960\n",
      "Epoch 00202: val_loss improved from 1.01895 to 1.01747, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/202-1.0175.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2866 - acc: 0.5961 - val_loss: 1.0175 - val_acc: 0.7142\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2942 - acc: 0.5920\n",
      "Epoch 00203: val_loss improved from 1.01747 to 1.01434, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/203-1.0143.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2943 - acc: 0.5919 - val_loss: 1.0143 - val_acc: 0.7133\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2874 - acc: 0.5972\n",
      "Epoch 00204: val_loss improved from 1.01434 to 1.01047, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/204-1.0105.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2873 - acc: 0.5972 - val_loss: 1.0105 - val_acc: 0.7186\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2858 - acc: 0.5973\n",
      "Epoch 00205: val_loss did not improve from 1.01047\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2857 - acc: 0.5973 - val_loss: 1.0139 - val_acc: 0.7149\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2951 - acc: 0.5958\n",
      "Epoch 00206: val_loss did not improve from 1.01047\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2951 - acc: 0.5958 - val_loss: 1.0150 - val_acc: 0.7172\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2888 - acc: 0.5961\n",
      "Epoch 00207: val_loss improved from 1.01047 to 1.00908, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/207-1.0091.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2887 - acc: 0.5961 - val_loss: 1.0091 - val_acc: 0.7147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2803 - acc: 0.5996\n",
      "Epoch 00208: val_loss improved from 1.00908 to 1.00529, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/208-1.0053.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.2803 - acc: 0.5995 - val_loss: 1.0053 - val_acc: 0.7142\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2851 - acc: 0.5987\n",
      "Epoch 00209: val_loss did not improve from 1.00529\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.2852 - acc: 0.5987 - val_loss: 1.0059 - val_acc: 0.7154\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2820 - acc: 0.5981\n",
      "Epoch 00210: val_loss did not improve from 1.00529\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2820 - acc: 0.5982 - val_loss: 1.0073 - val_acc: 0.7177\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2760 - acc: 0.6012\n",
      "Epoch 00211: val_loss did not improve from 1.00529\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2761 - acc: 0.6011 - val_loss: 1.0067 - val_acc: 0.7179\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2778 - acc: 0.6021\n",
      "Epoch 00212: val_loss improved from 1.00529 to 1.00359, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/212-1.0036.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2778 - acc: 0.6021 - val_loss: 1.0036 - val_acc: 0.7163\n",
      "Epoch 213/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2871 - acc: 0.5958\n",
      "Epoch 00213: val_loss did not improve from 1.00359\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2872 - acc: 0.5958 - val_loss: 1.0059 - val_acc: 0.7156\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2790 - acc: 0.6000\n",
      "Epoch 00214: val_loss improved from 1.00359 to 1.00169, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/214-1.0017.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.2789 - acc: 0.6000 - val_loss: 1.0017 - val_acc: 0.7193\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2738 - acc: 0.6024\n",
      "Epoch 00215: val_loss improved from 1.00169 to 0.99789, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/215-0.9979.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2738 - acc: 0.6024 - val_loss: 0.9979 - val_acc: 0.7191\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2758 - acc: 0.6011\n",
      "Epoch 00216: val_loss did not improve from 0.99789\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2758 - acc: 0.6011 - val_loss: 1.0021 - val_acc: 0.7200\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2772 - acc: 0.5992\n",
      "Epoch 00217: val_loss improved from 0.99789 to 0.99671, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/217-0.9967.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.2772 - acc: 0.5992 - val_loss: 0.9967 - val_acc: 0.7195\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2682 - acc: 0.6023\n",
      "Epoch 00218: val_loss did not improve from 0.99671\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2682 - acc: 0.6023 - val_loss: 0.9980 - val_acc: 0.7205\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2753 - acc: 0.6030\n",
      "Epoch 00219: val_loss improved from 0.99671 to 0.99636, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/219-0.9964.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.2755 - acc: 0.6030 - val_loss: 0.9964 - val_acc: 0.7214\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2715 - acc: 0.6015\n",
      "Epoch 00220: val_loss improved from 0.99636 to 0.98774, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/220-0.9877.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2715 - acc: 0.6015 - val_loss: 0.9877 - val_acc: 0.7242\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2679 - acc: 0.6042\n",
      "Epoch 00221: val_loss did not improve from 0.98774\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2679 - acc: 0.6042 - val_loss: 0.9989 - val_acc: 0.7167\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2715 - acc: 0.6039\n",
      "Epoch 00222: val_loss did not improve from 0.98774\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2717 - acc: 0.6039 - val_loss: 0.9891 - val_acc: 0.7219\n",
      "Epoch 223/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2706 - acc: 0.6008\n",
      "Epoch 00223: val_loss did not improve from 0.98774\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2705 - acc: 0.6009 - val_loss: 0.9899 - val_acc: 0.7247\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2678 - acc: 0.6030\n",
      "Epoch 00224: val_loss improved from 0.98774 to 0.98459, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/224-0.9846.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.2677 - acc: 0.6030 - val_loss: 0.9846 - val_acc: 0.7242\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2655 - acc: 0.6037\n",
      "Epoch 00225: val_loss did not improve from 0.98459\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2655 - acc: 0.6037 - val_loss: 0.9869 - val_acc: 0.7230\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2699 - acc: 0.6026\n",
      "Epoch 00226: val_loss did not improve from 0.98459\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.2698 - acc: 0.6026 - val_loss: 0.9899 - val_acc: 0.7237\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2646 - acc: 0.6029\n",
      "Epoch 00227: val_loss did not improve from 0.98459\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2648 - acc: 0.6029 - val_loss: 0.9866 - val_acc: 0.7254\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2654 - acc: 0.6043\n",
      "Epoch 00228: val_loss improved from 0.98459 to 0.98213, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/228-0.9821.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2654 - acc: 0.6043 - val_loss: 0.9821 - val_acc: 0.7230\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2650 - acc: 0.6039\n",
      "Epoch 00229: val_loss did not improve from 0.98213\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2650 - acc: 0.6039 - val_loss: 0.9822 - val_acc: 0.7233\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2652 - acc: 0.6020\n",
      "Epoch 00230: val_loss improved from 0.98213 to 0.97800, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/230-0.9780.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2653 - acc: 0.6019 - val_loss: 0.9780 - val_acc: 0.7275\n",
      "Epoch 231/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2613 - acc: 0.6052\n",
      "Epoch 00231: val_loss did not improve from 0.97800\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2612 - acc: 0.6052 - val_loss: 0.9825 - val_acc: 0.7235\n",
      "Epoch 232/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2613 - acc: 0.6036\n",
      "Epoch 00232: val_loss did not improve from 0.97800\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2613 - acc: 0.6036 - val_loss: 0.9804 - val_acc: 0.7258\n",
      "Epoch 233/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2618 - acc: 0.6035\n",
      "Epoch 00233: val_loss did not improve from 0.97800\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2619 - acc: 0.6035 - val_loss: 0.9822 - val_acc: 0.7233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2633 - acc: 0.6044\n",
      "Epoch 00234: val_loss did not improve from 0.97800\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2632 - acc: 0.6045 - val_loss: 0.9789 - val_acc: 0.7235\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2582 - acc: 0.6048\n",
      "Epoch 00235: val_loss did not improve from 0.97800\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2582 - acc: 0.6048 - val_loss: 0.9793 - val_acc: 0.7235\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2521 - acc: 0.6066\n",
      "Epoch 00236: val_loss improved from 0.97800 to 0.97453, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/236-0.9745.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2521 - acc: 0.6066 - val_loss: 0.9745 - val_acc: 0.7270\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2539 - acc: 0.6069\n",
      "Epoch 00237: val_loss did not improve from 0.97453\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2539 - acc: 0.6069 - val_loss: 0.9756 - val_acc: 0.7265\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2607 - acc: 0.6064\n",
      "Epoch 00238: val_loss did not improve from 0.97453\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2605 - acc: 0.6065 - val_loss: 0.9799 - val_acc: 0.7242\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2583 - acc: 0.6080\n",
      "Epoch 00239: val_loss improved from 0.97453 to 0.97063, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/239-0.9706.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2583 - acc: 0.6080 - val_loss: 0.9706 - val_acc: 0.7270\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2485 - acc: 0.6094\n",
      "Epoch 00240: val_loss did not improve from 0.97063\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.2485 - acc: 0.6093 - val_loss: 0.9772 - val_acc: 0.7275\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2513 - acc: 0.6088\n",
      "Epoch 00241: val_loss improved from 0.97063 to 0.96852, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/241-0.9685.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2513 - acc: 0.6088 - val_loss: 0.9685 - val_acc: 0.7298\n",
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2516 - acc: 0.6086\n",
      "Epoch 00242: val_loss improved from 0.96852 to 0.96726, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/242-0.9673.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2516 - acc: 0.6086 - val_loss: 0.9673 - val_acc: 0.7300\n",
      "Epoch 243/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2593 - acc: 0.6062\n",
      "Epoch 00243: val_loss improved from 0.96726 to 0.96641, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/243-0.9664.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2593 - acc: 0.6062 - val_loss: 0.9664 - val_acc: 0.7303\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2502 - acc: 0.6082\n",
      "Epoch 00244: val_loss did not improve from 0.96641\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2502 - acc: 0.6082 - val_loss: 0.9674 - val_acc: 0.7307\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2492 - acc: 0.6094\n",
      "Epoch 00245: val_loss improved from 0.96641 to 0.96349, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/245-0.9635.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2492 - acc: 0.6094 - val_loss: 0.9635 - val_acc: 0.7331\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2508 - acc: 0.6117\n",
      "Epoch 00246: val_loss did not improve from 0.96349\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2507 - acc: 0.6117 - val_loss: 0.9642 - val_acc: 0.7310\n",
      "Epoch 247/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2451 - acc: 0.6116\n",
      "Epoch 00247: val_loss did not improve from 0.96349\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2451 - acc: 0.6115 - val_loss: 0.9662 - val_acc: 0.7298\n",
      "Epoch 248/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2483 - acc: 0.6100\n",
      "Epoch 00248: val_loss did not improve from 0.96349\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2484 - acc: 0.6100 - val_loss: 0.9647 - val_acc: 0.7303\n",
      "Epoch 249/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2412 - acc: 0.6142\n",
      "Epoch 00249: val_loss did not improve from 0.96349\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2412 - acc: 0.6142 - val_loss: 0.9635 - val_acc: 0.7317\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2435 - acc: 0.6086\n",
      "Epoch 00250: val_loss improved from 0.96349 to 0.96113, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/250-0.9611.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2436 - acc: 0.6086 - val_loss: 0.9611 - val_acc: 0.7328\n",
      "Epoch 251/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2471 - acc: 0.6088\n",
      "Epoch 00251: val_loss did not improve from 0.96113\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2471 - acc: 0.6087 - val_loss: 0.9632 - val_acc: 0.7263\n",
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2450 - acc: 0.6133\n",
      "Epoch 00252: val_loss did not improve from 0.96113\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2451 - acc: 0.6133 - val_loss: 0.9660 - val_acc: 0.7317\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2438 - acc: 0.6121\n",
      "Epoch 00253: val_loss did not improve from 0.96113\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2439 - acc: 0.6121 - val_loss: 0.9631 - val_acc: 0.7275\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2449 - acc: 0.6097\n",
      "Epoch 00254: val_loss did not improve from 0.96113\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2449 - acc: 0.6097 - val_loss: 0.9706 - val_acc: 0.7303\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2393 - acc: 0.6130\n",
      "Epoch 00255: val_loss improved from 0.96113 to 0.96054, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/255-0.9605.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2394 - acc: 0.6129 - val_loss: 0.9605 - val_acc: 0.7317\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2419 - acc: 0.6126\n",
      "Epoch 00256: val_loss did not improve from 0.96054\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2419 - acc: 0.6126 - val_loss: 0.9646 - val_acc: 0.7310\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2445 - acc: 0.6102\n",
      "Epoch 00257: val_loss improved from 0.96054 to 0.95968, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/257-0.9597.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2444 - acc: 0.6102 - val_loss: 0.9597 - val_acc: 0.7324\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2435 - acc: 0.6121\n",
      "Epoch 00258: val_loss improved from 0.95968 to 0.95729, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/258-0.9573.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2434 - acc: 0.6121 - val_loss: 0.9573 - val_acc: 0.7305\n",
      "Epoch 259/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2403 - acc: 0.6125\n",
      "Epoch 00259: val_loss improved from 0.95729 to 0.95424, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/259-0.9542.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2402 - acc: 0.6125 - val_loss: 0.9542 - val_acc: 0.7314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 260/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2352 - acc: 0.6141\n",
      "Epoch 00260: val_loss improved from 0.95424 to 0.95163, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/260-0.9516.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.2353 - acc: 0.6141 - val_loss: 0.9516 - val_acc: 0.7333\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2348 - acc: 0.6148\n",
      "Epoch 00261: val_loss did not improve from 0.95163\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2347 - acc: 0.6148 - val_loss: 0.9526 - val_acc: 0.7340\n",
      "Epoch 262/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2389 - acc: 0.6132\n",
      "Epoch 00262: val_loss did not improve from 0.95163\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2390 - acc: 0.6132 - val_loss: 0.9526 - val_acc: 0.7340\n",
      "Epoch 263/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2379 - acc: 0.6137\n",
      "Epoch 00263: val_loss did not improve from 0.95163\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2377 - acc: 0.6138 - val_loss: 0.9631 - val_acc: 0.7310\n",
      "Epoch 264/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2352 - acc: 0.6145\n",
      "Epoch 00264: val_loss did not improve from 0.95163\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2354 - acc: 0.6145 - val_loss: 0.9522 - val_acc: 0.7356\n",
      "Epoch 265/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2310 - acc: 0.6174\n",
      "Epoch 00265: val_loss improved from 0.95163 to 0.94705, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/265-0.9471.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2310 - acc: 0.6174 - val_loss: 0.9471 - val_acc: 0.7314\n",
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2362 - acc: 0.6152\n",
      "Epoch 00266: val_loss did not improve from 0.94705\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2361 - acc: 0.6152 - val_loss: 0.9527 - val_acc: 0.7349\n",
      "Epoch 267/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2252 - acc: 0.6194\n",
      "Epoch 00267: val_loss did not improve from 0.94705\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2253 - acc: 0.6194 - val_loss: 0.9524 - val_acc: 0.7365\n",
      "Epoch 268/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2370 - acc: 0.6159\n",
      "Epoch 00268: val_loss improved from 0.94705 to 0.94683, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/268-0.9468.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2370 - acc: 0.6159 - val_loss: 0.9468 - val_acc: 0.7333\n",
      "Epoch 269/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2347 - acc: 0.6165\n",
      "Epoch 00269: val_loss did not improve from 0.94683\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2348 - acc: 0.6165 - val_loss: 0.9514 - val_acc: 0.7331\n",
      "Epoch 270/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2335 - acc: 0.6148\n",
      "Epoch 00270: val_loss did not improve from 0.94683\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2335 - acc: 0.6148 - val_loss: 0.9496 - val_acc: 0.7317\n",
      "Epoch 271/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2326 - acc: 0.6164\n",
      "Epoch 00271: val_loss improved from 0.94683 to 0.94346, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/271-0.9435.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2323 - acc: 0.6165 - val_loss: 0.9435 - val_acc: 0.7345\n",
      "Epoch 272/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2331 - acc: 0.6132\n",
      "Epoch 00272: val_loss did not improve from 0.94346\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2334 - acc: 0.6132 - val_loss: 0.9492 - val_acc: 0.7345\n",
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2264 - acc: 0.6171\n",
      "Epoch 00273: val_loss improved from 0.94346 to 0.94321, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/273-0.9432.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2264 - acc: 0.6171 - val_loss: 0.9432 - val_acc: 0.7365\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2283 - acc: 0.6160\n",
      "Epoch 00274: val_loss improved from 0.94321 to 0.93987, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/274-0.9399.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2283 - acc: 0.6160 - val_loss: 0.9399 - val_acc: 0.7375\n",
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2278 - acc: 0.6159\n",
      "Epoch 00275: val_loss did not improve from 0.93987\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2279 - acc: 0.6159 - val_loss: 0.9422 - val_acc: 0.7349\n",
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2260 - acc: 0.6171\n",
      "Epoch 00276: val_loss improved from 0.93987 to 0.93804, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/276-0.9380.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2262 - acc: 0.6170 - val_loss: 0.9380 - val_acc: 0.7379\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2254 - acc: 0.6197\n",
      "Epoch 00277: val_loss did not improve from 0.93804\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2254 - acc: 0.6197 - val_loss: 0.9568 - val_acc: 0.7303\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2236 - acc: 0.6196\n",
      "Epoch 00278: val_loss improved from 0.93804 to 0.93729, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/278-0.9373.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2237 - acc: 0.6195 - val_loss: 0.9373 - val_acc: 0.7410\n",
      "Epoch 279/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2389 - acc: 0.6154\n",
      "Epoch 00279: val_loss did not improve from 0.93729\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2388 - acc: 0.6154 - val_loss: 0.9437 - val_acc: 0.7372\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2243 - acc: 0.6197\n",
      "Epoch 00280: val_loss did not improve from 0.93729\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2243 - acc: 0.6197 - val_loss: 0.9421 - val_acc: 0.7384\n",
      "Epoch 281/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2192 - acc: 0.6198\n",
      "Epoch 00281: val_loss did not improve from 0.93729\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2192 - acc: 0.6198 - val_loss: 0.9431 - val_acc: 0.7352\n",
      "Epoch 282/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2212 - acc: 0.6193\n",
      "Epoch 00282: val_loss did not improve from 0.93729\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2211 - acc: 0.6193 - val_loss: 0.9374 - val_acc: 0.7368\n",
      "Epoch 283/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2254 - acc: 0.6192\n",
      "Epoch 00283: val_loss did not improve from 0.93729\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2256 - acc: 0.6192 - val_loss: 0.9457 - val_acc: 0.7340\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2203 - acc: 0.6182\n",
      "Epoch 00284: val_loss did not improve from 0.93729\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2204 - acc: 0.6182 - val_loss: 0.9445 - val_acc: 0.7347\n",
      "Epoch 285/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2226 - acc: 0.6205\n",
      "Epoch 00285: val_loss did not improve from 0.93729\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2225 - acc: 0.6205 - val_loss: 0.9481 - val_acc: 0.7347\n",
      "Epoch 286/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2194 - acc: 0.6198\n",
      "Epoch 00286: val_loss did not improve from 0.93729\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2196 - acc: 0.6198 - val_loss: 0.9401 - val_acc: 0.7391\n",
      "Epoch 287/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2310 - acc: 0.6176\n",
      "Epoch 00287: val_loss did not improve from 0.93729\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2311 - acc: 0.6176 - val_loss: 0.9442 - val_acc: 0.7310\n",
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2197 - acc: 0.6214\n",
      "Epoch 00288: val_loss improved from 0.93729 to 0.93154, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/288-0.9315.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2197 - acc: 0.6213 - val_loss: 0.9315 - val_acc: 0.7375\n",
      "Epoch 289/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2253 - acc: 0.6208\n",
      "Epoch 00289: val_loss did not improve from 0.93154\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.2254 - acc: 0.6207 - val_loss: 0.9369 - val_acc: 0.7389\n",
      "Epoch 290/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2248 - acc: 0.6192\n",
      "Epoch 00290: val_loss did not improve from 0.93154\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2248 - acc: 0.6192 - val_loss: 0.9386 - val_acc: 0.7391\n",
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2200 - acc: 0.6208\n",
      "Epoch 00291: val_loss improved from 0.93154 to 0.93039, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/291-0.9304.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2199 - acc: 0.6209 - val_loss: 0.9304 - val_acc: 0.7396\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2165 - acc: 0.6203\n",
      "Epoch 00292: val_loss improved from 0.93039 to 0.92913, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/292-0.9291.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2166 - acc: 0.6203 - val_loss: 0.9291 - val_acc: 0.7403\n",
      "Epoch 293/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2192 - acc: 0.6180\n",
      "Epoch 00293: val_loss did not improve from 0.92913\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2192 - acc: 0.6179 - val_loss: 0.9311 - val_acc: 0.7377\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2134 - acc: 0.6220\n",
      "Epoch 00294: val_loss improved from 0.92913 to 0.92840, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/294-0.9284.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2135 - acc: 0.6220 - val_loss: 0.9284 - val_acc: 0.7393\n",
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2210 - acc: 0.6184\n",
      "Epoch 00295: val_loss did not improve from 0.92840\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2212 - acc: 0.6184 - val_loss: 0.9377 - val_acc: 0.7319\n",
      "Epoch 296/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2167 - acc: 0.6195\n",
      "Epoch 00296: val_loss did not improve from 0.92840\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2162 - acc: 0.6198 - val_loss: 0.9301 - val_acc: 0.7400\n",
      "Epoch 297/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2223 - acc: 0.6185\n",
      "Epoch 00297: val_loss did not improve from 0.92840\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2223 - acc: 0.6185 - val_loss: 0.9308 - val_acc: 0.7405\n",
      "Epoch 298/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2181 - acc: 0.6198\n",
      "Epoch 00298: val_loss did not improve from 0.92840\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2181 - acc: 0.6198 - val_loss: 0.9298 - val_acc: 0.7417\n",
      "Epoch 299/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2164 - acc: 0.6218\n",
      "Epoch 00299: val_loss did not improve from 0.92840\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.2163 - acc: 0.6218 - val_loss: 0.9290 - val_acc: 0.7403\n",
      "Epoch 300/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2176 - acc: 0.6202\n",
      "Epoch 00300: val_loss did not improve from 0.92840\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2177 - acc: 0.6201 - val_loss: 0.9370 - val_acc: 0.7358\n",
      "Epoch 301/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2141 - acc: 0.6199\n",
      "Epoch 00301: val_loss did not improve from 0.92840\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.2141 - acc: 0.6199 - val_loss: 0.9310 - val_acc: 0.7370\n",
      "Epoch 302/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2142 - acc: 0.6225\n",
      "Epoch 00302: val_loss improved from 0.92840 to 0.92592, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/302-0.9259.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2142 - acc: 0.6226 - val_loss: 0.9259 - val_acc: 0.7421\n",
      "Epoch 303/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2125 - acc: 0.6231\n",
      "Epoch 00303: val_loss improved from 0.92592 to 0.92476, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/303-0.9248.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2131 - acc: 0.6229 - val_loss: 0.9248 - val_acc: 0.7379\n",
      "Epoch 304/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2161 - acc: 0.6237\n",
      "Epoch 00304: val_loss did not improve from 0.92476\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2162 - acc: 0.6237 - val_loss: 0.9294 - val_acc: 0.7372\n",
      "Epoch 305/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2084 - acc: 0.6267\n",
      "Epoch 00305: val_loss did not improve from 0.92476\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2082 - acc: 0.6267 - val_loss: 0.9258 - val_acc: 0.7410\n",
      "Epoch 306/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2064 - acc: 0.6235\n",
      "Epoch 00306: val_loss did not improve from 0.92476\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2061 - acc: 0.6236 - val_loss: 0.9282 - val_acc: 0.7391\n",
      "Epoch 307/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2056 - acc: 0.6249\n",
      "Epoch 00307: val_loss did not improve from 0.92476\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2056 - acc: 0.6249 - val_loss: 0.9275 - val_acc: 0.7396\n",
      "Epoch 308/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2147 - acc: 0.6218\n",
      "Epoch 00308: val_loss did not improve from 0.92476\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.2149 - acc: 0.6218 - val_loss: 0.9253 - val_acc: 0.7405\n",
      "Epoch 309/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2131 - acc: 0.6230\n",
      "Epoch 00309: val_loss improved from 0.92476 to 0.92449, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/309-0.9245.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2133 - acc: 0.6230 - val_loss: 0.9245 - val_acc: 0.7442\n",
      "Epoch 310/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2149 - acc: 0.6212\n",
      "Epoch 00310: val_loss did not improve from 0.92449\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2149 - acc: 0.6212 - val_loss: 0.9271 - val_acc: 0.7410\n",
      "Epoch 311/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2026 - acc: 0.6243\n",
      "Epoch 00311: val_loss improved from 0.92449 to 0.91893, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/311-0.9189.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2026 - acc: 0.6243 - val_loss: 0.9189 - val_acc: 0.7431\n",
      "Epoch 312/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2101 - acc: 0.6243\n",
      "Epoch 00312: val_loss did not improve from 0.91893\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2102 - acc: 0.6243 - val_loss: 0.9297 - val_acc: 0.7417\n",
      "Epoch 313/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2069 - acc: 0.6242\n",
      "Epoch 00313: val_loss did not improve from 0.91893\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2069 - acc: 0.6242 - val_loss: 0.9213 - val_acc: 0.7421\n",
      "Epoch 314/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2060 - acc: 0.6246\n",
      "Epoch 00314: val_loss did not improve from 0.91893\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2061 - acc: 0.6245 - val_loss: 0.9191 - val_acc: 0.7428\n",
      "Epoch 315/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2069 - acc: 0.6230\n",
      "Epoch 00315: val_loss did not improve from 0.91893\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2069 - acc: 0.6230 - val_loss: 0.9213 - val_acc: 0.7417\n",
      "Epoch 316/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2165 - acc: 0.6210\n",
      "Epoch 00316: val_loss did not improve from 0.91893\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2164 - acc: 0.6210 - val_loss: 0.9214 - val_acc: 0.7414\n",
      "Epoch 317/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2073 - acc: 0.6234\n",
      "Epoch 00317: val_loss did not improve from 0.91893\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2073 - acc: 0.6234 - val_loss: 0.9194 - val_acc: 0.7452\n",
      "Epoch 318/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2026 - acc: 0.6240\n",
      "Epoch 00318: val_loss improved from 0.91893 to 0.91611, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/318-0.9161.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2025 - acc: 0.6240 - val_loss: 0.9161 - val_acc: 0.7426\n",
      "Epoch 319/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2020 - acc: 0.6241\n",
      "Epoch 00319: val_loss improved from 0.91611 to 0.91379, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/319-0.9138.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2020 - acc: 0.6241 - val_loss: 0.9138 - val_acc: 0.7400\n",
      "Epoch 320/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1983 - acc: 0.6271\n",
      "Epoch 00320: val_loss did not improve from 0.91379\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1984 - acc: 0.6271 - val_loss: 0.9179 - val_acc: 0.7426\n",
      "Epoch 321/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2035 - acc: 0.6249\n",
      "Epoch 00321: val_loss did not improve from 0.91379\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2034 - acc: 0.6250 - val_loss: 0.9171 - val_acc: 0.7438\n",
      "Epoch 322/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2039 - acc: 0.6232\n",
      "Epoch 00322: val_loss improved from 0.91379 to 0.91358, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/322-0.9136.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2038 - acc: 0.6232 - val_loss: 0.9136 - val_acc: 0.7414\n",
      "Epoch 323/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2095 - acc: 0.6233\n",
      "Epoch 00323: val_loss did not improve from 0.91358\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2095 - acc: 0.6233 - val_loss: 0.9217 - val_acc: 0.7452\n",
      "Epoch 324/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2035 - acc: 0.6260\n",
      "Epoch 00324: val_loss did not improve from 0.91358\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2035 - acc: 0.6260 - val_loss: 0.9218 - val_acc: 0.7377\n",
      "Epoch 325/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2082 - acc: 0.6223\n",
      "Epoch 00325: val_loss did not improve from 0.91358\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2084 - acc: 0.6223 - val_loss: 0.9139 - val_acc: 0.7440\n",
      "Epoch 326/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2094 - acc: 0.6247\n",
      "Epoch 00326: val_loss did not improve from 0.91358\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.2095 - acc: 0.6247 - val_loss: 0.9153 - val_acc: 0.7449\n",
      "Epoch 327/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2090 - acc: 0.6226\n",
      "Epoch 00327: val_loss improved from 0.91358 to 0.91329, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/327-0.9133.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2090 - acc: 0.6226 - val_loss: 0.9133 - val_acc: 0.7424\n",
      "Epoch 328/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1999 - acc: 0.6247\n",
      "Epoch 00328: val_loss improved from 0.91329 to 0.91166, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/328-0.9117.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1999 - acc: 0.6247 - val_loss: 0.9117 - val_acc: 0.7433\n",
      "Epoch 329/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2015 - acc: 0.6259\n",
      "Epoch 00329: val_loss did not improve from 0.91166\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.2015 - acc: 0.6259 - val_loss: 0.9148 - val_acc: 0.7417\n",
      "Epoch 330/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1977 - acc: 0.6290\n",
      "Epoch 00330: val_loss did not improve from 0.91166\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1976 - acc: 0.6290 - val_loss: 0.9126 - val_acc: 0.7431\n",
      "Epoch 331/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1964 - acc: 0.6258\n",
      "Epoch 00331: val_loss improved from 0.91166 to 0.91150, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/331-0.9115.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1965 - acc: 0.6258 - val_loss: 0.9115 - val_acc: 0.7456\n",
      "Epoch 332/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1947 - acc: 0.6277\n",
      "Epoch 00332: val_loss improved from 0.91150 to 0.91051, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/332-0.9105.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1946 - acc: 0.6277 - val_loss: 0.9105 - val_acc: 0.7431\n",
      "Epoch 333/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1984 - acc: 0.6311\n",
      "Epoch 00333: val_loss improved from 0.91051 to 0.91001, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/333-0.9100.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1984 - acc: 0.6311 - val_loss: 0.9100 - val_acc: 0.7463\n",
      "Epoch 334/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.2011 - acc: 0.6249\n",
      "Epoch 00334: val_loss improved from 0.91001 to 0.90996, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/334-0.9100.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.2005 - acc: 0.6252 - val_loss: 0.9100 - val_acc: 0.7449\n",
      "Epoch 335/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2024 - acc: 0.6244\n",
      "Epoch 00335: val_loss did not improve from 0.90996\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.2024 - acc: 0.6244 - val_loss: 0.9136 - val_acc: 0.7435\n",
      "Epoch 336/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1991 - acc: 0.6261\n",
      "Epoch 00336: val_loss did not improve from 0.90996\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1990 - acc: 0.6262 - val_loss: 0.9133 - val_acc: 0.7438\n",
      "Epoch 337/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1923 - acc: 0.6310\n",
      "Epoch 00337: val_loss improved from 0.90996 to 0.90800, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/337-0.9080.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1924 - acc: 0.6309 - val_loss: 0.9080 - val_acc: 0.7449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 338/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1939 - acc: 0.6279\n",
      "Epoch 00338: val_loss did not improve from 0.90800\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1940 - acc: 0.6279 - val_loss: 0.9126 - val_acc: 0.7412\n",
      "Epoch 339/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1936 - acc: 0.6268\n",
      "Epoch 00339: val_loss improved from 0.90800 to 0.90710, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/339-0.9071.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1935 - acc: 0.6269 - val_loss: 0.9071 - val_acc: 0.7442\n",
      "Epoch 340/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1963 - acc: 0.6260\n",
      "Epoch 00340: val_loss did not improve from 0.90710\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1963 - acc: 0.6260 - val_loss: 0.9083 - val_acc: 0.7421\n",
      "Epoch 341/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1938 - acc: 0.6281\n",
      "Epoch 00341: val_loss did not improve from 0.90710\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1937 - acc: 0.6281 - val_loss: 0.9134 - val_acc: 0.7445\n",
      "Epoch 342/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1928 - acc: 0.6288\n",
      "Epoch 00342: val_loss improved from 0.90710 to 0.90458, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/342-0.9046.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1927 - acc: 0.6288 - val_loss: 0.9046 - val_acc: 0.7468\n",
      "Epoch 343/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1904 - acc: 0.6290\n",
      "Epoch 00343: val_loss improved from 0.90458 to 0.90327, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/343-0.9033.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1903 - acc: 0.6290 - val_loss: 0.9033 - val_acc: 0.7440\n",
      "Epoch 344/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1984 - acc: 0.6307\n",
      "Epoch 00344: val_loss did not improve from 0.90327\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1983 - acc: 0.6307 - val_loss: 0.9074 - val_acc: 0.7475\n",
      "Epoch 345/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1970 - acc: 0.6264\n",
      "Epoch 00345: val_loss did not improve from 0.90327\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1970 - acc: 0.6264 - val_loss: 0.9063 - val_acc: 0.7428\n",
      "Epoch 346/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1970 - acc: 0.6265\n",
      "Epoch 00346: val_loss did not improve from 0.90327\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1971 - acc: 0.6265 - val_loss: 0.9090 - val_acc: 0.7454\n",
      "Epoch 347/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1895 - acc: 0.6301\n",
      "Epoch 00347: val_loss did not improve from 0.90327\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1894 - acc: 0.6300 - val_loss: 0.9039 - val_acc: 0.7473\n",
      "Epoch 348/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1903 - acc: 0.6296\n",
      "Epoch 00348: val_loss did not improve from 0.90327\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1903 - acc: 0.6296 - val_loss: 0.9045 - val_acc: 0.7445\n",
      "Epoch 349/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1876 - acc: 0.6332\n",
      "Epoch 00349: val_loss improved from 0.90327 to 0.90158, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/349-0.9016.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1877 - acc: 0.6331 - val_loss: 0.9016 - val_acc: 0.7463\n",
      "Epoch 350/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1895 - acc: 0.6304\n",
      "Epoch 00350: val_loss improved from 0.90158 to 0.90098, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/350-0.9010.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1895 - acc: 0.6304 - val_loss: 0.9010 - val_acc: 0.7489\n",
      "Epoch 351/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1944 - acc: 0.6298\n",
      "Epoch 00351: val_loss improved from 0.90098 to 0.90069, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/351-0.9007.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1944 - acc: 0.6298 - val_loss: 0.9007 - val_acc: 0.7477\n",
      "Epoch 352/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1905 - acc: 0.6292\n",
      "Epoch 00352: val_loss did not improve from 0.90069\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1904 - acc: 0.6293 - val_loss: 0.9033 - val_acc: 0.7452\n",
      "Epoch 353/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1894 - acc: 0.6303\n",
      "Epoch 00353: val_loss did not improve from 0.90069\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1894 - acc: 0.6303 - val_loss: 0.9009 - val_acc: 0.7473\n",
      "Epoch 354/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1892 - acc: 0.6303\n",
      "Epoch 00354: val_loss did not improve from 0.90069\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1892 - acc: 0.6303 - val_loss: 0.9010 - val_acc: 0.7466\n",
      "Epoch 355/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1916 - acc: 0.6293\n",
      "Epoch 00355: val_loss did not improve from 0.90069\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1918 - acc: 0.6293 - val_loss: 0.9013 - val_acc: 0.7463\n",
      "Epoch 356/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1931 - acc: 0.6288\n",
      "Epoch 00356: val_loss did not improve from 0.90069\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1930 - acc: 0.6289 - val_loss: 0.9060 - val_acc: 0.7452\n",
      "Epoch 357/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1972 - acc: 0.6287\n",
      "Epoch 00357: val_loss did not improve from 0.90069\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1972 - acc: 0.6287 - val_loss: 0.9045 - val_acc: 0.7442\n",
      "Epoch 358/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1911 - acc: 0.6283\n",
      "Epoch 00358: val_loss improved from 0.90069 to 0.89997, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/358-0.9000.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1910 - acc: 0.6283 - val_loss: 0.9000 - val_acc: 0.7461\n",
      "Epoch 359/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1944 - acc: 0.6285\n",
      "Epoch 00359: val_loss improved from 0.89997 to 0.89646, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/359-0.8965.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1944 - acc: 0.6285 - val_loss: 0.8965 - val_acc: 0.7503\n",
      "Epoch 360/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1961 - acc: 0.6299\n",
      "Epoch 00360: val_loss improved from 0.89646 to 0.89549, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/360-0.8955.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1961 - acc: 0.6298 - val_loss: 0.8955 - val_acc: 0.7475\n",
      "Epoch 361/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1885 - acc: 0.6322\n",
      "Epoch 00361: val_loss did not improve from 0.89549\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1885 - acc: 0.6322 - val_loss: 0.9017 - val_acc: 0.7405\n",
      "Epoch 362/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1922 - acc: 0.6297\n",
      "Epoch 00362: val_loss did not improve from 0.89549\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1921 - acc: 0.6297 - val_loss: 0.8973 - val_acc: 0.7452\n",
      "Epoch 363/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1898 - acc: 0.6301\n",
      "Epoch 00363: val_loss did not improve from 0.89549\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1898 - acc: 0.6301 - val_loss: 0.9040 - val_acc: 0.7475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 364/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1878 - acc: 0.6300\n",
      "Epoch 00364: val_loss did not improve from 0.89549\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1877 - acc: 0.6300 - val_loss: 0.9025 - val_acc: 0.7466\n",
      "Epoch 365/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1860 - acc: 0.6324\n",
      "Epoch 00365: val_loss did not improve from 0.89549\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1862 - acc: 0.6323 - val_loss: 0.9035 - val_acc: 0.7447\n",
      "Epoch 366/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1894 - acc: 0.6301\n",
      "Epoch 00366: val_loss did not improve from 0.89549\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1894 - acc: 0.6301 - val_loss: 0.8963 - val_acc: 0.7461\n",
      "Epoch 367/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1907 - acc: 0.6310\n",
      "Epoch 00367: val_loss improved from 0.89549 to 0.89346, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/367-0.8935.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1908 - acc: 0.6309 - val_loss: 0.8935 - val_acc: 0.7473\n",
      "Epoch 368/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1822 - acc: 0.6324\n",
      "Epoch 00368: val_loss did not improve from 0.89346\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1825 - acc: 0.6324 - val_loss: 0.9003 - val_acc: 0.7435\n",
      "Epoch 369/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1874 - acc: 0.6319\n",
      "Epoch 00369: val_loss did not improve from 0.89346\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1873 - acc: 0.6319 - val_loss: 0.8935 - val_acc: 0.7473\n",
      "Epoch 370/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1922 - acc: 0.6286\n",
      "Epoch 00370: val_loss did not improve from 0.89346\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1921 - acc: 0.6287 - val_loss: 0.8995 - val_acc: 0.7452\n",
      "Epoch 371/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1913 - acc: 0.6302\n",
      "Epoch 00371: val_loss improved from 0.89346 to 0.89295, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/371-0.8930.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1912 - acc: 0.6302 - val_loss: 0.8930 - val_acc: 0.7496\n",
      "Epoch 372/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1827 - acc: 0.6337\n",
      "Epoch 00372: val_loss did not improve from 0.89295\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1829 - acc: 0.6336 - val_loss: 0.8958 - val_acc: 0.7489\n",
      "Epoch 373/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1882 - acc: 0.6330\n",
      "Epoch 00373: val_loss did not improve from 0.89295\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1881 - acc: 0.6330 - val_loss: 0.8992 - val_acc: 0.7482\n",
      "Epoch 374/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1828 - acc: 0.6301\n",
      "Epoch 00374: val_loss improved from 0.89295 to 0.89291, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/374-0.8929.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1828 - acc: 0.6301 - val_loss: 0.8929 - val_acc: 0.7524\n",
      "Epoch 375/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1830 - acc: 0.6318\n",
      "Epoch 00375: val_loss did not improve from 0.89291\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1829 - acc: 0.6318 - val_loss: 0.8956 - val_acc: 0.7456\n",
      "Epoch 376/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1821 - acc: 0.6326\n",
      "Epoch 00376: val_loss did not improve from 0.89291\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1822 - acc: 0.6326 - val_loss: 0.8945 - val_acc: 0.7487\n",
      "Epoch 377/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1891 - acc: 0.6312\n",
      "Epoch 00377: val_loss improved from 0.89291 to 0.89176, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/377-0.8918.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1891 - acc: 0.6312 - val_loss: 0.8918 - val_acc: 0.7501\n",
      "Epoch 378/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1821 - acc: 0.6316\n",
      "Epoch 00378: val_loss did not improve from 0.89176\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1822 - acc: 0.6316 - val_loss: 0.9003 - val_acc: 0.7449\n",
      "Epoch 379/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1769 - acc: 0.6325\n",
      "Epoch 00379: val_loss did not improve from 0.89176\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1769 - acc: 0.6325 - val_loss: 0.8946 - val_acc: 0.7449\n",
      "Epoch 380/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1933 - acc: 0.6299\n",
      "Epoch 00380: val_loss did not improve from 0.89176\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1935 - acc: 0.6299 - val_loss: 0.8948 - val_acc: 0.7512\n",
      "Epoch 381/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1893 - acc: 0.6328\n",
      "Epoch 00381: val_loss did not improve from 0.89176\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1894 - acc: 0.6328 - val_loss: 0.8937 - val_acc: 0.7536\n",
      "Epoch 382/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1766 - acc: 0.6347\n",
      "Epoch 00382: val_loss improved from 0.89176 to 0.89109, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/382-0.8911.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1766 - acc: 0.6347 - val_loss: 0.8911 - val_acc: 0.7533\n",
      "Epoch 383/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1877 - acc: 0.6313\n",
      "Epoch 00383: val_loss improved from 0.89109 to 0.88704, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/383-0.8870.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1876 - acc: 0.6313 - val_loss: 0.8870 - val_acc: 0.7517\n",
      "Epoch 384/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1832 - acc: 0.6333\n",
      "Epoch 00384: val_loss did not improve from 0.88704\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1832 - acc: 0.6333 - val_loss: 0.8913 - val_acc: 0.7515\n",
      "Epoch 385/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1857 - acc: 0.6305\n",
      "Epoch 00385: val_loss did not improve from 0.88704\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1857 - acc: 0.6305 - val_loss: 0.8946 - val_acc: 0.7473\n",
      "Epoch 386/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1800 - acc: 0.6310\n",
      "Epoch 00386: val_loss did not improve from 0.88704\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1800 - acc: 0.6310 - val_loss: 0.8875 - val_acc: 0.7494\n",
      "Epoch 387/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1823 - acc: 0.6340\n",
      "Epoch 00387: val_loss did not improve from 0.88704\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1825 - acc: 0.6340 - val_loss: 0.8980 - val_acc: 0.7421\n",
      "Epoch 388/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1774 - acc: 0.6313\n",
      "Epoch 00388: val_loss did not improve from 0.88704\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1774 - acc: 0.6313 - val_loss: 0.8948 - val_acc: 0.7452\n",
      "Epoch 389/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1834 - acc: 0.6339\n",
      "Epoch 00389: val_loss did not improve from 0.88704\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1834 - acc: 0.6339 - val_loss: 0.8983 - val_acc: 0.7456\n",
      "Epoch 390/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1782 - acc: 0.6310\n",
      "Epoch 00390: val_loss did not improve from 0.88704\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1782 - acc: 0.6310 - val_loss: 0.8872 - val_acc: 0.7515\n",
      "Epoch 391/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1749 - acc: 0.6358\n",
      "Epoch 00391: val_loss did not improve from 0.88704\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.1748 - acc: 0.6359 - val_loss: 0.8887 - val_acc: 0.7529\n",
      "Epoch 392/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1872 - acc: 0.6324\n",
      "Epoch 00392: val_loss did not improve from 0.88704\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1872 - acc: 0.6324 - val_loss: 0.8892 - val_acc: 0.7524\n",
      "Epoch 393/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1833 - acc: 0.6348\n",
      "Epoch 00393: val_loss improved from 0.88704 to 0.88670, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/393-0.8867.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1834 - acc: 0.6347 - val_loss: 0.8867 - val_acc: 0.7480\n",
      "Epoch 394/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1792 - acc: 0.6346\n",
      "Epoch 00394: val_loss did not improve from 0.88670\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1794 - acc: 0.6346 - val_loss: 0.8927 - val_acc: 0.7491\n",
      "Epoch 395/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1814 - acc: 0.6342\n",
      "Epoch 00395: val_loss improved from 0.88670 to 0.88519, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/395-0.8852.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1813 - acc: 0.6343 - val_loss: 0.8852 - val_acc: 0.7508\n",
      "Epoch 396/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1768 - acc: 0.6318\n",
      "Epoch 00396: val_loss did not improve from 0.88519\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1767 - acc: 0.6319 - val_loss: 0.8856 - val_acc: 0.7503\n",
      "Epoch 397/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1807 - acc: 0.6353\n",
      "Epoch 00397: val_loss did not improve from 0.88519\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1808 - acc: 0.6353 - val_loss: 0.8884 - val_acc: 0.7508\n",
      "Epoch 398/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1747 - acc: 0.6351\n",
      "Epoch 00398: val_loss did not improve from 0.88519\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1748 - acc: 0.6351 - val_loss: 0.8854 - val_acc: 0.7529\n",
      "Epoch 399/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1775 - acc: 0.6322\n",
      "Epoch 00399: val_loss did not improve from 0.88519\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1775 - acc: 0.6322 - val_loss: 0.8892 - val_acc: 0.7456\n",
      "Epoch 400/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1767 - acc: 0.6365\n",
      "Epoch 00400: val_loss did not improve from 0.88519\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1766 - acc: 0.6366 - val_loss: 0.8853 - val_acc: 0.7487\n",
      "Epoch 401/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1780 - acc: 0.6358\n",
      "Epoch 00401: val_loss did not improve from 0.88519\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1782 - acc: 0.6358 - val_loss: 0.8894 - val_acc: 0.7475\n",
      "Epoch 402/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1766 - acc: 0.6360\n",
      "Epoch 00402: val_loss did not improve from 0.88519\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1765 - acc: 0.6359 - val_loss: 0.8872 - val_acc: 0.7470\n",
      "Epoch 403/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1756 - acc: 0.6354\n",
      "Epoch 00403: val_loss did not improve from 0.88519\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1756 - acc: 0.6354 - val_loss: 0.8866 - val_acc: 0.7508\n",
      "Epoch 404/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1691 - acc: 0.6386\n",
      "Epoch 00404: val_loss improved from 0.88519 to 0.88156, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/404-0.8816.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1691 - acc: 0.6386 - val_loss: 0.8816 - val_acc: 0.7519\n",
      "Epoch 405/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1716 - acc: 0.6372\n",
      "Epoch 00405: val_loss did not improve from 0.88156\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1719 - acc: 0.6372 - val_loss: 0.8890 - val_acc: 0.7494\n",
      "Epoch 406/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1732 - acc: 0.6348\n",
      "Epoch 00406: val_loss did not improve from 0.88156\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1733 - acc: 0.6348 - val_loss: 0.8834 - val_acc: 0.7529\n",
      "Epoch 407/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1684 - acc: 0.6361\n",
      "Epoch 00407: val_loss improved from 0.88156 to 0.88115, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/407-0.8811.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1685 - acc: 0.6361 - val_loss: 0.8811 - val_acc: 0.7501\n",
      "Epoch 408/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1800 - acc: 0.6340\n",
      "Epoch 00408: val_loss did not improve from 0.88115\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1801 - acc: 0.6339 - val_loss: 0.8847 - val_acc: 0.7529\n",
      "Epoch 409/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1764 - acc: 0.6340\n",
      "Epoch 00409: val_loss did not improve from 0.88115\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1763 - acc: 0.6340 - val_loss: 0.8872 - val_acc: 0.7508\n",
      "Epoch 410/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1756 - acc: 0.6362\n",
      "Epoch 00410: val_loss improved from 0.88115 to 0.87844, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/410-0.8784.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1761 - acc: 0.6362 - val_loss: 0.8784 - val_acc: 0.7515\n",
      "Epoch 411/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1811 - acc: 0.6328\n",
      "Epoch 00411: val_loss did not improve from 0.87844\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1812 - acc: 0.6328 - val_loss: 0.8863 - val_acc: 0.7554\n",
      "Epoch 412/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1741 - acc: 0.6339\n",
      "Epoch 00412: val_loss did not improve from 0.87844\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1740 - acc: 0.6339 - val_loss: 0.8795 - val_acc: 0.7543\n",
      "Epoch 413/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1742 - acc: 0.6373\n",
      "Epoch 00413: val_loss did not improve from 0.87844\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1742 - acc: 0.6373 - val_loss: 0.8802 - val_acc: 0.7543\n",
      "Epoch 414/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1676 - acc: 0.6361\n",
      "Epoch 00414: val_loss did not improve from 0.87844\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1676 - acc: 0.6361 - val_loss: 0.8822 - val_acc: 0.7533\n",
      "Epoch 415/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1766 - acc: 0.6353\n",
      "Epoch 00415: val_loss did not improve from 0.87844\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1765 - acc: 0.6353 - val_loss: 0.8822 - val_acc: 0.7522\n",
      "Epoch 416/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1766 - acc: 0.6361\n",
      "Epoch 00416: val_loss did not improve from 0.87844\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1766 - acc: 0.6361 - val_loss: 0.8803 - val_acc: 0.7545\n",
      "Epoch 417/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1689 - acc: 0.6364\n",
      "Epoch 00417: val_loss improved from 0.87844 to 0.87698, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/417-0.8770.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1689 - acc: 0.6365 - val_loss: 0.8770 - val_acc: 0.7552\n",
      "Epoch 418/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1794 - acc: 0.6352\n",
      "Epoch 00418: val_loss did not improve from 0.87698\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1794 - acc: 0.6352 - val_loss: 0.8833 - val_acc: 0.7531\n",
      "Epoch 419/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1705 - acc: 0.6372\n",
      "Epoch 00419: val_loss did not improve from 0.87698\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1704 - acc: 0.6373 - val_loss: 0.8783 - val_acc: 0.7554\n",
      "Epoch 420/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1758 - acc: 0.6359\n",
      "Epoch 00420: val_loss did not improve from 0.87698\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1758 - acc: 0.6359 - val_loss: 0.8774 - val_acc: 0.7531\n",
      "Epoch 421/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1655 - acc: 0.6370\n",
      "Epoch 00421: val_loss improved from 0.87698 to 0.87270, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/421-0.8727.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1655 - acc: 0.6370 - val_loss: 0.8727 - val_acc: 0.7566\n",
      "Epoch 422/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1735 - acc: 0.6359\n",
      "Epoch 00422: val_loss did not improve from 0.87270\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1735 - acc: 0.6359 - val_loss: 0.8826 - val_acc: 0.7552\n",
      "Epoch 423/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1659 - acc: 0.6385\n",
      "Epoch 00423: val_loss did not improve from 0.87270\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1659 - acc: 0.6385 - val_loss: 0.8790 - val_acc: 0.7524\n",
      "Epoch 424/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1645 - acc: 0.6386\n",
      "Epoch 00424: val_loss did not improve from 0.87270\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1646 - acc: 0.6386 - val_loss: 0.8776 - val_acc: 0.7543\n",
      "Epoch 425/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1718 - acc: 0.6362\n",
      "Epoch 00425: val_loss did not improve from 0.87270\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1718 - acc: 0.6362 - val_loss: 0.8799 - val_acc: 0.7487\n",
      "Epoch 426/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1694 - acc: 0.6368\n",
      "Epoch 00426: val_loss did not improve from 0.87270\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1694 - acc: 0.6368 - val_loss: 0.8792 - val_acc: 0.7526\n",
      "Epoch 427/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1628 - acc: 0.6370\n",
      "Epoch 00427: val_loss did not improve from 0.87270\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1628 - acc: 0.6370 - val_loss: 0.8787 - val_acc: 0.7538\n",
      "Epoch 428/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1690 - acc: 0.6389\n",
      "Epoch 00428: val_loss did not improve from 0.87270\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1690 - acc: 0.6389 - val_loss: 0.8791 - val_acc: 0.7524\n",
      "Epoch 429/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1685 - acc: 0.6371\n",
      "Epoch 00429: val_loss did not improve from 0.87270\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1685 - acc: 0.6370 - val_loss: 0.8765 - val_acc: 0.7543\n",
      "Epoch 430/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1630 - acc: 0.6398\n",
      "Epoch 00430: val_loss improved from 0.87270 to 0.87235, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/430-0.8723.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1629 - acc: 0.6398 - val_loss: 0.8723 - val_acc: 0.7582\n",
      "Epoch 431/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1601 - acc: 0.6403\n",
      "Epoch 00431: val_loss improved from 0.87235 to 0.87222, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/431-0.8722.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1600 - acc: 0.6403 - val_loss: 0.8722 - val_acc: 0.7580\n",
      "Epoch 432/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1643 - acc: 0.6403\n",
      "Epoch 00432: val_loss did not improve from 0.87222\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1643 - acc: 0.6403 - val_loss: 0.8757 - val_acc: 0.7519\n",
      "Epoch 433/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1669 - acc: 0.6399\n",
      "Epoch 00433: val_loss did not improve from 0.87222\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1670 - acc: 0.6399 - val_loss: 0.8764 - val_acc: 0.7515\n",
      "Epoch 434/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1656 - acc: 0.6390\n",
      "Epoch 00434: val_loss did not improve from 0.87222\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1656 - acc: 0.6390 - val_loss: 0.8762 - val_acc: 0.7515\n",
      "Epoch 435/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1583 - acc: 0.6415\n",
      "Epoch 00435: val_loss did not improve from 0.87222\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1582 - acc: 0.6416 - val_loss: 0.8739 - val_acc: 0.7519\n",
      "Epoch 436/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1643 - acc: 0.6405\n",
      "Epoch 00436: val_loss did not improve from 0.87222\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1643 - acc: 0.6405 - val_loss: 0.8813 - val_acc: 0.7529\n",
      "Epoch 437/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1644 - acc: 0.6399\n",
      "Epoch 00437: val_loss did not improve from 0.87222\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1645 - acc: 0.6398 - val_loss: 0.8732 - val_acc: 0.7589\n",
      "Epoch 438/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1654 - acc: 0.6377\n",
      "Epoch 00438: val_loss improved from 0.87222 to 0.87216, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/438-0.8722.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1653 - acc: 0.6377 - val_loss: 0.8722 - val_acc: 0.7547\n",
      "Epoch 439/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1623 - acc: 0.6388\n",
      "Epoch 00439: val_loss did not improve from 0.87216\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1622 - acc: 0.6388 - val_loss: 0.8801 - val_acc: 0.7526\n",
      "Epoch 440/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1648 - acc: 0.6409\n",
      "Epoch 00440: val_loss did not improve from 0.87216\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1649 - acc: 0.6409 - val_loss: 0.8764 - val_acc: 0.7526\n",
      "Epoch 441/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1565 - acc: 0.6378\n",
      "Epoch 00441: val_loss did not improve from 0.87216\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1565 - acc: 0.6377 - val_loss: 0.8747 - val_acc: 0.7568\n",
      "Epoch 442/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1650 - acc: 0.6413\n",
      "Epoch 00442: val_loss did not improve from 0.87216\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.1647 - acc: 0.6414 - val_loss: 0.8742 - val_acc: 0.7540\n",
      "Epoch 443/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1636 - acc: 0.6402\n",
      "Epoch 00443: val_loss did not improve from 0.87216\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1639 - acc: 0.6402 - val_loss: 0.8773 - val_acc: 0.7582\n",
      "Epoch 444/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1640 - acc: 0.6393\n",
      "Epoch 00444: val_loss did not improve from 0.87216\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1641 - acc: 0.6392 - val_loss: 0.8799 - val_acc: 0.7545\n",
      "Epoch 445/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1605 - acc: 0.6399\n",
      "Epoch 00445: val_loss did not improve from 0.87216\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1605 - acc: 0.6399 - val_loss: 0.8755 - val_acc: 0.7522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 446/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1604 - acc: 0.6405\n",
      "Epoch 00446: val_loss did not improve from 0.87216\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1602 - acc: 0.6405 - val_loss: 0.8738 - val_acc: 0.7596\n",
      "Epoch 447/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1687 - acc: 0.6378\n",
      "Epoch 00447: val_loss improved from 0.87216 to 0.87146, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/447-0.8715.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1682 - acc: 0.6378 - val_loss: 0.8715 - val_acc: 0.7549\n",
      "Epoch 448/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1577 - acc: 0.6395\n",
      "Epoch 00448: val_loss improved from 0.87146 to 0.87069, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/448-0.8707.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1576 - acc: 0.6395 - val_loss: 0.8707 - val_acc: 0.7598\n",
      "Epoch 449/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1596 - acc: 0.6398\n",
      "Epoch 00449: val_loss did not improve from 0.87069\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1595 - acc: 0.6398 - val_loss: 0.8711 - val_acc: 0.7563\n",
      "Epoch 450/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1669 - acc: 0.6395\n",
      "Epoch 00450: val_loss did not improve from 0.87069\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1669 - acc: 0.6395 - val_loss: 0.8709 - val_acc: 0.7559\n",
      "Epoch 451/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1609 - acc: 0.6402\n",
      "Epoch 00451: val_loss did not improve from 0.87069\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1610 - acc: 0.6402 - val_loss: 0.8758 - val_acc: 0.7584\n",
      "Epoch 452/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1661 - acc: 0.6393\n",
      "Epoch 00452: val_loss improved from 0.87069 to 0.86898, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/452-0.8690.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1660 - acc: 0.6393 - val_loss: 0.8690 - val_acc: 0.7531\n",
      "Epoch 453/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1571 - acc: 0.6408\n",
      "Epoch 00453: val_loss improved from 0.86898 to 0.86856, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/453-0.8686.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1571 - acc: 0.6408 - val_loss: 0.8686 - val_acc: 0.7591\n",
      "Epoch 454/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1600 - acc: 0.6399\n",
      "Epoch 00454: val_loss did not improve from 0.86856\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1601 - acc: 0.6399 - val_loss: 0.8692 - val_acc: 0.7573\n",
      "Epoch 455/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1575 - acc: 0.6420\n",
      "Epoch 00455: val_loss did not improve from 0.86856\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1575 - acc: 0.6421 - val_loss: 0.8702 - val_acc: 0.7561\n",
      "Epoch 456/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1561 - acc: 0.6445\n",
      "Epoch 00456: val_loss did not improve from 0.86856\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1562 - acc: 0.6445 - val_loss: 0.8694 - val_acc: 0.7536\n",
      "Epoch 457/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1564 - acc: 0.6404\n",
      "Epoch 00457: val_loss did not improve from 0.86856\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1564 - acc: 0.6404 - val_loss: 0.8713 - val_acc: 0.7556\n",
      "Epoch 458/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1572 - acc: 0.6431\n",
      "Epoch 00458: val_loss improved from 0.86856 to 0.86781, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/458-0.8678.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1573 - acc: 0.6431 - val_loss: 0.8678 - val_acc: 0.7566\n",
      "Epoch 459/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1568 - acc: 0.6382\n",
      "Epoch 00459: val_loss improved from 0.86781 to 0.86506, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/459-0.8651.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1567 - acc: 0.6382 - val_loss: 0.8651 - val_acc: 0.7577\n",
      "Epoch 460/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1580 - acc: 0.6422\n",
      "Epoch 00460: val_loss did not improve from 0.86506\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1579 - acc: 0.6422 - val_loss: 0.8692 - val_acc: 0.7545\n",
      "Epoch 461/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1585 - acc: 0.6402\n",
      "Epoch 00461: val_loss did not improve from 0.86506\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1586 - acc: 0.6401 - val_loss: 0.8729 - val_acc: 0.7563\n",
      "Epoch 462/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1590 - acc: 0.6415\n",
      "Epoch 00462: val_loss did not improve from 0.86506\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1590 - acc: 0.6415 - val_loss: 0.8668 - val_acc: 0.7563\n",
      "Epoch 463/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1581 - acc: 0.6424\n",
      "Epoch 00463: val_loss did not improve from 0.86506\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1581 - acc: 0.6424 - val_loss: 0.8727 - val_acc: 0.7547\n",
      "Epoch 464/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1648 - acc: 0.6381\n",
      "Epoch 00464: val_loss improved from 0.86506 to 0.86481, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/464-0.8648.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1649 - acc: 0.6381 - val_loss: 0.8648 - val_acc: 0.7619\n",
      "Epoch 465/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1616 - acc: 0.6405\n",
      "Epoch 00465: val_loss did not improve from 0.86481\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1617 - acc: 0.6405 - val_loss: 0.8704 - val_acc: 0.7573\n",
      "Epoch 466/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1515 - acc: 0.6439\n",
      "Epoch 00466: val_loss improved from 0.86481 to 0.86261, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/466-0.8626.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1514 - acc: 0.6439 - val_loss: 0.8626 - val_acc: 0.7608\n",
      "Epoch 467/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1504 - acc: 0.6445\n",
      "Epoch 00467: val_loss did not improve from 0.86261\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1504 - acc: 0.6445 - val_loss: 0.8630 - val_acc: 0.7598\n",
      "Epoch 468/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1558 - acc: 0.6416\n",
      "Epoch 00468: val_loss did not improve from 0.86261\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1556 - acc: 0.6417 - val_loss: 0.8643 - val_acc: 0.7568\n",
      "Epoch 469/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1549 - acc: 0.6416\n",
      "Epoch 00469: val_loss did not improve from 0.86261\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.1549 - acc: 0.6415 - val_loss: 0.8726 - val_acc: 0.7522\n",
      "Epoch 470/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1451 - acc: 0.6441\n",
      "Epoch 00470: val_loss did not improve from 0.86261\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1450 - acc: 0.6441 - val_loss: 0.8740 - val_acc: 0.7568\n",
      "Epoch 471/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1582 - acc: 0.6410\n",
      "Epoch 00471: val_loss did not improve from 0.86261\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1583 - acc: 0.6409 - val_loss: 0.8645 - val_acc: 0.7568\n",
      "Epoch 472/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1574 - acc: 0.6414\n",
      "Epoch 00472: val_loss improved from 0.86261 to 0.86261, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/472-0.8626.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1574 - acc: 0.6415 - val_loss: 0.8626 - val_acc: 0.7633\n",
      "Epoch 473/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1510 - acc: 0.6426\n",
      "Epoch 00473: val_loss did not improve from 0.86261\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1509 - acc: 0.6426 - val_loss: 0.8652 - val_acc: 0.7601\n",
      "Epoch 474/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1507 - acc: 0.6408\n",
      "Epoch 00474: val_loss did not improve from 0.86261\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1508 - acc: 0.6408 - val_loss: 0.8651 - val_acc: 0.7596\n",
      "Epoch 475/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1580 - acc: 0.6406\n",
      "Epoch 00475: val_loss did not improve from 0.86261\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1580 - acc: 0.6406 - val_loss: 0.8643 - val_acc: 0.7556\n",
      "Epoch 476/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1567 - acc: 0.6402\n",
      "Epoch 00476: val_loss improved from 0.86261 to 0.86181, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/476-0.8618.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1566 - acc: 0.6402 - val_loss: 0.8618 - val_acc: 0.7612\n",
      "Epoch 477/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1537 - acc: 0.6437\n",
      "Epoch 00477: val_loss improved from 0.86181 to 0.85972, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/477-0.8597.hdf5\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1536 - acc: 0.6437 - val_loss: 0.8597 - val_acc: 0.7598\n",
      "Epoch 478/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1567 - acc: 0.6405\n",
      "Epoch 00478: val_loss did not improve from 0.85972\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1567 - acc: 0.6405 - val_loss: 0.8623 - val_acc: 0.7594\n",
      "Epoch 479/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1547 - acc: 0.6399\n",
      "Epoch 00479: val_loss did not improve from 0.85972\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 1.1547 - acc: 0.6399 - val_loss: 0.8658 - val_acc: 0.7577\n",
      "Epoch 480/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1535 - acc: 0.6432\n",
      "Epoch 00480: val_loss did not improve from 0.85972\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1535 - acc: 0.6432 - val_loss: 0.8654 - val_acc: 0.7589\n",
      "Epoch 481/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1538 - acc: 0.6419\n",
      "Epoch 00481: val_loss did not improve from 0.85972\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1538 - acc: 0.6420 - val_loss: 0.8636 - val_acc: 0.7608\n",
      "Epoch 482/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1525 - acc: 0.6429\n",
      "Epoch 00482: val_loss did not improve from 0.85972\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1527 - acc: 0.6428 - val_loss: 0.8621 - val_acc: 0.7589\n",
      "Epoch 483/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1543 - acc: 0.6418\n",
      "Epoch 00483: val_loss did not improve from 0.85972\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1545 - acc: 0.6418 - val_loss: 0.8614 - val_acc: 0.7580\n",
      "Epoch 484/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1586 - acc: 0.6423\n",
      "Epoch 00484: val_loss did not improve from 0.85972\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1585 - acc: 0.6423 - val_loss: 0.8657 - val_acc: 0.7519\n",
      "Epoch 485/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1460 - acc: 0.6449\n",
      "Epoch 00485: val_loss did not improve from 0.85972\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1461 - acc: 0.6450 - val_loss: 0.8613 - val_acc: 0.7603\n",
      "Epoch 486/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1501 - acc: 0.6423\n",
      "Epoch 00486: val_loss did not improve from 0.85972\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1501 - acc: 0.6424 - val_loss: 0.8637 - val_acc: 0.7598\n",
      "Epoch 487/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1564 - acc: 0.6424\n",
      "Epoch 00487: val_loss did not improve from 0.85972\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1564 - acc: 0.6424 - val_loss: 0.8651 - val_acc: 0.7563\n",
      "Epoch 488/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1483 - acc: 0.6445\n",
      "Epoch 00488: val_loss did not improve from 0.85972\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1484 - acc: 0.6445 - val_loss: 0.8649 - val_acc: 0.7540\n",
      "Epoch 489/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1531 - acc: 0.6427\n",
      "Epoch 00489: val_loss improved from 0.85972 to 0.85699, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/489-0.8570.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1531 - acc: 0.6427 - val_loss: 0.8570 - val_acc: 0.7626\n",
      "Epoch 490/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1510 - acc: 0.6403\n",
      "Epoch 00490: val_loss did not improve from 0.85699\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1509 - acc: 0.6403 - val_loss: 0.8621 - val_acc: 0.7577\n",
      "Epoch 491/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1537 - acc: 0.6430\n",
      "Epoch 00491: val_loss did not improve from 0.85699\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1536 - acc: 0.6431 - val_loss: 0.8628 - val_acc: 0.7575\n",
      "Epoch 492/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1512 - acc: 0.6449\n",
      "Epoch 00492: val_loss did not improve from 0.85699\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 1.1511 - acc: 0.6449 - val_loss: 0.8627 - val_acc: 0.7622\n",
      "Epoch 493/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1487 - acc: 0.6437\n",
      "Epoch 00493: val_loss did not improve from 0.85699\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1488 - acc: 0.6436 - val_loss: 0.8585 - val_acc: 0.7629\n",
      "Epoch 494/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1429 - acc: 0.6445\n",
      "Epoch 00494: val_loss did not improve from 0.85699\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1430 - acc: 0.6445 - val_loss: 0.8602 - val_acc: 0.7584\n",
      "Epoch 495/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1438 - acc: 0.6460\n",
      "Epoch 00495: val_loss improved from 0.85699 to 0.85600, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/495-0.8560.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1438 - acc: 0.6460 - val_loss: 0.8560 - val_acc: 0.7626\n",
      "Epoch 496/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1427 - acc: 0.6472\n",
      "Epoch 00496: val_loss improved from 0.85600 to 0.85450, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/496-0.8545.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.1429 - acc: 0.6471 - val_loss: 0.8545 - val_acc: 0.7643\n",
      "Epoch 497/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1467 - acc: 0.6452\n",
      "Epoch 00497: val_loss did not improve from 0.85450\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 1.1467 - acc: 0.6452 - val_loss: 0.8603 - val_acc: 0.7577\n",
      "Epoch 498/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1468 - acc: 0.6448\n",
      "Epoch 00498: val_loss did not improve from 0.85450\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.1467 - acc: 0.6449 - val_loss: 0.8582 - val_acc: 0.7608\n",
      "Epoch 499/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1446 - acc: 0.6433\n",
      "Epoch 00499: val_loss improved from 0.85450 to 0.85400, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv_checkpoint/499-0.8540.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.1447 - acc: 0.6433 - val_loss: 0.8540 - val_acc: 0.7598\n",
      "Epoch 500/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1541 - acc: 0.6415\n",
      "Epoch 00500: val_loss did not improve from 0.85400\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1541 - acc: 0.6415 - val_loss: 0.8600 - val_acc: 0.7608\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 219us/sample - loss: 0.9031 - acc: 0.7360\n",
      "Loss: 0.9030666095321671 Accuracy: 0.7360332\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7368 - acc: 0.0840\n",
      "Epoch 00001: val_loss improved from inf to 2.69050, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/001-2.6905.hdf5\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 2.7368 - acc: 0.0840 - val_loss: 2.6905 - val_acc: 0.1148\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6400 - acc: 0.1338\n",
      "Epoch 00002: val_loss improved from 2.69050 to 2.49261, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/002-2.4926.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 2.6400 - acc: 0.1338 - val_loss: 2.4926 - val_acc: 0.2455\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4459 - acc: 0.2002\n",
      "Epoch 00003: val_loss improved from 2.49261 to 2.26283, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/003-2.2628.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 2.4459 - acc: 0.2002 - val_loss: 2.2628 - val_acc: 0.3033\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3203 - acc: 0.2331\n",
      "Epoch 00004: val_loss improved from 2.26283 to 2.13037, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/004-2.1304.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 2.3203 - acc: 0.2331 - val_loss: 2.1304 - val_acc: 0.3555\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2229 - acc: 0.2558\n",
      "Epoch 00005: val_loss improved from 2.13037 to 2.02911, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/005-2.0291.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 2.2229 - acc: 0.2558 - val_loss: 2.0291 - val_acc: 0.3806\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1562 - acc: 0.2781\n",
      "Epoch 00006: val_loss improved from 2.02911 to 1.96214, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/006-1.9621.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 2.1562 - acc: 0.2781 - val_loss: 1.9621 - val_acc: 0.3965\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0979 - acc: 0.2974\n",
      "Epoch 00007: val_loss improved from 1.96214 to 1.90401, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/007-1.9040.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 2.0978 - acc: 0.2975 - val_loss: 1.9040 - val_acc: 0.4235\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0480 - acc: 0.3159\n",
      "Epoch 00008: val_loss improved from 1.90401 to 1.85875, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/008-1.8588.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 2.0479 - acc: 0.3160 - val_loss: 1.8588 - val_acc: 0.4379\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0065 - acc: 0.3293\n",
      "Epoch 00009: val_loss improved from 1.85875 to 1.80507, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/009-1.8051.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 2.0065 - acc: 0.3294 - val_loss: 1.8051 - val_acc: 0.4489\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9639 - acc: 0.3457\n",
      "Epoch 00010: val_loss improved from 1.80507 to 1.77388, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/010-1.7739.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.9639 - acc: 0.3457 - val_loss: 1.7739 - val_acc: 0.4554\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9267 - acc: 0.3581\n",
      "Epoch 00011: val_loss improved from 1.77388 to 1.73303, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/011-1.7330.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.9266 - acc: 0.3581 - val_loss: 1.7330 - val_acc: 0.4750\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8965 - acc: 0.3699\n",
      "Epoch 00012: val_loss improved from 1.73303 to 1.68463, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/012-1.6846.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.8965 - acc: 0.3699 - val_loss: 1.6846 - val_acc: 0.4875\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8630 - acc: 0.3819\n",
      "Epoch 00013: val_loss improved from 1.68463 to 1.66274, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/013-1.6627.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.8631 - acc: 0.3818 - val_loss: 1.6627 - val_acc: 0.4952\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8324 - acc: 0.3911\n",
      "Epoch 00014: val_loss improved from 1.66274 to 1.62420, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/014-1.6242.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.8324 - acc: 0.3911 - val_loss: 1.6242 - val_acc: 0.5150\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8039 - acc: 0.3995\n",
      "Epoch 00015: val_loss improved from 1.62420 to 1.58842, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/015-1.5884.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.8040 - acc: 0.3995 - val_loss: 1.5884 - val_acc: 0.5229\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7774 - acc: 0.4084\n",
      "Epoch 00016: val_loss improved from 1.58842 to 1.56610, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/016-1.5661.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.7772 - acc: 0.4084 - val_loss: 1.5661 - val_acc: 0.5292\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7538 - acc: 0.4206\n",
      "Epoch 00017: val_loss improved from 1.56610 to 1.53382, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/017-1.5338.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.7539 - acc: 0.4206 - val_loss: 1.5338 - val_acc: 0.5425\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7320 - acc: 0.4311\n",
      "Epoch 00018: val_loss improved from 1.53382 to 1.50583, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/018-1.5058.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.7320 - acc: 0.4311 - val_loss: 1.5058 - val_acc: 0.5525\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7046 - acc: 0.4392\n",
      "Epoch 00019: val_loss improved from 1.50583 to 1.48334, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/019-1.4833.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.7047 - acc: 0.4391 - val_loss: 1.4833 - val_acc: 0.5584\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6787 - acc: 0.4495\n",
      "Epoch 00020: val_loss improved from 1.48334 to 1.45185, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/020-1.4518.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.6787 - acc: 0.4495 - val_loss: 1.4518 - val_acc: 0.5684\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6594 - acc: 0.4575\n",
      "Epoch 00021: val_loss improved from 1.45185 to 1.43209, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/021-1.4321.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.6595 - acc: 0.4575 - val_loss: 1.4321 - val_acc: 0.5779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6414 - acc: 0.4610\n",
      "Epoch 00022: val_loss improved from 1.43209 to 1.41135, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/022-1.4113.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.6414 - acc: 0.4610 - val_loss: 1.4113 - val_acc: 0.5805\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6260 - acc: 0.4671\n",
      "Epoch 00023: val_loss improved from 1.41135 to 1.38756, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/023-1.3876.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.6259 - acc: 0.4672 - val_loss: 1.3876 - val_acc: 0.5917\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6095 - acc: 0.4780\n",
      "Epoch 00024: val_loss improved from 1.38756 to 1.37861, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/024-1.3786.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.6096 - acc: 0.4780 - val_loss: 1.3786 - val_acc: 0.5954\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5925 - acc: 0.4814\n",
      "Epoch 00025: val_loss improved from 1.37861 to 1.35612, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/025-1.3561.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.5925 - acc: 0.4814 - val_loss: 1.3561 - val_acc: 0.5945\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5757 - acc: 0.4862\n",
      "Epoch 00026: val_loss improved from 1.35612 to 1.34274, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/026-1.3427.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.5756 - acc: 0.4862 - val_loss: 1.3427 - val_acc: 0.6042\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5613 - acc: 0.4923\n",
      "Epoch 00027: val_loss improved from 1.34274 to 1.32566, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/027-1.3257.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.5613 - acc: 0.4923 - val_loss: 1.3257 - val_acc: 0.6063\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5435 - acc: 0.5013\n",
      "Epoch 00028: val_loss improved from 1.32566 to 1.30387, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/028-1.3039.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.5435 - acc: 0.5013 - val_loss: 1.3039 - val_acc: 0.6119\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5359 - acc: 0.5026\n",
      "Epoch 00029: val_loss improved from 1.30387 to 1.30093, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/029-1.3009.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.5359 - acc: 0.5025 - val_loss: 1.3009 - val_acc: 0.6175\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5239 - acc: 0.5068\n",
      "Epoch 00030: val_loss improved from 1.30093 to 1.28212, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/030-1.2821.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.5238 - acc: 0.5068 - val_loss: 1.2821 - val_acc: 0.6226\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5107 - acc: 0.5122\n",
      "Epoch 00031: val_loss improved from 1.28212 to 1.27415, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/031-1.2741.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.5107 - acc: 0.5122 - val_loss: 1.2741 - val_acc: 0.6238\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4926 - acc: 0.5192\n",
      "Epoch 00032: val_loss improved from 1.27415 to 1.25262, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/032-1.2526.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.4926 - acc: 0.5191 - val_loss: 1.2526 - val_acc: 0.6280\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4884 - acc: 0.5190\n",
      "Epoch 00033: val_loss improved from 1.25262 to 1.24354, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/033-1.2435.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.4885 - acc: 0.5190 - val_loss: 1.2435 - val_acc: 0.6327\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4778 - acc: 0.5259\n",
      "Epoch 00034: val_loss improved from 1.24354 to 1.23386, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/034-1.2339.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.4777 - acc: 0.5259 - val_loss: 1.2339 - val_acc: 0.6385\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4612 - acc: 0.5277\n",
      "Epoch 00035: val_loss improved from 1.23386 to 1.22354, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/035-1.2235.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.4612 - acc: 0.5277 - val_loss: 1.2235 - val_acc: 0.6382\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4601 - acc: 0.5298\n",
      "Epoch 00036: val_loss improved from 1.22354 to 1.21954, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/036-1.2195.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.4601 - acc: 0.5298 - val_loss: 1.2195 - val_acc: 0.6413\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4444 - acc: 0.5340\n",
      "Epoch 00037: val_loss improved from 1.21954 to 1.21129, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/037-1.2113.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.4445 - acc: 0.5339 - val_loss: 1.2113 - val_acc: 0.6436\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4387 - acc: 0.5403\n",
      "Epoch 00038: val_loss improved from 1.21129 to 1.19314, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/038-1.1931.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.4388 - acc: 0.5403 - val_loss: 1.1931 - val_acc: 0.6532\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4314 - acc: 0.5406\n",
      "Epoch 00039: val_loss did not improve from 1.19314\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.4314 - acc: 0.5406 - val_loss: 1.1951 - val_acc: 0.6469\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4243 - acc: 0.5435\n",
      "Epoch 00040: val_loss improved from 1.19314 to 1.18491, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/040-1.1849.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.4242 - acc: 0.5435 - val_loss: 1.1849 - val_acc: 0.6571\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4142 - acc: 0.5498\n",
      "Epoch 00041: val_loss improved from 1.18491 to 1.16703, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/041-1.1670.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.4142 - acc: 0.5498 - val_loss: 1.1670 - val_acc: 0.6587\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4021 - acc: 0.5520\n",
      "Epoch 00042: val_loss improved from 1.16703 to 1.15811, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/042-1.1581.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.4021 - acc: 0.5520 - val_loss: 1.1581 - val_acc: 0.6569\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3911 - acc: 0.5551\n",
      "Epoch 00043: val_loss improved from 1.15811 to 1.14675, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/043-1.1467.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.3911 - acc: 0.5550 - val_loss: 1.1467 - val_acc: 0.6662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3864 - acc: 0.5567\n",
      "Epoch 00044: val_loss improved from 1.14675 to 1.14322, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/044-1.1432.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.3863 - acc: 0.5568 - val_loss: 1.1432 - val_acc: 0.6636\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3828 - acc: 0.5598\n",
      "Epoch 00045: val_loss improved from 1.14322 to 1.13590, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/045-1.1359.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.3828 - acc: 0.5598 - val_loss: 1.1359 - val_acc: 0.6725\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3730 - acc: 0.5629\n",
      "Epoch 00046: val_loss improved from 1.13590 to 1.13097, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/046-1.1310.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.3729 - acc: 0.5630 - val_loss: 1.1310 - val_acc: 0.6739\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3621 - acc: 0.5674\n",
      "Epoch 00047: val_loss improved from 1.13097 to 1.11828, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/047-1.1183.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.3621 - acc: 0.5674 - val_loss: 1.1183 - val_acc: 0.6706\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3587 - acc: 0.5680\n",
      "Epoch 00048: val_loss improved from 1.11828 to 1.10698, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/048-1.1070.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.3587 - acc: 0.5680 - val_loss: 1.1070 - val_acc: 0.6758\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3530 - acc: 0.5694\n",
      "Epoch 00049: val_loss improved from 1.10698 to 1.10578, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/049-1.1058.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.3531 - acc: 0.5694 - val_loss: 1.1058 - val_acc: 0.6758\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3393 - acc: 0.5771\n",
      "Epoch 00050: val_loss improved from 1.10578 to 1.10282, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/050-1.1028.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3393 - acc: 0.5771 - val_loss: 1.1028 - val_acc: 0.6748\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3355 - acc: 0.5774\n",
      "Epoch 00051: val_loss improved from 1.10282 to 1.08401, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/051-1.0840.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.3354 - acc: 0.5774 - val_loss: 1.0840 - val_acc: 0.6811\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3308 - acc: 0.5763\n",
      "Epoch 00052: val_loss did not improve from 1.08401\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.3307 - acc: 0.5763 - val_loss: 1.0889 - val_acc: 0.6795\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3252 - acc: 0.5787\n",
      "Epoch 00053: val_loss did not improve from 1.08401\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.3254 - acc: 0.5787 - val_loss: 1.0895 - val_acc: 0.6785\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3190 - acc: 0.5811\n",
      "Epoch 00054: val_loss improved from 1.08401 to 1.07604, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/054-1.0760.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.3191 - acc: 0.5811 - val_loss: 1.0760 - val_acc: 0.6860\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3115 - acc: 0.5848\n",
      "Epoch 00055: val_loss improved from 1.07604 to 1.07028, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/055-1.0703.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.3115 - acc: 0.5848 - val_loss: 1.0703 - val_acc: 0.6813\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3071 - acc: 0.5858\n",
      "Epoch 00056: val_loss improved from 1.07028 to 1.06266, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/056-1.0627.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.3071 - acc: 0.5858 - val_loss: 1.0627 - val_acc: 0.6862\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3001 - acc: 0.5889\n",
      "Epoch 00057: val_loss improved from 1.06266 to 1.06216, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/057-1.0622.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.3001 - acc: 0.5889 - val_loss: 1.0622 - val_acc: 0.6895\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3022 - acc: 0.5893\n",
      "Epoch 00058: val_loss improved from 1.06216 to 1.04821, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/058-1.0482.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.3023 - acc: 0.5892 - val_loss: 1.0482 - val_acc: 0.6953\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2939 - acc: 0.5925\n",
      "Epoch 00059: val_loss did not improve from 1.04821\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.2940 - acc: 0.5925 - val_loss: 1.0528 - val_acc: 0.6923\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2904 - acc: 0.5926\n",
      "Epoch 00060: val_loss improved from 1.04821 to 1.04624, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/060-1.0462.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2903 - acc: 0.5926 - val_loss: 1.0462 - val_acc: 0.6916\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2836 - acc: 0.5932\n",
      "Epoch 00061: val_loss improved from 1.04624 to 1.03360, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/061-1.0336.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.2836 - acc: 0.5932 - val_loss: 1.0336 - val_acc: 0.7000\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2806 - acc: 0.5956\n",
      "Epoch 00062: val_loss did not improve from 1.03360\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2807 - acc: 0.5955 - val_loss: 1.0390 - val_acc: 0.6965\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2715 - acc: 0.5983\n",
      "Epoch 00063: val_loss did not improve from 1.03360\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.2714 - acc: 0.5983 - val_loss: 1.0390 - val_acc: 0.6956\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2679 - acc: 0.6023\n",
      "Epoch 00064: val_loss improved from 1.03360 to 1.02399, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/064-1.0240.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.2678 - acc: 0.6023 - val_loss: 1.0240 - val_acc: 0.6988\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2650 - acc: 0.6024\n",
      "Epoch 00065: val_loss improved from 1.02399 to 1.01595, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/065-1.0160.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.2650 - acc: 0.6024 - val_loss: 1.0160 - val_acc: 0.7002\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2616 - acc: 0.6012\n",
      "Epoch 00066: val_loss improved from 1.01595 to 1.01274, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/066-1.0127.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.2616 - acc: 0.6013 - val_loss: 1.0127 - val_acc: 0.7044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2597 - acc: 0.6018\n",
      "Epoch 00067: val_loss did not improve from 1.01274\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.2596 - acc: 0.6018 - val_loss: 1.0148 - val_acc: 0.7065\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2459 - acc: 0.6071\n",
      "Epoch 00068: val_loss did not improve from 1.01274\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.2458 - acc: 0.6071 - val_loss: 1.0145 - val_acc: 0.7053\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2544 - acc: 0.6034\n",
      "Epoch 00069: val_loss improved from 1.01274 to 0.99650, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/069-0.9965.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.2544 - acc: 0.6034 - val_loss: 0.9965 - val_acc: 0.7095\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2506 - acc: 0.6085\n",
      "Epoch 00070: val_loss improved from 0.99650 to 0.99187, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/070-0.9919.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 1.2505 - acc: 0.6085 - val_loss: 0.9919 - val_acc: 0.7126\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2446 - acc: 0.6082\n",
      "Epoch 00071: val_loss did not improve from 0.99187\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2445 - acc: 0.6082 - val_loss: 0.9932 - val_acc: 0.7109\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2371 - acc: 0.6110\n",
      "Epoch 00072: val_loss improved from 0.99187 to 0.99080, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/072-0.9908.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 1.2372 - acc: 0.6110 - val_loss: 0.9908 - val_acc: 0.7093\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2376 - acc: 0.6090\n",
      "Epoch 00073: val_loss improved from 0.99080 to 0.98917, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/073-0.9892.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2376 - acc: 0.6090 - val_loss: 0.9892 - val_acc: 0.7114\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2341 - acc: 0.6097\n",
      "Epoch 00074: val_loss improved from 0.98917 to 0.98099, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/074-0.9810.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.2341 - acc: 0.6097 - val_loss: 0.9810 - val_acc: 0.7158\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2299 - acc: 0.6158\n",
      "Epoch 00075: val_loss did not improve from 0.98099\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.2298 - acc: 0.6158 - val_loss: 0.9852 - val_acc: 0.7095\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2242 - acc: 0.6148\n",
      "Epoch 00076: val_loss improved from 0.98099 to 0.97598, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/076-0.9760.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2242 - acc: 0.6148 - val_loss: 0.9760 - val_acc: 0.7149\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2191 - acc: 0.6182\n",
      "Epoch 00077: val_loss improved from 0.97598 to 0.97439, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/077-0.9744.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2190 - acc: 0.6182 - val_loss: 0.9744 - val_acc: 0.7149\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2134 - acc: 0.6193\n",
      "Epoch 00078: val_loss did not improve from 0.97439\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2134 - acc: 0.6193 - val_loss: 0.9748 - val_acc: 0.7154\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2149 - acc: 0.6182\n",
      "Epoch 00079: val_loss did not improve from 0.97439\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2151 - acc: 0.6182 - val_loss: 0.9883 - val_acc: 0.7107\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2100 - acc: 0.6222\n",
      "Epoch 00080: val_loss improved from 0.97439 to 0.96187, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/080-0.9619.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.2099 - acc: 0.6222 - val_loss: 0.9619 - val_acc: 0.7207\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2120 - acc: 0.6184\n",
      "Epoch 00081: val_loss improved from 0.96187 to 0.96047, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/081-0.9605.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.2120 - acc: 0.6184 - val_loss: 0.9605 - val_acc: 0.7233\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2130 - acc: 0.6181\n",
      "Epoch 00082: val_loss improved from 0.96047 to 0.95539, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/082-0.9554.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.2130 - acc: 0.6181 - val_loss: 0.9554 - val_acc: 0.7226\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1993 - acc: 0.6235\n",
      "Epoch 00083: val_loss improved from 0.95539 to 0.94976, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/083-0.9498.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1994 - acc: 0.6235 - val_loss: 0.9498 - val_acc: 0.7202\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1999 - acc: 0.6250\n",
      "Epoch 00084: val_loss did not improve from 0.94976\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1999 - acc: 0.6250 - val_loss: 0.9625 - val_acc: 0.7151\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2040 - acc: 0.6225\n",
      "Epoch 00085: val_loss did not improve from 0.94976\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.2040 - acc: 0.6225 - val_loss: 0.9539 - val_acc: 0.7198\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1969 - acc: 0.6223\n",
      "Epoch 00086: val_loss did not improve from 0.94976\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.1972 - acc: 0.6223 - val_loss: 0.9582 - val_acc: 0.7207\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1954 - acc: 0.6252\n",
      "Epoch 00087: val_loss improved from 0.94976 to 0.94294, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/087-0.9429.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.1953 - acc: 0.6252 - val_loss: 0.9429 - val_acc: 0.7268\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1949 - acc: 0.6264\n",
      "Epoch 00088: val_loss did not improve from 0.94294\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1948 - acc: 0.6265 - val_loss: 0.9560 - val_acc: 0.7198\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1861 - acc: 0.6294\n",
      "Epoch 00089: val_loss did not improve from 0.94294\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1861 - acc: 0.6294 - val_loss: 0.9470 - val_acc: 0.7235\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1869 - acc: 0.6288\n",
      "Epoch 00090: val_loss did not improve from 0.94294\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1869 - acc: 0.6288 - val_loss: 0.9587 - val_acc: 0.7158\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1874 - acc: 0.6276\n",
      "Epoch 00091: val_loss improved from 0.94294 to 0.93853, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/091-0.9385.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1874 - acc: 0.6276 - val_loss: 0.9385 - val_acc: 0.7233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1821 - acc: 0.6323\n",
      "Epoch 00092: val_loss improved from 0.93853 to 0.93612, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/092-0.9361.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1822 - acc: 0.6323 - val_loss: 0.9361 - val_acc: 0.7256\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1811 - acc: 0.6293\n",
      "Epoch 00093: val_loss did not improve from 0.93612\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1810 - acc: 0.6293 - val_loss: 0.9394 - val_acc: 0.7240\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1731 - acc: 0.6323\n",
      "Epoch 00094: val_loss improved from 0.93612 to 0.93248, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/094-0.9325.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1732 - acc: 0.6323 - val_loss: 0.9325 - val_acc: 0.7279\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1765 - acc: 0.6298\n",
      "Epoch 00095: val_loss improved from 0.93248 to 0.92318, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/095-0.9232.hdf5\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 1.1764 - acc: 0.6298 - val_loss: 0.9232 - val_acc: 0.7324\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1669 - acc: 0.6355\n",
      "Epoch 00096: val_loss did not improve from 0.92318\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1669 - acc: 0.6355 - val_loss: 0.9355 - val_acc: 0.7247\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1787 - acc: 0.6301\n",
      "Epoch 00097: val_loss did not improve from 0.92318\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1787 - acc: 0.6301 - val_loss: 0.9309 - val_acc: 0.7300\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1637 - acc: 0.6365\n",
      "Epoch 00098: val_loss improved from 0.92318 to 0.91301, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/098-0.9130.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1636 - acc: 0.6365 - val_loss: 0.9130 - val_acc: 0.7305\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1689 - acc: 0.6362\n",
      "Epoch 00099: val_loss did not improve from 0.91301\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1688 - acc: 0.6362 - val_loss: 0.9178 - val_acc: 0.7303\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1594 - acc: 0.6411\n",
      "Epoch 00100: val_loss did not improve from 0.91301\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1593 - acc: 0.6411 - val_loss: 0.9150 - val_acc: 0.7321\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1601 - acc: 0.6368\n",
      "Epoch 00101: val_loss did not improve from 0.91301\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1602 - acc: 0.6369 - val_loss: 0.9165 - val_acc: 0.7275\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1622 - acc: 0.6382\n",
      "Epoch 00102: val_loss improved from 0.91301 to 0.90580, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/102-0.9058.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1621 - acc: 0.6382 - val_loss: 0.9058 - val_acc: 0.7342\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1571 - acc: 0.6404\n",
      "Epoch 00103: val_loss improved from 0.90580 to 0.90391, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/103-0.9039.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.1572 - acc: 0.6403 - val_loss: 0.9039 - val_acc: 0.7338\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1591 - acc: 0.6391\n",
      "Epoch 00104: val_loss did not improve from 0.90391\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1592 - acc: 0.6391 - val_loss: 0.9175 - val_acc: 0.7312\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1466 - acc: 0.6435\n",
      "Epoch 00105: val_loss improved from 0.90391 to 0.90208, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/105-0.9021.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1465 - acc: 0.6434 - val_loss: 0.9021 - val_acc: 0.7321\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1511 - acc: 0.6413\n",
      "Epoch 00106: val_loss did not improve from 0.90208\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.1511 - acc: 0.6414 - val_loss: 0.9055 - val_acc: 0.7356\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1535 - acc: 0.6396\n",
      "Epoch 00107: val_loss improved from 0.90208 to 0.89910, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/107-0.8991.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1534 - acc: 0.6396 - val_loss: 0.8991 - val_acc: 0.7370\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1441 - acc: 0.6414\n",
      "Epoch 00108: val_loss improved from 0.89910 to 0.89622, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/108-0.8962.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1441 - acc: 0.6414 - val_loss: 0.8962 - val_acc: 0.7335\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1382 - acc: 0.6434\n",
      "Epoch 00109: val_loss improved from 0.89622 to 0.88779, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/109-0.8878.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 1.1383 - acc: 0.6434 - val_loss: 0.8878 - val_acc: 0.7356\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1414 - acc: 0.6434\n",
      "Epoch 00110: val_loss did not improve from 0.88779\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1414 - acc: 0.6434 - val_loss: 0.9114 - val_acc: 0.7349\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1434 - acc: 0.6461\n",
      "Epoch 00111: val_loss did not improve from 0.88779\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1434 - acc: 0.6462 - val_loss: 0.8945 - val_acc: 0.7393\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1417 - acc: 0.6461\n",
      "Epoch 00112: val_loss did not improve from 0.88779\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1417 - acc: 0.6462 - val_loss: 0.8947 - val_acc: 0.7391\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1408 - acc: 0.6439\n",
      "Epoch 00113: val_loss improved from 0.88779 to 0.88274, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/113-0.8827.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 1.1409 - acc: 0.6439 - val_loss: 0.8827 - val_acc: 0.7389\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1380 - acc: 0.6449\n",
      "Epoch 00114: val_loss did not improve from 0.88274\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1380 - acc: 0.6449 - val_loss: 0.8867 - val_acc: 0.7393\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1338 - acc: 0.6466\n",
      "Epoch 00115: val_loss did not improve from 0.88274\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1337 - acc: 0.6466 - val_loss: 0.8919 - val_acc: 0.7356\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1312 - acc: 0.6500\n",
      "Epoch 00116: val_loss did not improve from 0.88274\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1311 - acc: 0.6500 - val_loss: 0.8852 - val_acc: 0.7377\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1268 - acc: 0.6452\n",
      "Epoch 00117: val_loss improved from 0.88274 to 0.88120, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/117-0.8812.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.1267 - acc: 0.6453 - val_loss: 0.8812 - val_acc: 0.7396\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1260 - acc: 0.6538\n",
      "Epoch 00118: val_loss did not improve from 0.88120\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.1260 - acc: 0.6538 - val_loss: 0.8817 - val_acc: 0.7452\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1305 - acc: 0.6468\n",
      "Epoch 00119: val_loss did not improve from 0.88120\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1305 - acc: 0.6467 - val_loss: 0.8871 - val_acc: 0.7419\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1275 - acc: 0.6511\n",
      "Epoch 00120: val_loss improved from 0.88120 to 0.87877, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/120-0.8788.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.1274 - acc: 0.6511 - val_loss: 0.8788 - val_acc: 0.7452\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1278 - acc: 0.6478\n",
      "Epoch 00121: val_loss improved from 0.87877 to 0.87677, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/121-0.8768.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.1278 - acc: 0.6478 - val_loss: 0.8768 - val_acc: 0.7454\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1269 - acc: 0.6501\n",
      "Epoch 00122: val_loss improved from 0.87677 to 0.87243, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/122-0.8724.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1269 - acc: 0.6500 - val_loss: 0.8724 - val_acc: 0.7445\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1234 - acc: 0.6480\n",
      "Epoch 00123: val_loss did not improve from 0.87243\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1235 - acc: 0.6480 - val_loss: 0.8775 - val_acc: 0.7440\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1157 - acc: 0.6537\n",
      "Epoch 00124: val_loss improved from 0.87243 to 0.86937, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/124-0.8694.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1157 - acc: 0.6537 - val_loss: 0.8694 - val_acc: 0.7435\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1179 - acc: 0.6532\n",
      "Epoch 00125: val_loss improved from 0.86937 to 0.86790, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/125-0.8679.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1179 - acc: 0.6532 - val_loss: 0.8679 - val_acc: 0.7440\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1205 - acc: 0.6513\n",
      "Epoch 00126: val_loss improved from 0.86790 to 0.86471, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/126-0.8647.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1204 - acc: 0.6513 - val_loss: 0.8647 - val_acc: 0.7491\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1136 - acc: 0.6525\n",
      "Epoch 00127: val_loss did not improve from 0.86471\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.1137 - acc: 0.6525 - val_loss: 0.8702 - val_acc: 0.7431\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1129 - acc: 0.6548\n",
      "Epoch 00128: val_loss did not improve from 0.86471\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1129 - acc: 0.6548 - val_loss: 0.8692 - val_acc: 0.7456\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1079 - acc: 0.6564\n",
      "Epoch 00129: val_loss improved from 0.86471 to 0.85946, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/129-0.8595.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1079 - acc: 0.6564 - val_loss: 0.8595 - val_acc: 0.7480\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1068 - acc: 0.6586\n",
      "Epoch 00130: val_loss did not improve from 0.85946\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.1069 - acc: 0.6585 - val_loss: 0.8633 - val_acc: 0.7456\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1039 - acc: 0.6579\n",
      "Epoch 00131: val_loss did not improve from 0.85946\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.1038 - acc: 0.6580 - val_loss: 0.8657 - val_acc: 0.7440\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1054 - acc: 0.6572\n",
      "Epoch 00132: val_loss did not improve from 0.85946\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.1053 - acc: 0.6572 - val_loss: 0.8635 - val_acc: 0.7487\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1059 - acc: 0.6576\n",
      "Epoch 00133: val_loss improved from 0.85946 to 0.85597, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/133-0.8560.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1061 - acc: 0.6575 - val_loss: 0.8560 - val_acc: 0.7489\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1009 - acc: 0.6565\n",
      "Epoch 00134: val_loss improved from 0.85597 to 0.85150, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/134-0.8515.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1009 - acc: 0.6565 - val_loss: 0.8515 - val_acc: 0.7498\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1013 - acc: 0.6567\n",
      "Epoch 00135: val_loss did not improve from 0.85150\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.1013 - acc: 0.6567 - val_loss: 0.8589 - val_acc: 0.7510\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0958 - acc: 0.6598\n",
      "Epoch 00136: val_loss did not improve from 0.85150\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.0960 - acc: 0.6598 - val_loss: 0.8533 - val_acc: 0.7501\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0979 - acc: 0.6615\n",
      "Epoch 00137: val_loss improved from 0.85150 to 0.84517, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/137-0.8452.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0979 - acc: 0.6615 - val_loss: 0.8452 - val_acc: 0.7533\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0937 - acc: 0.6612\n",
      "Epoch 00138: val_loss did not improve from 0.84517\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.0938 - acc: 0.6612 - val_loss: 0.8459 - val_acc: 0.7522\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0957 - acc: 0.6575\n",
      "Epoch 00139: val_loss did not improve from 0.84517\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0956 - acc: 0.6575 - val_loss: 0.8543 - val_acc: 0.7503\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0927 - acc: 0.6594\n",
      "Epoch 00140: val_loss did not improve from 0.84517\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0927 - acc: 0.6594 - val_loss: 0.8507 - val_acc: 0.7538\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0932 - acc: 0.6598\n",
      "Epoch 00141: val_loss did not improve from 0.84517\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0931 - acc: 0.6599 - val_loss: 0.8491 - val_acc: 0.7503\n",
      "Epoch 142/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0890 - acc: 0.6618\n",
      "Epoch 00142: val_loss did not improve from 0.84517\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0890 - acc: 0.6618 - val_loss: 0.8486 - val_acc: 0.7526\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0899 - acc: 0.6637\n",
      "Epoch 00143: val_loss did not improve from 0.84517\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0899 - acc: 0.6637 - val_loss: 0.8454 - val_acc: 0.7512\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0923 - acc: 0.6627\n",
      "Epoch 00144: val_loss improved from 0.84517 to 0.84318, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/144-0.8432.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.0924 - acc: 0.6627 - val_loss: 0.8432 - val_acc: 0.7515\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0875 - acc: 0.6635\n",
      "Epoch 00145: val_loss did not improve from 0.84318\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0879 - acc: 0.6634 - val_loss: 0.8486 - val_acc: 0.7559\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0842 - acc: 0.6627\n",
      "Epoch 00146: val_loss improved from 0.84318 to 0.83619, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/146-0.8362.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0842 - acc: 0.6627 - val_loss: 0.8362 - val_acc: 0.7566\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0804 - acc: 0.6636\n",
      "Epoch 00147: val_loss did not improve from 0.83619\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.0804 - acc: 0.6636 - val_loss: 0.8427 - val_acc: 0.7519\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0859 - acc: 0.6633\n",
      "Epoch 00148: val_loss did not improve from 0.83619\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0858 - acc: 0.6633 - val_loss: 0.8372 - val_acc: 0.7510\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0858 - acc: 0.6646\n",
      "Epoch 00149: val_loss did not improve from 0.83619\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0859 - acc: 0.6646 - val_loss: 0.8386 - val_acc: 0.7559\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0843 - acc: 0.6636\n",
      "Epoch 00150: val_loss improved from 0.83619 to 0.83358, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/150-0.8336.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.0843 - acc: 0.6636 - val_loss: 0.8336 - val_acc: 0.7615\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0860 - acc: 0.6643\n",
      "Epoch 00151: val_loss did not improve from 0.83358\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0859 - acc: 0.6643 - val_loss: 0.8369 - val_acc: 0.7554\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0773 - acc: 0.6674\n",
      "Epoch 00152: val_loss improved from 0.83358 to 0.82683, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/152-0.8268.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0775 - acc: 0.6674 - val_loss: 0.8268 - val_acc: 0.7591\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0753 - acc: 0.6679\n",
      "Epoch 00153: val_loss did not improve from 0.82683\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.0752 - acc: 0.6679 - val_loss: 0.8275 - val_acc: 0.7577\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0756 - acc: 0.6664\n",
      "Epoch 00154: val_loss improved from 0.82683 to 0.82603, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/154-0.8260.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.0756 - acc: 0.6664 - val_loss: 0.8260 - val_acc: 0.7603\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0731 - acc: 0.6689\n",
      "Epoch 00155: val_loss improved from 0.82603 to 0.82506, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/155-0.8251.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0730 - acc: 0.6690 - val_loss: 0.8251 - val_acc: 0.7610\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0778 - acc: 0.6677\n",
      "Epoch 00156: val_loss did not improve from 0.82506\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0781 - acc: 0.6677 - val_loss: 0.8369 - val_acc: 0.7570\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0731 - acc: 0.6645\n",
      "Epoch 00157: val_loss improved from 0.82506 to 0.82358, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/157-0.8236.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0732 - acc: 0.6644 - val_loss: 0.8236 - val_acc: 0.7570\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0696 - acc: 0.6685\n",
      "Epoch 00158: val_loss did not improve from 0.82358\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0696 - acc: 0.6685 - val_loss: 0.8253 - val_acc: 0.7647\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0678 - acc: 0.6714\n",
      "Epoch 00159: val_loss improved from 0.82358 to 0.82076, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/159-0.8208.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.0678 - acc: 0.6714 - val_loss: 0.8208 - val_acc: 0.7575\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0646 - acc: 0.6672\n",
      "Epoch 00160: val_loss improved from 0.82076 to 0.81649, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/160-0.8165.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0646 - acc: 0.6672 - val_loss: 0.8165 - val_acc: 0.7570\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0682 - acc: 0.6681\n",
      "Epoch 00161: val_loss did not improve from 0.81649\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0686 - acc: 0.6681 - val_loss: 0.8280 - val_acc: 0.7538\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0640 - acc: 0.6686\n",
      "Epoch 00162: val_loss did not improve from 0.81649\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0641 - acc: 0.6686 - val_loss: 0.8276 - val_acc: 0.7568\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0708 - acc: 0.6706\n",
      "Epoch 00163: val_loss did not improve from 0.81649\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0708 - acc: 0.6706 - val_loss: 0.8238 - val_acc: 0.7575\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0677 - acc: 0.6695\n",
      "Epoch 00164: val_loss improved from 0.81649 to 0.81347, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/164-0.8135.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0676 - acc: 0.6696 - val_loss: 0.8135 - val_acc: 0.7629\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0626 - acc: 0.6701\n",
      "Epoch 00165: val_loss did not improve from 0.81347\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0626 - acc: 0.6701 - val_loss: 0.8155 - val_acc: 0.7624\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0575 - acc: 0.6701\n",
      "Epoch 00166: val_loss improved from 0.81347 to 0.81095, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/166-0.8110.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0576 - acc: 0.6701 - val_loss: 0.8110 - val_acc: 0.7645\n",
      "Epoch 167/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0558 - acc: 0.6708\n",
      "Epoch 00167: val_loss did not improve from 0.81095\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.0557 - acc: 0.6709 - val_loss: 0.8116 - val_acc: 0.7594\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0624 - acc: 0.6703\n",
      "Epoch 00168: val_loss improved from 0.81095 to 0.80620, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/168-0.8062.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.0624 - acc: 0.6704 - val_loss: 0.8062 - val_acc: 0.7652\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0522 - acc: 0.6749\n",
      "Epoch 00169: val_loss did not improve from 0.80620\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0523 - acc: 0.6748 - val_loss: 0.8093 - val_acc: 0.7624\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0595 - acc: 0.6681\n",
      "Epoch 00170: val_loss did not improve from 0.80620\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0595 - acc: 0.6681 - val_loss: 0.8203 - val_acc: 0.7622\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0601 - acc: 0.6749\n",
      "Epoch 00171: val_loss improved from 0.80620 to 0.80297, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/171-0.8030.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.0601 - acc: 0.6749 - val_loss: 0.8030 - val_acc: 0.7689\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0556 - acc: 0.6740\n",
      "Epoch 00172: val_loss did not improve from 0.80297\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.0556 - acc: 0.6740 - val_loss: 0.8060 - val_acc: 0.7624\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0504 - acc: 0.6760\n",
      "Epoch 00173: val_loss did not improve from 0.80297\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.0504 - acc: 0.6759 - val_loss: 0.8061 - val_acc: 0.7659\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0522 - acc: 0.6743\n",
      "Epoch 00174: val_loss improved from 0.80297 to 0.79900, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/174-0.7990.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0521 - acc: 0.6743 - val_loss: 0.7990 - val_acc: 0.7671\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0538 - acc: 0.6742\n",
      "Epoch 00175: val_loss improved from 0.79900 to 0.79844, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/175-0.7984.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0538 - acc: 0.6742 - val_loss: 0.7984 - val_acc: 0.7678\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0473 - acc: 0.6742\n",
      "Epoch 00176: val_loss did not improve from 0.79844\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0472 - acc: 0.6742 - val_loss: 0.8014 - val_acc: 0.7657\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0494 - acc: 0.6744\n",
      "Epoch 00177: val_loss improved from 0.79844 to 0.79435, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/177-0.7943.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.0493 - acc: 0.6744 - val_loss: 0.7943 - val_acc: 0.7699\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0481 - acc: 0.6737\n",
      "Epoch 00178: val_loss did not improve from 0.79435\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.0481 - acc: 0.6737 - val_loss: 0.8020 - val_acc: 0.7664\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0517 - acc: 0.6736\n",
      "Epoch 00179: val_loss did not improve from 0.79435\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.0516 - acc: 0.6736 - val_loss: 0.7999 - val_acc: 0.7657\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0403 - acc: 0.6798\n",
      "Epoch 00180: val_loss improved from 0.79435 to 0.79175, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/180-0.7918.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0404 - acc: 0.6798 - val_loss: 0.7918 - val_acc: 0.7701\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0378 - acc: 0.6785\n",
      "Epoch 00181: val_loss did not improve from 0.79175\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0377 - acc: 0.6786 - val_loss: 0.7968 - val_acc: 0.7650\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0418 - acc: 0.6753\n",
      "Epoch 00182: val_loss did not improve from 0.79175\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0419 - acc: 0.6753 - val_loss: 0.8136 - val_acc: 0.7619\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0440 - acc: 0.6771\n",
      "Epoch 00183: val_loss did not improve from 0.79175\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0440 - acc: 0.6771 - val_loss: 0.8013 - val_acc: 0.7717\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0351 - acc: 0.6778\n",
      "Epoch 00184: val_loss improved from 0.79175 to 0.78789, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/184-0.7879.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.0352 - acc: 0.6778 - val_loss: 0.7879 - val_acc: 0.7745\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0401 - acc: 0.6779\n",
      "Epoch 00185: val_loss did not improve from 0.78789\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 1.0402 - acc: 0.6778 - val_loss: 0.7928 - val_acc: 0.7715\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0357 - acc: 0.6781\n",
      "Epoch 00186: val_loss improved from 0.78789 to 0.78752, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/186-0.7875.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 1.0356 - acc: 0.6782 - val_loss: 0.7875 - val_acc: 0.7720\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0362 - acc: 0.6795\n",
      "Epoch 00187: val_loss improved from 0.78752 to 0.78432, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/187-0.7843.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.0362 - acc: 0.6794 - val_loss: 0.7843 - val_acc: 0.7761\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0403 - acc: 0.6791\n",
      "Epoch 00188: val_loss did not improve from 0.78432\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0403 - acc: 0.6791 - val_loss: 0.7851 - val_acc: 0.7747\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0383 - acc: 0.6810\n",
      "Epoch 00189: val_loss did not improve from 0.78432\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0382 - acc: 0.6810 - val_loss: 0.7877 - val_acc: 0.7708\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0348 - acc: 0.6814\n",
      "Epoch 00190: val_loss improved from 0.78432 to 0.78187, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/190-0.7819.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.0347 - acc: 0.6814 - val_loss: 0.7819 - val_acc: 0.7703\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0307 - acc: 0.6808\n",
      "Epoch 00191: val_loss improved from 0.78187 to 0.78057, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/191-0.7806.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0308 - acc: 0.6807 - val_loss: 0.7806 - val_acc: 0.7729\n",
      "Epoch 192/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0400 - acc: 0.6818\n",
      "Epoch 00192: val_loss did not improve from 0.78057\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0399 - acc: 0.6819 - val_loss: 0.7830 - val_acc: 0.7713\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0262 - acc: 0.6833\n",
      "Epoch 00193: val_loss improved from 0.78057 to 0.77832, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/193-0.7783.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.0262 - acc: 0.6833 - val_loss: 0.7783 - val_acc: 0.7757\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0243 - acc: 0.6833\n",
      "Epoch 00194: val_loss did not improve from 0.77832\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0247 - acc: 0.6833 - val_loss: 0.7788 - val_acc: 0.7745\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0314 - acc: 0.6820\n",
      "Epoch 00195: val_loss did not improve from 0.77832\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0314 - acc: 0.6819 - val_loss: 0.7877 - val_acc: 0.7741\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0275 - acc: 0.6799\n",
      "Epoch 00196: val_loss did not improve from 0.77832\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0275 - acc: 0.6799 - val_loss: 0.7865 - val_acc: 0.7699\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0251 - acc: 0.6806\n",
      "Epoch 00197: val_loss did not improve from 0.77832\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0251 - acc: 0.6806 - val_loss: 0.7799 - val_acc: 0.7754\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0287 - acc: 0.6809\n",
      "Epoch 00198: val_loss did not improve from 0.77832\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 1.0286 - acc: 0.6809 - val_loss: 0.7838 - val_acc: 0.7761\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0208 - acc: 0.6857\n",
      "Epoch 00199: val_loss did not improve from 0.77832\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.0209 - acc: 0.6856 - val_loss: 0.7787 - val_acc: 0.7775\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0286 - acc: 0.6818\n",
      "Epoch 00200: val_loss did not improve from 0.77832\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0285 - acc: 0.6818 - val_loss: 0.7787 - val_acc: 0.7775\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0240 - acc: 0.6836\n",
      "Epoch 00201: val_loss did not improve from 0.77832\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 1.0241 - acc: 0.6836 - val_loss: 0.7787 - val_acc: 0.7771\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0286 - acc: 0.6832\n",
      "Epoch 00202: val_loss did not improve from 0.77832\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.0287 - acc: 0.6831 - val_loss: 0.7789 - val_acc: 0.7731\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0199 - acc: 0.6828\n",
      "Epoch 00203: val_loss improved from 0.77832 to 0.76363, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/203-0.7636.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0199 - acc: 0.6828 - val_loss: 0.7636 - val_acc: 0.7773\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0162 - acc: 0.6844\n",
      "Epoch 00204: val_loss did not improve from 0.76363\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0162 - acc: 0.6844 - val_loss: 0.7655 - val_acc: 0.7808\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0208 - acc: 0.6864\n",
      "Epoch 00205: val_loss did not improve from 0.76363\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0207 - acc: 0.6864 - val_loss: 0.7733 - val_acc: 0.7778\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0152 - acc: 0.6861\n",
      "Epoch 00206: val_loss did not improve from 0.76363\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0152 - acc: 0.6860 - val_loss: 0.7656 - val_acc: 0.7834\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0212 - acc: 0.6848\n",
      "Epoch 00207: val_loss did not improve from 0.76363\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0212 - acc: 0.6848 - val_loss: 0.7700 - val_acc: 0.7799\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0157 - acc: 0.6857\n",
      "Epoch 00208: val_loss did not improve from 0.76363\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0158 - acc: 0.6856 - val_loss: 0.7772 - val_acc: 0.7764\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0152 - acc: 0.6877\n",
      "Epoch 00209: val_loss improved from 0.76363 to 0.76176, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/209-0.7618.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.0152 - acc: 0.6877 - val_loss: 0.7618 - val_acc: 0.7817\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0170 - acc: 0.6858\n",
      "Epoch 00210: val_loss did not improve from 0.76176\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0171 - acc: 0.6857 - val_loss: 0.7629 - val_acc: 0.7850\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0128 - acc: 0.6885\n",
      "Epoch 00211: val_loss did not improve from 0.76176\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 1.0129 - acc: 0.6885 - val_loss: 0.7707 - val_acc: 0.7761\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0148 - acc: 0.6869\n",
      "Epoch 00212: val_loss did not improve from 0.76176\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0148 - acc: 0.6869 - val_loss: 0.7675 - val_acc: 0.7794\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0190 - acc: 0.6836\n",
      "Epoch 00213: val_loss did not improve from 0.76176\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.0190 - acc: 0.6836 - val_loss: 0.7625 - val_acc: 0.7817\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0117 - acc: 0.6890\n",
      "Epoch 00214: val_loss did not improve from 0.76176\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0117 - acc: 0.6891 - val_loss: 0.7670 - val_acc: 0.7836\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0151 - acc: 0.6859\n",
      "Epoch 00215: val_loss did not improve from 0.76176\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0150 - acc: 0.6859 - val_loss: 0.7646 - val_acc: 0.7806\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0026 - acc: 0.6890\n",
      "Epoch 00216: val_loss improved from 0.76176 to 0.75850, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/216-0.7585.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0027 - acc: 0.6890 - val_loss: 0.7585 - val_acc: 0.7822\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0117 - acc: 0.6882\n",
      "Epoch 00217: val_loss improved from 0.75850 to 0.75819, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/217-0.7582.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0116 - acc: 0.6882 - val_loss: 0.7582 - val_acc: 0.7843\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0092 - acc: 0.6878\n",
      "Epoch 00218: val_loss improved from 0.75819 to 0.75486, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/218-0.7549.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0091 - acc: 0.6878 - val_loss: 0.7549 - val_acc: 0.7864\n",
      "Epoch 219/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0038 - acc: 0.6894\n",
      "Epoch 00219: val_loss did not improve from 0.75486\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0038 - acc: 0.6894 - val_loss: 0.7550 - val_acc: 0.7876\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0060 - acc: 0.6906\n",
      "Epoch 00220: val_loss did not improve from 0.75486\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 1.0060 - acc: 0.6906 - val_loss: 0.7584 - val_acc: 0.7836\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0011 - acc: 0.6891\n",
      "Epoch 00221: val_loss improved from 0.75486 to 0.74871, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/221-0.7487.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 1.0011 - acc: 0.6891 - val_loss: 0.7487 - val_acc: 0.7904\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0085 - acc: 0.6882\n",
      "Epoch 00222: val_loss did not improve from 0.74871\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0085 - acc: 0.6882 - val_loss: 0.7640 - val_acc: 0.7817\n",
      "Epoch 223/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0075 - acc: 0.6907\n",
      "Epoch 00223: val_loss did not improve from 0.74871\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0075 - acc: 0.6906 - val_loss: 0.7594 - val_acc: 0.7780\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0052 - acc: 0.6890\n",
      "Epoch 00224: val_loss did not improve from 0.74871\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.0053 - acc: 0.6890 - val_loss: 0.7496 - val_acc: 0.7866\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0014 - acc: 0.6902\n",
      "Epoch 00225: val_loss did not improve from 0.74871\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.0014 - acc: 0.6902 - val_loss: 0.7577 - val_acc: 0.7857\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9940 - acc: 0.6953\n",
      "Epoch 00226: val_loss improved from 0.74871 to 0.74810, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/226-0.7481.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9940 - acc: 0.6953 - val_loss: 0.7481 - val_acc: 0.7848\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0065 - acc: 0.6882\n",
      "Epoch 00227: val_loss improved from 0.74810 to 0.74645, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/227-0.7465.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0064 - acc: 0.6882 - val_loss: 0.7465 - val_acc: 0.7911\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9973 - acc: 0.6922\n",
      "Epoch 00228: val_loss did not improve from 0.74645\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9972 - acc: 0.6923 - val_loss: 0.7473 - val_acc: 0.7866\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9968 - acc: 0.6926\n",
      "Epoch 00229: val_loss did not improve from 0.74645\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9968 - acc: 0.6926 - val_loss: 0.7487 - val_acc: 0.7885\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9998 - acc: 0.6911\n",
      "Epoch 00230: val_loss improved from 0.74645 to 0.73953, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/230-0.7395.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9999 - acc: 0.6911 - val_loss: 0.7395 - val_acc: 0.7925\n",
      "Epoch 231/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9966 - acc: 0.6926\n",
      "Epoch 00231: val_loss did not improve from 0.73953\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9965 - acc: 0.6927 - val_loss: 0.7417 - val_acc: 0.7925\n",
      "Epoch 232/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9975 - acc: 0.6922\n",
      "Epoch 00232: val_loss did not improve from 0.73953\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9975 - acc: 0.6922 - val_loss: 0.7406 - val_acc: 0.7906\n",
      "Epoch 233/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9924 - acc: 0.6946\n",
      "Epoch 00233: val_loss improved from 0.73953 to 0.73703, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/233-0.7370.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9923 - acc: 0.6947 - val_loss: 0.7370 - val_acc: 0.7908\n",
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9928 - acc: 0.6949\n",
      "Epoch 00234: val_loss did not improve from 0.73703\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9928 - acc: 0.6949 - val_loss: 0.7452 - val_acc: 0.7871\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9958 - acc: 0.6942\n",
      "Epoch 00235: val_loss did not improve from 0.73703\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.9958 - acc: 0.6943 - val_loss: 0.7540 - val_acc: 0.7866\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9901 - acc: 0.6938\n",
      "Epoch 00236: val_loss did not improve from 0.73703\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.9901 - acc: 0.6938 - val_loss: 0.7383 - val_acc: 0.7939\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9852 - acc: 0.6950\n",
      "Epoch 00237: val_loss did not improve from 0.73703\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.9852 - acc: 0.6950 - val_loss: 0.7440 - val_acc: 0.7894\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9909 - acc: 0.6938\n",
      "Epoch 00238: val_loss did not improve from 0.73703\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9909 - acc: 0.6937 - val_loss: 0.7401 - val_acc: 0.7929\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9892 - acc: 0.6926\n",
      "Epoch 00239: val_loss did not improve from 0.73703\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9891 - acc: 0.6926 - val_loss: 0.7380 - val_acc: 0.7934\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9902 - acc: 0.6947\n",
      "Epoch 00240: val_loss improved from 0.73703 to 0.73229, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/240-0.7323.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9901 - acc: 0.6947 - val_loss: 0.7323 - val_acc: 0.7913\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9885 - acc: 0.6945\n",
      "Epoch 00241: val_loss did not improve from 0.73229\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9885 - acc: 0.6945 - val_loss: 0.7420 - val_acc: 0.7862\n",
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9854 - acc: 0.6989\n",
      "Epoch 00242: val_loss improved from 0.73229 to 0.72972, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/242-0.7297.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9854 - acc: 0.6988 - val_loss: 0.7297 - val_acc: 0.7955\n",
      "Epoch 243/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9885 - acc: 0.6942\n",
      "Epoch 00243: val_loss improved from 0.72972 to 0.72887, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/243-0.7289.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9885 - acc: 0.6942 - val_loss: 0.7289 - val_acc: 0.7971\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9886 - acc: 0.6964\n",
      "Epoch 00244: val_loss did not improve from 0.72887\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9886 - acc: 0.6964 - val_loss: 0.7417 - val_acc: 0.7927\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9834 - acc: 0.6967\n",
      "Epoch 00245: val_loss did not improve from 0.72887\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9834 - acc: 0.6966 - val_loss: 0.7293 - val_acc: 0.7883\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9910 - acc: 0.6960\n",
      "Epoch 00246: val_loss did not improve from 0.72887\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9912 - acc: 0.6959 - val_loss: 0.7331 - val_acc: 0.7973\n",
      "Epoch 247/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9821 - acc: 0.6970\n",
      "Epoch 00247: val_loss did not improve from 0.72887\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9821 - acc: 0.6970 - val_loss: 0.7383 - val_acc: 0.7890\n",
      "Epoch 248/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9770 - acc: 0.6998\n",
      "Epoch 00248: val_loss improved from 0.72887 to 0.72750, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/248-0.7275.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9770 - acc: 0.6998 - val_loss: 0.7275 - val_acc: 0.7962\n",
      "Epoch 249/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9815 - acc: 0.6970\n",
      "Epoch 00249: val_loss improved from 0.72750 to 0.72418, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/249-0.7242.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.9815 - acc: 0.6970 - val_loss: 0.7242 - val_acc: 0.7976\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9785 - acc: 0.6994\n",
      "Epoch 00250: val_loss did not improve from 0.72418\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9785 - acc: 0.6994 - val_loss: 0.7281 - val_acc: 0.7939\n",
      "Epoch 251/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9783 - acc: 0.6961\n",
      "Epoch 00251: val_loss did not improve from 0.72418\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9785 - acc: 0.6961 - val_loss: 0.7341 - val_acc: 0.7939\n",
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9814 - acc: 0.6992\n",
      "Epoch 00252: val_loss did not improve from 0.72418\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9816 - acc: 0.6991 - val_loss: 0.7286 - val_acc: 0.7985\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9730 - acc: 0.7005\n",
      "Epoch 00253: val_loss did not improve from 0.72418\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9730 - acc: 0.7004 - val_loss: 0.7296 - val_acc: 0.7957\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9799 - acc: 0.6977\n",
      "Epoch 00254: val_loss did not improve from 0.72418\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.9799 - acc: 0.6977 - val_loss: 0.7293 - val_acc: 0.7964\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9744 - acc: 0.6986\n",
      "Epoch 00255: val_loss did not improve from 0.72418\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9743 - acc: 0.6986 - val_loss: 0.7287 - val_acc: 0.7934\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9727 - acc: 0.6995\n",
      "Epoch 00256: val_loss improved from 0.72418 to 0.72026, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/256-0.7203.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9728 - acc: 0.6995 - val_loss: 0.7203 - val_acc: 0.7985\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9698 - acc: 0.7001\n",
      "Epoch 00257: val_loss did not improve from 0.72026\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.9697 - acc: 0.7001 - val_loss: 0.7331 - val_acc: 0.7950\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9721 - acc: 0.7014\n",
      "Epoch 00258: val_loss improved from 0.72026 to 0.71016, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/258-0.7102.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.9720 - acc: 0.7014 - val_loss: 0.7102 - val_acc: 0.8027\n",
      "Epoch 259/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9770 - acc: 0.6991\n",
      "Epoch 00259: val_loss did not improve from 0.71016\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9771 - acc: 0.6991 - val_loss: 0.7144 - val_acc: 0.8013\n",
      "Epoch 260/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9717 - acc: 0.6987\n",
      "Epoch 00260: val_loss did not improve from 0.71016\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9717 - acc: 0.6987 - val_loss: 0.7112 - val_acc: 0.8027\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9696 - acc: 0.7002\n",
      "Epoch 00261: val_loss did not improve from 0.71016\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9696 - acc: 0.7001 - val_loss: 0.7181 - val_acc: 0.7999\n",
      "Epoch 262/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9655 - acc: 0.6995\n",
      "Epoch 00262: val_loss did not improve from 0.71016\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9655 - acc: 0.6996 - val_loss: 0.7158 - val_acc: 0.7966\n",
      "Epoch 263/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9712 - acc: 0.7002\n",
      "Epoch 00263: val_loss did not improve from 0.71016\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9711 - acc: 0.7002 - val_loss: 0.7147 - val_acc: 0.7976\n",
      "Epoch 264/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9630 - acc: 0.7027\n",
      "Epoch 00264: val_loss did not improve from 0.71016\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9630 - acc: 0.7028 - val_loss: 0.7119 - val_acc: 0.8027\n",
      "Epoch 265/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9664 - acc: 0.7028\n",
      "Epoch 00265: val_loss did not improve from 0.71016\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9663 - acc: 0.7028 - val_loss: 0.7193 - val_acc: 0.8036\n",
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9675 - acc: 0.7013\n",
      "Epoch 00266: val_loss did not improve from 0.71016\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9675 - acc: 0.7012 - val_loss: 0.7109 - val_acc: 0.8018\n",
      "Epoch 267/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9661 - acc: 0.7021\n",
      "Epoch 00267: val_loss did not improve from 0.71016\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9661 - acc: 0.7021 - val_loss: 0.7132 - val_acc: 0.8001\n",
      "Epoch 268/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9645 - acc: 0.7033\n",
      "Epoch 00268: val_loss improved from 0.71016 to 0.70983, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/268-0.7098.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9644 - acc: 0.7033 - val_loss: 0.7098 - val_acc: 0.8064\n",
      "Epoch 269/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9676 - acc: 0.7023\n",
      "Epoch 00269: val_loss did not improve from 0.70983\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9676 - acc: 0.7023 - val_loss: 0.7103 - val_acc: 0.8043\n",
      "Epoch 270/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9677 - acc: 0.7025\n",
      "Epoch 00270: val_loss did not improve from 0.70983\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9676 - acc: 0.7025 - val_loss: 0.7130 - val_acc: 0.8036\n",
      "Epoch 271/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9651 - acc: 0.7018\n",
      "Epoch 00271: val_loss did not improve from 0.70983\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9650 - acc: 0.7019 - val_loss: 0.7138 - val_acc: 0.8015\n",
      "Epoch 272/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9590 - acc: 0.7042\n",
      "Epoch 00272: val_loss improved from 0.70983 to 0.70380, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/272-0.7038.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9589 - acc: 0.7042 - val_loss: 0.7038 - val_acc: 0.8034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9637 - acc: 0.7033\n",
      "Epoch 00273: val_loss did not improve from 0.70380\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9638 - acc: 0.7033 - val_loss: 0.7085 - val_acc: 0.8029\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9611 - acc: 0.7040\n",
      "Epoch 00274: val_loss did not improve from 0.70380\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.9611 - acc: 0.7040 - val_loss: 0.7048 - val_acc: 0.8064\n",
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9643 - acc: 0.7039\n",
      "Epoch 00275: val_loss did not improve from 0.70380\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.9642 - acc: 0.7040 - val_loss: 0.7053 - val_acc: 0.8069\n",
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9591 - acc: 0.7042\n",
      "Epoch 00276: val_loss did not improve from 0.70380\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 0.9593 - acc: 0.7041 - val_loss: 0.7137 - val_acc: 0.8055\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9631 - acc: 0.7033\n",
      "Epoch 00277: val_loss did not improve from 0.70380\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 0.9631 - acc: 0.7033 - val_loss: 0.7077 - val_acc: 0.8018\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9589 - acc: 0.7064\n",
      "Epoch 00278: val_loss did not improve from 0.70380\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.9589 - acc: 0.7064 - val_loss: 0.7067 - val_acc: 0.8041\n",
      "Epoch 279/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9556 - acc: 0.7049\n",
      "Epoch 00279: val_loss improved from 0.70380 to 0.70097, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/279-0.7010.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9555 - acc: 0.7050 - val_loss: 0.7010 - val_acc: 0.8036\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9520 - acc: 0.7077\n",
      "Epoch 00280: val_loss did not improve from 0.70097\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9520 - acc: 0.7077 - val_loss: 0.7015 - val_acc: 0.8064\n",
      "Epoch 281/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9582 - acc: 0.7053\n",
      "Epoch 00281: val_loss did not improve from 0.70097\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9582 - acc: 0.7053 - val_loss: 0.7076 - val_acc: 0.8004\n",
      "Epoch 282/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9561 - acc: 0.7048\n",
      "Epoch 00282: val_loss improved from 0.70097 to 0.69929, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/282-0.6993.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9561 - acc: 0.7048 - val_loss: 0.6993 - val_acc: 0.8076\n",
      "Epoch 283/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9593 - acc: 0.7040\n",
      "Epoch 00283: val_loss did not improve from 0.69929\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9593 - acc: 0.7039 - val_loss: 0.7133 - val_acc: 0.8013\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9478 - acc: 0.7085\n",
      "Epoch 00284: val_loss improved from 0.69929 to 0.69923, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/284-0.6992.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9478 - acc: 0.7084 - val_loss: 0.6992 - val_acc: 0.8050\n",
      "Epoch 285/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9520 - acc: 0.7070\n",
      "Epoch 00285: val_loss improved from 0.69923 to 0.69325, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/285-0.6932.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9520 - acc: 0.7069 - val_loss: 0.6932 - val_acc: 0.8069\n",
      "Epoch 286/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9555 - acc: 0.7019\n",
      "Epoch 00286: val_loss did not improve from 0.69325\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9555 - acc: 0.7019 - val_loss: 0.6972 - val_acc: 0.8071\n",
      "Epoch 287/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9506 - acc: 0.7078\n",
      "Epoch 00287: val_loss did not improve from 0.69325\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9506 - acc: 0.7077 - val_loss: 0.6964 - val_acc: 0.8060\n",
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9481 - acc: 0.7099\n",
      "Epoch 00288: val_loss did not improve from 0.69325\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9481 - acc: 0.7100 - val_loss: 0.6991 - val_acc: 0.8048\n",
      "Epoch 289/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9566 - acc: 0.7040\n",
      "Epoch 00289: val_loss did not improve from 0.69325\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9567 - acc: 0.7040 - val_loss: 0.7022 - val_acc: 0.8046\n",
      "Epoch 290/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9492 - acc: 0.7091\n",
      "Epoch 00290: val_loss did not improve from 0.69325\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9491 - acc: 0.7091 - val_loss: 0.6937 - val_acc: 0.8055\n",
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9569 - acc: 0.7062\n",
      "Epoch 00291: val_loss did not improve from 0.69325\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9568 - acc: 0.7063 - val_loss: 0.7030 - val_acc: 0.8050\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9513 - acc: 0.7076\n",
      "Epoch 00292: val_loss did not improve from 0.69325\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9512 - acc: 0.7076 - val_loss: 0.6942 - val_acc: 0.8104\n",
      "Epoch 293/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9510 - acc: 0.7102\n",
      "Epoch 00293: val_loss did not improve from 0.69325\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9509 - acc: 0.7102 - val_loss: 0.6963 - val_acc: 0.8088\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9472 - acc: 0.7076\n",
      "Epoch 00294: val_loss did not improve from 0.69325\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9471 - acc: 0.7076 - val_loss: 0.6943 - val_acc: 0.8076\n",
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9480 - acc: 0.7079\n",
      "Epoch 00295: val_loss improved from 0.69325 to 0.68949, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/295-0.6895.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.9480 - acc: 0.7079 - val_loss: 0.6895 - val_acc: 0.8116\n",
      "Epoch 296/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9448 - acc: 0.7099\n",
      "Epoch 00296: val_loss did not improve from 0.68949\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9447 - acc: 0.7100 - val_loss: 0.6948 - val_acc: 0.8069\n",
      "Epoch 297/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9419 - acc: 0.7104\n",
      "Epoch 00297: val_loss did not improve from 0.68949\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9418 - acc: 0.7104 - val_loss: 0.6963 - val_acc: 0.8071\n",
      "Epoch 298/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9462 - acc: 0.7083\n",
      "Epoch 00298: val_loss did not improve from 0.68949\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9461 - acc: 0.7083 - val_loss: 0.6901 - val_acc: 0.8067\n",
      "Epoch 299/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9473 - acc: 0.7094\n",
      "Epoch 00299: val_loss did not improve from 0.68949\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9473 - acc: 0.7093 - val_loss: 0.6932 - val_acc: 0.8137\n",
      "Epoch 300/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9452 - acc: 0.7068\n",
      "Epoch 00300: val_loss did not improve from 0.68949\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9453 - acc: 0.7068 - val_loss: 0.6904 - val_acc: 0.8055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 301/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9407 - acc: 0.7105\n",
      "Epoch 00301: val_loss improved from 0.68949 to 0.68930, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/301-0.6893.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9407 - acc: 0.7105 - val_loss: 0.6893 - val_acc: 0.8109\n",
      "Epoch 302/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9395 - acc: 0.7122\n",
      "Epoch 00302: val_loss improved from 0.68930 to 0.68887, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/302-0.6889.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9395 - acc: 0.7122 - val_loss: 0.6889 - val_acc: 0.8111\n",
      "Epoch 303/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9408 - acc: 0.7109\n",
      "Epoch 00303: val_loss improved from 0.68887 to 0.68705, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/303-0.6871.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.9408 - acc: 0.7109 - val_loss: 0.6871 - val_acc: 0.8111\n",
      "Epoch 304/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9444 - acc: 0.7124\n",
      "Epoch 00304: val_loss improved from 0.68705 to 0.68536, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/304-0.6854.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.9443 - acc: 0.7125 - val_loss: 0.6854 - val_acc: 0.8116\n",
      "Epoch 305/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9458 - acc: 0.7093\n",
      "Epoch 00305: val_loss improved from 0.68536 to 0.68308, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/305-0.6831.hdf5\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.9458 - acc: 0.7093 - val_loss: 0.6831 - val_acc: 0.8120\n",
      "Epoch 306/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9430 - acc: 0.7103\n",
      "Epoch 00306: val_loss did not improve from 0.68308\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9430 - acc: 0.7103 - val_loss: 0.6923 - val_acc: 0.8060\n",
      "Epoch 307/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9357 - acc: 0.7126\n",
      "Epoch 00307: val_loss did not improve from 0.68308\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9357 - acc: 0.7126 - val_loss: 0.6894 - val_acc: 0.8095\n",
      "Epoch 308/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9435 - acc: 0.7112\n",
      "Epoch 00308: val_loss improved from 0.68308 to 0.68300, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/308-0.6830.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.9436 - acc: 0.7112 - val_loss: 0.6830 - val_acc: 0.8125\n",
      "Epoch 309/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9369 - acc: 0.7138\n",
      "Epoch 00309: val_loss did not improve from 0.68300\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9369 - acc: 0.7138 - val_loss: 0.6976 - val_acc: 0.8027\n",
      "Epoch 310/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9434 - acc: 0.7105\n",
      "Epoch 00310: val_loss improved from 0.68300 to 0.68107, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/310-0.6811.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9435 - acc: 0.7104 - val_loss: 0.6811 - val_acc: 0.8109\n",
      "Epoch 311/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9385 - acc: 0.7118\n",
      "Epoch 00311: val_loss improved from 0.68107 to 0.67954, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/311-0.6795.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.9385 - acc: 0.7118 - val_loss: 0.6795 - val_acc: 0.8130\n",
      "Epoch 312/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9370 - acc: 0.7116\n",
      "Epoch 00312: val_loss did not improve from 0.67954\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9371 - acc: 0.7116 - val_loss: 0.6908 - val_acc: 0.8111\n",
      "Epoch 313/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9342 - acc: 0.7102\n",
      "Epoch 00313: val_loss improved from 0.67954 to 0.67525, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/313-0.6753.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.9341 - acc: 0.7102 - val_loss: 0.6753 - val_acc: 0.8143\n",
      "Epoch 314/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9369 - acc: 0.7123\n",
      "Epoch 00314: val_loss improved from 0.67525 to 0.67328, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/314-0.6733.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.9368 - acc: 0.7122 - val_loss: 0.6733 - val_acc: 0.8141\n",
      "Epoch 315/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9316 - acc: 0.7139\n",
      "Epoch 00315: val_loss did not improve from 0.67328\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9316 - acc: 0.7139 - val_loss: 0.6850 - val_acc: 0.8097\n",
      "Epoch 316/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9358 - acc: 0.7132\n",
      "Epoch 00316: val_loss did not improve from 0.67328\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.9357 - acc: 0.7132 - val_loss: 0.6770 - val_acc: 0.8148\n",
      "Epoch 317/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9305 - acc: 0.7145\n",
      "Epoch 00317: val_loss did not improve from 0.67328\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9304 - acc: 0.7145 - val_loss: 0.6773 - val_acc: 0.8127\n",
      "Epoch 318/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9352 - acc: 0.7112\n",
      "Epoch 00318: val_loss did not improve from 0.67328\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9351 - acc: 0.7112 - val_loss: 0.6790 - val_acc: 0.8130\n",
      "Epoch 319/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9272 - acc: 0.7160\n",
      "Epoch 00319: val_loss improved from 0.67328 to 0.66842, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/319-0.6684.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9272 - acc: 0.7160 - val_loss: 0.6684 - val_acc: 0.8181\n",
      "Epoch 320/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9279 - acc: 0.7123\n",
      "Epoch 00320: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9279 - acc: 0.7123 - val_loss: 0.6743 - val_acc: 0.8174\n",
      "Epoch 321/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9381 - acc: 0.7102\n",
      "Epoch 00321: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.9382 - acc: 0.7102 - val_loss: 0.6725 - val_acc: 0.8202\n",
      "Epoch 322/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9367 - acc: 0.7119\n",
      "Epoch 00322: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9366 - acc: 0.7119 - val_loss: 0.6708 - val_acc: 0.8146\n",
      "Epoch 323/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9262 - acc: 0.7145\n",
      "Epoch 00323: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9262 - acc: 0.7145 - val_loss: 0.6727 - val_acc: 0.8174\n",
      "Epoch 324/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9307 - acc: 0.7143\n",
      "Epoch 00324: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9307 - acc: 0.7143 - val_loss: 0.6782 - val_acc: 0.8157\n",
      "Epoch 325/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9328 - acc: 0.7123\n",
      "Epoch 00325: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9329 - acc: 0.7123 - val_loss: 0.6753 - val_acc: 0.8148\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9350 - acc: 0.7119\n",
      "Epoch 00326: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9350 - acc: 0.7119 - val_loss: 0.6757 - val_acc: 0.8153\n",
      "Epoch 327/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9312 - acc: 0.7169\n",
      "Epoch 00327: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9313 - acc: 0.7169 - val_loss: 0.6712 - val_acc: 0.8157\n",
      "Epoch 328/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9260 - acc: 0.7150\n",
      "Epoch 00328: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9260 - acc: 0.7150 - val_loss: 0.6760 - val_acc: 0.8132\n",
      "Epoch 329/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9269 - acc: 0.7174\n",
      "Epoch 00329: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9269 - acc: 0.7174 - val_loss: 0.6715 - val_acc: 0.8141\n",
      "Epoch 330/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9253 - acc: 0.7169\n",
      "Epoch 00330: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9253 - acc: 0.7169 - val_loss: 0.6712 - val_acc: 0.8171\n",
      "Epoch 331/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9229 - acc: 0.7186\n",
      "Epoch 00331: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.9228 - acc: 0.7187 - val_loss: 0.6711 - val_acc: 0.8116\n",
      "Epoch 332/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9236 - acc: 0.7158\n",
      "Epoch 00332: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.9236 - acc: 0.7157 - val_loss: 0.6738 - val_acc: 0.8143\n",
      "Epoch 333/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9290 - acc: 0.7129\n",
      "Epoch 00333: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.9290 - acc: 0.7129 - val_loss: 0.6820 - val_acc: 0.8113\n",
      "Epoch 334/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9246 - acc: 0.7167\n",
      "Epoch 00334: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9246 - acc: 0.7168 - val_loss: 0.6774 - val_acc: 0.8141\n",
      "Epoch 335/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9260 - acc: 0.7188\n",
      "Epoch 00335: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9259 - acc: 0.7188 - val_loss: 0.6759 - val_acc: 0.8141\n",
      "Epoch 336/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9223 - acc: 0.7168\n",
      "Epoch 00336: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9224 - acc: 0.7168 - val_loss: 0.6778 - val_acc: 0.8137\n",
      "Epoch 337/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9231 - acc: 0.7161\n",
      "Epoch 00337: val_loss did not improve from 0.66842\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9231 - acc: 0.7161 - val_loss: 0.6751 - val_acc: 0.8174\n",
      "Epoch 338/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9239 - acc: 0.7166\n",
      "Epoch 00338: val_loss improved from 0.66842 to 0.66493, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/338-0.6649.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9239 - acc: 0.7166 - val_loss: 0.6649 - val_acc: 0.8183\n",
      "Epoch 339/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9173 - acc: 0.7175\n",
      "Epoch 00339: val_loss improved from 0.66493 to 0.65831, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/339-0.6583.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9173 - acc: 0.7175 - val_loss: 0.6583 - val_acc: 0.8192\n",
      "Epoch 340/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9196 - acc: 0.7176\n",
      "Epoch 00340: val_loss did not improve from 0.65831\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9196 - acc: 0.7176 - val_loss: 0.6673 - val_acc: 0.8167\n",
      "Epoch 341/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9181 - acc: 0.7196\n",
      "Epoch 00341: val_loss did not improve from 0.65831\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9181 - acc: 0.7196 - val_loss: 0.6734 - val_acc: 0.8125\n",
      "Epoch 342/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9224 - acc: 0.7184\n",
      "Epoch 00342: val_loss did not improve from 0.65831\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9224 - acc: 0.7184 - val_loss: 0.6586 - val_acc: 0.8195\n",
      "Epoch 343/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9194 - acc: 0.7192\n",
      "Epoch 00343: val_loss did not improve from 0.65831\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9193 - acc: 0.7193 - val_loss: 0.6603 - val_acc: 0.8206\n",
      "Epoch 344/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9182 - acc: 0.7170\n",
      "Epoch 00344: val_loss improved from 0.65831 to 0.65811, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/344-0.6581.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9181 - acc: 0.7170 - val_loss: 0.6581 - val_acc: 0.8195\n",
      "Epoch 345/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9192 - acc: 0.7165\n",
      "Epoch 00345: val_loss did not improve from 0.65811\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9192 - acc: 0.7165 - val_loss: 0.6666 - val_acc: 0.8146\n",
      "Epoch 346/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9126 - acc: 0.7168\n",
      "Epoch 00346: val_loss improved from 0.65811 to 0.65257, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/346-0.6526.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9127 - acc: 0.7168 - val_loss: 0.6526 - val_acc: 0.8232\n",
      "Epoch 347/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9115 - acc: 0.7195\n",
      "Epoch 00347: val_loss did not improve from 0.65257\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9115 - acc: 0.7195 - val_loss: 0.6581 - val_acc: 0.8202\n",
      "Epoch 348/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9145 - acc: 0.7183\n",
      "Epoch 00348: val_loss did not improve from 0.65257\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.9147 - acc: 0.7182 - val_loss: 0.6637 - val_acc: 0.8188\n",
      "Epoch 349/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9162 - acc: 0.7200\n",
      "Epoch 00349: val_loss did not improve from 0.65257\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9162 - acc: 0.7200 - val_loss: 0.6580 - val_acc: 0.8176\n",
      "Epoch 350/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9240 - acc: 0.7173\n",
      "Epoch 00350: val_loss did not improve from 0.65257\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9241 - acc: 0.7173 - val_loss: 0.6657 - val_acc: 0.8153\n",
      "Epoch 351/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9066 - acc: 0.7219\n",
      "Epoch 00351: val_loss did not improve from 0.65257\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.9065 - acc: 0.7219 - val_loss: 0.6579 - val_acc: 0.8213\n",
      "Epoch 352/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9144 - acc: 0.7184\n",
      "Epoch 00352: val_loss did not improve from 0.65257\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9143 - acc: 0.7184 - val_loss: 0.6562 - val_acc: 0.8204\n",
      "Epoch 353/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9130 - acc: 0.7195\n",
      "Epoch 00353: val_loss did not improve from 0.65257\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9130 - acc: 0.7195 - val_loss: 0.6624 - val_acc: 0.8171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 354/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9062 - acc: 0.7221\n",
      "Epoch 00354: val_loss did not improve from 0.65257\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9062 - acc: 0.7220 - val_loss: 0.6579 - val_acc: 0.8218\n",
      "Epoch 355/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9159 - acc: 0.7201\n",
      "Epoch 00355: val_loss did not improve from 0.65257\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9159 - acc: 0.7201 - val_loss: 0.6601 - val_acc: 0.8183\n",
      "Epoch 356/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9179 - acc: 0.7181\n",
      "Epoch 00356: val_loss improved from 0.65257 to 0.65051, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/356-0.6505.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9178 - acc: 0.7181 - val_loss: 0.6505 - val_acc: 0.8234\n",
      "Epoch 357/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9113 - acc: 0.7228\n",
      "Epoch 00357: val_loss did not improve from 0.65051\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9113 - acc: 0.7228 - val_loss: 0.6536 - val_acc: 0.8197\n",
      "Epoch 358/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9097 - acc: 0.7233\n",
      "Epoch 00358: val_loss improved from 0.65051 to 0.64903, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/358-0.6490.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9098 - acc: 0.7232 - val_loss: 0.6490 - val_acc: 0.8213\n",
      "Epoch 359/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9109 - acc: 0.7195\n",
      "Epoch 00359: val_loss did not improve from 0.64903\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9108 - acc: 0.7195 - val_loss: 0.6503 - val_acc: 0.8218\n",
      "Epoch 360/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9099 - acc: 0.7237\n",
      "Epoch 00360: val_loss did not improve from 0.64903\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9099 - acc: 0.7237 - val_loss: 0.6592 - val_acc: 0.8176\n",
      "Epoch 361/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9150 - acc: 0.7186\n",
      "Epoch 00361: val_loss did not improve from 0.64903\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9150 - acc: 0.7186 - val_loss: 0.6555 - val_acc: 0.8185\n",
      "Epoch 362/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9081 - acc: 0.7206\n",
      "Epoch 00362: val_loss did not improve from 0.64903\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9081 - acc: 0.7206 - val_loss: 0.6549 - val_acc: 0.8197\n",
      "Epoch 363/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9078 - acc: 0.7211\n",
      "Epoch 00363: val_loss did not improve from 0.64903\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9079 - acc: 0.7210 - val_loss: 0.6722 - val_acc: 0.8160\n",
      "Epoch 364/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9136 - acc: 0.7207\n",
      "Epoch 00364: val_loss did not improve from 0.64903\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9135 - acc: 0.7208 - val_loss: 0.6524 - val_acc: 0.8218\n",
      "Epoch 365/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9111 - acc: 0.7205\n",
      "Epoch 00365: val_loss did not improve from 0.64903\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9110 - acc: 0.7205 - val_loss: 0.6496 - val_acc: 0.8195\n",
      "Epoch 366/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9054 - acc: 0.7222\n",
      "Epoch 00366: val_loss did not improve from 0.64903\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9055 - acc: 0.7222 - val_loss: 0.6553 - val_acc: 0.8225\n",
      "Epoch 367/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9079 - acc: 0.7227\n",
      "Epoch 00367: val_loss did not improve from 0.64903\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9079 - acc: 0.7227 - val_loss: 0.6508 - val_acc: 0.8202\n",
      "Epoch 368/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9025 - acc: 0.7259\n",
      "Epoch 00368: val_loss did not improve from 0.64903\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9027 - acc: 0.7259 - val_loss: 0.6498 - val_acc: 0.8190\n",
      "Epoch 369/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9059 - acc: 0.7232\n",
      "Epoch 00369: val_loss improved from 0.64903 to 0.64803, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/369-0.6480.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9059 - acc: 0.7232 - val_loss: 0.6480 - val_acc: 0.8204\n",
      "Epoch 370/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8992 - acc: 0.7237\n",
      "Epoch 00370: val_loss did not improve from 0.64803\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.8992 - acc: 0.7238 - val_loss: 0.6528 - val_acc: 0.8211\n",
      "Epoch 371/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9048 - acc: 0.7240\n",
      "Epoch 00371: val_loss did not improve from 0.64803\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9048 - acc: 0.7241 - val_loss: 0.6502 - val_acc: 0.8237\n",
      "Epoch 372/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8994 - acc: 0.7246\n",
      "Epoch 00372: val_loss improved from 0.64803 to 0.64627, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/372-0.6463.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.8993 - acc: 0.7246 - val_loss: 0.6463 - val_acc: 0.8248\n",
      "Epoch 373/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9017 - acc: 0.7243\n",
      "Epoch 00373: val_loss improved from 0.64627 to 0.64308, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/373-0.6431.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.9018 - acc: 0.7243 - val_loss: 0.6431 - val_acc: 0.8192\n",
      "Epoch 374/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9029 - acc: 0.7221\n",
      "Epoch 00374: val_loss did not improve from 0.64308\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.9029 - acc: 0.7221 - val_loss: 0.6453 - val_acc: 0.8223\n",
      "Epoch 375/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9075 - acc: 0.7257\n",
      "Epoch 00375: val_loss did not improve from 0.64308\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9074 - acc: 0.7256 - val_loss: 0.6596 - val_acc: 0.8223\n",
      "Epoch 376/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9075 - acc: 0.7229\n",
      "Epoch 00376: val_loss did not improve from 0.64308\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9075 - acc: 0.7229 - val_loss: 0.6502 - val_acc: 0.8183\n",
      "Epoch 377/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9019 - acc: 0.7220\n",
      "Epoch 00377: val_loss did not improve from 0.64308\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.9019 - acc: 0.7220 - val_loss: 0.6439 - val_acc: 0.8269\n",
      "Epoch 378/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9017 - acc: 0.7229\n",
      "Epoch 00378: val_loss did not improve from 0.64308\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9017 - acc: 0.7228 - val_loss: 0.6431 - val_acc: 0.8237\n",
      "Epoch 379/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9061 - acc: 0.7213\n",
      "Epoch 00379: val_loss improved from 0.64308 to 0.64154, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/379-0.6415.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9060 - acc: 0.7213 - val_loss: 0.6415 - val_acc: 0.8260\n",
      "Epoch 380/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9066 - acc: 0.7216\n",
      "Epoch 00380: val_loss improved from 0.64154 to 0.63918, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/380-0.6392.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9066 - acc: 0.7216 - val_loss: 0.6392 - val_acc: 0.8244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9030 - acc: 0.7258\n",
      "Epoch 00381: val_loss did not improve from 0.63918\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9030 - acc: 0.7258 - val_loss: 0.6403 - val_acc: 0.8253\n",
      "Epoch 382/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9005 - acc: 0.7246\n",
      "Epoch 00382: val_loss did not improve from 0.63918\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.9006 - acc: 0.7245 - val_loss: 0.6445 - val_acc: 0.8246\n",
      "Epoch 383/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9005 - acc: 0.7235\n",
      "Epoch 00383: val_loss improved from 0.63918 to 0.63898, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/383-0.6390.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.9004 - acc: 0.7235 - val_loss: 0.6390 - val_acc: 0.8269\n",
      "Epoch 384/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9017 - acc: 0.7256\n",
      "Epoch 00384: val_loss did not improve from 0.63898\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9017 - acc: 0.7256 - val_loss: 0.6446 - val_acc: 0.8248\n",
      "Epoch 385/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9022 - acc: 0.7248\n",
      "Epoch 00385: val_loss did not improve from 0.63898\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.9021 - acc: 0.7248 - val_loss: 0.6443 - val_acc: 0.8260\n",
      "Epoch 386/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8936 - acc: 0.7264\n",
      "Epoch 00386: val_loss did not improve from 0.63898\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8936 - acc: 0.7265 - val_loss: 0.6432 - val_acc: 0.8234\n",
      "Epoch 387/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9008 - acc: 0.7227\n",
      "Epoch 00387: val_loss did not improve from 0.63898\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9008 - acc: 0.7228 - val_loss: 0.6431 - val_acc: 0.8248\n",
      "Epoch 388/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9042 - acc: 0.7258\n",
      "Epoch 00388: val_loss did not improve from 0.63898\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.9042 - acc: 0.7257 - val_loss: 0.6399 - val_acc: 0.8262\n",
      "Epoch 389/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9044 - acc: 0.7231\n",
      "Epoch 00389: val_loss did not improve from 0.63898\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.9043 - acc: 0.7231 - val_loss: 0.6427 - val_acc: 0.8248\n",
      "Epoch 390/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8987 - acc: 0.7238\n",
      "Epoch 00390: val_loss improved from 0.63898 to 0.63478, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/390-0.6348.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 0.8986 - acc: 0.7238 - val_loss: 0.6348 - val_acc: 0.8283\n",
      "Epoch 391/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8972 - acc: 0.7249\n",
      "Epoch 00391: val_loss improved from 0.63478 to 0.63395, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/391-0.6339.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8971 - acc: 0.7250 - val_loss: 0.6339 - val_acc: 0.8290\n",
      "Epoch 392/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8927 - acc: 0.7268\n",
      "Epoch 00392: val_loss did not improve from 0.63395\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8927 - acc: 0.7269 - val_loss: 0.6411 - val_acc: 0.8253\n",
      "Epoch 393/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8921 - acc: 0.7256\n",
      "Epoch 00393: val_loss did not improve from 0.63395\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 0.8922 - acc: 0.7256 - val_loss: 0.6356 - val_acc: 0.8265\n",
      "Epoch 394/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8946 - acc: 0.7293\n",
      "Epoch 00394: val_loss did not improve from 0.63395\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.8946 - acc: 0.7293 - val_loss: 0.6434 - val_acc: 0.8227\n",
      "Epoch 395/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8932 - acc: 0.7262\n",
      "Epoch 00395: val_loss improved from 0.63395 to 0.63257, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/395-0.6326.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8932 - acc: 0.7262 - val_loss: 0.6326 - val_acc: 0.8300\n",
      "Epoch 396/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8948 - acc: 0.7261\n",
      "Epoch 00396: val_loss did not improve from 0.63257\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.8948 - acc: 0.7261 - val_loss: 0.6475 - val_acc: 0.8220\n",
      "Epoch 397/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8984 - acc: 0.7245\n",
      "Epoch 00397: val_loss did not improve from 0.63257\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.8984 - acc: 0.7244 - val_loss: 0.6358 - val_acc: 0.8274\n",
      "Epoch 398/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8891 - acc: 0.7255\n",
      "Epoch 00398: val_loss improved from 0.63257 to 0.63170, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/398-0.6317.hdf5\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.8891 - acc: 0.7255 - val_loss: 0.6317 - val_acc: 0.8290\n",
      "Epoch 399/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8913 - acc: 0.7290\n",
      "Epoch 00399: val_loss did not improve from 0.63170\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.8913 - acc: 0.7291 - val_loss: 0.6360 - val_acc: 0.8251\n",
      "Epoch 400/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8974 - acc: 0.7247\n",
      "Epoch 00400: val_loss did not improve from 0.63170\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.8975 - acc: 0.7247 - val_loss: 0.6414 - val_acc: 0.8234\n",
      "Epoch 401/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8860 - acc: 0.7295\n",
      "Epoch 00401: val_loss did not improve from 0.63170\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.8860 - acc: 0.7295 - val_loss: 0.6333 - val_acc: 0.8281\n",
      "Epoch 402/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8913 - acc: 0.7256\n",
      "Epoch 00402: val_loss improved from 0.63170 to 0.63069, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/402-0.6307.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.8913 - acc: 0.7256 - val_loss: 0.6307 - val_acc: 0.8309\n",
      "Epoch 403/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8897 - acc: 0.7268\n",
      "Epoch 00403: val_loss did not improve from 0.63069\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.8898 - acc: 0.7268 - val_loss: 0.6353 - val_acc: 0.8253\n",
      "Epoch 404/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8890 - acc: 0.7298\n",
      "Epoch 00404: val_loss did not improve from 0.63069\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8889 - acc: 0.7298 - val_loss: 0.6362 - val_acc: 0.8260\n",
      "Epoch 405/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8873 - acc: 0.7284\n",
      "Epoch 00405: val_loss did not improve from 0.63069\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8873 - acc: 0.7284 - val_loss: 0.6345 - val_acc: 0.8286\n",
      "Epoch 406/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8949 - acc: 0.7287\n",
      "Epoch 00406: val_loss did not improve from 0.63069\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8949 - acc: 0.7287 - val_loss: 0.6343 - val_acc: 0.8295\n",
      "Epoch 407/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8888 - acc: 0.7271\n",
      "Epoch 00407: val_loss did not improve from 0.63069\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8888 - acc: 0.7271 - val_loss: 0.6503 - val_acc: 0.8218\n",
      "Epoch 408/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8939 - acc: 0.7249\n",
      "Epoch 00408: val_loss did not improve from 0.63069\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.8939 - acc: 0.7249 - val_loss: 0.6350 - val_acc: 0.8251\n",
      "Epoch 409/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8864 - acc: 0.7290\n",
      "Epoch 00409: val_loss did not improve from 0.63069\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.8864 - acc: 0.7291 - val_loss: 0.6310 - val_acc: 0.8293\n",
      "Epoch 410/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8801 - acc: 0.7291\n",
      "Epoch 00410: val_loss improved from 0.63069 to 0.62982, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/410-0.6298.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8802 - acc: 0.7291 - val_loss: 0.6298 - val_acc: 0.8246\n",
      "Epoch 411/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8818 - acc: 0.7291\n",
      "Epoch 00411: val_loss improved from 0.62982 to 0.62684, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/411-0.6268.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8819 - acc: 0.7291 - val_loss: 0.6268 - val_acc: 0.8302\n",
      "Epoch 412/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8876 - acc: 0.7298\n",
      "Epoch 00412: val_loss did not improve from 0.62684\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8876 - acc: 0.7298 - val_loss: 0.6357 - val_acc: 0.8244\n",
      "Epoch 413/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8882 - acc: 0.7277\n",
      "Epoch 00413: val_loss did not improve from 0.62684\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8881 - acc: 0.7278 - val_loss: 0.6302 - val_acc: 0.8274\n",
      "Epoch 414/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8894 - acc: 0.7295\n",
      "Epoch 00414: val_loss improved from 0.62684 to 0.62658, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/414-0.6266.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.8894 - acc: 0.7294 - val_loss: 0.6266 - val_acc: 0.8302\n",
      "Epoch 415/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8909 - acc: 0.7291\n",
      "Epoch 00415: val_loss did not improve from 0.62658\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8909 - acc: 0.7291 - val_loss: 0.6387 - val_acc: 0.8251\n",
      "Epoch 416/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8835 - acc: 0.7293\n",
      "Epoch 00416: val_loss did not improve from 0.62658\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.8835 - acc: 0.7293 - val_loss: 0.6267 - val_acc: 0.8297\n",
      "Epoch 417/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8900 - acc: 0.7278\n",
      "Epoch 00417: val_loss did not improve from 0.62658\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8902 - acc: 0.7278 - val_loss: 0.6305 - val_acc: 0.8274\n",
      "Epoch 418/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8866 - acc: 0.7292\n",
      "Epoch 00418: val_loss did not improve from 0.62658\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8867 - acc: 0.7292 - val_loss: 0.6315 - val_acc: 0.8279\n",
      "Epoch 419/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8891 - acc: 0.7272\n",
      "Epoch 00419: val_loss did not improve from 0.62658\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8895 - acc: 0.7272 - val_loss: 0.6345 - val_acc: 0.8223\n",
      "Epoch 420/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8779 - acc: 0.7288\n",
      "Epoch 00420: val_loss improved from 0.62658 to 0.62435, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/420-0.6244.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8778 - acc: 0.7288 - val_loss: 0.6244 - val_acc: 0.8309\n",
      "Epoch 421/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8784 - acc: 0.7313\n",
      "Epoch 00421: val_loss did not improve from 0.62435\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8784 - acc: 0.7313 - val_loss: 0.6322 - val_acc: 0.8279\n",
      "Epoch 422/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8857 - acc: 0.7309\n",
      "Epoch 00422: val_loss did not improve from 0.62435\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.8857 - acc: 0.7310 - val_loss: 0.6294 - val_acc: 0.8297\n",
      "Epoch 423/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8720 - acc: 0.7347\n",
      "Epoch 00423: val_loss did not improve from 0.62435\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8719 - acc: 0.7347 - val_loss: 0.6284 - val_acc: 0.8302\n",
      "Epoch 424/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8803 - acc: 0.7326\n",
      "Epoch 00424: val_loss did not improve from 0.62435\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8803 - acc: 0.7326 - val_loss: 0.6259 - val_acc: 0.8311\n",
      "Epoch 425/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8811 - acc: 0.7303\n",
      "Epoch 00425: val_loss improved from 0.62435 to 0.62046, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/425-0.6205.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.8812 - acc: 0.7302 - val_loss: 0.6205 - val_acc: 0.8297\n",
      "Epoch 426/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8869 - acc: 0.7296\n",
      "Epoch 00426: val_loss did not improve from 0.62046\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.8868 - acc: 0.7296 - val_loss: 0.6450 - val_acc: 0.8234\n",
      "Epoch 427/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8849 - acc: 0.7297\n",
      "Epoch 00427: val_loss did not improve from 0.62046\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8849 - acc: 0.7297 - val_loss: 0.6312 - val_acc: 0.8304\n",
      "Epoch 428/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8761 - acc: 0.7324\n",
      "Epoch 00428: val_loss did not improve from 0.62046\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8760 - acc: 0.7324 - val_loss: 0.6221 - val_acc: 0.8304\n",
      "Epoch 429/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8771 - acc: 0.7342\n",
      "Epoch 00429: val_loss did not improve from 0.62046\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8772 - acc: 0.7342 - val_loss: 0.6231 - val_acc: 0.8300\n",
      "Epoch 430/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8840 - acc: 0.7288\n",
      "Epoch 00430: val_loss did not improve from 0.62046\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8840 - acc: 0.7288 - val_loss: 0.6248 - val_acc: 0.8309\n",
      "Epoch 431/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8829 - acc: 0.7289\n",
      "Epoch 00431: val_loss did not improve from 0.62046\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 0.8829 - acc: 0.7289 - val_loss: 0.6221 - val_acc: 0.8314\n",
      "Epoch 432/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8777 - acc: 0.7306\n",
      "Epoch 00432: val_loss improved from 0.62046 to 0.61954, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/432-0.6195.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.8777 - acc: 0.7306 - val_loss: 0.6195 - val_acc: 0.8304\n",
      "Epoch 433/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8704 - acc: 0.7320\n",
      "Epoch 00433: val_loss did not improve from 0.61954\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8704 - acc: 0.7319 - val_loss: 0.6204 - val_acc: 0.8318\n",
      "Epoch 434/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8783 - acc: 0.7313\n",
      "Epoch 00434: val_loss improved from 0.61954 to 0.61678, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/434-0.6168.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8783 - acc: 0.7313 - val_loss: 0.6168 - val_acc: 0.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 435/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8757 - acc: 0.7335\n",
      "Epoch 00435: val_loss did not improve from 0.61678\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8757 - acc: 0.7335 - val_loss: 0.6245 - val_acc: 0.8339\n",
      "Epoch 436/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8797 - acc: 0.7315\n",
      "Epoch 00436: val_loss did not improve from 0.61678\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8799 - acc: 0.7314 - val_loss: 0.6262 - val_acc: 0.8325\n",
      "Epoch 437/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8767 - acc: 0.7346\n",
      "Epoch 00437: val_loss did not improve from 0.61678\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8767 - acc: 0.7347 - val_loss: 0.6171 - val_acc: 0.8304\n",
      "Epoch 438/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8735 - acc: 0.7313\n",
      "Epoch 00438: val_loss improved from 0.61678 to 0.61645, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/438-0.6164.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8734 - acc: 0.7313 - val_loss: 0.6164 - val_acc: 0.8348\n",
      "Epoch 439/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8718 - acc: 0.7336\n",
      "Epoch 00439: val_loss improved from 0.61645 to 0.61547, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/439-0.6155.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8722 - acc: 0.7335 - val_loss: 0.6155 - val_acc: 0.8314\n",
      "Epoch 440/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8782 - acc: 0.7319\n",
      "Epoch 00440: val_loss did not improve from 0.61547\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8782 - acc: 0.7319 - val_loss: 0.6191 - val_acc: 0.8321\n",
      "Epoch 441/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8775 - acc: 0.7324\n",
      "Epoch 00441: val_loss did not improve from 0.61547\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8774 - acc: 0.7324 - val_loss: 0.6249 - val_acc: 0.8279\n",
      "Epoch 442/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8714 - acc: 0.7360\n",
      "Epoch 00442: val_loss did not improve from 0.61547\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8714 - acc: 0.7359 - val_loss: 0.6198 - val_acc: 0.8309\n",
      "Epoch 443/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8743 - acc: 0.7339\n",
      "Epoch 00443: val_loss did not improve from 0.61547\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8743 - acc: 0.7339 - val_loss: 0.6183 - val_acc: 0.8314\n",
      "Epoch 444/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8739 - acc: 0.7339\n",
      "Epoch 00444: val_loss did not improve from 0.61547\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8739 - acc: 0.7338 - val_loss: 0.6157 - val_acc: 0.8360\n",
      "Epoch 445/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8739 - acc: 0.7321\n",
      "Epoch 00445: val_loss did not improve from 0.61547\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8739 - acc: 0.7321 - val_loss: 0.6233 - val_acc: 0.8323\n",
      "Epoch 446/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8644 - acc: 0.7373\n",
      "Epoch 00446: val_loss did not improve from 0.61547\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8643 - acc: 0.7373 - val_loss: 0.6194 - val_acc: 0.8311\n",
      "Epoch 447/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8659 - acc: 0.7351\n",
      "Epoch 00447: val_loss did not improve from 0.61547\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.8658 - acc: 0.7351 - val_loss: 0.6258 - val_acc: 0.8274\n",
      "Epoch 448/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8676 - acc: 0.7352\n",
      "Epoch 00448: val_loss did not improve from 0.61547\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8676 - acc: 0.7353 - val_loss: 0.6160 - val_acc: 0.8332\n",
      "Epoch 449/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8738 - acc: 0.7333\n",
      "Epoch 00449: val_loss improved from 0.61547 to 0.61104, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/449-0.6110.hdf5\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8738 - acc: 0.7333 - val_loss: 0.6110 - val_acc: 0.8346\n",
      "Epoch 450/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8700 - acc: 0.7360\n",
      "Epoch 00450: val_loss did not improve from 0.61104\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8700 - acc: 0.7360 - val_loss: 0.6136 - val_acc: 0.8337\n",
      "Epoch 451/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8750 - acc: 0.7334\n",
      "Epoch 00451: val_loss did not improve from 0.61104\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 0.8750 - acc: 0.7334 - val_loss: 0.6207 - val_acc: 0.8328\n",
      "Epoch 452/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8744 - acc: 0.7340\n",
      "Epoch 00452: val_loss did not improve from 0.61104\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 0.8744 - acc: 0.7340 - val_loss: 0.6171 - val_acc: 0.8341\n",
      "Epoch 453/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8723 - acc: 0.7336\n",
      "Epoch 00453: val_loss did not improve from 0.61104\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.8722 - acc: 0.7336 - val_loss: 0.6218 - val_acc: 0.8309\n",
      "Epoch 454/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8742 - acc: 0.7360\n",
      "Epoch 00454: val_loss did not improve from 0.61104\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8741 - acc: 0.7360 - val_loss: 0.6171 - val_acc: 0.8348\n",
      "Epoch 455/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8727 - acc: 0.7349\n",
      "Epoch 00455: val_loss did not improve from 0.61104\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8727 - acc: 0.7349 - val_loss: 0.6143 - val_acc: 0.8339\n",
      "Epoch 456/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8687 - acc: 0.7342\n",
      "Epoch 00456: val_loss did not improve from 0.61104\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8688 - acc: 0.7342 - val_loss: 0.6115 - val_acc: 0.8351\n",
      "Epoch 457/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8686 - acc: 0.7340\n",
      "Epoch 00457: val_loss did not improve from 0.61104\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8686 - acc: 0.7340 - val_loss: 0.6129 - val_acc: 0.8321\n",
      "Epoch 458/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8626 - acc: 0.7367\n",
      "Epoch 00458: val_loss did not improve from 0.61104\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8626 - acc: 0.7367 - val_loss: 0.6159 - val_acc: 0.8351\n",
      "Epoch 459/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8735 - acc: 0.7325\n",
      "Epoch 00459: val_loss did not improve from 0.61104\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8737 - acc: 0.7324 - val_loss: 0.6197 - val_acc: 0.8323\n",
      "Epoch 460/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8615 - acc: 0.7371\n",
      "Epoch 00460: val_loss did not improve from 0.61104\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.8617 - acc: 0.7371 - val_loss: 0.6153 - val_acc: 0.8318\n",
      "Epoch 461/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8716 - acc: 0.7331\n",
      "Epoch 00461: val_loss did not improve from 0.61104\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8716 - acc: 0.7331 - val_loss: 0.6138 - val_acc: 0.8334\n",
      "Epoch 462/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8686 - acc: 0.7361\n",
      "Epoch 00462: val_loss did not improve from 0.61104\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8688 - acc: 0.7361 - val_loss: 0.6176 - val_acc: 0.8332\n",
      "Epoch 463/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8639 - acc: 0.7353\n",
      "Epoch 00463: val_loss improved from 0.61104 to 0.60946, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/463-0.6095.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.8640 - acc: 0.7353 - val_loss: 0.6095 - val_acc: 0.8351\n",
      "Epoch 464/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8630 - acc: 0.7349\n",
      "Epoch 00464: val_loss did not improve from 0.60946\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8629 - acc: 0.7349 - val_loss: 0.6100 - val_acc: 0.8348\n",
      "Epoch 465/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8607 - acc: 0.7365\n",
      "Epoch 00465: val_loss did not improve from 0.60946\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8606 - acc: 0.7365 - val_loss: 0.6184 - val_acc: 0.8302\n",
      "Epoch 466/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8704 - acc: 0.7374\n",
      "Epoch 00466: val_loss did not improve from 0.60946\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8703 - acc: 0.7374 - val_loss: 0.6143 - val_acc: 0.8337\n",
      "Epoch 467/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8647 - acc: 0.7372\n",
      "Epoch 00467: val_loss did not improve from 0.60946\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8648 - acc: 0.7372 - val_loss: 0.6138 - val_acc: 0.8362\n",
      "Epoch 468/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8630 - acc: 0.7348\n",
      "Epoch 00468: val_loss did not improve from 0.60946\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 0.8631 - acc: 0.7348 - val_loss: 0.6114 - val_acc: 0.8346\n",
      "Epoch 469/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8688 - acc: 0.7349\n",
      "Epoch 00469: val_loss did not improve from 0.60946\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 0.8693 - acc: 0.7348 - val_loss: 0.6098 - val_acc: 0.8355\n",
      "Epoch 470/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8648 - acc: 0.7368\n",
      "Epoch 00470: val_loss did not improve from 0.60946\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 0.8647 - acc: 0.7368 - val_loss: 0.6158 - val_acc: 0.8309\n",
      "Epoch 471/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8639 - acc: 0.7356\n",
      "Epoch 00471: val_loss improved from 0.60946 to 0.60858, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/471-0.6086.hdf5\n",
      "36805/36805 [==============================] - 16s 436us/sample - loss: 0.8638 - acc: 0.7356 - val_loss: 0.6086 - val_acc: 0.8372\n",
      "Epoch 472/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8715 - acc: 0.7340\n",
      "Epoch 00472: val_loss did not improve from 0.60858\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.8715 - acc: 0.7341 - val_loss: 0.6152 - val_acc: 0.8334\n",
      "Epoch 473/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8667 - acc: 0.7345\n",
      "Epoch 00473: val_loss did not improve from 0.60858\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.8668 - acc: 0.7345 - val_loss: 0.6139 - val_acc: 0.8316\n",
      "Epoch 474/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8595 - acc: 0.7394\n",
      "Epoch 00474: val_loss did not improve from 0.60858\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.8597 - acc: 0.7394 - val_loss: 0.6207 - val_acc: 0.8346\n",
      "Epoch 475/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8632 - acc: 0.7349\n",
      "Epoch 00475: val_loss improved from 0.60858 to 0.60710, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/475-0.6071.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.8631 - acc: 0.7350 - val_loss: 0.6071 - val_acc: 0.8376\n",
      "Epoch 476/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8623 - acc: 0.7365\n",
      "Epoch 00476: val_loss did not improve from 0.60710\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8622 - acc: 0.7365 - val_loss: 0.6321 - val_acc: 0.8269\n",
      "Epoch 477/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8684 - acc: 0.7365\n",
      "Epoch 00477: val_loss did not improve from 0.60710\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.8684 - acc: 0.7365 - val_loss: 0.6129 - val_acc: 0.8355\n",
      "Epoch 478/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8617 - acc: 0.7362\n",
      "Epoch 00478: val_loss did not improve from 0.60710\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.8617 - acc: 0.7362 - val_loss: 0.6136 - val_acc: 0.8309\n",
      "Epoch 479/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8683 - acc: 0.7346\n",
      "Epoch 00479: val_loss did not improve from 0.60710\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.8682 - acc: 0.7346 - val_loss: 0.6081 - val_acc: 0.8367\n",
      "Epoch 480/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8564 - acc: 0.7405\n",
      "Epoch 00480: val_loss did not improve from 0.60710\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8564 - acc: 0.7405 - val_loss: 0.6073 - val_acc: 0.8351\n",
      "Epoch 481/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8597 - acc: 0.7358\n",
      "Epoch 00481: val_loss did not improve from 0.60710\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.8596 - acc: 0.7358 - val_loss: 0.6146 - val_acc: 0.8376\n",
      "Epoch 482/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8638 - acc: 0.7378\n",
      "Epoch 00482: val_loss improved from 0.60710 to 0.60560, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/482-0.6056.hdf5\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8638 - acc: 0.7378 - val_loss: 0.6056 - val_acc: 0.8383\n",
      "Epoch 483/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8540 - acc: 0.7385\n",
      "Epoch 00483: val_loss improved from 0.60560 to 0.60388, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/483-0.6039.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.8540 - acc: 0.7385 - val_loss: 0.6039 - val_acc: 0.8358\n",
      "Epoch 484/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8637 - acc: 0.7382\n",
      "Epoch 00484: val_loss did not improve from 0.60388\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8636 - acc: 0.7382 - val_loss: 0.6150 - val_acc: 0.8323\n",
      "Epoch 485/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8657 - acc: 0.7374\n",
      "Epoch 00485: val_loss improved from 0.60388 to 0.60331, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/485-0.6033.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8656 - acc: 0.7374 - val_loss: 0.6033 - val_acc: 0.8386\n",
      "Epoch 486/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8607 - acc: 0.7377\n",
      "Epoch 00486: val_loss improved from 0.60331 to 0.60186, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/486-0.6019.hdf5\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8608 - acc: 0.7377 - val_loss: 0.6019 - val_acc: 0.8372\n",
      "Epoch 487/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8570 - acc: 0.7384\n",
      "Epoch 00487: val_loss improved from 0.60186 to 0.60106, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/487-0.6011.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.8573 - acc: 0.7384 - val_loss: 0.6011 - val_acc: 0.8365\n",
      "Epoch 488/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8574 - acc: 0.7391\n",
      "Epoch 00488: val_loss improved from 0.60106 to 0.59649, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv_checkpoint/488-0.5965.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.8573 - acc: 0.7391 - val_loss: 0.5965 - val_acc: 0.8416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8521 - acc: 0.7408\n",
      "Epoch 00489: val_loss did not improve from 0.59649\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8520 - acc: 0.7408 - val_loss: 0.6081 - val_acc: 0.8374\n",
      "Epoch 490/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8607 - acc: 0.7396\n",
      "Epoch 00490: val_loss did not improve from 0.59649\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8607 - acc: 0.7396 - val_loss: 0.6122 - val_acc: 0.8365\n",
      "Epoch 491/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8556 - acc: 0.7379\n",
      "Epoch 00491: val_loss did not improve from 0.59649\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.8556 - acc: 0.7378 - val_loss: 0.5984 - val_acc: 0.8381\n",
      "Epoch 492/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8541 - acc: 0.7373\n",
      "Epoch 00492: val_loss did not improve from 0.59649\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8541 - acc: 0.7373 - val_loss: 0.6000 - val_acc: 0.8393\n",
      "Epoch 493/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8543 - acc: 0.7393\n",
      "Epoch 00493: val_loss did not improve from 0.59649\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8543 - acc: 0.7393 - val_loss: 0.6037 - val_acc: 0.8355\n",
      "Epoch 494/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8559 - acc: 0.7389\n",
      "Epoch 00494: val_loss did not improve from 0.59649\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8559 - acc: 0.7388 - val_loss: 0.5996 - val_acc: 0.8397\n",
      "Epoch 495/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8538 - acc: 0.7411\n",
      "Epoch 00495: val_loss did not improve from 0.59649\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.8538 - acc: 0.7411 - val_loss: 0.5989 - val_acc: 0.8376\n",
      "Epoch 496/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8573 - acc: 0.7400\n",
      "Epoch 00496: val_loss did not improve from 0.59649\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.8574 - acc: 0.7400 - val_loss: 0.6147 - val_acc: 0.8334\n",
      "Epoch 497/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8574 - acc: 0.7376\n",
      "Epoch 00497: val_loss did not improve from 0.59649\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8573 - acc: 0.7376 - val_loss: 0.5999 - val_acc: 0.8383\n",
      "Epoch 498/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8558 - acc: 0.7420\n",
      "Epoch 00498: val_loss did not improve from 0.59649\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.8558 - acc: 0.7420 - val_loss: 0.5999 - val_acc: 0.8383\n",
      "Epoch 499/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8521 - acc: 0.7377\n",
      "Epoch 00499: val_loss did not improve from 0.59649\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8520 - acc: 0.7377 - val_loss: 0.6018 - val_acc: 0.8386\n",
      "Epoch 500/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8548 - acc: 0.7407\n",
      "Epoch 00500: val_loss did not improve from 0.59649\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.8548 - acc: 0.7407 - val_loss: 0.6035 - val_acc: 0.8365\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 244us/sample - loss: 0.6589 - acc: 0.8064\n",
      "Loss: 0.6589304419445224 Accuracy: 0.8064382\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.7007 - acc: 0.1156\n",
      "Epoch 00001: val_loss improved from inf to 2.54712, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/001-2.5471.hdf5\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 2.7006 - acc: 0.1157 - val_loss: 2.5471 - val_acc: 0.2055\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4264 - acc: 0.2162\n",
      "Epoch 00002: val_loss improved from 2.54712 to 2.18394, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/002-2.1839.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 2.4264 - acc: 0.2162 - val_loss: 2.1839 - val_acc: 0.3215\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1963 - acc: 0.2741\n",
      "Epoch 00003: val_loss improved from 2.18394 to 1.98888, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/003-1.9889.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 2.1961 - acc: 0.2741 - val_loss: 1.9889 - val_acc: 0.3920\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0580 - acc: 0.3151\n",
      "Epoch 00004: val_loss improved from 1.98888 to 1.85507, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/004-1.8551.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 2.0580 - acc: 0.3151 - val_loss: 1.8551 - val_acc: 0.4335\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9589 - acc: 0.3445\n",
      "Epoch 00005: val_loss improved from 1.85507 to 1.77789, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/005-1.7779.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 1.9590 - acc: 0.3444 - val_loss: 1.7779 - val_acc: 0.4479\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8845 - acc: 0.3636\n",
      "Epoch 00006: val_loss improved from 1.77789 to 1.68960, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/006-1.6896.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 1.8846 - acc: 0.3636 - val_loss: 1.6896 - val_acc: 0.4694\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8222 - acc: 0.3867\n",
      "Epoch 00007: val_loss improved from 1.68960 to 1.62837, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/007-1.6284.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.8221 - acc: 0.3868 - val_loss: 1.6284 - val_acc: 0.4934\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7688 - acc: 0.4068\n",
      "Epoch 00008: val_loss improved from 1.62837 to 1.57485, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/008-1.5748.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 1.7688 - acc: 0.4068 - val_loss: 1.5748 - val_acc: 0.5190\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7307 - acc: 0.4205\n",
      "Epoch 00009: val_loss improved from 1.57485 to 1.53084, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/009-1.5308.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.7308 - acc: 0.4205 - val_loss: 1.5308 - val_acc: 0.5229\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6731 - acc: 0.4415\n",
      "Epoch 00010: val_loss improved from 1.53084 to 1.49213, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/010-1.4921.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 1.6732 - acc: 0.4414 - val_loss: 1.4921 - val_acc: 0.5425\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6385 - acc: 0.4564\n",
      "Epoch 00011: val_loss improved from 1.49213 to 1.44496, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/011-1.4450.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.6386 - acc: 0.4564 - val_loss: 1.4450 - val_acc: 0.5637\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6082 - acc: 0.4679\n",
      "Epoch 00012: val_loss improved from 1.44496 to 1.40362, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/012-1.4036.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.6082 - acc: 0.4679 - val_loss: 1.4036 - val_acc: 0.5821\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5768 - acc: 0.4817\n",
      "Epoch 00013: val_loss improved from 1.40362 to 1.37661, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/013-1.3766.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 1.5768 - acc: 0.4818 - val_loss: 1.3766 - val_acc: 0.5840\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5497 - acc: 0.4939\n",
      "Epoch 00014: val_loss improved from 1.37661 to 1.33983, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/014-1.3398.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 1.5496 - acc: 0.4939 - val_loss: 1.3398 - val_acc: 0.6059\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5176 - acc: 0.5054\n",
      "Epoch 00015: val_loss improved from 1.33983 to 1.32384, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/015-1.3238.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.5177 - acc: 0.5053 - val_loss: 1.3238 - val_acc: 0.6138\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4916 - acc: 0.5139\n",
      "Epoch 00016: val_loss improved from 1.32384 to 1.29218, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/016-1.2922.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 1.4917 - acc: 0.5138 - val_loss: 1.2922 - val_acc: 0.6173\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4698 - acc: 0.5276\n",
      "Epoch 00017: val_loss improved from 1.29218 to 1.28100, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/017-1.2810.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.4697 - acc: 0.5276 - val_loss: 1.2810 - val_acc: 0.6189\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4446 - acc: 0.5339\n",
      "Epoch 00018: val_loss improved from 1.28100 to 1.24767, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/018-1.2477.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.4446 - acc: 0.5339 - val_loss: 1.2477 - val_acc: 0.6336\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4249 - acc: 0.5445\n",
      "Epoch 00019: val_loss improved from 1.24767 to 1.21985, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/019-1.2198.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 1.4249 - acc: 0.5445 - val_loss: 1.2198 - val_acc: 0.6413\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4019 - acc: 0.5517\n",
      "Epoch 00020: val_loss improved from 1.21985 to 1.20522, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/020-1.2052.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 1.4020 - acc: 0.5517 - val_loss: 1.2052 - val_acc: 0.6462\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3850 - acc: 0.5610\n",
      "Epoch 00021: val_loss improved from 1.20522 to 1.18493, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/021-1.1849.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.3849 - acc: 0.5610 - val_loss: 1.1849 - val_acc: 0.6511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3628 - acc: 0.5687\n",
      "Epoch 00022: val_loss improved from 1.18493 to 1.17845, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/022-1.1784.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.3628 - acc: 0.5687 - val_loss: 1.1784 - val_acc: 0.6536\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3502 - acc: 0.5714\n",
      "Epoch 00023: val_loss improved from 1.17845 to 1.14647, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/023-1.1465.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 1.3501 - acc: 0.5714 - val_loss: 1.1465 - val_acc: 0.6667\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3288 - acc: 0.5793\n",
      "Epoch 00024: val_loss improved from 1.14647 to 1.13365, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/024-1.1336.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 1.3288 - acc: 0.5793 - val_loss: 1.1336 - val_acc: 0.6678\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3087 - acc: 0.5890\n",
      "Epoch 00025: val_loss improved from 1.13365 to 1.11816, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/025-1.1182.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.3088 - acc: 0.5890 - val_loss: 1.1182 - val_acc: 0.6753\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2932 - acc: 0.5936\n",
      "Epoch 00026: val_loss improved from 1.11816 to 1.10505, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/026-1.1050.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 1.2932 - acc: 0.5937 - val_loss: 1.1050 - val_acc: 0.6785\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2759 - acc: 0.5993\n",
      "Epoch 00027: val_loss improved from 1.10505 to 1.07941, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/027-1.0794.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 1.2759 - acc: 0.5993 - val_loss: 1.0794 - val_acc: 0.6876\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2647 - acc: 0.6031\n",
      "Epoch 00028: val_loss improved from 1.07941 to 1.06280, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/028-1.0628.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 1.2647 - acc: 0.6031 - val_loss: 1.0628 - val_acc: 0.6942\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2456 - acc: 0.6120\n",
      "Epoch 00029: val_loss improved from 1.06280 to 1.04342, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/029-1.0434.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 1.2456 - acc: 0.6120 - val_loss: 1.0434 - val_acc: 0.6995\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2327 - acc: 0.6175\n",
      "Epoch 00030: val_loss did not improve from 1.04342\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.2327 - acc: 0.6175 - val_loss: 1.0488 - val_acc: 0.7009\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2168 - acc: 0.6229\n",
      "Epoch 00031: val_loss improved from 1.04342 to 1.02361, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/031-1.0236.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 1.2168 - acc: 0.6229 - val_loss: 1.0236 - val_acc: 0.7077\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2035 - acc: 0.6281\n",
      "Epoch 00032: val_loss improved from 1.02361 to 0.99849, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/032-0.9985.hdf5\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 1.2035 - acc: 0.6281 - val_loss: 0.9985 - val_acc: 0.7121\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1898 - acc: 0.6391\n",
      "Epoch 00033: val_loss improved from 0.99849 to 0.99008, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/033-0.9901.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 1.1898 - acc: 0.6391 - val_loss: 0.9901 - val_acc: 0.7188\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1773 - acc: 0.6366\n",
      "Epoch 00034: val_loss improved from 0.99008 to 0.97856, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/034-0.9786.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.1772 - acc: 0.6366 - val_loss: 0.9786 - val_acc: 0.7228\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1598 - acc: 0.6432\n",
      "Epoch 00035: val_loss improved from 0.97856 to 0.96528, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/035-0.9653.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.1597 - acc: 0.6432 - val_loss: 0.9653 - val_acc: 0.7247\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1468 - acc: 0.6485\n",
      "Epoch 00036: val_loss improved from 0.96528 to 0.95998, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/036-0.9600.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.1468 - acc: 0.6484 - val_loss: 0.9600 - val_acc: 0.7221\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1368 - acc: 0.6506\n",
      "Epoch 00037: val_loss improved from 0.95998 to 0.94103, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/037-0.9410.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 1.1368 - acc: 0.6506 - val_loss: 0.9410 - val_acc: 0.7398\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1245 - acc: 0.6592\n",
      "Epoch 00038: val_loss improved from 0.94103 to 0.92129, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/038-0.9213.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.1245 - acc: 0.6593 - val_loss: 0.9213 - val_acc: 0.7424\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1074 - acc: 0.6608\n",
      "Epoch 00039: val_loss improved from 0.92129 to 0.91335, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/039-0.9133.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.1075 - acc: 0.6608 - val_loss: 0.9133 - val_acc: 0.7494\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0997 - acc: 0.6635\n",
      "Epoch 00040: val_loss improved from 0.91335 to 0.90497, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/040-0.9050.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 1.0997 - acc: 0.6634 - val_loss: 0.9050 - val_acc: 0.7428\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0828 - acc: 0.6712\n",
      "Epoch 00041: val_loss improved from 0.90497 to 0.88479, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/041-0.8848.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 1.0827 - acc: 0.6713 - val_loss: 0.8848 - val_acc: 0.7526\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0795 - acc: 0.6748\n",
      "Epoch 00042: val_loss did not improve from 0.88479\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.0796 - acc: 0.6749 - val_loss: 0.8852 - val_acc: 0.7563\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0609 - acc: 0.6803\n",
      "Epoch 00043: val_loss improved from 0.88479 to 0.86392, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/043-0.8639.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 1.0608 - acc: 0.6804 - val_loss: 0.8639 - val_acc: 0.7531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0533 - acc: 0.6804\n",
      "Epoch 00044: val_loss improved from 0.86392 to 0.84903, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/044-0.8490.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.0532 - acc: 0.6804 - val_loss: 0.8490 - val_acc: 0.7617\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0410 - acc: 0.6852\n",
      "Epoch 00045: val_loss improved from 0.84903 to 0.83477, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/045-0.8348.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.0409 - acc: 0.6852 - val_loss: 0.8348 - val_acc: 0.7643\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0377 - acc: 0.6872\n",
      "Epoch 00046: val_loss improved from 0.83477 to 0.82651, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/046-0.8265.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.0377 - acc: 0.6872 - val_loss: 0.8265 - val_acc: 0.7666\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0171 - acc: 0.6924\n",
      "Epoch 00047: val_loss improved from 0.82651 to 0.81449, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/047-0.8145.hdf5\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 1.0170 - acc: 0.6924 - val_loss: 0.8145 - val_acc: 0.7715\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0170 - acc: 0.6947\n",
      "Epoch 00048: val_loss improved from 0.81449 to 0.81298, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/048-0.8130.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 1.0170 - acc: 0.6946 - val_loss: 0.8130 - val_acc: 0.7743\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0011 - acc: 0.7011\n",
      "Epoch 00049: val_loss improved from 0.81298 to 0.78907, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/049-0.7891.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 1.0011 - acc: 0.7010 - val_loss: 0.7891 - val_acc: 0.7780\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9901 - acc: 0.7006\n",
      "Epoch 00050: val_loss improved from 0.78907 to 0.77939, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/050-0.7794.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9900 - acc: 0.7006 - val_loss: 0.7794 - val_acc: 0.7773\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9847 - acc: 0.7027\n",
      "Epoch 00051: val_loss improved from 0.77939 to 0.77724, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/051-0.7772.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.9848 - acc: 0.7026 - val_loss: 0.7772 - val_acc: 0.7808\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9768 - acc: 0.7078\n",
      "Epoch 00052: val_loss improved from 0.77724 to 0.77012, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/052-0.7701.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.9767 - acc: 0.7079 - val_loss: 0.7701 - val_acc: 0.7829\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9526 - acc: 0.7140\n",
      "Epoch 00053: val_loss improved from 0.77012 to 0.76310, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/053-0.7631.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9525 - acc: 0.7141 - val_loss: 0.7631 - val_acc: 0.7848\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9534 - acc: 0.7138\n",
      "Epoch 00054: val_loss did not improve from 0.76310\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9535 - acc: 0.7138 - val_loss: 0.7653 - val_acc: 0.7817\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9484 - acc: 0.7163\n",
      "Epoch 00055: val_loss improved from 0.76310 to 0.74027, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/055-0.7403.hdf5\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.9485 - acc: 0.7163 - val_loss: 0.7403 - val_acc: 0.7927\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9347 - acc: 0.7194\n",
      "Epoch 00056: val_loss did not improve from 0.74027\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9350 - acc: 0.7193 - val_loss: 0.7453 - val_acc: 0.7890\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9323 - acc: 0.7211\n",
      "Epoch 00057: val_loss improved from 0.74027 to 0.72692, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/057-0.7269.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.9323 - acc: 0.7210 - val_loss: 0.7269 - val_acc: 0.7952\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9244 - acc: 0.7235\n",
      "Epoch 00058: val_loss improved from 0.72692 to 0.71350, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/058-0.7135.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.9243 - acc: 0.7235 - val_loss: 0.7135 - val_acc: 0.8020\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9106 - acc: 0.7271\n",
      "Epoch 00059: val_loss improved from 0.71350 to 0.70849, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/059-0.7085.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.9105 - acc: 0.7271 - val_loss: 0.7085 - val_acc: 0.8039\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9103 - acc: 0.7267\n",
      "Epoch 00060: val_loss improved from 0.70849 to 0.70067, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/060-0.7007.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.9104 - acc: 0.7267 - val_loss: 0.7007 - val_acc: 0.8057\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9047 - acc: 0.7326\n",
      "Epoch 00061: val_loss improved from 0.70067 to 0.69770, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/061-0.6977.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.9047 - acc: 0.7326 - val_loss: 0.6977 - val_acc: 0.8050\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8948 - acc: 0.7336\n",
      "Epoch 00062: val_loss improved from 0.69770 to 0.68413, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/062-0.6841.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.8947 - acc: 0.7336 - val_loss: 0.6841 - val_acc: 0.8074\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8908 - acc: 0.7336\n",
      "Epoch 00063: val_loss improved from 0.68413 to 0.67580, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/063-0.6758.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.8907 - acc: 0.7336 - val_loss: 0.6758 - val_acc: 0.8104\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8781 - acc: 0.7380\n",
      "Epoch 00064: val_loss improved from 0.67580 to 0.67070, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/064-0.6707.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.8781 - acc: 0.7380 - val_loss: 0.6707 - val_acc: 0.8127\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8771 - acc: 0.7386\n",
      "Epoch 00065: val_loss improved from 0.67070 to 0.66138, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/065-0.6614.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.8772 - acc: 0.7386 - val_loss: 0.6614 - val_acc: 0.8148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8672 - acc: 0.7411\n",
      "Epoch 00066: val_loss did not improve from 0.66138\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.8671 - acc: 0.7411 - val_loss: 0.6649 - val_acc: 0.8092\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8597 - acc: 0.7421\n",
      "Epoch 00067: val_loss improved from 0.66138 to 0.65874, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/067-0.6587.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.8596 - acc: 0.7421 - val_loss: 0.6587 - val_acc: 0.8157\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8554 - acc: 0.7454\n",
      "Epoch 00068: val_loss did not improve from 0.65874\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.8553 - acc: 0.7454 - val_loss: 0.6630 - val_acc: 0.8102\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8505 - acc: 0.7472\n",
      "Epoch 00069: val_loss improved from 0.65874 to 0.64725, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/069-0.6473.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.8507 - acc: 0.7471 - val_loss: 0.6473 - val_acc: 0.8178\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8384 - acc: 0.7494\n",
      "Epoch 00070: val_loss improved from 0.64725 to 0.64664, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/070-0.6466.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.8384 - acc: 0.7494 - val_loss: 0.6466 - val_acc: 0.8174\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8427 - acc: 0.7477\n",
      "Epoch 00071: val_loss improved from 0.64664 to 0.63476, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/071-0.6348.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.8427 - acc: 0.7477 - val_loss: 0.6348 - val_acc: 0.8216\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8345 - acc: 0.7548\n",
      "Epoch 00072: val_loss improved from 0.63476 to 0.62728, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/072-0.6273.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.8344 - acc: 0.7548 - val_loss: 0.6273 - val_acc: 0.8213\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8298 - acc: 0.7528\n",
      "Epoch 00073: val_loss improved from 0.62728 to 0.62207, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/073-0.6221.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.8297 - acc: 0.7529 - val_loss: 0.6221 - val_acc: 0.8230\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8226 - acc: 0.7580\n",
      "Epoch 00074: val_loss improved from 0.62207 to 0.62167, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/074-0.6217.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.8227 - acc: 0.7580 - val_loss: 0.6217 - val_acc: 0.8295\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8122 - acc: 0.7606\n",
      "Epoch 00075: val_loss improved from 0.62167 to 0.61649, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/075-0.6165.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.8122 - acc: 0.7605 - val_loss: 0.6165 - val_acc: 0.8265\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8125 - acc: 0.7614\n",
      "Epoch 00076: val_loss improved from 0.61649 to 0.60899, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/076-0.6090.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.8124 - acc: 0.7614 - val_loss: 0.6090 - val_acc: 0.8304\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8033 - acc: 0.7632\n",
      "Epoch 00077: val_loss improved from 0.60899 to 0.60281, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/077-0.6028.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.8033 - acc: 0.7632 - val_loss: 0.6028 - val_acc: 0.8328\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7988 - acc: 0.7641\n",
      "Epoch 00078: val_loss improved from 0.60281 to 0.59611, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/078-0.5961.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.7988 - acc: 0.7641 - val_loss: 0.5961 - val_acc: 0.8321\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7919 - acc: 0.7637\n",
      "Epoch 00079: val_loss improved from 0.59611 to 0.58784, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/079-0.5878.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.7919 - acc: 0.7637 - val_loss: 0.5878 - val_acc: 0.8355\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7901 - acc: 0.7660\n",
      "Epoch 00080: val_loss improved from 0.58784 to 0.58548, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/080-0.5855.hdf5\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.7901 - acc: 0.7660 - val_loss: 0.5855 - val_acc: 0.8358\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7933 - acc: 0.7652\n",
      "Epoch 00081: val_loss did not improve from 0.58548\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.7933 - acc: 0.7652 - val_loss: 0.5931 - val_acc: 0.8379\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7829 - acc: 0.7693\n",
      "Epoch 00082: val_loss did not improve from 0.58548\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.7830 - acc: 0.7693 - val_loss: 0.5881 - val_acc: 0.8411\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7771 - acc: 0.7718\n",
      "Epoch 00083: val_loss improved from 0.58548 to 0.57784, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/083-0.5778.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.7771 - acc: 0.7718 - val_loss: 0.5778 - val_acc: 0.8386\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7804 - acc: 0.7707\n",
      "Epoch 00084: val_loss did not improve from 0.57784\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.7805 - acc: 0.7707 - val_loss: 0.6026 - val_acc: 0.8309\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7699 - acc: 0.7721\n",
      "Epoch 00085: val_loss did not improve from 0.57784\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.7700 - acc: 0.7722 - val_loss: 0.5848 - val_acc: 0.8376\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7622 - acc: 0.7739\n",
      "Epoch 00086: val_loss improved from 0.57784 to 0.56046, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/086-0.5605.hdf5\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.7623 - acc: 0.7739 - val_loss: 0.5605 - val_acc: 0.8442\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7610 - acc: 0.7776\n",
      "Epoch 00087: val_loss did not improve from 0.56046\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.7611 - acc: 0.7776 - val_loss: 0.5797 - val_acc: 0.8369\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7636 - acc: 0.7721\n",
      "Epoch 00088: val_loss improved from 0.56046 to 0.55704, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/088-0.5570.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.7638 - acc: 0.7721 - val_loss: 0.5570 - val_acc: 0.8477\n",
      "Epoch 89/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7491 - acc: 0.7805\n",
      "Epoch 00089: val_loss did not improve from 0.55704\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.7491 - acc: 0.7805 - val_loss: 0.5595 - val_acc: 0.8458\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7549 - acc: 0.7790\n",
      "Epoch 00090: val_loss did not improve from 0.55704\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.7548 - acc: 0.7790 - val_loss: 0.5660 - val_acc: 0.8486\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7471 - acc: 0.7804\n",
      "Epoch 00091: val_loss improved from 0.55704 to 0.55351, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/091-0.5535.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.7471 - acc: 0.7804 - val_loss: 0.5535 - val_acc: 0.8507\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7480 - acc: 0.7800\n",
      "Epoch 00092: val_loss improved from 0.55351 to 0.53906, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/092-0.5391.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.7480 - acc: 0.7800 - val_loss: 0.5391 - val_acc: 0.8577\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7335 - acc: 0.7866\n",
      "Epoch 00093: val_loss did not improve from 0.53906\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.7334 - acc: 0.7866 - val_loss: 0.5436 - val_acc: 0.8549\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7356 - acc: 0.7834\n",
      "Epoch 00094: val_loss improved from 0.53906 to 0.53873, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/094-0.5387.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.7357 - acc: 0.7834 - val_loss: 0.5387 - val_acc: 0.8532\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7358 - acc: 0.7865\n",
      "Epoch 00095: val_loss did not improve from 0.53873\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.7360 - acc: 0.7865 - val_loss: 0.5418 - val_acc: 0.8512\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7300 - acc: 0.7865\n",
      "Epoch 00096: val_loss improved from 0.53873 to 0.53369, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/096-0.5337.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.7301 - acc: 0.7864 - val_loss: 0.5337 - val_acc: 0.8528\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7289 - acc: 0.7861\n",
      "Epoch 00097: val_loss did not improve from 0.53369\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.7289 - acc: 0.7860 - val_loss: 0.5441 - val_acc: 0.8544\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7212 - acc: 0.7885\n",
      "Epoch 00098: val_loss improved from 0.53369 to 0.52760, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/098-0.5276.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.7212 - acc: 0.7885 - val_loss: 0.5276 - val_acc: 0.8586\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7164 - acc: 0.7919\n",
      "Epoch 00099: val_loss improved from 0.52760 to 0.52058, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/099-0.5206.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.7163 - acc: 0.7919 - val_loss: 0.5206 - val_acc: 0.8623\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7127 - acc: 0.7925\n",
      "Epoch 00100: val_loss did not improve from 0.52058\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.7127 - acc: 0.7925 - val_loss: 0.5242 - val_acc: 0.8609\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7103 - acc: 0.7924\n",
      "Epoch 00101: val_loss improved from 0.52058 to 0.51313, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/101-0.5131.hdf5\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.7103 - acc: 0.7924 - val_loss: 0.5131 - val_acc: 0.8649\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7117 - acc: 0.7907\n",
      "Epoch 00102: val_loss did not improve from 0.51313\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.7117 - acc: 0.7907 - val_loss: 0.5147 - val_acc: 0.8605\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6977 - acc: 0.7938\n",
      "Epoch 00103: val_loss did not improve from 0.51313\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.6977 - acc: 0.7938 - val_loss: 0.5156 - val_acc: 0.8607\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7093 - acc: 0.7902\n",
      "Epoch 00104: val_loss improved from 0.51313 to 0.51276, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/104-0.5128.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.7093 - acc: 0.7903 - val_loss: 0.5128 - val_acc: 0.8626\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6945 - acc: 0.7974\n",
      "Epoch 00105: val_loss improved from 0.51276 to 0.50807, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/105-0.5081.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.6946 - acc: 0.7973 - val_loss: 0.5081 - val_acc: 0.8607\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7026 - acc: 0.7964\n",
      "Epoch 00106: val_loss did not improve from 0.50807\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.7026 - acc: 0.7964 - val_loss: 0.5152 - val_acc: 0.8651\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6925 - acc: 0.7980\n",
      "Epoch 00107: val_loss improved from 0.50807 to 0.49691, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/107-0.4969.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.6925 - acc: 0.7980 - val_loss: 0.4969 - val_acc: 0.8707\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6910 - acc: 0.7986\n",
      "Epoch 00108: val_loss did not improve from 0.49691\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.6910 - acc: 0.7986 - val_loss: 0.5089 - val_acc: 0.8665\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6865 - acc: 0.8007\n",
      "Epoch 00109: val_loss improved from 0.49691 to 0.49171, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/109-0.4917.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.6864 - acc: 0.8007 - val_loss: 0.4917 - val_acc: 0.8668\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6900 - acc: 0.7989\n",
      "Epoch 00110: val_loss improved from 0.49171 to 0.49011, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/110-0.4901.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.6900 - acc: 0.7990 - val_loss: 0.4901 - val_acc: 0.8707\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6881 - acc: 0.7995\n",
      "Epoch 00111: val_loss improved from 0.49011 to 0.48598, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/111-0.4860.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.6882 - acc: 0.7995 - val_loss: 0.4860 - val_acc: 0.8719\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6828 - acc: 0.7999\n",
      "Epoch 00112: val_loss did not improve from 0.48598\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.6828 - acc: 0.7999 - val_loss: 0.5052 - val_acc: 0.8682\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6786 - acc: 0.8009\n",
      "Epoch 00113: val_loss did not improve from 0.48598\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.6786 - acc: 0.8008 - val_loss: 0.4944 - val_acc: 0.8691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6765 - acc: 0.8015\n",
      "Epoch 00114: val_loss did not improve from 0.48598\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.6766 - acc: 0.8015 - val_loss: 0.4939 - val_acc: 0.8721\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6742 - acc: 0.8025\n",
      "Epoch 00115: val_loss did not improve from 0.48598\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.6743 - acc: 0.8025 - val_loss: 0.5080 - val_acc: 0.8656\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6759 - acc: 0.8033\n",
      "Epoch 00116: val_loss did not improve from 0.48598\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.6760 - acc: 0.8033 - val_loss: 0.4881 - val_acc: 0.8714\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6717 - acc: 0.8056\n",
      "Epoch 00117: val_loss improved from 0.48598 to 0.48218, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/117-0.4822.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.6717 - acc: 0.8056 - val_loss: 0.4822 - val_acc: 0.8742\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6656 - acc: 0.8036\n",
      "Epoch 00118: val_loss improved from 0.48218 to 0.47813, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/118-0.4781.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.6657 - acc: 0.8036 - val_loss: 0.4781 - val_acc: 0.8740\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6622 - acc: 0.8060\n",
      "Epoch 00119: val_loss improved from 0.47813 to 0.47139, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/119-0.4714.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.6623 - acc: 0.8060 - val_loss: 0.4714 - val_acc: 0.8758\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6618 - acc: 0.8062\n",
      "Epoch 00120: val_loss did not improve from 0.47139\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.6617 - acc: 0.8062 - val_loss: 0.4811 - val_acc: 0.8751\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6599 - acc: 0.8077\n",
      "Epoch 00121: val_loss did not improve from 0.47139\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.6599 - acc: 0.8077 - val_loss: 0.4771 - val_acc: 0.8737\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6588 - acc: 0.8055\n",
      "Epoch 00122: val_loss improved from 0.47139 to 0.47000, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/122-0.4700.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.6588 - acc: 0.8055 - val_loss: 0.4700 - val_acc: 0.8765\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6529 - acc: 0.8087\n",
      "Epoch 00123: val_loss improved from 0.47000 to 0.46773, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/123-0.4677.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.6528 - acc: 0.8087 - val_loss: 0.4677 - val_acc: 0.8765\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6593 - acc: 0.8082\n",
      "Epoch 00124: val_loss did not improve from 0.46773\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.6595 - acc: 0.8081 - val_loss: 0.4711 - val_acc: 0.8754\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6498 - acc: 0.8106\n",
      "Epoch 00125: val_loss did not improve from 0.46773\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.6498 - acc: 0.8106 - val_loss: 0.4699 - val_acc: 0.8763\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6464 - acc: 0.8106\n",
      "Epoch 00126: val_loss improved from 0.46773 to 0.46643, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/126-0.4664.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.6464 - acc: 0.8106 - val_loss: 0.4664 - val_acc: 0.8793\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6472 - acc: 0.8092\n",
      "Epoch 00127: val_loss improved from 0.46643 to 0.45752, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/127-0.4575.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.6472 - acc: 0.8092 - val_loss: 0.4575 - val_acc: 0.8796\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6420 - acc: 0.8137\n",
      "Epoch 00128: val_loss did not improve from 0.45752\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.6420 - acc: 0.8137 - val_loss: 0.4602 - val_acc: 0.8775\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6364 - acc: 0.8123\n",
      "Epoch 00129: val_loss improved from 0.45752 to 0.45480, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/129-0.4548.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.6364 - acc: 0.8123 - val_loss: 0.4548 - val_acc: 0.8807\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6405 - acc: 0.8134\n",
      "Epoch 00130: val_loss improved from 0.45480 to 0.45138, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/130-0.4514.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.6405 - acc: 0.8134 - val_loss: 0.4514 - val_acc: 0.8765\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6384 - acc: 0.8137\n",
      "Epoch 00131: val_loss did not improve from 0.45138\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.6383 - acc: 0.8137 - val_loss: 0.4596 - val_acc: 0.8779\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6337 - acc: 0.8159\n",
      "Epoch 00132: val_loss improved from 0.45138 to 0.45138, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/132-0.4514.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.6338 - acc: 0.8159 - val_loss: 0.4514 - val_acc: 0.8791\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6330 - acc: 0.8136\n",
      "Epoch 00133: val_loss did not improve from 0.45138\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.6330 - acc: 0.8136 - val_loss: 0.4516 - val_acc: 0.8821\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6321 - acc: 0.8163\n",
      "Epoch 00134: val_loss improved from 0.45138 to 0.45034, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/134-0.4503.hdf5\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.6322 - acc: 0.8163 - val_loss: 0.4503 - val_acc: 0.8807\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6280 - acc: 0.8153\n",
      "Epoch 00135: val_loss did not improve from 0.45034\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.6279 - acc: 0.8154 - val_loss: 0.4683 - val_acc: 0.8747\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6179 - acc: 0.8185\n",
      "Epoch 00136: val_loss improved from 0.45034 to 0.44984, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/136-0.4498.hdf5\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.6178 - acc: 0.8185 - val_loss: 0.4498 - val_acc: 0.8842\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6224 - acc: 0.8177\n",
      "Epoch 00137: val_loss improved from 0.44984 to 0.44098, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/137-0.4410.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.6223 - acc: 0.8178 - val_loss: 0.4410 - val_acc: 0.8826\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6259 - acc: 0.8175\n",
      "Epoch 00138: val_loss did not improve from 0.44098\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.6259 - acc: 0.8175 - val_loss: 0.4433 - val_acc: 0.8833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6223 - acc: 0.8179\n",
      "Epoch 00139: val_loss did not improve from 0.44098\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.6224 - acc: 0.8179 - val_loss: 0.4474 - val_acc: 0.8798\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6185 - acc: 0.8196\n",
      "Epoch 00140: val_loss improved from 0.44098 to 0.43593, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/140-0.4359.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.6187 - acc: 0.8196 - val_loss: 0.4359 - val_acc: 0.8875\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6151 - acc: 0.8199\n",
      "Epoch 00141: val_loss did not improve from 0.43593\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.6151 - acc: 0.8199 - val_loss: 0.4384 - val_acc: 0.8859\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6165 - acc: 0.8203\n",
      "Epoch 00142: val_loss improved from 0.43593 to 0.43441, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/142-0.4344.hdf5\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.6165 - acc: 0.8203 - val_loss: 0.4344 - val_acc: 0.8840\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6117 - acc: 0.8198\n",
      "Epoch 00143: val_loss improved from 0.43441 to 0.43259, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/143-0.4326.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.6116 - acc: 0.8199 - val_loss: 0.4326 - val_acc: 0.8866\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6113 - acc: 0.8202\n",
      "Epoch 00144: val_loss did not improve from 0.43259\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.6113 - acc: 0.8202 - val_loss: 0.4499 - val_acc: 0.8838\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6011 - acc: 0.8267\n",
      "Epoch 00145: val_loss did not improve from 0.43259\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.6011 - acc: 0.8267 - val_loss: 0.4344 - val_acc: 0.8870\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6055 - acc: 0.8240\n",
      "Epoch 00146: val_loss improved from 0.43259 to 0.42851, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/146-0.4285.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.6055 - acc: 0.8240 - val_loss: 0.4285 - val_acc: 0.8877\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6033 - acc: 0.8215\n",
      "Epoch 00147: val_loss did not improve from 0.42851\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.6034 - acc: 0.8215 - val_loss: 0.4673 - val_acc: 0.8754\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6076 - acc: 0.8233\n",
      "Epoch 00148: val_loss did not improve from 0.42851\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.6075 - acc: 0.8234 - val_loss: 0.4370 - val_acc: 0.8859\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6034 - acc: 0.8252\n",
      "Epoch 00149: val_loss improved from 0.42851 to 0.42621, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/149-0.4262.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.6034 - acc: 0.8252 - val_loss: 0.4262 - val_acc: 0.8896\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6024 - acc: 0.8247\n",
      "Epoch 00150: val_loss did not improve from 0.42621\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.6025 - acc: 0.8246 - val_loss: 0.4296 - val_acc: 0.8894\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5999 - acc: 0.8247\n",
      "Epoch 00151: val_loss improved from 0.42621 to 0.41950, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/151-0.4195.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.5998 - acc: 0.8247 - val_loss: 0.4195 - val_acc: 0.8891\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5972 - acc: 0.8249\n",
      "Epoch 00152: val_loss did not improve from 0.41950\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.5972 - acc: 0.8249 - val_loss: 0.4226 - val_acc: 0.8884\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5998 - acc: 0.8258\n",
      "Epoch 00153: val_loss did not improve from 0.41950\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.5997 - acc: 0.8258 - val_loss: 0.4206 - val_acc: 0.8891\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5942 - acc: 0.8264\n",
      "Epoch 00154: val_loss did not improve from 0.41950\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.5944 - acc: 0.8264 - val_loss: 0.4278 - val_acc: 0.8880\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5937 - acc: 0.8298\n",
      "Epoch 00155: val_loss did not improve from 0.41950\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.5937 - acc: 0.8298 - val_loss: 0.4280 - val_acc: 0.8877\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5887 - acc: 0.8264\n",
      "Epoch 00156: val_loss did not improve from 0.41950\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.5887 - acc: 0.8264 - val_loss: 0.4231 - val_acc: 0.8889\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5832 - acc: 0.8269\n",
      "Epoch 00157: val_loss improved from 0.41950 to 0.41779, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/157-0.4178.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5832 - acc: 0.8270 - val_loss: 0.4178 - val_acc: 0.8921\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5934 - acc: 0.8261\n",
      "Epoch 00158: val_loss did not improve from 0.41779\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5933 - acc: 0.8261 - val_loss: 0.4194 - val_acc: 0.8898\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5806 - acc: 0.8307\n",
      "Epoch 00159: val_loss improved from 0.41779 to 0.41762, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/159-0.4176.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.5807 - acc: 0.8307 - val_loss: 0.4176 - val_acc: 0.8917\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5869 - acc: 0.8275\n",
      "Epoch 00160: val_loss improved from 0.41762 to 0.41365, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/160-0.4137.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5869 - acc: 0.8275 - val_loss: 0.4137 - val_acc: 0.8884\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5854 - acc: 0.8288\n",
      "Epoch 00161: val_loss did not improve from 0.41365\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.5855 - acc: 0.8287 - val_loss: 0.4320 - val_acc: 0.8863\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5743 - acc: 0.8336\n",
      "Epoch 00162: val_loss improved from 0.41365 to 0.41022, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/162-0.4102.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5743 - acc: 0.8336 - val_loss: 0.4102 - val_acc: 0.8942\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5753 - acc: 0.8299\n",
      "Epoch 00163: val_loss improved from 0.41022 to 0.40994, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/163-0.4099.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5756 - acc: 0.8299 - val_loss: 0.4099 - val_acc: 0.8935\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5788 - acc: 0.8323\n",
      "Epoch 00164: val_loss did not improve from 0.40994\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.5788 - acc: 0.8323 - val_loss: 0.4181 - val_acc: 0.8901\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5747 - acc: 0.8321\n",
      "Epoch 00165: val_loss did not improve from 0.40994\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.5747 - acc: 0.8320 - val_loss: 0.4116 - val_acc: 0.8926\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5762 - acc: 0.8329\n",
      "Epoch 00166: val_loss did not improve from 0.40994\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.5762 - acc: 0.8329 - val_loss: 0.4188 - val_acc: 0.8877\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5757 - acc: 0.8288\n",
      "Epoch 00167: val_loss improved from 0.40994 to 0.40449, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/167-0.4045.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5757 - acc: 0.8288 - val_loss: 0.4045 - val_acc: 0.8970\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5762 - acc: 0.8325\n",
      "Epoch 00168: val_loss improved from 0.40449 to 0.40432, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/168-0.4043.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.5762 - acc: 0.8325 - val_loss: 0.4043 - val_acc: 0.8952\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5707 - acc: 0.8317\n",
      "Epoch 00169: val_loss did not improve from 0.40432\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.5707 - acc: 0.8317 - val_loss: 0.4186 - val_acc: 0.8912\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5679 - acc: 0.8350\n",
      "Epoch 00170: val_loss did not improve from 0.40432\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5679 - acc: 0.8350 - val_loss: 0.4075 - val_acc: 0.8931\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5686 - acc: 0.8336\n",
      "Epoch 00171: val_loss improved from 0.40432 to 0.40120, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/171-0.4012.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.5686 - acc: 0.8336 - val_loss: 0.4012 - val_acc: 0.9005\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5657 - acc: 0.8341\n",
      "Epoch 00172: val_loss did not improve from 0.40120\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5656 - acc: 0.8341 - val_loss: 0.4081 - val_acc: 0.8966\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5639 - acc: 0.8361\n",
      "Epoch 00173: val_loss improved from 0.40120 to 0.39430, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/173-0.3943.hdf5\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 0.5638 - acc: 0.8362 - val_loss: 0.3943 - val_acc: 0.9024\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5609 - acc: 0.8355\n",
      "Epoch 00174: val_loss did not improve from 0.39430\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.5609 - acc: 0.8355 - val_loss: 0.3979 - val_acc: 0.8977\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5650 - acc: 0.8348\n",
      "Epoch 00175: val_loss did not improve from 0.39430\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.5649 - acc: 0.8348 - val_loss: 0.4034 - val_acc: 0.8968\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5618 - acc: 0.8357\n",
      "Epoch 00176: val_loss did not improve from 0.39430\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.5618 - acc: 0.8356 - val_loss: 0.4005 - val_acc: 0.8968\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5633 - acc: 0.8350\n",
      "Epoch 00177: val_loss did not improve from 0.39430\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5633 - acc: 0.8350 - val_loss: 0.4014 - val_acc: 0.8987\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5617 - acc: 0.8370\n",
      "Epoch 00178: val_loss did not improve from 0.39430\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.5617 - acc: 0.8370 - val_loss: 0.3964 - val_acc: 0.8980\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5555 - acc: 0.8361\n",
      "Epoch 00179: val_loss did not improve from 0.39430\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5554 - acc: 0.8361 - val_loss: 0.3991 - val_acc: 0.8984\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5567 - acc: 0.8346\n",
      "Epoch 00180: val_loss improved from 0.39430 to 0.39228, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/180-0.3923.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5568 - acc: 0.8346 - val_loss: 0.3923 - val_acc: 0.8980\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5497 - acc: 0.8383\n",
      "Epoch 00181: val_loss did not improve from 0.39228\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.5496 - acc: 0.8384 - val_loss: 0.3938 - val_acc: 0.9031\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5503 - acc: 0.8366\n",
      "Epoch 00182: val_loss did not improve from 0.39228\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.5502 - acc: 0.8366 - val_loss: 0.4268 - val_acc: 0.8898\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5516 - acc: 0.8395\n",
      "Epoch 00183: val_loss improved from 0.39228 to 0.38965, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/183-0.3897.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.5515 - acc: 0.8396 - val_loss: 0.3897 - val_acc: 0.9031\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5520 - acc: 0.8376\n",
      "Epoch 00184: val_loss did not improve from 0.38965\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5520 - acc: 0.8376 - val_loss: 0.3950 - val_acc: 0.9024\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5528 - acc: 0.8377\n",
      "Epoch 00185: val_loss did not improve from 0.38965\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5528 - acc: 0.8377 - val_loss: 0.3964 - val_acc: 0.8984\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5483 - acc: 0.8373\n",
      "Epoch 00186: val_loss improved from 0.38965 to 0.38351, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/186-0.3835.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.5483 - acc: 0.8373 - val_loss: 0.3835 - val_acc: 0.9010\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5484 - acc: 0.8402\n",
      "Epoch 00187: val_loss did not improve from 0.38351\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.5485 - acc: 0.8402 - val_loss: 0.3887 - val_acc: 0.9017\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5456 - acc: 0.8389\n",
      "Epoch 00188: val_loss improved from 0.38351 to 0.38068, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/188-0.3807.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5456 - acc: 0.8389 - val_loss: 0.3807 - val_acc: 0.9036\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5441 - acc: 0.8410\n",
      "Epoch 00189: val_loss did not improve from 0.38068\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.5441 - acc: 0.8410 - val_loss: 0.3914 - val_acc: 0.9001\n",
      "Epoch 190/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5441 - acc: 0.8392\n",
      "Epoch 00190: val_loss did not improve from 0.38068\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.5445 - acc: 0.8391 - val_loss: 0.3842 - val_acc: 0.9036\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5389 - acc: 0.8403\n",
      "Epoch 00191: val_loss did not improve from 0.38068\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5389 - acc: 0.8403 - val_loss: 0.3836 - val_acc: 0.9022\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5447 - acc: 0.8417\n",
      "Epoch 00192: val_loss did not improve from 0.38068\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.5446 - acc: 0.8417 - val_loss: 0.3851 - val_acc: 0.9038\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5365 - acc: 0.8424\n",
      "Epoch 00193: val_loss did not improve from 0.38068\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5365 - acc: 0.8424 - val_loss: 0.3887 - val_acc: 0.9024\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5360 - acc: 0.8427\n",
      "Epoch 00194: val_loss did not improve from 0.38068\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.5360 - acc: 0.8427 - val_loss: 0.3874 - val_acc: 0.9029\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5385 - acc: 0.8424\n",
      "Epoch 00195: val_loss did not improve from 0.38068\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.5386 - acc: 0.8424 - val_loss: 0.3929 - val_acc: 0.8970\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5365 - acc: 0.8415\n",
      "Epoch 00196: val_loss improved from 0.38068 to 0.37397, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/196-0.3740.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.5365 - acc: 0.8415 - val_loss: 0.3740 - val_acc: 0.9019\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5384 - acc: 0.8415\n",
      "Epoch 00197: val_loss did not improve from 0.37397\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5384 - acc: 0.8415 - val_loss: 0.3864 - val_acc: 0.9050\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5346 - acc: 0.8435\n",
      "Epoch 00198: val_loss did not improve from 0.37397\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.5347 - acc: 0.8435 - val_loss: 0.3844 - val_acc: 0.9050\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5342 - acc: 0.8432\n",
      "Epoch 00199: val_loss did not improve from 0.37397\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.5342 - acc: 0.8432 - val_loss: 0.3897 - val_acc: 0.8987\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5317 - acc: 0.8445\n",
      "Epoch 00200: val_loss did not improve from 0.37397\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5317 - acc: 0.8445 - val_loss: 0.3743 - val_acc: 0.9052\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5303 - acc: 0.8430\n",
      "Epoch 00201: val_loss did not improve from 0.37397\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.5303 - acc: 0.8430 - val_loss: 0.3740 - val_acc: 0.9019\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5310 - acc: 0.8448\n",
      "Epoch 00202: val_loss did not improve from 0.37397\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5310 - acc: 0.8448 - val_loss: 0.3954 - val_acc: 0.8994\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5296 - acc: 0.8451\n",
      "Epoch 00203: val_loss improved from 0.37397 to 0.37392, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/203-0.3739.hdf5\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.5296 - acc: 0.8450 - val_loss: 0.3739 - val_acc: 0.9029\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5247 - acc: 0.8443\n",
      "Epoch 00204: val_loss improved from 0.37392 to 0.37370, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/204-0.3737.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5247 - acc: 0.8443 - val_loss: 0.3737 - val_acc: 0.9026\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5280 - acc: 0.8446\n",
      "Epoch 00205: val_loss did not improve from 0.37370\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5280 - acc: 0.8446 - val_loss: 0.3778 - val_acc: 0.9017\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5221 - acc: 0.8458\n",
      "Epoch 00206: val_loss did not improve from 0.37370\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.5222 - acc: 0.8458 - val_loss: 0.3816 - val_acc: 0.9054\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5328 - acc: 0.8439\n",
      "Epoch 00207: val_loss did not improve from 0.37370\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.5330 - acc: 0.8439 - val_loss: 0.3788 - val_acc: 0.9050\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5193 - acc: 0.8471\n",
      "Epoch 00208: val_loss improved from 0.37370 to 0.36953, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/208-0.3695.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5193 - acc: 0.8471 - val_loss: 0.3695 - val_acc: 0.9033\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5177 - acc: 0.8457\n",
      "Epoch 00209: val_loss did not improve from 0.36953\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5178 - acc: 0.8457 - val_loss: 0.3721 - val_acc: 0.9085\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5203 - acc: 0.8465\n",
      "Epoch 00210: val_loss did not improve from 0.36953\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.5203 - acc: 0.8465 - val_loss: 0.3788 - val_acc: 0.9064\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5229 - acc: 0.8454\n",
      "Epoch 00211: val_loss did not improve from 0.36953\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.5229 - acc: 0.8454 - val_loss: 0.3743 - val_acc: 0.9071\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5156 - acc: 0.8465\n",
      "Epoch 00212: val_loss improved from 0.36953 to 0.36738, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/212-0.3674.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.5156 - acc: 0.8465 - val_loss: 0.3674 - val_acc: 0.9054\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5133 - acc: 0.8474\n",
      "Epoch 00213: val_loss did not improve from 0.36738\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.5133 - acc: 0.8474 - val_loss: 0.3752 - val_acc: 0.9057\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5186 - acc: 0.8458\n",
      "Epoch 00214: val_loss improved from 0.36738 to 0.36644, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/214-0.3664.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.5187 - acc: 0.8458 - val_loss: 0.3664 - val_acc: 0.9087\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5173 - acc: 0.8497\n",
      "Epoch 00215: val_loss did not improve from 0.36644\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.5173 - acc: 0.8497 - val_loss: 0.3695 - val_acc: 0.9080\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5124 - acc: 0.8491\n",
      "Epoch 00216: val_loss did not improve from 0.36644\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5124 - acc: 0.8492 - val_loss: 0.3715 - val_acc: 0.9087\n",
      "Epoch 217/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5157 - acc: 0.8475\n",
      "Epoch 00217: val_loss did not improve from 0.36644\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.5156 - acc: 0.8475 - val_loss: 0.3700 - val_acc: 0.9038\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5172 - acc: 0.8466\n",
      "Epoch 00218: val_loss did not improve from 0.36644\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5171 - acc: 0.8467 - val_loss: 0.3821 - val_acc: 0.9043\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5158 - acc: 0.8469\n",
      "Epoch 00219: val_loss improved from 0.36644 to 0.36321, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/219-0.3632.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5159 - acc: 0.8469 - val_loss: 0.3632 - val_acc: 0.9096\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5117 - acc: 0.8480\n",
      "Epoch 00220: val_loss did not improve from 0.36321\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5116 - acc: 0.8480 - val_loss: 0.3719 - val_acc: 0.9064\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5089 - acc: 0.8498\n",
      "Epoch 00221: val_loss improved from 0.36321 to 0.36129, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/221-0.3613.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5090 - acc: 0.8497 - val_loss: 0.3613 - val_acc: 0.9068\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5128 - acc: 0.8482\n",
      "Epoch 00222: val_loss did not improve from 0.36129\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.5128 - acc: 0.8482 - val_loss: 0.3712 - val_acc: 0.9033\n",
      "Epoch 223/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5083 - acc: 0.8493\n",
      "Epoch 00223: val_loss did not improve from 0.36129\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5083 - acc: 0.8494 - val_loss: 0.3827 - val_acc: 0.8998\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5046 - acc: 0.8499\n",
      "Epoch 00224: val_loss did not improve from 0.36129\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.5045 - acc: 0.8499 - val_loss: 0.3692 - val_acc: 0.9073\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5053 - acc: 0.8505\n",
      "Epoch 00225: val_loss did not improve from 0.36129\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.5053 - acc: 0.8505 - val_loss: 0.3688 - val_acc: 0.9043\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5099 - acc: 0.8486\n",
      "Epoch 00226: val_loss did not improve from 0.36129\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.5099 - acc: 0.8486 - val_loss: 0.3724 - val_acc: 0.9066\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5062 - acc: 0.8513\n",
      "Epoch 00227: val_loss did not improve from 0.36129\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.5062 - acc: 0.8514 - val_loss: 0.3818 - val_acc: 0.9001\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5034 - acc: 0.8503\n",
      "Epoch 00228: val_loss improved from 0.36129 to 0.35915, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/228-0.3592.hdf5\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.5035 - acc: 0.8503 - val_loss: 0.3592 - val_acc: 0.9092\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5036 - acc: 0.8519\n",
      "Epoch 00229: val_loss did not improve from 0.35915\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.5036 - acc: 0.8519 - val_loss: 0.3705 - val_acc: 0.9064\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5019 - acc: 0.8522\n",
      "Epoch 00230: val_loss did not improve from 0.35915\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.5019 - acc: 0.8522 - val_loss: 0.3629 - val_acc: 0.9089\n",
      "Epoch 231/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4995 - acc: 0.8523\n",
      "Epoch 00231: val_loss did not improve from 0.35915\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4995 - acc: 0.8523 - val_loss: 0.3711 - val_acc: 0.9047\n",
      "Epoch 232/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4999 - acc: 0.8527\n",
      "Epoch 00232: val_loss improved from 0.35915 to 0.35612, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/232-0.3561.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4999 - acc: 0.8527 - val_loss: 0.3561 - val_acc: 0.9110\n",
      "Epoch 233/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5101 - acc: 0.8520\n",
      "Epoch 00233: val_loss improved from 0.35612 to 0.35406, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/233-0.3541.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.5102 - acc: 0.8520 - val_loss: 0.3541 - val_acc: 0.9073\n",
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4945 - acc: 0.8524\n",
      "Epoch 00234: val_loss did not improve from 0.35406\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4945 - acc: 0.8524 - val_loss: 0.3597 - val_acc: 0.9094\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4975 - acc: 0.8547\n",
      "Epoch 00235: val_loss did not improve from 0.35406\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4975 - acc: 0.8547 - val_loss: 0.3669 - val_acc: 0.9036\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4937 - acc: 0.8526\n",
      "Epoch 00236: val_loss improved from 0.35406 to 0.35310, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/236-0.3531.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4937 - acc: 0.8526 - val_loss: 0.3531 - val_acc: 0.9096\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4934 - acc: 0.8538\n",
      "Epoch 00237: val_loss improved from 0.35310 to 0.35120, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/237-0.3512.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4933 - acc: 0.8539 - val_loss: 0.3512 - val_acc: 0.9099\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4963 - acc: 0.8517\n",
      "Epoch 00238: val_loss did not improve from 0.35120\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4963 - acc: 0.8517 - val_loss: 0.3606 - val_acc: 0.9092\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4917 - acc: 0.8552\n",
      "Epoch 00239: val_loss did not improve from 0.35120\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.4918 - acc: 0.8552 - val_loss: 0.3569 - val_acc: 0.9078\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4950 - acc: 0.8512\n",
      "Epoch 00240: val_loss did not improve from 0.35120\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4949 - acc: 0.8513 - val_loss: 0.3616 - val_acc: 0.9052\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4900 - acc: 0.8559\n",
      "Epoch 00241: val_loss improved from 0.35120 to 0.35026, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/241-0.3503.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4900 - acc: 0.8559 - val_loss: 0.3503 - val_acc: 0.9092\n",
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4911 - acc: 0.8554\n",
      "Epoch 00242: val_loss did not improve from 0.35026\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.4911 - acc: 0.8554 - val_loss: 0.3536 - val_acc: 0.9085\n",
      "Epoch 243/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4935 - acc: 0.8547\n",
      "Epoch 00243: val_loss did not improve from 0.35026\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4935 - acc: 0.8547 - val_loss: 0.3571 - val_acc: 0.9068\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4903 - acc: 0.8551\n",
      "Epoch 00244: val_loss did not improve from 0.35026\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4902 - acc: 0.8551 - val_loss: 0.3540 - val_acc: 0.9103\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4957 - acc: 0.8552\n",
      "Epoch 00245: val_loss did not improve from 0.35026\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4956 - acc: 0.8553 - val_loss: 0.3600 - val_acc: 0.9075\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4926 - acc: 0.8546\n",
      "Epoch 00246: val_loss did not improve from 0.35026\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.4926 - acc: 0.8546 - val_loss: 0.3519 - val_acc: 0.9092\n",
      "Epoch 247/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4864 - acc: 0.8554\n",
      "Epoch 00247: val_loss did not improve from 0.35026\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4864 - acc: 0.8554 - val_loss: 0.3555 - val_acc: 0.9096\n",
      "Epoch 248/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4834 - acc: 0.8583\n",
      "Epoch 00248: val_loss did not improve from 0.35026\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4834 - acc: 0.8583 - val_loss: 0.3550 - val_acc: 0.9075\n",
      "Epoch 249/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4923 - acc: 0.8533\n",
      "Epoch 00249: val_loss improved from 0.35026 to 0.34726, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/249-0.3473.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4923 - acc: 0.8533 - val_loss: 0.3473 - val_acc: 0.9106\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4846 - acc: 0.8561\n",
      "Epoch 00250: val_loss did not improve from 0.34726\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4846 - acc: 0.8561 - val_loss: 0.3498 - val_acc: 0.9136\n",
      "Epoch 251/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4883 - acc: 0.8544\n",
      "Epoch 00251: val_loss did not improve from 0.34726\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4883 - acc: 0.8544 - val_loss: 0.3537 - val_acc: 0.9075\n",
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4819 - acc: 0.8557\n",
      "Epoch 00252: val_loss did not improve from 0.34726\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4822 - acc: 0.8556 - val_loss: 0.3838 - val_acc: 0.8966\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4848 - acc: 0.8564\n",
      "Epoch 00253: val_loss improved from 0.34726 to 0.34242, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/253-0.3424.hdf5\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.4847 - acc: 0.8565 - val_loss: 0.3424 - val_acc: 0.9117\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4868 - acc: 0.8543\n",
      "Epoch 00254: val_loss did not improve from 0.34242\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4869 - acc: 0.8542 - val_loss: 0.3533 - val_acc: 0.9099\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4833 - acc: 0.8556\n",
      "Epoch 00255: val_loss did not improve from 0.34242\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4832 - acc: 0.8556 - val_loss: 0.3453 - val_acc: 0.9126\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4866 - acc: 0.8581\n",
      "Epoch 00256: val_loss did not improve from 0.34242\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4866 - acc: 0.8581 - val_loss: 0.3545 - val_acc: 0.9115\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4771 - acc: 0.8564\n",
      "Epoch 00257: val_loss did not improve from 0.34242\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.4771 - acc: 0.8564 - val_loss: 0.3558 - val_acc: 0.9129\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4769 - acc: 0.8596\n",
      "Epoch 00258: val_loss did not improve from 0.34242\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4769 - acc: 0.8596 - val_loss: 0.3551 - val_acc: 0.9101\n",
      "Epoch 259/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4790 - acc: 0.8586\n",
      "Epoch 00259: val_loss did not improve from 0.34242\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4790 - acc: 0.8586 - val_loss: 0.3443 - val_acc: 0.9103\n",
      "Epoch 260/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4823 - acc: 0.8565\n",
      "Epoch 00260: val_loss improved from 0.34242 to 0.34130, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/260-0.3413.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4823 - acc: 0.8564 - val_loss: 0.3413 - val_acc: 0.9117\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4788 - acc: 0.8576\n",
      "Epoch 00261: val_loss did not improve from 0.34130\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4787 - acc: 0.8577 - val_loss: 0.3424 - val_acc: 0.9101\n",
      "Epoch 262/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4789 - acc: 0.8578\n",
      "Epoch 00262: val_loss did not improve from 0.34130\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4789 - acc: 0.8578 - val_loss: 0.3525 - val_acc: 0.9057\n",
      "Epoch 263/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4757 - acc: 0.8590\n",
      "Epoch 00263: val_loss did not improve from 0.34130\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4758 - acc: 0.8590 - val_loss: 0.3437 - val_acc: 0.9110\n",
      "Epoch 264/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4772 - acc: 0.8593\n",
      "Epoch 00264: val_loss did not improve from 0.34130\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4772 - acc: 0.8593 - val_loss: 0.3429 - val_acc: 0.9096\n",
      "Epoch 265/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4736 - acc: 0.8580\n",
      "Epoch 00265: val_loss did not improve from 0.34130\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4737 - acc: 0.8580 - val_loss: 0.3426 - val_acc: 0.9096\n",
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4729 - acc: 0.8587\n",
      "Epoch 00266: val_loss improved from 0.34130 to 0.33801, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/266-0.3380.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4729 - acc: 0.8587 - val_loss: 0.3380 - val_acc: 0.9110\n",
      "Epoch 267/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4732 - acc: 0.8594\n",
      "Epoch 00267: val_loss did not improve from 0.33801\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.4731 - acc: 0.8594 - val_loss: 0.3496 - val_acc: 0.9103\n",
      "Epoch 268/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4758 - acc: 0.8585\n",
      "Epoch 00268: val_loss improved from 0.33801 to 0.33679, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/268-0.3368.hdf5\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.4758 - acc: 0.8585 - val_loss: 0.3368 - val_acc: 0.9136\n",
      "Epoch 269/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4693 - acc: 0.8591\n",
      "Epoch 00269: val_loss did not improve from 0.33679\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4693 - acc: 0.8591 - val_loss: 0.3433 - val_acc: 0.9106\n",
      "Epoch 270/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4724 - acc: 0.8585\n",
      "Epoch 00270: val_loss did not improve from 0.33679\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4724 - acc: 0.8585 - val_loss: 0.3389 - val_acc: 0.9092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 271/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4711 - acc: 0.8610\n",
      "Epoch 00271: val_loss did not improve from 0.33679\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4710 - acc: 0.8610 - val_loss: 0.3379 - val_acc: 0.9110\n",
      "Epoch 272/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4688 - acc: 0.8599\n",
      "Epoch 00272: val_loss did not improve from 0.33679\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4688 - acc: 0.8599 - val_loss: 0.3395 - val_acc: 0.9126\n",
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4730 - acc: 0.8608\n",
      "Epoch 00273: val_loss did not improve from 0.33679\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4729 - acc: 0.8609 - val_loss: 0.3462 - val_acc: 0.9099\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4698 - acc: 0.8591\n",
      "Epoch 00274: val_loss improved from 0.33679 to 0.33673, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/274-0.3367.hdf5\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.4698 - acc: 0.8591 - val_loss: 0.3367 - val_acc: 0.9136\n",
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4680 - acc: 0.8613\n",
      "Epoch 00275: val_loss improved from 0.33673 to 0.33376, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/275-0.3338.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4680 - acc: 0.8613 - val_loss: 0.3338 - val_acc: 0.9119\n",
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4670 - acc: 0.8596\n",
      "Epoch 00276: val_loss did not improve from 0.33376\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.4671 - acc: 0.8596 - val_loss: 0.3387 - val_acc: 0.9101\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4674 - acc: 0.8602\n",
      "Epoch 00277: val_loss did not improve from 0.33376\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4673 - acc: 0.8602 - val_loss: 0.3347 - val_acc: 0.9119\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4650 - acc: 0.8636\n",
      "Epoch 00278: val_loss did not improve from 0.33376\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4650 - acc: 0.8636 - val_loss: 0.3386 - val_acc: 0.9129\n",
      "Epoch 279/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4637 - acc: 0.8622\n",
      "Epoch 00279: val_loss did not improve from 0.33376\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4638 - acc: 0.8622 - val_loss: 0.3353 - val_acc: 0.9126\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4703 - acc: 0.8608\n",
      "Epoch 00280: val_loss did not improve from 0.33376\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4703 - acc: 0.8607 - val_loss: 0.3361 - val_acc: 0.9124\n",
      "Epoch 281/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8628\n",
      "Epoch 00281: val_loss did not improve from 0.33376\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4654 - acc: 0.8628 - val_loss: 0.3473 - val_acc: 0.9119\n",
      "Epoch 282/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4688 - acc: 0.8601\n",
      "Epoch 00282: val_loss did not improve from 0.33376\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4688 - acc: 0.8601 - val_loss: 0.3426 - val_acc: 0.9124\n",
      "Epoch 283/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4630 - acc: 0.8646\n",
      "Epoch 00283: val_loss did not improve from 0.33376\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.4630 - acc: 0.8646 - val_loss: 0.3356 - val_acc: 0.9129\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4576 - acc: 0.8639\n",
      "Epoch 00284: val_loss did not improve from 0.33376\n",
      "36805/36805 [==============================] - 16s 445us/sample - loss: 0.4575 - acc: 0.8640 - val_loss: 0.3362 - val_acc: 0.9136\n",
      "Epoch 285/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4593 - acc: 0.8618\n",
      "Epoch 00285: val_loss did not improve from 0.33376\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4593 - acc: 0.8618 - val_loss: 0.3371 - val_acc: 0.9129\n",
      "Epoch 286/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4594 - acc: 0.8631\n",
      "Epoch 00286: val_loss improved from 0.33376 to 0.33335, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/286-0.3334.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4595 - acc: 0.8630 - val_loss: 0.3334 - val_acc: 0.9133\n",
      "Epoch 287/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.8624\n",
      "Epoch 00287: val_loss did not improve from 0.33335\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4611 - acc: 0.8624 - val_loss: 0.3493 - val_acc: 0.9085\n",
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4583 - acc: 0.8628\n",
      "Epoch 00288: val_loss improved from 0.33335 to 0.33332, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/288-0.3333.hdf5\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.4583 - acc: 0.8628 - val_loss: 0.3333 - val_acc: 0.9126\n",
      "Epoch 289/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4567 - acc: 0.8630\n",
      "Epoch 00289: val_loss did not improve from 0.33332\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4567 - acc: 0.8630 - val_loss: 0.3393 - val_acc: 0.9136\n",
      "Epoch 290/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4575 - acc: 0.8652\n",
      "Epoch 00290: val_loss did not improve from 0.33332\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4575 - acc: 0.8651 - val_loss: 0.3341 - val_acc: 0.9138\n",
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4534 - acc: 0.8627\n",
      "Epoch 00291: val_loss did not improve from 0.33332\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.4534 - acc: 0.8627 - val_loss: 0.3500 - val_acc: 0.9082\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4561 - acc: 0.8652\n",
      "Epoch 00292: val_loss improved from 0.33332 to 0.33233, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/292-0.3323.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4561 - acc: 0.8652 - val_loss: 0.3323 - val_acc: 0.9126\n",
      "Epoch 293/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4612 - acc: 0.8624\n",
      "Epoch 00293: val_loss improved from 0.33233 to 0.33043, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/293-0.3304.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4612 - acc: 0.8624 - val_loss: 0.3304 - val_acc: 0.9124\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4589 - acc: 0.8637\n",
      "Epoch 00294: val_loss did not improve from 0.33043\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4589 - acc: 0.8637 - val_loss: 0.3401 - val_acc: 0.9126\n",
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4548 - acc: 0.8633\n",
      "Epoch 00295: val_loss did not improve from 0.33043\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4547 - acc: 0.8633 - val_loss: 0.3342 - val_acc: 0.9138\n",
      "Epoch 296/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4567 - acc: 0.8619\n",
      "Epoch 00296: val_loss did not improve from 0.33043\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4567 - acc: 0.8619 - val_loss: 0.3322 - val_acc: 0.9101\n",
      "Epoch 297/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4519 - acc: 0.8656\n",
      "Epoch 00297: val_loss did not improve from 0.33043\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4519 - acc: 0.8656 - val_loss: 0.3451 - val_acc: 0.9115\n",
      "Epoch 298/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4556 - acc: 0.8621\n",
      "Epoch 00298: val_loss did not improve from 0.33043\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.4555 - acc: 0.8621 - val_loss: 0.3321 - val_acc: 0.9136\n",
      "Epoch 299/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4507 - acc: 0.8661\n",
      "Epoch 00299: val_loss improved from 0.33043 to 0.32738, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/299-0.3274.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4507 - acc: 0.8661 - val_loss: 0.3274 - val_acc: 0.9150\n",
      "Epoch 300/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4498 - acc: 0.8665\n",
      "Epoch 00300: val_loss did not improve from 0.32738\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4499 - acc: 0.8665 - val_loss: 0.3345 - val_acc: 0.9126\n",
      "Epoch 301/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4500 - acc: 0.8665\n",
      "Epoch 00301: val_loss did not improve from 0.32738\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4501 - acc: 0.8665 - val_loss: 0.3311 - val_acc: 0.9124\n",
      "Epoch 302/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4507 - acc: 0.8664\n",
      "Epoch 00302: val_loss improved from 0.32738 to 0.32727, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/302-0.3273.hdf5\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4507 - acc: 0.8663 - val_loss: 0.3273 - val_acc: 0.9168\n",
      "Epoch 303/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4514 - acc: 0.8651\n",
      "Epoch 00303: val_loss did not improve from 0.32727\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.4515 - acc: 0.8650 - val_loss: 0.3335 - val_acc: 0.9119\n",
      "Epoch 304/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4481 - acc: 0.8659\n",
      "Epoch 00304: val_loss did not improve from 0.32727\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.4480 - acc: 0.8659 - val_loss: 0.3344 - val_acc: 0.9129\n",
      "Epoch 305/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4524 - acc: 0.8646\n",
      "Epoch 00305: val_loss improved from 0.32727 to 0.32531, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/305-0.3253.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4524 - acc: 0.8646 - val_loss: 0.3253 - val_acc: 0.9152\n",
      "Epoch 306/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4506 - acc: 0.8670\n",
      "Epoch 00306: val_loss did not improve from 0.32531\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.4510 - acc: 0.8669 - val_loss: 0.3384 - val_acc: 0.9103\n",
      "Epoch 307/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4526 - acc: 0.8633\n",
      "Epoch 00307: val_loss did not improve from 0.32531\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4525 - acc: 0.8633 - val_loss: 0.3300 - val_acc: 0.9145\n",
      "Epoch 308/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.8673\n",
      "Epoch 00308: val_loss did not improve from 0.32531\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4472 - acc: 0.8673 - val_loss: 0.3254 - val_acc: 0.9164\n",
      "Epoch 309/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4473 - acc: 0.8657\n",
      "Epoch 00309: val_loss did not improve from 0.32531\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4473 - acc: 0.8657 - val_loss: 0.3301 - val_acc: 0.9131\n",
      "Epoch 310/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4448 - acc: 0.8681\n",
      "Epoch 00310: val_loss did not improve from 0.32531\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4448 - acc: 0.8681 - val_loss: 0.3311 - val_acc: 0.9150\n",
      "Epoch 311/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4503 - acc: 0.8669\n",
      "Epoch 00311: val_loss did not improve from 0.32531\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4504 - acc: 0.8669 - val_loss: 0.3363 - val_acc: 0.9129\n",
      "Epoch 312/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4451 - acc: 0.8659\n",
      "Epoch 00312: val_loss did not improve from 0.32531\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4451 - acc: 0.8659 - val_loss: 0.3307 - val_acc: 0.9136\n",
      "Epoch 313/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4471 - acc: 0.8668\n",
      "Epoch 00313: val_loss improved from 0.32531 to 0.32286, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/313-0.3229.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4471 - acc: 0.8668 - val_loss: 0.3229 - val_acc: 0.9166\n",
      "Epoch 314/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4458 - acc: 0.8654\n",
      "Epoch 00314: val_loss did not improve from 0.32286\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4458 - acc: 0.8654 - val_loss: 0.3361 - val_acc: 0.9117\n",
      "Epoch 315/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4393 - acc: 0.8680\n",
      "Epoch 00315: val_loss did not improve from 0.32286\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4393 - acc: 0.8680 - val_loss: 0.3267 - val_acc: 0.9150\n",
      "Epoch 316/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4505 - acc: 0.8673\n",
      "Epoch 00316: val_loss did not improve from 0.32286\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.4506 - acc: 0.8673 - val_loss: 0.3230 - val_acc: 0.9140\n",
      "Epoch 317/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4403 - acc: 0.8684\n",
      "Epoch 00317: val_loss improved from 0.32286 to 0.32282, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/317-0.3228.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4404 - acc: 0.8684 - val_loss: 0.3228 - val_acc: 0.9145\n",
      "Epoch 318/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4417 - acc: 0.8698\n",
      "Epoch 00318: val_loss did not improve from 0.32282\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4416 - acc: 0.8698 - val_loss: 0.3258 - val_acc: 0.9180\n",
      "Epoch 319/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4418 - acc: 0.8680\n",
      "Epoch 00319: val_loss did not improve from 0.32282\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4418 - acc: 0.8680 - val_loss: 0.3299 - val_acc: 0.9140\n",
      "Epoch 320/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4392 - acc: 0.8682\n",
      "Epoch 00320: val_loss improved from 0.32282 to 0.32142, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/320-0.3214.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4392 - acc: 0.8682 - val_loss: 0.3214 - val_acc: 0.9157\n",
      "Epoch 321/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4404 - acc: 0.8687\n",
      "Epoch 00321: val_loss did not improve from 0.32142\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4404 - acc: 0.8687 - val_loss: 0.3289 - val_acc: 0.9147\n",
      "Epoch 322/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4432 - acc: 0.8680\n",
      "Epoch 00322: val_loss did not improve from 0.32142\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4431 - acc: 0.8680 - val_loss: 0.3259 - val_acc: 0.9161\n",
      "Epoch 323/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4418 - acc: 0.8683\n",
      "Epoch 00323: val_loss did not improve from 0.32142\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4418 - acc: 0.8683 - val_loss: 0.3256 - val_acc: 0.9143\n",
      "Epoch 324/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4394 - acc: 0.8702\n",
      "Epoch 00324: val_loss did not improve from 0.32142\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4395 - acc: 0.8702 - val_loss: 0.3235 - val_acc: 0.9152\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4402 - acc: 0.8677\n",
      "Epoch 00325: val_loss did not improve from 0.32142\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4402 - acc: 0.8678 - val_loss: 0.3255 - val_acc: 0.9159\n",
      "Epoch 326/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4420 - acc: 0.8675\n",
      "Epoch 00326: val_loss did not improve from 0.32142\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4420 - acc: 0.8675 - val_loss: 0.3324 - val_acc: 0.9126\n",
      "Epoch 327/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4364 - acc: 0.8687\n",
      "Epoch 00327: val_loss did not improve from 0.32142\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4364 - acc: 0.8687 - val_loss: 0.3280 - val_acc: 0.9143\n",
      "Epoch 328/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4363 - acc: 0.8695\n",
      "Epoch 00328: val_loss did not improve from 0.32142\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4363 - acc: 0.8695 - val_loss: 0.3316 - val_acc: 0.9140\n",
      "Epoch 329/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4373 - acc: 0.8681\n",
      "Epoch 00329: val_loss did not improve from 0.32142\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4373 - acc: 0.8681 - val_loss: 0.3425 - val_acc: 0.9119\n",
      "Epoch 330/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4381 - acc: 0.8684\n",
      "Epoch 00330: val_loss did not improve from 0.32142\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4381 - acc: 0.8684 - val_loss: 0.3266 - val_acc: 0.9136\n",
      "Epoch 331/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4380 - acc: 0.8693\n",
      "Epoch 00331: val_loss did not improve from 0.32142\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4380 - acc: 0.8693 - val_loss: 0.3224 - val_acc: 0.9133\n",
      "Epoch 332/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4361 - acc: 0.8687\n",
      "Epoch 00332: val_loss did not improve from 0.32142\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4361 - acc: 0.8688 - val_loss: 0.3257 - val_acc: 0.9131\n",
      "Epoch 333/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4382 - acc: 0.8693\n",
      "Epoch 00333: val_loss did not improve from 0.32142\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4382 - acc: 0.8693 - val_loss: 0.3294 - val_acc: 0.9133\n",
      "Epoch 334/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4302 - acc: 0.8728\n",
      "Epoch 00334: val_loss improved from 0.32142 to 0.31922, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/334-0.3192.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4302 - acc: 0.8728 - val_loss: 0.3192 - val_acc: 0.9168\n",
      "Epoch 335/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4308 - acc: 0.8711\n",
      "Epoch 00335: val_loss did not improve from 0.31922\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4308 - acc: 0.8711 - val_loss: 0.3281 - val_acc: 0.9131\n",
      "Epoch 336/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4341 - acc: 0.8706\n",
      "Epoch 00336: val_loss did not improve from 0.31922\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4341 - acc: 0.8706 - val_loss: 0.3271 - val_acc: 0.9154\n",
      "Epoch 337/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4315 - acc: 0.8704\n",
      "Epoch 00337: val_loss did not improve from 0.31922\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4315 - acc: 0.8704 - val_loss: 0.3237 - val_acc: 0.9145\n",
      "Epoch 338/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4356 - acc: 0.8692\n",
      "Epoch 00338: val_loss did not improve from 0.31922\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4358 - acc: 0.8691 - val_loss: 0.3222 - val_acc: 0.9145\n",
      "Epoch 339/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4382 - acc: 0.8686\n",
      "Epoch 00339: val_loss improved from 0.31922 to 0.31827, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/339-0.3183.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4382 - acc: 0.8686 - val_loss: 0.3183 - val_acc: 0.9164\n",
      "Epoch 340/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4285 - acc: 0.8713\n",
      "Epoch 00340: val_loss did not improve from 0.31827\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4285 - acc: 0.8713 - val_loss: 0.3251 - val_acc: 0.9140\n",
      "Epoch 341/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4267 - acc: 0.8720\n",
      "Epoch 00341: val_loss did not improve from 0.31827\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4267 - acc: 0.8720 - val_loss: 0.3224 - val_acc: 0.9161\n",
      "Epoch 342/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4238 - acc: 0.8721\n",
      "Epoch 00342: val_loss improved from 0.31827 to 0.31801, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/342-0.3180.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4239 - acc: 0.8721 - val_loss: 0.3180 - val_acc: 0.9180\n",
      "Epoch 343/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4274 - acc: 0.8714\n",
      "Epoch 00343: val_loss did not improve from 0.31801\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4275 - acc: 0.8714 - val_loss: 0.3230 - val_acc: 0.9143\n",
      "Epoch 344/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4304 - acc: 0.8704\n",
      "Epoch 00344: val_loss did not improve from 0.31801\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4304 - acc: 0.8704 - val_loss: 0.3254 - val_acc: 0.9147\n",
      "Epoch 345/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4332 - acc: 0.8735\n",
      "Epoch 00345: val_loss did not improve from 0.31801\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4334 - acc: 0.8734 - val_loss: 0.3219 - val_acc: 0.9140\n",
      "Epoch 346/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4295 - acc: 0.8710\n",
      "Epoch 00346: val_loss did not improve from 0.31801\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4295 - acc: 0.8710 - val_loss: 0.3185 - val_acc: 0.9152\n",
      "Epoch 347/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4271 - acc: 0.8704\n",
      "Epoch 00347: val_loss did not improve from 0.31801\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4271 - acc: 0.8704 - val_loss: 0.3187 - val_acc: 0.9157\n",
      "Epoch 348/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4246 - acc: 0.8728\n",
      "Epoch 00348: val_loss improved from 0.31801 to 0.31720, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/348-0.3172.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4245 - acc: 0.8728 - val_loss: 0.3172 - val_acc: 0.9178\n",
      "Epoch 349/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4235 - acc: 0.8727\n",
      "Epoch 00349: val_loss did not improve from 0.31720\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4239 - acc: 0.8727 - val_loss: 0.3206 - val_acc: 0.9152\n",
      "Epoch 350/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4261 - acc: 0.8729\n",
      "Epoch 00350: val_loss did not improve from 0.31720\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4260 - acc: 0.8729 - val_loss: 0.3224 - val_acc: 0.9161\n",
      "Epoch 351/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4280 - acc: 0.8715\n",
      "Epoch 00351: val_loss improved from 0.31720 to 0.31519, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/351-0.3152.hdf5\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.4279 - acc: 0.8715 - val_loss: 0.3152 - val_acc: 0.9171\n",
      "Epoch 352/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4201 - acc: 0.8729\n",
      "Epoch 00352: val_loss improved from 0.31519 to 0.31430, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/352-0.3143.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4201 - acc: 0.8729 - val_loss: 0.3143 - val_acc: 0.9152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4253 - acc: 0.8710\n",
      "Epoch 00353: val_loss did not improve from 0.31430\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.4252 - acc: 0.8710 - val_loss: 0.3215 - val_acc: 0.9145\n",
      "Epoch 354/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4248 - acc: 0.8721\n",
      "Epoch 00354: val_loss did not improve from 0.31430\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.4248 - acc: 0.8721 - val_loss: 0.3278 - val_acc: 0.9131\n",
      "Epoch 355/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4291 - acc: 0.8715\n",
      "Epoch 00355: val_loss did not improve from 0.31430\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4291 - acc: 0.8715 - val_loss: 0.3200 - val_acc: 0.9154\n",
      "Epoch 356/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4232 - acc: 0.8747\n",
      "Epoch 00356: val_loss did not improve from 0.31430\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4233 - acc: 0.8747 - val_loss: 0.3210 - val_acc: 0.9154\n",
      "Epoch 357/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4268 - acc: 0.8709\n",
      "Epoch 00357: val_loss did not improve from 0.31430\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4268 - acc: 0.8709 - val_loss: 0.3157 - val_acc: 0.9145\n",
      "Epoch 358/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4217 - acc: 0.8738\n",
      "Epoch 00358: val_loss did not improve from 0.31430\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4216 - acc: 0.8738 - val_loss: 0.3182 - val_acc: 0.9171\n",
      "Epoch 359/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4241 - acc: 0.8730\n",
      "Epoch 00359: val_loss did not improve from 0.31430\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4241 - acc: 0.8730 - val_loss: 0.3173 - val_acc: 0.9171\n",
      "Epoch 360/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4173 - acc: 0.8757\n",
      "Epoch 00360: val_loss did not improve from 0.31430\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4173 - acc: 0.8758 - val_loss: 0.3249 - val_acc: 0.9138\n",
      "Epoch 361/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4223 - acc: 0.8728\n",
      "Epoch 00361: val_loss did not improve from 0.31430\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4223 - acc: 0.8728 - val_loss: 0.3152 - val_acc: 0.9164\n",
      "Epoch 362/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4176 - acc: 0.8751\n",
      "Epoch 00362: val_loss did not improve from 0.31430\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4176 - acc: 0.8751 - val_loss: 0.3191 - val_acc: 0.9157\n",
      "Epoch 363/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4204 - acc: 0.8732\n",
      "Epoch 00363: val_loss improved from 0.31430 to 0.31303, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/363-0.3130.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4203 - acc: 0.8732 - val_loss: 0.3130 - val_acc: 0.9173\n",
      "Epoch 364/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4183 - acc: 0.8741\n",
      "Epoch 00364: val_loss did not improve from 0.31303\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4183 - acc: 0.8741 - val_loss: 0.3188 - val_acc: 0.9147\n",
      "Epoch 365/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4194 - acc: 0.8737\n",
      "Epoch 00365: val_loss did not improve from 0.31303\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.4194 - acc: 0.8737 - val_loss: 0.3186 - val_acc: 0.9154\n",
      "Epoch 366/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4208 - acc: 0.8738\n",
      "Epoch 00366: val_loss did not improve from 0.31303\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.4207 - acc: 0.8738 - val_loss: 0.3192 - val_acc: 0.9159\n",
      "Epoch 367/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4238 - acc: 0.8725\n",
      "Epoch 00367: val_loss did not improve from 0.31303\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4238 - acc: 0.8725 - val_loss: 0.3174 - val_acc: 0.9145\n",
      "Epoch 368/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4213 - acc: 0.8741\n",
      "Epoch 00368: val_loss did not improve from 0.31303\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.4213 - acc: 0.8741 - val_loss: 0.3162 - val_acc: 0.9189\n",
      "Epoch 369/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4157 - acc: 0.8747\n",
      "Epoch 00369: val_loss did not improve from 0.31303\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4158 - acc: 0.8746 - val_loss: 0.3183 - val_acc: 0.9171\n",
      "Epoch 370/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4195 - acc: 0.8747\n",
      "Epoch 00370: val_loss did not improve from 0.31303\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.4197 - acc: 0.8746 - val_loss: 0.3168 - val_acc: 0.9157\n",
      "Epoch 371/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4134 - acc: 0.8745\n",
      "Epoch 00371: val_loss did not improve from 0.31303\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4134 - acc: 0.8745 - val_loss: 0.3144 - val_acc: 0.9171\n",
      "Epoch 372/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4145 - acc: 0.8755\n",
      "Epoch 00372: val_loss did not improve from 0.31303\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4144 - acc: 0.8755 - val_loss: 0.3139 - val_acc: 0.9175\n",
      "Epoch 373/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4152 - acc: 0.8743\n",
      "Epoch 00373: val_loss did not improve from 0.31303\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4153 - acc: 0.8743 - val_loss: 0.3159 - val_acc: 0.9159\n",
      "Epoch 374/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4156 - acc: 0.8736\n",
      "Epoch 00374: val_loss improved from 0.31303 to 0.31064, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/374-0.3106.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4157 - acc: 0.8736 - val_loss: 0.3106 - val_acc: 0.9159\n",
      "Epoch 375/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4186 - acc: 0.8769\n",
      "Epoch 00375: val_loss did not improve from 0.31064\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4188 - acc: 0.8769 - val_loss: 0.3130 - val_acc: 0.9173\n",
      "Epoch 376/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4112 - acc: 0.8775\n",
      "Epoch 00376: val_loss did not improve from 0.31064\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4111 - acc: 0.8775 - val_loss: 0.3428 - val_acc: 0.9096\n",
      "Epoch 377/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4162 - acc: 0.8729\n",
      "Epoch 00377: val_loss did not improve from 0.31064\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4161 - acc: 0.8730 - val_loss: 0.3141 - val_acc: 0.9150\n",
      "Epoch 378/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4188 - acc: 0.8746\n",
      "Epoch 00378: val_loss did not improve from 0.31064\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4188 - acc: 0.8746 - val_loss: 0.3121 - val_acc: 0.9180\n",
      "Epoch 379/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4094 - acc: 0.8766\n",
      "Epoch 00379: val_loss did not improve from 0.31064\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.4094 - acc: 0.8766 - val_loss: 0.3150 - val_acc: 0.9180\n",
      "Epoch 380/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4117 - acc: 0.8766\n",
      "Epoch 00380: val_loss did not improve from 0.31064\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4117 - acc: 0.8766 - val_loss: 0.3166 - val_acc: 0.9180\n",
      "Epoch 381/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4162 - acc: 0.8762\n",
      "Epoch 00381: val_loss did not improve from 0.31064\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4162 - acc: 0.8762 - val_loss: 0.3145 - val_acc: 0.9168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 382/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4116 - acc: 0.8763\n",
      "Epoch 00382: val_loss did not improve from 0.31064\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4116 - acc: 0.8763 - val_loss: 0.3217 - val_acc: 0.9159\n",
      "Epoch 383/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4099 - acc: 0.8752\n",
      "Epoch 00383: val_loss did not improve from 0.31064\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4102 - acc: 0.8752 - val_loss: 0.3240 - val_acc: 0.9168\n",
      "Epoch 384/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4174 - acc: 0.8751\n",
      "Epoch 00384: val_loss improved from 0.31064 to 0.30842, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/384-0.3084.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4173 - acc: 0.8751 - val_loss: 0.3084 - val_acc: 0.9185\n",
      "Epoch 385/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4128 - acc: 0.8761\n",
      "Epoch 00385: val_loss did not improve from 0.30842\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4128 - acc: 0.8761 - val_loss: 0.3149 - val_acc: 0.9161\n",
      "Epoch 386/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4085 - acc: 0.8781\n",
      "Epoch 00386: val_loss did not improve from 0.30842\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4085 - acc: 0.8781 - val_loss: 0.3194 - val_acc: 0.9145\n",
      "Epoch 387/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4146 - acc: 0.8761\n",
      "Epoch 00387: val_loss improved from 0.30842 to 0.30710, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/387-0.3071.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4146 - acc: 0.8761 - val_loss: 0.3071 - val_acc: 0.9171\n",
      "Epoch 388/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.8760\n",
      "Epoch 00388: val_loss did not improve from 0.30710\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4125 - acc: 0.8760 - val_loss: 0.3163 - val_acc: 0.9161\n",
      "Epoch 389/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4151 - acc: 0.8760\n",
      "Epoch 00389: val_loss did not improve from 0.30710\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4151 - acc: 0.8760 - val_loss: 0.3240 - val_acc: 0.9154\n",
      "Epoch 390/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4074 - acc: 0.8769\n",
      "Epoch 00390: val_loss did not improve from 0.30710\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4075 - acc: 0.8769 - val_loss: 0.3096 - val_acc: 0.9178\n",
      "Epoch 391/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4098 - acc: 0.8764\n",
      "Epoch 00391: val_loss did not improve from 0.30710\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4098 - acc: 0.8764 - val_loss: 0.3097 - val_acc: 0.9171\n",
      "Epoch 392/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4110 - acc: 0.8753\n",
      "Epoch 00392: val_loss did not improve from 0.30710\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.4110 - acc: 0.8753 - val_loss: 0.3198 - val_acc: 0.9168\n",
      "Epoch 393/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4098 - acc: 0.8771\n",
      "Epoch 00393: val_loss did not improve from 0.30710\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4098 - acc: 0.8771 - val_loss: 0.3156 - val_acc: 0.9164\n",
      "Epoch 394/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4074 - acc: 0.8791\n",
      "Epoch 00394: val_loss improved from 0.30710 to 0.30567, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/394-0.3057.hdf5\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.4074 - acc: 0.8791 - val_loss: 0.3057 - val_acc: 0.9157\n",
      "Epoch 395/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4067 - acc: 0.8768\n",
      "Epoch 00395: val_loss did not improve from 0.30567\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4067 - acc: 0.8768 - val_loss: 0.3081 - val_acc: 0.9187\n",
      "Epoch 396/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4036 - acc: 0.8773\n",
      "Epoch 00396: val_loss did not improve from 0.30567\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.4035 - acc: 0.8773 - val_loss: 0.3158 - val_acc: 0.9143\n",
      "Epoch 397/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4132 - acc: 0.8738\n",
      "Epoch 00397: val_loss did not improve from 0.30567\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4133 - acc: 0.8738 - val_loss: 0.3156 - val_acc: 0.9154\n",
      "Epoch 398/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4117 - acc: 0.8770\n",
      "Epoch 00398: val_loss did not improve from 0.30567\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4117 - acc: 0.8770 - val_loss: 0.3110 - val_acc: 0.9182\n",
      "Epoch 399/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4051 - acc: 0.8768\n",
      "Epoch 00399: val_loss did not improve from 0.30567\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4050 - acc: 0.8769 - val_loss: 0.3121 - val_acc: 0.9194\n",
      "Epoch 400/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4072 - acc: 0.8787\n",
      "Epoch 00400: val_loss did not improve from 0.30567\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4071 - acc: 0.8787 - val_loss: 0.3133 - val_acc: 0.9189\n",
      "Epoch 401/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4050 - acc: 0.8775\n",
      "Epoch 00401: val_loss did not improve from 0.30567\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4050 - acc: 0.8775 - val_loss: 0.3060 - val_acc: 0.9199\n",
      "Epoch 402/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4025 - acc: 0.8768\n",
      "Epoch 00402: val_loss did not improve from 0.30567\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4025 - acc: 0.8768 - val_loss: 0.3101 - val_acc: 0.9182\n",
      "Epoch 403/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4070 - acc: 0.8761\n",
      "Epoch 00403: val_loss did not improve from 0.30567\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4071 - acc: 0.8761 - val_loss: 0.3096 - val_acc: 0.9147\n",
      "Epoch 404/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4064 - acc: 0.8772\n",
      "Epoch 00404: val_loss did not improve from 0.30567\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4064 - acc: 0.8772 - val_loss: 0.3150 - val_acc: 0.9161\n",
      "Epoch 405/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4065 - acc: 0.8780\n",
      "Epoch 00405: val_loss did not improve from 0.30567\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.4066 - acc: 0.8780 - val_loss: 0.3074 - val_acc: 0.9201\n",
      "Epoch 406/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4081 - acc: 0.8779\n",
      "Epoch 00406: val_loss improved from 0.30567 to 0.30533, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/406-0.3053.hdf5\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.4081 - acc: 0.8779 - val_loss: 0.3053 - val_acc: 0.9171\n",
      "Epoch 407/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4004 - acc: 0.8812\n",
      "Epoch 00407: val_loss did not improve from 0.30533\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4003 - acc: 0.8812 - val_loss: 0.3075 - val_acc: 0.9171\n",
      "Epoch 408/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4064 - acc: 0.8774\n",
      "Epoch 00408: val_loss did not improve from 0.30533\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4064 - acc: 0.8774 - val_loss: 0.3170 - val_acc: 0.9138\n",
      "Epoch 409/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4066 - acc: 0.8776\n",
      "Epoch 00409: val_loss did not improve from 0.30533\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4066 - acc: 0.8776 - val_loss: 0.3064 - val_acc: 0.9171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 410/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4065 - acc: 0.8775\n",
      "Epoch 00410: val_loss did not improve from 0.30533\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.4065 - acc: 0.8775 - val_loss: 0.3112 - val_acc: 0.9159\n",
      "Epoch 411/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4049 - acc: 0.8757\n",
      "Epoch 00411: val_loss improved from 0.30533 to 0.30363, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/411-0.3036.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.4049 - acc: 0.8758 - val_loss: 0.3036 - val_acc: 0.9168\n",
      "Epoch 412/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4035 - acc: 0.8795\n",
      "Epoch 00412: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.4037 - acc: 0.8795 - val_loss: 0.3116 - val_acc: 0.9164\n",
      "Epoch 413/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4018 - acc: 0.8780\n",
      "Epoch 00413: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4019 - acc: 0.8780 - val_loss: 0.3111 - val_acc: 0.9152\n",
      "Epoch 414/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4041 - acc: 0.8787\n",
      "Epoch 00414: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.4041 - acc: 0.8787 - val_loss: 0.3101 - val_acc: 0.9185\n",
      "Epoch 415/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4030 - acc: 0.8778\n",
      "Epoch 00415: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4030 - acc: 0.8778 - val_loss: 0.3131 - val_acc: 0.9189\n",
      "Epoch 416/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4009 - acc: 0.8794\n",
      "Epoch 00416: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.4009 - acc: 0.8794 - val_loss: 0.3082 - val_acc: 0.9185\n",
      "Epoch 417/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4010 - acc: 0.8777\n",
      "Epoch 00417: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.4010 - acc: 0.8777 - val_loss: 0.3055 - val_acc: 0.9175\n",
      "Epoch 418/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4045 - acc: 0.8769\n",
      "Epoch 00418: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.4045 - acc: 0.8769 - val_loss: 0.3082 - val_acc: 0.9189\n",
      "Epoch 419/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3967 - acc: 0.8808\n",
      "Epoch 00419: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3966 - acc: 0.8808 - val_loss: 0.3049 - val_acc: 0.9171\n",
      "Epoch 420/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3986 - acc: 0.8808\n",
      "Epoch 00420: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.3986 - acc: 0.8808 - val_loss: 0.3045 - val_acc: 0.9178\n",
      "Epoch 421/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3990 - acc: 0.8796\n",
      "Epoch 00421: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.3990 - acc: 0.8796 - val_loss: 0.3083 - val_acc: 0.9171\n",
      "Epoch 422/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4038 - acc: 0.8789\n",
      "Epoch 00422: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.4038 - acc: 0.8789 - val_loss: 0.3107 - val_acc: 0.9175\n",
      "Epoch 423/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3991 - acc: 0.8798\n",
      "Epoch 00423: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3991 - acc: 0.8799 - val_loss: 0.3052 - val_acc: 0.9161\n",
      "Epoch 424/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3997 - acc: 0.8790\n",
      "Epoch 00424: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3997 - acc: 0.8790 - val_loss: 0.3055 - val_acc: 0.9187\n",
      "Epoch 425/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3953 - acc: 0.8806\n",
      "Epoch 00425: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3953 - acc: 0.8806 - val_loss: 0.3142 - val_acc: 0.9150\n",
      "Epoch 426/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3991 - acc: 0.8787\n",
      "Epoch 00426: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3991 - acc: 0.8787 - val_loss: 0.3128 - val_acc: 0.9173\n",
      "Epoch 427/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3965 - acc: 0.8813\n",
      "Epoch 00427: val_loss did not improve from 0.30363\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3966 - acc: 0.8813 - val_loss: 0.3055 - val_acc: 0.9178\n",
      "Epoch 428/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3998 - acc: 0.8792\n",
      "Epoch 00428: val_loss improved from 0.30363 to 0.30154, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/428-0.3015.hdf5\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.3998 - acc: 0.8792 - val_loss: 0.3015 - val_acc: 0.9187\n",
      "Epoch 429/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3922 - acc: 0.8800\n",
      "Epoch 00429: val_loss did not improve from 0.30154\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.3922 - acc: 0.8800 - val_loss: 0.3031 - val_acc: 0.9192\n",
      "Epoch 430/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3951 - acc: 0.8811\n",
      "Epoch 00430: val_loss did not improve from 0.30154\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.3951 - acc: 0.8811 - val_loss: 0.3044 - val_acc: 0.9152\n",
      "Epoch 431/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3915 - acc: 0.8806\n",
      "Epoch 00431: val_loss did not improve from 0.30154\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.3916 - acc: 0.8806 - val_loss: 0.3097 - val_acc: 0.9196\n",
      "Epoch 432/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3973 - acc: 0.8815\n",
      "Epoch 00432: val_loss did not improve from 0.30154\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3973 - acc: 0.8815 - val_loss: 0.3079 - val_acc: 0.9196\n",
      "Epoch 433/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3950 - acc: 0.8839\n",
      "Epoch 00433: val_loss did not improve from 0.30154\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3951 - acc: 0.8838 - val_loss: 0.3112 - val_acc: 0.9157\n",
      "Epoch 434/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3954 - acc: 0.8824\n",
      "Epoch 00434: val_loss did not improve from 0.30154\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3954 - acc: 0.8824 - val_loss: 0.3096 - val_acc: 0.9164\n",
      "Epoch 435/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3945 - acc: 0.8806\n",
      "Epoch 00435: val_loss improved from 0.30154 to 0.30085, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/435-0.3009.hdf5\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3945 - acc: 0.8806 - val_loss: 0.3009 - val_acc: 0.9175\n",
      "Epoch 436/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3938 - acc: 0.8808\n",
      "Epoch 00436: val_loss did not improve from 0.30085\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.3938 - acc: 0.8809 - val_loss: 0.3101 - val_acc: 0.9161\n",
      "Epoch 437/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3935 - acc: 0.8808\n",
      "Epoch 00437: val_loss did not improve from 0.30085\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3934 - acc: 0.8808 - val_loss: 0.3024 - val_acc: 0.9164\n",
      "Epoch 438/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3949 - acc: 0.8822\n",
      "Epoch 00438: val_loss did not improve from 0.30085\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3948 - acc: 0.8822 - val_loss: 0.3123 - val_acc: 0.9175\n",
      "Epoch 439/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3925 - acc: 0.8818\n",
      "Epoch 00439: val_loss did not improve from 0.30085\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3924 - acc: 0.8819 - val_loss: 0.3029 - val_acc: 0.9166\n",
      "Epoch 440/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3874 - acc: 0.8827\n",
      "Epoch 00440: val_loss did not improve from 0.30085\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3874 - acc: 0.8827 - val_loss: 0.3107 - val_acc: 0.9147\n",
      "Epoch 441/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3941 - acc: 0.8822\n",
      "Epoch 00441: val_loss did not improve from 0.30085\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.3941 - acc: 0.8822 - val_loss: 0.3040 - val_acc: 0.9171\n",
      "Epoch 442/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3868 - acc: 0.8835\n",
      "Epoch 00442: val_loss did not improve from 0.30085\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3868 - acc: 0.8835 - val_loss: 0.3061 - val_acc: 0.9168\n",
      "Epoch 443/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3916 - acc: 0.8810\n",
      "Epoch 00443: val_loss did not improve from 0.30085\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3916 - acc: 0.8810 - val_loss: 0.3038 - val_acc: 0.9199\n",
      "Epoch 444/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3927 - acc: 0.8801\n",
      "Epoch 00444: val_loss did not improve from 0.30085\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3927 - acc: 0.8801 - val_loss: 0.3100 - val_acc: 0.9166\n",
      "Epoch 445/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3890 - acc: 0.8822\n",
      "Epoch 00445: val_loss did not improve from 0.30085\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3890 - acc: 0.8822 - val_loss: 0.3013 - val_acc: 0.9175\n",
      "Epoch 446/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3902 - acc: 0.8808\n",
      "Epoch 00446: val_loss improved from 0.30085 to 0.29993, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/446-0.2999.hdf5\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.3901 - acc: 0.8808 - val_loss: 0.2999 - val_acc: 0.9173\n",
      "Epoch 447/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3897 - acc: 0.8813\n",
      "Epoch 00447: val_loss did not improve from 0.29993\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3897 - acc: 0.8813 - val_loss: 0.3071 - val_acc: 0.9182\n",
      "Epoch 448/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3934 - acc: 0.8809\n",
      "Epoch 00448: val_loss did not improve from 0.29993\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3934 - acc: 0.8809 - val_loss: 0.3071 - val_acc: 0.9145\n",
      "Epoch 449/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3877 - acc: 0.8824\n",
      "Epoch 00449: val_loss did not improve from 0.29993\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3876 - acc: 0.8824 - val_loss: 0.3086 - val_acc: 0.9208\n",
      "Epoch 450/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3901 - acc: 0.8809\n",
      "Epoch 00450: val_loss did not improve from 0.29993\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.3901 - acc: 0.8809 - val_loss: 0.3056 - val_acc: 0.9210\n",
      "Epoch 451/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3909 - acc: 0.8818\n",
      "Epoch 00451: val_loss improved from 0.29993 to 0.29911, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/451-0.2991.hdf5\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.3908 - acc: 0.8818 - val_loss: 0.2991 - val_acc: 0.9194\n",
      "Epoch 452/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3863 - acc: 0.8830\n",
      "Epoch 00452: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3864 - acc: 0.8829 - val_loss: 0.3065 - val_acc: 0.9161\n",
      "Epoch 453/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3904 - acc: 0.8811\n",
      "Epoch 00453: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3903 - acc: 0.8812 - val_loss: 0.3046 - val_acc: 0.9206\n",
      "Epoch 454/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3847 - acc: 0.8816\n",
      "Epoch 00454: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 448us/sample - loss: 0.3847 - acc: 0.8816 - val_loss: 0.3008 - val_acc: 0.9166\n",
      "Epoch 455/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3827 - acc: 0.8845\n",
      "Epoch 00455: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3827 - acc: 0.8845 - val_loss: 0.3025 - val_acc: 0.9201\n",
      "Epoch 456/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3898 - acc: 0.8821\n",
      "Epoch 00456: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3898 - acc: 0.8822 - val_loss: 0.3070 - val_acc: 0.9152\n",
      "Epoch 457/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3893 - acc: 0.8830\n",
      "Epoch 00457: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.3893 - acc: 0.8830 - val_loss: 0.3115 - val_acc: 0.9187\n",
      "Epoch 458/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3869 - acc: 0.8827\n",
      "Epoch 00458: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3869 - acc: 0.8827 - val_loss: 0.3074 - val_acc: 0.9171\n",
      "Epoch 459/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3840 - acc: 0.8846\n",
      "Epoch 00459: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.3841 - acc: 0.8846 - val_loss: 0.3039 - val_acc: 0.9187\n",
      "Epoch 460/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3865 - acc: 0.8820\n",
      "Epoch 00460: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3865 - acc: 0.8819 - val_loss: 0.3067 - val_acc: 0.9178\n",
      "Epoch 461/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3855 - acc: 0.8838\n",
      "Epoch 00461: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3855 - acc: 0.8838 - val_loss: 0.3087 - val_acc: 0.9157\n",
      "Epoch 462/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3908 - acc: 0.8801\n",
      "Epoch 00462: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3909 - acc: 0.8801 - val_loss: 0.3146 - val_acc: 0.9185\n",
      "Epoch 463/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3843 - acc: 0.8819\n",
      "Epoch 00463: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.3843 - acc: 0.8819 - val_loss: 0.3075 - val_acc: 0.9152\n",
      "Epoch 464/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3856 - acc: 0.8834\n",
      "Epoch 00464: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.3855 - acc: 0.8834 - val_loss: 0.3004 - val_acc: 0.9206\n",
      "Epoch 465/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3802 - acc: 0.8854\n",
      "Epoch 00465: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3803 - acc: 0.8853 - val_loss: 0.3021 - val_acc: 0.9196\n",
      "Epoch 466/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3833 - acc: 0.8815\n",
      "Epoch 00466: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3834 - acc: 0.8815 - val_loss: 0.3017 - val_acc: 0.9189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 467/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3851 - acc: 0.8825\n",
      "Epoch 00467: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.3850 - acc: 0.8825 - val_loss: 0.3040 - val_acc: 0.9173\n",
      "Epoch 468/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3889 - acc: 0.8815\n",
      "Epoch 00468: val_loss did not improve from 0.29911\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3889 - acc: 0.8816 - val_loss: 0.3132 - val_acc: 0.9143\n",
      "Epoch 469/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3851 - acc: 0.8837\n",
      "Epoch 00469: val_loss improved from 0.29911 to 0.29909, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/469-0.2991.hdf5\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3851 - acc: 0.8837 - val_loss: 0.2991 - val_acc: 0.9208\n",
      "Epoch 470/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3823 - acc: 0.8842\n",
      "Epoch 00470: val_loss did not improve from 0.29909\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3823 - acc: 0.8842 - val_loss: 0.3051 - val_acc: 0.9187\n",
      "Epoch 471/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3840 - acc: 0.8823\n",
      "Epoch 00471: val_loss did not improve from 0.29909\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3839 - acc: 0.8823 - val_loss: 0.3079 - val_acc: 0.9189\n",
      "Epoch 472/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3830 - acc: 0.8837\n",
      "Epoch 00472: val_loss did not improve from 0.29909\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3830 - acc: 0.8837 - val_loss: 0.3027 - val_acc: 0.9168\n",
      "Epoch 473/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3792 - acc: 0.8852\n",
      "Epoch 00473: val_loss did not improve from 0.29909\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.3791 - acc: 0.8852 - val_loss: 0.3039 - val_acc: 0.9185\n",
      "Epoch 474/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3823 - acc: 0.8850\n",
      "Epoch 00474: val_loss did not improve from 0.29909\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3823 - acc: 0.8850 - val_loss: 0.3006 - val_acc: 0.9182\n",
      "Epoch 475/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3840 - acc: 0.8821\n",
      "Epoch 00475: val_loss did not improve from 0.29909\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3839 - acc: 0.8822 - val_loss: 0.3073 - val_acc: 0.9166\n",
      "Epoch 476/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3864 - acc: 0.8832\n",
      "Epoch 00476: val_loss did not improve from 0.29909\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3864 - acc: 0.8832 - val_loss: 0.3057 - val_acc: 0.9180\n",
      "Epoch 477/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3751 - acc: 0.8862\n",
      "Epoch 00477: val_loss did not improve from 0.29909\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3750 - acc: 0.8862 - val_loss: 0.3105 - val_acc: 0.9152\n",
      "Epoch 478/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3828 - acc: 0.8829\n",
      "Epoch 00478: val_loss improved from 0.29909 to 0.29663, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv_checkpoint/478-0.2966.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3828 - acc: 0.8829 - val_loss: 0.2966 - val_acc: 0.9173\n",
      "Epoch 479/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3801 - acc: 0.8832\n",
      "Epoch 00479: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.3801 - acc: 0.8831 - val_loss: 0.3114 - val_acc: 0.9133\n",
      "Epoch 480/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3796 - acc: 0.8847\n",
      "Epoch 00480: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.3796 - acc: 0.8847 - val_loss: 0.3014 - val_acc: 0.9192\n",
      "Epoch 481/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3802 - acc: 0.8846\n",
      "Epoch 00481: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.3802 - acc: 0.8846 - val_loss: 0.2969 - val_acc: 0.9206\n",
      "Epoch 482/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3811 - acc: 0.8846\n",
      "Epoch 00482: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.3811 - acc: 0.8846 - val_loss: 0.3019 - val_acc: 0.9171\n",
      "Epoch 483/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3726 - acc: 0.8849\n",
      "Epoch 00483: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.3726 - acc: 0.8849 - val_loss: 0.3116 - val_acc: 0.9152\n",
      "Epoch 484/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3760 - acc: 0.8867\n",
      "Epoch 00484: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.3760 - acc: 0.8867 - val_loss: 0.2997 - val_acc: 0.9159\n",
      "Epoch 485/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3787 - acc: 0.8845\n",
      "Epoch 00485: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.3787 - acc: 0.8846 - val_loss: 0.2988 - val_acc: 0.9220\n",
      "Epoch 486/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3799 - acc: 0.8849\n",
      "Epoch 00486: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.3799 - acc: 0.8849 - val_loss: 0.3003 - val_acc: 0.9194\n",
      "Epoch 487/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3798 - acc: 0.8855\n",
      "Epoch 00487: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3798 - acc: 0.8855 - val_loss: 0.3011 - val_acc: 0.9201\n",
      "Epoch 488/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3772 - acc: 0.8839\n",
      "Epoch 00488: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.3773 - acc: 0.8839 - val_loss: 0.3067 - val_acc: 0.9196\n",
      "Epoch 489/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3743 - acc: 0.8850\n",
      "Epoch 00489: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.3743 - acc: 0.8850 - val_loss: 0.3003 - val_acc: 0.9203\n",
      "Epoch 490/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3779 - acc: 0.8853\n",
      "Epoch 00490: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 450us/sample - loss: 0.3778 - acc: 0.8853 - val_loss: 0.2969 - val_acc: 0.9199\n",
      "Epoch 491/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3787 - acc: 0.8837\n",
      "Epoch 00491: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.3787 - acc: 0.8837 - val_loss: 0.3008 - val_acc: 0.9168\n",
      "Epoch 492/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3760 - acc: 0.8855\n",
      "Epoch 00492: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3760 - acc: 0.8855 - val_loss: 0.2987 - val_acc: 0.9180\n",
      "Epoch 493/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3795 - acc: 0.8845\n",
      "Epoch 00493: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.3796 - acc: 0.8844 - val_loss: 0.2968 - val_acc: 0.9206\n",
      "Epoch 494/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3752 - acc: 0.8855\n",
      "Epoch 00494: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3754 - acc: 0.8854 - val_loss: 0.3033 - val_acc: 0.9185\n",
      "Epoch 495/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3729 - acc: 0.8863\n",
      "Epoch 00495: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3729 - acc: 0.8863 - val_loss: 0.2977 - val_acc: 0.9187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 496/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3780 - acc: 0.8844\n",
      "Epoch 00496: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.3779 - acc: 0.8844 - val_loss: 0.2984 - val_acc: 0.9194\n",
      "Epoch 497/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3771 - acc: 0.8862\n",
      "Epoch 00497: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 453us/sample - loss: 0.3771 - acc: 0.8862 - val_loss: 0.3035 - val_acc: 0.9178\n",
      "Epoch 498/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3741 - acc: 0.8869\n",
      "Epoch 00498: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.3741 - acc: 0.8869 - val_loss: 0.2990 - val_acc: 0.9192\n",
      "Epoch 499/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3793 - acc: 0.8858\n",
      "Epoch 00499: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 0.3793 - acc: 0.8858 - val_loss: 0.2988 - val_acc: 0.9206\n",
      "Epoch 500/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3720 - acc: 0.8864\n",
      "Epoch 00500: val_loss did not improve from 0.29663\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.3720 - acc: 0.8864 - val_loss: 0.3043 - val_acc: 0.9161\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 272us/sample - loss: 0.3302 - acc: 0.9070\n",
      "Loss: 0.3301833349101145 Accuracy: 0.90695745\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.6481 - acc: 0.1274\n",
      "Epoch 00001: val_loss improved from inf to 2.33897, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/001-2.3390.hdf5\n",
      "36805/36805 [==============================] - 20s 550us/sample - loss: 2.6481 - acc: 0.1274 - val_loss: 2.3390 - val_acc: 0.2791\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2206 - acc: 0.2643\n",
      "Epoch 00002: val_loss improved from 2.33897 to 1.90259, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/002-1.9026.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 2.2206 - acc: 0.2643 - val_loss: 1.9026 - val_acc: 0.3911\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9823 - acc: 0.3342\n",
      "Epoch 00003: val_loss improved from 1.90259 to 1.73482, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/003-1.7348.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 1.9824 - acc: 0.3342 - val_loss: 1.7348 - val_acc: 0.4594\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8326 - acc: 0.3863\n",
      "Epoch 00004: val_loss improved from 1.73482 to 1.58783, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/004-1.5878.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 1.8325 - acc: 0.3864 - val_loss: 1.5878 - val_acc: 0.5246\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7277 - acc: 0.4229\n",
      "Epoch 00005: val_loss improved from 1.58783 to 1.50058, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/005-1.5006.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 1.7276 - acc: 0.4229 - val_loss: 1.5006 - val_acc: 0.5469\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6368 - acc: 0.4542\n",
      "Epoch 00006: val_loss improved from 1.50058 to 1.38787, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/006-1.3879.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 1.6368 - acc: 0.4542 - val_loss: 1.3879 - val_acc: 0.5784\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5549 - acc: 0.4842\n",
      "Epoch 00007: val_loss improved from 1.38787 to 1.31654, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/007-1.3165.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 1.5548 - acc: 0.4842 - val_loss: 1.3165 - val_acc: 0.6136\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4816 - acc: 0.5119\n",
      "Epoch 00008: val_loss improved from 1.31654 to 1.27708, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/008-1.2771.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 1.4816 - acc: 0.5119 - val_loss: 1.2771 - val_acc: 0.6133\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4196 - acc: 0.5375\n",
      "Epoch 00009: val_loss improved from 1.27708 to 1.17149, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/009-1.1715.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 1.4196 - acc: 0.5375 - val_loss: 1.1715 - val_acc: 0.6541\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3682 - acc: 0.5544\n",
      "Epoch 00010: val_loss improved from 1.17149 to 1.12871, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/010-1.1287.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 1.3683 - acc: 0.5544 - val_loss: 1.1287 - val_acc: 0.6667\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3154 - acc: 0.5750\n",
      "Epoch 00011: val_loss improved from 1.12871 to 1.07757, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/011-1.0776.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 1.3154 - acc: 0.5749 - val_loss: 1.0776 - val_acc: 0.6818\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2773 - acc: 0.5895\n",
      "Epoch 00012: val_loss improved from 1.07757 to 1.03642, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/012-1.0364.hdf5\n",
      "36805/36805 [==============================] - 17s 471us/sample - loss: 1.2771 - acc: 0.5896 - val_loss: 1.0364 - val_acc: 0.7065\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2267 - acc: 0.6093\n",
      "Epoch 00013: val_loss improved from 1.03642 to 0.98511, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/013-0.9851.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 1.2269 - acc: 0.6093 - val_loss: 0.9851 - val_acc: 0.7044\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1833 - acc: 0.6252\n",
      "Epoch 00014: val_loss improved from 0.98511 to 0.93071, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/014-0.9307.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 1.1833 - acc: 0.6251 - val_loss: 0.9307 - val_acc: 0.7282\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1508 - acc: 0.6376\n",
      "Epoch 00015: val_loss improved from 0.93071 to 0.91746, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/015-0.9175.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 1.1507 - acc: 0.6375 - val_loss: 0.9175 - val_acc: 0.7414\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1132 - acc: 0.6500\n",
      "Epoch 00016: val_loss improved from 0.91746 to 0.85849, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/016-0.8585.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 1.1131 - acc: 0.6500 - val_loss: 0.8585 - val_acc: 0.7505\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0887 - acc: 0.6617\n",
      "Epoch 00017: val_loss improved from 0.85849 to 0.82986, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/017-0.8299.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 1.0888 - acc: 0.6617 - val_loss: 0.8299 - val_acc: 0.7559\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0514 - acc: 0.6679\n",
      "Epoch 00018: val_loss improved from 0.82986 to 0.82701, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/018-0.8270.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 1.0514 - acc: 0.6679 - val_loss: 0.8270 - val_acc: 0.7650\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0202 - acc: 0.6812\n",
      "Epoch 00019: val_loss improved from 0.82701 to 0.77876, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/019-0.7788.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 1.0203 - acc: 0.6812 - val_loss: 0.7788 - val_acc: 0.7773\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9976 - acc: 0.6915\n",
      "Epoch 00020: val_loss improved from 0.77876 to 0.76050, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/020-0.7605.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.9975 - acc: 0.6915 - val_loss: 0.7605 - val_acc: 0.7852\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9672 - acc: 0.7004\n",
      "Epoch 00021: val_loss improved from 0.76050 to 0.74294, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/021-0.7429.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.9673 - acc: 0.7003 - val_loss: 0.7429 - val_acc: 0.7857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9472 - acc: 0.7069\n",
      "Epoch 00022: val_loss improved from 0.74294 to 0.70453, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/022-0.7045.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.9471 - acc: 0.7069 - val_loss: 0.7045 - val_acc: 0.8041\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9229 - acc: 0.7166\n",
      "Epoch 00023: val_loss improved from 0.70453 to 0.67731, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/023-0.6773.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.9229 - acc: 0.7166 - val_loss: 0.6773 - val_acc: 0.8064\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9047 - acc: 0.7224\n",
      "Epoch 00024: val_loss improved from 0.67731 to 0.65986, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/024-0.6599.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.9048 - acc: 0.7224 - val_loss: 0.6599 - val_acc: 0.8120\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8785 - acc: 0.7332\n",
      "Epoch 00025: val_loss improved from 0.65986 to 0.63257, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/025-0.6326.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.8785 - acc: 0.7332 - val_loss: 0.6326 - val_acc: 0.8239\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8608 - acc: 0.7373\n",
      "Epoch 00026: val_loss improved from 0.63257 to 0.61642, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/026-0.6164.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.8609 - acc: 0.7373 - val_loss: 0.6164 - val_acc: 0.8258\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8417 - acc: 0.7432\n",
      "Epoch 00027: val_loss improved from 0.61642 to 0.60900, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/027-0.6090.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.8417 - acc: 0.7432 - val_loss: 0.6090 - val_acc: 0.8302\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8187 - acc: 0.7497\n",
      "Epoch 00028: val_loss improved from 0.60900 to 0.58687, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/028-0.5869.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.8187 - acc: 0.7497 - val_loss: 0.5869 - val_acc: 0.8386\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8097 - acc: 0.7515\n",
      "Epoch 00029: val_loss improved from 0.58687 to 0.57398, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/029-0.5740.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.8098 - acc: 0.7514 - val_loss: 0.5740 - val_acc: 0.8393\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7961 - acc: 0.7586\n",
      "Epoch 00030: val_loss improved from 0.57398 to 0.55246, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/030-0.5525.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.7960 - acc: 0.7585 - val_loss: 0.5525 - val_acc: 0.8488\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7799 - acc: 0.7645\n",
      "Epoch 00031: val_loss did not improve from 0.55246\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.7800 - acc: 0.7644 - val_loss: 0.5597 - val_acc: 0.8423\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7566 - acc: 0.7710\n",
      "Epoch 00032: val_loss improved from 0.55246 to 0.53744, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/032-0.5374.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.7565 - acc: 0.7710 - val_loss: 0.5374 - val_acc: 0.8491\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7518 - acc: 0.7708\n",
      "Epoch 00033: val_loss improved from 0.53744 to 0.53554, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/033-0.5355.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.7518 - acc: 0.7708 - val_loss: 0.5355 - val_acc: 0.8458\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7320 - acc: 0.7793\n",
      "Epoch 00034: val_loss improved from 0.53554 to 0.50933, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/034-0.5093.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.7320 - acc: 0.7792 - val_loss: 0.5093 - val_acc: 0.8595\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7186 - acc: 0.7830\n",
      "Epoch 00035: val_loss improved from 0.50933 to 0.50161, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/035-0.5016.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.7187 - acc: 0.7830 - val_loss: 0.5016 - val_acc: 0.8591\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7008 - acc: 0.7886\n",
      "Epoch 00036: val_loss improved from 0.50161 to 0.48025, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/036-0.4803.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.7008 - acc: 0.7887 - val_loss: 0.4803 - val_acc: 0.8633\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6939 - acc: 0.7901\n",
      "Epoch 00037: val_loss improved from 0.48025 to 0.47164, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/037-0.4716.hdf5\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.6939 - acc: 0.7901 - val_loss: 0.4716 - val_acc: 0.8656\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6783 - acc: 0.7939\n",
      "Epoch 00038: val_loss improved from 0.47164 to 0.46885, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/038-0.4689.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.6782 - acc: 0.7939 - val_loss: 0.4689 - val_acc: 0.8672\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6730 - acc: 0.7973\n",
      "Epoch 00039: val_loss did not improve from 0.46885\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.6730 - acc: 0.7972 - val_loss: 0.4767 - val_acc: 0.8696\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6580 - acc: 0.7991\n",
      "Epoch 00040: val_loss improved from 0.46885 to 0.44368, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/040-0.4437.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.6582 - acc: 0.7991 - val_loss: 0.4437 - val_acc: 0.8805\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6532 - acc: 0.8036\n",
      "Epoch 00041: val_loss improved from 0.44368 to 0.43725, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/041-0.4372.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.6532 - acc: 0.8036 - val_loss: 0.4372 - val_acc: 0.8828\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6425 - acc: 0.8061\n",
      "Epoch 00042: val_loss did not improve from 0.43725\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.6425 - acc: 0.8061 - val_loss: 0.4414 - val_acc: 0.8812\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6279 - acc: 0.8120\n",
      "Epoch 00043: val_loss did not improve from 0.43725\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.6278 - acc: 0.8120 - val_loss: 0.4926 - val_acc: 0.8549\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6226 - acc: 0.8124\n",
      "Epoch 00044: val_loss improved from 0.43725 to 0.41797, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/044-0.4180.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.6226 - acc: 0.8124 - val_loss: 0.4180 - val_acc: 0.8866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6149 - acc: 0.8140\n",
      "Epoch 00045: val_loss improved from 0.41797 to 0.40005, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/045-0.4001.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.6149 - acc: 0.8140 - val_loss: 0.4001 - val_acc: 0.8926\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6059 - acc: 0.8187\n",
      "Epoch 00046: val_loss did not improve from 0.40005\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.6058 - acc: 0.8187 - val_loss: 0.4036 - val_acc: 0.8891\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6022 - acc: 0.8163\n",
      "Epoch 00047: val_loss improved from 0.40005 to 0.39828, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/047-0.3983.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.6021 - acc: 0.8163 - val_loss: 0.3983 - val_acc: 0.8901\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5877 - acc: 0.8232\n",
      "Epoch 00048: val_loss improved from 0.39828 to 0.38255, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/048-0.3826.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.5877 - acc: 0.8231 - val_loss: 0.3826 - val_acc: 0.8966\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5831 - acc: 0.8277\n",
      "Epoch 00049: val_loss did not improve from 0.38255\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.5831 - acc: 0.8277 - val_loss: 0.3888 - val_acc: 0.8912\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5708 - acc: 0.8283\n",
      "Epoch 00050: val_loss improved from 0.38255 to 0.38163, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/050-0.3816.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.5709 - acc: 0.8283 - val_loss: 0.3816 - val_acc: 0.8973\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5681 - acc: 0.8300\n",
      "Epoch 00051: val_loss improved from 0.38163 to 0.36929, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/051-0.3693.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.5681 - acc: 0.8299 - val_loss: 0.3693 - val_acc: 0.9005\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5621 - acc: 0.8312\n",
      "Epoch 00052: val_loss improved from 0.36929 to 0.36244, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/052-0.3624.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.5621 - acc: 0.8312 - val_loss: 0.3624 - val_acc: 0.9026\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5553 - acc: 0.8346\n",
      "Epoch 00053: val_loss improved from 0.36244 to 0.35763, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/053-0.3576.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.5552 - acc: 0.8346 - val_loss: 0.3576 - val_acc: 0.9050\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5436 - acc: 0.8371\n",
      "Epoch 00054: val_loss improved from 0.35763 to 0.35563, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/054-0.3556.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.5436 - acc: 0.8371 - val_loss: 0.3556 - val_acc: 0.9033\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5412 - acc: 0.8398\n",
      "Epoch 00055: val_loss improved from 0.35563 to 0.35492, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/055-0.3549.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.5414 - acc: 0.8398 - val_loss: 0.3549 - val_acc: 0.9026\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5352 - acc: 0.8421\n",
      "Epoch 00056: val_loss did not improve from 0.35492\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.5351 - acc: 0.8421 - val_loss: 0.3670 - val_acc: 0.8980\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5305 - acc: 0.8416\n",
      "Epoch 00057: val_loss improved from 0.35492 to 0.34081, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/057-0.3408.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.5306 - acc: 0.8416 - val_loss: 0.3408 - val_acc: 0.9092\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5253 - acc: 0.8426\n",
      "Epoch 00058: val_loss did not improve from 0.34081\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.5254 - acc: 0.8426 - val_loss: 0.3568 - val_acc: 0.9008\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5241 - acc: 0.8443\n",
      "Epoch 00059: val_loss did not improve from 0.34081\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.5241 - acc: 0.8443 - val_loss: 0.3451 - val_acc: 0.9026\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5166 - acc: 0.8446\n",
      "Epoch 00060: val_loss improved from 0.34081 to 0.32476, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/060-0.3248.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.5167 - acc: 0.8446 - val_loss: 0.3248 - val_acc: 0.9133\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5084 - acc: 0.8478\n",
      "Epoch 00061: val_loss improved from 0.32476 to 0.32150, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/061-0.3215.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.5086 - acc: 0.8478 - val_loss: 0.3215 - val_acc: 0.9147\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5070 - acc: 0.8473\n",
      "Epoch 00062: val_loss did not improve from 0.32150\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.5070 - acc: 0.8473 - val_loss: 0.3219 - val_acc: 0.9099\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5069 - acc: 0.8499\n",
      "Epoch 00063: val_loss improved from 0.32150 to 0.31361, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/063-0.3136.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.5068 - acc: 0.8499 - val_loss: 0.3136 - val_acc: 0.9152\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4972 - acc: 0.8524\n",
      "Epoch 00064: val_loss improved from 0.31361 to 0.31036, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/064-0.3104.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.4972 - acc: 0.8524 - val_loss: 0.3104 - val_acc: 0.9159\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4906 - acc: 0.8541\n",
      "Epoch 00065: val_loss did not improve from 0.31036\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.4906 - acc: 0.8541 - val_loss: 0.3182 - val_acc: 0.9136\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4865 - acc: 0.8546\n",
      "Epoch 00066: val_loss did not improve from 0.31036\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.4864 - acc: 0.8546 - val_loss: 0.3132 - val_acc: 0.9164\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4817 - acc: 0.8570\n",
      "Epoch 00067: val_loss improved from 0.31036 to 0.30056, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/067-0.3006.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.4817 - acc: 0.8570 - val_loss: 0.3006 - val_acc: 0.9182\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4805 - acc: 0.8564\n",
      "Epoch 00068: val_loss did not improve from 0.30056\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.4805 - acc: 0.8564 - val_loss: 0.3038 - val_acc: 0.9164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4744 - acc: 0.8589\n",
      "Epoch 00069: val_loss did not improve from 0.30056\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.4744 - acc: 0.8590 - val_loss: 0.3128 - val_acc: 0.9152\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4750 - acc: 0.8561\n",
      "Epoch 00070: val_loss did not improve from 0.30056\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.4750 - acc: 0.8562 - val_loss: 0.3023 - val_acc: 0.9180\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4703 - acc: 0.8593\n",
      "Epoch 00071: val_loss improved from 0.30056 to 0.29572, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/071-0.2957.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.4704 - acc: 0.8593 - val_loss: 0.2957 - val_acc: 0.9210\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4684 - acc: 0.8602\n",
      "Epoch 00072: val_loss improved from 0.29572 to 0.29106, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/072-0.2911.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.4685 - acc: 0.8602 - val_loss: 0.2911 - val_acc: 0.9201\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.8597\n",
      "Epoch 00073: val_loss improved from 0.29106 to 0.28340, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/073-0.2834.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.4597 - acc: 0.8597 - val_loss: 0.2834 - val_acc: 0.9229\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4508 - acc: 0.8638\n",
      "Epoch 00074: val_loss did not improve from 0.28340\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.4509 - acc: 0.8637 - val_loss: 0.3020 - val_acc: 0.9152\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4521 - acc: 0.8655\n",
      "Epoch 00075: val_loss did not improve from 0.28340\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.4520 - acc: 0.8655 - val_loss: 0.2985 - val_acc: 0.9161\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4483 - acc: 0.8644\n",
      "Epoch 00076: val_loss did not improve from 0.28340\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.4483 - acc: 0.8644 - val_loss: 0.2855 - val_acc: 0.9213\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4496 - acc: 0.8671\n",
      "Epoch 00077: val_loss did not improve from 0.28340\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.4495 - acc: 0.8671 - val_loss: 0.2857 - val_acc: 0.9241\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4469 - acc: 0.8673\n",
      "Epoch 00078: val_loss improved from 0.28340 to 0.27715, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/078-0.2772.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.4468 - acc: 0.8674 - val_loss: 0.2772 - val_acc: 0.9248\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4464 - acc: 0.8654\n",
      "Epoch 00079: val_loss did not improve from 0.27715\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.4464 - acc: 0.8654 - val_loss: 0.2852 - val_acc: 0.9234\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4368 - acc: 0.8673\n",
      "Epoch 00080: val_loss did not improve from 0.27715\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.4368 - acc: 0.8673 - val_loss: 0.2833 - val_acc: 0.9213\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4366 - acc: 0.8686\n",
      "Epoch 00081: val_loss improved from 0.27715 to 0.26923, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/081-0.2692.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.4365 - acc: 0.8686 - val_loss: 0.2692 - val_acc: 0.9287\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4325 - acc: 0.8711\n",
      "Epoch 00082: val_loss did not improve from 0.26923\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.4324 - acc: 0.8711 - val_loss: 0.2704 - val_acc: 0.9266\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4286 - acc: 0.8711\n",
      "Epoch 00083: val_loss did not improve from 0.26923\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.4288 - acc: 0.8711 - val_loss: 0.2743 - val_acc: 0.9245\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4276 - acc: 0.8716\n",
      "Epoch 00084: val_loss improved from 0.26923 to 0.26723, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/084-0.2672.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.4275 - acc: 0.8716 - val_loss: 0.2672 - val_acc: 0.9269\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4200 - acc: 0.8754\n",
      "Epoch 00085: val_loss improved from 0.26723 to 0.26493, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/085-0.2649.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.4200 - acc: 0.8754 - val_loss: 0.2649 - val_acc: 0.9262\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4230 - acc: 0.8724\n",
      "Epoch 00086: val_loss did not improve from 0.26493\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.4231 - acc: 0.8724 - val_loss: 0.2769 - val_acc: 0.9248\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4159 - acc: 0.8750\n",
      "Epoch 00087: val_loss improved from 0.26493 to 0.26432, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/087-0.2643.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.4159 - acc: 0.8750 - val_loss: 0.2643 - val_acc: 0.9266\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4143 - acc: 0.8754\n",
      "Epoch 00088: val_loss improved from 0.26432 to 0.26082, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/088-0.2608.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.4143 - acc: 0.8755 - val_loss: 0.2608 - val_acc: 0.9280\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4159 - acc: 0.8752\n",
      "Epoch 00089: val_loss did not improve from 0.26082\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.4159 - acc: 0.8752 - val_loss: 0.2633 - val_acc: 0.9280\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4066 - acc: 0.8770\n",
      "Epoch 00090: val_loss did not improve from 0.26082\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.4066 - acc: 0.8770 - val_loss: 0.2684 - val_acc: 0.9234\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4079 - acc: 0.8786\n",
      "Epoch 00091: val_loss did not improve from 0.26082\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.4079 - acc: 0.8786 - val_loss: 0.2676 - val_acc: 0.9266\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4086 - acc: 0.8769\n",
      "Epoch 00092: val_loss did not improve from 0.26082\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.4086 - acc: 0.8769 - val_loss: 0.2721 - val_acc: 0.9210\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4041 - acc: 0.8776\n",
      "Epoch 00093: val_loss improved from 0.26082 to 0.25863, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/093-0.2586.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.4041 - acc: 0.8776 - val_loss: 0.2586 - val_acc: 0.9248\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4001 - acc: 0.8786\n",
      "Epoch 00094: val_loss did not improve from 0.25863\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.4001 - acc: 0.8786 - val_loss: 0.2603 - val_acc: 0.9283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3997 - acc: 0.8786\n",
      "Epoch 00095: val_loss improved from 0.25863 to 0.25816, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/095-0.2582.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3997 - acc: 0.8786 - val_loss: 0.2582 - val_acc: 0.9294\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3929 - acc: 0.8823\n",
      "Epoch 00096: val_loss did not improve from 0.25816\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3929 - acc: 0.8822 - val_loss: 0.2672 - val_acc: 0.9241\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3935 - acc: 0.8800\n",
      "Epoch 00097: val_loss improved from 0.25816 to 0.25792, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/097-0.2579.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3934 - acc: 0.8800 - val_loss: 0.2579 - val_acc: 0.9266\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3936 - acc: 0.8822\n",
      "Epoch 00098: val_loss did not improve from 0.25792\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.3935 - acc: 0.8822 - val_loss: 0.2718 - val_acc: 0.9229\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3910 - acc: 0.8821\n",
      "Epoch 00099: val_loss did not improve from 0.25792\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.3910 - acc: 0.8821 - val_loss: 0.2638 - val_acc: 0.9241\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3863 - acc: 0.8821\n",
      "Epoch 00100: val_loss improved from 0.25792 to 0.25031, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/100-0.2503.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3863 - acc: 0.8821 - val_loss: 0.2503 - val_acc: 0.9311\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3806 - acc: 0.8862\n",
      "Epoch 00101: val_loss improved from 0.25031 to 0.24698, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/101-0.2470.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3807 - acc: 0.8861 - val_loss: 0.2470 - val_acc: 0.9315\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3858 - acc: 0.8827\n",
      "Epoch 00102: val_loss did not improve from 0.24698\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3858 - acc: 0.8827 - val_loss: 0.2780 - val_acc: 0.9229\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3854 - acc: 0.8830\n",
      "Epoch 00103: val_loss did not improve from 0.24698\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3854 - acc: 0.8830 - val_loss: 0.2506 - val_acc: 0.9306\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3822 - acc: 0.8846\n",
      "Epoch 00104: val_loss did not improve from 0.24698\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3821 - acc: 0.8846 - val_loss: 0.2526 - val_acc: 0.9280\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3772 - acc: 0.8876\n",
      "Epoch 00105: val_loss did not improve from 0.24698\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3772 - acc: 0.8876 - val_loss: 0.2484 - val_acc: 0.9313\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3744 - acc: 0.8876\n",
      "Epoch 00106: val_loss improved from 0.24698 to 0.24560, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/106-0.2456.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3744 - acc: 0.8876 - val_loss: 0.2456 - val_acc: 0.9331\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3780 - acc: 0.8840\n",
      "Epoch 00107: val_loss improved from 0.24560 to 0.23743, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/107-0.2374.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.3780 - acc: 0.8840 - val_loss: 0.2374 - val_acc: 0.9364\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3728 - acc: 0.8871\n",
      "Epoch 00108: val_loss did not improve from 0.23743\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3728 - acc: 0.8871 - val_loss: 0.2400 - val_acc: 0.9329\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3761 - acc: 0.8874\n",
      "Epoch 00109: val_loss improved from 0.23743 to 0.23652, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/109-0.2365.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.3761 - acc: 0.8874 - val_loss: 0.2365 - val_acc: 0.9345\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3665 - acc: 0.8893\n",
      "Epoch 00110: val_loss improved from 0.23652 to 0.23560, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/110-0.2356.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3665 - acc: 0.8894 - val_loss: 0.2356 - val_acc: 0.9341\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3721 - acc: 0.8878\n",
      "Epoch 00111: val_loss did not improve from 0.23560\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3722 - acc: 0.8878 - val_loss: 0.2382 - val_acc: 0.9331\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3680 - acc: 0.8880\n",
      "Epoch 00112: val_loss improved from 0.23560 to 0.23492, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/112-0.2349.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.3680 - acc: 0.8880 - val_loss: 0.2349 - val_acc: 0.9355\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3658 - acc: 0.8894\n",
      "Epoch 00113: val_loss did not improve from 0.23492\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3657 - acc: 0.8894 - val_loss: 0.2775 - val_acc: 0.9173\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3606 - acc: 0.8897\n",
      "Epoch 00114: val_loss did not improve from 0.23492\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.3608 - acc: 0.8897 - val_loss: 0.2439 - val_acc: 0.9297\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3627 - acc: 0.8896\n",
      "Epoch 00115: val_loss improved from 0.23492 to 0.23222, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/115-0.2322.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3627 - acc: 0.8896 - val_loss: 0.2322 - val_acc: 0.9359\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3578 - acc: 0.8930\n",
      "Epoch 00116: val_loss did not improve from 0.23222\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3578 - acc: 0.8930 - val_loss: 0.2356 - val_acc: 0.9338\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3530 - acc: 0.8935\n",
      "Epoch 00117: val_loss improved from 0.23222 to 0.23027, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/117-0.2303.hdf5\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.3530 - acc: 0.8934 - val_loss: 0.2303 - val_acc: 0.9348\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3652 - acc: 0.8901\n",
      "Epoch 00118: val_loss improved from 0.23027 to 0.22529, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/118-0.2253.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.3651 - acc: 0.8901 - val_loss: 0.2253 - val_acc: 0.9376\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3505 - acc: 0.8947\n",
      "Epoch 00119: val_loss did not improve from 0.22529\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3505 - acc: 0.8947 - val_loss: 0.2433 - val_acc: 0.9322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3525 - acc: 0.8927\n",
      "Epoch 00120: val_loss did not improve from 0.22529\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3524 - acc: 0.8928 - val_loss: 0.2273 - val_acc: 0.9364\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3533 - acc: 0.8923\n",
      "Epoch 00121: val_loss did not improve from 0.22529\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3533 - acc: 0.8923 - val_loss: 0.2281 - val_acc: 0.9357\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3502 - acc: 0.8932\n",
      "Epoch 00122: val_loss did not improve from 0.22529\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.3501 - acc: 0.8932 - val_loss: 0.2284 - val_acc: 0.9369\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3462 - acc: 0.8945\n",
      "Epoch 00123: val_loss did not improve from 0.22529\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3462 - acc: 0.8945 - val_loss: 0.2329 - val_acc: 0.9308\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3436 - acc: 0.8959\n",
      "Epoch 00124: val_loss did not improve from 0.22529\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3436 - acc: 0.8959 - val_loss: 0.2356 - val_acc: 0.9336\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3424 - acc: 0.8951\n",
      "Epoch 00125: val_loss improved from 0.22529 to 0.22443, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/125-0.2244.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3424 - acc: 0.8951 - val_loss: 0.2244 - val_acc: 0.9371\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3482 - acc: 0.8939\n",
      "Epoch 00126: val_loss did not improve from 0.22443\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3483 - acc: 0.8938 - val_loss: 0.2495 - val_acc: 0.9278\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3495 - acc: 0.8948\n",
      "Epoch 00127: val_loss did not improve from 0.22443\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3495 - acc: 0.8948 - val_loss: 0.2275 - val_acc: 0.9364\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3427 - acc: 0.8938\n",
      "Epoch 00128: val_loss did not improve from 0.22443\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3427 - acc: 0.8938 - val_loss: 0.2263 - val_acc: 0.9387\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3371 - acc: 0.8980\n",
      "Epoch 00129: val_loss improved from 0.22443 to 0.22268, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/129-0.2227.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3371 - acc: 0.8980 - val_loss: 0.2227 - val_acc: 0.9376\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3437 - acc: 0.8956\n",
      "Epoch 00130: val_loss improved from 0.22268 to 0.22062, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/130-0.2206.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3442 - acc: 0.8956 - val_loss: 0.2206 - val_acc: 0.9406\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3352 - acc: 0.8974\n",
      "Epoch 00131: val_loss improved from 0.22062 to 0.22036, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/131-0.2204.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.3352 - acc: 0.8974 - val_loss: 0.2204 - val_acc: 0.9383\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3322 - acc: 0.8989\n",
      "Epoch 00132: val_loss improved from 0.22036 to 0.21924, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/132-0.2192.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3322 - acc: 0.8988 - val_loss: 0.2192 - val_acc: 0.9399\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3321 - acc: 0.8986\n",
      "Epoch 00133: val_loss did not improve from 0.21924\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3321 - acc: 0.8986 - val_loss: 0.2278 - val_acc: 0.9355\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3342 - acc: 0.8960\n",
      "Epoch 00134: val_loss did not improve from 0.21924\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.3342 - acc: 0.8959 - val_loss: 0.2291 - val_acc: 0.9371\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3305 - acc: 0.9003\n",
      "Epoch 00135: val_loss did not improve from 0.21924\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3305 - acc: 0.9003 - val_loss: 0.2420 - val_acc: 0.9350\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3282 - acc: 0.9000\n",
      "Epoch 00136: val_loss did not improve from 0.21924\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3282 - acc: 0.9000 - val_loss: 0.2297 - val_acc: 0.9369\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3288 - acc: 0.8997\n",
      "Epoch 00137: val_loss did not improve from 0.21924\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3287 - acc: 0.8997 - val_loss: 0.2209 - val_acc: 0.9401\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3281 - acc: 0.9002\n",
      "Epoch 00138: val_loss did not improve from 0.21924\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3282 - acc: 0.9002 - val_loss: 0.2227 - val_acc: 0.9357\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3273 - acc: 0.8990\n",
      "Epoch 00139: val_loss improved from 0.21924 to 0.21421, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/139-0.2142.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.3272 - acc: 0.8990 - val_loss: 0.2142 - val_acc: 0.9401\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3286 - acc: 0.8989\n",
      "Epoch 00140: val_loss did not improve from 0.21421\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.3288 - acc: 0.8988 - val_loss: 0.2146 - val_acc: 0.9392\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3246 - acc: 0.9031\n",
      "Epoch 00141: val_loss improved from 0.21421 to 0.21330, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/141-0.2133.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3247 - acc: 0.9031 - val_loss: 0.2133 - val_acc: 0.9394\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3256 - acc: 0.8985\n",
      "Epoch 00142: val_loss did not improve from 0.21330\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3256 - acc: 0.8984 - val_loss: 0.2156 - val_acc: 0.9397\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3240 - acc: 0.8999\n",
      "Epoch 00143: val_loss improved from 0.21330 to 0.21195, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/143-0.2120.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3241 - acc: 0.8999 - val_loss: 0.2120 - val_acc: 0.9404\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3177 - acc: 0.9029\n",
      "Epoch 00144: val_loss did not improve from 0.21195\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3176 - acc: 0.9029 - val_loss: 0.2154 - val_acc: 0.9415\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3163 - acc: 0.9027\n",
      "Epoch 00145: val_loss did not improve from 0.21195\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3163 - acc: 0.9027 - val_loss: 0.2200 - val_acc: 0.9383\n",
      "Epoch 146/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3139 - acc: 0.9039\n",
      "Epoch 00146: val_loss did not improve from 0.21195\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3139 - acc: 0.9039 - val_loss: 0.2143 - val_acc: 0.9394\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3144 - acc: 0.9034\n",
      "Epoch 00147: val_loss improved from 0.21195 to 0.21105, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/147-0.2110.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3143 - acc: 0.9034 - val_loss: 0.2110 - val_acc: 0.9387\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3172 - acc: 0.9047\n",
      "Epoch 00148: val_loss did not improve from 0.21105\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3171 - acc: 0.9047 - val_loss: 0.2228 - val_acc: 0.9369\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3191 - acc: 0.9013\n",
      "Epoch 00149: val_loss did not improve from 0.21105\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3191 - acc: 0.9013 - val_loss: 0.2186 - val_acc: 0.9380\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3151 - acc: 0.9027\n",
      "Epoch 00150: val_loss did not improve from 0.21105\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3151 - acc: 0.9027 - val_loss: 0.2191 - val_acc: 0.9401\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3101 - acc: 0.9037\n",
      "Epoch 00151: val_loss did not improve from 0.21105\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3101 - acc: 0.9037 - val_loss: 0.2142 - val_acc: 0.9401\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3118 - acc: 0.9030\n",
      "Epoch 00152: val_loss improved from 0.21105 to 0.21007, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/152-0.2101.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3118 - acc: 0.9030 - val_loss: 0.2101 - val_acc: 0.9441\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3115 - acc: 0.9048\n",
      "Epoch 00153: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3114 - acc: 0.9048 - val_loss: 0.2136 - val_acc: 0.9411\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3075 - acc: 0.9037\n",
      "Epoch 00154: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.3075 - acc: 0.9037 - val_loss: 0.2114 - val_acc: 0.9385\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3077 - acc: 0.9034\n",
      "Epoch 00155: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3077 - acc: 0.9034 - val_loss: 0.2117 - val_acc: 0.9397\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3063 - acc: 0.9062\n",
      "Epoch 00156: val_loss did not improve from 0.21007\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3064 - acc: 0.9062 - val_loss: 0.2176 - val_acc: 0.9408\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3049 - acc: 0.9049\n",
      "Epoch 00157: val_loss improved from 0.21007 to 0.21000, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/157-0.2100.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3048 - acc: 0.9049 - val_loss: 0.2100 - val_acc: 0.9406\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3040 - acc: 0.9068\n",
      "Epoch 00158: val_loss did not improve from 0.21000\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.3040 - acc: 0.9068 - val_loss: 0.2469 - val_acc: 0.9273\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3045 - acc: 0.9071\n",
      "Epoch 00159: val_loss did not improve from 0.21000\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3044 - acc: 0.9071 - val_loss: 0.2200 - val_acc: 0.9366\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3051 - acc: 0.9055\n",
      "Epoch 00160: val_loss did not improve from 0.21000\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.3051 - acc: 0.9055 - val_loss: 0.2225 - val_acc: 0.9387\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2996 - acc: 0.9074\n",
      "Epoch 00161: val_loss did not improve from 0.21000\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2998 - acc: 0.9074 - val_loss: 0.2160 - val_acc: 0.9369\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3007 - acc: 0.9076\n",
      "Epoch 00162: val_loss did not improve from 0.21000\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.3006 - acc: 0.9076 - val_loss: 0.2397 - val_acc: 0.9311\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2989 - acc: 0.9095\n",
      "Epoch 00163: val_loss did not improve from 0.21000\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.2990 - acc: 0.9095 - val_loss: 0.2132 - val_acc: 0.9411\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3008 - acc: 0.9069\n",
      "Epoch 00164: val_loss improved from 0.21000 to 0.20696, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/164-0.2070.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.3008 - acc: 0.9069 - val_loss: 0.2070 - val_acc: 0.9441\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3009 - acc: 0.9065\n",
      "Epoch 00165: val_loss improved from 0.20696 to 0.20627, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/165-0.2063.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3008 - acc: 0.9065 - val_loss: 0.2063 - val_acc: 0.9457\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2933 - acc: 0.9101\n",
      "Epoch 00166: val_loss improved from 0.20627 to 0.20504, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/166-0.2050.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2932 - acc: 0.9101 - val_loss: 0.2050 - val_acc: 0.9422\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2937 - acc: 0.9093\n",
      "Epoch 00167: val_loss did not improve from 0.20504\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2937 - acc: 0.9093 - val_loss: 0.2069 - val_acc: 0.9415\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2967 - acc: 0.9087\n",
      "Epoch 00168: val_loss improved from 0.20504 to 0.20234, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/168-0.2023.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2967 - acc: 0.9088 - val_loss: 0.2023 - val_acc: 0.9429\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2894 - acc: 0.9120\n",
      "Epoch 00169: val_loss did not improve from 0.20234\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2894 - acc: 0.9120 - val_loss: 0.2052 - val_acc: 0.9448\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2943 - acc: 0.9092\n",
      "Epoch 00170: val_loss did not improve from 0.20234\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2943 - acc: 0.9092 - val_loss: 0.2129 - val_acc: 0.9443\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2956 - acc: 0.9086\n",
      "Epoch 00171: val_loss did not improve from 0.20234\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2956 - acc: 0.9086 - val_loss: 0.2094 - val_acc: 0.9441\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2910 - acc: 0.9111\n",
      "Epoch 00172: val_loss did not improve from 0.20234\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.2910 - acc: 0.9111 - val_loss: 0.2172 - val_acc: 0.9392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2970 - acc: 0.9087\n",
      "Epoch 00173: val_loss did not improve from 0.20234\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2970 - acc: 0.9087 - val_loss: 0.2083 - val_acc: 0.9390\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2887 - acc: 0.9103\n",
      "Epoch 00174: val_loss improved from 0.20234 to 0.20089, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/174-0.2009.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2887 - acc: 0.9103 - val_loss: 0.2009 - val_acc: 0.9455\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2853 - acc: 0.9119\n",
      "Epoch 00175: val_loss did not improve from 0.20089\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2853 - acc: 0.9119 - val_loss: 0.2026 - val_acc: 0.9464\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2855 - acc: 0.9110\n",
      "Epoch 00176: val_loss did not improve from 0.20089\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2855 - acc: 0.9110 - val_loss: 0.2070 - val_acc: 0.9427\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2803 - acc: 0.9138\n",
      "Epoch 00177: val_loss did not improve from 0.20089\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2803 - acc: 0.9138 - val_loss: 0.2031 - val_acc: 0.9434\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2822 - acc: 0.9110\n",
      "Epoch 00178: val_loss did not improve from 0.20089\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2822 - acc: 0.9110 - val_loss: 0.2086 - val_acc: 0.9408\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2826 - acc: 0.9124\n",
      "Epoch 00179: val_loss did not improve from 0.20089\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.2826 - acc: 0.9124 - val_loss: 0.2117 - val_acc: 0.9429\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2879 - acc: 0.9096\n",
      "Epoch 00180: val_loss did not improve from 0.20089\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2879 - acc: 0.9096 - val_loss: 0.2025 - val_acc: 0.9434\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2839 - acc: 0.9109\n",
      "Epoch 00181: val_loss did not improve from 0.20089\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2839 - acc: 0.9109 - val_loss: 0.2021 - val_acc: 0.9460\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2806 - acc: 0.9126\n",
      "Epoch 00182: val_loss did not improve from 0.20089\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2807 - acc: 0.9126 - val_loss: 0.2063 - val_acc: 0.9439\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2839 - acc: 0.9135\n",
      "Epoch 00183: val_loss improved from 0.20089 to 0.19885, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/183-0.1988.hdf5\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2839 - acc: 0.9135 - val_loss: 0.1988 - val_acc: 0.9467\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2794 - acc: 0.9122\n",
      "Epoch 00184: val_loss did not improve from 0.19885\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2794 - acc: 0.9122 - val_loss: 0.2148 - val_acc: 0.9399\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2783 - acc: 0.9145\n",
      "Epoch 00185: val_loss improved from 0.19885 to 0.19592, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/185-0.1959.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2783 - acc: 0.9145 - val_loss: 0.1959 - val_acc: 0.9455\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2824 - acc: 0.9130\n",
      "Epoch 00186: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2824 - acc: 0.9129 - val_loss: 0.2163 - val_acc: 0.9385\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2777 - acc: 0.9139\n",
      "Epoch 00187: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2776 - acc: 0.9139 - val_loss: 0.2006 - val_acc: 0.9446\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.9145\n",
      "Epoch 00188: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2801 - acc: 0.9145 - val_loss: 0.1988 - val_acc: 0.9441\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2763 - acc: 0.9121\n",
      "Epoch 00189: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2764 - acc: 0.9120 - val_loss: 0.2030 - val_acc: 0.9446\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2760 - acc: 0.9128\n",
      "Epoch 00190: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2761 - acc: 0.9128 - val_loss: 0.2140 - val_acc: 0.9392\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2757 - acc: 0.9142\n",
      "Epoch 00191: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2757 - acc: 0.9142 - val_loss: 0.2202 - val_acc: 0.9397\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2717 - acc: 0.9144\n",
      "Epoch 00192: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2717 - acc: 0.9144 - val_loss: 0.1971 - val_acc: 0.9481\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2725 - acc: 0.9142\n",
      "Epoch 00193: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2725 - acc: 0.9142 - val_loss: 0.2381 - val_acc: 0.9336\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2733 - acc: 0.9145\n",
      "Epoch 00194: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2733 - acc: 0.9145 - val_loss: 0.1973 - val_acc: 0.9476\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2746 - acc: 0.9148\n",
      "Epoch 00195: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2747 - acc: 0.9147 - val_loss: 0.2020 - val_acc: 0.9439\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2735 - acc: 0.9144\n",
      "Epoch 00196: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2735 - acc: 0.9144 - val_loss: 0.1998 - val_acc: 0.9457\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2709 - acc: 0.9142\n",
      "Epoch 00197: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2708 - acc: 0.9142 - val_loss: 0.2045 - val_acc: 0.9404\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2731 - acc: 0.9155\n",
      "Epoch 00198: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2732 - acc: 0.9155 - val_loss: 0.1974 - val_acc: 0.9460\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2711 - acc: 0.9161\n",
      "Epoch 00199: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2710 - acc: 0.9161 - val_loss: 0.1961 - val_acc: 0.9448\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2680 - acc: 0.9169\n",
      "Epoch 00200: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2680 - acc: 0.9169 - val_loss: 0.2051 - val_acc: 0.9446\n",
      "Epoch 201/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2654 - acc: 0.9183\n",
      "Epoch 00201: val_loss did not improve from 0.19592\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2654 - acc: 0.9182 - val_loss: 0.1970 - val_acc: 0.9471\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2675 - acc: 0.9182\n",
      "Epoch 00202: val_loss improved from 0.19592 to 0.19573, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/202-0.1957.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.2676 - acc: 0.9182 - val_loss: 0.1957 - val_acc: 0.9469\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2661 - acc: 0.9169\n",
      "Epoch 00203: val_loss improved from 0.19573 to 0.19354, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/203-0.1935.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2660 - acc: 0.9169 - val_loss: 0.1935 - val_acc: 0.9474\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2613 - acc: 0.9201\n",
      "Epoch 00204: val_loss improved from 0.19354 to 0.19227, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/204-0.1923.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2613 - acc: 0.9201 - val_loss: 0.1923 - val_acc: 0.9485\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2641 - acc: 0.9158\n",
      "Epoch 00205: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2642 - acc: 0.9157 - val_loss: 0.1963 - val_acc: 0.9474\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2608 - acc: 0.9186\n",
      "Epoch 00206: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2608 - acc: 0.9186 - val_loss: 0.1936 - val_acc: 0.9492\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2654 - acc: 0.9161\n",
      "Epoch 00207: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2654 - acc: 0.9162 - val_loss: 0.1947 - val_acc: 0.9453\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2599 - acc: 0.9204\n",
      "Epoch 00208: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2599 - acc: 0.9204 - val_loss: 0.1950 - val_acc: 0.9471\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2642 - acc: 0.9188\n",
      "Epoch 00209: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2641 - acc: 0.9188 - val_loss: 0.1994 - val_acc: 0.9485\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.9177\n",
      "Epoch 00210: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2560 - acc: 0.9177 - val_loss: 0.2055 - val_acc: 0.9401\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2631 - acc: 0.9187\n",
      "Epoch 00211: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2631 - acc: 0.9187 - val_loss: 0.1943 - val_acc: 0.9439\n",
      "Epoch 212/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2624 - acc: 0.9177\n",
      "Epoch 00212: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2624 - acc: 0.9177 - val_loss: 0.2021 - val_acc: 0.9469\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2584 - acc: 0.9191\n",
      "Epoch 00213: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2584 - acc: 0.9191 - val_loss: 0.1952 - val_acc: 0.9474\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2601 - acc: 0.9200\n",
      "Epoch 00214: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2602 - acc: 0.9200 - val_loss: 0.2063 - val_acc: 0.9425\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2577 - acc: 0.9198\n",
      "Epoch 00215: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2578 - acc: 0.9198 - val_loss: 0.1953 - val_acc: 0.9483\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2563 - acc: 0.9195\n",
      "Epoch 00216: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2563 - acc: 0.9195 - val_loss: 0.1962 - val_acc: 0.9476\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2534 - acc: 0.9203\n",
      "Epoch 00217: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2533 - acc: 0.9203 - val_loss: 0.1952 - val_acc: 0.9499\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2552 - acc: 0.9204\n",
      "Epoch 00218: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2553 - acc: 0.9203 - val_loss: 0.2027 - val_acc: 0.9448\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2609 - acc: 0.9192\n",
      "Epoch 00219: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.2609 - acc: 0.9192 - val_loss: 0.1953 - val_acc: 0.9471\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2531 - acc: 0.9205\n",
      "Epoch 00220: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2531 - acc: 0.9205 - val_loss: 0.2015 - val_acc: 0.9448\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2505 - acc: 0.9215\n",
      "Epoch 00221: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2505 - acc: 0.9215 - val_loss: 0.1981 - val_acc: 0.9471\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2508 - acc: 0.9219\n",
      "Epoch 00222: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2508 - acc: 0.9219 - val_loss: 0.2005 - val_acc: 0.9453\n",
      "Epoch 223/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2492 - acc: 0.9225\n",
      "Epoch 00223: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2492 - acc: 0.9225 - val_loss: 0.1980 - val_acc: 0.9471\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2483 - acc: 0.9214\n",
      "Epoch 00224: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2483 - acc: 0.9214 - val_loss: 0.1971 - val_acc: 0.9443\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2515 - acc: 0.9217\n",
      "Epoch 00225: val_loss did not improve from 0.19227\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2515 - acc: 0.9217 - val_loss: 0.2151 - val_acc: 0.9401\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2527 - acc: 0.9207\n",
      "Epoch 00226: val_loss improved from 0.19227 to 0.19188, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/226-0.1919.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2527 - acc: 0.9206 - val_loss: 0.1919 - val_acc: 0.9478\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2467 - acc: 0.9232\n",
      "Epoch 00227: val_loss did not improve from 0.19188\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2467 - acc: 0.9232 - val_loss: 0.2008 - val_acc: 0.9443\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2494 - acc: 0.9221\n",
      "Epoch 00228: val_loss improved from 0.19188 to 0.18643, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/228-0.1864.hdf5\n",
      "36805/36805 [==============================] - 17s 470us/sample - loss: 0.2494 - acc: 0.9221 - val_loss: 0.1864 - val_acc: 0.9506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2467 - acc: 0.9229\n",
      "Epoch 00229: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2467 - acc: 0.9228 - val_loss: 0.1972 - val_acc: 0.9469\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2480 - acc: 0.9224\n",
      "Epoch 00230: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2480 - acc: 0.9224 - val_loss: 0.1886 - val_acc: 0.9492\n",
      "Epoch 231/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2439 - acc: 0.9244\n",
      "Epoch 00231: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2439 - acc: 0.9244 - val_loss: 0.1918 - val_acc: 0.9464\n",
      "Epoch 232/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2461 - acc: 0.9218\n",
      "Epoch 00232: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2461 - acc: 0.9219 - val_loss: 0.1943 - val_acc: 0.9443\n",
      "Epoch 233/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2420 - acc: 0.9257\n",
      "Epoch 00233: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2420 - acc: 0.9257 - val_loss: 0.1998 - val_acc: 0.9471\n",
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2393 - acc: 0.9244\n",
      "Epoch 00234: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2393 - acc: 0.9244 - val_loss: 0.1914 - val_acc: 0.9511\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2444 - acc: 0.9249\n",
      "Epoch 00235: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2446 - acc: 0.9249 - val_loss: 0.1894 - val_acc: 0.9474\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2482 - acc: 0.9216\n",
      "Epoch 00236: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2482 - acc: 0.9216 - val_loss: 0.1913 - val_acc: 0.9492\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2412 - acc: 0.9241\n",
      "Epoch 00237: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2412 - acc: 0.9241 - val_loss: 0.2069 - val_acc: 0.9446\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2395 - acc: 0.9235\n",
      "Epoch 00238: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2395 - acc: 0.9235 - val_loss: 0.2098 - val_acc: 0.9425\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2392 - acc: 0.9244\n",
      "Epoch 00239: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2392 - acc: 0.9244 - val_loss: 0.1921 - val_acc: 0.9488\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2419 - acc: 0.9249\n",
      "Epoch 00240: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2419 - acc: 0.9248 - val_loss: 0.1944 - val_acc: 0.9485\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2404 - acc: 0.9252\n",
      "Epoch 00241: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2404 - acc: 0.9252 - val_loss: 0.1915 - val_acc: 0.9488\n",
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2372 - acc: 0.9250\n",
      "Epoch 00242: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2372 - acc: 0.9250 - val_loss: 0.1914 - val_acc: 0.9490\n",
      "Epoch 243/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2385 - acc: 0.9245\n",
      "Epoch 00243: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2385 - acc: 0.9245 - val_loss: 0.1920 - val_acc: 0.9511\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2376 - acc: 0.9246\n",
      "Epoch 00244: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2376 - acc: 0.9246 - val_loss: 0.1882 - val_acc: 0.9506\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2387 - acc: 0.9249\n",
      "Epoch 00245: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2388 - acc: 0.9249 - val_loss: 0.1903 - val_acc: 0.9485\n",
      "Epoch 246/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2377 - acc: 0.9259\n",
      "Epoch 00246: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2377 - acc: 0.9259 - val_loss: 0.1892 - val_acc: 0.9488\n",
      "Epoch 247/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2390 - acc: 0.9248\n",
      "Epoch 00247: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2390 - acc: 0.9248 - val_loss: 0.1931 - val_acc: 0.9497\n",
      "Epoch 248/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2356 - acc: 0.9257\n",
      "Epoch 00248: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2356 - acc: 0.9257 - val_loss: 0.1915 - val_acc: 0.9481\n",
      "Epoch 249/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2393 - acc: 0.9249\n",
      "Epoch 00249: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2393 - acc: 0.9249 - val_loss: 0.1938 - val_acc: 0.9485\n",
      "Epoch 250/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2311 - acc: 0.9286\n",
      "Epoch 00250: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2310 - acc: 0.9286 - val_loss: 0.1902 - val_acc: 0.9497\n",
      "Epoch 251/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2328 - acc: 0.9267\n",
      "Epoch 00251: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2328 - acc: 0.9267 - val_loss: 0.1913 - val_acc: 0.9481\n",
      "Epoch 252/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2289 - acc: 0.9278\n",
      "Epoch 00252: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2289 - acc: 0.9278 - val_loss: 0.1877 - val_acc: 0.9492\n",
      "Epoch 253/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2318 - acc: 0.9254\n",
      "Epoch 00253: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2318 - acc: 0.9254 - val_loss: 0.1918 - val_acc: 0.9490\n",
      "Epoch 254/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2309 - acc: 0.9276\n",
      "Epoch 00254: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2308 - acc: 0.9276 - val_loss: 0.1909 - val_acc: 0.9515\n",
      "Epoch 255/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2325 - acc: 0.9258\n",
      "Epoch 00255: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2325 - acc: 0.9259 - val_loss: 0.1899 - val_acc: 0.9497\n",
      "Epoch 256/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2341 - acc: 0.9250\n",
      "Epoch 00256: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2341 - acc: 0.9250 - val_loss: 0.1887 - val_acc: 0.9495\n",
      "Epoch 257/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2291 - acc: 0.9268\n",
      "Epoch 00257: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2291 - acc: 0.9268 - val_loss: 0.2042 - val_acc: 0.9429\n",
      "Epoch 258/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2352 - acc: 0.9259\n",
      "Epoch 00258: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2352 - acc: 0.9259 - val_loss: 0.1996 - val_acc: 0.9488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2296 - acc: 0.9267\n",
      "Epoch 00259: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2297 - acc: 0.9267 - val_loss: 0.2104 - val_acc: 0.9464\n",
      "Epoch 260/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2344 - acc: 0.9258\n",
      "Epoch 00260: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2344 - acc: 0.9258 - val_loss: 0.1869 - val_acc: 0.9506\n",
      "Epoch 261/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2311 - acc: 0.9281\n",
      "Epoch 00261: val_loss did not improve from 0.18643\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2311 - acc: 0.9281 - val_loss: 0.2020 - val_acc: 0.9481\n",
      "Epoch 262/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2291 - acc: 0.9283\n",
      "Epoch 00262: val_loss improved from 0.18643 to 0.18354, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/262-0.1835.hdf5\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2291 - acc: 0.9282 - val_loss: 0.1835 - val_acc: 0.9488\n",
      "Epoch 263/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2302 - acc: 0.9274\n",
      "Epoch 00263: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2302 - acc: 0.9274 - val_loss: 0.1920 - val_acc: 0.9478\n",
      "Epoch 264/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2292 - acc: 0.9287\n",
      "Epoch 00264: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2291 - acc: 0.9287 - val_loss: 0.1965 - val_acc: 0.9476\n",
      "Epoch 265/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2308 - acc: 0.9269\n",
      "Epoch 00265: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2308 - acc: 0.9269 - val_loss: 0.1963 - val_acc: 0.9474\n",
      "Epoch 266/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2301 - acc: 0.9269\n",
      "Epoch 00266: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2301 - acc: 0.9269 - val_loss: 0.1857 - val_acc: 0.9506\n",
      "Epoch 267/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9272\n",
      "Epoch 00267: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2256 - acc: 0.9272 - val_loss: 0.1903 - val_acc: 0.9495\n",
      "Epoch 268/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2255 - acc: 0.9271\n",
      "Epoch 00268: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2255 - acc: 0.9271 - val_loss: 0.1894 - val_acc: 0.9492\n",
      "Epoch 269/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2245 - acc: 0.9294\n",
      "Epoch 00269: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 469us/sample - loss: 0.2245 - acc: 0.9294 - val_loss: 0.1842 - val_acc: 0.9511\n",
      "Epoch 270/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2260 - acc: 0.9279\n",
      "Epoch 00270: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2260 - acc: 0.9278 - val_loss: 0.1878 - val_acc: 0.9483\n",
      "Epoch 271/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2231 - acc: 0.9292\n",
      "Epoch 00271: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2231 - acc: 0.9291 - val_loss: 0.1911 - val_acc: 0.9492\n",
      "Epoch 272/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2214 - acc: 0.9291\n",
      "Epoch 00272: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2213 - acc: 0.9291 - val_loss: 0.1902 - val_acc: 0.9518\n",
      "Epoch 273/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2236 - acc: 0.9283\n",
      "Epoch 00273: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2236 - acc: 0.9282 - val_loss: 0.1970 - val_acc: 0.9471\n",
      "Epoch 274/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2223 - acc: 0.9294\n",
      "Epoch 00274: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2223 - acc: 0.9294 - val_loss: 0.1886 - val_acc: 0.9509\n",
      "Epoch 275/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2206 - acc: 0.9307\n",
      "Epoch 00275: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2207 - acc: 0.9307 - val_loss: 0.1938 - val_acc: 0.9492\n",
      "Epoch 276/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2223 - acc: 0.9288\n",
      "Epoch 00276: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2222 - acc: 0.9288 - val_loss: 0.1850 - val_acc: 0.9495\n",
      "Epoch 277/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2226 - acc: 0.9293\n",
      "Epoch 00277: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2225 - acc: 0.9293 - val_loss: 0.1887 - val_acc: 0.9485\n",
      "Epoch 278/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2220 - acc: 0.9307\n",
      "Epoch 00278: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.2220 - acc: 0.9307 - val_loss: 0.1967 - val_acc: 0.9460\n",
      "Epoch 279/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2201 - acc: 0.9301\n",
      "Epoch 00279: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2201 - acc: 0.9301 - val_loss: 0.1975 - val_acc: 0.9476\n",
      "Epoch 280/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2217 - acc: 0.9289\n",
      "Epoch 00280: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2218 - acc: 0.9288 - val_loss: 0.1914 - val_acc: 0.9518\n",
      "Epoch 281/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2216 - acc: 0.9301\n",
      "Epoch 00281: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2216 - acc: 0.9301 - val_loss: 0.1909 - val_acc: 0.9488\n",
      "Epoch 282/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2160 - acc: 0.9301\n",
      "Epoch 00282: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2160 - acc: 0.9301 - val_loss: 0.1875 - val_acc: 0.9511\n",
      "Epoch 283/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2159 - acc: 0.9310\n",
      "Epoch 00283: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2159 - acc: 0.9310 - val_loss: 0.1909 - val_acc: 0.9488\n",
      "Epoch 284/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2181 - acc: 0.9309\n",
      "Epoch 00284: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2181 - acc: 0.9309 - val_loss: 0.1860 - val_acc: 0.9509\n",
      "Epoch 285/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2190 - acc: 0.9301\n",
      "Epoch 00285: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2190 - acc: 0.9301 - val_loss: 0.1948 - val_acc: 0.9488\n",
      "Epoch 286/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2190 - acc: 0.9303\n",
      "Epoch 00286: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2189 - acc: 0.9303 - val_loss: 0.1872 - val_acc: 0.9502\n",
      "Epoch 287/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2154 - acc: 0.9308\n",
      "Epoch 00287: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2154 - acc: 0.9308 - val_loss: 0.2094 - val_acc: 0.9441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2145 - acc: 0.9310\n",
      "Epoch 00288: val_loss did not improve from 0.18354\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2145 - acc: 0.9309 - val_loss: 0.1925 - val_acc: 0.9488\n",
      "Epoch 289/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2138 - acc: 0.9324\n",
      "Epoch 00289: val_loss improved from 0.18354 to 0.18247, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/289-0.1825.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2138 - acc: 0.9324 - val_loss: 0.1825 - val_acc: 0.9495\n",
      "Epoch 290/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2140 - acc: 0.9313\n",
      "Epoch 00290: val_loss did not improve from 0.18247\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2140 - acc: 0.9313 - val_loss: 0.1952 - val_acc: 0.9502\n",
      "Epoch 291/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2161 - acc: 0.9310\n",
      "Epoch 00291: val_loss did not improve from 0.18247\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2161 - acc: 0.9310 - val_loss: 0.1884 - val_acc: 0.9509\n",
      "Epoch 292/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2154 - acc: 0.9304\n",
      "Epoch 00292: val_loss did not improve from 0.18247\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2153 - acc: 0.9304 - val_loss: 0.1935 - val_acc: 0.9506\n",
      "Epoch 293/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2114 - acc: 0.9305\n",
      "Epoch 00293: val_loss did not improve from 0.18247\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2114 - acc: 0.9305 - val_loss: 0.1885 - val_acc: 0.9464\n",
      "Epoch 294/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2136 - acc: 0.9328\n",
      "Epoch 00294: val_loss did not improve from 0.18247\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2136 - acc: 0.9328 - val_loss: 0.1972 - val_acc: 0.9495\n",
      "Epoch 295/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2129 - acc: 0.9315\n",
      "Epoch 00295: val_loss did not improve from 0.18247\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2129 - acc: 0.9315 - val_loss: 0.1933 - val_acc: 0.9478\n",
      "Epoch 296/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2151 - acc: 0.9315\n",
      "Epoch 00296: val_loss did not improve from 0.18247\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2151 - acc: 0.9315 - val_loss: 0.1995 - val_acc: 0.9488\n",
      "Epoch 297/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9311\n",
      "Epoch 00297: val_loss did not improve from 0.18247\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2107 - acc: 0.9311 - val_loss: 0.1884 - val_acc: 0.9506\n",
      "Epoch 298/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9323\n",
      "Epoch 00298: val_loss did not improve from 0.18247\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2110 - acc: 0.9323 - val_loss: 0.1897 - val_acc: 0.9490\n",
      "Epoch 299/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9317\n",
      "Epoch 00299: val_loss did not improve from 0.18247\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2107 - acc: 0.9317 - val_loss: 0.1919 - val_acc: 0.9495\n",
      "Epoch 300/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9317\n",
      "Epoch 00300: val_loss did not improve from 0.18247\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2090 - acc: 0.9317 - val_loss: 0.1922 - val_acc: 0.9518\n",
      "Epoch 301/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2079 - acc: 0.9332\n",
      "Epoch 00301: val_loss did not improve from 0.18247\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.2078 - acc: 0.9332 - val_loss: 0.1940 - val_acc: 0.9483\n",
      "Epoch 302/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2085 - acc: 0.9338\n",
      "Epoch 00302: val_loss improved from 0.18247 to 0.18243, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv_checkpoint/302-0.1824.hdf5\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2085 - acc: 0.9338 - val_loss: 0.1824 - val_acc: 0.9492\n",
      "Epoch 303/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2104 - acc: 0.9324\n",
      "Epoch 00303: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2104 - acc: 0.9324 - val_loss: 0.1885 - val_acc: 0.9511\n",
      "Epoch 304/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2058 - acc: 0.9339\n",
      "Epoch 00304: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2058 - acc: 0.9339 - val_loss: 0.1891 - val_acc: 0.9495\n",
      "Epoch 305/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9329\n",
      "Epoch 00305: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2090 - acc: 0.9329 - val_loss: 0.1971 - val_acc: 0.9469\n",
      "Epoch 306/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2078 - acc: 0.9334\n",
      "Epoch 00306: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2077 - acc: 0.9334 - val_loss: 0.2044 - val_acc: 0.9467\n",
      "Epoch 307/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2069 - acc: 0.9327\n",
      "Epoch 00307: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2069 - acc: 0.9328 - val_loss: 0.1884 - val_acc: 0.9506\n",
      "Epoch 308/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2055 - acc: 0.9344\n",
      "Epoch 00308: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2055 - acc: 0.9344 - val_loss: 0.2041 - val_acc: 0.9464\n",
      "Epoch 309/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2068 - acc: 0.9331\n",
      "Epoch 00309: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2068 - acc: 0.9331 - val_loss: 0.1895 - val_acc: 0.9474\n",
      "Epoch 310/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2065 - acc: 0.9322\n",
      "Epoch 00310: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2067 - acc: 0.9321 - val_loss: 0.1928 - val_acc: 0.9476\n",
      "Epoch 311/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2046 - acc: 0.9342\n",
      "Epoch 00311: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2046 - acc: 0.9342 - val_loss: 0.1922 - val_acc: 0.9502\n",
      "Epoch 312/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2042 - acc: 0.9348\n",
      "Epoch 00312: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2042 - acc: 0.9348 - val_loss: 0.1908 - val_acc: 0.9502\n",
      "Epoch 313/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2046 - acc: 0.9342\n",
      "Epoch 00313: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.2046 - acc: 0.9342 - val_loss: 0.1922 - val_acc: 0.9474\n",
      "Epoch 314/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2060 - acc: 0.9353\n",
      "Epoch 00314: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2060 - acc: 0.9353 - val_loss: 0.1951 - val_acc: 0.9478\n",
      "Epoch 315/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2067 - acc: 0.9338\n",
      "Epoch 00315: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2067 - acc: 0.9338 - val_loss: 0.1922 - val_acc: 0.9490\n",
      "Epoch 316/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2029 - acc: 0.9346\n",
      "Epoch 00316: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.2029 - acc: 0.9346 - val_loss: 0.1950 - val_acc: 0.9499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 317/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2060 - acc: 0.9333\n",
      "Epoch 00317: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2059 - acc: 0.9334 - val_loss: 0.1911 - val_acc: 0.9488\n",
      "Epoch 318/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9340\n",
      "Epoch 00318: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.2044 - acc: 0.9340 - val_loss: 0.1869 - val_acc: 0.9534\n",
      "Epoch 319/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2064 - acc: 0.9337\n",
      "Epoch 00319: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.2064 - acc: 0.9338 - val_loss: 0.1896 - val_acc: 0.9509\n",
      "Epoch 320/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2045 - acc: 0.9348\n",
      "Epoch 00320: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2045 - acc: 0.9348 - val_loss: 0.1978 - val_acc: 0.9457\n",
      "Epoch 321/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2002 - acc: 0.9360\n",
      "Epoch 00321: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2002 - acc: 0.9360 - val_loss: 0.1994 - val_acc: 0.9467\n",
      "Epoch 322/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2029 - acc: 0.9359\n",
      "Epoch 00322: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.2029 - acc: 0.9359 - val_loss: 0.1936 - val_acc: 0.9488\n",
      "Epoch 323/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9369\n",
      "Epoch 00323: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.1986 - acc: 0.9369 - val_loss: 0.1940 - val_acc: 0.9504\n",
      "Epoch 324/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2010 - acc: 0.9340\n",
      "Epoch 00324: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2010 - acc: 0.9340 - val_loss: 0.1957 - val_acc: 0.9492\n",
      "Epoch 325/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9350\n",
      "Epoch 00325: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2018 - acc: 0.9350 - val_loss: 0.1966 - val_acc: 0.9478\n",
      "Epoch 326/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9346\n",
      "Epoch 00326: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.2011 - acc: 0.9346 - val_loss: 0.1960 - val_acc: 0.9492\n",
      "Epoch 327/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1968 - acc: 0.9374\n",
      "Epoch 00327: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.1967 - acc: 0.9374 - val_loss: 0.1905 - val_acc: 0.9504\n",
      "Epoch 328/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1977 - acc: 0.9356\n",
      "Epoch 00328: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.1977 - acc: 0.9356 - val_loss: 0.1859 - val_acc: 0.9513\n",
      "Epoch 329/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9356\n",
      "Epoch 00329: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.2005 - acc: 0.9356 - val_loss: 0.1991 - val_acc: 0.9499\n",
      "Epoch 330/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1979 - acc: 0.9365\n",
      "Epoch 00330: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.1979 - acc: 0.9365 - val_loss: 0.1955 - val_acc: 0.9499\n",
      "Epoch 331/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1962 - acc: 0.9355\n",
      "Epoch 00331: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.1962 - acc: 0.9355 - val_loss: 0.1926 - val_acc: 0.9527\n",
      "Epoch 332/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1944 - acc: 0.9361\n",
      "Epoch 00332: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.1944 - acc: 0.9361 - val_loss: 0.1869 - val_acc: 0.9506\n",
      "Epoch 333/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1999 - acc: 0.9364\n",
      "Epoch 00333: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 467us/sample - loss: 0.1998 - acc: 0.9364 - val_loss: 0.1888 - val_acc: 0.9511\n",
      "Epoch 334/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9359\n",
      "Epoch 00334: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.1981 - acc: 0.9359 - val_loss: 0.1899 - val_acc: 0.9483\n",
      "Epoch 335/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1973 - acc: 0.9360\n",
      "Epoch 00335: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.1973 - acc: 0.9360 - val_loss: 0.1929 - val_acc: 0.9490\n",
      "Epoch 336/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2008 - acc: 0.9352\n",
      "Epoch 00336: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.2008 - acc: 0.9353 - val_loss: 0.1906 - val_acc: 0.9502\n",
      "Epoch 337/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1943 - acc: 0.9356\n",
      "Epoch 00337: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.1944 - acc: 0.9356 - val_loss: 0.1922 - val_acc: 0.9504\n",
      "Epoch 338/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1964 - acc: 0.9365\n",
      "Epoch 00338: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.1964 - acc: 0.9365 - val_loss: 0.1929 - val_acc: 0.9485\n",
      "Epoch 339/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1947 - acc: 0.9377\n",
      "Epoch 00339: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.1947 - acc: 0.9377 - val_loss: 0.1920 - val_acc: 0.9520\n",
      "Epoch 340/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1960 - acc: 0.9380\n",
      "Epoch 00340: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.1960 - acc: 0.9381 - val_loss: 0.2028 - val_acc: 0.9495\n",
      "Epoch 341/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1933 - acc: 0.9376\n",
      "Epoch 00341: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.1934 - acc: 0.9376 - val_loss: 0.1976 - val_acc: 0.9506\n",
      "Epoch 342/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1931 - acc: 0.9390\n",
      "Epoch 00342: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.1931 - acc: 0.9391 - val_loss: 0.1934 - val_acc: 0.9485\n",
      "Epoch 343/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1947 - acc: 0.9366\n",
      "Epoch 00343: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.1948 - acc: 0.9366 - val_loss: 0.1959 - val_acc: 0.9481\n",
      "Epoch 344/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9385\n",
      "Epoch 00344: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.1926 - acc: 0.9385 - val_loss: 0.1962 - val_acc: 0.9504\n",
      "Epoch 345/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9374\n",
      "Epoch 00345: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.1923 - acc: 0.9374 - val_loss: 0.1939 - val_acc: 0.9509\n",
      "Epoch 346/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1920 - acc: 0.9373\n",
      "Epoch 00346: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 466us/sample - loss: 0.1919 - acc: 0.9373 - val_loss: 0.1890 - val_acc: 0.9527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 347/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1913 - acc: 0.9376\n",
      "Epoch 00347: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.1913 - acc: 0.9376 - val_loss: 0.1913 - val_acc: 0.9518\n",
      "Epoch 348/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1887 - acc: 0.9392\n",
      "Epoch 00348: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.1888 - acc: 0.9391 - val_loss: 0.1985 - val_acc: 0.9481\n",
      "Epoch 349/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1915 - acc: 0.9383\n",
      "Epoch 00349: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 468us/sample - loss: 0.1915 - acc: 0.9383 - val_loss: 0.1856 - val_acc: 0.9520\n",
      "Epoch 350/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1949 - acc: 0.9369\n",
      "Epoch 00350: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.1951 - acc: 0.9368 - val_loss: 0.1949 - val_acc: 0.9481\n",
      "Epoch 351/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9399\n",
      "Epoch 00351: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.1884 - acc: 0.9399 - val_loss: 0.1960 - val_acc: 0.9513\n",
      "Epoch 352/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1921 - acc: 0.9383\n",
      "Epoch 00352: val_loss did not improve from 0.18243\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.1922 - acc: 0.9382 - val_loss: 0.1902 - val_acc: 0.9502\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 282us/sample - loss: 0.2143 - acc: 0.9348\n",
      "Loss: 0.2142969814663983 Accuracy: 0.9347871\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5586 - acc: 0.1563\n",
      "Epoch 00001: val_loss improved from inf to 2.02206, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/001-2.0221.hdf5\n",
      "36805/36805 [==============================] - 21s 578us/sample - loss: 2.5585 - acc: 0.1563 - val_loss: 2.0221 - val_acc: 0.4062\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9279 - acc: 0.3629\n",
      "Epoch 00002: val_loss improved from 2.02206 to 1.53185, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/002-1.5319.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 1.9280 - acc: 0.3629 - val_loss: 1.5319 - val_acc: 0.5691\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6213 - acc: 0.4746\n",
      "Epoch 00003: val_loss improved from 1.53185 to 1.29039, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/003-1.2904.hdf5\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 1.6214 - acc: 0.4745 - val_loss: 1.2904 - val_acc: 0.6070\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4386 - acc: 0.5342\n",
      "Epoch 00004: val_loss improved from 1.29039 to 1.12548, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/004-1.1255.hdf5\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 1.4387 - acc: 0.5342 - val_loss: 1.1255 - val_acc: 0.6548\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3076 - acc: 0.5764\n",
      "Epoch 00005: val_loss improved from 1.12548 to 1.01802, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/005-1.0180.hdf5\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 1.3076 - acc: 0.5764 - val_loss: 1.0180 - val_acc: 0.6862\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2066 - acc: 0.6115\n",
      "Epoch 00006: val_loss improved from 1.01802 to 0.90865, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/006-0.9086.hdf5\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 1.2066 - acc: 0.6115 - val_loss: 0.9086 - val_acc: 0.7191\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1248 - acc: 0.6408\n",
      "Epoch 00007: val_loss improved from 0.90865 to 0.85272, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/007-0.8527.hdf5\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 1.1249 - acc: 0.6408 - val_loss: 0.8527 - val_acc: 0.7494\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0606 - acc: 0.6652\n",
      "Epoch 00008: val_loss improved from 0.85272 to 0.77325, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/008-0.7732.hdf5\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 1.0605 - acc: 0.6652 - val_loss: 0.7732 - val_acc: 0.7636\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9979 - acc: 0.6870\n",
      "Epoch 00009: val_loss improved from 0.77325 to 0.73662, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/009-0.7366.hdf5\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.9978 - acc: 0.6870 - val_loss: 0.7366 - val_acc: 0.7890\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9476 - acc: 0.7019\n",
      "Epoch 00010: val_loss improved from 0.73662 to 0.67933, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/010-0.6793.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.9477 - acc: 0.7019 - val_loss: 0.6793 - val_acc: 0.8022\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8921 - acc: 0.7194\n",
      "Epoch 00011: val_loss improved from 0.67933 to 0.67807, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/011-0.6781.hdf5\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.8920 - acc: 0.7194 - val_loss: 0.6781 - val_acc: 0.8025\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8376 - acc: 0.7393\n",
      "Epoch 00012: val_loss improved from 0.67807 to 0.59157, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/012-0.5916.hdf5\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.8375 - acc: 0.7394 - val_loss: 0.5916 - val_acc: 0.8283\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8053 - acc: 0.7505\n",
      "Epoch 00013: val_loss improved from 0.59157 to 0.55690, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/013-0.5569.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.8055 - acc: 0.7505 - val_loss: 0.5569 - val_acc: 0.8411\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7712 - acc: 0.7614\n",
      "Epoch 00014: val_loss improved from 0.55690 to 0.52890, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/014-0.5289.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.7713 - acc: 0.7614 - val_loss: 0.5289 - val_acc: 0.8507\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7350 - acc: 0.7733\n",
      "Epoch 00015: val_loss improved from 0.52890 to 0.51312, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/015-0.5131.hdf5\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.7349 - acc: 0.7733 - val_loss: 0.5131 - val_acc: 0.8537\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7070 - acc: 0.7820\n",
      "Epoch 00016: val_loss improved from 0.51312 to 0.48585, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/016-0.4859.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.7070 - acc: 0.7819 - val_loss: 0.4859 - val_acc: 0.8600\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6805 - acc: 0.7895\n",
      "Epoch 00017: val_loss improved from 0.48585 to 0.46964, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/017-0.4696.hdf5\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.6805 - acc: 0.7895 - val_loss: 0.4696 - val_acc: 0.8626\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6588 - acc: 0.7961\n",
      "Epoch 00018: val_loss improved from 0.46964 to 0.44699, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/018-0.4470.hdf5\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.6589 - acc: 0.7961 - val_loss: 0.4470 - val_acc: 0.8730\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6370 - acc: 0.8055\n",
      "Epoch 00019: val_loss improved from 0.44699 to 0.42942, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/019-0.4294.hdf5\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.6369 - acc: 0.8056 - val_loss: 0.4294 - val_acc: 0.8775\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6110 - acc: 0.8118\n",
      "Epoch 00020: val_loss improved from 0.42942 to 0.41507, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/020-0.4151.hdf5\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.6109 - acc: 0.8118 - val_loss: 0.4151 - val_acc: 0.8800\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5944 - acc: 0.8192\n",
      "Epoch 00021: val_loss improved from 0.41507 to 0.39709, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/021-0.3971.hdf5\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.5945 - acc: 0.8191 - val_loss: 0.3971 - val_acc: 0.8870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5754 - acc: 0.8225\n",
      "Epoch 00022: val_loss improved from 0.39709 to 0.38233, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/022-0.3823.hdf5\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.5754 - acc: 0.8225 - val_loss: 0.3823 - val_acc: 0.8894\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5550 - acc: 0.8290\n",
      "Epoch 00023: val_loss did not improve from 0.38233\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.5550 - acc: 0.8290 - val_loss: 0.3840 - val_acc: 0.8898\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5444 - acc: 0.8339\n",
      "Epoch 00024: val_loss improved from 0.38233 to 0.35769, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/024-0.3577.hdf5\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.5443 - acc: 0.8339 - val_loss: 0.3577 - val_acc: 0.8956\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5270 - acc: 0.8376\n",
      "Epoch 00025: val_loss improved from 0.35769 to 0.34298, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/025-0.3430.hdf5\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.5270 - acc: 0.8375 - val_loss: 0.3430 - val_acc: 0.9015\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5105 - acc: 0.8441\n",
      "Epoch 00026: val_loss improved from 0.34298 to 0.33340, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/026-0.3334.hdf5\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.5105 - acc: 0.8441 - val_loss: 0.3334 - val_acc: 0.9052\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5005 - acc: 0.8465\n",
      "Epoch 00027: val_loss did not improve from 0.33340\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.5005 - acc: 0.8465 - val_loss: 0.3354 - val_acc: 0.9022\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4869 - acc: 0.8508\n",
      "Epoch 00028: val_loss improved from 0.33340 to 0.32212, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/028-0.3221.hdf5\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.4869 - acc: 0.8508 - val_loss: 0.3221 - val_acc: 0.9047\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4771 - acc: 0.8540\n",
      "Epoch 00029: val_loss improved from 0.32212 to 0.31159, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/029-0.3116.hdf5\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.4771 - acc: 0.8540 - val_loss: 0.3116 - val_acc: 0.9094\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4626 - acc: 0.8589\n",
      "Epoch 00030: val_loss did not improve from 0.31159\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.4626 - acc: 0.8589 - val_loss: 0.3197 - val_acc: 0.9043\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4527 - acc: 0.8609\n",
      "Epoch 00031: val_loss improved from 0.31159 to 0.29682, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/031-0.2968.hdf5\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.4528 - acc: 0.8609 - val_loss: 0.2968 - val_acc: 0.9173\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4424 - acc: 0.8638\n",
      "Epoch 00032: val_loss improved from 0.29682 to 0.29386, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/032-0.2939.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.4423 - acc: 0.8638 - val_loss: 0.2939 - val_acc: 0.9187\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4403 - acc: 0.8651\n",
      "Epoch 00033: val_loss improved from 0.29386 to 0.28686, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/033-0.2869.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.4402 - acc: 0.8651 - val_loss: 0.2869 - val_acc: 0.9154\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4240 - acc: 0.8701\n",
      "Epoch 00034: val_loss improved from 0.28686 to 0.27707, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/034-0.2771.hdf5\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.4240 - acc: 0.8701 - val_loss: 0.2771 - val_acc: 0.9192\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4154 - acc: 0.8731\n",
      "Epoch 00035: val_loss improved from 0.27707 to 0.27361, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/035-0.2736.hdf5\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.4153 - acc: 0.8731 - val_loss: 0.2736 - val_acc: 0.9241\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4108 - acc: 0.8741\n",
      "Epoch 00036: val_loss improved from 0.27361 to 0.26776, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/036-0.2678.hdf5\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.4110 - acc: 0.8740 - val_loss: 0.2678 - val_acc: 0.9238\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4015 - acc: 0.8770\n",
      "Epoch 00037: val_loss improved from 0.26776 to 0.26371, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/037-0.2637.hdf5\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.4016 - acc: 0.8770 - val_loss: 0.2637 - val_acc: 0.9234\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3929 - acc: 0.8784\n",
      "Epoch 00038: val_loss improved from 0.26371 to 0.26101, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/038-0.2610.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.3929 - acc: 0.8784 - val_loss: 0.2610 - val_acc: 0.9238\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3904 - acc: 0.8795\n",
      "Epoch 00039: val_loss improved from 0.26101 to 0.25370, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/039-0.2537.hdf5\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.3904 - acc: 0.8795 - val_loss: 0.2537 - val_acc: 0.9276\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3877 - acc: 0.8821\n",
      "Epoch 00040: val_loss improved from 0.25370 to 0.24594, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/040-0.2459.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.3876 - acc: 0.8821 - val_loss: 0.2459 - val_acc: 0.9276\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3743 - acc: 0.8870\n",
      "Epoch 00041: val_loss improved from 0.24594 to 0.24219, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/041-0.2422.hdf5\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.3743 - acc: 0.8870 - val_loss: 0.2422 - val_acc: 0.9304\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3699 - acc: 0.8852\n",
      "Epoch 00042: val_loss improved from 0.24219 to 0.23585, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/042-0.2358.hdf5\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.3698 - acc: 0.8852 - val_loss: 0.2358 - val_acc: 0.9320\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3657 - acc: 0.8889\n",
      "Epoch 00043: val_loss did not improve from 0.23585\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.3658 - acc: 0.8889 - val_loss: 0.2365 - val_acc: 0.9306\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3609 - acc: 0.8885\n",
      "Epoch 00044: val_loss improved from 0.23585 to 0.23423, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/044-0.2342.hdf5\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.3609 - acc: 0.8885 - val_loss: 0.2342 - val_acc: 0.9313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3528 - acc: 0.8922\n",
      "Epoch 00045: val_loss did not improve from 0.23423\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.3528 - acc: 0.8922 - val_loss: 0.2373 - val_acc: 0.9278\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3463 - acc: 0.8948\n",
      "Epoch 00046: val_loss improved from 0.23423 to 0.22577, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/046-0.2258.hdf5\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.3463 - acc: 0.8948 - val_loss: 0.2258 - val_acc: 0.9336\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3394 - acc: 0.8953\n",
      "Epoch 00047: val_loss did not improve from 0.22577\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.3394 - acc: 0.8953 - val_loss: 0.2270 - val_acc: 0.9366\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3408 - acc: 0.8946\n",
      "Epoch 00048: val_loss did not improve from 0.22577\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.3408 - acc: 0.8946 - val_loss: 0.2285 - val_acc: 0.9341\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3319 - acc: 0.8983\n",
      "Epoch 00049: val_loss improved from 0.22577 to 0.21431, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/049-0.2143.hdf5\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.3319 - acc: 0.8984 - val_loss: 0.2143 - val_acc: 0.9376\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3282 - acc: 0.8993\n",
      "Epoch 00050: val_loss did not improve from 0.21431\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.3282 - acc: 0.8993 - val_loss: 0.2235 - val_acc: 0.9373\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3235 - acc: 0.8997\n",
      "Epoch 00051: val_loss did not improve from 0.21431\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.3235 - acc: 0.8997 - val_loss: 0.2171 - val_acc: 0.9357\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3193 - acc: 0.9023\n",
      "Epoch 00052: val_loss did not improve from 0.21431\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.3193 - acc: 0.9023 - val_loss: 0.2190 - val_acc: 0.9378\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3162 - acc: 0.9024\n",
      "Epoch 00053: val_loss improved from 0.21431 to 0.20203, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/053-0.2020.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.3162 - acc: 0.9024 - val_loss: 0.2020 - val_acc: 0.9408\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3127 - acc: 0.9039\n",
      "Epoch 00054: val_loss did not improve from 0.20203\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.3127 - acc: 0.9039 - val_loss: 0.2060 - val_acc: 0.9401\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3082 - acc: 0.9049\n",
      "Epoch 00055: val_loss improved from 0.20203 to 0.19686, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/055-0.1969.hdf5\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.3082 - acc: 0.9049 - val_loss: 0.1969 - val_acc: 0.9404\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2992 - acc: 0.9085\n",
      "Epoch 00056: val_loss improved from 0.19686 to 0.19299, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/056-0.1930.hdf5\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.2992 - acc: 0.9085 - val_loss: 0.1930 - val_acc: 0.9434\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3040 - acc: 0.9073\n",
      "Epoch 00057: val_loss did not improve from 0.19299\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.3040 - acc: 0.9073 - val_loss: 0.1974 - val_acc: 0.9420\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2933 - acc: 0.9085\n",
      "Epoch 00058: val_loss did not improve from 0.19299\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.2932 - acc: 0.9085 - val_loss: 0.1933 - val_acc: 0.9415\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2937 - acc: 0.9103\n",
      "Epoch 00059: val_loss did not improve from 0.19299\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.2937 - acc: 0.9103 - val_loss: 0.2093 - val_acc: 0.9359\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2900 - acc: 0.9108\n",
      "Epoch 00060: val_loss improved from 0.19299 to 0.18987, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/060-0.1899.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.2900 - acc: 0.9108 - val_loss: 0.1899 - val_acc: 0.9425\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2859 - acc: 0.9121\n",
      "Epoch 00061: val_loss did not improve from 0.18987\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.2859 - acc: 0.9121 - val_loss: 0.2013 - val_acc: 0.9434\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2774 - acc: 0.9142\n",
      "Epoch 00062: val_loss improved from 0.18987 to 0.18135, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/062-0.1813.hdf5\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.2774 - acc: 0.9142 - val_loss: 0.1813 - val_acc: 0.9453\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2821 - acc: 0.9130\n",
      "Epoch 00063: val_loss did not improve from 0.18135\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.2822 - acc: 0.9129 - val_loss: 0.1844 - val_acc: 0.9460\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2715 - acc: 0.9175\n",
      "Epoch 00064: val_loss did not improve from 0.18135\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.2715 - acc: 0.9175 - val_loss: 0.1898 - val_acc: 0.9453\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2691 - acc: 0.9167\n",
      "Epoch 00065: val_loss did not improve from 0.18135\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.2691 - acc: 0.9167 - val_loss: 0.1820 - val_acc: 0.9448\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2708 - acc: 0.9155\n",
      "Epoch 00066: val_loss improved from 0.18135 to 0.18006, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/066-0.1801.hdf5\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.2708 - acc: 0.9156 - val_loss: 0.1801 - val_acc: 0.9474\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2673 - acc: 0.9183\n",
      "Epoch 00067: val_loss improved from 0.18006 to 0.17417, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/067-0.1742.hdf5\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.2673 - acc: 0.9183 - val_loss: 0.1742 - val_acc: 0.9509\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2638 - acc: 0.9192\n",
      "Epoch 00068: val_loss did not improve from 0.17417\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.2638 - acc: 0.9192 - val_loss: 0.1858 - val_acc: 0.9481\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2641 - acc: 0.9186\n",
      "Epoch 00069: val_loss improved from 0.17417 to 0.17394, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/069-0.1739.hdf5\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.2641 - acc: 0.9186 - val_loss: 0.1739 - val_acc: 0.9462\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2599 - acc: 0.9204\n",
      "Epoch 00070: val_loss did not improve from 0.17394\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.2598 - acc: 0.9204 - val_loss: 0.1768 - val_acc: 0.9455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2542 - acc: 0.9218\n",
      "Epoch 00071: val_loss did not improve from 0.17394\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.2542 - acc: 0.9218 - val_loss: 0.1821 - val_acc: 0.9429\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2553 - acc: 0.9202\n",
      "Epoch 00072: val_loss did not improve from 0.17394\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.2553 - acc: 0.9202 - val_loss: 0.1790 - val_acc: 0.9485\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2482 - acc: 0.9226\n",
      "Epoch 00073: val_loss did not improve from 0.17394\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.2482 - acc: 0.9226 - val_loss: 0.1755 - val_acc: 0.9469\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2478 - acc: 0.9226\n",
      "Epoch 00074: val_loss improved from 0.17394 to 0.17316, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/074-0.1732.hdf5\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.2477 - acc: 0.9226 - val_loss: 0.1732 - val_acc: 0.9464\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2481 - acc: 0.9223\n",
      "Epoch 00075: val_loss improved from 0.17316 to 0.16625, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/075-0.1662.hdf5\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.2481 - acc: 0.9223 - val_loss: 0.1662 - val_acc: 0.9515\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2448 - acc: 0.9240\n",
      "Epoch 00076: val_loss improved from 0.16625 to 0.16264, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/076-0.1626.hdf5\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.2448 - acc: 0.9240 - val_loss: 0.1626 - val_acc: 0.9525\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2447 - acc: 0.9224\n",
      "Epoch 00077: val_loss did not improve from 0.16264\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.2447 - acc: 0.9223 - val_loss: 0.1667 - val_acc: 0.9511\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2408 - acc: 0.9249\n",
      "Epoch 00078: val_loss did not improve from 0.16264\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.2408 - acc: 0.9249 - val_loss: 0.1652 - val_acc: 0.9506\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2409 - acc: 0.9249\n",
      "Epoch 00079: val_loss did not improve from 0.16264\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.2409 - acc: 0.9249 - val_loss: 0.1686 - val_acc: 0.9495\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2342 - acc: 0.9265\n",
      "Epoch 00080: val_loss did not improve from 0.16264\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.2343 - acc: 0.9265 - val_loss: 0.1690 - val_acc: 0.9511\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2342 - acc: 0.9267\n",
      "Epoch 00081: val_loss improved from 0.16264 to 0.15897, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/081-0.1590.hdf5\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.2342 - acc: 0.9267 - val_loss: 0.1590 - val_acc: 0.9509\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2300 - acc: 0.9266\n",
      "Epoch 00082: val_loss did not improve from 0.15897\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.2300 - acc: 0.9266 - val_loss: 0.1614 - val_acc: 0.9543\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2255 - acc: 0.9284\n",
      "Epoch 00083: val_loss did not improve from 0.15897\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.2254 - acc: 0.9284 - val_loss: 0.1662 - val_acc: 0.9525\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2236 - acc: 0.9314\n",
      "Epoch 00084: val_loss did not improve from 0.15897\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.2237 - acc: 0.9314 - val_loss: 0.1885 - val_acc: 0.9441\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.9277\n",
      "Epoch 00085: val_loss improved from 0.15897 to 0.15801, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/085-0.1580.hdf5\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.2282 - acc: 0.9278 - val_loss: 0.1580 - val_acc: 0.9518\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9299\n",
      "Epoch 00086: val_loss did not improve from 0.15801\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.2199 - acc: 0.9300 - val_loss: 0.1612 - val_acc: 0.9506\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2213 - acc: 0.9307\n",
      "Epoch 00087: val_loss did not improve from 0.15801\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.2213 - acc: 0.9307 - val_loss: 0.1623 - val_acc: 0.9520\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2206 - acc: 0.9308\n",
      "Epoch 00088: val_loss did not improve from 0.15801\n",
      "36805/36805 [==============================] - 18s 478us/sample - loss: 0.2206 - acc: 0.9307 - val_loss: 0.1690 - val_acc: 0.9502\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2173 - acc: 0.9318\n",
      "Epoch 00089: val_loss did not improve from 0.15801\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.2173 - acc: 0.9318 - val_loss: 0.1611 - val_acc: 0.9546\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2181 - acc: 0.9315\n",
      "Epoch 00090: val_loss did not improve from 0.15801\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.2181 - acc: 0.9316 - val_loss: 0.1710 - val_acc: 0.9490\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2130 - acc: 0.9334\n",
      "Epoch 00091: val_loss improved from 0.15801 to 0.15722, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/091-0.1572.hdf5\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.2131 - acc: 0.9334 - val_loss: 0.1572 - val_acc: 0.9548\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2148 - acc: 0.9314\n",
      "Epoch 00092: val_loss did not improve from 0.15722\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.2148 - acc: 0.9314 - val_loss: 0.1608 - val_acc: 0.9515\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2137 - acc: 0.9324\n",
      "Epoch 00093: val_loss improved from 0.15722 to 0.15369, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/093-0.1537.hdf5\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.2137 - acc: 0.9324 - val_loss: 0.1537 - val_acc: 0.9536\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2112 - acc: 0.9336\n",
      "Epoch 00094: val_loss did not improve from 0.15369\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.2112 - acc: 0.9336 - val_loss: 0.1552 - val_acc: 0.9557\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2090 - acc: 0.9334\n",
      "Epoch 00095: val_loss did not improve from 0.15369\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.2090 - acc: 0.9334 - val_loss: 0.1640 - val_acc: 0.9513\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2042 - acc: 0.9341\n",
      "Epoch 00096: val_loss improved from 0.15369 to 0.14910, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/096-0.1491.hdf5\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.2042 - acc: 0.9341 - val_loss: 0.1491 - val_acc: 0.9571\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1998 - acc: 0.9372\n",
      "Epoch 00097: val_loss did not improve from 0.14910\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.1998 - acc: 0.9372 - val_loss: 0.1533 - val_acc: 0.9562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2020 - acc: 0.9353\n",
      "Epoch 00098: val_loss did not improve from 0.14910\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.2019 - acc: 0.9353 - val_loss: 0.1496 - val_acc: 0.9557\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1983 - acc: 0.9377\n",
      "Epoch 00099: val_loss improved from 0.14910 to 0.14694, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/099-0.1469.hdf5\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.1983 - acc: 0.9378 - val_loss: 0.1469 - val_acc: 0.9555\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2006 - acc: 0.9384\n",
      "Epoch 00100: val_loss did not improve from 0.14694\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.2006 - acc: 0.9384 - val_loss: 0.1525 - val_acc: 0.9539\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9370\n",
      "Epoch 00101: val_loss did not improve from 0.14694\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.1993 - acc: 0.9370 - val_loss: 0.1499 - val_acc: 0.9564\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1952 - acc: 0.9383\n",
      "Epoch 00102: val_loss did not improve from 0.14694\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.1951 - acc: 0.9383 - val_loss: 0.1515 - val_acc: 0.9548\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1948 - acc: 0.9379\n",
      "Epoch 00103: val_loss did not improve from 0.14694\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1947 - acc: 0.9379 - val_loss: 0.1532 - val_acc: 0.9550\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1945 - acc: 0.9385\n",
      "Epoch 00104: val_loss did not improve from 0.14694\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1945 - acc: 0.9385 - val_loss: 0.1525 - val_acc: 0.9541\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1928 - acc: 0.9385\n",
      "Epoch 00105: val_loss improved from 0.14694 to 0.14481, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/105-0.1448.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1928 - acc: 0.9385 - val_loss: 0.1448 - val_acc: 0.9576\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1908 - acc: 0.9382\n",
      "Epoch 00106: val_loss did not improve from 0.14481\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.1908 - acc: 0.9382 - val_loss: 0.1693 - val_acc: 0.9488\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9390\n",
      "Epoch 00107: val_loss did not improve from 0.14481\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1926 - acc: 0.9390 - val_loss: 0.1481 - val_acc: 0.9571\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1920 - acc: 0.9394\n",
      "Epoch 00108: val_loss did not improve from 0.14481\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1920 - acc: 0.9394 - val_loss: 0.1452 - val_acc: 0.9583\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1867 - acc: 0.9402\n",
      "Epoch 00109: val_loss improved from 0.14481 to 0.14107, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/109-0.1411.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1867 - acc: 0.9402 - val_loss: 0.1411 - val_acc: 0.9588\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1877 - acc: 0.9380\n",
      "Epoch 00110: val_loss did not improve from 0.14107\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.1877 - acc: 0.9380 - val_loss: 0.1450 - val_acc: 0.9560\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9418\n",
      "Epoch 00111: val_loss did not improve from 0.14107\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1819 - acc: 0.9418 - val_loss: 0.1653 - val_acc: 0.9513\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1818 - acc: 0.9420\n",
      "Epoch 00112: val_loss did not improve from 0.14107\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1818 - acc: 0.9420 - val_loss: 0.1464 - val_acc: 0.9550\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1817 - acc: 0.9416\n",
      "Epoch 00113: val_loss did not improve from 0.14107\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1817 - acc: 0.9416 - val_loss: 0.1545 - val_acc: 0.9532\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9435\n",
      "Epoch 00114: val_loss did not improve from 0.14107\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.1803 - acc: 0.9435 - val_loss: 0.1524 - val_acc: 0.9525\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9428\n",
      "Epoch 00115: val_loss did not improve from 0.14107\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1780 - acc: 0.9428 - val_loss: 0.1465 - val_acc: 0.9567\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1788 - acc: 0.9423\n",
      "Epoch 00116: val_loss did not improve from 0.14107\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.1789 - acc: 0.9423 - val_loss: 0.1466 - val_acc: 0.9567\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1777 - acc: 0.9421\n",
      "Epoch 00117: val_loss improved from 0.14107 to 0.13993, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/117-0.1399.hdf5\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.1778 - acc: 0.9421 - val_loss: 0.1399 - val_acc: 0.9588\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1758 - acc: 0.9437\n",
      "Epoch 00118: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1758 - acc: 0.9437 - val_loss: 0.1454 - val_acc: 0.9555\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1745 - acc: 0.9430\n",
      "Epoch 00119: val_loss did not improve from 0.13993\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1745 - acc: 0.9430 - val_loss: 0.1464 - val_acc: 0.9564\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1713 - acc: 0.9445\n",
      "Epoch 00120: val_loss improved from 0.13993 to 0.13878, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/120-0.1388.hdf5\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.1713 - acc: 0.9445 - val_loss: 0.1388 - val_acc: 0.9595\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1716 - acc: 0.9443\n",
      "Epoch 00121: val_loss did not improve from 0.13878\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1715 - acc: 0.9443 - val_loss: 0.1453 - val_acc: 0.9553\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9453\n",
      "Epoch 00122: val_loss improved from 0.13878 to 0.13549, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/122-0.1355.hdf5\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.1690 - acc: 0.9453 - val_loss: 0.1355 - val_acc: 0.9602\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1691 - acc: 0.9472\n",
      "Epoch 00123: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1690 - acc: 0.9472 - val_loss: 0.1367 - val_acc: 0.9588\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1672 - acc: 0.9449\n",
      "Epoch 00124: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.1672 - acc: 0.9449 - val_loss: 0.1393 - val_acc: 0.9576\n",
      "Epoch 125/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9462\n",
      "Epoch 00125: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.1678 - acc: 0.9462 - val_loss: 0.1408 - val_acc: 0.9602\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9460\n",
      "Epoch 00126: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1669 - acc: 0.9460 - val_loss: 0.1401 - val_acc: 0.9583\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1658 - acc: 0.9476\n",
      "Epoch 00127: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1658 - acc: 0.9476 - val_loss: 0.1409 - val_acc: 0.9581\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1607 - acc: 0.9478\n",
      "Epoch 00128: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1607 - acc: 0.9478 - val_loss: 0.1383 - val_acc: 0.9597\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1635 - acc: 0.9473\n",
      "Epoch 00129: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1635 - acc: 0.9473 - val_loss: 0.1389 - val_acc: 0.9569\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1610 - acc: 0.9475\n",
      "Epoch 00130: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1610 - acc: 0.9475 - val_loss: 0.1370 - val_acc: 0.9597\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1626 - acc: 0.9481\n",
      "Epoch 00131: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.1626 - acc: 0.9481 - val_loss: 0.1436 - val_acc: 0.9569\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9480\n",
      "Epoch 00132: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.1604 - acc: 0.9480 - val_loss: 0.1532 - val_acc: 0.9562\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9488\n",
      "Epoch 00133: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1579 - acc: 0.9488 - val_loss: 0.1416 - val_acc: 0.9571\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9481\n",
      "Epoch 00134: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1587 - acc: 0.9481 - val_loss: 0.1375 - val_acc: 0.9590\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9496\n",
      "Epoch 00135: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1577 - acc: 0.9496 - val_loss: 0.1374 - val_acc: 0.9578\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1540 - acc: 0.9506\n",
      "Epoch 00136: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1540 - acc: 0.9506 - val_loss: 0.1377 - val_acc: 0.9604\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9490\n",
      "Epoch 00137: val_loss did not improve from 0.13549\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1587 - acc: 0.9491 - val_loss: 0.1355 - val_acc: 0.9590\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9502\n",
      "Epoch 00138: val_loss improved from 0.13549 to 0.13248, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/138-0.1325.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1549 - acc: 0.9502 - val_loss: 0.1325 - val_acc: 0.9597\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1533 - acc: 0.9503\n",
      "Epoch 00139: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.1533 - acc: 0.9503 - val_loss: 0.1436 - val_acc: 0.9578\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9498\n",
      "Epoch 00140: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1520 - acc: 0.9498 - val_loss: 0.1360 - val_acc: 0.9595\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9516\n",
      "Epoch 00141: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1516 - acc: 0.9516 - val_loss: 0.1419 - val_acc: 0.9595\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9503\n",
      "Epoch 00142: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1497 - acc: 0.9503 - val_loss: 0.1387 - val_acc: 0.9574\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9512\n",
      "Epoch 00143: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1513 - acc: 0.9512 - val_loss: 0.1423 - val_acc: 0.9574\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9529\n",
      "Epoch 00144: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1468 - acc: 0.9529 - val_loss: 0.1354 - val_acc: 0.9611\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1456 - acc: 0.9533\n",
      "Epoch 00145: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.1456 - acc: 0.9533 - val_loss: 0.1365 - val_acc: 0.9583\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1475 - acc: 0.9518\n",
      "Epoch 00146: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.1475 - acc: 0.9518 - val_loss: 0.1372 - val_acc: 0.9592\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1472 - acc: 0.9523\n",
      "Epoch 00147: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1471 - acc: 0.9523 - val_loss: 0.1362 - val_acc: 0.9609\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9516\n",
      "Epoch 00148: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1474 - acc: 0.9516 - val_loss: 0.1354 - val_acc: 0.9585\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1443 - acc: 0.9522\n",
      "Epoch 00149: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1443 - acc: 0.9522 - val_loss: 0.1375 - val_acc: 0.9578\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1458 - acc: 0.9517\n",
      "Epoch 00150: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1458 - acc: 0.9517 - val_loss: 0.1401 - val_acc: 0.9583\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9540\n",
      "Epoch 00151: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1369 - acc: 0.9540 - val_loss: 0.1429 - val_acc: 0.9562\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1443 - acc: 0.9533\n",
      "Epoch 00152: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.1443 - acc: 0.9533 - val_loss: 0.1382 - val_acc: 0.9590\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9561\n",
      "Epoch 00153: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1362 - acc: 0.9561 - val_loss: 0.1357 - val_acc: 0.9592\n",
      "Epoch 154/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9537\n",
      "Epoch 00154: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1394 - acc: 0.9537 - val_loss: 0.1333 - val_acc: 0.9590\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9556\n",
      "Epoch 00155: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1376 - acc: 0.9556 - val_loss: 0.1405 - val_acc: 0.9571\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9527\n",
      "Epoch 00156: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1436 - acc: 0.9527 - val_loss: 0.1539 - val_acc: 0.9574\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9548\n",
      "Epoch 00157: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1394 - acc: 0.9548 - val_loss: 0.1401 - val_acc: 0.9595\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9566\n",
      "Epoch 00158: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1326 - acc: 0.9566 - val_loss: 0.1399 - val_acc: 0.9588\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9558\n",
      "Epoch 00159: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1325 - acc: 0.9558 - val_loss: 0.1415 - val_acc: 0.9583\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1346 - acc: 0.9557\n",
      "Epoch 00160: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.1346 - acc: 0.9557 - val_loss: 0.1335 - val_acc: 0.9597\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9563\n",
      "Epoch 00161: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1329 - acc: 0.9563 - val_loss: 0.1393 - val_acc: 0.9569\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9561\n",
      "Epoch 00162: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1343 - acc: 0.9561 - val_loss: 0.1393 - val_acc: 0.9590\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9562\n",
      "Epoch 00163: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1335 - acc: 0.9562 - val_loss: 0.1508 - val_acc: 0.9571\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9570\n",
      "Epoch 00164: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1325 - acc: 0.9569 - val_loss: 0.1330 - val_acc: 0.9604\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9557\n",
      "Epoch 00165: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1324 - acc: 0.9557 - val_loss: 0.1411 - val_acc: 0.9590\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9568\n",
      "Epoch 00166: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.1304 - acc: 0.9568 - val_loss: 0.1367 - val_acc: 0.9590\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9571\n",
      "Epoch 00167: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1304 - acc: 0.9571 - val_loss: 0.1354 - val_acc: 0.9595\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9590\n",
      "Epoch 00168: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1257 - acc: 0.9591 - val_loss: 0.1439 - val_acc: 0.9602\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9571\n",
      "Epoch 00169: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1300 - acc: 0.9571 - val_loss: 0.1344 - val_acc: 0.9602\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1309 - acc: 0.9575\n",
      "Epoch 00170: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.1309 - acc: 0.9575 - val_loss: 0.1362 - val_acc: 0.9595\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9575\n",
      "Epoch 00171: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1254 - acc: 0.9575 - val_loss: 0.1477 - val_acc: 0.9574\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9573\n",
      "Epoch 00172: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1277 - acc: 0.9573 - val_loss: 0.1372 - val_acc: 0.9583\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9579\n",
      "Epoch 00173: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.1259 - acc: 0.9579 - val_loss: 0.1445 - val_acc: 0.9583\n",
      "Epoch 174/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1278 - acc: 0.9583\n",
      "Epoch 00174: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1278 - acc: 0.9583 - val_loss: 0.1410 - val_acc: 0.9595\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9596\n",
      "Epoch 00175: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1233 - acc: 0.9596 - val_loss: 0.1413 - val_acc: 0.9595\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9584\n",
      "Epoch 00176: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.1244 - acc: 0.9583 - val_loss: 0.1429 - val_acc: 0.9590\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9580\n",
      "Epoch 00177: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1265 - acc: 0.9580 - val_loss: 0.1526 - val_acc: 0.9562\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9589\n",
      "Epoch 00178: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1250 - acc: 0.9589 - val_loss: 0.1477 - val_acc: 0.9581\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9604\n",
      "Epoch 00179: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.1216 - acc: 0.9604 - val_loss: 0.1384 - val_acc: 0.9616\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9598\n",
      "Epoch 00180: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1194 - acc: 0.9598 - val_loss: 0.1390 - val_acc: 0.9606\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9593\n",
      "Epoch 00181: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.1214 - acc: 0.9593 - val_loss: 0.1331 - val_acc: 0.9606\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9601\n",
      "Epoch 00182: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.1211 - acc: 0.9601 - val_loss: 0.1336 - val_acc: 0.9599\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9602\n",
      "Epoch 00183: val_loss did not improve from 0.13248\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1168 - acc: 0.9602 - val_loss: 0.1392 - val_acc: 0.9592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9590\n",
      "Epoch 00184: val_loss improved from 0.13248 to 0.13187, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/184-0.1319.hdf5\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1230 - acc: 0.9590 - val_loss: 0.1319 - val_acc: 0.9620\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9612\n",
      "Epoch 00185: val_loss did not improve from 0.13187\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.1163 - acc: 0.9611 - val_loss: 0.1391 - val_acc: 0.9585\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9613\n",
      "Epoch 00186: val_loss did not improve from 0.13187\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1168 - acc: 0.9613 - val_loss: 0.1372 - val_acc: 0.9609\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9614\n",
      "Epoch 00187: val_loss did not improve from 0.13187\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1165 - acc: 0.9614 - val_loss: 0.1420 - val_acc: 0.9590\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9611\n",
      "Epoch 00188: val_loss improved from 0.13187 to 0.12984, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/188-0.1298.hdf5\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.1170 - acc: 0.9611 - val_loss: 0.1298 - val_acc: 0.9625\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9612\n",
      "Epoch 00189: val_loss did not improve from 0.12984\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.1166 - acc: 0.9612 - val_loss: 0.1449 - val_acc: 0.9606\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9616\n",
      "Epoch 00190: val_loss did not improve from 0.12984\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.1190 - acc: 0.9616 - val_loss: 0.1331 - val_acc: 0.9602\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9636\n",
      "Epoch 00191: val_loss did not improve from 0.12984\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.1121 - acc: 0.9636 - val_loss: 0.1379 - val_acc: 0.9606\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9612\n",
      "Epoch 00192: val_loss did not improve from 0.12984\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1168 - acc: 0.9612 - val_loss: 0.1479 - val_acc: 0.9583\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9628\n",
      "Epoch 00193: val_loss did not improve from 0.12984\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1123 - acc: 0.9627 - val_loss: 0.1398 - val_acc: 0.9627\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9618\n",
      "Epoch 00194: val_loss did not improve from 0.12984\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1139 - acc: 0.9618 - val_loss: 0.1391 - val_acc: 0.9602\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9610\n",
      "Epoch 00195: val_loss improved from 0.12984 to 0.12918, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv_checkpoint/195-0.1292.hdf5\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.1152 - acc: 0.9610 - val_loss: 0.1292 - val_acc: 0.9627\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9620\n",
      "Epoch 00196: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1113 - acc: 0.9620 - val_loss: 0.1337 - val_acc: 0.9634\n",
      "Epoch 197/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9637\n",
      "Epoch 00197: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1091 - acc: 0.9637 - val_loss: 0.1533 - val_acc: 0.9576\n",
      "Epoch 198/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9638\n",
      "Epoch 00198: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1075 - acc: 0.9638 - val_loss: 0.1372 - val_acc: 0.9616\n",
      "Epoch 199/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9640\n",
      "Epoch 00199: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 481us/sample - loss: 0.1097 - acc: 0.9641 - val_loss: 0.1384 - val_acc: 0.9623\n",
      "Epoch 200/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9625\n",
      "Epoch 00200: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1115 - acc: 0.9625 - val_loss: 0.1382 - val_acc: 0.9599\n",
      "Epoch 201/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9626\n",
      "Epoch 00201: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1129 - acc: 0.9626 - val_loss: 0.1410 - val_acc: 0.9588\n",
      "Epoch 202/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9631\n",
      "Epoch 00202: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1090 - acc: 0.9630 - val_loss: 0.1413 - val_acc: 0.9618\n",
      "Epoch 203/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9631\n",
      "Epoch 00203: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.1083 - acc: 0.9631 - val_loss: 0.1413 - val_acc: 0.9616\n",
      "Epoch 204/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9627\n",
      "Epoch 00204: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1107 - acc: 0.9627 - val_loss: 0.1331 - val_acc: 0.9609\n",
      "Epoch 205/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1094 - acc: 0.9636\n",
      "Epoch 00205: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 489us/sample - loss: 0.1095 - acc: 0.9636 - val_loss: 0.1423 - val_acc: 0.9623\n",
      "Epoch 206/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9646\n",
      "Epoch 00206: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1078 - acc: 0.9646 - val_loss: 0.1475 - val_acc: 0.9588\n",
      "Epoch 207/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9636\n",
      "Epoch 00207: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 487us/sample - loss: 0.1071 - acc: 0.9636 - val_loss: 0.1360 - val_acc: 0.9625\n",
      "Epoch 208/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9648\n",
      "Epoch 00208: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1065 - acc: 0.9648 - val_loss: 0.1402 - val_acc: 0.9609\n",
      "Epoch 209/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9641\n",
      "Epoch 00209: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.1030 - acc: 0.9641 - val_loss: 0.1400 - val_acc: 0.9604\n",
      "Epoch 210/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9652\n",
      "Epoch 00210: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 485us/sample - loss: 0.1023 - acc: 0.9652 - val_loss: 0.1419 - val_acc: 0.9599\n",
      "Epoch 211/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1047 - acc: 0.9644\n",
      "Epoch 00211: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 486us/sample - loss: 0.1047 - acc: 0.9644 - val_loss: 0.1352 - val_acc: 0.9613\n",
      "Epoch 212/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9654\n",
      "Epoch 00212: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 483us/sample - loss: 0.1040 - acc: 0.9654 - val_loss: 0.1372 - val_acc: 0.9620\n",
      "Epoch 213/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9639\n",
      "Epoch 00213: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1049 - acc: 0.9639 - val_loss: 0.1464 - val_acc: 0.9583\n",
      "Epoch 214/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9640\n",
      "Epoch 00214: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 0.1036 - acc: 0.9640 - val_loss: 0.1505 - val_acc: 0.9597\n",
      "Epoch 215/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9647\n",
      "Epoch 00215: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 480us/sample - loss: 0.1039 - acc: 0.9647 - val_loss: 0.1465 - val_acc: 0.9599\n",
      "Epoch 216/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9652\n",
      "Epoch 00216: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 484us/sample - loss: 0.1012 - acc: 0.9652 - val_loss: 0.1367 - val_acc: 0.9613\n",
      "Epoch 217/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9664\n",
      "Epoch 00217: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.1004 - acc: 0.9664 - val_loss: 0.1351 - val_acc: 0.9620\n",
      "Epoch 218/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9658\n",
      "Epoch 00218: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 488us/sample - loss: 0.0997 - acc: 0.9658 - val_loss: 0.1428 - val_acc: 0.9604\n",
      "Epoch 219/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9661\n",
      "Epoch 00219: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0996 - acc: 0.9661 - val_loss: 0.1347 - val_acc: 0.9625\n",
      "Epoch 220/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9668\n",
      "Epoch 00220: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0968 - acc: 0.9669 - val_loss: 0.1429 - val_acc: 0.9611\n",
      "Epoch 221/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9655\n",
      "Epoch 00221: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.1013 - acc: 0.9655 - val_loss: 0.1422 - val_acc: 0.9618\n",
      "Epoch 222/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9658\n",
      "Epoch 00222: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.1046 - acc: 0.9658 - val_loss: 0.1367 - val_acc: 0.9604\n",
      "Epoch 223/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9659\n",
      "Epoch 00223: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.1001 - acc: 0.9659 - val_loss: 0.1404 - val_acc: 0.9609\n",
      "Epoch 224/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9660\n",
      "Epoch 00224: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0976 - acc: 0.9660 - val_loss: 0.1367 - val_acc: 0.9620\n",
      "Epoch 225/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9682\n",
      "Epoch 00225: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0937 - acc: 0.9682 - val_loss: 0.1405 - val_acc: 0.9641\n",
      "Epoch 226/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9679\n",
      "Epoch 00226: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0961 - acc: 0.9679 - val_loss: 0.1432 - val_acc: 0.9618\n",
      "Epoch 227/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9672\n",
      "Epoch 00227: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0975 - acc: 0.9672 - val_loss: 0.1419 - val_acc: 0.9620\n",
      "Epoch 228/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9676\n",
      "Epoch 00228: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0967 - acc: 0.9676 - val_loss: 0.1405 - val_acc: 0.9595\n",
      "Epoch 229/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9677\n",
      "Epoch 00229: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0970 - acc: 0.9677 - val_loss: 0.1426 - val_acc: 0.9599\n",
      "Epoch 230/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9665\n",
      "Epoch 00230: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0967 - acc: 0.9666 - val_loss: 0.1419 - val_acc: 0.9632\n",
      "Epoch 231/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9664\n",
      "Epoch 00231: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.0959 - acc: 0.9664 - val_loss: 0.1346 - val_acc: 0.9632\n",
      "Epoch 232/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9687\n",
      "Epoch 00232: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 490us/sample - loss: 0.0918 - acc: 0.9687 - val_loss: 0.1437 - val_acc: 0.9606\n",
      "Epoch 233/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9669\n",
      "Epoch 00233: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0981 - acc: 0.9669 - val_loss: 0.1413 - val_acc: 0.9618\n",
      "Epoch 234/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9670\n",
      "Epoch 00234: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0967 - acc: 0.9670 - val_loss: 0.1393 - val_acc: 0.9609\n",
      "Epoch 235/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9679\n",
      "Epoch 00235: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0945 - acc: 0.9679 - val_loss: 0.1355 - val_acc: 0.9634\n",
      "Epoch 236/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9681\n",
      "Epoch 00236: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0912 - acc: 0.9681 - val_loss: 0.1430 - val_acc: 0.9625\n",
      "Epoch 237/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9674\n",
      "Epoch 00237: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0955 - acc: 0.9674 - val_loss: 0.1421 - val_acc: 0.9595\n",
      "Epoch 238/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9700\n",
      "Epoch 00238: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0890 - acc: 0.9700 - val_loss: 0.1483 - val_acc: 0.9597\n",
      "Epoch 239/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9685\n",
      "Epoch 00239: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0936 - acc: 0.9685 - val_loss: 0.1417 - val_acc: 0.9602\n",
      "Epoch 240/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9676\n",
      "Epoch 00240: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0956 - acc: 0.9676 - val_loss: 0.1447 - val_acc: 0.9625\n",
      "Epoch 241/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9683\n",
      "Epoch 00241: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0914 - acc: 0.9683 - val_loss: 0.1351 - val_acc: 0.9620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9690\n",
      "Epoch 00242: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0945 - acc: 0.9690 - val_loss: 0.1420 - val_acc: 0.9609\n",
      "Epoch 243/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9706\n",
      "Epoch 00243: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0885 - acc: 0.9706 - val_loss: 0.1398 - val_acc: 0.9639\n",
      "Epoch 244/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9698\n",
      "Epoch 00244: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0910 - acc: 0.9698 - val_loss: 0.1505 - val_acc: 0.9634\n",
      "Epoch 245/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9701\n",
      "Epoch 00245: val_loss did not improve from 0.12918\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0887 - acc: 0.9701 - val_loss: 0.1354 - val_acc: 0.9641\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 311us/sample - loss: 0.1930 - acc: 0.9487\n",
      "Loss: 0.1930468858464361 Accuracy: 0.948702\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5925 - acc: 0.1475\n",
      "Epoch 00001: val_loss improved from inf to 2.20051, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/001-2.2005.hdf5\n",
      "36805/36805 [==============================] - 23s 634us/sample - loss: 2.5924 - acc: 0.1475 - val_loss: 2.2005 - val_acc: 0.3287\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9276 - acc: 0.3776\n",
      "Epoch 00002: val_loss improved from 2.20051 to 1.30297, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/002-1.3030.hdf5\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 1.9275 - acc: 0.3776 - val_loss: 1.3030 - val_acc: 0.6077\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3941 - acc: 0.5423\n",
      "Epoch 00003: val_loss improved from 1.30297 to 1.00140, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/003-1.0014.hdf5\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 1.3941 - acc: 0.5423 - val_loss: 1.0014 - val_acc: 0.6958\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1577 - acc: 0.6242\n",
      "Epoch 00004: val_loss improved from 1.00140 to 0.85292, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/004-0.8529.hdf5\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 1.1577 - acc: 0.6242 - val_loss: 0.8529 - val_acc: 0.7396\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0321 - acc: 0.6634\n",
      "Epoch 00005: val_loss improved from 0.85292 to 0.75169, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/005-0.7517.hdf5\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 1.0322 - acc: 0.6634 - val_loss: 0.7517 - val_acc: 0.7619\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9302 - acc: 0.6987\n",
      "Epoch 00006: val_loss improved from 0.75169 to 0.67519, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/006-0.6752.hdf5\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.9302 - acc: 0.6987 - val_loss: 0.6752 - val_acc: 0.7969\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8601 - acc: 0.7220\n",
      "Epoch 00007: val_loss improved from 0.67519 to 0.62128, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/007-0.6213.hdf5\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.8600 - acc: 0.7220 - val_loss: 0.6213 - val_acc: 0.8050\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7949 - acc: 0.7457\n",
      "Epoch 00008: val_loss improved from 0.62128 to 0.57801, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/008-0.5780.hdf5\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.7952 - acc: 0.7457 - val_loss: 0.5780 - val_acc: 0.8251\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7325 - acc: 0.7673\n",
      "Epoch 00009: val_loss improved from 0.57801 to 0.51453, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/009-0.5145.hdf5\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.7326 - acc: 0.7673 - val_loss: 0.5145 - val_acc: 0.8505\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6886 - acc: 0.7823\n",
      "Epoch 00010: val_loss improved from 0.51453 to 0.50235, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/010-0.5024.hdf5\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.6888 - acc: 0.7823 - val_loss: 0.5024 - val_acc: 0.8516\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6446 - acc: 0.7948\n",
      "Epoch 00011: val_loss improved from 0.50235 to 0.46650, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/011-0.4665.hdf5\n",
      "36805/36805 [==============================] - 19s 512us/sample - loss: 0.6446 - acc: 0.7948 - val_loss: 0.4665 - val_acc: 0.8586\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6039 - acc: 0.8087\n",
      "Epoch 00012: val_loss improved from 0.46650 to 0.40701, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/012-0.4070.hdf5\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.6039 - acc: 0.8087 - val_loss: 0.4070 - val_acc: 0.8845\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5580 - acc: 0.8239\n",
      "Epoch 00013: val_loss improved from 0.40701 to 0.37546, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/013-0.3755.hdf5\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.5580 - acc: 0.8240 - val_loss: 0.3755 - val_acc: 0.8882\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5368 - acc: 0.8293\n",
      "Epoch 00014: val_loss improved from 0.37546 to 0.36661, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/014-0.3666.hdf5\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.5368 - acc: 0.8293 - val_loss: 0.3666 - val_acc: 0.8933\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5070 - acc: 0.8417\n",
      "Epoch 00015: val_loss improved from 0.36661 to 0.33926, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/015-0.3393.hdf5\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.5070 - acc: 0.8417 - val_loss: 0.3393 - val_acc: 0.9026\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4837 - acc: 0.8499\n",
      "Epoch 00016: val_loss improved from 0.33926 to 0.32399, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/016-0.3240.hdf5\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.4838 - acc: 0.8499 - val_loss: 0.3240 - val_acc: 0.9061\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4664 - acc: 0.8546\n",
      "Epoch 00017: val_loss improved from 0.32399 to 0.31928, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/017-0.3193.hdf5\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.4664 - acc: 0.8546 - val_loss: 0.3193 - val_acc: 0.9057\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4460 - acc: 0.8594\n",
      "Epoch 00018: val_loss improved from 0.31928 to 0.29357, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/018-0.2936.hdf5\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.4460 - acc: 0.8594 - val_loss: 0.2936 - val_acc: 0.9145\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4305 - acc: 0.8651\n",
      "Epoch 00019: val_loss improved from 0.29357 to 0.28111, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/019-0.2811.hdf5\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.4305 - acc: 0.8651 - val_loss: 0.2811 - val_acc: 0.9159\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4132 - acc: 0.8706\n",
      "Epoch 00020: val_loss improved from 0.28111 to 0.27614, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/020-0.2761.hdf5\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.4132 - acc: 0.8706 - val_loss: 0.2761 - val_acc: 0.9168\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3977 - acc: 0.8749\n",
      "Epoch 00021: val_loss improved from 0.27614 to 0.26329, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/021-0.2633.hdf5\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.3977 - acc: 0.8749 - val_loss: 0.2633 - val_acc: 0.9231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3793 - acc: 0.8815\n",
      "Epoch 00022: val_loss improved from 0.26329 to 0.25572, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/022-0.2557.hdf5\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.3793 - acc: 0.8816 - val_loss: 0.2557 - val_acc: 0.9238\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3649 - acc: 0.8851\n",
      "Epoch 00023: val_loss improved from 0.25572 to 0.25233, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/023-0.2523.hdf5\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.3648 - acc: 0.8851 - val_loss: 0.2523 - val_acc: 0.9220\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3520 - acc: 0.8902\n",
      "Epoch 00024: val_loss improved from 0.25233 to 0.23129, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/024-0.2313.hdf5\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.3519 - acc: 0.8903 - val_loss: 0.2313 - val_acc: 0.9334\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3413 - acc: 0.8925\n",
      "Epoch 00025: val_loss improved from 0.23129 to 0.22602, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/025-0.2260.hdf5\n",
      "36805/36805 [==============================] - 19s 522us/sample - loss: 0.3413 - acc: 0.8925 - val_loss: 0.2260 - val_acc: 0.9311\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3333 - acc: 0.8941\n",
      "Epoch 00026: val_loss improved from 0.22602 to 0.22231, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/026-0.2223.hdf5\n",
      "36805/36805 [==============================] - 19s 524us/sample - loss: 0.3333 - acc: 0.8941 - val_loss: 0.2223 - val_acc: 0.9327\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3272 - acc: 0.8982\n",
      "Epoch 00027: val_loss did not improve from 0.22231\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.3271 - acc: 0.8982 - val_loss: 0.2289 - val_acc: 0.9308\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3130 - acc: 0.9030\n",
      "Epoch 00028: val_loss improved from 0.22231 to 0.21101, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/028-0.2110.hdf5\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.3130 - acc: 0.9030 - val_loss: 0.2110 - val_acc: 0.9352\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3032 - acc: 0.9046\n",
      "Epoch 00029: val_loss improved from 0.21101 to 0.20151, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/029-0.2015.hdf5\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.3032 - acc: 0.9046 - val_loss: 0.2015 - val_acc: 0.9394\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2957 - acc: 0.9058\n",
      "Epoch 00030: val_loss did not improve from 0.20151\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.2957 - acc: 0.9058 - val_loss: 0.2112 - val_acc: 0.9348\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2903 - acc: 0.9091\n",
      "Epoch 00031: val_loss improved from 0.20151 to 0.19728, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/031-0.1973.hdf5\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.2903 - acc: 0.9091 - val_loss: 0.1973 - val_acc: 0.9401\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2817 - acc: 0.9114\n",
      "Epoch 00032: val_loss did not improve from 0.19728\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.2817 - acc: 0.9113 - val_loss: 0.2176 - val_acc: 0.9301\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2742 - acc: 0.9130\n",
      "Epoch 00033: val_loss did not improve from 0.19728\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.2742 - acc: 0.9130 - val_loss: 0.2097 - val_acc: 0.9327\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2681 - acc: 0.9170\n",
      "Epoch 00034: val_loss improved from 0.19728 to 0.19169, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/034-0.1917.hdf5\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.2681 - acc: 0.9170 - val_loss: 0.1917 - val_acc: 0.9413\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2553 - acc: 0.9201\n",
      "Epoch 00035: val_loss improved from 0.19169 to 0.19056, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/035-0.1906.hdf5\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.2553 - acc: 0.9201 - val_loss: 0.1906 - val_acc: 0.9420\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2568 - acc: 0.9196\n",
      "Epoch 00036: val_loss improved from 0.19056 to 0.18910, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/036-0.1891.hdf5\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.2568 - acc: 0.9195 - val_loss: 0.1891 - val_acc: 0.9422\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2515 - acc: 0.9205\n",
      "Epoch 00037: val_loss did not improve from 0.18910\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.2516 - acc: 0.9205 - val_loss: 0.1907 - val_acc: 0.9408\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2490 - acc: 0.9215\n",
      "Epoch 00038: val_loss improved from 0.18910 to 0.18757, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/038-0.1876.hdf5\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 0.2489 - acc: 0.9215 - val_loss: 0.1876 - val_acc: 0.9427\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2398 - acc: 0.9258\n",
      "Epoch 00039: val_loss improved from 0.18757 to 0.18255, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/039-0.1825.hdf5\n",
      "36805/36805 [==============================] - 19s 521us/sample - loss: 0.2399 - acc: 0.9257 - val_loss: 0.1825 - val_acc: 0.9446\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2361 - acc: 0.9246\n",
      "Epoch 00040: val_loss improved from 0.18255 to 0.17352, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/040-0.1735.hdf5\n",
      "36805/36805 [==============================] - 19s 521us/sample - loss: 0.2361 - acc: 0.9246 - val_loss: 0.1735 - val_acc: 0.9467\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2293 - acc: 0.9286\n",
      "Epoch 00041: val_loss did not improve from 0.17352\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.2293 - acc: 0.9286 - val_loss: 0.1866 - val_acc: 0.9446\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2258 - acc: 0.9285\n",
      "Epoch 00042: val_loss did not improve from 0.17352\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.2258 - acc: 0.9284 - val_loss: 0.1794 - val_acc: 0.9432\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2240 - acc: 0.9290\n",
      "Epoch 00043: val_loss did not improve from 0.17352\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.2240 - acc: 0.9290 - val_loss: 0.1809 - val_acc: 0.9467\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2147 - acc: 0.9319\n",
      "Epoch 00044: val_loss improved from 0.17352 to 0.17090, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/044-0.1709.hdf5\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.2147 - acc: 0.9319 - val_loss: 0.1709 - val_acc: 0.9474\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2146 - acc: 0.9310\n",
      "Epoch 00045: val_loss improved from 0.17090 to 0.17090, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/045-0.1709.hdf5\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.2146 - acc: 0.9310 - val_loss: 0.1709 - val_acc: 0.9471\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2072 - acc: 0.9347\n",
      "Epoch 00046: val_loss improved from 0.17090 to 0.16895, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/046-0.1690.hdf5\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.2072 - acc: 0.9347 - val_loss: 0.1690 - val_acc: 0.9471\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2051 - acc: 0.9355\n",
      "Epoch 00047: val_loss did not improve from 0.16895\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.2052 - acc: 0.9354 - val_loss: 0.1834 - val_acc: 0.9453\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2048 - acc: 0.9340\n",
      "Epoch 00048: val_loss did not improve from 0.16895\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.2047 - acc: 0.9341 - val_loss: 0.1761 - val_acc: 0.9448\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1983 - acc: 0.9365\n",
      "Epoch 00049: val_loss did not improve from 0.16895\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.1983 - acc: 0.9366 - val_loss: 0.1875 - val_acc: 0.9474\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1936 - acc: 0.9390\n",
      "Epoch 00050: val_loss improved from 0.16895 to 0.16536, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/050-0.1654.hdf5\n",
      "36805/36805 [==============================] - 19s 523us/sample - loss: 0.1936 - acc: 0.9391 - val_loss: 0.1654 - val_acc: 0.9504\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1884 - acc: 0.9395\n",
      "Epoch 00051: val_loss improved from 0.16536 to 0.15929, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/051-0.1593.hdf5\n",
      "36805/36805 [==============================] - 19s 522us/sample - loss: 0.1884 - acc: 0.9395 - val_loss: 0.1593 - val_acc: 0.9520\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1919 - acc: 0.9397\n",
      "Epoch 00052: val_loss did not improve from 0.15929\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.1919 - acc: 0.9397 - val_loss: 0.1631 - val_acc: 0.9481\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.9406\n",
      "Epoch 00053: val_loss did not improve from 0.15929\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.1855 - acc: 0.9406 - val_loss: 0.1777 - val_acc: 0.9448\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1844 - acc: 0.9414\n",
      "Epoch 00054: val_loss did not improve from 0.15929\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.1845 - acc: 0.9413 - val_loss: 0.1666 - val_acc: 0.9490\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9416\n",
      "Epoch 00055: val_loss did not improve from 0.15929\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.1829 - acc: 0.9416 - val_loss: 0.1597 - val_acc: 0.9513\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1764 - acc: 0.9431\n",
      "Epoch 00056: val_loss did not improve from 0.15929\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.1764 - acc: 0.9431 - val_loss: 0.1697 - val_acc: 0.9506\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9440\n",
      "Epoch 00057: val_loss improved from 0.15929 to 0.15822, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/057-0.1582.hdf5\n",
      "36805/36805 [==============================] - 19s 520us/sample - loss: 0.1739 - acc: 0.9441 - val_loss: 0.1582 - val_acc: 0.9534\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1696 - acc: 0.9457\n",
      "Epoch 00058: val_loss did not improve from 0.15822\n",
      "36805/36805 [==============================] - 19s 524us/sample - loss: 0.1696 - acc: 0.9457 - val_loss: 0.1653 - val_acc: 0.9513\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9453\n",
      "Epoch 00059: val_loss did not improve from 0.15822\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.1694 - acc: 0.9453 - val_loss: 0.1664 - val_acc: 0.9492\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1665 - acc: 0.9459\n",
      "Epoch 00060: val_loss improved from 0.15822 to 0.15275, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/060-0.1527.hdf5\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.1665 - acc: 0.9459 - val_loss: 0.1527 - val_acc: 0.9539\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1611 - acc: 0.9481\n",
      "Epoch 00061: val_loss did not improve from 0.15275\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.1611 - acc: 0.9481 - val_loss: 0.1611 - val_acc: 0.9518\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1610 - acc: 0.9475\n",
      "Epoch 00062: val_loss did not improve from 0.15275\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.1610 - acc: 0.9475 - val_loss: 0.1633 - val_acc: 0.9529\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1575 - acc: 0.9483\n",
      "Epoch 00063: val_loss improved from 0.15275 to 0.15230, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/063-0.1523.hdf5\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.1575 - acc: 0.9483 - val_loss: 0.1523 - val_acc: 0.9511\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1563 - acc: 0.9498\n",
      "Epoch 00064: val_loss did not improve from 0.15230\n",
      "36805/36805 [==============================] - 19s 508us/sample - loss: 0.1563 - acc: 0.9498 - val_loss: 0.1597 - val_acc: 0.9502\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1544 - acc: 0.9502\n",
      "Epoch 00065: val_loss did not improve from 0.15230\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.1543 - acc: 0.9502 - val_loss: 0.1529 - val_acc: 0.9550\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1482 - acc: 0.9507\n",
      "Epoch 00066: val_loss improved from 0.15230 to 0.14788, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/066-0.1479.hdf5\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.1483 - acc: 0.9507 - val_loss: 0.1479 - val_acc: 0.9553\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9506\n",
      "Epoch 00067: val_loss did not improve from 0.14788\n",
      "36805/36805 [==============================] - 19s 512us/sample - loss: 0.1516 - acc: 0.9506 - val_loss: 0.1766 - val_acc: 0.9481\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9522\n",
      "Epoch 00068: val_loss did not improve from 0.14788\n",
      "36805/36805 [==============================] - 19s 512us/sample - loss: 0.1468 - acc: 0.9522 - val_loss: 0.1667 - val_acc: 0.9518\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9504\n",
      "Epoch 00069: val_loss did not improve from 0.14788\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.1502 - acc: 0.9504 - val_loss: 0.1518 - val_acc: 0.9548\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1453 - acc: 0.9530\n",
      "Epoch 00070: val_loss did not improve from 0.14788\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.1453 - acc: 0.9530 - val_loss: 0.1551 - val_acc: 0.9539\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9549\n",
      "Epoch 00071: val_loss did not improve from 0.14788\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.1418 - acc: 0.9549 - val_loss: 0.1522 - val_acc: 0.9525\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9550\n",
      "Epoch 00072: val_loss did not improve from 0.14788\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.1394 - acc: 0.9550 - val_loss: 0.1634 - val_acc: 0.9539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9551\n",
      "Epoch 00073: val_loss did not improve from 0.14788\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.1373 - acc: 0.9551 - val_loss: 0.1594 - val_acc: 0.9555\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1327 - acc: 0.9557\n",
      "Epoch 00074: val_loss did not improve from 0.14788\n",
      "36805/36805 [==============================] - 20s 537us/sample - loss: 0.1327 - acc: 0.9557 - val_loss: 0.1532 - val_acc: 0.9543\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9544\n",
      "Epoch 00075: val_loss did not improve from 0.14788\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.1363 - acc: 0.9544 - val_loss: 0.1549 - val_acc: 0.9546\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9564\n",
      "Epoch 00076: val_loss did not improve from 0.14788\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.1319 - acc: 0.9564 - val_loss: 0.1601 - val_acc: 0.9513\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9569\n",
      "Epoch 00077: val_loss did not improve from 0.14788\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.1319 - acc: 0.9569 - val_loss: 0.1634 - val_acc: 0.9555\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9579\n",
      "Epoch 00078: val_loss did not improve from 0.14788\n",
      "36805/36805 [==============================] - 19s 510us/sample - loss: 0.1298 - acc: 0.9579 - val_loss: 0.1729 - val_acc: 0.9522\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9567\n",
      "Epoch 00079: val_loss improved from 0.14788 to 0.14619, saving model to model/checkpoint/1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv_checkpoint/079-0.1462.hdf5\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.1281 - acc: 0.9567 - val_loss: 0.1462 - val_acc: 0.9571\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9593\n",
      "Epoch 00080: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 512us/sample - loss: 0.1239 - acc: 0.9593 - val_loss: 0.1476 - val_acc: 0.9557\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9584\n",
      "Epoch 00081: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 516us/sample - loss: 0.1256 - acc: 0.9583 - val_loss: 0.1663 - val_acc: 0.9525\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9595\n",
      "Epoch 00082: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.1202 - acc: 0.9595 - val_loss: 0.1615 - val_acc: 0.9555\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9603\n",
      "Epoch 00083: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 517us/sample - loss: 0.1207 - acc: 0.9603 - val_loss: 0.1527 - val_acc: 0.9562\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9596\n",
      "Epoch 00084: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 519us/sample - loss: 0.1203 - acc: 0.9596 - val_loss: 0.1601 - val_acc: 0.9557\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9617\n",
      "Epoch 00085: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.1164 - acc: 0.9616 - val_loss: 0.1691 - val_acc: 0.9522\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9601\n",
      "Epoch 00086: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 512us/sample - loss: 0.1183 - acc: 0.9601 - val_loss: 0.1562 - val_acc: 0.9553\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9630\n",
      "Epoch 00087: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 508us/sample - loss: 0.1141 - acc: 0.9630 - val_loss: 0.1548 - val_acc: 0.9571\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9630\n",
      "Epoch 00088: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 509us/sample - loss: 0.1124 - acc: 0.9630 - val_loss: 0.1539 - val_acc: 0.9581\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9611\n",
      "Epoch 00089: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 508us/sample - loss: 0.1159 - acc: 0.9611 - val_loss: 0.1520 - val_acc: 0.9555\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9635\n",
      "Epoch 00090: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 510us/sample - loss: 0.1108 - acc: 0.9635 - val_loss: 0.1541 - val_acc: 0.9574\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9652\n",
      "Epoch 00091: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.1051 - acc: 0.9652 - val_loss: 0.1660 - val_acc: 0.9548\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9626\n",
      "Epoch 00092: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 510us/sample - loss: 0.1102 - acc: 0.9626 - val_loss: 0.1599 - val_acc: 0.9564\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9644\n",
      "Epoch 00093: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.1043 - acc: 0.9644 - val_loss: 0.1506 - val_acc: 0.9564\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9651\n",
      "Epoch 00094: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 510us/sample - loss: 0.1050 - acc: 0.9651 - val_loss: 0.1482 - val_acc: 0.9599\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9655\n",
      "Epoch 00095: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 18s 502us/sample - loss: 0.1038 - acc: 0.9655 - val_loss: 0.1551 - val_acc: 0.9578\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9652\n",
      "Epoch 00096: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 509us/sample - loss: 0.1035 - acc: 0.9652 - val_loss: 0.1618 - val_acc: 0.9564\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9654\n",
      "Epoch 00097: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 505us/sample - loss: 0.1018 - acc: 0.9654 - val_loss: 0.1523 - val_acc: 0.9583\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9661\n",
      "Epoch 00098: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.1005 - acc: 0.9660 - val_loss: 0.1644 - val_acc: 0.9529\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9647\n",
      "Epoch 00099: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 507us/sample - loss: 0.1019 - acc: 0.9647 - val_loss: 0.1538 - val_acc: 0.9576\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9677\n",
      "Epoch 00100: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 510us/sample - loss: 0.0976 - acc: 0.9677 - val_loss: 0.1493 - val_acc: 0.9576\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9670\n",
      "Epoch 00101: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 508us/sample - loss: 0.0979 - acc: 0.9670 - val_loss: 0.1636 - val_acc: 0.9571\n",
      "Epoch 102/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9675\n",
      "Epoch 00102: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 504us/sample - loss: 0.0967 - acc: 0.9675 - val_loss: 0.1644 - val_acc: 0.9527\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9672\n",
      "Epoch 00103: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 507us/sample - loss: 0.0957 - acc: 0.9672 - val_loss: 0.1513 - val_acc: 0.9592\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9694\n",
      "Epoch 00104: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 506us/sample - loss: 0.0901 - acc: 0.9694 - val_loss: 0.1554 - val_acc: 0.9574\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9676\n",
      "Epoch 00105: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 506us/sample - loss: 0.0956 - acc: 0.9676 - val_loss: 0.1576 - val_acc: 0.9571\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9684\n",
      "Epoch 00106: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 507us/sample - loss: 0.0927 - acc: 0.9684 - val_loss: 0.1531 - val_acc: 0.9592\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9693\n",
      "Epoch 00107: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 512us/sample - loss: 0.0910 - acc: 0.9693 - val_loss: 0.1772 - val_acc: 0.9555\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9701\n",
      "Epoch 00108: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 506us/sample - loss: 0.0888 - acc: 0.9700 - val_loss: 0.1602 - val_acc: 0.9592\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9696\n",
      "Epoch 00109: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.0908 - acc: 0.9697 - val_loss: 0.1617 - val_acc: 0.9585\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9694\n",
      "Epoch 00110: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 510us/sample - loss: 0.0887 - acc: 0.9694 - val_loss: 0.1771 - val_acc: 0.9539\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9687\n",
      "Epoch 00111: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 506us/sample - loss: 0.0920 - acc: 0.9687 - val_loss: 0.1474 - val_acc: 0.9578\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9715\n",
      "Epoch 00112: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.0847 - acc: 0.9715 - val_loss: 0.1605 - val_acc: 0.9578\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9706\n",
      "Epoch 00113: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 504us/sample - loss: 0.0849 - acc: 0.9706 - val_loss: 0.1793 - val_acc: 0.9527\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9720\n",
      "Epoch 00114: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 506us/sample - loss: 0.0825 - acc: 0.9720 - val_loss: 0.1574 - val_acc: 0.9576\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9719\n",
      "Epoch 00115: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 508us/sample - loss: 0.0820 - acc: 0.9719 - val_loss: 0.1529 - val_acc: 0.9595\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9717\n",
      "Epoch 00116: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 508us/sample - loss: 0.0823 - acc: 0.9717 - val_loss: 0.1649 - val_acc: 0.9581\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9727\n",
      "Epoch 00117: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 508us/sample - loss: 0.0805 - acc: 0.9727 - val_loss: 0.1745 - val_acc: 0.9581\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9724\n",
      "Epoch 00118: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 509us/sample - loss: 0.0801 - acc: 0.9724 - val_loss: 0.1771 - val_acc: 0.9555\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9726\n",
      "Epoch 00119: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.0792 - acc: 0.9726 - val_loss: 0.1590 - val_acc: 0.9602\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9726\n",
      "Epoch 00120: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 508us/sample - loss: 0.0797 - acc: 0.9726 - val_loss: 0.1669 - val_acc: 0.9613\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9725\n",
      "Epoch 00121: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.0793 - acc: 0.9725 - val_loss: 0.1795 - val_acc: 0.9581\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9727\n",
      "Epoch 00122: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.0765 - acc: 0.9727 - val_loss: 0.1718 - val_acc: 0.9569\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9741\n",
      "Epoch 00123: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.0757 - acc: 0.9741 - val_loss: 0.1634 - val_acc: 0.9588\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9739\n",
      "Epoch 00124: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 509us/sample - loss: 0.0767 - acc: 0.9739 - val_loss: 0.1673 - val_acc: 0.9583\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9752\n",
      "Epoch 00125: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 506us/sample - loss: 0.0711 - acc: 0.9752 - val_loss: 0.1554 - val_acc: 0.9585\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9732\n",
      "Epoch 00126: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 507us/sample - loss: 0.0758 - acc: 0.9732 - val_loss: 0.1688 - val_acc: 0.9599\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9749\n",
      "Epoch 00127: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.0742 - acc: 0.9749 - val_loss: 0.1617 - val_acc: 0.9606\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9758\n",
      "Epoch 00128: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.0704 - acc: 0.9758 - val_loss: 0.1668 - val_acc: 0.9590\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9760\n",
      "Epoch 00129: val_loss did not improve from 0.14619\n",
      "36805/36805 [==============================] - 19s 508us/sample - loss: 0.0713 - acc: 0.9760 - val_loss: 0.1616 - val_acc: 0.9620\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 339us/sample - loss: 0.2102 - acc: 0.9344\n",
      "Loss: 0.21017240282778676 Accuracy: 0.93437177\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_multi_3_GAP_ch_32_DO'\n",
    "\n",
    "for i in range(3, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_cnn(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 32)    192         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 32)    0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 32)     0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 32)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 32)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 32)     0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 32)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 32)           0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 32)           0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 32)           0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 96)           0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_average_pooling1d_19[0][0]\n",
      "                                                                 global_average_pooling1d_20[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 96)           0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           1552        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,048\n",
      "Trainable params: 12,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 1s 300us/sample - loss: 0.9031 - acc: 0.7360\n",
      "Loss: 0.9030666095321671 Accuracy: 0.7360332\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 16000, 32)    192         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16000, 32)    0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 5333, 32)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5333, 32)     0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1777, 32)     0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1777, 32)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 592, 32)      0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 592, 32)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 197, 32)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 32)           0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 32)           0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 32)           0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 96)           0           global_average_pooling1d_21[0][0]\n",
      "                                                                 global_average_pooling1d_22[0][0]\n",
      "                                                                 global_average_pooling1d_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 96)           0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           1552        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,200\n",
      "Trainable params: 17,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 314us/sample - loss: 0.6589 - acc: 0.8064\n",
      "Loss: 0.6589304419445224 Accuracy: 0.8064382\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 16000, 32)    192         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16000, 32)    0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 5333, 32)     0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5333, 32)     0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1777, 32)     0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1777, 32)     0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 592, 32)      0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 592, 32)      0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 197, 32)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 197, 64)      0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 65, 64)       0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_24 (Gl (None, 32)           0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (Gl (None, 32)           0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_26 (Gl (None, 64)           0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 128)          0           global_average_pooling1d_24[0][0]\n",
      "                                                                 global_average_pooling1d_25[0][0]\n",
      "                                                                 global_average_pooling1d_26[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           2064        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,016\n",
      "Trainable params: 28,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 1s 310us/sample - loss: 0.3302 - acc: 0.9070\n",
      "Loss: 0.3301833349101145 Accuracy: 0.90695745\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 16000, 32)    192         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16000, 32)    0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 5333, 32)     0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5333, 32)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1777, 32)     0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1777, 32)     0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 592, 32)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 592, 32)      0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 197, 32)      0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 197, 64)      0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 65, 64)       0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 65, 64)       0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 21, 64)       0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_27 (Gl (None, 32)           0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_28 (Gl (None, 64)           0           max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_29 (Gl (None, 64)           0           max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 160)          0           global_average_pooling1d_27[0][0]\n",
      "                                                                 global_average_pooling1d_28[0][0]\n",
      "                                                                 global_average_pooling1d_29[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 160)          0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           2576        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 49,072\n",
      "Trainable params: 49,072\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 338us/sample - loss: 0.2143 - acc: 0.9348\n",
      "Loss: 0.2142969814663983 Accuracy: 0.9347871\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 16000, 32)    192         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16000, 32)    0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 5333, 32)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5333, 32)     0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 1777, 32)     0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1777, 32)     0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 592, 32)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 592, 32)      0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 197, 32)      0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 197, 64)      0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 65, 64)       0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 65, 64)       0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 21, 64)       0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 21, 64)       0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 7, 64)        0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_30 (Gl (None, 64)           0           max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_31 (Gl (None, 64)           0           max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_32 (Gl (None, 64)           0           max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 192)          0           global_average_pooling1d_30[0][0]\n",
      "                                                                 global_average_pooling1d_31[0][0]\n",
      "                                                                 global_average_pooling1d_32[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 192)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           3088        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 70,128\n",
      "Trainable params: 70,128\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 356us/sample - loss: 0.1930 - acc: 0.9487\n",
      "Loss: 0.1930468858464361 Accuracy: 0.948702\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 16000, 32)    192         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16000, 32)    0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 5333, 32)     0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5333, 32)     0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 1777, 32)     0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1777, 32)     0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 592, 32)      0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 592, 32)      0           conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 197, 32)      0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 197, 64)      0           conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 65, 64)       0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 65, 64)       0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 21, 64)       0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 21, 64)       0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 7, 64)        0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 7, 64)        20544       max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 64)        0           conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 2, 64)        0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_33 (Gl (None, 64)           0           max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_34 (Gl (None, 64)           0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_35 (Gl (None, 64)           0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 192)          0           global_average_pooling1d_33[0][0]\n",
      "                                                                 global_average_pooling1d_34[0][0]\n",
      "                                                                 global_average_pooling1d_35[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 192)          0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           3088        dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 90,672\n",
      "Trainable params: 90,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 348us/sample - loss: 0.2102 - acc: 0.9344\n",
      "Loss: 0.21017240282778676 Accuracy: 0.93437177\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_multi_3_GAP_ch_32_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 9):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, 16000, 32)    192         input_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 16000, 32)    0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling1D) (None, 5333, 32)     0           activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 5333, 32)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling1D) (None, 1777, 32)     0           activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 1777, 32)     0           conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling1D) (None, 592, 32)      0           activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_18 (Gl (None, 32)           0           max_pooling1d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_19 (Gl (None, 32)           0           max_pooling1d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_20 (Gl (None, 32)           0           max_pooling1d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 96)           0           global_average_pooling1d_18[0][0]\n",
      "                                                                 global_average_pooling1d_19[0][0]\n",
      "                                                                 global_average_pooling1d_20[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 96)           0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16)           1552        dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 12,048\n",
      "Trainable params: 12,048\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 358us/sample - loss: 0.9058 - acc: 0.7362\n",
      "Loss: 0.9058280536690234 Accuracy: 0.7362409\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, 16000, 32)    192         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 16000, 32)    0           conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling1D) (None, 5333, 32)     0           activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 5333, 32)     0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling1D) (None, 1777, 32)     0           activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 1777, 32)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling1D) (None, 592, 32)      0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 592, 32)      0           conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling1D) (None, 197, 32)      0           activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_21 (Gl (None, 32)           0           max_pooling1d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_22 (Gl (None, 32)           0           max_pooling1d_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_23 (Gl (None, 32)           0           max_pooling1d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 96)           0           global_average_pooling1d_21[0][0]\n",
      "                                                                 global_average_pooling1d_22[0][0]\n",
      "                                                                 global_average_pooling1d_23[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 96)           0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16)           1552        dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 17,200\n",
      "Trainable params: 17,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 354us/sample - loss: 0.6640 - acc: 0.8027\n",
      "Loss: 0.663954120954868 Accuracy: 0.8026999\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, 16000, 32)    192         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 16000, 32)    0           conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling1D) (None, 5333, 32)     0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_40[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 5333, 32)     0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling1D) (None, 1777, 32)     0           activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 1777, 32)     0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling1D) (None, 592, 32)      0           activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 592, 32)      0           conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling1D) (None, 197, 32)      0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 197, 64)      0           conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling1D) (None, 65, 64)       0           activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_24 (Gl (None, 32)           0           max_pooling1d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_25 (Gl (None, 32)           0           max_pooling1d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_26 (Gl (None, 64)           0           max_pooling1d_44[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 128)          0           global_average_pooling1d_24[0][0]\n",
      "                                                                 global_average_pooling1d_25[0][0]\n",
      "                                                                 global_average_pooling1d_26[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 128)          0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 16)           2064        dropout_8[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 28,016\n",
      "Trainable params: 28,016\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 365us/sample - loss: 0.3385 - acc: 0.9038\n",
      "Loss: 0.33852789064062716 Accuracy: 0.90384215\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_10 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, 16000, 32)    192         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 16000, 32)    0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling1D) (None, 5333, 32)     0           activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_45[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 5333, 32)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling1D) (None, 1777, 32)     0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_46[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 1777, 32)     0           conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling1D) (None, 592, 32)      0           activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_47[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 592, 32)      0           conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling1D) (None, 197, 32)      0           activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 197, 64)      0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling1D) (None, 65, 64)       0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 65, 64)       0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling1D) (None, 21, 64)       0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_27 (Gl (None, 32)           0           max_pooling1d_48[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_28 (Gl (None, 64)           0           max_pooling1d_49[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_29 (Gl (None, 64)           0           max_pooling1d_50[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 160)          0           global_average_pooling1d_27[0][0]\n",
      "                                                                 global_average_pooling1d_28[0][0]\n",
      "                                                                 global_average_pooling1d_29[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 160)          0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16)           2576        dropout_9[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 49,072\n",
      "Trainable params: 49,072\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 404us/sample - loss: 0.2177 - acc: 0.9342\n",
      "Loss: 0.21774046612924752 Accuracy: 0.93416405\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, 16000, 32)    192         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 16000, 32)    0           conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling1D) (None, 5333, 32)     0           activation_51[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_51[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 5333, 32)     0           conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling1D) (None, 1777, 32)     0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_52[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 1777, 32)     0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling1D) (None, 592, 32)      0           activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_53[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 592, 32)      0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling1D) (None, 197, 32)      0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_54[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 197, 64)      0           conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling1D) (None, 65, 64)       0           activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 65, 64)       0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling1D) (None, 21, 64)       0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 21, 64)       0           conv1d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling1D) (None, 7, 64)        0           activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_30 (Gl (None, 64)           0           max_pooling1d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_31 (Gl (None, 64)           0           max_pooling1d_56[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_32 (Gl (None, 64)           0           max_pooling1d_57[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 192)          0           global_average_pooling1d_30[0][0]\n",
      "                                                                 global_average_pooling1d_31[0][0]\n",
      "                                                                 global_average_pooling1d_32[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 192)          0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16)           3088        dropout_10[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 70,128\n",
      "Trainable params: 70,128\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 413us/sample - loss: 0.1958 - acc: 0.9491\n",
      "Loss: 0.19581885691712825 Accuracy: 0.94911736\n",
      "\n",
      "1D_CNN_custom_multi_3_GAP_ch_32_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_58 (Conv1D)              (None, 16000, 32)    192         input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16000, 32)    0           conv1d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling1D) (None, 5333, 32)     0           activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_59 (Conv1D)              (None, 5333, 32)     5152        max_pooling1d_58[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 5333, 32)     0           conv1d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling1D) (None, 1777, 32)     0           activation_59[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_60 (Conv1D)              (None, 1777, 32)     5152        max_pooling1d_59[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 1777, 32)     0           conv1d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling1D) (None, 592, 32)      0           activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_61 (Conv1D)              (None, 592, 32)      5152        max_pooling1d_60[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 592, 32)      0           conv1d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling1D) (None, 197, 32)      0           activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_62 (Conv1D)              (None, 197, 64)      10304       max_pooling1d_61[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 197, 64)      0           conv1d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling1D) (None, 65, 64)       0           activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_63 (Conv1D)              (None, 65, 64)       20544       max_pooling1d_62[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 65, 64)       0           conv1d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling1D) (None, 21, 64)       0           activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_64 (Conv1D)              (None, 21, 64)       20544       max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 21, 64)       0           conv1d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling1D) (None, 7, 64)        0           activation_64[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_65 (Conv1D)              (None, 7, 64)        20544       max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 7, 64)        0           conv1d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling1D) (None, 2, 64)        0           activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_33 (Gl (None, 64)           0           max_pooling1d_63[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_34 (Gl (None, 64)           0           max_pooling1d_64[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_35 (Gl (None, 64)           0           max_pooling1d_65[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 192)          0           global_average_pooling1d_33[0][0]\n",
      "                                                                 global_average_pooling1d_34[0][0]\n",
      "                                                                 global_average_pooling1d_35[0][0]\n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 192)          0           concatenate_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16)           3088        dropout_11[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 90,672\n",
      "Trainable params: 90,672\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 418us/sample - loss: 0.2493 - acc: 0.9389\n",
      "Loss: 0.24930718194379986 Accuracy: 0.9389408\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 9):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
