{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, padding='same', \n",
    "                      input_shape=input_shape)) \n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), strides=1, \n",
    "                          padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,400\n",
      "Trainable params: 16,384,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                8192016   \n",
      "=================================================================\n",
      "Total params: 8,212,944\n",
      "Trainable params: 8,212,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                4096016   \n",
      "=================================================================\n",
      "Total params: 4,137,488\n",
      "Trainable params: 4,137,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,110,032\n",
      "Trainable params: 2,110,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,151,120\n",
      "Trainable params: 2,151,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,209,168\n",
      "Trainable params: 1,209,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 779,216\n",
      "Trainable params: 779,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 605,264\n",
      "Trainable params: 605,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                253968    \n",
      "=================================================================\n",
      "Total params: 767,312\n",
      "Trainable params: 767,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 968,272\n",
      "Trainable params: 968,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                61456     \n",
      "=================================================================\n",
      "Total params: 1,230,672\n",
      "Trainable params: 1,230,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,525,840\n",
      "Trainable params: 1,525,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                24592     \n",
      "=================================================================\n",
      "Total params: 2,177,616\n",
      "Trainable params: 2,177,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 14):\n",
    "    model = build_1d_cnn_custom_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1732 - acc: 0.3211\n",
      "Epoch 00001: val_loss improved from inf to 1.86342, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_3_conv_checkpoint/001-1.8634.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 2.1731 - acc: 0.3211 - val_loss: 1.8634 - val_acc: 0.4088\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5918 - acc: 0.5194\n",
      "Epoch 00002: val_loss improved from 1.86342 to 1.56657, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_3_conv_checkpoint/002-1.5666.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 1.5918 - acc: 0.5194 - val_loss: 1.5666 - val_acc: 0.5204\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2863 - acc: 0.6115\n",
      "Epoch 00003: val_loss improved from 1.56657 to 1.52970, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_3_conv_checkpoint/003-1.5297.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 1.2863 - acc: 0.6115 - val_loss: 1.5297 - val_acc: 0.5288\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0729 - acc: 0.6749\n",
      "Epoch 00004: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 1.0728 - acc: 0.6750 - val_loss: 1.5491 - val_acc: 0.5239\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8973 - acc: 0.7298\n",
      "Epoch 00005: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.8973 - acc: 0.7298 - val_loss: 1.6273 - val_acc: 0.5101\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7499 - acc: 0.7723\n",
      "Epoch 00006: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.7498 - acc: 0.7723 - val_loss: 1.6669 - val_acc: 0.5164\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6300 - acc: 0.8121\n",
      "Epoch 00007: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.6300 - acc: 0.8122 - val_loss: 1.7656 - val_acc: 0.5176\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5175 - acc: 0.8463\n",
      "Epoch 00008: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.5175 - acc: 0.8463 - val_loss: 1.8631 - val_acc: 0.5136\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4319 - acc: 0.8728\n",
      "Epoch 00009: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.4319 - acc: 0.8728 - val_loss: 1.9754 - val_acc: 0.5141\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3637 - acc: 0.8943\n",
      "Epoch 00010: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.3637 - acc: 0.8943 - val_loss: 2.0814 - val_acc: 0.5164\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3014 - acc: 0.9129\n",
      "Epoch 00011: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.3014 - acc: 0.9129 - val_loss: 2.2479 - val_acc: 0.5059\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2614 - acc: 0.9230\n",
      "Epoch 00012: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2614 - acc: 0.9230 - val_loss: 2.3209 - val_acc: 0.5027\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2243 - acc: 0.9351\n",
      "Epoch 00013: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.2243 - acc: 0.9351 - val_loss: 2.4277 - val_acc: 0.5167\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9447\n",
      "Epoch 00014: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1959 - acc: 0.9447 - val_loss: 2.5489 - val_acc: 0.5118\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1717 - acc: 0.9524\n",
      "Epoch 00015: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1717 - acc: 0.9525 - val_loss: 2.6231 - val_acc: 0.5143\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1558 - acc: 0.9560\n",
      "Epoch 00016: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1558 - acc: 0.9560 - val_loss: 2.6891 - val_acc: 0.5239\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9621\n",
      "Epoch 00017: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1392 - acc: 0.9621 - val_loss: 2.8052 - val_acc: 0.5029\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9639\n",
      "Epoch 00018: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1313 - acc: 0.9639 - val_loss: 2.7529 - val_acc: 0.5178\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9677\n",
      "Epoch 00019: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1218 - acc: 0.9677 - val_loss: 2.9291 - val_acc: 0.5190\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9707\n",
      "Epoch 00020: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1101 - acc: 0.9707 - val_loss: 2.9339 - val_acc: 0.5136\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9702\n",
      "Epoch 00021: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.1106 - acc: 0.9702 - val_loss: 2.9501 - val_acc: 0.5153\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9750\n",
      "Epoch 00022: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0938 - acc: 0.9750 - val_loss: 2.9750 - val_acc: 0.5239\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9759\n",
      "Epoch 00023: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0942 - acc: 0.9759 - val_loss: 3.0502 - val_acc: 0.5267\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9767\n",
      "Epoch 00024: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0917 - acc: 0.9767 - val_loss: 3.1107 - val_acc: 0.5220\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9799\n",
      "Epoch 00025: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0802 - acc: 0.9799 - val_loss: 3.0994 - val_acc: 0.5143\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9769\n",
      "Epoch 00026: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0867 - acc: 0.9769 - val_loss: 3.2058 - val_acc: 0.5136\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9807\n",
      "Epoch 00027: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0765 - acc: 0.9807 - val_loss: 3.1273 - val_acc: 0.5281\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9823\n",
      "Epoch 00028: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0715 - acc: 0.9823 - val_loss: 3.1955 - val_acc: 0.5234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9833\n",
      "Epoch 00029: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0674 - acc: 0.9833 - val_loss: 3.1843 - val_acc: 0.5269\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9826\n",
      "Epoch 00030: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0697 - acc: 0.9826 - val_loss: 3.2252 - val_acc: 0.5222\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9834\n",
      "Epoch 00031: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0660 - acc: 0.9834 - val_loss: 3.2990 - val_acc: 0.5323\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9844\n",
      "Epoch 00032: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0662 - acc: 0.9844 - val_loss: 3.2792 - val_acc: 0.5234\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9852\n",
      "Epoch 00033: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0634 - acc: 0.9852 - val_loss: 3.2410 - val_acc: 0.5353\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9843\n",
      "Epoch 00034: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0639 - acc: 0.9843 - val_loss: 3.3408 - val_acc: 0.5285\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9863\n",
      "Epoch 00035: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0568 - acc: 0.9863 - val_loss: 3.3539 - val_acc: 0.5334\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9865\n",
      "Epoch 00036: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0568 - acc: 0.9865 - val_loss: 3.2915 - val_acc: 0.5372\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9858\n",
      "Epoch 00037: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0590 - acc: 0.9858 - val_loss: 3.3129 - val_acc: 0.5311\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9858\n",
      "Epoch 00038: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0616 - acc: 0.9858 - val_loss: 3.3499 - val_acc: 0.5376\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9880\n",
      "Epoch 00039: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0523 - acc: 0.9880 - val_loss: 3.3422 - val_acc: 0.5269\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9876\n",
      "Epoch 00040: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0532 - acc: 0.9876 - val_loss: 3.3189 - val_acc: 0.5358\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9893\n",
      "Epoch 00041: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0482 - acc: 0.9893 - val_loss: 3.3301 - val_acc: 0.5355\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9879\n",
      "Epoch 00042: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0531 - acc: 0.9879 - val_loss: 3.3211 - val_acc: 0.5427\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9887\n",
      "Epoch 00043: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0493 - acc: 0.9887 - val_loss: 3.3740 - val_acc: 0.5418\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9889\n",
      "Epoch 00044: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0483 - acc: 0.9889 - val_loss: 3.4577 - val_acc: 0.5283\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9888\n",
      "Epoch 00045: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0495 - acc: 0.9888 - val_loss: 3.4558 - val_acc: 0.5309\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9891\n",
      "Epoch 00046: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0458 - acc: 0.9891 - val_loss: 3.5444 - val_acc: 0.5332\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9897\n",
      "Epoch 00047: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0445 - acc: 0.9897 - val_loss: 3.5100 - val_acc: 0.5374\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9902\n",
      "Epoch 00048: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0424 - acc: 0.9902 - val_loss: 3.5426 - val_acc: 0.5316\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9898\n",
      "Epoch 00049: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0435 - acc: 0.9898 - val_loss: 3.5435 - val_acc: 0.5271\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9901\n",
      "Epoch 00050: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0444 - acc: 0.9901 - val_loss: 3.4504 - val_acc: 0.5367\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9902\n",
      "Epoch 00051: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0450 - acc: 0.9902 - val_loss: 3.5152 - val_acc: 0.5283\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9907\n",
      "Epoch 00052: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0411 - acc: 0.9907 - val_loss: 3.4982 - val_acc: 0.5386\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9906\n",
      "Epoch 00053: val_loss did not improve from 1.52970\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0434 - acc: 0.9906 - val_loss: 3.3532 - val_acc: 0.5455\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 650us/sample - loss: 1.5832 - acc: 0.5036\n",
      "Loss: 1.5832462274396901 Accuracy: 0.50363445\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1101 - acc: 0.3323\n",
      "Epoch 00001: val_loss improved from inf to 1.67202, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_4_conv_checkpoint/001-1.6720.hdf5\n",
      "36805/36805 [==============================] - 60s 2ms/sample - loss: 2.1099 - acc: 0.3323 - val_loss: 1.6720 - val_acc: 0.4945\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4675 - acc: 0.5471\n",
      "Epoch 00002: val_loss improved from 1.67202 to 1.41502, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_4_conv_checkpoint/002-1.4150.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 1.4674 - acc: 0.5471 - val_loss: 1.4150 - val_acc: 0.5688\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1926 - acc: 0.6366\n",
      "Epoch 00003: val_loss improved from 1.41502 to 1.33476, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_4_conv_checkpoint/003-1.3348.hdf5\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 1.1926 - acc: 0.6366 - val_loss: 1.3348 - val_acc: 0.5819\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0107 - acc: 0.6918\n",
      "Epoch 00004: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 1.0107 - acc: 0.6918 - val_loss: 1.3486 - val_acc: 0.5910\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8639 - acc: 0.7373\n",
      "Epoch 00005: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.8639 - acc: 0.7373 - val_loss: 1.3761 - val_acc: 0.5768\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7370 - acc: 0.7730\n",
      "Epoch 00006: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.7369 - acc: 0.7730 - val_loss: 1.3989 - val_acc: 0.5844\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6170 - acc: 0.8122\n",
      "Epoch 00007: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.6170 - acc: 0.8122 - val_loss: 1.4845 - val_acc: 0.5807\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5272 - acc: 0.8395\n",
      "Epoch 00008: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.5271 - acc: 0.8395 - val_loss: 1.5394 - val_acc: 0.5842\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4406 - acc: 0.8654\n",
      "Epoch 00009: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.4405 - acc: 0.8654 - val_loss: 1.5921 - val_acc: 0.5977\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3815 - acc: 0.8824\n",
      "Epoch 00010: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.3815 - acc: 0.8824 - val_loss: 1.6883 - val_acc: 0.5828\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3234 - acc: 0.9022\n",
      "Epoch 00011: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.3234 - acc: 0.9022 - val_loss: 1.8438 - val_acc: 0.5733\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2776 - acc: 0.9151\n",
      "Epoch 00012: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2776 - acc: 0.9151 - val_loss: 1.8269 - val_acc: 0.5963\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2434 - acc: 0.9262\n",
      "Epoch 00013: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2435 - acc: 0.9262 - val_loss: 1.9030 - val_acc: 0.5893\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2164 - acc: 0.9354\n",
      "Epoch 00014: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.2164 - acc: 0.9354 - val_loss: 1.9605 - val_acc: 0.5877\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1849 - acc: 0.9444\n",
      "Epoch 00015: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1849 - acc: 0.9444 - val_loss: 2.0544 - val_acc: 0.5919\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1699 - acc: 0.9490\n",
      "Epoch 00016: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1698 - acc: 0.9491 - val_loss: 2.0873 - val_acc: 0.6005\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1582 - acc: 0.9525\n",
      "Epoch 00017: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1582 - acc: 0.9525 - val_loss: 2.1423 - val_acc: 0.5970\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1521 - acc: 0.9551\n",
      "Epoch 00018: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1521 - acc: 0.9551 - val_loss: 2.1047 - val_acc: 0.6066\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9601\n",
      "Epoch 00019: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1381 - acc: 0.9601 - val_loss: 2.1680 - val_acc: 0.6031\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9652\n",
      "Epoch 00020: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1214 - acc: 0.9652 - val_loss: 2.2432 - val_acc: 0.5956\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9632\n",
      "Epoch 00021: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1241 - acc: 0.9632 - val_loss: 2.2879 - val_acc: 0.5991\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9693\n",
      "Epoch 00022: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1083 - acc: 0.9693 - val_loss: 2.3132 - val_acc: 0.6007\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9700\n",
      "Epoch 00023: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1055 - acc: 0.9700 - val_loss: 2.4050 - val_acc: 0.5991\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9710\n",
      "Epoch 00024: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.1012 - acc: 0.9710 - val_loss: 2.4149 - val_acc: 0.6014\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9728\n",
      "Epoch 00025: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0999 - acc: 0.9728 - val_loss: 2.2931 - val_acc: 0.6152\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9756\n",
      "Epoch 00026: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0892 - acc: 0.9756 - val_loss: 2.4401 - val_acc: 0.6110\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9751\n",
      "Epoch 00027: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0876 - acc: 0.9751 - val_loss: 2.3431 - val_acc: 0.6077\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9780\n",
      "Epoch 00028: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0800 - acc: 0.9780 - val_loss: 2.3790 - val_acc: 0.6177\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9782\n",
      "Epoch 00029: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0817 - acc: 0.9782 - val_loss: 2.5189 - val_acc: 0.6056\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9776\n",
      "Epoch 00030: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0812 - acc: 0.9776 - val_loss: 2.3954 - val_acc: 0.6196\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9793\n",
      "Epoch 00031: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 0.0766 - acc: 0.9793 - val_loss: 2.3479 - val_acc: 0.6292\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9805\n",
      "Epoch 00032: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0735 - acc: 0.9805 - val_loss: 2.4511 - val_acc: 0.6157\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9805\n",
      "Epoch 00033: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0728 - acc: 0.9805 - val_loss: 2.5501 - val_acc: 0.6098\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9817\n",
      "Epoch 00034: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0687 - acc: 0.9817 - val_loss: 2.4484 - val_acc: 0.6147\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9827\n",
      "Epoch 00035: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0646 - acc: 0.9827 - val_loss: 2.4656 - val_acc: 0.6229\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9824\n",
      "Epoch 00036: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0677 - acc: 0.9824 - val_loss: 2.5229 - val_acc: 0.6254\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9827\n",
      "Epoch 00037: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0681 - acc: 0.9827 - val_loss: 2.4949 - val_acc: 0.6133\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9839\n",
      "Epoch 00038: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0618 - acc: 0.9839 - val_loss: 2.5533 - val_acc: 0.6233\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9823\n",
      "Epoch 00039: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0662 - acc: 0.9823 - val_loss: 2.4635 - val_acc: 0.6222\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9849\n",
      "Epoch 00040: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0598 - acc: 0.9849 - val_loss: 2.4444 - val_acc: 0.6327\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9854\n",
      "Epoch 00041: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0586 - acc: 0.9854 - val_loss: 2.4589 - val_acc: 0.6315\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9858\n",
      "Epoch 00042: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0573 - acc: 0.9858 - val_loss: 2.4786 - val_acc: 0.6371\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9861\n",
      "Epoch 00043: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0563 - acc: 0.9861 - val_loss: 2.4030 - val_acc: 0.6406\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9848\n",
      "Epoch 00044: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0589 - acc: 0.9848 - val_loss: 2.5292 - val_acc: 0.6355\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9860\n",
      "Epoch 00045: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0561 - acc: 0.9860 - val_loss: 2.4717 - val_acc: 0.6422\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9867\n",
      "Epoch 00046: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0540 - acc: 0.9867 - val_loss: 2.5469 - val_acc: 0.6226\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9874\n",
      "Epoch 00047: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0503 - acc: 0.9874 - val_loss: 2.5664 - val_acc: 0.6308\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9876\n",
      "Epoch 00048: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0504 - acc: 0.9876 - val_loss: 2.5943 - val_acc: 0.6285\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9872\n",
      "Epoch 00049: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0501 - acc: 0.9872 - val_loss: 2.5051 - val_acc: 0.6338\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9884\n",
      "Epoch 00050: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 57s 2ms/sample - loss: 0.0464 - acc: 0.9884 - val_loss: 2.5783 - val_acc: 0.6350\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9886\n",
      "Epoch 00051: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0458 - acc: 0.9886 - val_loss: 2.5757 - val_acc: 0.6329\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9882\n",
      "Epoch 00052: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0474 - acc: 0.9882 - val_loss: 2.5174 - val_acc: 0.6389\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9875\n",
      "Epoch 00053: val_loss did not improve from 1.33476\n",
      "36805/36805 [==============================] - 58s 2ms/sample - loss: 0.0495 - acc: 0.9875 - val_loss: 2.5993 - val_acc: 0.6334\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 698us/sample - loss: 1.3960 - acc: 0.5597\n",
      "Loss: 1.396030033439367 Accuracy: 0.55970925\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9887 - acc: 0.3633\n",
      "Epoch 00001: val_loss improved from inf to 1.54432, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_5_conv_checkpoint/001-1.5443.hdf5\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 1.9886 - acc: 0.3633 - val_loss: 1.5443 - val_acc: 0.4955\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3923 - acc: 0.5609\n",
      "Epoch 00002: val_loss improved from 1.54432 to 1.30406, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_5_conv_checkpoint/002-1.3041.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 1.3923 - acc: 0.5609 - val_loss: 1.3041 - val_acc: 0.6007\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1484 - acc: 0.6479\n",
      "Epoch 00003: val_loss improved from 1.30406 to 1.25762, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_5_conv_checkpoint/003-1.2576.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 1.1484 - acc: 0.6478 - val_loss: 1.2576 - val_acc: 0.6082\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9767 - acc: 0.7019\n",
      "Epoch 00004: val_loss improved from 1.25762 to 1.19925, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_5_conv_checkpoint/004-1.1992.hdf5\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.9767 - acc: 0.7019 - val_loss: 1.1992 - val_acc: 0.6208\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8215 - acc: 0.7494\n",
      "Epoch 00005: val_loss improved from 1.19925 to 1.15014, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_5_conv_checkpoint/005-1.1501.hdf5\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.8215 - acc: 0.7494 - val_loss: 1.1501 - val_acc: 0.6413\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6801 - acc: 0.7943\n",
      "Epoch 00006: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.6801 - acc: 0.7943 - val_loss: 1.1749 - val_acc: 0.6462\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5508 - acc: 0.8328\n",
      "Epoch 00007: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.5508 - acc: 0.8328 - val_loss: 1.2294 - val_acc: 0.6476\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4456 - acc: 0.8667\n",
      "Epoch 00008: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.4457 - acc: 0.8666 - val_loss: 1.2948 - val_acc: 0.6462\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3557 - acc: 0.8933\n",
      "Epoch 00009: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.3561 - acc: 0.8933 - val_loss: 1.3558 - val_acc: 0.6532\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2801 - acc: 0.9171\n",
      "Epoch 00010: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.2800 - acc: 0.9171 - val_loss: 1.4721 - val_acc: 0.6532\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2373 - acc: 0.9288\n",
      "Epoch 00011: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.2373 - acc: 0.9288 - val_loss: 1.4077 - val_acc: 0.6653\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9402\n",
      "Epoch 00012: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.2005 - acc: 0.9402 - val_loss: 1.5264 - val_acc: 0.6608\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1732 - acc: 0.9480\n",
      "Epoch 00013: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1731 - acc: 0.9480 - val_loss: 1.6699 - val_acc: 0.6480\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9563\n",
      "Epoch 00014: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.1463 - acc: 0.9562 - val_loss: 1.6904 - val_acc: 0.6569\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9602\n",
      "Epoch 00015: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.1371 - acc: 0.9602 - val_loss: 1.6695 - val_acc: 0.6718\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9663\n",
      "Epoch 00016: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.1163 - acc: 0.9663 - val_loss: 1.7853 - val_acc: 0.6618\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9708\n",
      "Epoch 00017: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.1016 - acc: 0.9708 - val_loss: 1.7979 - val_acc: 0.6657\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9721\n",
      "Epoch 00018: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0945 - acc: 0.9721 - val_loss: 1.8541 - val_acc: 0.6655\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0940 - acc: 0.9730\n",
      "Epoch 00019: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0940 - acc: 0.9730 - val_loss: 1.8380 - val_acc: 0.6713\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9737\n",
      "Epoch 00020: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0872 - acc: 0.9736 - val_loss: 1.8297 - val_acc: 0.6716\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9762\n",
      "Epoch 00021: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0820 - acc: 0.9762 - val_loss: 1.7748 - val_acc: 0.6874\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0664 - acc: 0.9815\n",
      "Epoch 00022: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0664 - acc: 0.9815 - val_loss: 1.9145 - val_acc: 0.6769\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9800\n",
      "Epoch 00023: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0700 - acc: 0.9800 - val_loss: 1.9139 - val_acc: 0.6771\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9798\n",
      "Epoch 00024: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0691 - acc: 0.9798 - val_loss: 1.9305 - val_acc: 0.6781\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9823\n",
      "Epoch 00025: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0629 - acc: 0.9823 - val_loss: 2.0632 - val_acc: 0.6771\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9831\n",
      "Epoch 00026: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0607 - acc: 0.9830 - val_loss: 1.9704 - val_acc: 0.6869\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9820\n",
      "Epoch 00027: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0650 - acc: 0.9820 - val_loss: 1.9065 - val_acc: 0.6865\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9840\n",
      "Epoch 00028: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0585 - acc: 0.9841 - val_loss: 2.0634 - val_acc: 0.6823\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9848\n",
      "Epoch 00029: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0563 - acc: 0.9848 - val_loss: 1.9410 - val_acc: 0.6830\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9864\n",
      "Epoch 00030: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0516 - acc: 0.9864 - val_loss: 1.9439 - val_acc: 0.6802\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9863\n",
      "Epoch 00031: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0504 - acc: 0.9863 - val_loss: 2.0196 - val_acc: 0.6962\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9857\n",
      "Epoch 00032: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0516 - acc: 0.9857 - val_loss: 1.9828 - val_acc: 0.6951\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9870\n",
      "Epoch 00033: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0495 - acc: 0.9870 - val_loss: 1.9700 - val_acc: 0.6916\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9865\n",
      "Epoch 00034: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0497 - acc: 0.9865 - val_loss: 1.9822 - val_acc: 0.6988\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9889\n",
      "Epoch 00035: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0453 - acc: 0.9889 - val_loss: 1.9871 - val_acc: 0.6930\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9877\n",
      "Epoch 00036: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0446 - acc: 0.9877 - val_loss: 1.9953 - val_acc: 0.6976\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9889\n",
      "Epoch 00037: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0452 - acc: 0.9889 - val_loss: 2.0822 - val_acc: 0.6879\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9889\n",
      "Epoch 00038: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0432 - acc: 0.9889 - val_loss: 2.0758 - val_acc: 0.6897\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9879\n",
      "Epoch 00039: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0457 - acc: 0.9879 - val_loss: 1.9464 - val_acc: 0.7079\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9890\n",
      "Epoch 00040: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0425 - acc: 0.9891 - val_loss: 1.9934 - val_acc: 0.6944\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9897\n",
      "Epoch 00041: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0399 - acc: 0.9897 - val_loss: 1.9843 - val_acc: 0.7007\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9901\n",
      "Epoch 00042: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0364 - acc: 0.9901 - val_loss: 1.9831 - val_acc: 0.6988\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9899\n",
      "Epoch 00043: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0394 - acc: 0.9899 - val_loss: 2.0352 - val_acc: 0.7039\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9894\n",
      "Epoch 00044: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0391 - acc: 0.9894 - val_loss: 1.9735 - val_acc: 0.7025\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9911\n",
      "Epoch 00045: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0352 - acc: 0.9911 - val_loss: 1.9736 - val_acc: 0.7039\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9903\n",
      "Epoch 00046: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0363 - acc: 0.9903 - val_loss: 2.1189 - val_acc: 0.6855\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9910\n",
      "Epoch 00047: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0362 - acc: 0.9910 - val_loss: 2.0351 - val_acc: 0.7037\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9900\n",
      "Epoch 00048: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0395 - acc: 0.9900 - val_loss: 2.1088 - val_acc: 0.6962\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9908\n",
      "Epoch 00049: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0377 - acc: 0.9908 - val_loss: 2.0241 - val_acc: 0.7049\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9911\n",
      "Epoch 00050: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0354 - acc: 0.9911 - val_loss: 2.0359 - val_acc: 0.6976\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9926\n",
      "Epoch 00051: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0319 - acc: 0.9926 - val_loss: 2.0738 - val_acc: 0.6974\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9917\n",
      "Epoch 00052: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0332 - acc: 0.9917 - val_loss: 2.1297 - val_acc: 0.6974\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9912\n",
      "Epoch 00053: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0354 - acc: 0.9913 - val_loss: 1.9769 - val_acc: 0.7098\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9928\n",
      "Epoch 00054: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 64s 2ms/sample - loss: 0.0297 - acc: 0.9928 - val_loss: 1.9897 - val_acc: 0.7126\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9919\n",
      "Epoch 00055: val_loss did not improve from 1.15014\n",
      "36805/36805 [==============================] - 63s 2ms/sample - loss: 0.0322 - acc: 0.9919 - val_loss: 2.1487 - val_acc: 0.7004\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 755us/sample - loss: 1.2224 - acc: 0.6233\n",
      "Loss: 1.222374301065661 Accuracy: 0.6232606\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0112 - acc: 0.3488\n",
      "Epoch 00001: val_loss improved from inf to 1.48009, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_6_conv_checkpoint/001-1.4801.hdf5\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 2.0112 - acc: 0.3488 - val_loss: 1.4801 - val_acc: 0.5332\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3653 - acc: 0.5741\n",
      "Epoch 00002: val_loss improved from 1.48009 to 1.19642, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_6_conv_checkpoint/002-1.1964.hdf5\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 1.3653 - acc: 0.5741 - val_loss: 1.1964 - val_acc: 0.6271\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1167 - acc: 0.6582\n",
      "Epoch 00003: val_loss improved from 1.19642 to 1.05033, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_6_conv_checkpoint/003-1.0503.hdf5\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 1.1167 - acc: 0.6582 - val_loss: 1.0503 - val_acc: 0.6869\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9480 - acc: 0.7104\n",
      "Epoch 00004: val_loss improved from 1.05033 to 0.96554, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_6_conv_checkpoint/004-0.9655.hdf5\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.9481 - acc: 0.7104 - val_loss: 0.9655 - val_acc: 0.7025\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8173 - acc: 0.7524\n",
      "Epoch 00005: val_loss improved from 0.96554 to 0.88119, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_6_conv_checkpoint/005-0.8812.hdf5\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.8177 - acc: 0.7523 - val_loss: 0.8812 - val_acc: 0.7356\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7042 - acc: 0.7887\n",
      "Epoch 00006: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.7043 - acc: 0.7887 - val_loss: 0.9425 - val_acc: 0.7151\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6083 - acc: 0.8149\n",
      "Epoch 00007: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.6082 - acc: 0.8149 - val_loss: 0.9315 - val_acc: 0.7158\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5165 - acc: 0.8429\n",
      "Epoch 00008: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.5166 - acc: 0.8429 - val_loss: 0.9017 - val_acc: 0.7365\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4467 - acc: 0.8628\n",
      "Epoch 00009: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.4468 - acc: 0.8628 - val_loss: 0.9643 - val_acc: 0.7296\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3827 - acc: 0.8814\n",
      "Epoch 00010: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.3827 - acc: 0.8814 - val_loss: 0.9357 - val_acc: 0.7403\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3118 - acc: 0.9044\n",
      "Epoch 00011: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.3118 - acc: 0.9044 - val_loss: 0.9729 - val_acc: 0.7410\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2700 - acc: 0.9181\n",
      "Epoch 00012: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.2700 - acc: 0.9181 - val_loss: 0.9646 - val_acc: 0.7545\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2332 - acc: 0.9274\n",
      "Epoch 00013: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.2332 - acc: 0.9275 - val_loss: 1.2398 - val_acc: 0.7226\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9363\n",
      "Epoch 00014: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.2061 - acc: 0.9363 - val_loss: 1.0205 - val_acc: 0.7508\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1838 - acc: 0.9426\n",
      "Epoch 00015: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.1838 - acc: 0.9426 - val_loss: 1.1085 - val_acc: 0.7522\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1589 - acc: 0.9518\n",
      "Epoch 00016: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.1589 - acc: 0.9518 - val_loss: 1.0960 - val_acc: 0.7575\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1505 - acc: 0.9540\n",
      "Epoch 00017: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.1505 - acc: 0.9540 - val_loss: 1.1502 - val_acc: 0.7456\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1382 - acc: 0.9565\n",
      "Epoch 00018: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.1382 - acc: 0.9565 - val_loss: 1.1189 - val_acc: 0.7689\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9629\n",
      "Epoch 00019: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.1209 - acc: 0.9628 - val_loss: 1.1255 - val_acc: 0.7626\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9641\n",
      "Epoch 00020: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.1178 - acc: 0.9641 - val_loss: 1.2325 - val_acc: 0.7461\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9668\n",
      "Epoch 00021: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.1079 - acc: 0.9668 - val_loss: 1.1722 - val_acc: 0.7633\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1002 - acc: 0.9695\n",
      "Epoch 00022: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.1002 - acc: 0.9695 - val_loss: 1.1861 - val_acc: 0.7713\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9722\n",
      "Epoch 00023: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.0942 - acc: 0.9722 - val_loss: 1.2415 - val_acc: 0.7601\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9720\n",
      "Epoch 00024: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.0905 - acc: 0.9720 - val_loss: 1.2301 - val_acc: 0.7645\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9756\n",
      "Epoch 00025: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.0846 - acc: 0.9756 - val_loss: 1.2736 - val_acc: 0.7615\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9761\n",
      "Epoch 00026: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0834 - acc: 0.9761 - val_loss: 1.2369 - val_acc: 0.7561\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9767\n",
      "Epoch 00027: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0773 - acc: 0.9767 - val_loss: 1.3650 - val_acc: 0.7612\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9774\n",
      "Epoch 00028: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0798 - acc: 0.9774 - val_loss: 1.1899 - val_acc: 0.7666\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9776\n",
      "Epoch 00029: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0744 - acc: 0.9776 - val_loss: 1.3667 - val_acc: 0.7661\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9776\n",
      "Epoch 00030: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0759 - acc: 0.9776 - val_loss: 1.2834 - val_acc: 0.7654\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9811\n",
      "Epoch 00031: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0681 - acc: 0.9811 - val_loss: 1.2683 - val_acc: 0.7806\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9804\n",
      "Epoch 00032: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.0691 - acc: 0.9804 - val_loss: 1.3252 - val_acc: 0.7687\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9823\n",
      "Epoch 00033: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.0641 - acc: 0.9822 - val_loss: 1.2465 - val_acc: 0.7775\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9811\n",
      "Epoch 00034: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.0687 - acc: 0.9811 - val_loss: 1.2868 - val_acc: 0.7715\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9847\n",
      "Epoch 00035: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0565 - acc: 0.9847 - val_loss: 1.2797 - val_acc: 0.7817\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9818\n",
      "Epoch 00036: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0635 - acc: 0.9818 - val_loss: 1.2446 - val_acc: 0.7820\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9820\n",
      "Epoch 00037: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0631 - acc: 0.9820 - val_loss: 1.3055 - val_acc: 0.7631\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9830\n",
      "Epoch 00038: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.0618 - acc: 0.9830 - val_loss: 1.3214 - val_acc: 0.7680\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9837\n",
      "Epoch 00039: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.0586 - acc: 0.9836 - val_loss: 1.3960 - val_acc: 0.7682\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9853\n",
      "Epoch 00040: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0550 - acc: 0.9853 - val_loss: 1.3046 - val_acc: 0.7668\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9850\n",
      "Epoch 00041: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0550 - acc: 0.9850 - val_loss: 1.2795 - val_acc: 0.7701\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9861\n",
      "Epoch 00042: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0505 - acc: 0.9861 - val_loss: 1.3344 - val_acc: 0.7813\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9859\n",
      "Epoch 00043: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0525 - acc: 0.9859 - val_loss: 1.3272 - val_acc: 0.7752\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9851\n",
      "Epoch 00044: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0547 - acc: 0.9851 - val_loss: 1.3078 - val_acc: 0.7773\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9861\n",
      "Epoch 00045: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0515 - acc: 0.9861 - val_loss: 1.3085 - val_acc: 0.7869\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9879\n",
      "Epoch 00046: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0451 - acc: 0.9879 - val_loss: 1.3156 - val_acc: 0.7775\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9878\n",
      "Epoch 00047: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0443 - acc: 0.9878 - val_loss: 1.3547 - val_acc: 0.7841\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9873\n",
      "Epoch 00048: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0494 - acc: 0.9873 - val_loss: 1.3776 - val_acc: 0.7782\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9870\n",
      "Epoch 00049: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0478 - acc: 0.9870 - val_loss: 1.2687 - val_acc: 0.7934\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9871\n",
      "Epoch 00050: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.0478 - acc: 0.9871 - val_loss: 1.2957 - val_acc: 0.7883\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9866\n",
      "Epoch 00051: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 66s 2ms/sample - loss: 0.0492 - acc: 0.9866 - val_loss: 1.3605 - val_acc: 0.7834\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9893\n",
      "Epoch 00052: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0422 - acc: 0.9893 - val_loss: 1.3193 - val_acc: 0.7729\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9890\n",
      "Epoch 00053: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0413 - acc: 0.9891 - val_loss: 1.3859 - val_acc: 0.7810\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9887\n",
      "Epoch 00054: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0432 - acc: 0.9888 - val_loss: 1.4011 - val_acc: 0.7734\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9880\n",
      "Epoch 00055: val_loss did not improve from 0.88119\n",
      "36805/36805 [==============================] - 67s 2ms/sample - loss: 0.0437 - acc: 0.9880 - val_loss: 1.3919 - val_acc: 0.7836\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 814us/sample - loss: 0.9725 - acc: 0.7084\n",
      "Loss: 0.9725124305530005 Accuracy: 0.7084112\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0534 - acc: 0.3279\n",
      "Epoch 00001: val_loss improved from inf to 1.47903, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_7_conv_checkpoint/001-1.4790.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 2.0535 - acc: 0.3279 - val_loss: 1.4790 - val_acc: 0.5250\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4275 - acc: 0.5430\n",
      "Epoch 00002: val_loss improved from 1.47903 to 1.23961, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_7_conv_checkpoint/002-1.2396.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 1.4275 - acc: 0.5430 - val_loss: 1.2396 - val_acc: 0.6096\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2400 - acc: 0.6143\n",
      "Epoch 00003: val_loss improved from 1.23961 to 1.08471, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_7_conv_checkpoint/003-1.0847.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 1.2400 - acc: 0.6143 - val_loss: 1.0847 - val_acc: 0.6697\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0784 - acc: 0.6725\n",
      "Epoch 00004: val_loss improved from 1.08471 to 0.91845, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_7_conv_checkpoint/004-0.9184.hdf5\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 1.0784 - acc: 0.6725 - val_loss: 0.9184 - val_acc: 0.7307\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9296 - acc: 0.7191\n",
      "Epoch 00005: val_loss improved from 0.91845 to 0.86285, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_7_conv_checkpoint/005-0.8629.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.9296 - acc: 0.7191 - val_loss: 0.8629 - val_acc: 0.7431\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8311 - acc: 0.7486\n",
      "Epoch 00006: val_loss improved from 0.86285 to 0.77366, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_7_conv_checkpoint/006-0.7737.hdf5\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.8311 - acc: 0.7486 - val_loss: 0.7737 - val_acc: 0.7741\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7504 - acc: 0.7741\n",
      "Epoch 00007: val_loss improved from 0.77366 to 0.72210, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_7_conv_checkpoint/007-0.7221.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.7504 - acc: 0.7741 - val_loss: 0.7221 - val_acc: 0.7911\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6738 - acc: 0.7980\n",
      "Epoch 00008: val_loss improved from 0.72210 to 0.68219, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_7_conv_checkpoint/008-0.6822.hdf5\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.6738 - acc: 0.7980 - val_loss: 0.6822 - val_acc: 0.8020\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6111 - acc: 0.8192\n",
      "Epoch 00009: val_loss improved from 0.68219 to 0.65316, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_7_conv_checkpoint/009-0.6532.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.6111 - acc: 0.8192 - val_loss: 0.6532 - val_acc: 0.8188\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5565 - acc: 0.8342\n",
      "Epoch 00010: val_loss improved from 0.65316 to 0.64972, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_7_conv_checkpoint/010-0.6497.hdf5\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.5565 - acc: 0.8342 - val_loss: 0.6497 - val_acc: 0.8164\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5084 - acc: 0.8483\n",
      "Epoch 00011: val_loss improved from 0.64972 to 0.59308, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_7_conv_checkpoint/011-0.5931.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.5084 - acc: 0.8483 - val_loss: 0.5931 - val_acc: 0.8311\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4607 - acc: 0.8608\n",
      "Epoch 00012: val_loss improved from 0.59308 to 0.58345, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_7_conv_checkpoint/012-0.5835.hdf5\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.4607 - acc: 0.8608 - val_loss: 0.5835 - val_acc: 0.8367\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4149 - acc: 0.8791\n",
      "Epoch 00013: val_loss did not improve from 0.58345\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.4149 - acc: 0.8791 - val_loss: 0.5854 - val_acc: 0.8407\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3699 - acc: 0.8884\n",
      "Epoch 00014: val_loss did not improve from 0.58345\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.3698 - acc: 0.8884 - val_loss: 0.6517 - val_acc: 0.8276\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3404 - acc: 0.8974\n",
      "Epoch 00015: val_loss improved from 0.58345 to 0.58052, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_7_conv_checkpoint/015-0.5805.hdf5\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.3404 - acc: 0.8974 - val_loss: 0.5805 - val_acc: 0.8495\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2963 - acc: 0.9094\n",
      "Epoch 00016: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.2963 - acc: 0.9094 - val_loss: 0.7005 - val_acc: 0.8269\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2729 - acc: 0.9154\n",
      "Epoch 00017: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.2729 - acc: 0.9154 - val_loss: 0.5892 - val_acc: 0.8428\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2374 - acc: 0.9263\n",
      "Epoch 00018: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.2374 - acc: 0.9263 - val_loss: 0.6470 - val_acc: 0.8416\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2206 - acc: 0.9313\n",
      "Epoch 00019: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.2206 - acc: 0.9313 - val_loss: 0.6923 - val_acc: 0.8246\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1970 - acc: 0.9394\n",
      "Epoch 00020: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.1970 - acc: 0.9394 - val_loss: 0.6629 - val_acc: 0.8376\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1769 - acc: 0.9444\n",
      "Epoch 00021: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.1769 - acc: 0.9444 - val_loss: 0.6357 - val_acc: 0.8512\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1646 - acc: 0.9493\n",
      "Epoch 00022: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.1647 - acc: 0.9492 - val_loss: 0.6881 - val_acc: 0.8428\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1484 - acc: 0.9540\n",
      "Epoch 00023: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.1485 - acc: 0.9540 - val_loss: 0.6729 - val_acc: 0.8495\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9564\n",
      "Epoch 00024: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.1380 - acc: 0.9563 - val_loss: 0.6784 - val_acc: 0.8449\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9589\n",
      "Epoch 00025: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.1301 - acc: 0.9589 - val_loss: 0.6986 - val_acc: 0.8481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9624\n",
      "Epoch 00026: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.1212 - acc: 0.9624 - val_loss: 0.7191 - val_acc: 0.8463\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9650\n",
      "Epoch 00027: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.1126 - acc: 0.9650 - val_loss: 0.7013 - val_acc: 0.8509\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9672\n",
      "Epoch 00028: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.1065 - acc: 0.9672 - val_loss: 0.7105 - val_acc: 0.8546\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0979 - acc: 0.9692\n",
      "Epoch 00029: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0979 - acc: 0.9692 - val_loss: 0.7381 - val_acc: 0.8481\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9715\n",
      "Epoch 00030: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0949 - acc: 0.9714 - val_loss: 0.6839 - val_acc: 0.8628\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9687\n",
      "Epoch 00031: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.1005 - acc: 0.9687 - val_loss: 0.7277 - val_acc: 0.8591\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9746\n",
      "Epoch 00032: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0827 - acc: 0.9746 - val_loss: 0.7485 - val_acc: 0.8542\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9728\n",
      "Epoch 00033: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0910 - acc: 0.9728 - val_loss: 0.7635 - val_acc: 0.8567\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9771\n",
      "Epoch 00034: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0755 - acc: 0.9771 - val_loss: 0.7587 - val_acc: 0.8586\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9763\n",
      "Epoch 00035: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0777 - acc: 0.9763 - val_loss: 0.7313 - val_acc: 0.8593\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9746\n",
      "Epoch 00036: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0839 - acc: 0.9746 - val_loss: 0.7089 - val_acc: 0.8665\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9804\n",
      "Epoch 00037: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0674 - acc: 0.9804 - val_loss: 0.7739 - val_acc: 0.8586\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9776\n",
      "Epoch 00038: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0756 - acc: 0.9776 - val_loss: 0.7343 - val_acc: 0.8602\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9799\n",
      "Epoch 00039: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0673 - acc: 0.9799 - val_loss: 0.8045 - val_acc: 0.8544\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9792\n",
      "Epoch 00040: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0711 - acc: 0.9792 - val_loss: 0.7607 - val_acc: 0.8593\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9820\n",
      "Epoch 00041: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0650 - acc: 0.9820 - val_loss: 0.7436 - val_acc: 0.8612\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9823\n",
      "Epoch 00042: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0601 - acc: 0.9823 - val_loss: 0.7318 - val_acc: 0.8675\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9809\n",
      "Epoch 00043: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0665 - acc: 0.9809 - val_loss: 0.7552 - val_acc: 0.8705\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9822\n",
      "Epoch 00044: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0589 - acc: 0.9822 - val_loss: 0.7654 - val_acc: 0.8612\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9837\n",
      "Epoch 00045: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0580 - acc: 0.9838 - val_loss: 0.7315 - val_acc: 0.8651\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9826\n",
      "Epoch 00046: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0583 - acc: 0.9826 - val_loss: 0.8609 - val_acc: 0.8577\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9835\n",
      "Epoch 00047: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0572 - acc: 0.9835 - val_loss: 0.7567 - val_acc: 0.8689\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9830\n",
      "Epoch 00048: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0587 - acc: 0.9830 - val_loss: 0.7769 - val_acc: 0.8665\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9857\n",
      "Epoch 00049: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0511 - acc: 0.9857 - val_loss: 0.7687 - val_acc: 0.8670\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9849\n",
      "Epoch 00050: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0546 - acc: 0.9849 - val_loss: 0.7933 - val_acc: 0.8663\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9866\n",
      "Epoch 00051: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0476 - acc: 0.9866 - val_loss: 0.7812 - val_acc: 0.8707\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9838\n",
      "Epoch 00052: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0572 - acc: 0.9838 - val_loss: 0.7994 - val_acc: 0.8619\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9859\n",
      "Epoch 00053: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0504 - acc: 0.9859 - val_loss: 0.7669 - val_acc: 0.8689\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9853\n",
      "Epoch 00054: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0525 - acc: 0.9853 - val_loss: 0.8165 - val_acc: 0.8675\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9863\n",
      "Epoch 00055: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0482 - acc: 0.9863 - val_loss: 0.7954 - val_acc: 0.8712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9872\n",
      "Epoch 00056: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0464 - acc: 0.9872 - val_loss: 0.7955 - val_acc: 0.8565\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9857\n",
      "Epoch 00057: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0507 - acc: 0.9857 - val_loss: 0.7734 - val_acc: 0.8726\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9882\n",
      "Epoch 00058: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0454 - acc: 0.9882 - val_loss: 0.7650 - val_acc: 0.8696\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9863\n",
      "Epoch 00059: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0486 - acc: 0.9863 - val_loss: 0.7539 - val_acc: 0.8693\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9882\n",
      "Epoch 00060: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0457 - acc: 0.9882 - val_loss: 0.8241 - val_acc: 0.8672\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9885\n",
      "Epoch 00061: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0422 - acc: 0.9885 - val_loss: 0.8681 - val_acc: 0.8574\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9868\n",
      "Epoch 00062: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0475 - acc: 0.9868 - val_loss: 0.7490 - val_acc: 0.8749\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9889\n",
      "Epoch 00063: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0415 - acc: 0.9889 - val_loss: 0.8029 - val_acc: 0.8689\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9865\n",
      "Epoch 00064: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0485 - acc: 0.9865 - val_loss: 0.8023 - val_acc: 0.8758\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9900\n",
      "Epoch 00065: val_loss did not improve from 0.58052\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0384 - acc: 0.9900 - val_loss: 0.7501 - val_acc: 0.8677\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 824us/sample - loss: 0.6998 - acc: 0.8102\n",
      "Loss: 0.6997917437355342 Accuracy: 0.81017655\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2025 - acc: 0.2750\n",
      "Epoch 00001: val_loss improved from inf to 1.50535, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/001-1.5053.hdf5\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 2.2024 - acc: 0.2750 - val_loss: 1.5053 - val_acc: 0.5164\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4457 - acc: 0.5276\n",
      "Epoch 00002: val_loss improved from 1.50535 to 1.23907, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/002-1.2391.hdf5\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 1.4457 - acc: 0.5275 - val_loss: 1.2391 - val_acc: 0.6157\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2522 - acc: 0.6011\n",
      "Epoch 00003: val_loss improved from 1.23907 to 1.14018, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/003-1.1402.hdf5\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 1.2524 - acc: 0.6011 - val_loss: 1.1402 - val_acc: 0.6604\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0600 - acc: 0.6718\n",
      "Epoch 00004: val_loss improved from 1.14018 to 0.90156, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/004-0.9016.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 1.0601 - acc: 0.6718 - val_loss: 0.9016 - val_acc: 0.7284\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8818 - acc: 0.7311\n",
      "Epoch 00005: val_loss improved from 0.90156 to 0.74294, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/005-0.7429.hdf5\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.8818 - acc: 0.7310 - val_loss: 0.7429 - val_acc: 0.7799\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7644 - acc: 0.7692\n",
      "Epoch 00006: val_loss improved from 0.74294 to 0.71855, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/006-0.7186.hdf5\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.7643 - acc: 0.7692 - val_loss: 0.7186 - val_acc: 0.7880\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6640 - acc: 0.8016\n",
      "Epoch 00007: val_loss improved from 0.71855 to 0.61094, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/007-0.6109.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.6640 - acc: 0.8016 - val_loss: 0.6109 - val_acc: 0.8153\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5970 - acc: 0.8226\n",
      "Epoch 00008: val_loss improved from 0.61094 to 0.59072, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/008-0.5907.hdf5\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.5972 - acc: 0.8225 - val_loss: 0.5907 - val_acc: 0.8325\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5401 - acc: 0.8368\n",
      "Epoch 00009: val_loss improved from 0.59072 to 0.53762, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/009-0.5376.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.5402 - acc: 0.8368 - val_loss: 0.5376 - val_acc: 0.8442\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4920 - acc: 0.8546\n",
      "Epoch 00010: val_loss improved from 0.53762 to 0.51043, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/010-0.5104.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.4919 - acc: 0.8546 - val_loss: 0.5104 - val_acc: 0.8500\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4438 - acc: 0.8678\n",
      "Epoch 00011: val_loss improved from 0.51043 to 0.45594, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/011-0.4559.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.4437 - acc: 0.8678 - val_loss: 0.4559 - val_acc: 0.8744\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4131 - acc: 0.8746\n",
      "Epoch 00012: val_loss did not improve from 0.45594\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.4131 - acc: 0.8746 - val_loss: 0.4963 - val_acc: 0.8661\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3825 - acc: 0.8850\n",
      "Epoch 00013: val_loss improved from 0.45594 to 0.42204, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/013-0.4220.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.3825 - acc: 0.8850 - val_loss: 0.4220 - val_acc: 0.8875\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3473 - acc: 0.8949\n",
      "Epoch 00014: val_loss improved from 0.42204 to 0.41077, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/014-0.4108.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.3473 - acc: 0.8949 - val_loss: 0.4108 - val_acc: 0.8840\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3212 - acc: 0.9012\n",
      "Epoch 00015: val_loss did not improve from 0.41077\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.3212 - acc: 0.9012 - val_loss: 0.4197 - val_acc: 0.8819\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2967 - acc: 0.9079\n",
      "Epoch 00016: val_loss improved from 0.41077 to 0.39059, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/016-0.3906.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.2968 - acc: 0.9079 - val_loss: 0.3906 - val_acc: 0.8898\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2829 - acc: 0.9137\n",
      "Epoch 00017: val_loss improved from 0.39059 to 0.37952, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/017-0.3795.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.2829 - acc: 0.9137 - val_loss: 0.3795 - val_acc: 0.8954\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2633 - acc: 0.9205\n",
      "Epoch 00018: val_loss did not improve from 0.37952\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.2633 - acc: 0.9205 - val_loss: 0.3899 - val_acc: 0.8928\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2355 - acc: 0.9285\n",
      "Epoch 00019: val_loss did not improve from 0.37952\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.2355 - acc: 0.9285 - val_loss: 0.3859 - val_acc: 0.8968\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2226 - acc: 0.9305\n",
      "Epoch 00020: val_loss did not improve from 0.37952\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.2226 - acc: 0.9305 - val_loss: 0.4019 - val_acc: 0.8973\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2092 - acc: 0.9356\n",
      "Epoch 00021: val_loss did not improve from 0.37952\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.2092 - acc: 0.9356 - val_loss: 0.3826 - val_acc: 0.8952\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9400\n",
      "Epoch 00022: val_loss improved from 0.37952 to 0.37356, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_8_conv_checkpoint/022-0.3736.hdf5\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.1958 - acc: 0.9400 - val_loss: 0.3736 - val_acc: 0.9031\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1813 - acc: 0.9420\n",
      "Epoch 00023: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.1813 - acc: 0.9420 - val_loss: 0.4108 - val_acc: 0.8982\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9452\n",
      "Epoch 00024: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.1755 - acc: 0.9452 - val_loss: 0.3953 - val_acc: 0.8980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9488\n",
      "Epoch 00025: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.1609 - acc: 0.9488 - val_loss: 0.3784 - val_acc: 0.9059\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9500\n",
      "Epoch 00026: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.1551 - acc: 0.9500 - val_loss: 0.3741 - val_acc: 0.9061\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9536\n",
      "Epoch 00027: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.1412 - acc: 0.9536 - val_loss: 0.3812 - val_acc: 0.9050\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1350 - acc: 0.9569\n",
      "Epoch 00028: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.1350 - acc: 0.9569 - val_loss: 0.4075 - val_acc: 0.8991\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9595\n",
      "Epoch 00029: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.1253 - acc: 0.9595 - val_loss: 0.4180 - val_acc: 0.8989\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1217 - acc: 0.9600\n",
      "Epoch 00030: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.1217 - acc: 0.9600 - val_loss: 0.4161 - val_acc: 0.9078\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1156 - acc: 0.9618\n",
      "Epoch 00031: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.1156 - acc: 0.9618 - val_loss: 0.4037 - val_acc: 0.9075\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9639\n",
      "Epoch 00032: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.1092 - acc: 0.9638 - val_loss: 0.4696 - val_acc: 0.8924\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9627\n",
      "Epoch 00033: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.1172 - acc: 0.9627 - val_loss: 0.3928 - val_acc: 0.9078\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9684\n",
      "Epoch 00034: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.1005 - acc: 0.9684 - val_loss: 0.3805 - val_acc: 0.9136\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9691\n",
      "Epoch 00035: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0941 - acc: 0.9691 - val_loss: 0.4189 - val_acc: 0.9101\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9694\n",
      "Epoch 00036: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0949 - acc: 0.9694 - val_loss: 0.4127 - val_acc: 0.9071\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9690\n",
      "Epoch 00037: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0939 - acc: 0.9690 - val_loss: 0.4376 - val_acc: 0.9059\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9727\n",
      "Epoch 00038: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0853 - acc: 0.9727 - val_loss: 0.4291 - val_acc: 0.9101\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9736\n",
      "Epoch 00039: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0821 - acc: 0.9736 - val_loss: 0.4356 - val_acc: 0.9124\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9739\n",
      "Epoch 00040: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0795 - acc: 0.9739 - val_loss: 0.3949 - val_acc: 0.9185\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9765\n",
      "Epoch 00041: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0763 - acc: 0.9766 - val_loss: 0.4137 - val_acc: 0.9122\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9758\n",
      "Epoch 00042: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0736 - acc: 0.9758 - val_loss: 0.4689 - val_acc: 0.9085\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9751\n",
      "Epoch 00043: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0771 - acc: 0.9751 - val_loss: 0.4321 - val_acc: 0.9131\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9777\n",
      "Epoch 00044: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0695 - acc: 0.9777 - val_loss: 0.4175 - val_acc: 0.9152\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9783\n",
      "Epoch 00045: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0693 - acc: 0.9783 - val_loss: 0.4410 - val_acc: 0.9147\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9787\n",
      "Epoch 00046: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0669 - acc: 0.9788 - val_loss: 0.4635 - val_acc: 0.9092\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9779\n",
      "Epoch 00047: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0687 - acc: 0.9779 - val_loss: 0.4247 - val_acc: 0.9154\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9801\n",
      "Epoch 00048: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0621 - acc: 0.9801 - val_loss: 0.4434 - val_acc: 0.9138\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9795\n",
      "Epoch 00049: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0640 - acc: 0.9795 - val_loss: 0.4531 - val_acc: 0.9180\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9808\n",
      "Epoch 00050: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0620 - acc: 0.9808 - val_loss: 0.4366 - val_acc: 0.9161\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9812\n",
      "Epoch 00051: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0605 - acc: 0.9812 - val_loss: 0.4160 - val_acc: 0.9189\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9805\n",
      "Epoch 00052: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0610 - acc: 0.9805 - val_loss: 0.4128 - val_acc: 0.9119\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9817\n",
      "Epoch 00053: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0580 - acc: 0.9817 - val_loss: 0.4262 - val_acc: 0.9161\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9824\n",
      "Epoch 00054: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0546 - acc: 0.9824 - val_loss: 0.4305 - val_acc: 0.9180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9816\n",
      "Epoch 00055: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0593 - acc: 0.9816 - val_loss: 0.4739 - val_acc: 0.9140\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9840\n",
      "Epoch 00056: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0524 - acc: 0.9840 - val_loss: 0.4287 - val_acc: 0.9187\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9852\n",
      "Epoch 00057: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0510 - acc: 0.9852 - val_loss: 0.4505 - val_acc: 0.9152\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9824\n",
      "Epoch 00058: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0565 - acc: 0.9824 - val_loss: 0.4310 - val_acc: 0.9196\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9853\n",
      "Epoch 00059: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0491 - acc: 0.9853 - val_loss: 0.4474 - val_acc: 0.9217\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9840\n",
      "Epoch 00060: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0532 - acc: 0.9840 - val_loss: 0.4304 - val_acc: 0.9189\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9871\n",
      "Epoch 00061: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0445 - acc: 0.9871 - val_loss: 0.4715 - val_acc: 0.9138\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9840\n",
      "Epoch 00062: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 68s 2ms/sample - loss: 0.0518 - acc: 0.9840 - val_loss: 0.4555 - val_acc: 0.9159\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9862\n",
      "Epoch 00063: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0462 - acc: 0.9862 - val_loss: 0.4362 - val_acc: 0.9187\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9869\n",
      "Epoch 00064: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0454 - acc: 0.9869 - val_loss: 0.4336 - val_acc: 0.9222\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9866\n",
      "Epoch 00065: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0465 - acc: 0.9866 - val_loss: 0.4770 - val_acc: 0.9189\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9868\n",
      "Epoch 00066: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0447 - acc: 0.9868 - val_loss: 0.4265 - val_acc: 0.9189\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9868\n",
      "Epoch 00067: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0449 - acc: 0.9868 - val_loss: 0.4536 - val_acc: 0.9166\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9876\n",
      "Epoch 00068: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0412 - acc: 0.9876 - val_loss: 0.4574 - val_acc: 0.9252\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9859\n",
      "Epoch 00069: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0453 - acc: 0.9859 - val_loss: 0.4431 - val_acc: 0.9203\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9875\n",
      "Epoch 00070: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0405 - acc: 0.9875 - val_loss: 0.4949 - val_acc: 0.9166\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9875\n",
      "Epoch 00071: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 69s 2ms/sample - loss: 0.0417 - acc: 0.9875 - val_loss: 0.5323 - val_acc: 0.9082\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9866\n",
      "Epoch 00072: val_loss did not improve from 0.37356\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0448 - acc: 0.9866 - val_loss: 0.4429 - val_acc: 0.9227\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 871us/sample - loss: 0.4463 - acc: 0.8708\n",
      "Loss: 0.44626714471468426 Accuracy: 0.87082034\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1511 - acc: 0.2899\n",
      "Epoch 00001: val_loss improved from inf to 1.39764, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_9_conv_checkpoint/001-1.3976.hdf5\n",
      "36805/36805 [==============================] - 78s 2ms/sample - loss: 2.1511 - acc: 0.2899 - val_loss: 1.3976 - val_acc: 0.5525\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3180 - acc: 0.5744\n",
      "Epoch 00002: val_loss improved from 1.39764 to 1.13474, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_9_conv_checkpoint/002-1.1347.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.3179 - acc: 0.5744 - val_loss: 1.1347 - val_acc: 0.6403\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0758 - acc: 0.6583\n",
      "Epoch 00003: val_loss improved from 1.13474 to 1.04298, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_9_conv_checkpoint/003-1.0430.hdf5\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 1.0757 - acc: 0.6583 - val_loss: 1.0430 - val_acc: 0.6820\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9078 - acc: 0.7144\n",
      "Epoch 00004: val_loss improved from 1.04298 to 0.89049, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_9_conv_checkpoint/004-0.8905.hdf5\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.9077 - acc: 0.7144 - val_loss: 0.8905 - val_acc: 0.7328\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7747 - acc: 0.7572\n",
      "Epoch 00005: val_loss improved from 0.89049 to 0.78449, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_9_conv_checkpoint/005-0.7845.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.7746 - acc: 0.7572 - val_loss: 0.7845 - val_acc: 0.7706\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6570 - acc: 0.7961\n",
      "Epoch 00006: val_loss improved from 0.78449 to 0.56659, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_9_conv_checkpoint/006-0.5666.hdf5\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.6570 - acc: 0.7961 - val_loss: 0.5666 - val_acc: 0.8451\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5601 - acc: 0.8274\n",
      "Epoch 00007: val_loss improved from 0.56659 to 0.53475, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_9_conv_checkpoint/007-0.5347.hdf5\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.5601 - acc: 0.8275 - val_loss: 0.5347 - val_acc: 0.8586\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4776 - acc: 0.8545\n",
      "Epoch 00008: val_loss improved from 0.53475 to 0.44543, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_9_conv_checkpoint/008-0.4454.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.4776 - acc: 0.8545 - val_loss: 0.4454 - val_acc: 0.8821\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4152 - acc: 0.8711\n",
      "Epoch 00009: val_loss improved from 0.44543 to 0.38256, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_9_conv_checkpoint/009-0.3826.hdf5\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.4152 - acc: 0.8711 - val_loss: 0.3826 - val_acc: 0.8956\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3672 - acc: 0.8867\n",
      "Epoch 00010: val_loss improved from 0.38256 to 0.38114, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_9_conv_checkpoint/010-0.3811.hdf5\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.3672 - acc: 0.8867 - val_loss: 0.3811 - val_acc: 0.8856\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3228 - acc: 0.8984\n",
      "Epoch 00011: val_loss did not improve from 0.38114\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.3228 - acc: 0.8984 - val_loss: 0.4145 - val_acc: 0.8845\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2928 - acc: 0.9081\n",
      "Epoch 00012: val_loss did not improve from 0.38114\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2929 - acc: 0.9081 - val_loss: 0.4816 - val_acc: 0.8684\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2710 - acc: 0.9154\n",
      "Epoch 00013: val_loss improved from 0.38114 to 0.30365, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_9_conv_checkpoint/013-0.3037.hdf5\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.2710 - acc: 0.9153 - val_loss: 0.3037 - val_acc: 0.9159\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2504 - acc: 0.9206\n",
      "Epoch 00014: val_loss did not improve from 0.30365\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2504 - acc: 0.9206 - val_loss: 0.3392 - val_acc: 0.9185\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2259 - acc: 0.9276\n",
      "Epoch 00015: val_loss did not improve from 0.30365\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.2259 - acc: 0.9276 - val_loss: 0.3223 - val_acc: 0.9145\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2097 - acc: 0.9323\n",
      "Epoch 00016: val_loss did not improve from 0.30365\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.2097 - acc: 0.9323 - val_loss: 0.3064 - val_acc: 0.9168\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1923 - acc: 0.9384\n",
      "Epoch 00017: val_loss improved from 0.30365 to 0.28068, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_9_conv_checkpoint/017-0.2807.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1923 - acc: 0.9384 - val_loss: 0.2807 - val_acc: 0.9304\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1792 - acc: 0.9420\n",
      "Epoch 00018: val_loss did not improve from 0.28068\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.1791 - acc: 0.9420 - val_loss: 0.2980 - val_acc: 0.9189\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1651 - acc: 0.9454\n",
      "Epoch 00019: val_loss did not improve from 0.28068\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1651 - acc: 0.9454 - val_loss: 0.2850 - val_acc: 0.9278\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1541 - acc: 0.9480\n",
      "Epoch 00020: val_loss did not improve from 0.28068\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1541 - acc: 0.9480 - val_loss: 0.2845 - val_acc: 0.9311\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1413 - acc: 0.9535\n",
      "Epoch 00021: val_loss did not improve from 0.28068\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1412 - acc: 0.9535 - val_loss: 0.3036 - val_acc: 0.9252\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9563\n",
      "Epoch 00022: val_loss improved from 0.28068 to 0.27808, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_9_conv_checkpoint/022-0.2781.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1321 - acc: 0.9563 - val_loss: 0.2781 - val_acc: 0.9338\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9596\n",
      "Epoch 00023: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.1233 - acc: 0.9596 - val_loss: 0.3133 - val_acc: 0.9271\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9615\n",
      "Epoch 00024: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.1163 - acc: 0.9615 - val_loss: 0.3206 - val_acc: 0.9206\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1140 - acc: 0.9621\n",
      "Epoch 00025: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1140 - acc: 0.9622 - val_loss: 0.2838 - val_acc: 0.9345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9651\n",
      "Epoch 00026: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.1034 - acc: 0.9651 - val_loss: 0.3181 - val_acc: 0.9297\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9676\n",
      "Epoch 00027: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.1019 - acc: 0.9676 - val_loss: 0.3160 - val_acc: 0.9264\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9689\n",
      "Epoch 00028: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0915 - acc: 0.9689 - val_loss: 0.3249 - val_acc: 0.9264\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0890 - acc: 0.9709\n",
      "Epoch 00029: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0890 - acc: 0.9709 - val_loss: 0.3144 - val_acc: 0.9285\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9705\n",
      "Epoch 00030: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0856 - acc: 0.9705 - val_loss: 0.2949 - val_acc: 0.9324\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9724\n",
      "Epoch 00031: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0832 - acc: 0.9724 - val_loss: 0.3182 - val_acc: 0.9348\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9746\n",
      "Epoch 00032: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0742 - acc: 0.9747 - val_loss: 0.2936 - val_acc: 0.9355\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9745\n",
      "Epoch 00033: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0732 - acc: 0.9745 - val_loss: 0.2990 - val_acc: 0.9336\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9790\n",
      "Epoch 00034: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0668 - acc: 0.9790 - val_loss: 0.2976 - val_acc: 0.9380\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9759\n",
      "Epoch 00035: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0752 - acc: 0.9759 - val_loss: 0.2930 - val_acc: 0.9387\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9791\n",
      "Epoch 00036: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0640 - acc: 0.9791 - val_loss: 0.3001 - val_acc: 0.9359\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9800\n",
      "Epoch 00037: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0605 - acc: 0.9800 - val_loss: 0.3272 - val_acc: 0.9338\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9802\n",
      "Epoch 00038: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0628 - acc: 0.9802 - val_loss: 0.3200 - val_acc: 0.9399\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9798\n",
      "Epoch 00039: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0598 - acc: 0.9798 - val_loss: 0.2930 - val_acc: 0.9341\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9808\n",
      "Epoch 00040: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0562 - acc: 0.9808 - val_loss: 0.3162 - val_acc: 0.9422\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9820\n",
      "Epoch 00041: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0537 - acc: 0.9820 - val_loss: 0.3125 - val_acc: 0.9380\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9806\n",
      "Epoch 00042: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0566 - acc: 0.9806 - val_loss: 0.3211 - val_acc: 0.9373\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9839\n",
      "Epoch 00043: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0495 - acc: 0.9839 - val_loss: 0.3366 - val_acc: 0.9352\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9833\n",
      "Epoch 00044: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0510 - acc: 0.9833 - val_loss: 0.3234 - val_acc: 0.9343\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9845\n",
      "Epoch 00045: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0453 - acc: 0.9845 - val_loss: 0.3634 - val_acc: 0.9352\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9841\n",
      "Epoch 00046: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0479 - acc: 0.9841 - val_loss: 0.3488 - val_acc: 0.9413\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9847\n",
      "Epoch 00047: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0456 - acc: 0.9847 - val_loss: 0.3470 - val_acc: 0.9385\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9846\n",
      "Epoch 00048: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0463 - acc: 0.9846 - val_loss: 0.3143 - val_acc: 0.9380\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9848\n",
      "Epoch 00049: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0461 - acc: 0.9848 - val_loss: 0.3444 - val_acc: 0.9376\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9870\n",
      "Epoch 00050: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0388 - acc: 0.9870 - val_loss: 0.3051 - val_acc: 0.9385\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9867\n",
      "Epoch 00051: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0395 - acc: 0.9867 - val_loss: 0.3606 - val_acc: 0.9283\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9870\n",
      "Epoch 00052: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0392 - acc: 0.9870 - val_loss: 0.3180 - val_acc: 0.9378\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9864\n",
      "Epoch 00053: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0414 - acc: 0.9864 - val_loss: 0.3272 - val_acc: 0.9362\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9873\n",
      "Epoch 00054: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0395 - acc: 0.9873 - val_loss: 0.3313 - val_acc: 0.9378\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9862\n",
      "Epoch 00055: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0408 - acc: 0.9863 - val_loss: 0.3290 - val_acc: 0.9401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9887\n",
      "Epoch 00056: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0343 - acc: 0.9887 - val_loss: 0.3459 - val_acc: 0.9408\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9879\n",
      "Epoch 00057: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0364 - acc: 0.9879 - val_loss: 0.3244 - val_acc: 0.9399\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9889\n",
      "Epoch 00058: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0345 - acc: 0.9889 - val_loss: 0.3439 - val_acc: 0.9404\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9885\n",
      "Epoch 00059: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0357 - acc: 0.9885 - val_loss: 0.3243 - val_acc: 0.9392\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9903\n",
      "Epoch 00060: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0302 - acc: 0.9903 - val_loss: 0.3225 - val_acc: 0.9453\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9885\n",
      "Epoch 00061: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0350 - acc: 0.9885 - val_loss: 0.3252 - val_acc: 0.9422\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9904\n",
      "Epoch 00062: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0312 - acc: 0.9904 - val_loss: 0.3409 - val_acc: 0.9406\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9892\n",
      "Epoch 00063: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0343 - acc: 0.9892 - val_loss: 0.3501 - val_acc: 0.9434\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9883\n",
      "Epoch 00064: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0355 - acc: 0.9883 - val_loss: 0.3097 - val_acc: 0.9427\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9896\n",
      "Epoch 00065: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0326 - acc: 0.9896 - val_loss: 0.3202 - val_acc: 0.9448\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9910\n",
      "Epoch 00066: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0267 - acc: 0.9910 - val_loss: 0.3464 - val_acc: 0.9392\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9907\n",
      "Epoch 00067: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0300 - acc: 0.9907 - val_loss: 0.3239 - val_acc: 0.9390\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9903\n",
      "Epoch 00068: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0303 - acc: 0.9903 - val_loss: 0.3034 - val_acc: 0.9420\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9910\n",
      "Epoch 00069: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0286 - acc: 0.9910 - val_loss: 0.3254 - val_acc: 0.9418\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9911\n",
      "Epoch 00070: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0289 - acc: 0.9911 - val_loss: 0.3228 - val_acc: 0.9413\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9907\n",
      "Epoch 00071: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0283 - acc: 0.9907 - val_loss: 0.3262 - val_acc: 0.9420\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9890\n",
      "Epoch 00072: val_loss did not improve from 0.27808\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.0323 - acc: 0.9890 - val_loss: 0.3116 - val_acc: 0.9434\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 914us/sample - loss: 0.3063 - acc: 0.9153\n",
      "Loss: 0.3063253529779884 Accuracy: 0.9152648\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2412 - acc: 0.2622\n",
      "Epoch 00001: val_loss improved from inf to 1.41011, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/001-1.4101.hdf5\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 2.2412 - acc: 0.2622 - val_loss: 1.4101 - val_acc: 0.5451\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3025 - acc: 0.5777\n",
      "Epoch 00002: val_loss improved from 1.41011 to 0.98192, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/002-0.9819.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 1.3024 - acc: 0.5777 - val_loss: 0.9819 - val_acc: 0.6995\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0159 - acc: 0.6736\n",
      "Epoch 00003: val_loss improved from 0.98192 to 0.81740, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/003-0.8174.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 1.0159 - acc: 0.6736 - val_loss: 0.8174 - val_acc: 0.7463\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8464 - acc: 0.7286\n",
      "Epoch 00004: val_loss improved from 0.81740 to 0.64211, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/004-0.6421.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.8464 - acc: 0.7286 - val_loss: 0.6421 - val_acc: 0.8062\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6977 - acc: 0.7786\n",
      "Epoch 00005: val_loss improved from 0.64211 to 0.49821, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/005-0.4982.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.6977 - acc: 0.7786 - val_loss: 0.4982 - val_acc: 0.8563\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5729 - acc: 0.8185\n",
      "Epoch 00006: val_loss improved from 0.49821 to 0.44457, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/006-0.4446.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.5728 - acc: 0.8185 - val_loss: 0.4446 - val_acc: 0.8707\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4841 - acc: 0.8477\n",
      "Epoch 00007: val_loss improved from 0.44457 to 0.36499, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/007-0.3650.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.4842 - acc: 0.8477 - val_loss: 0.3650 - val_acc: 0.8977\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4116 - acc: 0.8714\n",
      "Epoch 00008: val_loss improved from 0.36499 to 0.33638, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/008-0.3364.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.4116 - acc: 0.8714 - val_loss: 0.3364 - val_acc: 0.9040\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3611 - acc: 0.8874\n",
      "Epoch 00009: val_loss improved from 0.33638 to 0.28237, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/009-0.2824.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.3612 - acc: 0.8874 - val_loss: 0.2824 - val_acc: 0.9196\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3202 - acc: 0.8985\n",
      "Epoch 00010: val_loss improved from 0.28237 to 0.26993, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/010-0.2699.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.3202 - acc: 0.8985 - val_loss: 0.2699 - val_acc: 0.9201\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2821 - acc: 0.9105\n",
      "Epoch 00011: val_loss improved from 0.26993 to 0.24678, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/011-0.2468.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.2821 - acc: 0.9106 - val_loss: 0.2468 - val_acc: 0.9287\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2571 - acc: 0.9193\n",
      "Epoch 00012: val_loss improved from 0.24678 to 0.21038, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/012-0.2104.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.2571 - acc: 0.9193 - val_loss: 0.2104 - val_acc: 0.9401\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.9242\n",
      "Epoch 00013: val_loss did not improve from 0.21038\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.2401 - acc: 0.9242 - val_loss: 0.2105 - val_acc: 0.9415\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2170 - acc: 0.9317\n",
      "Epoch 00014: val_loss did not improve from 0.21038\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.2170 - acc: 0.9317 - val_loss: 0.2573 - val_acc: 0.9248\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9337\n",
      "Epoch 00015: val_loss improved from 0.21038 to 0.19240, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/015-0.1924.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.2039 - acc: 0.9337 - val_loss: 0.1924 - val_acc: 0.9453\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1839 - acc: 0.9396\n",
      "Epoch 00016: val_loss improved from 0.19240 to 0.17864, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/016-0.1786.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1839 - acc: 0.9396 - val_loss: 0.1786 - val_acc: 0.9474\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1707 - acc: 0.9457\n",
      "Epoch 00017: val_loss did not improve from 0.17864\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1706 - acc: 0.9457 - val_loss: 0.1874 - val_acc: 0.9464\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1616 - acc: 0.9478\n",
      "Epoch 00018: val_loss did not improve from 0.17864\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1615 - acc: 0.9478 - val_loss: 0.2067 - val_acc: 0.9432\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1518 - acc: 0.9514\n",
      "Epoch 00019: val_loss improved from 0.17864 to 0.17682, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/019-0.1768.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1518 - acc: 0.9514 - val_loss: 0.1768 - val_acc: 0.9502\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1391 - acc: 0.9534\n",
      "Epoch 00020: val_loss did not improve from 0.17682\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1391 - acc: 0.9534 - val_loss: 0.2011 - val_acc: 0.9448\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9568\n",
      "Epoch 00021: val_loss did not improve from 0.17682\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1329 - acc: 0.9568 - val_loss: 0.1800 - val_acc: 0.9495\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9579\n",
      "Epoch 00022: val_loss improved from 0.17682 to 0.17243, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/022-0.1724.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1265 - acc: 0.9579 - val_loss: 0.1724 - val_acc: 0.9532\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9606\n",
      "Epoch 00023: val_loss did not improve from 0.17243\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1214 - acc: 0.9606 - val_loss: 0.1928 - val_acc: 0.9439\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9625\n",
      "Epoch 00024: val_loss did not improve from 0.17243\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1131 - acc: 0.9625 - val_loss: 0.1790 - val_acc: 0.9506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9653\n",
      "Epoch 00025: val_loss did not improve from 0.17243\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1027 - acc: 0.9653 - val_loss: 0.1954 - val_acc: 0.9502\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9649\n",
      "Epoch 00026: val_loss did not improve from 0.17243\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1039 - acc: 0.9649 - val_loss: 0.1957 - val_acc: 0.9483\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9658\n",
      "Epoch 00027: val_loss did not improve from 0.17243\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.1012 - acc: 0.9658 - val_loss: 0.1740 - val_acc: 0.9532\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9717\n",
      "Epoch 00028: val_loss improved from 0.17243 to 0.16759, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/028-0.1676.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0850 - acc: 0.9717 - val_loss: 0.1676 - val_acc: 0.9553\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9712\n",
      "Epoch 00029: val_loss did not improve from 0.16759\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0876 - acc: 0.9712 - val_loss: 0.1739 - val_acc: 0.9534\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9730\n",
      "Epoch 00030: val_loss did not improve from 0.16759\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0808 - acc: 0.9730 - val_loss: 0.1758 - val_acc: 0.9553\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9738\n",
      "Epoch 00031: val_loss did not improve from 0.16759\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0791 - acc: 0.9738 - val_loss: 0.2016 - val_acc: 0.9541\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9730\n",
      "Epoch 00032: val_loss did not improve from 0.16759\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0797 - acc: 0.9730 - val_loss: 0.1992 - val_acc: 0.9476\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9755\n",
      "Epoch 00033: val_loss did not improve from 0.16759\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0738 - acc: 0.9755 - val_loss: 0.1759 - val_acc: 0.9560\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9778\n",
      "Epoch 00034: val_loss improved from 0.16759 to 0.16244, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_10_conv_checkpoint/034-0.1624.hdf5\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0682 - acc: 0.9778 - val_loss: 0.1624 - val_acc: 0.9581\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9775\n",
      "Epoch 00035: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0668 - acc: 0.9775 - val_loss: 0.1816 - val_acc: 0.9539\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9790\n",
      "Epoch 00036: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0625 - acc: 0.9790 - val_loss: 0.1859 - val_acc: 0.9536\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9776\n",
      "Epoch 00037: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0639 - acc: 0.9776 - val_loss: 0.1823 - val_acc: 0.9557\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9796\n",
      "Epoch 00038: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0610 - acc: 0.9796 - val_loss: 0.1795 - val_acc: 0.9571\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9813\n",
      "Epoch 00039: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0569 - acc: 0.9813 - val_loss: 0.2102 - val_acc: 0.9536\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9803\n",
      "Epoch 00040: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0603 - acc: 0.9803 - val_loss: 0.1844 - val_acc: 0.9585\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9826\n",
      "Epoch 00041: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0514 - acc: 0.9826 - val_loss: 0.2037 - val_acc: 0.9553\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9818\n",
      "Epoch 00042: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0527 - acc: 0.9819 - val_loss: 0.1959 - val_acc: 0.9555\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9839\n",
      "Epoch 00043: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0485 - acc: 0.9839 - val_loss: 0.1979 - val_acc: 0.9557\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9840\n",
      "Epoch 00044: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0478 - acc: 0.9840 - val_loss: 0.1928 - val_acc: 0.9578\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9847\n",
      "Epoch 00045: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0474 - acc: 0.9846 - val_loss: 0.1903 - val_acc: 0.9562\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9853\n",
      "Epoch 00046: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0439 - acc: 0.9853 - val_loss: 0.1909 - val_acc: 0.9602\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9851\n",
      "Epoch 00047: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0450 - acc: 0.9851 - val_loss: 0.1901 - val_acc: 0.9550\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9863\n",
      "Epoch 00048: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0393 - acc: 0.9863 - val_loss: 0.1941 - val_acc: 0.9550\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9863\n",
      "Epoch 00049: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0401 - acc: 0.9863 - val_loss: 0.1998 - val_acc: 0.9604\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9870\n",
      "Epoch 00050: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0397 - acc: 0.9870 - val_loss: 0.1987 - val_acc: 0.9555\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9877\n",
      "Epoch 00051: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0393 - acc: 0.9877 - val_loss: 0.2113 - val_acc: 0.9567\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9872\n",
      "Epoch 00052: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0387 - acc: 0.9872 - val_loss: 0.1898 - val_acc: 0.9597\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0414 - acc: 0.9861\n",
      "Epoch 00053: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0414 - acc: 0.9861 - val_loss: 0.1739 - val_acc: 0.9578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9896\n",
      "Epoch 00054: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0323 - acc: 0.9896 - val_loss: 0.2064 - val_acc: 0.9576\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9883\n",
      "Epoch 00055: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0361 - acc: 0.9883 - val_loss: 0.1964 - val_acc: 0.9588\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9887\n",
      "Epoch 00056: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0341 - acc: 0.9887 - val_loss: 0.1985 - val_acc: 0.9555\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9889\n",
      "Epoch 00057: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0336 - acc: 0.9889 - val_loss: 0.1937 - val_acc: 0.9578\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9871\n",
      "Epoch 00058: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0386 - acc: 0.9871 - val_loss: 0.1834 - val_acc: 0.9609\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9886\n",
      "Epoch 00059: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0342 - acc: 0.9886 - val_loss: 0.1977 - val_acc: 0.9576\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9891\n",
      "Epoch 00060: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0323 - acc: 0.9891 - val_loss: 0.1959 - val_acc: 0.9597\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9903\n",
      "Epoch 00061: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0298 - acc: 0.9903 - val_loss: 0.2030 - val_acc: 0.9581\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9895\n",
      "Epoch 00062: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0316 - acc: 0.9895 - val_loss: 0.1864 - val_acc: 0.9616\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9902\n",
      "Epoch 00063: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0306 - acc: 0.9902 - val_loss: 0.1884 - val_acc: 0.9560\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9904\n",
      "Epoch 00064: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0302 - acc: 0.9904 - val_loss: 0.2118 - val_acc: 0.9576\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9906\n",
      "Epoch 00065: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0297 - acc: 0.9906 - val_loss: 0.1879 - val_acc: 0.9581\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9913\n",
      "Epoch 00066: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0260 - acc: 0.9913 - val_loss: 0.2216 - val_acc: 0.9555\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9902\n",
      "Epoch 00067: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0291 - acc: 0.9902 - val_loss: 0.2026 - val_acc: 0.9588\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9912\n",
      "Epoch 00068: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0263 - acc: 0.9912 - val_loss: 0.2167 - val_acc: 0.9581\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9904\n",
      "Epoch 00069: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0311 - acc: 0.9904 - val_loss: 0.2364 - val_acc: 0.9569\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9920\n",
      "Epoch 00070: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0252 - acc: 0.9920 - val_loss: 0.1849 - val_acc: 0.9627\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9916\n",
      "Epoch 00071: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0267 - acc: 0.9916 - val_loss: 0.2144 - val_acc: 0.9585\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0246 - acc: 0.9916\n",
      "Epoch 00072: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0246 - acc: 0.9916 - val_loss: 0.1911 - val_acc: 0.9620\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9933\n",
      "Epoch 00073: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0216 - acc: 0.9933 - val_loss: 0.2257 - val_acc: 0.9574\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9922\n",
      "Epoch 00074: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0243 - acc: 0.9922 - val_loss: 0.2024 - val_acc: 0.9611\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9920\n",
      "Epoch 00075: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0221 - acc: 0.9920 - val_loss: 0.2230 - val_acc: 0.9576\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9920\n",
      "Epoch 00076: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0238 - acc: 0.9920 - val_loss: 0.2255 - val_acc: 0.9574\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9926\n",
      "Epoch 00077: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0220 - acc: 0.9926 - val_loss: 0.1967 - val_acc: 0.9613\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9937\n",
      "Epoch 00078: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0203 - acc: 0.9937 - val_loss: 0.2078 - val_acc: 0.9616\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9922\n",
      "Epoch 00079: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0231 - acc: 0.9922 - val_loss: 0.2284 - val_acc: 0.9569\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9923\n",
      "Epoch 00080: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0237 - acc: 0.9923 - val_loss: 0.1892 - val_acc: 0.9625\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9934\n",
      "Epoch 00081: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0203 - acc: 0.9934 - val_loss: 0.2179 - val_acc: 0.9609\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9935\n",
      "Epoch 00082: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0195 - acc: 0.9935 - val_loss: 0.2152 - val_acc: 0.9592\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9931\n",
      "Epoch 00083: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0210 - acc: 0.9931 - val_loss: 0.1850 - val_acc: 0.9620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9933\n",
      "Epoch 00084: val_loss did not improve from 0.16244\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0198 - acc: 0.9933 - val_loss: 0.2202 - val_acc: 0.9574\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_10_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 926us/sample - loss: 0.2203 - acc: 0.9435\n",
      "Loss: 0.22033937996947753 Accuracy: 0.9435099\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1624 - acc: 0.2850\n",
      "Epoch 00001: val_loss improved from inf to 1.29230, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/001-1.2923.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 2.1624 - acc: 0.2850 - val_loss: 1.2923 - val_acc: 0.5875\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1597 - acc: 0.6193\n",
      "Epoch 00002: val_loss improved from 1.29230 to 0.79907, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/002-0.7991.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 1.1597 - acc: 0.6193 - val_loss: 0.7991 - val_acc: 0.7375\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8398 - acc: 0.7267\n",
      "Epoch 00003: val_loss improved from 0.79907 to 0.65294, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/003-0.6529.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.8397 - acc: 0.7267 - val_loss: 0.6529 - val_acc: 0.7829\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6609 - acc: 0.7853\n",
      "Epoch 00004: val_loss improved from 0.65294 to 0.45499, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/004-0.4550.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.6609 - acc: 0.7853 - val_loss: 0.4550 - val_acc: 0.8693\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5340 - acc: 0.8286\n",
      "Epoch 00005: val_loss improved from 0.45499 to 0.34783, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/005-0.3478.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.5340 - acc: 0.8287 - val_loss: 0.3478 - val_acc: 0.8926\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4479 - acc: 0.8557\n",
      "Epoch 00006: val_loss did not improve from 0.34783\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.4480 - acc: 0.8557 - val_loss: 0.3655 - val_acc: 0.8842\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3839 - acc: 0.8757\n",
      "Epoch 00007: val_loss improved from 0.34783 to 0.27370, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/007-0.2737.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.3839 - acc: 0.8757 - val_loss: 0.2737 - val_acc: 0.9152\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3399 - acc: 0.8902\n",
      "Epoch 00008: val_loss improved from 0.27370 to 0.24700, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/008-0.2470.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.3398 - acc: 0.8902 - val_loss: 0.2470 - val_acc: 0.9185\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2991 - acc: 0.9043\n",
      "Epoch 00009: val_loss improved from 0.24700 to 0.21429, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/009-0.2143.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.2991 - acc: 0.9043 - val_loss: 0.2143 - val_acc: 0.9320\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2716 - acc: 0.9124\n",
      "Epoch 00010: val_loss did not improve from 0.21429\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.2715 - acc: 0.9124 - val_loss: 0.2228 - val_acc: 0.9320\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2472 - acc: 0.9215\n",
      "Epoch 00011: val_loss improved from 0.21429 to 0.20412, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/011-0.2041.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.2472 - acc: 0.9215 - val_loss: 0.2041 - val_acc: 0.9392\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2261 - acc: 0.9272\n",
      "Epoch 00012: val_loss improved from 0.20412 to 0.17631, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/012-0.1763.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.2260 - acc: 0.9272 - val_loss: 0.1763 - val_acc: 0.9483\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9329\n",
      "Epoch 00013: val_loss improved from 0.17631 to 0.16953, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/013-0.1695.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.2044 - acc: 0.9329 - val_loss: 0.1695 - val_acc: 0.9478\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1914 - acc: 0.9380\n",
      "Epoch 00014: val_loss improved from 0.16953 to 0.16916, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/014-0.1692.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1914 - acc: 0.9380 - val_loss: 0.1692 - val_acc: 0.9485\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1745 - acc: 0.9427\n",
      "Epoch 00015: val_loss improved from 0.16916 to 0.15696, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/015-0.1570.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1745 - acc: 0.9428 - val_loss: 0.1570 - val_acc: 0.9520\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1631 - acc: 0.9466\n",
      "Epoch 00016: val_loss improved from 0.15696 to 0.14193, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/016-0.1419.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1631 - acc: 0.9466 - val_loss: 0.1419 - val_acc: 0.9604\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1528 - acc: 0.9505\n",
      "Epoch 00017: val_loss did not improve from 0.14193\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1528 - acc: 0.9506 - val_loss: 0.1813 - val_acc: 0.9469\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9525\n",
      "Epoch 00018: val_loss did not improve from 0.14193\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1449 - acc: 0.9525 - val_loss: 0.1556 - val_acc: 0.9564\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9561\n",
      "Epoch 00019: val_loss improved from 0.14193 to 0.13770, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/019-0.1377.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1320 - acc: 0.9561 - val_loss: 0.1377 - val_acc: 0.9609\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9608\n",
      "Epoch 00020: val_loss did not improve from 0.13770\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1229 - acc: 0.9608 - val_loss: 0.1545 - val_acc: 0.9583\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9612\n",
      "Epoch 00021: val_loss did not improve from 0.13770\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1192 - acc: 0.9612 - val_loss: 0.1390 - val_acc: 0.9595\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9648\n",
      "Epoch 00022: val_loss did not improve from 0.13770\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1063 - acc: 0.9648 - val_loss: 0.1423 - val_acc: 0.9564\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9660\n",
      "Epoch 00023: val_loss did not improve from 0.13770\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.1006 - acc: 0.9660 - val_loss: 0.1435 - val_acc: 0.9581\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9671\n",
      "Epoch 00024: val_loss improved from 0.13770 to 0.13250, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/024-0.1325.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0994 - acc: 0.9671 - val_loss: 0.1325 - val_acc: 0.9639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9691\n",
      "Epoch 00025: val_loss did not improve from 0.13250\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0922 - acc: 0.9691 - val_loss: 0.1484 - val_acc: 0.9576\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9700\n",
      "Epoch 00026: val_loss improved from 0.13250 to 0.13194, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/026-0.1319.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0875 - acc: 0.9700 - val_loss: 0.1319 - val_acc: 0.9627\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9727\n",
      "Epoch 00027: val_loss improved from 0.13194 to 0.13048, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/027-0.1305.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0836 - acc: 0.9727 - val_loss: 0.1305 - val_acc: 0.9616\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9745\n",
      "Epoch 00028: val_loss improved from 0.13048 to 0.12688, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/028-0.1269.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0758 - acc: 0.9745 - val_loss: 0.1269 - val_acc: 0.9637\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9742\n",
      "Epoch 00029: val_loss did not improve from 0.12688\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0760 - acc: 0.9742 - val_loss: 0.1474 - val_acc: 0.9616\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9753\n",
      "Epoch 00030: val_loss improved from 0.12688 to 0.11292, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_11_conv_checkpoint/030-0.1129.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0735 - acc: 0.9753 - val_loss: 0.1129 - val_acc: 0.9679\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9781\n",
      "Epoch 00031: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0656 - acc: 0.9781 - val_loss: 0.1276 - val_acc: 0.9662\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9780\n",
      "Epoch 00032: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0632 - acc: 0.9780 - val_loss: 0.1353 - val_acc: 0.9637\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9787\n",
      "Epoch 00033: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0609 - acc: 0.9787 - val_loss: 0.1521 - val_acc: 0.9665\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9810\n",
      "Epoch 00034: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0569 - acc: 0.9810 - val_loss: 0.1490 - val_acc: 0.9637\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9807\n",
      "Epoch 00035: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0565 - acc: 0.9807 - val_loss: 0.1286 - val_acc: 0.9660\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0528 - acc: 0.9828\n",
      "Epoch 00036: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0528 - acc: 0.9828 - val_loss: 0.1559 - val_acc: 0.9627\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9837\n",
      "Epoch 00037: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0491 - acc: 0.9837 - val_loss: 0.1463 - val_acc: 0.9641\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9836\n",
      "Epoch 00038: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0516 - acc: 0.9836 - val_loss: 0.1424 - val_acc: 0.9639\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9836\n",
      "Epoch 00039: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0453 - acc: 0.9836 - val_loss: 0.1637 - val_acc: 0.9623\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9828\n",
      "Epoch 00040: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0492 - acc: 0.9828 - val_loss: 0.1256 - val_acc: 0.9672\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9860\n",
      "Epoch 00041: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0427 - acc: 0.9860 - val_loss: 0.1461 - val_acc: 0.9653\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9835\n",
      "Epoch 00042: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0485 - acc: 0.9835 - val_loss: 0.1474 - val_acc: 0.9639\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9862\n",
      "Epoch 00043: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0397 - acc: 0.9862 - val_loss: 0.1422 - val_acc: 0.9646\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9874\n",
      "Epoch 00044: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0373 - acc: 0.9874 - val_loss: 0.1604 - val_acc: 0.9669\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9865\n",
      "Epoch 00045: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0390 - acc: 0.9866 - val_loss: 0.1508 - val_acc: 0.9660\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9873\n",
      "Epoch 00046: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0376 - acc: 0.9873 - val_loss: 0.1613 - val_acc: 0.9632\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9870\n",
      "Epoch 00047: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0404 - acc: 0.9870 - val_loss: 0.1579 - val_acc: 0.9630\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9881\n",
      "Epoch 00048: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0372 - acc: 0.9881 - val_loss: 0.1814 - val_acc: 0.9611\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9888\n",
      "Epoch 00049: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0330 - acc: 0.9888 - val_loss: 0.1813 - val_acc: 0.9634\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9885\n",
      "Epoch 00050: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0336 - acc: 0.9885 - val_loss: 0.1469 - val_acc: 0.9672\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9886\n",
      "Epoch 00051: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0326 - acc: 0.9886 - val_loss: 0.1604 - val_acc: 0.9660\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9893\n",
      "Epoch 00052: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0333 - acc: 0.9893 - val_loss: 0.1573 - val_acc: 0.9623\n",
      "Epoch 53/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9894\n",
      "Epoch 00053: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0310 - acc: 0.9894 - val_loss: 0.1795 - val_acc: 0.9672\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9896\n",
      "Epoch 00054: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0311 - acc: 0.9896 - val_loss: 0.1336 - val_acc: 0.9686\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9904\n",
      "Epoch 00055: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0282 - acc: 0.9904 - val_loss: 0.1481 - val_acc: 0.9674\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9903\n",
      "Epoch 00056: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0288 - acc: 0.9903 - val_loss: 0.1717 - val_acc: 0.9618\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9908\n",
      "Epoch 00057: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0282 - acc: 0.9908 - val_loss: 0.1388 - val_acc: 0.9695\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9916\n",
      "Epoch 00058: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0264 - acc: 0.9916 - val_loss: 0.1724 - val_acc: 0.9620\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9910\n",
      "Epoch 00059: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0264 - acc: 0.9910 - val_loss: 0.1592 - val_acc: 0.9665\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9914\n",
      "Epoch 00060: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0260 - acc: 0.9914 - val_loss: 0.1639 - val_acc: 0.9676\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9917\n",
      "Epoch 00061: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0244 - acc: 0.9917 - val_loss: 0.1817 - val_acc: 0.9623\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9927\n",
      "Epoch 00062: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0221 - acc: 0.9927 - val_loss: 0.1614 - val_acc: 0.9665\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9923\n",
      "Epoch 00063: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0226 - acc: 0.9923 - val_loss: 0.1673 - val_acc: 0.9688\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9926\n",
      "Epoch 00064: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0222 - acc: 0.9926 - val_loss: 0.1343 - val_acc: 0.9686\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9926\n",
      "Epoch 00065: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0222 - acc: 0.9926 - val_loss: 0.1525 - val_acc: 0.9688\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9932\n",
      "Epoch 00066: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0212 - acc: 0.9932 - val_loss: 0.1508 - val_acc: 0.9676\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9920\n",
      "Epoch 00067: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0240 - acc: 0.9920 - val_loss: 0.1461 - val_acc: 0.9648\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9932\n",
      "Epoch 00068: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0214 - acc: 0.9932 - val_loss: 0.1561 - val_acc: 0.9658\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9933\n",
      "Epoch 00069: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0207 - acc: 0.9933 - val_loss: 0.1561 - val_acc: 0.9660\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9929\n",
      "Epoch 00070: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0225 - acc: 0.9929 - val_loss: 0.1362 - val_acc: 0.9704\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9941\n",
      "Epoch 00071: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0188 - acc: 0.9941 - val_loss: 0.1899 - val_acc: 0.9639\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9929\n",
      "Epoch 00072: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0202 - acc: 0.9929 - val_loss: 0.1572 - val_acc: 0.9688\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9924\n",
      "Epoch 00073: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0236 - acc: 0.9924 - val_loss: 0.1520 - val_acc: 0.9690\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9945\n",
      "Epoch 00074: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0165 - acc: 0.9945 - val_loss: 0.1797 - val_acc: 0.9686\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9944\n",
      "Epoch 00075: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0182 - acc: 0.9944 - val_loss: 0.1729 - val_acc: 0.9651\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9953\n",
      "Epoch 00076: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0144 - acc: 0.9953 - val_loss: 0.1888 - val_acc: 0.9662\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9937\n",
      "Epoch 00077: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0186 - acc: 0.9937 - val_loss: 0.1707 - val_acc: 0.9709\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9931\n",
      "Epoch 00078: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0203 - acc: 0.9931 - val_loss: 0.1598 - val_acc: 0.9693\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9934\n",
      "Epoch 00079: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 72s 2ms/sample - loss: 0.0184 - acc: 0.9934 - val_loss: 0.1615 - val_acc: 0.9669\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9946\n",
      "Epoch 00080: val_loss did not improve from 0.11292\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0166 - acc: 0.9946 - val_loss: 0.1623 - val_acc: 0.9681\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_11_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 943us/sample - loss: 0.1658 - acc: 0.9499\n",
      "Loss: 0.16580953433227688 Accuracy: 0.9499481\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1723 - acc: 0.2893\n",
      "Epoch 00001: val_loss improved from inf to 1.16824, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_12_conv_checkpoint/001-1.1682.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 2.1722 - acc: 0.2894 - val_loss: 1.1682 - val_acc: 0.6129\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0787 - acc: 0.6436\n",
      "Epoch 00002: val_loss improved from 1.16824 to 0.71270, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_12_conv_checkpoint/002-0.7127.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.0786 - acc: 0.6436 - val_loss: 0.7127 - val_acc: 0.7715\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7473 - acc: 0.7564\n",
      "Epoch 00003: val_loss improved from 0.71270 to 0.63742, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_12_conv_checkpoint/003-0.6374.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.7472 - acc: 0.7565 - val_loss: 0.6374 - val_acc: 0.7855\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5719 - acc: 0.8157\n",
      "Epoch 00004: val_loss improved from 0.63742 to 0.35986, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_12_conv_checkpoint/004-0.3599.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5719 - acc: 0.8157 - val_loss: 0.3599 - val_acc: 0.8842\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4445 - acc: 0.8563\n",
      "Epoch 00005: val_loss improved from 0.35986 to 0.30956, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_12_conv_checkpoint/005-0.3096.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4444 - acc: 0.8563 - val_loss: 0.3096 - val_acc: 0.9017\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3653 - acc: 0.8837\n",
      "Epoch 00006: val_loss improved from 0.30956 to 0.22251, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_12_conv_checkpoint/006-0.2225.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3653 - acc: 0.8837 - val_loss: 0.2225 - val_acc: 0.9331\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3074 - acc: 0.9002\n",
      "Epoch 00007: val_loss improved from 0.22251 to 0.22000, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_12_conv_checkpoint/007-0.2200.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3074 - acc: 0.9001 - val_loss: 0.2200 - val_acc: 0.9338\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2763 - acc: 0.9108\n",
      "Epoch 00008: val_loss improved from 0.22000 to 0.19689, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_12_conv_checkpoint/008-0.1969.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2763 - acc: 0.9109 - val_loss: 0.1969 - val_acc: 0.9415\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2477 - acc: 0.9178\n",
      "Epoch 00009: val_loss did not improve from 0.19689\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2478 - acc: 0.9178 - val_loss: 0.2114 - val_acc: 0.9334\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2231 - acc: 0.9270\n",
      "Epoch 00010: val_loss improved from 0.19689 to 0.17119, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_12_conv_checkpoint/010-0.1712.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2231 - acc: 0.9270 - val_loss: 0.1712 - val_acc: 0.9490\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1985 - acc: 0.9344\n",
      "Epoch 00011: val_loss did not improve from 0.17119\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1985 - acc: 0.9344 - val_loss: 0.1829 - val_acc: 0.9427\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1890 - acc: 0.9376\n",
      "Epoch 00012: val_loss improved from 0.17119 to 0.16353, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_12_conv_checkpoint/012-0.1635.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1890 - acc: 0.9376 - val_loss: 0.1635 - val_acc: 0.9502\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9415\n",
      "Epoch 00013: val_loss did not improve from 0.16353\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1735 - acc: 0.9415 - val_loss: 0.1691 - val_acc: 0.9495\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1598 - acc: 0.9474\n",
      "Epoch 00014: val_loss improved from 0.16353 to 0.14154, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_12_conv_checkpoint/014-0.1415.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1598 - acc: 0.9474 - val_loss: 0.1415 - val_acc: 0.9546\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9540\n",
      "Epoch 00015: val_loss did not improve from 0.14154\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1394 - acc: 0.9539 - val_loss: 0.1999 - val_acc: 0.9448\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9518\n",
      "Epoch 00016: val_loss did not improve from 0.14154\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1437 - acc: 0.9518 - val_loss: 0.1455 - val_acc: 0.9553\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9554\n",
      "Epoch 00017: val_loss did not improve from 0.14154\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1300 - acc: 0.9554 - val_loss: 0.2162 - val_acc: 0.9399\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1218 - acc: 0.9603\n",
      "Epoch 00018: val_loss did not improve from 0.14154\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1218 - acc: 0.9603 - val_loss: 0.1540 - val_acc: 0.9543\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9635\n",
      "Epoch 00019: val_loss improved from 0.14154 to 0.11940, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_12_conv_checkpoint/019-0.1194.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1078 - acc: 0.9635 - val_loss: 0.1194 - val_acc: 0.9634\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9649\n",
      "Epoch 00020: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1022 - acc: 0.9649 - val_loss: 0.1615 - val_acc: 0.9515\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9666\n",
      "Epoch 00021: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1020 - acc: 0.9666 - val_loss: 0.1570 - val_acc: 0.9532\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9705\n",
      "Epoch 00022: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0877 - acc: 0.9705 - val_loss: 0.1446 - val_acc: 0.9564\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9729\n",
      "Epoch 00023: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0820 - acc: 0.9729 - val_loss: 0.1439 - val_acc: 0.9564\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9735\n",
      "Epoch 00024: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0782 - acc: 0.9735 - val_loss: 0.1333 - val_acc: 0.9599\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9736\n",
      "Epoch 00025: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0794 - acc: 0.9736 - val_loss: 0.1220 - val_acc: 0.9641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9768\n",
      "Epoch 00026: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0700 - acc: 0.9768 - val_loss: 0.1516 - val_acc: 0.9571\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9779\n",
      "Epoch 00027: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0674 - acc: 0.9779 - val_loss: 0.1346 - val_acc: 0.9606\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9791\n",
      "Epoch 00028: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0626 - acc: 0.9791 - val_loss: 0.1450 - val_acc: 0.9630\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9800\n",
      "Epoch 00029: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0585 - acc: 0.9800 - val_loss: 0.1597 - val_acc: 0.9604\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9797\n",
      "Epoch 00030: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0614 - acc: 0.9797 - val_loss: 0.1412 - val_acc: 0.9623\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9822\n",
      "Epoch 00031: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0515 - acc: 0.9822 - val_loss: 0.1381 - val_acc: 0.9651\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9813\n",
      "Epoch 00032: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0542 - acc: 0.9813 - val_loss: 0.1712 - val_acc: 0.9592\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9831\n",
      "Epoch 00033: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0499 - acc: 0.9831 - val_loss: 0.1543 - val_acc: 0.9602\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9840\n",
      "Epoch 00034: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0458 - acc: 0.9841 - val_loss: 0.1467 - val_acc: 0.9639\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9846\n",
      "Epoch 00035: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0461 - acc: 0.9846 - val_loss: 0.1727 - val_acc: 0.9588\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9852\n",
      "Epoch 00036: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0432 - acc: 0.9852 - val_loss: 0.1406 - val_acc: 0.9648\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9862\n",
      "Epoch 00037: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0424 - acc: 0.9862 - val_loss: 0.1542 - val_acc: 0.9609\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9862\n",
      "Epoch 00038: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0389 - acc: 0.9863 - val_loss: 0.1395 - val_acc: 0.9632\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9864\n",
      "Epoch 00039: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0419 - acc: 0.9864 - val_loss: 0.1379 - val_acc: 0.9648\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9870\n",
      "Epoch 00040: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0378 - acc: 0.9870 - val_loss: 0.1558 - val_acc: 0.9609\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9880\n",
      "Epoch 00041: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0374 - acc: 0.9880 - val_loss: 0.1684 - val_acc: 0.9613\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9885\n",
      "Epoch 00042: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0324 - acc: 0.9885 - val_loss: 0.1456 - val_acc: 0.9653\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9885\n",
      "Epoch 00043: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0363 - acc: 0.9885 - val_loss: 0.1315 - val_acc: 0.9660\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9888\n",
      "Epoch 00044: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0335 - acc: 0.9888 - val_loss: 0.1444 - val_acc: 0.9655\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9891\n",
      "Epoch 00045: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0339 - acc: 0.9891 - val_loss: 0.1692 - val_acc: 0.9590\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9865\n",
      "Epoch 00046: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0441 - acc: 0.9865 - val_loss: 0.1543 - val_acc: 0.9646\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9904\n",
      "Epoch 00047: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0291 - acc: 0.9904 - val_loss: 0.1673 - val_acc: 0.9613\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9907\n",
      "Epoch 00048: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0292 - acc: 0.9907 - val_loss: 0.1484 - val_acc: 0.9658\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9907\n",
      "Epoch 00049: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0275 - acc: 0.9907 - val_loss: 0.1441 - val_acc: 0.9625\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9910\n",
      "Epoch 00050: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0274 - acc: 0.9910 - val_loss: 0.1677 - val_acc: 0.9630\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 00051: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0252 - acc: 0.9917 - val_loss: 0.1937 - val_acc: 0.9644\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9915\n",
      "Epoch 00052: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0264 - acc: 0.9916 - val_loss: 0.1326 - val_acc: 0.9681\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9912\n",
      "Epoch 00053: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0264 - acc: 0.9912 - val_loss: 0.1405 - val_acc: 0.9676\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9926\n",
      "Epoch 00054: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0228 - acc: 0.9926 - val_loss: 0.1616 - val_acc: 0.9644\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9921\n",
      "Epoch 00055: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0232 - acc: 0.9921 - val_loss: 0.1529 - val_acc: 0.9672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9916\n",
      "Epoch 00056: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0250 - acc: 0.9916 - val_loss: 0.1682 - val_acc: 0.9616\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9926\n",
      "Epoch 00057: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 0.0225 - acc: 0.9926 - val_loss: 0.2128 - val_acc: 0.9620\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9916\n",
      "Epoch 00058: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0253 - acc: 0.9916 - val_loss: 0.1606 - val_acc: 0.9672\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9929\n",
      "Epoch 00059: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0202 - acc: 0.9929 - val_loss: 0.1735 - val_acc: 0.9639\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9929\n",
      "Epoch 00060: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0230 - acc: 0.9929 - val_loss: 0.1543 - val_acc: 0.9651\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9937\n",
      "Epoch 00061: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0200 - acc: 0.9937 - val_loss: 0.1586 - val_acc: 0.9688\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9942\n",
      "Epoch 00062: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0187 - acc: 0.9942 - val_loss: 0.1687 - val_acc: 0.9646\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9930\n",
      "Epoch 00063: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0213 - acc: 0.9930 - val_loss: 0.2083 - val_acc: 0.9620\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9933\n",
      "Epoch 00064: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0195 - acc: 0.9933 - val_loss: 0.1638 - val_acc: 0.9674\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9942\n",
      "Epoch 00065: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0174 - acc: 0.9942 - val_loss: 0.1748 - val_acc: 0.9646\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9943\n",
      "Epoch 00066: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0191 - acc: 0.9943 - val_loss: 0.1588 - val_acc: 0.9674\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9941\n",
      "Epoch 00067: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0189 - acc: 0.9941 - val_loss: 0.1643 - val_acc: 0.9646\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9943\n",
      "Epoch 00068: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0186 - acc: 0.9943 - val_loss: 0.1756 - val_acc: 0.9651\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9940\n",
      "Epoch 00069: val_loss did not improve from 0.11940\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0202 - acc: 0.9940 - val_loss: 0.1747 - val_acc: 0.9658\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_12_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 959us/sample - loss: 0.1764 - acc: 0.9483\n",
      "Loss: 0.17644321271377933 Accuracy: 0.9482866\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0418 - acc: 0.3329\n",
      "Epoch 00001: val_loss improved from inf to 1.04063, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_13_conv_checkpoint/001-1.0406.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 2.0419 - acc: 0.3329 - val_loss: 1.0406 - val_acc: 0.6534\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9230 - acc: 0.6920\n",
      "Epoch 00002: val_loss improved from 1.04063 to 0.66953, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_13_conv_checkpoint/002-0.6695.hdf5\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.9232 - acc: 0.6919 - val_loss: 0.6695 - val_acc: 0.7782\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6247 - acc: 0.7929\n",
      "Epoch 00003: val_loss improved from 0.66953 to 0.41554, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_13_conv_checkpoint/003-0.4155.hdf5\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.6247 - acc: 0.7929 - val_loss: 0.4155 - val_acc: 0.8691\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4696 - acc: 0.8482\n",
      "Epoch 00004: val_loss improved from 0.41554 to 0.30520, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_13_conv_checkpoint/004-0.3052.hdf5\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.4696 - acc: 0.8482 - val_loss: 0.3052 - val_acc: 0.9019\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3738 - acc: 0.8779\n",
      "Epoch 00005: val_loss improved from 0.30520 to 0.25843, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_13_conv_checkpoint/005-0.2584.hdf5\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.3737 - acc: 0.8778 - val_loss: 0.2584 - val_acc: 0.9222\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3091 - acc: 0.9007\n",
      "Epoch 00006: val_loss improved from 0.25843 to 0.22361, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_13_conv_checkpoint/006-0.2236.hdf5\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.3091 - acc: 0.9007 - val_loss: 0.2236 - val_acc: 0.9297\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2641 - acc: 0.9137\n",
      "Epoch 00007: val_loss improved from 0.22361 to 0.20501, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_13_conv_checkpoint/007-0.2050.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2640 - acc: 0.9137 - val_loss: 0.2050 - val_acc: 0.9373\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2346 - acc: 0.9230\n",
      "Epoch 00008: val_loss improved from 0.20501 to 0.20236, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_13_conv_checkpoint/008-0.2024.hdf5\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.2346 - acc: 0.9230 - val_loss: 0.2024 - val_acc: 0.9371\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2046 - acc: 0.9314\n",
      "Epoch 00009: val_loss improved from 0.20236 to 0.16396, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_13_conv_checkpoint/009-0.1640.hdf5\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.2045 - acc: 0.9314 - val_loss: 0.1640 - val_acc: 0.9488\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9389\n",
      "Epoch 00010: val_loss did not improve from 0.16396\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.1841 - acc: 0.9389 - val_loss: 0.1770 - val_acc: 0.9455\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1570 - acc: 0.9486\n",
      "Epoch 00011: val_loss improved from 0.16396 to 0.15609, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_13_conv_checkpoint/011-0.1561.hdf5\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.1570 - acc: 0.9486 - val_loss: 0.1561 - val_acc: 0.9497\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1470 - acc: 0.9514\n",
      "Epoch 00012: val_loss improved from 0.15609 to 0.14640, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_13_conv_checkpoint/012-0.1464.hdf5\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.1470 - acc: 0.9514 - val_loss: 0.1464 - val_acc: 0.9525\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9573\n",
      "Epoch 00013: val_loss did not improve from 0.14640\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.1303 - acc: 0.9573 - val_loss: 0.1521 - val_acc: 0.9550\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9609\n",
      "Epoch 00014: val_loss did not improve from 0.14640\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1183 - acc: 0.9609 - val_loss: 0.1913 - val_acc: 0.9390\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9649\n",
      "Epoch 00015: val_loss did not improve from 0.14640\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1056 - acc: 0.9650 - val_loss: 0.1515 - val_acc: 0.9539\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9681\n",
      "Epoch 00016: val_loss improved from 0.14640 to 0.13707, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_13_conv_checkpoint/016-0.1371.hdf5\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0944 - acc: 0.9681 - val_loss: 0.1371 - val_acc: 0.9588\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9689\n",
      "Epoch 00017: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0943 - acc: 0.9689 - val_loss: 0.1489 - val_acc: 0.9569\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9732\n",
      "Epoch 00018: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0803 - acc: 0.9732 - val_loss: 0.1558 - val_acc: 0.9529\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9738\n",
      "Epoch 00019: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0773 - acc: 0.9738 - val_loss: 0.1708 - val_acc: 0.9550\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9774\n",
      "Epoch 00020: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0671 - acc: 0.9774 - val_loss: 0.1587 - val_acc: 0.9562\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9785\n",
      "Epoch 00021: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0627 - acc: 0.9785 - val_loss: 0.1508 - val_acc: 0.9576\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9798\n",
      "Epoch 00022: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0621 - acc: 0.9798 - val_loss: 0.1533 - val_acc: 0.9585\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9826\n",
      "Epoch 00023: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0531 - acc: 0.9826 - val_loss: 0.1744 - val_acc: 0.9569\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9835\n",
      "Epoch 00024: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0489 - acc: 0.9835 - val_loss: 0.1659 - val_acc: 0.9583\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9847\n",
      "Epoch 00025: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0462 - acc: 0.9847 - val_loss: 0.1737 - val_acc: 0.9553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9840\n",
      "Epoch 00026: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0468 - acc: 0.9840 - val_loss: 0.1773 - val_acc: 0.9520\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9855\n",
      "Epoch 00027: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0449 - acc: 0.9855 - val_loss: 0.1843 - val_acc: 0.9553\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9867\n",
      "Epoch 00028: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0408 - acc: 0.9867 - val_loss: 0.1552 - val_acc: 0.9597\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9876\n",
      "Epoch 00029: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0391 - acc: 0.9876 - val_loss: 0.1728 - val_acc: 0.9581\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9886\n",
      "Epoch 00030: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0357 - acc: 0.9886 - val_loss: 0.2439 - val_acc: 0.9460\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9880\n",
      "Epoch 00031: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0362 - acc: 0.9880 - val_loss: 0.2006 - val_acc: 0.9506\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9886\n",
      "Epoch 00032: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0362 - acc: 0.9886 - val_loss: 0.1645 - val_acc: 0.9597\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9896\n",
      "Epoch 00033: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0336 - acc: 0.9896 - val_loss: 0.2158 - val_acc: 0.9511\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9898\n",
      "Epoch 00034: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0332 - acc: 0.9898 - val_loss: 0.1785 - val_acc: 0.9571\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9912\n",
      "Epoch 00035: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0262 - acc: 0.9912 - val_loss: 0.1807 - val_acc: 0.9602\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9875\n",
      "Epoch 00036: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0407 - acc: 0.9875 - val_loss: 0.1647 - val_acc: 0.9613\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9913\n",
      "Epoch 00037: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0272 - acc: 0.9913 - val_loss: 0.1951 - val_acc: 0.9588\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9910\n",
      "Epoch 00038: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0282 - acc: 0.9910 - val_loss: 0.1671 - val_acc: 0.9618\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9921\n",
      "Epoch 00039: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0245 - acc: 0.9921 - val_loss: 0.2125 - val_acc: 0.9606\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9921\n",
      "Epoch 00040: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0252 - acc: 0.9921 - val_loss: 0.1889 - val_acc: 0.9604\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9917\n",
      "Epoch 00041: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0255 - acc: 0.9917 - val_loss: 0.1917 - val_acc: 0.9564\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9929\n",
      "Epoch 00042: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0231 - acc: 0.9929 - val_loss: 0.2105 - val_acc: 0.9578\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9938\n",
      "Epoch 00043: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0208 - acc: 0.9938 - val_loss: 0.1674 - val_acc: 0.9630\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9920\n",
      "Epoch 00044: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0255 - acc: 0.9920 - val_loss: 0.1874 - val_acc: 0.9569\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9947\n",
      "Epoch 00045: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0175 - acc: 0.9947 - val_loss: 0.1795 - val_acc: 0.9627\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9927\n",
      "Epoch 00046: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0241 - acc: 0.9927 - val_loss: 0.1898 - val_acc: 0.9606\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9943\n",
      "Epoch 00047: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0196 - acc: 0.9943 - val_loss: 0.2538 - val_acc: 0.9534\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9936\n",
      "Epoch 00048: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0202 - acc: 0.9936 - val_loss: 0.2242 - val_acc: 0.9625\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9933\n",
      "Epoch 00049: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0223 - acc: 0.9933 - val_loss: 0.1995 - val_acc: 0.9665\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9951\n",
      "Epoch 00050: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0168 - acc: 0.9951 - val_loss: 0.2268 - val_acc: 0.9618\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9953\n",
      "Epoch 00051: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0158 - acc: 0.9953 - val_loss: 0.3073 - val_acc: 0.9506\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9931\n",
      "Epoch 00052: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0230 - acc: 0.9931 - val_loss: 0.1945 - val_acc: 0.9620\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9946\n",
      "Epoch 00053: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0172 - acc: 0.9946 - val_loss: 0.2129 - val_acc: 0.9609\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9940\n",
      "Epoch 00054: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0195 - acc: 0.9940 - val_loss: 0.1919 - val_acc: 0.9667\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9956\n",
      "Epoch 00055: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0143 - acc: 0.9956 - val_loss: 0.1889 - val_acc: 0.9639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9949\n",
      "Epoch 00056: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0162 - acc: 0.9949 - val_loss: 0.2064 - val_acc: 0.9639\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9949\n",
      "Epoch 00057: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0161 - acc: 0.9949 - val_loss: 0.2177 - val_acc: 0.9602\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9942\n",
      "Epoch 00058: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0177 - acc: 0.9942 - val_loss: 0.1808 - val_acc: 0.9637\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9957\n",
      "Epoch 00059: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0159 - acc: 0.9957 - val_loss: 0.1957 - val_acc: 0.9581\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9954\n",
      "Epoch 00060: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0152 - acc: 0.9954 - val_loss: 0.2198 - val_acc: 0.9625\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9957\n",
      "Epoch 00061: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0138 - acc: 0.9957 - val_loss: 0.2029 - val_acc: 0.9620\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9952\n",
      "Epoch 00062: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.0154 - acc: 0.9952 - val_loss: 0.2497 - val_acc: 0.9604\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9948\n",
      "Epoch 00063: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0175 - acc: 0.9948 - val_loss: 0.1967 - val_acc: 0.9634\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9948\n",
      "Epoch 00064: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0184 - acc: 0.9948 - val_loss: 0.1619 - val_acc: 0.9653\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9969\n",
      "Epoch 00065: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0119 - acc: 0.9969 - val_loss: 0.1829 - val_acc: 0.9667\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9964\n",
      "Epoch 00066: val_loss did not improve from 0.13707\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.0125 - acc: 0.9964 - val_loss: 0.2164 - val_acc: 0.9599\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_13_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1985 - acc: 0.9437\n",
      "Loss: 0.19850728744534565 Accuracy: 0.94371754\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 14):\n",
    "    base = '1D_CNN_custom_pool_2_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_pool_2_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                4096016   \n",
      "=================================================================\n",
      "Total params: 4,137,488\n",
      "Trainable params: 4,137,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 781us/sample - loss: 1.5832 - acc: 0.5036\n",
      "Loss: 1.5832462274396901 Accuracy: 0.50363445\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_94 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,110,032\n",
      "Trainable params: 2,110,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 872us/sample - loss: 1.3960 - acc: 0.5597\n",
      "Loss: 1.396030033439367 Accuracy: 0.55970925\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,151,120\n",
      "Trainable params: 2,151,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 914us/sample - loss: 1.2224 - acc: 0.6233\n",
      "Loss: 1.222374301065661 Accuracy: 0.6232606\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,209,168\n",
      "Trainable params: 1,209,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 972us/sample - loss: 0.9725 - acc: 0.7084\n",
      "Loss: 0.9725124305530005 Accuracy: 0.7084112\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_109 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 779,216\n",
      "Trainable params: 779,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.6998 - acc: 0.8102\n",
      "Loss: 0.6997917437355342 Accuracy: 0.81017655\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_116 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 605,264\n",
      "Trainable params: 605,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.4463 - acc: 0.8708\n",
      "Loss: 0.44626714471468426 Accuracy: 0.87082034\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_124 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                253968    \n",
      "=================================================================\n",
      "Total params: 767,312\n",
      "Trainable params: 767,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.3063 - acc: 0.9153\n",
      "Loss: 0.3063253529779884 Accuracy: 0.9152648\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_10_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 968,272\n",
      "Trainable params: 968,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2203 - acc: 0.9435\n",
      "Loss: 0.22033937996947753 Accuracy: 0.9435099\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_11_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_143 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_126 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_127 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_128 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_129 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_130 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_131 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                61456     \n",
      "=================================================================\n",
      "Total params: 1,230,672\n",
      "Trainable params: 1,230,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1658 - acc: 0.9499\n",
      "Loss: 0.16580953433227688 Accuracy: 0.9499481\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_12_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_154 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_132 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_141 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_142 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,525,840\n",
      "Trainable params: 1,525,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1764 - acc: 0.9483\n",
      "Loss: 0.17644321271377933 Accuracy: 0.9482866\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_13_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_166 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_149 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_150 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_151 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_152 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_154 (MaxPoolin (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                24592     \n",
      "=================================================================\n",
      "Total params: 2,177,616\n",
      "Trainable params: 2,177,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1985 - acc: 0.9437\n",
      "Loss: 0.19850728744534565 Accuracy: 0.94371754\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_pool_2_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 14):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_pool_2_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                4096016   \n",
      "=================================================================\n",
      "Total params: 4,137,488\n",
      "Trainable params: 4,137,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 961us/sample - loss: 3.6493 - acc: 0.5092\n",
      "Loss: 3.6493440891475815 Accuracy: 0.50924194\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_94 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,110,032\n",
      "Trainable params: 2,110,032\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 993us/sample - loss: 2.7457 - acc: 0.6023\n",
      "Loss: 2.745656345096085 Accuracy: 0.60228455\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,151,120\n",
      "Trainable params: 2,151,120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 2.3843 - acc: 0.6725\n",
      "Loss: 2.3842678971751083 Accuracy: 0.67248183\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,209,168\n",
      "Trainable params: 1,209,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.6249 - acc: 0.7578\n",
      "Loss: 1.624868957176882 Accuracy: 0.7578401\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_109 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 779,216\n",
      "Trainable params: 779,216\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.9395 - acc: 0.8303\n",
      "Loss: 0.9394520367912538 Accuracy: 0.8303219\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_116 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 605,264\n",
      "Trainable params: 605,264\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.5614 - acc: 0.8966\n",
      "Loss: 0.5613918216552813 Accuracy: 0.8965732\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_124 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                253968    \n",
      "=================================================================\n",
      "Total params: 767,312\n",
      "Trainable params: 767,312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3577 - acc: 0.9283\n",
      "Loss: 0.357661056255502 Accuracy: 0.9283489\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_10_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 968,272\n",
      "Trainable params: 968,272\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2807 - acc: 0.9472\n",
      "Loss: 0.2807300772808051 Accuracy: 0.94724816\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_11_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_143 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_126 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_127 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_128 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_129 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_130 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_131 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                61456     \n",
      "=================================================================\n",
      "Total params: 1,230,672\n",
      "Trainable params: 1,230,672\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2003 - acc: 0.9568\n",
      "Loss: 0.20034045435361655 Accuracy: 0.95680165\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_12_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_154 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_132 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_141 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_142 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,525,840\n",
      "Trainable params: 1,525,840\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2352 - acc: 0.9595\n",
      "Loss: 0.23519485304171997 Accuracy: 0.95950156\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_13_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_166 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_149 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_150 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_151 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_152 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_154 (MaxPoolin (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                24592     \n",
      "=================================================================\n",
      "Total params: 2,177,616\n",
      "Trainable params: 2,177,616\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2853 - acc: 0.9475\n",
      "Loss: 0.2853179139779496 Accuracy: 0.9474559\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 14):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
