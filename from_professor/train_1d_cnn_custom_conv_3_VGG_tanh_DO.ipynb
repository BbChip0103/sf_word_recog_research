{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_VGG_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                      activation='tanh', input_shape=input_shape)) \n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', \n",
    "                  activation='tanh')) \n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='tanh'))\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='tanh'))         \n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,396,624\n",
      "Trainable params: 16,396,624\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,498,320\n",
      "Trainable params: 5,498,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9831 - acc: 0.3694\n",
      "Epoch 00001: val_loss improved from inf to 1.64221, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_3_conv_checkpoint/001-1.6422.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.9831 - acc: 0.3694 - val_loss: 1.6422 - val_acc: 0.4852\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4150 - acc: 0.5593\n",
      "Epoch 00002: val_loss improved from 1.64221 to 1.49858, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_3_conv_checkpoint/002-1.4986.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 1.4150 - acc: 0.5593 - val_loss: 1.4986 - val_acc: 0.5362\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1557 - acc: 0.6451\n",
      "Epoch 00003: val_loss improved from 1.49858 to 1.47973, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_3_conv_checkpoint/003-1.4797.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 1.1557 - acc: 0.6451 - val_loss: 1.4797 - val_acc: 0.5469\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9727 - acc: 0.7028\n",
      "Epoch 00004: val_loss improved from 1.47973 to 1.43566, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_3_conv_checkpoint/004-1.4357.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.9726 - acc: 0.7028 - val_loss: 1.4357 - val_acc: 0.5651\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8149 - acc: 0.7524\n",
      "Epoch 00005: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.8149 - acc: 0.7525 - val_loss: 1.4968 - val_acc: 0.5644\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6874 - acc: 0.7904\n",
      "Epoch 00006: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.6874 - acc: 0.7904 - val_loss: 1.4947 - val_acc: 0.5795\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5803 - acc: 0.8263\n",
      "Epoch 00007: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.5803 - acc: 0.8263 - val_loss: 1.5144 - val_acc: 0.5809\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4874 - acc: 0.8560\n",
      "Epoch 00008: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.4873 - acc: 0.8560 - val_loss: 1.5559 - val_acc: 0.5798\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4103 - acc: 0.8804\n",
      "Epoch 00009: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.4103 - acc: 0.8803 - val_loss: 1.5769 - val_acc: 0.5896\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3506 - acc: 0.8991\n",
      "Epoch 00010: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.3507 - acc: 0.8991 - val_loss: 1.6313 - val_acc: 0.5847\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3058 - acc: 0.9136\n",
      "Epoch 00011: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3058 - acc: 0.9136 - val_loss: 1.6635 - val_acc: 0.5891\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2649 - acc: 0.9257\n",
      "Epoch 00012: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2649 - acc: 0.9257 - val_loss: 1.7015 - val_acc: 0.5910\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2293 - acc: 0.9365\n",
      "Epoch 00013: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2293 - acc: 0.9366 - val_loss: 1.7197 - val_acc: 0.6042\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9447\n",
      "Epoch 00014: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2011 - acc: 0.9447 - val_loss: 1.7743 - val_acc: 0.5942\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1808 - acc: 0.9524\n",
      "Epoch 00015: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1809 - acc: 0.9524 - val_loss: 1.7757 - val_acc: 0.6075\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1608 - acc: 0.9576\n",
      "Epoch 00016: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1608 - acc: 0.9576 - val_loss: 1.8214 - val_acc: 0.6073\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9609\n",
      "Epoch 00017: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1483 - acc: 0.9609 - val_loss: 1.9042 - val_acc: 0.5991\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9660\n",
      "Epoch 00018: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1333 - acc: 0.9660 - val_loss: 1.9208 - val_acc: 0.6033\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1264 - acc: 0.9674\n",
      "Epoch 00019: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1264 - acc: 0.9674 - val_loss: 1.9188 - val_acc: 0.6061\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9695\n",
      "Epoch 00020: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1160 - acc: 0.9695 - val_loss: 1.9211 - val_acc: 0.6110\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9727\n",
      "Epoch 00021: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1045 - acc: 0.9727 - val_loss: 1.9809 - val_acc: 0.6040\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9757\n",
      "Epoch 00022: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0993 - acc: 0.9757 - val_loss: 2.0023 - val_acc: 0.6129\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9743\n",
      "Epoch 00023: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1010 - acc: 0.9743 - val_loss: 1.9903 - val_acc: 0.6096\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9766\n",
      "Epoch 00024: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0898 - acc: 0.9766 - val_loss: 2.0336 - val_acc: 0.6124\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9795\n",
      "Epoch 00025: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0816 - acc: 0.9795 - val_loss: 2.1015 - val_acc: 0.6108\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9796\n",
      "Epoch 00026: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0851 - acc: 0.9796 - val_loss: 2.0709 - val_acc: 0.6171\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9801\n",
      "Epoch 00027: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0791 - acc: 0.9801 - val_loss: 2.0933 - val_acc: 0.6175\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9792\n",
      "Epoch 00028: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0803 - acc: 0.9792 - val_loss: 2.1576 - val_acc: 0.6150\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9803\n",
      "Epoch 00029: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0744 - acc: 0.9803 - val_loss: 2.1276 - val_acc: 0.6096\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9814\n",
      "Epoch 00030: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0736 - acc: 0.9814 - val_loss: 2.1552 - val_acc: 0.6131\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9826\n",
      "Epoch 00031: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0668 - acc: 0.9826 - val_loss: 2.0932 - val_acc: 0.6226\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9849\n",
      "Epoch 00032: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0606 - acc: 0.9849 - val_loss: 2.1923 - val_acc: 0.6159\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9833\n",
      "Epoch 00033: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0666 - acc: 0.9833 - val_loss: 2.1983 - val_acc: 0.6201\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9850\n",
      "Epoch 00034: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0599 - acc: 0.9850 - val_loss: 2.1666 - val_acc: 0.6210\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9864\n",
      "Epoch 00035: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0572 - acc: 0.9864 - val_loss: 2.2556 - val_acc: 0.6198\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9840\n",
      "Epoch 00036: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0638 - acc: 0.9840 - val_loss: 2.2751 - val_acc: 0.6112\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9845\n",
      "Epoch 00037: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0598 - acc: 0.9845 - val_loss: 2.2410 - val_acc: 0.6212\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9869\n",
      "Epoch 00038: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0544 - acc: 0.9869 - val_loss: 2.2422 - val_acc: 0.6231\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9873\n",
      "Epoch 00039: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0513 - acc: 0.9873 - val_loss: 2.3116 - val_acc: 0.6184\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9858\n",
      "Epoch 00040: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0543 - acc: 0.9858 - val_loss: 2.2573 - val_acc: 0.6306\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9855\n",
      "Epoch 00041: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0557 - acc: 0.9855 - val_loss: 2.2783 - val_acc: 0.6205\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9865\n",
      "Epoch 00042: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0516 - acc: 0.9866 - val_loss: 2.3100 - val_acc: 0.6292\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9875\n",
      "Epoch 00043: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0490 - acc: 0.9875 - val_loss: 2.3350 - val_acc: 0.6252\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9876\n",
      "Epoch 00044: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0487 - acc: 0.9876 - val_loss: 2.2983 - val_acc: 0.6273\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9882\n",
      "Epoch 00045: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0471 - acc: 0.9882 - val_loss: 2.3356 - val_acc: 0.6268\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9876\n",
      "Epoch 00046: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0483 - acc: 0.9876 - val_loss: 2.3300 - val_acc: 0.6205\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9876\n",
      "Epoch 00047: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0471 - acc: 0.9876 - val_loss: 2.3529 - val_acc: 0.6224\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9893\n",
      "Epoch 00048: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0460 - acc: 0.9893 - val_loss: 2.3679 - val_acc: 0.6240\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9878\n",
      "Epoch 00049: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0487 - acc: 0.9878 - val_loss: 2.3407 - val_acc: 0.6357\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9905\n",
      "Epoch 00050: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0401 - acc: 0.9905 - val_loss: 2.4270 - val_acc: 0.6194\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9886\n",
      "Epoch 00051: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0451 - acc: 0.9886 - val_loss: 2.3813 - val_acc: 0.6287\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9882\n",
      "Epoch 00052: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0458 - acc: 0.9882 - val_loss: 2.4214 - val_acc: 0.6222\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9895\n",
      "Epoch 00053: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0421 - acc: 0.9895 - val_loss: 2.3591 - val_acc: 0.6296\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9901\n",
      "Epoch 00054: val_loss did not improve from 1.43566\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0394 - acc: 0.9901 - val_loss: 2.4388 - val_acc: 0.6285\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 873us/sample - loss: 1.5296 - acc: 0.5381\n",
      "Loss: 1.5296365349958743 Accuracy: 0.5381101\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8271 - acc: 0.4186\n",
      "Epoch 00001: val_loss improved from inf to 1.43232, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_4_conv_checkpoint/001-1.4323.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.8270 - acc: 0.4186 - val_loss: 1.4323 - val_acc: 0.5660\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3101 - acc: 0.5975\n",
      "Epoch 00002: val_loss improved from 1.43232 to 1.20974, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_4_conv_checkpoint/002-1.2097.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.3101 - acc: 0.5974 - val_loss: 1.2097 - val_acc: 0.6280\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1205 - acc: 0.6626\n",
      "Epoch 00003: val_loss improved from 1.20974 to 1.12617, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_4_conv_checkpoint/003-1.1262.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.1204 - acc: 0.6626 - val_loss: 1.1262 - val_acc: 0.6627\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0011 - acc: 0.7005\n",
      "Epoch 00004: val_loss improved from 1.12617 to 1.10880, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_4_conv_checkpoint/004-1.1088.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 1.0010 - acc: 0.7006 - val_loss: 1.1088 - val_acc: 0.6781\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9050 - acc: 0.7304\n",
      "Epoch 00005: val_loss improved from 1.10880 to 1.07112, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_4_conv_checkpoint/005-1.0711.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.9049 - acc: 0.7304 - val_loss: 1.0711 - val_acc: 0.6776\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8262 - acc: 0.7559\n",
      "Epoch 00006: val_loss improved from 1.07112 to 1.04507, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_4_conv_checkpoint/006-1.0451.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.8261 - acc: 0.7559 - val_loss: 1.0451 - val_acc: 0.6904\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7553 - acc: 0.7771\n",
      "Epoch 00007: val_loss improved from 1.04507 to 1.02390, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_4_conv_checkpoint/007-1.0239.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.7553 - acc: 0.7771 - val_loss: 1.0239 - val_acc: 0.6988\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6980 - acc: 0.7942\n",
      "Epoch 00008: val_loss did not improve from 1.02390\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.6981 - acc: 0.7941 - val_loss: 1.0310 - val_acc: 0.7004\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6369 - acc: 0.8138\n",
      "Epoch 00009: val_loss did not improve from 1.02390\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.6369 - acc: 0.8138 - val_loss: 1.0275 - val_acc: 0.7028\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5841 - acc: 0.8294\n",
      "Epoch 00010: val_loss improved from 1.02390 to 0.99424, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_4_conv_checkpoint/010-0.9942.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5841 - acc: 0.8294 - val_loss: 0.9942 - val_acc: 0.7167\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5384 - acc: 0.8464\n",
      "Epoch 00011: val_loss improved from 0.99424 to 0.98789, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_4_conv_checkpoint/011-0.9879.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.5384 - acc: 0.8464 - val_loss: 0.9879 - val_acc: 0.7167\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4896 - acc: 0.8590\n",
      "Epoch 00012: val_loss did not improve from 0.98789\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4897 - acc: 0.8590 - val_loss: 0.9921 - val_acc: 0.7195\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8674\n",
      "Epoch 00013: val_loss improved from 0.98789 to 0.98544, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_4_conv_checkpoint/013-0.9854.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4590 - acc: 0.8674 - val_loss: 0.9854 - val_acc: 0.7247\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4175 - acc: 0.8804\n",
      "Epoch 00014: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.4174 - acc: 0.8805 - val_loss: 0.9904 - val_acc: 0.7247\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3871 - acc: 0.8908\n",
      "Epoch 00015: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3871 - acc: 0.8908 - val_loss: 0.9941 - val_acc: 0.7205\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3581 - acc: 0.8995\n",
      "Epoch 00016: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3581 - acc: 0.8996 - val_loss: 1.0124 - val_acc: 0.7216\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3361 - acc: 0.9047\n",
      "Epoch 00017: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3361 - acc: 0.9047 - val_loss: 1.0049 - val_acc: 0.7242\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3100 - acc: 0.9135\n",
      "Epoch 00018: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3100 - acc: 0.9135 - val_loss: 0.9919 - val_acc: 0.7314\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2843 - acc: 0.9213\n",
      "Epoch 00019: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2843 - acc: 0.9213 - val_loss: 1.0121 - val_acc: 0.7305\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2703 - acc: 0.9253\n",
      "Epoch 00020: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2703 - acc: 0.9253 - val_loss: 1.0152 - val_acc: 0.7263\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2532 - acc: 0.9291\n",
      "Epoch 00021: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2532 - acc: 0.9291 - val_loss: 1.0545 - val_acc: 0.7212\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2300 - acc: 0.9362\n",
      "Epoch 00022: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2300 - acc: 0.9362 - val_loss: 1.0447 - val_acc: 0.7300\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9398\n",
      "Epoch 00023: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2200 - acc: 0.9398 - val_loss: 1.0571 - val_acc: 0.7193\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2047 - acc: 0.9444\n",
      "Epoch 00024: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.2047 - acc: 0.9444 - val_loss: 1.0617 - val_acc: 0.7247\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1937 - acc: 0.9483\n",
      "Epoch 00025: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1938 - acc: 0.9482 - val_loss: 1.0633 - val_acc: 0.7319\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1849 - acc: 0.9498\n",
      "Epoch 00026: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1848 - acc: 0.9498 - val_loss: 1.0407 - val_acc: 0.7410\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9551\n",
      "Epoch 00027: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1703 - acc: 0.9551 - val_loss: 1.0548 - val_acc: 0.7331\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9557\n",
      "Epoch 00028: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1653 - acc: 0.9557 - val_loss: 1.0791 - val_acc: 0.7335\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9584\n",
      "Epoch 00029: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1549 - acc: 0.9584 - val_loss: 1.0829 - val_acc: 0.7331\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9602\n",
      "Epoch 00030: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1508 - acc: 0.9602 - val_loss: 1.1058 - val_acc: 0.7324\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9627\n",
      "Epoch 00031: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1414 - acc: 0.9627 - val_loss: 1.1211 - val_acc: 0.7386\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9651\n",
      "Epoch 00032: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1353 - acc: 0.9651 - val_loss: 1.1192 - val_acc: 0.7377\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9666\n",
      "Epoch 00033: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1269 - acc: 0.9666 - val_loss: 1.1057 - val_acc: 0.7345\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9665\n",
      "Epoch 00034: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1279 - acc: 0.9665 - val_loss: 1.1190 - val_acc: 0.7386\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9687\n",
      "Epoch 00035: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1207 - acc: 0.9687 - val_loss: 1.1175 - val_acc: 0.7389\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9685\n",
      "Epoch 00036: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1178 - acc: 0.9685 - val_loss: 1.1393 - val_acc: 0.7333\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1108 - acc: 0.9722\n",
      "Epoch 00037: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1108 - acc: 0.9722 - val_loss: 1.1431 - val_acc: 0.7370\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9715\n",
      "Epoch 00038: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1054 - acc: 0.9715 - val_loss: 1.1519 - val_acc: 0.7326\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9725\n",
      "Epoch 00039: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1051 - acc: 0.9725 - val_loss: 1.1275 - val_acc: 0.7442\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9728\n",
      "Epoch 00040: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.1063 - acc: 0.9728 - val_loss: 1.1271 - val_acc: 0.7414\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9753\n",
      "Epoch 00041: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0956 - acc: 0.9753 - val_loss: 1.1643 - val_acc: 0.7382\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9757\n",
      "Epoch 00042: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0932 - acc: 0.9757 - val_loss: 1.2132 - val_acc: 0.7372\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9749\n",
      "Epoch 00043: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0947 - acc: 0.9749 - val_loss: 1.1711 - val_acc: 0.7407\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9780\n",
      "Epoch 00044: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0868 - acc: 0.9780 - val_loss: 1.1475 - val_acc: 0.7421\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9774\n",
      "Epoch 00045: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0876 - acc: 0.9774 - val_loss: 1.2116 - val_acc: 0.7414\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9786\n",
      "Epoch 00046: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0830 - acc: 0.9786 - val_loss: 1.1700 - val_acc: 0.7424\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9776\n",
      "Epoch 00047: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0850 - acc: 0.9776 - val_loss: 1.2179 - val_acc: 0.7363\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9798\n",
      "Epoch 00048: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0790 - acc: 0.9798 - val_loss: 1.2159 - val_acc: 0.7389\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9778\n",
      "Epoch 00049: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0848 - acc: 0.9778 - val_loss: 1.2191 - val_acc: 0.7391\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9799\n",
      "Epoch 00050: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0761 - acc: 0.9799 - val_loss: 1.2024 - val_acc: 0.7463\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9805\n",
      "Epoch 00051: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0727 - acc: 0.9805 - val_loss: 1.2129 - val_acc: 0.7389\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9803\n",
      "Epoch 00052: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0775 - acc: 0.9803 - val_loss: 1.1974 - val_acc: 0.7468\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9808\n",
      "Epoch 00053: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0725 - acc: 0.9808 - val_loss: 1.2353 - val_acc: 0.7424\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9815\n",
      "Epoch 00054: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0708 - acc: 0.9816 - val_loss: 1.2185 - val_acc: 0.7496\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9825\n",
      "Epoch 00055: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0674 - acc: 0.9824 - val_loss: 1.2544 - val_acc: 0.7379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9828\n",
      "Epoch 00056: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0671 - acc: 0.9828 - val_loss: 1.2538 - val_acc: 0.7459\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9824\n",
      "Epoch 00057: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0676 - acc: 0.9824 - val_loss: 1.2273 - val_acc: 0.7442\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9834\n",
      "Epoch 00058: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0637 - acc: 0.9833 - val_loss: 1.2394 - val_acc: 0.7424\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9824\n",
      "Epoch 00059: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0660 - acc: 0.9824 - val_loss: 1.2569 - val_acc: 0.7470\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9833\n",
      "Epoch 00060: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0627 - acc: 0.9833 - val_loss: 1.2353 - val_acc: 0.7496\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9844\n",
      "Epoch 00061: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0598 - acc: 0.9844 - val_loss: 1.2735 - val_acc: 0.7438\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9848\n",
      "Epoch 00062: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0595 - acc: 0.9848 - val_loss: 1.2411 - val_acc: 0.7496\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9839\n",
      "Epoch 00063: val_loss did not improve from 0.98544\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0616 - acc: 0.9839 - val_loss: 1.2654 - val_acc: 0.7505\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 938us/sample - loss: 1.0711 - acc: 0.6885\n",
      "Loss: 1.0711028837588221 Accuracy: 0.6884735\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7641 - acc: 0.4332\n",
      "Epoch 00001: val_loss improved from inf to 1.40032, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv_checkpoint/001-1.4003.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 1.7640 - acc: 0.4331 - val_loss: 1.4003 - val_acc: 0.5735\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3419 - acc: 0.5861\n",
      "Epoch 00002: val_loss improved from 1.40032 to 1.15762, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv_checkpoint/002-1.1576.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.3420 - acc: 0.5860 - val_loss: 1.1576 - val_acc: 0.6492\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1570 - acc: 0.6496\n",
      "Epoch 00003: val_loss improved from 1.15762 to 1.05219, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv_checkpoint/003-1.0522.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.1571 - acc: 0.6496 - val_loss: 1.0522 - val_acc: 0.6832\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0419 - acc: 0.6893\n",
      "Epoch 00004: val_loss improved from 1.05219 to 0.97939, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv_checkpoint/004-0.9794.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.0418 - acc: 0.6893 - val_loss: 0.9794 - val_acc: 0.7128\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9551 - acc: 0.7175\n",
      "Epoch 00005: val_loss did not improve from 0.97939\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.9553 - acc: 0.7175 - val_loss: 1.0168 - val_acc: 0.6925\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8857 - acc: 0.7387\n",
      "Epoch 00006: val_loss improved from 0.97939 to 0.89591, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv_checkpoint/006-0.8959.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8857 - acc: 0.7386 - val_loss: 0.8959 - val_acc: 0.7419\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8361 - acc: 0.7554\n",
      "Epoch 00007: val_loss improved from 0.89591 to 0.87318, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv_checkpoint/007-0.8732.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8360 - acc: 0.7554 - val_loss: 0.8732 - val_acc: 0.7489\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7765 - acc: 0.7725\n",
      "Epoch 00008: val_loss improved from 0.87318 to 0.81344, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv_checkpoint/008-0.8134.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7764 - acc: 0.7725 - val_loss: 0.8134 - val_acc: 0.7722\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7320 - acc: 0.7851\n",
      "Epoch 00009: val_loss did not improve from 0.81344\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7320 - acc: 0.7851 - val_loss: 0.8189 - val_acc: 0.7619\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6778 - acc: 0.8023\n",
      "Epoch 00010: val_loss improved from 0.81344 to 0.80439, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv_checkpoint/010-0.8044.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6778 - acc: 0.8023 - val_loss: 0.8044 - val_acc: 0.7764\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6425 - acc: 0.8131\n",
      "Epoch 00011: val_loss improved from 0.80439 to 0.76234, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv_checkpoint/011-0.7623.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6424 - acc: 0.8131 - val_loss: 0.7623 - val_acc: 0.7838\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6011 - acc: 0.8263\n",
      "Epoch 00012: val_loss did not improve from 0.76234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6012 - acc: 0.8263 - val_loss: 0.8027 - val_acc: 0.7727\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5725 - acc: 0.8343\n",
      "Epoch 00013: val_loss did not improve from 0.76234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5724 - acc: 0.8344 - val_loss: 0.7883 - val_acc: 0.7803\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5347 - acc: 0.8453\n",
      "Epoch 00014: val_loss did not improve from 0.76234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5348 - acc: 0.8453 - val_loss: 0.7912 - val_acc: 0.7780\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5044 - acc: 0.8530\n",
      "Epoch 00015: val_loss did not improve from 0.76234\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5044 - acc: 0.8530 - val_loss: 0.7698 - val_acc: 0.7817\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4757 - acc: 0.8637\n",
      "Epoch 00016: val_loss did not improve from 0.76234\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4757 - acc: 0.8637 - val_loss: 0.7658 - val_acc: 0.7789\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4465 - acc: 0.8714\n",
      "Epoch 00017: val_loss improved from 0.76234 to 0.74669, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv_checkpoint/017-0.7467.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4466 - acc: 0.8713 - val_loss: 0.7467 - val_acc: 0.7901\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4177 - acc: 0.8803\n",
      "Epoch 00018: val_loss improved from 0.74669 to 0.74542, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv_checkpoint/018-0.7454.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4176 - acc: 0.8803 - val_loss: 0.7454 - val_acc: 0.7899\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3928 - acc: 0.8862\n",
      "Epoch 00019: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3928 - acc: 0.8861 - val_loss: 0.7653 - val_acc: 0.7869\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3734 - acc: 0.8924\n",
      "Epoch 00020: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3734 - acc: 0.8924 - val_loss: 0.7632 - val_acc: 0.7866\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3473 - acc: 0.9012\n",
      "Epoch 00021: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3473 - acc: 0.9012 - val_loss: 0.7592 - val_acc: 0.7880\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3288 - acc: 0.9050\n",
      "Epoch 00022: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3289 - acc: 0.9050 - val_loss: 0.7477 - val_acc: 0.7932\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3138 - acc: 0.9087\n",
      "Epoch 00023: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3138 - acc: 0.9087 - val_loss: 0.7756 - val_acc: 0.7813\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2935 - acc: 0.9162\n",
      "Epoch 00024: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2936 - acc: 0.9162 - val_loss: 0.7725 - val_acc: 0.7850\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2795 - acc: 0.9209\n",
      "Epoch 00025: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2795 - acc: 0.9209 - val_loss: 0.7609 - val_acc: 0.7962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2627 - acc: 0.9256\n",
      "Epoch 00026: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2627 - acc: 0.9256 - val_loss: 0.7563 - val_acc: 0.7959\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2478 - acc: 0.9295\n",
      "Epoch 00027: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2478 - acc: 0.9295 - val_loss: 0.7805 - val_acc: 0.7901\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2366 - acc: 0.9320\n",
      "Epoch 00028: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2366 - acc: 0.9320 - val_loss: 0.7735 - val_acc: 0.7897\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2193 - acc: 0.9378\n",
      "Epoch 00029: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2193 - acc: 0.9378 - val_loss: 0.7650 - val_acc: 0.7966\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2110 - acc: 0.9395\n",
      "Epoch 00030: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2110 - acc: 0.9395 - val_loss: 0.7973 - val_acc: 0.7906\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2001 - acc: 0.9440\n",
      "Epoch 00031: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2001 - acc: 0.9440 - val_loss: 0.7678 - val_acc: 0.7999\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1921 - acc: 0.9470\n",
      "Epoch 00032: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1921 - acc: 0.9470 - val_loss: 0.7978 - val_acc: 0.7941\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1831 - acc: 0.9487\n",
      "Epoch 00033: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1831 - acc: 0.9487 - val_loss: 0.7765 - val_acc: 0.7971\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1721 - acc: 0.9535\n",
      "Epoch 00034: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1721 - acc: 0.9535 - val_loss: 0.7729 - val_acc: 0.8008\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1686 - acc: 0.9539\n",
      "Epoch 00035: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1686 - acc: 0.9539 - val_loss: 0.7850 - val_acc: 0.7948\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9558\n",
      "Epoch 00036: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1595 - acc: 0.9558 - val_loss: 0.8198 - val_acc: 0.7936\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9594\n",
      "Epoch 00037: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1503 - acc: 0.9594 - val_loss: 0.8488 - val_acc: 0.7915\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1473 - acc: 0.9591\n",
      "Epoch 00038: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1473 - acc: 0.9591 - val_loss: 0.8185 - val_acc: 0.7934\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1429 - acc: 0.9609\n",
      "Epoch 00039: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1429 - acc: 0.9609 - val_loss: 0.8523 - val_acc: 0.7843\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9629\n",
      "Epoch 00040: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1358 - acc: 0.9629 - val_loss: 0.8073 - val_acc: 0.7997\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9652\n",
      "Epoch 00041: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1286 - acc: 0.9652 - val_loss: 0.8271 - val_acc: 0.8046\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9633\n",
      "Epoch 00042: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1286 - acc: 0.9633 - val_loss: 0.8310 - val_acc: 0.8004\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9683\n",
      "Epoch 00043: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1195 - acc: 0.9683 - val_loss: 0.8139 - val_acc: 0.8036\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9687\n",
      "Epoch 00044: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1152 - acc: 0.9687 - val_loss: 0.8416 - val_acc: 0.7952\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9697\n",
      "Epoch 00045: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1114 - acc: 0.9697 - val_loss: 0.8411 - val_acc: 0.8011\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9699\n",
      "Epoch 00046: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1096 - acc: 0.9699 - val_loss: 0.8417 - val_acc: 0.8034\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9701\n",
      "Epoch 00047: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1091 - acc: 0.9701 - val_loss: 0.8504 - val_acc: 0.8015\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9721\n",
      "Epoch 00048: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1016 - acc: 0.9722 - val_loss: 0.8723 - val_acc: 0.7966\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9725\n",
      "Epoch 00049: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1025 - acc: 0.9725 - val_loss: 0.8748 - val_acc: 0.7987\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9739\n",
      "Epoch 00050: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0958 - acc: 0.9739 - val_loss: 0.8684 - val_acc: 0.7966\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9747\n",
      "Epoch 00051: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0948 - acc: 0.9747 - val_loss: 0.8534 - val_acc: 0.8060\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9756\n",
      "Epoch 00052: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0939 - acc: 0.9756 - val_loss: 0.8710 - val_acc: 0.8015\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9768\n",
      "Epoch 00053: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0878 - acc: 0.9768 - val_loss: 0.8848 - val_acc: 0.7985\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9770\n",
      "Epoch 00054: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0877 - acc: 0.9770 - val_loss: 0.8962 - val_acc: 0.7997\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9753\n",
      "Epoch 00055: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0910 - acc: 0.9753 - val_loss: 0.9150 - val_acc: 0.7913\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9787\n",
      "Epoch 00056: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0820 - acc: 0.9788 - val_loss: 0.9233 - val_acc: 0.8020\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9780\n",
      "Epoch 00057: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0826 - acc: 0.9780 - val_loss: 0.9328 - val_acc: 0.7987\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9780\n",
      "Epoch 00058: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0815 - acc: 0.9780 - val_loss: 0.9144 - val_acc: 0.7980\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9780\n",
      "Epoch 00059: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0815 - acc: 0.9780 - val_loss: 0.9157 - val_acc: 0.8006\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9799\n",
      "Epoch 00060: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0760 - acc: 0.9799 - val_loss: 0.8852 - val_acc: 0.8074\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9815\n",
      "Epoch 00061: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0711 - acc: 0.9815 - val_loss: 0.9187 - val_acc: 0.8078\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9805\n",
      "Epoch 00062: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0756 - acc: 0.9805 - val_loss: 0.9056 - val_acc: 0.8050\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9784\n",
      "Epoch 00063: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0753 - acc: 0.9784 - val_loss: 0.9492 - val_acc: 0.7920\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9801\n",
      "Epoch 00064: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0712 - acc: 0.9801 - val_loss: 0.9045 - val_acc: 0.8106\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9809\n",
      "Epoch 00065: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0735 - acc: 0.9809 - val_loss: 0.9255 - val_acc: 0.8022\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9817\n",
      "Epoch 00066: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0692 - acc: 0.9817 - val_loss: 0.9212 - val_acc: 0.8048\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9820\n",
      "Epoch 00067: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0665 - acc: 0.9820 - val_loss: 0.9133 - val_acc: 0.8048\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9821\n",
      "Epoch 00068: val_loss did not improve from 0.74542\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0668 - acc: 0.9821 - val_loss: 1.0089 - val_acc: 0.7890\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 992us/sample - loss: 0.8078 - acc: 0.7560\n",
      "Loss: 0.8078143773791946 Accuracy: 0.7559709\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8717 - acc: 0.3947\n",
      "Epoch 00001: val_loss improved from inf to 1.44631, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/001-1.4463.hdf5\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 1.8717 - acc: 0.3947 - val_loss: 1.4463 - val_acc: 0.5539\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4196 - acc: 0.5567\n",
      "Epoch 00002: val_loss improved from 1.44631 to 1.20276, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/002-1.2028.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.4195 - acc: 0.5567 - val_loss: 1.2028 - val_acc: 0.6466\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2148 - acc: 0.6307\n",
      "Epoch 00003: val_loss improved from 1.20276 to 1.05314, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/003-1.0531.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.2147 - acc: 0.6308 - val_loss: 1.0531 - val_acc: 0.6890\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0842 - acc: 0.6728\n",
      "Epoch 00004: val_loss improved from 1.05314 to 0.95252, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/004-0.9525.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.0842 - acc: 0.6728 - val_loss: 0.9525 - val_acc: 0.7216\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9959 - acc: 0.7054\n",
      "Epoch 00005: val_loss improved from 0.95252 to 0.88591, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/005-0.8859.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9959 - acc: 0.7054 - val_loss: 0.8859 - val_acc: 0.7529\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9205 - acc: 0.7277\n",
      "Epoch 00006: val_loss improved from 0.88591 to 0.81669, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/006-0.8167.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9205 - acc: 0.7277 - val_loss: 0.8167 - val_acc: 0.7689\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8528 - acc: 0.7470\n",
      "Epoch 00007: val_loss improved from 0.81669 to 0.78817, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/007-0.7882.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8527 - acc: 0.7470 - val_loss: 0.7882 - val_acc: 0.7754\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8033 - acc: 0.7624\n",
      "Epoch 00008: val_loss improved from 0.78817 to 0.70049, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/008-0.7005.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8032 - acc: 0.7624 - val_loss: 0.7005 - val_acc: 0.7978\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7493 - acc: 0.7822\n",
      "Epoch 00009: val_loss did not improve from 0.70049\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7495 - acc: 0.7821 - val_loss: 0.7182 - val_acc: 0.7952\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7130 - acc: 0.7892\n",
      "Epoch 00010: val_loss improved from 0.70049 to 0.65401, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/010-0.6540.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7129 - acc: 0.7892 - val_loss: 0.6540 - val_acc: 0.8150\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6696 - acc: 0.8037\n",
      "Epoch 00011: val_loss improved from 0.65401 to 0.64251, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/011-0.6425.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6696 - acc: 0.8036 - val_loss: 0.6425 - val_acc: 0.8167\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6447 - acc: 0.8113\n",
      "Epoch 00012: val_loss improved from 0.64251 to 0.62855, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/012-0.6286.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6446 - acc: 0.8114 - val_loss: 0.6286 - val_acc: 0.8258\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6126 - acc: 0.8200\n",
      "Epoch 00013: val_loss improved from 0.62855 to 0.58843, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/013-0.5884.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6126 - acc: 0.8200 - val_loss: 0.5884 - val_acc: 0.8307\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5875 - acc: 0.8279\n",
      "Epoch 00014: val_loss did not improve from 0.58843\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5875 - acc: 0.8279 - val_loss: 0.5961 - val_acc: 0.8295\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5669 - acc: 0.8342\n",
      "Epoch 00015: val_loss improved from 0.58843 to 0.55931, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/015-0.5593.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5668 - acc: 0.8342 - val_loss: 0.5593 - val_acc: 0.8372\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5459 - acc: 0.8425\n",
      "Epoch 00016: val_loss did not improve from 0.55931\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5459 - acc: 0.8425 - val_loss: 0.5607 - val_acc: 0.8393\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5223 - acc: 0.8458\n",
      "Epoch 00017: val_loss improved from 0.55931 to 0.52798, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/017-0.5280.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5225 - acc: 0.8458 - val_loss: 0.5280 - val_acc: 0.8519\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5048 - acc: 0.8532\n",
      "Epoch 00018: val_loss improved from 0.52798 to 0.52620, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/018-0.5262.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5047 - acc: 0.8532 - val_loss: 0.5262 - val_acc: 0.8563\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4918 - acc: 0.8573\n",
      "Epoch 00019: val_loss did not improve from 0.52620\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4918 - acc: 0.8573 - val_loss: 0.5357 - val_acc: 0.8470\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4727 - acc: 0.8617\n",
      "Epoch 00020: val_loss improved from 0.52620 to 0.49972, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/020-0.4997.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4727 - acc: 0.8617 - val_loss: 0.4997 - val_acc: 0.8584\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4587 - acc: 0.8652\n",
      "Epoch 00021: val_loss did not improve from 0.49972\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4587 - acc: 0.8652 - val_loss: 0.5246 - val_acc: 0.8509\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4418 - acc: 0.8707\n",
      "Epoch 00022: val_loss did not improve from 0.49972\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4419 - acc: 0.8706 - val_loss: 0.5250 - val_acc: 0.8537\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4290 - acc: 0.8749\n",
      "Epoch 00023: val_loss improved from 0.49972 to 0.49191, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/023-0.4919.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4290 - acc: 0.8749 - val_loss: 0.4919 - val_acc: 0.8640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4143 - acc: 0.8797\n",
      "Epoch 00024: val_loss improved from 0.49191 to 0.48925, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/024-0.4893.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4144 - acc: 0.8796 - val_loss: 0.4893 - val_acc: 0.8605\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4030 - acc: 0.8832\n",
      "Epoch 00025: val_loss did not improve from 0.48925\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4030 - acc: 0.8832 - val_loss: 0.5048 - val_acc: 0.8605\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3913 - acc: 0.8845\n",
      "Epoch 00026: val_loss improved from 0.48925 to 0.48623, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/026-0.4862.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3913 - acc: 0.8845 - val_loss: 0.4862 - val_acc: 0.8661\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3856 - acc: 0.8860\n",
      "Epoch 00027: val_loss improved from 0.48623 to 0.46326, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/027-0.4633.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3856 - acc: 0.8860 - val_loss: 0.4633 - val_acc: 0.8728\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3671 - acc: 0.8924\n",
      "Epoch 00028: val_loss did not improve from 0.46326\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3672 - acc: 0.8924 - val_loss: 0.5035 - val_acc: 0.8630\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3566 - acc: 0.8957\n",
      "Epoch 00029: val_loss improved from 0.46326 to 0.45070, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/029-0.4507.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3566 - acc: 0.8957 - val_loss: 0.4507 - val_acc: 0.8772\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3442 - acc: 0.8970\n",
      "Epoch 00030: val_loss did not improve from 0.45070\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3442 - acc: 0.8970 - val_loss: 0.4727 - val_acc: 0.8714\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3390 - acc: 0.8994\n",
      "Epoch 00031: val_loss improved from 0.45070 to 0.43788, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/031-0.4379.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3390 - acc: 0.8994 - val_loss: 0.4379 - val_acc: 0.8784\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3278 - acc: 0.9037\n",
      "Epoch 00032: val_loss did not improve from 0.43788\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3278 - acc: 0.9037 - val_loss: 0.4625 - val_acc: 0.8789\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3227 - acc: 0.9057\n",
      "Epoch 00033: val_loss did not improve from 0.43788\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3226 - acc: 0.9057 - val_loss: 0.4462 - val_acc: 0.8761\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3086 - acc: 0.9080\n",
      "Epoch 00034: val_loss improved from 0.43788 to 0.43235, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/034-0.4323.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3086 - acc: 0.9081 - val_loss: 0.4323 - val_acc: 0.8852\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3023 - acc: 0.9086\n",
      "Epoch 00035: val_loss improved from 0.43235 to 0.42709, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/035-0.4271.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3023 - acc: 0.9087 - val_loss: 0.4271 - val_acc: 0.8849\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2912 - acc: 0.9136\n",
      "Epoch 00036: val_loss did not improve from 0.42709\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2912 - acc: 0.9136 - val_loss: 0.4503 - val_acc: 0.8812\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2864 - acc: 0.9150\n",
      "Epoch 00037: val_loss did not improve from 0.42709\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2863 - acc: 0.9150 - val_loss: 0.4753 - val_acc: 0.8740\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2790 - acc: 0.9151\n",
      "Epoch 00038: val_loss did not improve from 0.42709\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2790 - acc: 0.9151 - val_loss: 0.4284 - val_acc: 0.8819\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2723 - acc: 0.9194\n",
      "Epoch 00039: val_loss did not improve from 0.42709\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2723 - acc: 0.9194 - val_loss: 0.4417 - val_acc: 0.8782\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2641 - acc: 0.9210\n",
      "Epoch 00040: val_loss did not improve from 0.42709\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2641 - acc: 0.9210 - val_loss: 0.4677 - val_acc: 0.8807\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2572 - acc: 0.9236\n",
      "Epoch 00041: val_loss improved from 0.42709 to 0.42368, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/041-0.4237.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2572 - acc: 0.9236 - val_loss: 0.4237 - val_acc: 0.8891\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2501 - acc: 0.9251\n",
      "Epoch 00042: val_loss did not improve from 0.42368\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2501 - acc: 0.9250 - val_loss: 0.4289 - val_acc: 0.8833\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2451 - acc: 0.9270\n",
      "Epoch 00043: val_loss did not improve from 0.42368\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2451 - acc: 0.9270 - val_loss: 0.4294 - val_acc: 0.8887\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2337 - acc: 0.9296\n",
      "Epoch 00044: val_loss did not improve from 0.42368\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2337 - acc: 0.9296 - val_loss: 0.4286 - val_acc: 0.8847\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2320 - acc: 0.9318\n",
      "Epoch 00045: val_loss did not improve from 0.42368\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2320 - acc: 0.9318 - val_loss: 0.4438 - val_acc: 0.8861\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2290 - acc: 0.9309\n",
      "Epoch 00046: val_loss improved from 0.42368 to 0.41919, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/046-0.4192.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2290 - acc: 0.9309 - val_loss: 0.4192 - val_acc: 0.8901\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2246 - acc: 0.9330\n",
      "Epoch 00047: val_loss improved from 0.41919 to 0.41477, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/047-0.4148.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2246 - acc: 0.9330 - val_loss: 0.4148 - val_acc: 0.8875\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2174 - acc: 0.9360\n",
      "Epoch 00048: val_loss did not improve from 0.41477\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2174 - acc: 0.9360 - val_loss: 0.4231 - val_acc: 0.8884\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2089 - acc: 0.9371\n",
      "Epoch 00049: val_loss did not improve from 0.41477\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2089 - acc: 0.9371 - val_loss: 0.4189 - val_acc: 0.8901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9365\n",
      "Epoch 00050: val_loss did not improve from 0.41477\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2044 - acc: 0.9365 - val_loss: 0.4169 - val_acc: 0.8875\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2009 - acc: 0.9404\n",
      "Epoch 00051: val_loss did not improve from 0.41477\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2009 - acc: 0.9404 - val_loss: 0.4446 - val_acc: 0.8870\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1978 - acc: 0.9410\n",
      "Epoch 00052: val_loss improved from 0.41477 to 0.41344, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/052-0.4134.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1978 - acc: 0.9410 - val_loss: 0.4134 - val_acc: 0.8877\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1908 - acc: 0.9425\n",
      "Epoch 00053: val_loss did not improve from 0.41344\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1908 - acc: 0.9425 - val_loss: 0.4416 - val_acc: 0.8842\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1846 - acc: 0.9443\n",
      "Epoch 00054: val_loss did not improve from 0.41344\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1846 - acc: 0.9443 - val_loss: 0.4271 - val_acc: 0.8863\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1824 - acc: 0.9438\n",
      "Epoch 00055: val_loss did not improve from 0.41344\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1824 - acc: 0.9437 - val_loss: 0.4419 - val_acc: 0.8842\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1771 - acc: 0.9469\n",
      "Epoch 00056: val_loss improved from 0.41344 to 0.41269, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/056-0.4127.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1771 - acc: 0.9469 - val_loss: 0.4127 - val_acc: 0.8973\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9479\n",
      "Epoch 00057: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1755 - acc: 0.9479 - val_loss: 0.4191 - val_acc: 0.8921\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9493\n",
      "Epoch 00058: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1681 - acc: 0.9493 - val_loss: 0.4537 - val_acc: 0.8828\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1659 - acc: 0.9503\n",
      "Epoch 00059: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1659 - acc: 0.9503 - val_loss: 0.4227 - val_acc: 0.8921\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1630 - acc: 0.9498\n",
      "Epoch 00060: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1630 - acc: 0.9498 - val_loss: 0.4269 - val_acc: 0.8926\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1619 - acc: 0.9518\n",
      "Epoch 00061: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1619 - acc: 0.9518 - val_loss: 0.4267 - val_acc: 0.8933\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1560 - acc: 0.9539\n",
      "Epoch 00062: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1561 - acc: 0.9539 - val_loss: 0.4230 - val_acc: 0.8945\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1626 - acc: 0.9513\n",
      "Epoch 00063: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1626 - acc: 0.9513 - val_loss: 0.4268 - val_acc: 0.8959\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1458 - acc: 0.9554\n",
      "Epoch 00064: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1458 - acc: 0.9554 - val_loss: 0.4246 - val_acc: 0.8938\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9560\n",
      "Epoch 00065: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1435 - acc: 0.9560 - val_loss: 0.4457 - val_acc: 0.8889\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9567\n",
      "Epoch 00066: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1402 - acc: 0.9567 - val_loss: 0.4312 - val_acc: 0.8933\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9601\n",
      "Epoch 00067: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1351 - acc: 0.9600 - val_loss: 0.4296 - val_acc: 0.8935\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1396 - acc: 0.9566\n",
      "Epoch 00068: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1396 - acc: 0.9566 - val_loss: 0.4407 - val_acc: 0.8977\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9594\n",
      "Epoch 00069: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1331 - acc: 0.9594 - val_loss: 0.4211 - val_acc: 0.8966\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9607\n",
      "Epoch 00070: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1324 - acc: 0.9607 - val_loss: 0.4361 - val_acc: 0.8987\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9610\n",
      "Epoch 00071: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1278 - acc: 0.9609 - val_loss: 0.4324 - val_acc: 0.8998\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1237 - acc: 0.9624\n",
      "Epoch 00072: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1237 - acc: 0.9624 - val_loss: 0.4286 - val_acc: 0.8935\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1255 - acc: 0.9621\n",
      "Epoch 00073: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1255 - acc: 0.9622 - val_loss: 0.4505 - val_acc: 0.8928\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9640\n",
      "Epoch 00074: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1192 - acc: 0.9640 - val_loss: 0.4426 - val_acc: 0.8926\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9637\n",
      "Epoch 00075: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1207 - acc: 0.9637 - val_loss: 0.4145 - val_acc: 0.9003\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9670\n",
      "Epoch 00076: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1105 - acc: 0.9670 - val_loss: 0.4167 - val_acc: 0.9024\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9655\n",
      "Epoch 00077: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1145 - acc: 0.9655 - val_loss: 0.4314 - val_acc: 0.8980\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1130 - acc: 0.9660\n",
      "Epoch 00078: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1130 - acc: 0.9660 - val_loss: 0.4417 - val_acc: 0.8961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1110 - acc: 0.9659\n",
      "Epoch 00079: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1110 - acc: 0.9659 - val_loss: 0.4374 - val_acc: 0.8977\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9666\n",
      "Epoch 00080: val_loss did not improve from 0.41269\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1084 - acc: 0.9666 - val_loss: 0.4862 - val_acc: 0.8887\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9675\n",
      "Epoch 00081: val_loss improved from 0.41269 to 0.41258, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv_checkpoint/081-0.4126.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1069 - acc: 0.9675 - val_loss: 0.4126 - val_acc: 0.9010\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9692\n",
      "Epoch 00082: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1036 - acc: 0.9692 - val_loss: 0.4319 - val_acc: 0.8989\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9701\n",
      "Epoch 00083: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1001 - acc: 0.9701 - val_loss: 0.4479 - val_acc: 0.8947\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9705\n",
      "Epoch 00084: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1001 - acc: 0.9705 - val_loss: 0.4357 - val_acc: 0.9047\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9721\n",
      "Epoch 00085: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0949 - acc: 0.9722 - val_loss: 0.4293 - val_acc: 0.9005\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9721\n",
      "Epoch 00086: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0951 - acc: 0.9721 - val_loss: 0.4434 - val_acc: 0.8991\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9703\n",
      "Epoch 00087: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0970 - acc: 0.9703 - val_loss: 0.4638 - val_acc: 0.8963\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9691\n",
      "Epoch 00088: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1013 - acc: 0.9691 - val_loss: 0.4428 - val_acc: 0.8968\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9727\n",
      "Epoch 00089: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0920 - acc: 0.9727 - val_loss: 0.4276 - val_acc: 0.9015\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9729\n",
      "Epoch 00090: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0914 - acc: 0.9729 - val_loss: 0.4658 - val_acc: 0.8938\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9721\n",
      "Epoch 00091: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0927 - acc: 0.9721 - val_loss: 0.4477 - val_acc: 0.8982\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9751\n",
      "Epoch 00092: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0866 - acc: 0.9751 - val_loss: 0.4299 - val_acc: 0.9036\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9737\n",
      "Epoch 00093: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0884 - acc: 0.9737 - val_loss: 0.4514 - val_acc: 0.9050\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9764\n",
      "Epoch 00094: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0808 - acc: 0.9764 - val_loss: 0.4619 - val_acc: 0.9015\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9742\n",
      "Epoch 00095: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0881 - acc: 0.9742 - val_loss: 0.4840 - val_acc: 0.8928\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9758\n",
      "Epoch 00096: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0845 - acc: 0.9758 - val_loss: 0.4317 - val_acc: 0.9040\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9761\n",
      "Epoch 00097: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0824 - acc: 0.9761 - val_loss: 0.4726 - val_acc: 0.8968\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9779\n",
      "Epoch 00098: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0765 - acc: 0.9779 - val_loss: 0.4590 - val_acc: 0.8994\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9777\n",
      "Epoch 00099: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0765 - acc: 0.9777 - val_loss: 0.4627 - val_acc: 0.9024\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9773\n",
      "Epoch 00100: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0778 - acc: 0.9773 - val_loss: 0.4887 - val_acc: 0.8947\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9799\n",
      "Epoch 00101: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0705 - acc: 0.9799 - val_loss: 0.5079 - val_acc: 0.8915\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9746\n",
      "Epoch 00102: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0852 - acc: 0.9746 - val_loss: 0.4517 - val_acc: 0.8966\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9797\n",
      "Epoch 00103: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0711 - acc: 0.9797 - val_loss: 0.4883 - val_acc: 0.8970\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9787\n",
      "Epoch 00104: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0734 - acc: 0.9787 - val_loss: 0.4872 - val_acc: 0.8940\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9808\n",
      "Epoch 00105: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0680 - acc: 0.9808 - val_loss: 0.4929 - val_acc: 0.8959\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9798\n",
      "Epoch 00106: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0706 - acc: 0.9798 - val_loss: 0.4872 - val_acc: 0.8952\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9793\n",
      "Epoch 00107: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0697 - acc: 0.9793 - val_loss: 0.4787 - val_acc: 0.8966\n",
      "Epoch 108/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9801\n",
      "Epoch 00108: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0692 - acc: 0.9801 - val_loss: 0.4864 - val_acc: 0.8926\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9792\n",
      "Epoch 00109: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0709 - acc: 0.9792 - val_loss: 0.4908 - val_acc: 0.8975\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9815\n",
      "Epoch 00110: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0630 - acc: 0.9816 - val_loss: 0.4784 - val_acc: 0.8991\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9801\n",
      "Epoch 00111: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0675 - acc: 0.9801 - val_loss: 0.4619 - val_acc: 0.9040\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9824\n",
      "Epoch 00112: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0642 - acc: 0.9824 - val_loss: 0.4637 - val_acc: 0.9029\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0655 - acc: 0.9810\n",
      "Epoch 00113: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0655 - acc: 0.9810 - val_loss: 0.4561 - val_acc: 0.9047\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9805\n",
      "Epoch 00114: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0660 - acc: 0.9805 - val_loss: 0.4836 - val_acc: 0.8933\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9795\n",
      "Epoch 00115: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0685 - acc: 0.9795 - val_loss: 0.4611 - val_acc: 0.9024\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9831\n",
      "Epoch 00116: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0616 - acc: 0.9831 - val_loss: 0.4856 - val_acc: 0.9019\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9795\n",
      "Epoch 00117: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0688 - acc: 0.9795 - val_loss: 0.4714 - val_acc: 0.9012\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9802\n",
      "Epoch 00118: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0696 - acc: 0.9802 - val_loss: 0.4772 - val_acc: 0.8984\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9845\n",
      "Epoch 00119: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0542 - acc: 0.9845 - val_loss: 0.4831 - val_acc: 0.8987\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9827\n",
      "Epoch 00120: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0595 - acc: 0.9827 - val_loss: 0.4774 - val_acc: 0.8994\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9824\n",
      "Epoch 00121: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0600 - acc: 0.9824 - val_loss: 0.4585 - val_acc: 0.9038\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9841\n",
      "Epoch 00122: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0553 - acc: 0.9841 - val_loss: 0.4562 - val_acc: 0.9024\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9823\n",
      "Epoch 00123: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0627 - acc: 0.9823 - val_loss: 0.4657 - val_acc: 0.9019\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9856\n",
      "Epoch 00124: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0535 - acc: 0.9856 - val_loss: 0.4963 - val_acc: 0.8970\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9836\n",
      "Epoch 00125: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0588 - acc: 0.9836 - val_loss: 0.4759 - val_acc: 0.8989\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9829\n",
      "Epoch 00126: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0599 - acc: 0.9829 - val_loss: 0.4950 - val_acc: 0.8963\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9838\n",
      "Epoch 00127: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0558 - acc: 0.9838 - val_loss: 0.4622 - val_acc: 0.9047\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9840\n",
      "Epoch 00128: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0569 - acc: 0.9840 - val_loss: 0.4940 - val_acc: 0.9082\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9853\n",
      "Epoch 00129: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0517 - acc: 0.9853 - val_loss: 0.4714 - val_acc: 0.9029\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9856\n",
      "Epoch 00130: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0527 - acc: 0.9856 - val_loss: 0.4656 - val_acc: 0.9099\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9827\n",
      "Epoch 00131: val_loss did not improve from 0.41258\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0594 - acc: 0.9827 - val_loss: 0.4875 - val_acc: 0.9015\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 966us/sample - loss: 0.4960 - acc: 0.8692\n",
      "Loss: 0.4959927596283355 Accuracy: 0.86915886\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9403 - acc: 0.3746\n",
      "Epoch 00001: val_loss improved from inf to 1.47570, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/001-1.4757.hdf5\n",
      "36805/36805 [==============================] - 97s 3ms/sample - loss: 1.9403 - acc: 0.3746 - val_loss: 1.4757 - val_acc: 0.5460\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4427 - acc: 0.5506\n",
      "Epoch 00002: val_loss improved from 1.47570 to 1.16888, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/002-1.1689.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.4428 - acc: 0.5506 - val_loss: 1.1689 - val_acc: 0.6557\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1949 - acc: 0.6365\n",
      "Epoch 00003: val_loss improved from 1.16888 to 1.00840, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/003-1.0084.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.1948 - acc: 0.6366 - val_loss: 1.0084 - val_acc: 0.6935\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0382 - acc: 0.6883\n",
      "Epoch 00004: val_loss improved from 1.00840 to 0.89188, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/004-0.8919.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.0381 - acc: 0.6884 - val_loss: 0.8919 - val_acc: 0.7377\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9140 - acc: 0.7264\n",
      "Epoch 00005: val_loss improved from 0.89188 to 0.75410, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/005-0.7541.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.9139 - acc: 0.7264 - val_loss: 0.7541 - val_acc: 0.7852\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8237 - acc: 0.7566\n",
      "Epoch 00006: val_loss improved from 0.75410 to 0.68149, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/006-0.6815.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.8238 - acc: 0.7566 - val_loss: 0.6815 - val_acc: 0.8057\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7460 - acc: 0.7806\n",
      "Epoch 00007: val_loss improved from 0.68149 to 0.63496, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/007-0.6350.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.7459 - acc: 0.7806 - val_loss: 0.6350 - val_acc: 0.8251\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6793 - acc: 0.8018\n",
      "Epoch 00008: val_loss improved from 0.63496 to 0.61239, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/008-0.6124.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.6793 - acc: 0.8018 - val_loss: 0.6124 - val_acc: 0.8281\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6269 - acc: 0.8208\n",
      "Epoch 00009: val_loss improved from 0.61239 to 0.51413, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/009-0.5141.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.6269 - acc: 0.8208 - val_loss: 0.5141 - val_acc: 0.8626\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5812 - acc: 0.8355\n",
      "Epoch 00010: val_loss improved from 0.51413 to 0.48640, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/010-0.4864.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5812 - acc: 0.8355 - val_loss: 0.4864 - val_acc: 0.8642\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5462 - acc: 0.8436\n",
      "Epoch 00011: val_loss improved from 0.48640 to 0.46219, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/011-0.4622.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5462 - acc: 0.8435 - val_loss: 0.4622 - val_acc: 0.8733\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5196 - acc: 0.8509\n",
      "Epoch 00012: val_loss improved from 0.46219 to 0.43810, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/012-0.4381.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5195 - acc: 0.8509 - val_loss: 0.4381 - val_acc: 0.8793\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4826 - acc: 0.8632\n",
      "Epoch 00013: val_loss improved from 0.43810 to 0.41381, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/013-0.4138.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4828 - acc: 0.8631 - val_loss: 0.4138 - val_acc: 0.8831\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4613 - acc: 0.8678\n",
      "Epoch 00014: val_loss improved from 0.41381 to 0.41277, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/014-0.4128.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4613 - acc: 0.8678 - val_loss: 0.4128 - val_acc: 0.8882\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4402 - acc: 0.8738\n",
      "Epoch 00015: val_loss improved from 0.41277 to 0.39149, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/015-0.3915.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4403 - acc: 0.8738 - val_loss: 0.3915 - val_acc: 0.8982\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4200 - acc: 0.8798\n",
      "Epoch 00016: val_loss improved from 0.39149 to 0.37695, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/016-0.3769.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4199 - acc: 0.8799 - val_loss: 0.3769 - val_acc: 0.8975\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3979 - acc: 0.8874\n",
      "Epoch 00017: val_loss improved from 0.37695 to 0.35704, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/017-0.3570.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3978 - acc: 0.8874 - val_loss: 0.3570 - val_acc: 0.9015\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3836 - acc: 0.8899\n",
      "Epoch 00018: val_loss improved from 0.35704 to 0.34860, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/018-0.3486.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3836 - acc: 0.8900 - val_loss: 0.3486 - val_acc: 0.8996\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3643 - acc: 0.8946\n",
      "Epoch 00019: val_loss improved from 0.34860 to 0.33612, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/019-0.3361.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3643 - acc: 0.8946 - val_loss: 0.3361 - val_acc: 0.9087\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3552 - acc: 0.8974\n",
      "Epoch 00020: val_loss improved from 0.33612 to 0.32582, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/020-0.3258.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3552 - acc: 0.8974 - val_loss: 0.3258 - val_acc: 0.9122\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3438 - acc: 0.9015\n",
      "Epoch 00021: val_loss improved from 0.32582 to 0.32063, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/021-0.3206.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3439 - acc: 0.9015 - val_loss: 0.3206 - val_acc: 0.9115\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3341 - acc: 0.9038\n",
      "Epoch 00022: val_loss improved from 0.32063 to 0.30861, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/022-0.3086.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3341 - acc: 0.9038 - val_loss: 0.3086 - val_acc: 0.9124\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3231 - acc: 0.9067\n",
      "Epoch 00023: val_loss improved from 0.30861 to 0.30514, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/023-0.3051.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3231 - acc: 0.9068 - val_loss: 0.3051 - val_acc: 0.9166\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3048 - acc: 0.9115\n",
      "Epoch 00024: val_loss did not improve from 0.30514\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3049 - acc: 0.9115 - val_loss: 0.3148 - val_acc: 0.9136\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2969 - acc: 0.9152\n",
      "Epoch 00025: val_loss improved from 0.30514 to 0.28891, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/025-0.2889.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2969 - acc: 0.9152 - val_loss: 0.2889 - val_acc: 0.9231\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2886 - acc: 0.9162\n",
      "Epoch 00026: val_loss did not improve from 0.28891\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2886 - acc: 0.9162 - val_loss: 0.2937 - val_acc: 0.9192\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2774 - acc: 0.9196\n",
      "Epoch 00027: val_loss did not improve from 0.28891\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2773 - acc: 0.9197 - val_loss: 0.2897 - val_acc: 0.9217\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2717 - acc: 0.9208\n",
      "Epoch 00028: val_loss improved from 0.28891 to 0.26842, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/028-0.2684.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2717 - acc: 0.9208 - val_loss: 0.2684 - val_acc: 0.9283\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2606 - acc: 0.9253\n",
      "Epoch 00029: val_loss improved from 0.26842 to 0.25217, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/029-0.2522.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2606 - acc: 0.9253 - val_loss: 0.2522 - val_acc: 0.9320\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2571 - acc: 0.9257\n",
      "Epoch 00030: val_loss did not improve from 0.25217\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2571 - acc: 0.9257 - val_loss: 0.2600 - val_acc: 0.9283\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2478 - acc: 0.9271\n",
      "Epoch 00031: val_loss did not improve from 0.25217\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2478 - acc: 0.9270 - val_loss: 0.2941 - val_acc: 0.9150\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2436 - acc: 0.9284\n",
      "Epoch 00032: val_loss did not improve from 0.25217\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2436 - acc: 0.9284 - val_loss: 0.2640 - val_acc: 0.9276\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2426 - acc: 0.9287\n",
      "Epoch 00033: val_loss did not improve from 0.25217\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2426 - acc: 0.9287 - val_loss: 0.2796 - val_acc: 0.9264\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2282 - acc: 0.9345\n",
      "Epoch 00034: val_loss did not improve from 0.25217\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2283 - acc: 0.9344 - val_loss: 0.2576 - val_acc: 0.9320\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2249 - acc: 0.9329\n",
      "Epoch 00035: val_loss did not improve from 0.25217\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2248 - acc: 0.9329 - val_loss: 0.2545 - val_acc: 0.9320\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2180 - acc: 0.9353\n",
      "Epoch 00036: val_loss did not improve from 0.25217\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2180 - acc: 0.9353 - val_loss: 0.2689 - val_acc: 0.9264\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2117 - acc: 0.9376\n",
      "Epoch 00037: val_loss did not improve from 0.25217\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2118 - acc: 0.9376 - val_loss: 0.2582 - val_acc: 0.9297\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.9371\n",
      "Epoch 00038: val_loss did not improve from 0.25217\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2102 - acc: 0.9371 - val_loss: 0.2686 - val_acc: 0.9343\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1988 - acc: 0.9410\n",
      "Epoch 00039: val_loss did not improve from 0.25217\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1988 - acc: 0.9410 - val_loss: 0.2625 - val_acc: 0.9306\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1954 - acc: 0.9414\n",
      "Epoch 00040: val_loss did not improve from 0.25217\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1954 - acc: 0.9414 - val_loss: 0.2604 - val_acc: 0.9317\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1941 - acc: 0.9429\n",
      "Epoch 00041: val_loss improved from 0.25217 to 0.23782, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/041-0.2378.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1941 - acc: 0.9429 - val_loss: 0.2378 - val_acc: 0.9380\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1841 - acc: 0.9455\n",
      "Epoch 00042: val_loss did not improve from 0.23782\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1841 - acc: 0.9456 - val_loss: 0.2454 - val_acc: 0.9369\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9477\n",
      "Epoch 00043: val_loss did not improve from 0.23782\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1811 - acc: 0.9477 - val_loss: 0.2594 - val_acc: 0.9273\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1841 - acc: 0.9457\n",
      "Epoch 00044: val_loss did not improve from 0.23782\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1841 - acc: 0.9457 - val_loss: 0.2493 - val_acc: 0.9324\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1736 - acc: 0.9477\n",
      "Epoch 00045: val_loss did not improve from 0.23782\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1736 - acc: 0.9477 - val_loss: 0.2493 - val_acc: 0.9366\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1694 - acc: 0.9486\n",
      "Epoch 00046: val_loss improved from 0.23782 to 0.22846, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/046-0.2285.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1694 - acc: 0.9486 - val_loss: 0.2285 - val_acc: 0.9341\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1682 - acc: 0.9500\n",
      "Epoch 00047: val_loss did not improve from 0.22846\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1682 - acc: 0.9500 - val_loss: 0.2296 - val_acc: 0.9408\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1629 - acc: 0.9513\n",
      "Epoch 00048: val_loss did not improve from 0.22846\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1630 - acc: 0.9513 - val_loss: 0.2320 - val_acc: 0.9397\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1627 - acc: 0.9507\n",
      "Epoch 00049: val_loss did not improve from 0.22846\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1627 - acc: 0.9507 - val_loss: 0.2389 - val_acc: 0.9373\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9526\n",
      "Epoch 00050: val_loss improved from 0.22846 to 0.22574, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/050-0.2257.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1604 - acc: 0.9526 - val_loss: 0.2257 - val_acc: 0.9352\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1518 - acc: 0.9549\n",
      "Epoch 00051: val_loss improved from 0.22574 to 0.22217, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/051-0.2222.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1518 - acc: 0.9549 - val_loss: 0.2222 - val_acc: 0.9387\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9564\n",
      "Epoch 00052: val_loss did not improve from 0.22217\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1474 - acc: 0.9564 - val_loss: 0.2286 - val_acc: 0.9364\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1482 - acc: 0.9565\n",
      "Epoch 00053: val_loss did not improve from 0.22217\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1482 - acc: 0.9566 - val_loss: 0.2347 - val_acc: 0.9334\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1434 - acc: 0.9565\n",
      "Epoch 00054: val_loss did not improve from 0.22217\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1434 - acc: 0.9565 - val_loss: 0.2365 - val_acc: 0.9399\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9596\n",
      "Epoch 00055: val_loss did not improve from 0.22217\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1372 - acc: 0.9596 - val_loss: 0.2335 - val_acc: 0.9390\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9569\n",
      "Epoch 00056: val_loss did not improve from 0.22217\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1382 - acc: 0.9569 - val_loss: 0.2252 - val_acc: 0.9401\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9610\n",
      "Epoch 00057: val_loss did not improve from 0.22217\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1299 - acc: 0.9610 - val_loss: 0.2573 - val_acc: 0.9345\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9615\n",
      "Epoch 00058: val_loss improved from 0.22217 to 0.22100, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/058-0.2210.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1269 - acc: 0.9615 - val_loss: 0.2210 - val_acc: 0.9399\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9624\n",
      "Epoch 00059: val_loss did not improve from 0.22100\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1253 - acc: 0.9624 - val_loss: 0.2453 - val_acc: 0.9397\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9613\n",
      "Epoch 00060: val_loss did not improve from 0.22100\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1257 - acc: 0.9613 - val_loss: 0.2315 - val_acc: 0.9331\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9627\n",
      "Epoch 00061: val_loss improved from 0.22100 to 0.21775, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/061-0.2178.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1237 - acc: 0.9627 - val_loss: 0.2178 - val_acc: 0.9406\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9635\n",
      "Epoch 00062: val_loss did not improve from 0.21775\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1193 - acc: 0.9635 - val_loss: 0.2298 - val_acc: 0.9387\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9633\n",
      "Epoch 00063: val_loss did not improve from 0.21775\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1260 - acc: 0.9633 - val_loss: 0.2278 - val_acc: 0.9441\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9673\n",
      "Epoch 00064: val_loss did not improve from 0.21775\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1113 - acc: 0.9673 - val_loss: 0.2338 - val_acc: 0.9371\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9674\n",
      "Epoch 00065: val_loss did not improve from 0.21775\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1069 - acc: 0.9674 - val_loss: 0.2318 - val_acc: 0.9394\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9673\n",
      "Epoch 00066: val_loss did not improve from 0.21775\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1075 - acc: 0.9673 - val_loss: 0.2342 - val_acc: 0.9434\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9688\n",
      "Epoch 00067: val_loss did not improve from 0.21775\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1051 - acc: 0.9688 - val_loss: 0.2478 - val_acc: 0.9376\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9678\n",
      "Epoch 00068: val_loss did not improve from 0.21775\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1043 - acc: 0.9678 - val_loss: 0.2338 - val_acc: 0.9404\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9701\n",
      "Epoch 00069: val_loss did not improve from 0.21775\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0992 - acc: 0.9701 - val_loss: 0.2529 - val_acc: 0.9359\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9688\n",
      "Epoch 00070: val_loss did not improve from 0.21775\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1019 - acc: 0.9688 - val_loss: 0.2292 - val_acc: 0.9413\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9726\n",
      "Epoch 00071: val_loss did not improve from 0.21775\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0923 - acc: 0.9726 - val_loss: 0.2349 - val_acc: 0.9373\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9724\n",
      "Epoch 00072: val_loss improved from 0.21775 to 0.21455, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/072-0.2145.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0910 - acc: 0.9724 - val_loss: 0.2145 - val_acc: 0.9406\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9715\n",
      "Epoch 00073: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0932 - acc: 0.9714 - val_loss: 0.2638 - val_acc: 0.9334\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0895 - acc: 0.9732\n",
      "Epoch 00074: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0895 - acc: 0.9732 - val_loss: 0.2221 - val_acc: 0.9413\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9757\n",
      "Epoch 00075: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0817 - acc: 0.9757 - val_loss: 0.2391 - val_acc: 0.9411\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9749\n",
      "Epoch 00076: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0825 - acc: 0.9749 - val_loss: 0.2193 - val_acc: 0.9439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9742\n",
      "Epoch 00077: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0854 - acc: 0.9742 - val_loss: 0.2329 - val_acc: 0.9404\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9743\n",
      "Epoch 00078: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0852 - acc: 0.9743 - val_loss: 0.2545 - val_acc: 0.9336\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9765\n",
      "Epoch 00079: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0784 - acc: 0.9765 - val_loss: 0.2194 - val_acc: 0.9436\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9766\n",
      "Epoch 00080: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0764 - acc: 0.9766 - val_loss: 0.2410 - val_acc: 0.9425\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9754\n",
      "Epoch 00081: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0803 - acc: 0.9754 - val_loss: 0.2243 - val_acc: 0.9439\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9786\n",
      "Epoch 00082: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0718 - acc: 0.9786 - val_loss: 0.2317 - val_acc: 0.9453\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9796\n",
      "Epoch 00083: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0681 - acc: 0.9796 - val_loss: 0.2681 - val_acc: 0.9359\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9788\n",
      "Epoch 00084: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0708 - acc: 0.9788 - val_loss: 0.2472 - val_acc: 0.9357\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9794\n",
      "Epoch 00085: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0682 - acc: 0.9794 - val_loss: 0.2428 - val_acc: 0.9387\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9804\n",
      "Epoch 00086: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0670 - acc: 0.9804 - val_loss: 0.2423 - val_acc: 0.9418\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9810\n",
      "Epoch 00087: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0640 - acc: 0.9810 - val_loss: 0.2624 - val_acc: 0.9378\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9801\n",
      "Epoch 00088: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0669 - acc: 0.9801 - val_loss: 0.2387 - val_acc: 0.9378\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9806\n",
      "Epoch 00089: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0639 - acc: 0.9806 - val_loss: 0.2299 - val_acc: 0.9469\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9792\n",
      "Epoch 00090: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0687 - acc: 0.9792 - val_loss: 0.2571 - val_acc: 0.9404\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9823\n",
      "Epoch 00091: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0621 - acc: 0.9823 - val_loss: 0.2408 - val_acc: 0.9406\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9811\n",
      "Epoch 00092: val_loss did not improve from 0.21455\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0637 - acc: 0.9811 - val_loss: 0.2295 - val_acc: 0.9397\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9823\n",
      "Epoch 00093: val_loss improved from 0.21455 to 0.20855, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv_checkpoint/093-0.2086.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0587 - acc: 0.9823 - val_loss: 0.2086 - val_acc: 0.9518\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9843\n",
      "Epoch 00094: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0534 - acc: 0.9843 - val_loss: 0.2183 - val_acc: 0.9429\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9835\n",
      "Epoch 00095: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0556 - acc: 0.9835 - val_loss: 0.2184 - val_acc: 0.9476\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9827\n",
      "Epoch 00096: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0577 - acc: 0.9827 - val_loss: 0.2255 - val_acc: 0.9471\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9845\n",
      "Epoch 00097: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0510 - acc: 0.9845 - val_loss: 0.2643 - val_acc: 0.9366\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9836\n",
      "Epoch 00098: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0536 - acc: 0.9836 - val_loss: 0.2399 - val_acc: 0.9429\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9844\n",
      "Epoch 00099: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0534 - acc: 0.9844 - val_loss: 0.2623 - val_acc: 0.9383\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9836\n",
      "Epoch 00100: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0521 - acc: 0.9836 - val_loss: 0.2792 - val_acc: 0.9376\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9861\n",
      "Epoch 00101: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0465 - acc: 0.9861 - val_loss: 0.2554 - val_acc: 0.9425\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9846\n",
      "Epoch 00102: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0501 - acc: 0.9846 - val_loss: 0.2678 - val_acc: 0.9422\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9846\n",
      "Epoch 00103: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0518 - acc: 0.9846 - val_loss: 0.2316 - val_acc: 0.9432\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9877\n",
      "Epoch 00104: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0411 - acc: 0.9877 - val_loss: 0.2478 - val_acc: 0.9432\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9873\n",
      "Epoch 00105: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0444 - acc: 0.9873 - val_loss: 0.2896 - val_acc: 0.9355\n",
      "Epoch 106/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9867\n",
      "Epoch 00106: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0440 - acc: 0.9867 - val_loss: 0.2677 - val_acc: 0.9399\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9880\n",
      "Epoch 00107: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0417 - acc: 0.9880 - val_loss: 0.2542 - val_acc: 0.9436\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9863\n",
      "Epoch 00108: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0451 - acc: 0.9863 - val_loss: 0.2844 - val_acc: 0.9362\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9863\n",
      "Epoch 00109: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0458 - acc: 0.9863 - val_loss: 0.2972 - val_acc: 0.9343\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9863\n",
      "Epoch 00110: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0454 - acc: 0.9863 - val_loss: 0.2422 - val_acc: 0.9427\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9887\n",
      "Epoch 00111: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0398 - acc: 0.9887 - val_loss: 0.2358 - val_acc: 0.9467\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9862\n",
      "Epoch 00112: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0461 - acc: 0.9862 - val_loss: 0.2594 - val_acc: 0.9380\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9891\n",
      "Epoch 00113: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0364 - acc: 0.9891 - val_loss: 0.2493 - val_acc: 0.9443\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9878\n",
      "Epoch 00114: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0413 - acc: 0.9878 - val_loss: 0.2553 - val_acc: 0.9434\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9885\n",
      "Epoch 00115: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0391 - acc: 0.9885 - val_loss: 0.2732 - val_acc: 0.9366\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9891\n",
      "Epoch 00116: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0368 - acc: 0.9891 - val_loss: 0.2689 - val_acc: 0.9439\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9870\n",
      "Epoch 00117: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0428 - acc: 0.9870 - val_loss: 0.2646 - val_acc: 0.9422\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9879\n",
      "Epoch 00118: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0427 - acc: 0.9879 - val_loss: 0.2659 - val_acc: 0.9408\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9933\n",
      "Epoch 00119: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0262 - acc: 0.9933 - val_loss: 0.2629 - val_acc: 0.9411\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9889\n",
      "Epoch 00120: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0364 - acc: 0.9889 - val_loss: 0.2925 - val_acc: 0.9364\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9915\n",
      "Epoch 00121: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0323 - acc: 0.9916 - val_loss: 0.2602 - val_acc: 0.9460\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9884\n",
      "Epoch 00122: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0388 - acc: 0.9884 - val_loss: 0.2981 - val_acc: 0.9380\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9863\n",
      "Epoch 00123: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0459 - acc: 0.9863 - val_loss: 0.2592 - val_acc: 0.9434\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9914\n",
      "Epoch 00124: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0306 - acc: 0.9914 - val_loss: 0.2546 - val_acc: 0.9446\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9912\n",
      "Epoch 00125: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0292 - acc: 0.9912 - val_loss: 0.2796 - val_acc: 0.9427\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9898\n",
      "Epoch 00126: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0345 - acc: 0.9898 - val_loss: 0.2562 - val_acc: 0.9436\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9894\n",
      "Epoch 00127: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0338 - acc: 0.9894 - val_loss: 0.2627 - val_acc: 0.9434\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9889\n",
      "Epoch 00128: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0366 - acc: 0.9889 - val_loss: 0.2754 - val_acc: 0.9415\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9919\n",
      "Epoch 00129: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0287 - acc: 0.9919 - val_loss: 0.2664 - val_acc: 0.9443\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9935\n",
      "Epoch 00130: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0248 - acc: 0.9935 - val_loss: 0.2667 - val_acc: 0.9399\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9898\n",
      "Epoch 00131: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0339 - acc: 0.9898 - val_loss: 0.2771 - val_acc: 0.9415\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9929\n",
      "Epoch 00132: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0268 - acc: 0.9929 - val_loss: 0.2747 - val_acc: 0.9404\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9853\n",
      "Epoch 00133: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0492 - acc: 0.9853 - val_loss: 0.2626 - val_acc: 0.9434\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9950\n",
      "Epoch 00134: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0193 - acc: 0.9950 - val_loss: 0.2532 - val_acc: 0.9455\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9936\n",
      "Epoch 00135: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0231 - acc: 0.9936 - val_loss: 0.2671 - val_acc: 0.9408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9912\n",
      "Epoch 00136: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0321 - acc: 0.9912 - val_loss: 0.2749 - val_acc: 0.9425\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9918\n",
      "Epoch 00137: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0281 - acc: 0.9918 - val_loss: 0.2823 - val_acc: 0.9406\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9921\n",
      "Epoch 00138: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0265 - acc: 0.9921 - val_loss: 0.2955 - val_acc: 0.9397\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9916\n",
      "Epoch 00139: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0284 - acc: 0.9916 - val_loss: 0.2834 - val_acc: 0.9392\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9928\n",
      "Epoch 00140: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0259 - acc: 0.9928 - val_loss: 0.2727 - val_acc: 0.9429\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9936\n",
      "Epoch 00141: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0217 - acc: 0.9936 - val_loss: 0.2597 - val_acc: 0.9448\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9920\n",
      "Epoch 00142: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0278 - acc: 0.9920 - val_loss: 0.2995 - val_acc: 0.9401\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9933\n",
      "Epoch 00143: val_loss did not improve from 0.20855\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0234 - acc: 0.9933 - val_loss: 0.3289 - val_acc: 0.9334\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2569 - acc: 0.9271\n",
      "Loss: 0.2569013264575666 Accuracy: 0.9271028\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9532 - acc: 0.3645\n",
      "Epoch 00001: val_loss improved from inf to 1.41860, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/001-1.4186.hdf5\n",
      "36805/36805 [==============================] - 100s 3ms/sample - loss: 1.9531 - acc: 0.3645 - val_loss: 1.4186 - val_acc: 0.5597\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4373 - acc: 0.5455\n",
      "Epoch 00002: val_loss improved from 1.41860 to 1.13758, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/002-1.1376.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 1.4373 - acc: 0.5455 - val_loss: 1.1376 - val_acc: 0.6532\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1255 - acc: 0.6578\n",
      "Epoch 00003: val_loss improved from 1.13758 to 0.84754, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/003-0.8475.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 1.1255 - acc: 0.6578 - val_loss: 0.8475 - val_acc: 0.7689\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8582 - acc: 0.7448\n",
      "Epoch 00004: val_loss improved from 0.84754 to 0.64667, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/004-0.6467.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.8583 - acc: 0.7447 - val_loss: 0.6467 - val_acc: 0.8146\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6948 - acc: 0.7952\n",
      "Epoch 00005: val_loss improved from 0.64667 to 0.51352, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/005-0.5135.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6948 - acc: 0.7952 - val_loss: 0.5135 - val_acc: 0.8607\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5755 - acc: 0.8305\n",
      "Epoch 00006: val_loss improved from 0.51352 to 0.40774, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/006-0.4077.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.5755 - acc: 0.8304 - val_loss: 0.4077 - val_acc: 0.8877\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4933 - acc: 0.8554\n",
      "Epoch 00007: val_loss improved from 0.40774 to 0.35969, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/007-0.3597.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4933 - acc: 0.8555 - val_loss: 0.3597 - val_acc: 0.9064\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4359 - acc: 0.8730\n",
      "Epoch 00008: val_loss improved from 0.35969 to 0.35596, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/008-0.3560.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4359 - acc: 0.8731 - val_loss: 0.3560 - val_acc: 0.9001\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3955 - acc: 0.8854\n",
      "Epoch 00009: val_loss improved from 0.35596 to 0.30729, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/009-0.3073.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3955 - acc: 0.8854 - val_loss: 0.3073 - val_acc: 0.9157\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3585 - acc: 0.8948\n",
      "Epoch 00010: val_loss improved from 0.30729 to 0.27943, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/010-0.2794.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3585 - acc: 0.8948 - val_loss: 0.2794 - val_acc: 0.9248\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3311 - acc: 0.9045\n",
      "Epoch 00011: val_loss improved from 0.27943 to 0.25798, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/011-0.2580.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3311 - acc: 0.9045 - val_loss: 0.2580 - val_acc: 0.9271\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3084 - acc: 0.9108\n",
      "Epoch 00012: val_loss improved from 0.25798 to 0.23189, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/012-0.2319.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3084 - acc: 0.9108 - val_loss: 0.2319 - val_acc: 0.9329\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2936 - acc: 0.9164\n",
      "Epoch 00013: val_loss improved from 0.23189 to 0.22256, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/013-0.2226.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2936 - acc: 0.9164 - val_loss: 0.2226 - val_acc: 0.9369\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2666 - acc: 0.9228\n",
      "Epoch 00014: val_loss improved from 0.22256 to 0.20791, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/014-0.2079.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2665 - acc: 0.9228 - val_loss: 0.2079 - val_acc: 0.9394\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2569 - acc: 0.9251\n",
      "Epoch 00015: val_loss improved from 0.20791 to 0.20375, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/015-0.2037.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2569 - acc: 0.9251 - val_loss: 0.2037 - val_acc: 0.9399\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2396 - acc: 0.9306\n",
      "Epoch 00016: val_loss did not improve from 0.20375\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2396 - acc: 0.9306 - val_loss: 0.2100 - val_acc: 0.9383\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.9336\n",
      "Epoch 00017: val_loss improved from 0.20375 to 0.19616, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/017-0.1962.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2283 - acc: 0.9337 - val_loss: 0.1962 - val_acc: 0.9448\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2208 - acc: 0.9361\n",
      "Epoch 00018: val_loss did not improve from 0.19616\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2207 - acc: 0.9361 - val_loss: 0.2022 - val_acc: 0.9397\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2048 - acc: 0.9389\n",
      "Epoch 00019: val_loss improved from 0.19616 to 0.17497, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/019-0.1750.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2047 - acc: 0.9389 - val_loss: 0.1750 - val_acc: 0.9546\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9408\n",
      "Epoch 00020: val_loss did not improve from 0.17497\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2004 - acc: 0.9408 - val_loss: 0.2033 - val_acc: 0.9418\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1915 - acc: 0.9439\n",
      "Epoch 00021: val_loss did not improve from 0.17497\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1915 - acc: 0.9439 - val_loss: 0.1852 - val_acc: 0.9504\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1890 - acc: 0.9447\n",
      "Epoch 00022: val_loss did not improve from 0.17497\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1889 - acc: 0.9447 - val_loss: 0.1824 - val_acc: 0.9481\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1762 - acc: 0.9484\n",
      "Epoch 00023: val_loss improved from 0.17497 to 0.16926, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/023-0.1693.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1762 - acc: 0.9484 - val_loss: 0.1693 - val_acc: 0.9541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1711 - acc: 0.9498\n",
      "Epoch 00024: val_loss improved from 0.16926 to 0.16194, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/024-0.1619.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1711 - acc: 0.9497 - val_loss: 0.1619 - val_acc: 0.9534\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1656 - acc: 0.9519\n",
      "Epoch 00025: val_loss did not improve from 0.16194\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1657 - acc: 0.9518 - val_loss: 0.1802 - val_acc: 0.9488\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1588 - acc: 0.9538\n",
      "Epoch 00026: val_loss did not improve from 0.16194\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1588 - acc: 0.9537 - val_loss: 0.1886 - val_acc: 0.9467\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1529 - acc: 0.9545\n",
      "Epoch 00027: val_loss improved from 0.16194 to 0.15462, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/027-0.1546.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1529 - acc: 0.9545 - val_loss: 0.1546 - val_acc: 0.9571\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9563\n",
      "Epoch 00028: val_loss did not improve from 0.15462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1465 - acc: 0.9563 - val_loss: 0.1592 - val_acc: 0.9553\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9589\n",
      "Epoch 00029: val_loss did not improve from 0.15462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1383 - acc: 0.9588 - val_loss: 0.1609 - val_acc: 0.9529\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1402 - acc: 0.9580\n",
      "Epoch 00030: val_loss did not improve from 0.15462\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1403 - acc: 0.9580 - val_loss: 0.1577 - val_acc: 0.9534\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1377 - acc: 0.9595\n",
      "Epoch 00031: val_loss improved from 0.15462 to 0.14713, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv_checkpoint/031-0.1471.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1378 - acc: 0.9594 - val_loss: 0.1471 - val_acc: 0.9576\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9620\n",
      "Epoch 00032: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1244 - acc: 0.9620 - val_loss: 0.1855 - val_acc: 0.9492\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9636\n",
      "Epoch 00033: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1216 - acc: 0.9636 - val_loss: 0.1723 - val_acc: 0.9511\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9658\n",
      "Epoch 00034: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1151 - acc: 0.9658 - val_loss: 0.1505 - val_acc: 0.9557\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9650\n",
      "Epoch 00035: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1141 - acc: 0.9650 - val_loss: 0.1808 - val_acc: 0.9502\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9664\n",
      "Epoch 00036: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1091 - acc: 0.9664 - val_loss: 0.1650 - val_acc: 0.9520\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9684\n",
      "Epoch 00037: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1048 - acc: 0.9684 - val_loss: 0.2072 - val_acc: 0.9504\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9693\n",
      "Epoch 00038: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1005 - acc: 0.9693 - val_loss: 0.1648 - val_acc: 0.9520\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9702\n",
      "Epoch 00039: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1005 - acc: 0.9702 - val_loss: 0.1647 - val_acc: 0.9518\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9724\n",
      "Epoch 00040: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0921 - acc: 0.9724 - val_loss: 0.1661 - val_acc: 0.9513\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9728\n",
      "Epoch 00041: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0875 - acc: 0.9728 - val_loss: 0.1711 - val_acc: 0.9546\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9739\n",
      "Epoch 00042: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0869 - acc: 0.9739 - val_loss: 0.1578 - val_acc: 0.9562\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9715\n",
      "Epoch 00043: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0947 - acc: 0.9715 - val_loss: 0.1650 - val_acc: 0.9560\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9759\n",
      "Epoch 00044: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0788 - acc: 0.9759 - val_loss: 0.1769 - val_acc: 0.9534\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9773\n",
      "Epoch 00045: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0760 - acc: 0.9773 - val_loss: 0.1522 - val_acc: 0.9562\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9792\n",
      "Epoch 00046: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0700 - acc: 0.9792 - val_loss: 0.1615 - val_acc: 0.9564\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9786\n",
      "Epoch 00047: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0713 - acc: 0.9786 - val_loss: 0.1572 - val_acc: 0.9585\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9803\n",
      "Epoch 00048: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0653 - acc: 0.9803 - val_loss: 0.1572 - val_acc: 0.9557\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9808\n",
      "Epoch 00049: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0641 - acc: 0.9808 - val_loss: 0.1703 - val_acc: 0.9543\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9822\n",
      "Epoch 00050: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0602 - acc: 0.9822 - val_loss: 0.1572 - val_acc: 0.9564\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9819\n",
      "Epoch 00051: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0590 - acc: 0.9819 - val_loss: 0.1663 - val_acc: 0.9550\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9798\n",
      "Epoch 00052: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0642 - acc: 0.9798 - val_loss: 0.1518 - val_acc: 0.9599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9846\n",
      "Epoch 00053: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0517 - acc: 0.9846 - val_loss: 0.1875 - val_acc: 0.9522\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9846\n",
      "Epoch 00054: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0511 - acc: 0.9845 - val_loss: 0.1655 - val_acc: 0.9571\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9850\n",
      "Epoch 00055: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0497 - acc: 0.9850 - val_loss: 0.1584 - val_acc: 0.9588\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9852\n",
      "Epoch 00056: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0476 - acc: 0.9852 - val_loss: 0.1893 - val_acc: 0.9499\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9882\n",
      "Epoch 00057: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0411 - acc: 0.9882 - val_loss: 0.1666 - val_acc: 0.9569\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9849\n",
      "Epoch 00058: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0482 - acc: 0.9849 - val_loss: 0.1642 - val_acc: 0.9534\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9871\n",
      "Epoch 00059: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0447 - acc: 0.9871 - val_loss: 0.1681 - val_acc: 0.9583\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9878\n",
      "Epoch 00060: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0408 - acc: 0.9878 - val_loss: 0.1706 - val_acc: 0.9560\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9890\n",
      "Epoch 00061: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0371 - acc: 0.9890 - val_loss: 0.1760 - val_acc: 0.9567\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9883\n",
      "Epoch 00062: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0399 - acc: 0.9883 - val_loss: 0.1662 - val_acc: 0.9576\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9888\n",
      "Epoch 00063: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0395 - acc: 0.9888 - val_loss: 0.1931 - val_acc: 0.9518\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9923\n",
      "Epoch 00064: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0291 - acc: 0.9923 - val_loss: 0.1739 - val_acc: 0.9499\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9887\n",
      "Epoch 00065: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0360 - acc: 0.9887 - val_loss: 0.1741 - val_acc: 0.9576\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9904\n",
      "Epoch 00066: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0324 - acc: 0.9904 - val_loss: 0.1948 - val_acc: 0.9504\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9885\n",
      "Epoch 00067: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0391 - acc: 0.9885 - val_loss: 0.1859 - val_acc: 0.9527\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9928\n",
      "Epoch 00068: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0249 - acc: 0.9928 - val_loss: 0.1726 - val_acc: 0.9548\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9923\n",
      "Epoch 00069: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0281 - acc: 0.9923 - val_loss: 0.1905 - val_acc: 0.9527\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9902\n",
      "Epoch 00070: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0333 - acc: 0.9902 - val_loss: 0.1828 - val_acc: 0.9546\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9929\n",
      "Epoch 00071: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0250 - acc: 0.9929 - val_loss: 0.2182 - val_acc: 0.9462\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9919\n",
      "Epoch 00072: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0287 - acc: 0.9919 - val_loss: 0.1808 - val_acc: 0.9536\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9943\n",
      "Epoch 00073: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0231 - acc: 0.9943 - val_loss: 0.1937 - val_acc: 0.9546\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9913\n",
      "Epoch 00074: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0307 - acc: 0.9913 - val_loss: 0.1879 - val_acc: 0.9541\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9948\n",
      "Epoch 00075: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0212 - acc: 0.9948 - val_loss: 0.1833 - val_acc: 0.9595\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9932\n",
      "Epoch 00076: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0240 - acc: 0.9932 - val_loss: 0.2008 - val_acc: 0.9536\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9942\n",
      "Epoch 00077: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0207 - acc: 0.9942 - val_loss: 0.1894 - val_acc: 0.9541\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9919\n",
      "Epoch 00078: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0271 - acc: 0.9919 - val_loss: 0.1760 - val_acc: 0.9576\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9944\n",
      "Epoch 00079: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0210 - acc: 0.9944 - val_loss: 0.1786 - val_acc: 0.9576\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9944\n",
      "Epoch 00080: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0211 - acc: 0.9944 - val_loss: 0.1970 - val_acc: 0.9557\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9920\n",
      "Epoch 00081: val_loss did not improve from 0.14713\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0273 - acc: 0.9920 - val_loss: 0.1936 - val_acc: 0.9539\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1982 - acc: 0.9387\n",
      "Loss: 0.1981866773662785 Accuracy: 0.9387331\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5118 - acc: 0.5205\n",
      "Epoch 00001: val_loss improved from inf to 0.89264, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv_checkpoint/001-0.8926.hdf5\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 1.5117 - acc: 0.5205 - val_loss: 0.8926 - val_acc: 0.7426\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8149 - acc: 0.7532\n",
      "Epoch 00002: val_loss improved from 0.89264 to 0.52904, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv_checkpoint/002-0.5290.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.8149 - acc: 0.7532 - val_loss: 0.5290 - val_acc: 0.8512\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5644 - acc: 0.8322\n",
      "Epoch 00003: val_loss improved from 0.52904 to 0.36792, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv_checkpoint/003-0.3679.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.5644 - acc: 0.8322 - val_loss: 0.3679 - val_acc: 0.8989\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4313 - acc: 0.8716\n",
      "Epoch 00004: val_loss improved from 0.36792 to 0.29994, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv_checkpoint/004-0.2999.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4313 - acc: 0.8716 - val_loss: 0.2999 - val_acc: 0.9164\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3540 - acc: 0.8956\n",
      "Epoch 00005: val_loss improved from 0.29994 to 0.25188, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv_checkpoint/005-0.2519.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3541 - acc: 0.8956 - val_loss: 0.2519 - val_acc: 0.9236\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3040 - acc: 0.9107\n",
      "Epoch 00006: val_loss improved from 0.25188 to 0.21064, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv_checkpoint/006-0.2106.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3040 - acc: 0.9107 - val_loss: 0.2106 - val_acc: 0.9413\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2687 - acc: 0.9204\n",
      "Epoch 00007: val_loss improved from 0.21064 to 0.19846, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv_checkpoint/007-0.1985.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2687 - acc: 0.9204 - val_loss: 0.1985 - val_acc: 0.9446\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2371 - acc: 0.9279\n",
      "Epoch 00008: val_loss improved from 0.19846 to 0.18506, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv_checkpoint/008-0.1851.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2371 - acc: 0.9278 - val_loss: 0.1851 - val_acc: 0.9474\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2177 - acc: 0.9347\n",
      "Epoch 00009: val_loss did not improve from 0.18506\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2177 - acc: 0.9347 - val_loss: 0.2062 - val_acc: 0.9371\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9387\n",
      "Epoch 00010: val_loss improved from 0.18506 to 0.16021, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv_checkpoint/010-0.1602.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2022 - acc: 0.9387 - val_loss: 0.1602 - val_acc: 0.9529\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1857 - acc: 0.9441\n",
      "Epoch 00011: val_loss did not improve from 0.16021\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1857 - acc: 0.9441 - val_loss: 0.1636 - val_acc: 0.9546\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1707 - acc: 0.9479\n",
      "Epoch 00012: val_loss improved from 0.16021 to 0.14798, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv_checkpoint/012-0.1480.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1707 - acc: 0.9479 - val_loss: 0.1480 - val_acc: 0.9583\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9510\n",
      "Epoch 00013: val_loss did not improve from 0.14798\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1597 - acc: 0.9510 - val_loss: 0.1481 - val_acc: 0.9536\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9554\n",
      "Epoch 00014: val_loss did not improve from 0.14798\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1489 - acc: 0.9554 - val_loss: 0.1525 - val_acc: 0.9569\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9561\n",
      "Epoch 00015: val_loss did not improve from 0.14798\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1449 - acc: 0.9561 - val_loss: 0.1500 - val_acc: 0.9536\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1324 - acc: 0.9601\n",
      "Epoch 00016: val_loss improved from 0.14798 to 0.13460, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv_checkpoint/016-0.1346.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1324 - acc: 0.9601 - val_loss: 0.1346 - val_acc: 0.9609\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9627\n",
      "Epoch 00017: val_loss did not improve from 0.13460\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1211 - acc: 0.9627 - val_loss: 0.1528 - val_acc: 0.9532\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9642\n",
      "Epoch 00018: val_loss did not improve from 0.13460\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1180 - acc: 0.9642 - val_loss: 0.1491 - val_acc: 0.9564\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9656\n",
      "Epoch 00019: val_loss did not improve from 0.13460\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1104 - acc: 0.9656 - val_loss: 0.1416 - val_acc: 0.9581\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9668\n",
      "Epoch 00020: val_loss did not improve from 0.13460\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1087 - acc: 0.9668 - val_loss: 0.1376 - val_acc: 0.9581\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9701\n",
      "Epoch 00021: val_loss did not improve from 0.13460\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0967 - acc: 0.9701 - val_loss: 0.1410 - val_acc: 0.9567\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9719\n",
      "Epoch 00022: val_loss did not improve from 0.13460\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0917 - acc: 0.9719 - val_loss: 0.1439 - val_acc: 0.9560\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0875 - acc: 0.9729\n",
      "Epoch 00023: val_loss did not improve from 0.13460\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0875 - acc: 0.9729 - val_loss: 0.1571 - val_acc: 0.9539\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9738\n",
      "Epoch 00024: val_loss improved from 0.13460 to 0.12742, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv_checkpoint/024-0.1274.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0853 - acc: 0.9738 - val_loss: 0.1274 - val_acc: 0.9604\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9764\n",
      "Epoch 00025: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0762 - acc: 0.9764 - val_loss: 0.1314 - val_acc: 0.9639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9768\n",
      "Epoch 00026: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0757 - acc: 0.9768 - val_loss: 0.1278 - val_acc: 0.9646\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9799\n",
      "Epoch 00027: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0683 - acc: 0.9799 - val_loss: 0.1410 - val_acc: 0.9609\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9787\n",
      "Epoch 00028: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0677 - acc: 0.9787 - val_loss: 0.1419 - val_acc: 0.9630\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9805\n",
      "Epoch 00029: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0638 - acc: 0.9805 - val_loss: 0.1344 - val_acc: 0.9602\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9820\n",
      "Epoch 00030: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0594 - acc: 0.9820 - val_loss: 0.1352 - val_acc: 0.9637\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9826\n",
      "Epoch 00031: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0558 - acc: 0.9826 - val_loss: 0.1300 - val_acc: 0.9660\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9835\n",
      "Epoch 00032: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0542 - acc: 0.9835 - val_loss: 0.1371 - val_acc: 0.9611\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9828\n",
      "Epoch 00033: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0547 - acc: 0.9828 - val_loss: 0.1509 - val_acc: 0.9613\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9860\n",
      "Epoch 00034: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0461 - acc: 0.9860 - val_loss: 0.1488 - val_acc: 0.9611\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9862\n",
      "Epoch 00035: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0465 - acc: 0.9863 - val_loss: 0.1372 - val_acc: 0.9632\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9860\n",
      "Epoch 00036: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0433 - acc: 0.9860 - val_loss: 0.1335 - val_acc: 0.9644\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9864\n",
      "Epoch 00037: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0424 - acc: 0.9864 - val_loss: 0.1322 - val_acc: 0.9644\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9893\n",
      "Epoch 00038: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0359 - acc: 0.9893 - val_loss: 0.1514 - val_acc: 0.9602\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9878\n",
      "Epoch 00039: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0389 - acc: 0.9878 - val_loss: 0.1376 - val_acc: 0.9651\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9900\n",
      "Epoch 00040: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0314 - acc: 0.9900 - val_loss: 0.1661 - val_acc: 0.9599\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9897\n",
      "Epoch 00041: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0336 - acc: 0.9897 - val_loss: 0.1429 - val_acc: 0.9648\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9914\n",
      "Epoch 00042: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0295 - acc: 0.9914 - val_loss: 0.1649 - val_acc: 0.9604\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9901\n",
      "Epoch 00043: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0322 - acc: 0.9901 - val_loss: 0.1412 - val_acc: 0.9653\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9922\n",
      "Epoch 00044: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0267 - acc: 0.9922 - val_loss: 0.1522 - val_acc: 0.9639\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9925\n",
      "Epoch 00045: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0258 - acc: 0.9925 - val_loss: 0.1617 - val_acc: 0.9637\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9934\n",
      "Epoch 00046: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0226 - acc: 0.9934 - val_loss: 0.1591 - val_acc: 0.9630\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9912\n",
      "Epoch 00047: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0265 - acc: 0.9912 - val_loss: 0.1599 - val_acc: 0.9609\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9928\n",
      "Epoch 00048: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0235 - acc: 0.9928 - val_loss: 0.1627 - val_acc: 0.9627\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9939\n",
      "Epoch 00049: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0207 - acc: 0.9939 - val_loss: 0.1413 - val_acc: 0.9660\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 00050: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0257 - acc: 0.9917 - val_loss: 0.1633 - val_acc: 0.9613\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9937\n",
      "Epoch 00051: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0205 - acc: 0.9937 - val_loss: 0.1532 - val_acc: 0.9620\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9956\n",
      "Epoch 00052: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0160 - acc: 0.9956 - val_loss: 0.1476 - val_acc: 0.9651\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9931\n",
      "Epoch 00053: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0223 - acc: 0.9931 - val_loss: 0.1472 - val_acc: 0.9613\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9941\n",
      "Epoch 00054: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0197 - acc: 0.9941 - val_loss: 0.1667 - val_acc: 0.9630\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9964\n",
      "Epoch 00055: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0144 - acc: 0.9964 - val_loss: 0.1959 - val_acc: 0.9574\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9943\n",
      "Epoch 00056: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0191 - acc: 0.9943 - val_loss: 0.1658 - val_acc: 0.9604\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9947\n",
      "Epoch 00057: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0180 - acc: 0.9947 - val_loss: 0.1705 - val_acc: 0.9627\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9940\n",
      "Epoch 00058: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0179 - acc: 0.9940 - val_loss: 0.1504 - val_acc: 0.9658\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9958\n",
      "Epoch 00059: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0137 - acc: 0.9958 - val_loss: 0.1703 - val_acc: 0.9632\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9963\n",
      "Epoch 00060: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0122 - acc: 0.9963 - val_loss: 0.1629 - val_acc: 0.9641\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9948\n",
      "Epoch 00061: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0164 - acc: 0.9948 - val_loss: 0.1639 - val_acc: 0.9627\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9951\n",
      "Epoch 00062: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0162 - acc: 0.9951 - val_loss: 0.1595 - val_acc: 0.9660\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9966\n",
      "Epoch 00063: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0120 - acc: 0.9966 - val_loss: 0.1664 - val_acc: 0.9641\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9943\n",
      "Epoch 00064: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0189 - acc: 0.9943 - val_loss: 0.1865 - val_acc: 0.9602\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9978\n",
      "Epoch 00065: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0082 - acc: 0.9978 - val_loss: 0.1669 - val_acc: 0.9646\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9985\n",
      "Epoch 00066: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0066 - acc: 0.9985 - val_loss: 0.1896 - val_acc: 0.9602\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9898\n",
      "Epoch 00067: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0343 - acc: 0.9898 - val_loss: 0.1575 - val_acc: 0.9658\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9976\n",
      "Epoch 00068: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0084 - acc: 0.9976 - val_loss: 0.1678 - val_acc: 0.9667\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9959\n",
      "Epoch 00069: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0137 - acc: 0.9959 - val_loss: 0.1816 - val_acc: 0.9611\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9971\n",
      "Epoch 00070: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0101 - acc: 0.9971 - val_loss: 0.1661 - val_acc: 0.9651\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9979\n",
      "Epoch 00071: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0073 - acc: 0.9979 - val_loss: 0.1895 - val_acc: 0.9595\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9954\n",
      "Epoch 00072: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0144 - acc: 0.9954 - val_loss: 0.1712 - val_acc: 0.9651\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9960\n",
      "Epoch 00073: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0133 - acc: 0.9960 - val_loss: 0.1684 - val_acc: 0.9630\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9959\n",
      "Epoch 00074: val_loss did not improve from 0.12742\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0124 - acc: 0.9959 - val_loss: 0.1954 - val_acc: 0.9588\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1677 - acc: 0.9510\n",
      "Loss: 0.16767958380351558 Accuracy: 0.9509865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    base = '1D_CNN_custom_conv_3_VGG_tanh_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 986us/sample - loss: 1.5296 - acc: 0.5381\n",
      "Loss: 1.5296365349958743 Accuracy: 0.5381101\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.0711 - acc: 0.6885\n",
      "Loss: 1.0711028837588221 Accuracy: 0.6884735\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.8078 - acc: 0.7560\n",
      "Loss: 0.8078143773791946 Accuracy: 0.7559709\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_114 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.4960 - acc: 0.8692\n",
      "Loss: 0.4959927596283355 Accuracy: 0.86915886\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_126 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2569 - acc: 0.9271\n",
      "Loss: 0.2569013264575666 Accuracy: 0.9271028\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_116 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.1982 - acc: 0.9387\n",
      "Loss: 0.1981866773662785 Accuracy: 0.9387331\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1677 - acc: 0.9510\n",
      "Loss: 0.16767958380351558 Accuracy: 0.9509865\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_tanh_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,881,680\n",
      "Trainable params: 1,881,680\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 2.8146 - acc: 0.5861\n",
      "Loss: 2.8145711502677306 Accuracy: 0.58608514\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 692,944\n",
      "Trainable params: 692,944\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.3925 - acc: 0.7165\n",
      "Loss: 1.3924545615880537 Accuracy: 0.7165109\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 564,176\n",
      "Trainable params: 564,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.1097 - acc: 0.7574\n",
      "Loss: 1.1097291856787534 Accuracy: 0.7574247\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_114 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 392,400\n",
      "Trainable params: 392,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.5840 - acc: 0.8733\n",
      "Loss: 0.5839728851277509 Accuracy: 0.8733126\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_126 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 400,848\n",
      "Trainable params: 400,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3980 - acc: 0.9094\n",
      "Loss: 0.398021513789985 Accuracy: 0.90944964\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_140 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 470,736\n",
      "Trainable params: 470,736\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2236 - acc: 0.9410\n",
      "Loss: 0.22360510120162524 Accuracy: 0.9410176\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_156 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 760,016\n",
      "Trainable params: 760,016\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2570 - acc: 0.9460\n",
      "Loss: 0.25696964077960976 Accuracy: 0.94600207\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base+'_last'), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
