{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO_075_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.75))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,400\n",
      "Trainable params: 16,384,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,481,936\n",
      "Trainable params: 5,481,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,136\n",
      "Trainable params: 1,861,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 668,240\n",
      "Trainable params: 668,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 506,576\n",
      "Trainable params: 506,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 318,288\n",
      "Trainable params: 318,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 310,224\n",
      "Trainable params: 310,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 363,600\n",
      "Trainable params: 363,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 521,552\n",
      "Trainable params: 521,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO_075_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3504 - acc: 0.2346\n",
      "Epoch 00001: val_loss improved from inf to 1.91396, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_3_conv_checkpoint/001-1.9140.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 2.3503 - acc: 0.2346 - val_loss: 1.9140 - val_acc: 0.3755\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6911 - acc: 0.4539\n",
      "Epoch 00002: val_loss improved from 1.91396 to 1.61010, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_3_conv_checkpoint/002-1.6101.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.6913 - acc: 0.4538 - val_loss: 1.6101 - val_acc: 0.4861\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3588 - acc: 0.5631\n",
      "Epoch 00003: val_loss improved from 1.61010 to 1.54886, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_3_conv_checkpoint/003-1.5489.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.3587 - acc: 0.5631 - val_loss: 1.5489 - val_acc: 0.4971\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1259 - acc: 0.6393\n",
      "Epoch 00004: val_loss did not improve from 1.54886\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.1259 - acc: 0.6393 - val_loss: 1.9599 - val_acc: 0.4603\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0312 - acc: 0.6723\n",
      "Epoch 00005: val_loss improved from 1.54886 to 1.23502, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_3_conv_checkpoint/005-1.2350.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 1.0313 - acc: 0.6723 - val_loss: 1.2350 - val_acc: 0.6159\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8877 - acc: 0.7146\n",
      "Epoch 00006: val_loss did not improve from 1.23502\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.8877 - acc: 0.7145 - val_loss: 1.3855 - val_acc: 0.5670\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7940 - acc: 0.7444\n",
      "Epoch 00007: val_loss improved from 1.23502 to 1.08680, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_3_conv_checkpoint/007-1.0868.hdf5\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.7939 - acc: 0.7444 - val_loss: 1.0868 - val_acc: 0.6569\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7116 - acc: 0.7696\n",
      "Epoch 00008: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.7116 - acc: 0.7696 - val_loss: 1.1498 - val_acc: 0.6478\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6347 - acc: 0.7947\n",
      "Epoch 00009: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.6346 - acc: 0.7947 - val_loss: 1.2438 - val_acc: 0.6380\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5853 - acc: 0.8092\n",
      "Epoch 00010: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5852 - acc: 0.8092 - val_loss: 1.1833 - val_acc: 0.6550\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5316 - acc: 0.8261\n",
      "Epoch 00011: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5316 - acc: 0.8261 - val_loss: 1.2132 - val_acc: 0.6641\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5284 - acc: 0.8305\n",
      "Epoch 00012: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.5284 - acc: 0.8305 - val_loss: 1.1850 - val_acc: 0.6734\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4713 - acc: 0.8464\n",
      "Epoch 00013: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4712 - acc: 0.8464 - val_loss: 1.3457 - val_acc: 0.6608\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4450 - acc: 0.8557\n",
      "Epoch 00014: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4452 - acc: 0.8556 - val_loss: 1.4539 - val_acc: 0.6184\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4609 - acc: 0.8495\n",
      "Epoch 00015: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4609 - acc: 0.8495 - val_loss: 1.2647 - val_acc: 0.6615\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4083 - acc: 0.8682\n",
      "Epoch 00016: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4084 - acc: 0.8681 - val_loss: 1.2177 - val_acc: 0.6730\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4016 - acc: 0.8694\n",
      "Epoch 00017: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.4016 - acc: 0.8694 - val_loss: 1.2452 - val_acc: 0.6900\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3793 - acc: 0.8772\n",
      "Epoch 00018: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3792 - acc: 0.8772 - val_loss: 1.2026 - val_acc: 0.6965\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3581 - acc: 0.8851\n",
      "Epoch 00019: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3580 - acc: 0.8851 - val_loss: 1.2643 - val_acc: 0.6876\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3466 - acc: 0.8875\n",
      "Epoch 00020: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3465 - acc: 0.8875 - val_loss: 1.3324 - val_acc: 0.6783\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3265 - acc: 0.8952\n",
      "Epoch 00021: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3265 - acc: 0.8952 - val_loss: 1.2642 - val_acc: 0.6783\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3252 - acc: 0.8946\n",
      "Epoch 00022: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3252 - acc: 0.8946 - val_loss: 1.2622 - val_acc: 0.6960\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2983 - acc: 0.9027\n",
      "Epoch 00023: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2983 - acc: 0.9027 - val_loss: 1.3013 - val_acc: 0.6734\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3049 - acc: 0.9008\n",
      "Epoch 00024: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.3050 - acc: 0.9008 - val_loss: 1.4575 - val_acc: 0.6436\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2879 - acc: 0.9066\n",
      "Epoch 00025: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2878 - acc: 0.9066 - val_loss: 1.2880 - val_acc: 0.6902\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2932 - acc: 0.9057\n",
      "Epoch 00026: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2933 - acc: 0.9057 - val_loss: 1.4768 - val_acc: 0.6711\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2741 - acc: 0.9119\n",
      "Epoch 00027: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2741 - acc: 0.9119 - val_loss: 1.2945 - val_acc: 0.7060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2624 - acc: 0.9171\n",
      "Epoch 00028: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2623 - acc: 0.9172 - val_loss: 1.3152 - val_acc: 0.7126\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2645 - acc: 0.9148\n",
      "Epoch 00029: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2645 - acc: 0.9148 - val_loss: 1.4070 - val_acc: 0.6799\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2554 - acc: 0.9198\n",
      "Epoch 00030: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2554 - acc: 0.9198 - val_loss: 1.3925 - val_acc: 0.7046\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2506 - acc: 0.9205\n",
      "Epoch 00031: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2506 - acc: 0.9205 - val_loss: 1.2795 - val_acc: 0.6965\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2457 - acc: 0.9209\n",
      "Epoch 00032: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2457 - acc: 0.9209 - val_loss: 1.2856 - val_acc: 0.7107\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2349 - acc: 0.9251\n",
      "Epoch 00033: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2349 - acc: 0.9251 - val_loss: 1.3841 - val_acc: 0.6879\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2257 - acc: 0.9270\n",
      "Epoch 00034: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2256 - acc: 0.9270 - val_loss: 1.2936 - val_acc: 0.7018\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2295 - acc: 0.9266\n",
      "Epoch 00035: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2294 - acc: 0.9266 - val_loss: 1.3353 - val_acc: 0.7004\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2211 - acc: 0.9295\n",
      "Epoch 00036: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2211 - acc: 0.9295 - val_loss: 1.4308 - val_acc: 0.7028\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2240 - acc: 0.9291\n",
      "Epoch 00037: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2240 - acc: 0.9291 - val_loss: 1.3998 - val_acc: 0.6960\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2253 - acc: 0.9308\n",
      "Epoch 00038: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2253 - acc: 0.9308 - val_loss: 1.2972 - val_acc: 0.7042\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2076 - acc: 0.9322\n",
      "Epoch 00039: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2076 - acc: 0.9322 - val_loss: 1.3859 - val_acc: 0.7051\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2210 - acc: 0.9290\n",
      "Epoch 00040: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2210 - acc: 0.9290 - val_loss: 1.3787 - val_acc: 0.7004\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2070 - acc: 0.9336\n",
      "Epoch 00041: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2069 - acc: 0.9336 - val_loss: 1.3230 - val_acc: 0.7065\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9326\n",
      "Epoch 00042: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2136 - acc: 0.9325 - val_loss: 1.5261 - val_acc: 0.7009\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2064 - acc: 0.9346\n",
      "Epoch 00043: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2063 - acc: 0.9347 - val_loss: 1.4410 - val_acc: 0.7023\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2014 - acc: 0.9357\n",
      "Epoch 00044: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2014 - acc: 0.9357 - val_loss: 1.5582 - val_acc: 0.6613\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2053 - acc: 0.9356\n",
      "Epoch 00045: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2053 - acc: 0.9356 - val_loss: 1.4792 - val_acc: 0.7119\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2020 - acc: 0.9372\n",
      "Epoch 00046: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.2020 - acc: 0.9371 - val_loss: 1.3311 - val_acc: 0.7219\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9379\n",
      "Epoch 00047: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1967 - acc: 0.9379 - val_loss: 1.4387 - val_acc: 0.7060\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1902 - acc: 0.9394\n",
      "Epoch 00048: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1902 - acc: 0.9394 - val_loss: 1.3254 - val_acc: 0.7174\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9441\n",
      "Epoch 00049: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1820 - acc: 0.9441 - val_loss: 1.4532 - val_acc: 0.6865\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1850 - acc: 0.9405\n",
      "Epoch 00050: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1849 - acc: 0.9406 - val_loss: 1.3767 - val_acc: 0.7172\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1827 - acc: 0.9427\n",
      "Epoch 00051: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1827 - acc: 0.9427 - val_loss: 1.3605 - val_acc: 0.7093\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1765 - acc: 0.9449\n",
      "Epoch 00052: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1765 - acc: 0.9449 - val_loss: 1.3390 - val_acc: 0.7202\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1857 - acc: 0.9418\n",
      "Epoch 00053: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1857 - acc: 0.9418 - val_loss: 1.3205 - val_acc: 0.7223\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9427\n",
      "Epoch 00054: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1819 - acc: 0.9427 - val_loss: 1.4800 - val_acc: 0.7053\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9474\n",
      "Epoch 00055: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1710 - acc: 0.9474 - val_loss: 1.4011 - val_acc: 0.7112\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1730 - acc: 0.9460\n",
      "Epoch 00056: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1730 - acc: 0.9460 - val_loss: 1.4372 - val_acc: 0.7140\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1649 - acc: 0.9476\n",
      "Epoch 00057: val_loss did not improve from 1.08680\n",
      "36805/36805 [==============================] - 45s 1ms/sample - loss: 0.1649 - acc: 0.9476 - val_loss: 1.4091 - val_acc: 0.7160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 546us/sample - loss: 1.2394 - acc: 0.6226\n",
      "Loss: 1.2393806066592288 Accuracy: 0.62263757\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2346 - acc: 0.2645\n",
      "Epoch 00001: val_loss improved from inf to 1.95412, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_4_conv_checkpoint/001-1.9541.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 2.2347 - acc: 0.2645 - val_loss: 1.9541 - val_acc: 0.3664\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5335 - acc: 0.5019\n",
      "Epoch 00002: val_loss improved from 1.95412 to 1.14279, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_4_conv_checkpoint/002-1.1428.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 1.5334 - acc: 0.5019 - val_loss: 1.1428 - val_acc: 0.6413\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2028 - acc: 0.6176\n",
      "Epoch 00003: val_loss improved from 1.14279 to 1.08710, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_4_conv_checkpoint/003-1.0871.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 1.2027 - acc: 0.6176 - val_loss: 1.0871 - val_acc: 0.6685\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0313 - acc: 0.6730\n",
      "Epoch 00004: val_loss did not improve from 1.08710\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 1.0315 - acc: 0.6730 - val_loss: 1.5771 - val_acc: 0.5192\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9476 - acc: 0.7033\n",
      "Epoch 00005: val_loss did not improve from 1.08710\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.9477 - acc: 0.7032 - val_loss: 1.4035 - val_acc: 0.5700\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9992 - acc: 0.6846\n",
      "Epoch 00006: val_loss improved from 1.08710 to 0.82316, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_4_conv_checkpoint/006-0.8232.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.9992 - acc: 0.6846 - val_loss: 0.8232 - val_acc: 0.7633\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8872 - acc: 0.7221\n",
      "Epoch 00007: val_loss did not improve from 0.82316\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.8872 - acc: 0.7221 - val_loss: 0.9726 - val_acc: 0.7137\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7830 - acc: 0.7523\n",
      "Epoch 00008: val_loss did not improve from 0.82316\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.7829 - acc: 0.7523 - val_loss: 0.8620 - val_acc: 0.7461\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6971 - acc: 0.7826\n",
      "Epoch 00009: val_loss improved from 0.82316 to 0.74235, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_4_conv_checkpoint/009-0.7424.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.6971 - acc: 0.7826 - val_loss: 0.7424 - val_acc: 0.7810\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6663 - acc: 0.7904\n",
      "Epoch 00010: val_loss did not improve from 0.74235\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.6663 - acc: 0.7904 - val_loss: 1.1134 - val_acc: 0.6867\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6141 - acc: 0.8063\n",
      "Epoch 00011: val_loss did not improve from 0.74235\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.6141 - acc: 0.8063 - val_loss: 0.9614 - val_acc: 0.7251\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5918 - acc: 0.8109\n",
      "Epoch 00012: val_loss improved from 0.74235 to 0.71898, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_4_conv_checkpoint/012-0.7190.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.5917 - acc: 0.8109 - val_loss: 0.7190 - val_acc: 0.7876\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5541 - acc: 0.8250\n",
      "Epoch 00013: val_loss did not improve from 0.71898\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.5540 - acc: 0.8250 - val_loss: 0.9206 - val_acc: 0.7219\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5512 - acc: 0.8221\n",
      "Epoch 00014: val_loss did not improve from 0.71898\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.5514 - acc: 0.8221 - val_loss: 1.1117 - val_acc: 0.6816\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5626 - acc: 0.8200\n",
      "Epoch 00015: val_loss did not improve from 0.71898\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.5626 - acc: 0.8200 - val_loss: 0.7441 - val_acc: 0.7747\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4987 - acc: 0.8412\n",
      "Epoch 00016: val_loss improved from 0.71898 to 0.69524, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_4_conv_checkpoint/016-0.6952.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4987 - acc: 0.8412 - val_loss: 0.6952 - val_acc: 0.8053\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4943 - acc: 0.8414\n",
      "Epoch 00017: val_loss did not improve from 0.69524\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4943 - acc: 0.8414 - val_loss: 0.7413 - val_acc: 0.7864\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4700 - acc: 0.8479\n",
      "Epoch 00018: val_loss did not improve from 0.69524\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.4700 - acc: 0.8479 - val_loss: 0.7672 - val_acc: 0.7920\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4473 - acc: 0.8555\n",
      "Epoch 00019: val_loss did not improve from 0.69524\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.4473 - acc: 0.8555 - val_loss: 0.8008 - val_acc: 0.7708\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4452 - acc: 0.8568\n",
      "Epoch 00020: val_loss improved from 0.69524 to 0.68290, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_4_conv_checkpoint/020-0.6829.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4451 - acc: 0.8568 - val_loss: 0.6829 - val_acc: 0.8148\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4212 - acc: 0.8640\n",
      "Epoch 00021: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4212 - acc: 0.8640 - val_loss: 0.7101 - val_acc: 0.8008\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4151 - acc: 0.8659\n",
      "Epoch 00022: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4150 - acc: 0.8659 - val_loss: 0.7303 - val_acc: 0.8060\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3975 - acc: 0.8715\n",
      "Epoch 00023: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.3975 - acc: 0.8715 - val_loss: 1.1440 - val_acc: 0.7226\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4213 - acc: 0.8631\n",
      "Epoch 00024: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4213 - acc: 0.8631 - val_loss: 0.7123 - val_acc: 0.8071\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3912 - acc: 0.8712\n",
      "Epoch 00025: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3912 - acc: 0.8712 - val_loss: 0.7125 - val_acc: 0.8167\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3809 - acc: 0.8755\n",
      "Epoch 00026: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3808 - acc: 0.8755 - val_loss: 0.7051 - val_acc: 0.8167\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3606 - acc: 0.8802\n",
      "Epoch 00027: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.3606 - acc: 0.8803 - val_loss: 0.7526 - val_acc: 0.8064\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3617 - acc: 0.8827\n",
      "Epoch 00028: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3617 - acc: 0.8827 - val_loss: 0.7817 - val_acc: 0.7957\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3478 - acc: 0.8834\n",
      "Epoch 00029: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3478 - acc: 0.8834 - val_loss: 0.8407 - val_acc: 0.7838\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3496 - acc: 0.8854\n",
      "Epoch 00030: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3497 - acc: 0.8854 - val_loss: 0.7465 - val_acc: 0.8106\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3490 - acc: 0.8850\n",
      "Epoch 00031: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3491 - acc: 0.8850 - val_loss: 0.8145 - val_acc: 0.7855\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3431 - acc: 0.8867\n",
      "Epoch 00032: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.3431 - acc: 0.8867 - val_loss: 0.7172 - val_acc: 0.8216\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3249 - acc: 0.8922\n",
      "Epoch 00033: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.3249 - acc: 0.8922 - val_loss: 0.7162 - val_acc: 0.8097\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3256 - acc: 0.8918\n",
      "Epoch 00034: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3256 - acc: 0.8918 - val_loss: 0.7549 - val_acc: 0.8088\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3224 - acc: 0.8936\n",
      "Epoch 00035: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3224 - acc: 0.8936 - val_loss: 0.7470 - val_acc: 0.8130\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3163 - acc: 0.8961\n",
      "Epoch 00036: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3163 - acc: 0.8961 - val_loss: 0.7427 - val_acc: 0.8111\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3174 - acc: 0.8956\n",
      "Epoch 00037: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3174 - acc: 0.8956 - val_loss: 0.8286 - val_acc: 0.7978\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3163 - acc: 0.8961\n",
      "Epoch 00038: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.3162 - acc: 0.8961 - val_loss: 0.7276 - val_acc: 0.8153\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3091 - acc: 0.8990\n",
      "Epoch 00039: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3090 - acc: 0.8990 - val_loss: 0.7094 - val_acc: 0.8067\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3051 - acc: 0.8992\n",
      "Epoch 00040: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3051 - acc: 0.8992 - val_loss: 0.7307 - val_acc: 0.8225\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2909 - acc: 0.9028\n",
      "Epoch 00041: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2909 - acc: 0.9028 - val_loss: 0.7125 - val_acc: 0.8255\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2897 - acc: 0.9028\n",
      "Epoch 00042: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2897 - acc: 0.9028 - val_loss: 0.7443 - val_acc: 0.8255\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2870 - acc: 0.9042\n",
      "Epoch 00043: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2870 - acc: 0.9041 - val_loss: 0.7593 - val_acc: 0.8090\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2861 - acc: 0.9045\n",
      "Epoch 00044: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2861 - acc: 0.9044 - val_loss: 0.8702 - val_acc: 0.7803\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2998 - acc: 0.9023\n",
      "Epoch 00045: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2998 - acc: 0.9023 - val_loss: 0.8389 - val_acc: 0.7962\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2846 - acc: 0.9045\n",
      "Epoch 00046: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2845 - acc: 0.9045 - val_loss: 0.7708 - val_acc: 0.8081\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2822 - acc: 0.9071\n",
      "Epoch 00047: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2822 - acc: 0.9071 - val_loss: 0.7764 - val_acc: 0.8111\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4652 - acc: 0.8544\n",
      "Epoch 00048: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4653 - acc: 0.8544 - val_loss: 1.0934 - val_acc: 0.6667\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4956 - acc: 0.8350\n",
      "Epoch 00049: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4955 - acc: 0.8350 - val_loss: 0.8073 - val_acc: 0.8004\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3549 - acc: 0.8845\n",
      "Epoch 00050: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.3549 - acc: 0.8845 - val_loss: 0.7765 - val_acc: 0.8069\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3293 - acc: 0.8908\n",
      "Epoch 00051: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3293 - acc: 0.8908 - val_loss: 0.7698 - val_acc: 0.8139\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3203 - acc: 0.8958\n",
      "Epoch 00052: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.3204 - acc: 0.8957 - val_loss: 0.8338 - val_acc: 0.8025\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3163 - acc: 0.8945\n",
      "Epoch 00053: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3163 - acc: 0.8945 - val_loss: 0.8316 - val_acc: 0.8069\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2879 - acc: 0.9057\n",
      "Epoch 00054: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2878 - acc: 0.9057 - val_loss: 0.7952 - val_acc: 0.8004\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2876 - acc: 0.9039\n",
      "Epoch 00055: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2875 - acc: 0.9039 - val_loss: 0.7348 - val_acc: 0.8216\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2910 - acc: 0.9033\n",
      "Epoch 00056: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2910 - acc: 0.9033 - val_loss: 0.8220 - val_acc: 0.8109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2767 - acc: 0.9091\n",
      "Epoch 00057: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2767 - acc: 0.9091 - val_loss: 0.8211 - val_acc: 0.8178\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2668 - acc: 0.9129\n",
      "Epoch 00058: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2668 - acc: 0.9129 - val_loss: 0.7740 - val_acc: 0.8123\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2607 - acc: 0.9140\n",
      "Epoch 00059: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2606 - acc: 0.9140 - val_loss: 0.8056 - val_acc: 0.8083\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2636 - acc: 0.9126\n",
      "Epoch 00060: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2636 - acc: 0.9126 - val_loss: 0.7739 - val_acc: 0.8160\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2588 - acc: 0.9146\n",
      "Epoch 00061: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2587 - acc: 0.9146 - val_loss: 0.7619 - val_acc: 0.8192\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2513 - acc: 0.9165\n",
      "Epoch 00062: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2512 - acc: 0.9165 - val_loss: 0.8168 - val_acc: 0.8085\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2498 - acc: 0.9178\n",
      "Epoch 00063: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2497 - acc: 0.9178 - val_loss: 0.8604 - val_acc: 0.8095\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2499 - acc: 0.9177\n",
      "Epoch 00064: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2499 - acc: 0.9177 - val_loss: 0.8270 - val_acc: 0.8204\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2574 - acc: 0.9158\n",
      "Epoch 00065: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2574 - acc: 0.9158 - val_loss: 0.8554 - val_acc: 0.8127\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2469 - acc: 0.9192\n",
      "Epoch 00066: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2469 - acc: 0.9192 - val_loss: 0.7694 - val_acc: 0.8192\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2484 - acc: 0.9177\n",
      "Epoch 00067: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2483 - acc: 0.9177 - val_loss: 0.9495 - val_acc: 0.7845\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2412 - acc: 0.9198\n",
      "Epoch 00068: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2412 - acc: 0.9198 - val_loss: 0.7812 - val_acc: 0.8181\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2432 - acc: 0.9199\n",
      "Epoch 00069: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2432 - acc: 0.9199 - val_loss: 0.8427 - val_acc: 0.8150\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2468 - acc: 0.9184\n",
      "Epoch 00070: val_loss did not improve from 0.68290\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2468 - acc: 0.9184 - val_loss: 0.7710 - val_acc: 0.8195\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 571us/sample - loss: 0.8214 - acc: 0.7726\n",
      "Loss: 0.82138472635798 Accuracy: 0.7725857\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1963 - acc: 0.2748\n",
      "Epoch 00001: val_loss improved from inf to 2.06665, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_5_conv_checkpoint/001-2.0667.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 2.1962 - acc: 0.2749 - val_loss: 2.0667 - val_acc: 0.3464\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5179 - acc: 0.5092\n",
      "Epoch 00002: val_loss improved from 2.06665 to 1.10882, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_5_conv_checkpoint/002-1.1088.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 1.5179 - acc: 0.5092 - val_loss: 1.1088 - val_acc: 0.6469\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1336 - acc: 0.6424\n",
      "Epoch 00003: val_loss did not improve from 1.10882\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 1.1336 - acc: 0.6423 - val_loss: 1.5199 - val_acc: 0.5246\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9593 - acc: 0.6961\n",
      "Epoch 00004: val_loss improved from 1.10882 to 0.84711, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_5_conv_checkpoint/004-0.8471.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.9596 - acc: 0.6960 - val_loss: 0.8471 - val_acc: 0.7545\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7813 - acc: 0.7603\n",
      "Epoch 00005: val_loss did not improve from 0.84711\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.7815 - acc: 0.7602 - val_loss: 1.1310 - val_acc: 0.6606\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8223 - acc: 0.7392\n",
      "Epoch 00006: val_loss improved from 0.84711 to 0.83172, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_5_conv_checkpoint/006-0.8317.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.8225 - acc: 0.7392 - val_loss: 0.8317 - val_acc: 0.7461\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7016 - acc: 0.7823\n",
      "Epoch 00007: val_loss did not improve from 0.83172\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.7017 - acc: 0.7823 - val_loss: 1.5601 - val_acc: 0.6164\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6665 - acc: 0.7921\n",
      "Epoch 00008: val_loss improved from 0.83172 to 0.60167, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_5_conv_checkpoint/008-0.6017.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.6664 - acc: 0.7921 - val_loss: 0.6017 - val_acc: 0.8269\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6008 - acc: 0.8125\n",
      "Epoch 00009: val_loss did not improve from 0.60167\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.6008 - acc: 0.8125 - val_loss: 0.6407 - val_acc: 0.8160\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5614 - acc: 0.8249\n",
      "Epoch 00010: val_loss improved from 0.60167 to 0.56787, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_5_conv_checkpoint/010-0.5679.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5614 - acc: 0.8249 - val_loss: 0.5679 - val_acc: 0.8397\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5319 - acc: 0.8363\n",
      "Epoch 00011: val_loss did not improve from 0.56787\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5319 - acc: 0.8363 - val_loss: 0.5862 - val_acc: 0.8332\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5050 - acc: 0.8423\n",
      "Epoch 00012: val_loss improved from 0.56787 to 0.56266, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_5_conv_checkpoint/012-0.5627.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5050 - acc: 0.8424 - val_loss: 0.5627 - val_acc: 0.8442\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5068 - acc: 0.8410\n",
      "Epoch 00013: val_loss did not improve from 0.56266\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5068 - acc: 0.8409 - val_loss: 0.5703 - val_acc: 0.8390\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4759 - acc: 0.8530\n",
      "Epoch 00014: val_loss improved from 0.56266 to 0.51741, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_5_conv_checkpoint/014-0.5174.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.4759 - acc: 0.8530 - val_loss: 0.5174 - val_acc: 0.8661\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4536 - acc: 0.8586\n",
      "Epoch 00015: val_loss did not improve from 0.51741\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.4535 - acc: 0.8586 - val_loss: 0.5374 - val_acc: 0.8514\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4291 - acc: 0.8645\n",
      "Epoch 00016: val_loss did not improve from 0.51741\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.4292 - acc: 0.8644 - val_loss: 0.6160 - val_acc: 0.8328\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4198 - acc: 0.8682\n",
      "Epoch 00017: val_loss did not improve from 0.51741\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.4197 - acc: 0.8682 - val_loss: 0.5303 - val_acc: 0.8658\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4092 - acc: 0.8713\n",
      "Epoch 00018: val_loss improved from 0.51741 to 0.48599, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_5_conv_checkpoint/018-0.4860.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.4092 - acc: 0.8713 - val_loss: 0.4860 - val_acc: 0.8696\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3935 - acc: 0.8749\n",
      "Epoch 00019: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3935 - acc: 0.8748 - val_loss: 0.5837 - val_acc: 0.8456\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3813 - acc: 0.8776\n",
      "Epoch 00020: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3814 - acc: 0.8776 - val_loss: 0.5619 - val_acc: 0.8505\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3725 - acc: 0.8805\n",
      "Epoch 00021: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3724 - acc: 0.8806 - val_loss: 0.5063 - val_acc: 0.8649\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3608 - acc: 0.8856\n",
      "Epoch 00022: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3608 - acc: 0.8856 - val_loss: 0.5119 - val_acc: 0.8609\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3493 - acc: 0.8858\n",
      "Epoch 00023: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3492 - acc: 0.8858 - val_loss: 0.5463 - val_acc: 0.8570\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3365 - acc: 0.8910\n",
      "Epoch 00024: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3365 - acc: 0.8910 - val_loss: 0.6175 - val_acc: 0.8477\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3398 - acc: 0.8921\n",
      "Epoch 00025: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3398 - acc: 0.8921 - val_loss: 0.5107 - val_acc: 0.8675\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3293 - acc: 0.8935\n",
      "Epoch 00026: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3294 - acc: 0.8935 - val_loss: 0.5608 - val_acc: 0.8507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3205 - acc: 0.8962\n",
      "Epoch 00027: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3204 - acc: 0.8962 - val_loss: 0.5311 - val_acc: 0.8654\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3127 - acc: 0.8983\n",
      "Epoch 00028: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3126 - acc: 0.8983 - val_loss: 0.5165 - val_acc: 0.8616\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2973 - acc: 0.9016\n",
      "Epoch 00029: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2973 - acc: 0.9016 - val_loss: 0.5217 - val_acc: 0.8735\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3008 - acc: 0.9021\n",
      "Epoch 00030: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3008 - acc: 0.9021 - val_loss: 0.4913 - val_acc: 0.8784\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2970 - acc: 0.9029\n",
      "Epoch 00031: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2969 - acc: 0.9029 - val_loss: 0.5176 - val_acc: 0.8703\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2772 - acc: 0.9101\n",
      "Epoch 00032: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2772 - acc: 0.9101 - val_loss: 0.4884 - val_acc: 0.8775\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2803 - acc: 0.9076\n",
      "Epoch 00033: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2803 - acc: 0.9076 - val_loss: 0.5172 - val_acc: 0.8754\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2810 - acc: 0.9085\n",
      "Epoch 00034: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2810 - acc: 0.9085 - val_loss: 0.5362 - val_acc: 0.8675\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2655 - acc: 0.9141\n",
      "Epoch 00035: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2655 - acc: 0.9141 - val_loss: 0.5350 - val_acc: 0.8705\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2636 - acc: 0.9150\n",
      "Epoch 00036: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2636 - acc: 0.9150 - val_loss: 0.4916 - val_acc: 0.8779\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2594 - acc: 0.9168\n",
      "Epoch 00037: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2594 - acc: 0.9168 - val_loss: 0.5196 - val_acc: 0.8712\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2568 - acc: 0.9165\n",
      "Epoch 00038: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2568 - acc: 0.9165 - val_loss: 0.5285 - val_acc: 0.8777\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2525 - acc: 0.9179\n",
      "Epoch 00039: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2525 - acc: 0.9179 - val_loss: 0.5399 - val_acc: 0.8689\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2516 - acc: 0.9183\n",
      "Epoch 00040: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2516 - acc: 0.9182 - val_loss: 0.5412 - val_acc: 0.8740\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2601 - acc: 0.9161\n",
      "Epoch 00041: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2600 - acc: 0.9162 - val_loss: 0.5156 - val_acc: 0.8719\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2542 - acc: 0.9153\n",
      "Epoch 00042: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2541 - acc: 0.9153 - val_loss: 0.5170 - val_acc: 0.8765\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2436 - acc: 0.9198\n",
      "Epoch 00043: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2438 - acc: 0.9198 - val_loss: 0.6634 - val_acc: 0.8421\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2568 - acc: 0.9174\n",
      "Epoch 00044: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2568 - acc: 0.9173 - val_loss: 0.5087 - val_acc: 0.8693\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2370 - acc: 0.9236\n",
      "Epoch 00045: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2370 - acc: 0.9236 - val_loss: 0.5792 - val_acc: 0.8751\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2290 - acc: 0.9247\n",
      "Epoch 00046: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2290 - acc: 0.9247 - val_loss: 0.6878 - val_acc: 0.8435\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2337 - acc: 0.9227\n",
      "Epoch 00047: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2337 - acc: 0.9227 - val_loss: 0.5156 - val_acc: 0.8758\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2380 - acc: 0.9224\n",
      "Epoch 00048: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2380 - acc: 0.9224 - val_loss: 0.5647 - val_acc: 0.8607\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2518 - acc: 0.9178\n",
      "Epoch 00049: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2518 - acc: 0.9178 - val_loss: 0.5477 - val_acc: 0.8747\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2279 - acc: 0.9270\n",
      "Epoch 00050: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2279 - acc: 0.9270 - val_loss: 0.5355 - val_acc: 0.8684\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2342 - acc: 0.9254\n",
      "Epoch 00051: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2341 - acc: 0.9254 - val_loss: 0.5617 - val_acc: 0.8721\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2203 - acc: 0.9270\n",
      "Epoch 00052: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2203 - acc: 0.9270 - val_loss: 0.5528 - val_acc: 0.8710\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2221 - acc: 0.9280\n",
      "Epoch 00053: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2221 - acc: 0.9280 - val_loss: 0.5820 - val_acc: 0.8719\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2227 - acc: 0.9282\n",
      "Epoch 00054: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2227 - acc: 0.9282 - val_loss: 0.5733 - val_acc: 0.8730\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2178 - acc: 0.9289\n",
      "Epoch 00055: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2178 - acc: 0.9289 - val_loss: 0.5038 - val_acc: 0.8763\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2105 - acc: 0.9324\n",
      "Epoch 00056: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2105 - acc: 0.9324 - val_loss: 0.5742 - val_acc: 0.8724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2128 - acc: 0.9307\n",
      "Epoch 00057: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2127 - acc: 0.9307 - val_loss: 0.5346 - val_acc: 0.8763\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2037 - acc: 0.9333\n",
      "Epoch 00058: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2038 - acc: 0.9332 - val_loss: 0.5545 - val_acc: 0.8826\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2080 - acc: 0.9330\n",
      "Epoch 00059: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2080 - acc: 0.9331 - val_loss: 0.5577 - val_acc: 0.8761\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2007 - acc: 0.9347\n",
      "Epoch 00060: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2008 - acc: 0.9347 - val_loss: 0.5496 - val_acc: 0.8703\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2050 - acc: 0.9331\n",
      "Epoch 00061: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2050 - acc: 0.9331 - val_loss: 0.5884 - val_acc: 0.8744\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2020 - acc: 0.9337\n",
      "Epoch 00062: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2020 - acc: 0.9338 - val_loss: 0.5594 - val_acc: 0.8675\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2000 - acc: 0.9356\n",
      "Epoch 00063: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2001 - acc: 0.9356 - val_loss: 0.5503 - val_acc: 0.8803\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9345\n",
      "Epoch 00064: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2061 - acc: 0.9345 - val_loss: 0.5487 - val_acc: 0.8765\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1964 - acc: 0.9367\n",
      "Epoch 00065: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1965 - acc: 0.9367 - val_loss: 0.6065 - val_acc: 0.8635\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2095 - acc: 0.9316\n",
      "Epoch 00066: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2094 - acc: 0.9316 - val_loss: 0.5188 - val_acc: 0.8782\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9366\n",
      "Epoch 00067: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1967 - acc: 0.9366 - val_loss: 0.5499 - val_acc: 0.8761\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1955 - acc: 0.9364\n",
      "Epoch 00068: val_loss did not improve from 0.48599\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1955 - acc: 0.9364 - val_loss: 0.5464 - val_acc: 0.8772\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 580us/sample - loss: 0.5893 - acc: 0.8351\n",
      "Loss: 0.5893327088742242 Accuracy: 0.8350986\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3990 - acc: 0.2105\n",
      "Epoch 00001: val_loss improved from inf to 1.86501, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/001-1.8650.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 2.3989 - acc: 0.2106 - val_loss: 1.8650 - val_acc: 0.4128\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6784 - acc: 0.4402\n",
      "Epoch 00002: val_loss improved from 1.86501 to 1.37932, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/002-1.3793.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 1.6784 - acc: 0.4402 - val_loss: 1.3793 - val_acc: 0.5514\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2639 - acc: 0.5989\n",
      "Epoch 00003: val_loss did not improve from 1.37932\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 1.2640 - acc: 0.5989 - val_loss: 1.8914 - val_acc: 0.3769\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9621 - acc: 0.6990\n",
      "Epoch 00004: val_loss improved from 1.37932 to 0.86481, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/004-0.8648.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.9620 - acc: 0.6991 - val_loss: 0.8648 - val_acc: 0.7517\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7801 - acc: 0.7620\n",
      "Epoch 00005: val_loss improved from 0.86481 to 0.67100, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/005-0.6710.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.7801 - acc: 0.7620 - val_loss: 0.6710 - val_acc: 0.8092\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7452 - acc: 0.7727\n",
      "Epoch 00006: val_loss improved from 0.67100 to 0.56249, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/006-0.5625.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.7452 - acc: 0.7727 - val_loss: 0.5625 - val_acc: 0.8423\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5849 - acc: 0.8240\n",
      "Epoch 00007: val_loss did not improve from 0.56249\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5849 - acc: 0.8240 - val_loss: 0.7603 - val_acc: 0.7843\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5927 - acc: 0.8204\n",
      "Epoch 00008: val_loss improved from 0.56249 to 0.52332, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/008-0.5233.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5927 - acc: 0.8204 - val_loss: 0.5233 - val_acc: 0.8512\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5183 - acc: 0.8432\n",
      "Epoch 00009: val_loss did not improve from 0.52332\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5183 - acc: 0.8432 - val_loss: 0.5419 - val_acc: 0.8376\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5374 - acc: 0.8337\n",
      "Epoch 00010: val_loss did not improve from 0.52332\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5373 - acc: 0.8337 - val_loss: 0.5489 - val_acc: 0.8553\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5295 - acc: 0.8381\n",
      "Epoch 00011: val_loss improved from 0.52332 to 0.43640, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/011-0.4364.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5296 - acc: 0.8381 - val_loss: 0.4364 - val_acc: 0.8684\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5594 - acc: 0.8292\n",
      "Epoch 00012: val_loss did not improve from 0.43640\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.5594 - acc: 0.8292 - val_loss: 0.6413 - val_acc: 0.8139\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4916 - acc: 0.8493\n",
      "Epoch 00013: val_loss improved from 0.43640 to 0.42304, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/013-0.4230.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.4916 - acc: 0.8493 - val_loss: 0.4230 - val_acc: 0.8833\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4137 - acc: 0.8730\n",
      "Epoch 00014: val_loss improved from 0.42304 to 0.35235, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/014-0.3523.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.4137 - acc: 0.8731 - val_loss: 0.3523 - val_acc: 0.9001\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3909 - acc: 0.8778\n",
      "Epoch 00015: val_loss improved from 0.35235 to 0.34686, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/015-0.3469.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3908 - acc: 0.8778 - val_loss: 0.3469 - val_acc: 0.9050\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3727 - acc: 0.8861\n",
      "Epoch 00016: val_loss improved from 0.34686 to 0.30338, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/016-0.3034.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3727 - acc: 0.8862 - val_loss: 0.3034 - val_acc: 0.9220\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3452 - acc: 0.8921\n",
      "Epoch 00017: val_loss did not improve from 0.30338\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3452 - acc: 0.8921 - val_loss: 0.3048 - val_acc: 0.9210\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3293 - acc: 0.8974\n",
      "Epoch 00018: val_loss did not improve from 0.30338\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3292 - acc: 0.8974 - val_loss: 0.3406 - val_acc: 0.9126\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3171 - acc: 0.8988\n",
      "Epoch 00019: val_loss did not improve from 0.30338\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3170 - acc: 0.8988 - val_loss: 0.3399 - val_acc: 0.9099\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3041 - acc: 0.9048\n",
      "Epoch 00020: val_loss did not improve from 0.30338\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3042 - acc: 0.9048 - val_loss: 0.5068 - val_acc: 0.8544\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3147 - acc: 0.9009\n",
      "Epoch 00021: val_loss improved from 0.30338 to 0.30270, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/021-0.3027.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3147 - acc: 0.9009 - val_loss: 0.3027 - val_acc: 0.9175\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2912 - acc: 0.9081\n",
      "Epoch 00022: val_loss did not improve from 0.30270\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2912 - acc: 0.9081 - val_loss: 0.3043 - val_acc: 0.9199\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2822 - acc: 0.9102\n",
      "Epoch 00023: val_loss did not improve from 0.30270\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2826 - acc: 0.9101 - val_loss: 0.7369 - val_acc: 0.7792\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3578 - acc: 0.8868\n",
      "Epoch 00024: val_loss did not improve from 0.30270\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3577 - acc: 0.8868 - val_loss: 0.3190 - val_acc: 0.9180\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2876 - acc: 0.9087\n",
      "Epoch 00025: val_loss did not improve from 0.30270\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2877 - acc: 0.9087 - val_loss: 0.4269 - val_acc: 0.8984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2738 - acc: 0.9133\n",
      "Epoch 00026: val_loss did not improve from 0.30270\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2738 - acc: 0.9133 - val_loss: 0.3170 - val_acc: 0.9201\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2532 - acc: 0.9204\n",
      "Epoch 00027: val_loss did not improve from 0.30270\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2532 - acc: 0.9204 - val_loss: 0.3574 - val_acc: 0.9038\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2539 - acc: 0.9195\n",
      "Epoch 00028: val_loss did not improve from 0.30270\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2539 - acc: 0.9195 - val_loss: 0.3219 - val_acc: 0.9094\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2442 - acc: 0.9217\n",
      "Epoch 00029: val_loss did not improve from 0.30270\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2442 - acc: 0.9217 - val_loss: 0.3382 - val_acc: 0.9201\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2372 - acc: 0.9247\n",
      "Epoch 00030: val_loss did not improve from 0.30270\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2372 - acc: 0.9247 - val_loss: 0.3244 - val_acc: 0.9175\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2346 - acc: 0.9249\n",
      "Epoch 00031: val_loss improved from 0.30270 to 0.28330, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/031-0.2833.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2346 - acc: 0.9249 - val_loss: 0.2833 - val_acc: 0.9292\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2272 - acc: 0.9284\n",
      "Epoch 00032: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2273 - acc: 0.9284 - val_loss: 0.3453 - val_acc: 0.9059\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2366 - acc: 0.9229\n",
      "Epoch 00033: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2367 - acc: 0.9228 - val_loss: 0.3216 - val_acc: 0.9178\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2261 - acc: 0.9270\n",
      "Epoch 00034: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2261 - acc: 0.9270 - val_loss: 0.2996 - val_acc: 0.9189\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2189 - acc: 0.9289\n",
      "Epoch 00035: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2189 - acc: 0.9288 - val_loss: 0.4464 - val_acc: 0.9001\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2230 - acc: 0.9285\n",
      "Epoch 00036: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2230 - acc: 0.9285 - val_loss: 0.3181 - val_acc: 0.9194\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2138 - acc: 0.9308\n",
      "Epoch 00037: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2138 - acc: 0.9308 - val_loss: 0.3093 - val_acc: 0.9175\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2095 - acc: 0.9310\n",
      "Epoch 00038: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2096 - acc: 0.9309 - val_loss: 0.3573 - val_acc: 0.9154\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2134 - acc: 0.9298\n",
      "Epoch 00039: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2133 - acc: 0.9298 - val_loss: 0.2892 - val_acc: 0.9264\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1991 - acc: 0.9354\n",
      "Epoch 00040: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1991 - acc: 0.9354 - val_loss: 0.2974 - val_acc: 0.9271\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1945 - acc: 0.9362\n",
      "Epoch 00041: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1945 - acc: 0.9363 - val_loss: 0.2981 - val_acc: 0.9252\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9363\n",
      "Epoch 00042: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1966 - acc: 0.9363 - val_loss: 0.2999 - val_acc: 0.9297\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9366\n",
      "Epoch 00043: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1964 - acc: 0.9366 - val_loss: 0.3038 - val_acc: 0.9306\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1825 - acc: 0.9403\n",
      "Epoch 00044: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1825 - acc: 0.9403 - val_loss: 0.3348 - val_acc: 0.9248\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9370\n",
      "Epoch 00045: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1956 - acc: 0.9370 - val_loss: 0.3285 - val_acc: 0.9222\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1816 - acc: 0.9414\n",
      "Epoch 00046: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1815 - acc: 0.9414 - val_loss: 0.2957 - val_acc: 0.9271\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1805 - acc: 0.9411\n",
      "Epoch 00047: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1805 - acc: 0.9411 - val_loss: 0.3073 - val_acc: 0.9234\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1740 - acc: 0.9428\n",
      "Epoch 00048: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1740 - acc: 0.9428 - val_loss: 0.3105 - val_acc: 0.9278\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1766 - acc: 0.9404\n",
      "Epoch 00049: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1766 - acc: 0.9404 - val_loss: 0.3246 - val_acc: 0.9143\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9434\n",
      "Epoch 00050: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1722 - acc: 0.9434 - val_loss: 0.2938 - val_acc: 0.9234\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1731 - acc: 0.9443\n",
      "Epoch 00051: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1731 - acc: 0.9443 - val_loss: 0.3035 - val_acc: 0.9273\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1693 - acc: 0.9442\n",
      "Epoch 00052: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1693 - acc: 0.9442 - val_loss: 0.3029 - val_acc: 0.9245\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9441\n",
      "Epoch 00053: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1720 - acc: 0.9441 - val_loss: 0.3156 - val_acc: 0.9283\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1708 - acc: 0.9439\n",
      "Epoch 00054: val_loss did not improve from 0.28330\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1708 - acc: 0.9439 - val_loss: 0.3288 - val_acc: 0.9250\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9463\n",
      "Epoch 00055: val_loss improved from 0.28330 to 0.28188, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_6_conv_checkpoint/055-0.2819.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1644 - acc: 0.9463 - val_loss: 0.2819 - val_acc: 0.9320\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9481\n",
      "Epoch 00056: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1595 - acc: 0.9481 - val_loss: 0.3176 - val_acc: 0.9292\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9456\n",
      "Epoch 00057: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1677 - acc: 0.9456 - val_loss: 0.3065 - val_acc: 0.9301\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9479\n",
      "Epoch 00058: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1604 - acc: 0.9479 - val_loss: 0.3395 - val_acc: 0.9285\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1613 - acc: 0.9467\n",
      "Epoch 00059: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1612 - acc: 0.9467 - val_loss: 0.3096 - val_acc: 0.9192\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9489\n",
      "Epoch 00060: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1580 - acc: 0.9488 - val_loss: 0.3381 - val_acc: 0.9208\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1631 - acc: 0.9474\n",
      "Epoch 00061: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1632 - acc: 0.9474 - val_loss: 0.3486 - val_acc: 0.9199\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1599 - acc: 0.9474\n",
      "Epoch 00062: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1599 - acc: 0.9474 - val_loss: 0.3036 - val_acc: 0.9290\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9462\n",
      "Epoch 00063: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1608 - acc: 0.9462 - val_loss: 0.3924 - val_acc: 0.9182\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1534 - acc: 0.9495\n",
      "Epoch 00064: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1535 - acc: 0.9494 - val_loss: 0.3039 - val_acc: 0.9255\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9481\n",
      "Epoch 00065: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1579 - acc: 0.9481 - val_loss: 0.3763 - val_acc: 0.9189\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1562 - acc: 0.9494\n",
      "Epoch 00066: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1561 - acc: 0.9494 - val_loss: 0.3182 - val_acc: 0.9301\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9511\n",
      "Epoch 00067: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1494 - acc: 0.9511 - val_loss: 0.3802 - val_acc: 0.9255\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1712 - acc: 0.9438\n",
      "Epoch 00068: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1712 - acc: 0.9437 - val_loss: 0.3089 - val_acc: 0.9234\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1607 - acc: 0.9468\n",
      "Epoch 00069: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1607 - acc: 0.9469 - val_loss: 0.2970 - val_acc: 0.9308\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9533\n",
      "Epoch 00070: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1424 - acc: 0.9533 - val_loss: 0.3107 - val_acc: 0.9259\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9515\n",
      "Epoch 00071: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1490 - acc: 0.9515 - val_loss: 0.3042 - val_acc: 0.9292\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1561 - acc: 0.9495\n",
      "Epoch 00072: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1561 - acc: 0.9495 - val_loss: 0.3029 - val_acc: 0.9336\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9523\n",
      "Epoch 00073: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1476 - acc: 0.9523 - val_loss: 0.3135 - val_acc: 0.9308\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9536\n",
      "Epoch 00074: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1389 - acc: 0.9536 - val_loss: 0.3319 - val_acc: 0.9215\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1410 - acc: 0.9530\n",
      "Epoch 00075: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1410 - acc: 0.9530 - val_loss: 0.3388 - val_acc: 0.9269\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1322 - acc: 0.9565\n",
      "Epoch 00076: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1322 - acc: 0.9565 - val_loss: 0.2845 - val_acc: 0.9304\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9537\n",
      "Epoch 00077: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1386 - acc: 0.9537 - val_loss: 0.3888 - val_acc: 0.9122\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9425\n",
      "Epoch 00078: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1780 - acc: 0.9425 - val_loss: 0.3109 - val_acc: 0.9236\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1395 - acc: 0.9540\n",
      "Epoch 00079: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1395 - acc: 0.9541 - val_loss: 0.3247 - val_acc: 0.9308\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9533\n",
      "Epoch 00080: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1414 - acc: 0.9533 - val_loss: 0.3317 - val_acc: 0.9301\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1403 - acc: 0.9546\n",
      "Epoch 00081: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1403 - acc: 0.9547 - val_loss: 0.3215 - val_acc: 0.9311\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9549\n",
      "Epoch 00082: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1386 - acc: 0.9549 - val_loss: 0.3315 - val_acc: 0.9301\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9562\n",
      "Epoch 00083: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1331 - acc: 0.9562 - val_loss: 0.3086 - val_acc: 0.9322\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9549\n",
      "Epoch 00084: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1378 - acc: 0.9549 - val_loss: 0.3044 - val_acc: 0.9306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9574\n",
      "Epoch 00085: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1315 - acc: 0.9574 - val_loss: 0.3235 - val_acc: 0.9366\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9579\n",
      "Epoch 00086: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1343 - acc: 0.9579 - val_loss: 0.3546 - val_acc: 0.9208\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1434 - acc: 0.9538\n",
      "Epoch 00087: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1434 - acc: 0.9538 - val_loss: 0.3223 - val_acc: 0.9283\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9563\n",
      "Epoch 00088: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1322 - acc: 0.9563 - val_loss: 0.3319 - val_acc: 0.9364\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9602\n",
      "Epoch 00089: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1253 - acc: 0.9602 - val_loss: 0.3594 - val_acc: 0.9231\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9571\n",
      "Epoch 00090: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1333 - acc: 0.9571 - val_loss: 0.3102 - val_acc: 0.9338\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9565\n",
      "Epoch 00091: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1329 - acc: 0.9565 - val_loss: 0.3217 - val_acc: 0.9292\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9576\n",
      "Epoch 00092: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1282 - acc: 0.9576 - val_loss: 0.3844 - val_acc: 0.9154\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9513\n",
      "Epoch 00093: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1535 - acc: 0.9513 - val_loss: 0.3613 - val_acc: 0.9276\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1431 - acc: 0.9531\n",
      "Epoch 00094: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1431 - acc: 0.9531 - val_loss: 0.3617 - val_acc: 0.9227\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9567\n",
      "Epoch 00095: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1321 - acc: 0.9567 - val_loss: 0.3638 - val_acc: 0.9304\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9581\n",
      "Epoch 00096: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1277 - acc: 0.9581 - val_loss: 0.3670 - val_acc: 0.9269\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9579\n",
      "Epoch 00097: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1288 - acc: 0.9579 - val_loss: 0.3008 - val_acc: 0.9320\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9536\n",
      "Epoch 00098: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1405 - acc: 0.9536 - val_loss: 0.3748 - val_acc: 0.9280\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9563\n",
      "Epoch 00099: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1305 - acc: 0.9563 - val_loss: 0.4140 - val_acc: 0.9187\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9565\n",
      "Epoch 00100: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1362 - acc: 0.9565 - val_loss: 0.3586 - val_acc: 0.9294\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9601\n",
      "Epoch 00101: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1196 - acc: 0.9601 - val_loss: 0.3412 - val_acc: 0.9343\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9565\n",
      "Epoch 00102: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1340 - acc: 0.9565 - val_loss: 0.3367 - val_acc: 0.9304\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9590\n",
      "Epoch 00103: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1287 - acc: 0.9590 - val_loss: 0.3474 - val_acc: 0.9283\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1319 - acc: 0.9577\n",
      "Epoch 00104: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1319 - acc: 0.9577 - val_loss: 0.3435 - val_acc: 0.9320\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9596\n",
      "Epoch 00105: val_loss did not improve from 0.28188\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1262 - acc: 0.9596 - val_loss: 0.3219 - val_acc: 0.9283\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 621us/sample - loss: 0.3347 - acc: 0.9140\n",
      "Loss: 0.3347402188513014 Accuracy: 0.9140187\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5201 - acc: 0.1661\n",
      "Epoch 00001: val_loss improved from inf to 2.25108, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/001-2.2511.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 2.5201 - acc: 0.1661 - val_loss: 2.2511 - val_acc: 0.3007\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7287 - acc: 0.4235\n",
      "Epoch 00002: val_loss improved from 2.25108 to 1.41802, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/002-1.4180.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 1.7287 - acc: 0.4236 - val_loss: 1.4180 - val_acc: 0.5330\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3293 - acc: 0.5640\n",
      "Epoch 00003: val_loss did not improve from 1.41802\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 1.3292 - acc: 0.5640 - val_loss: 4.5297 - val_acc: 0.1829\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1188 - acc: 0.6449\n",
      "Epoch 00004: val_loss improved from 1.41802 to 1.00605, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/004-1.0061.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 1.1187 - acc: 0.6449 - val_loss: 1.0061 - val_acc: 0.6986\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7753 - acc: 0.7582\n",
      "Epoch 00005: val_loss improved from 1.00605 to 0.40544, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/005-0.4054.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.7752 - acc: 0.7582 - val_loss: 0.4054 - val_acc: 0.8826\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6107 - acc: 0.8089\n",
      "Epoch 00006: val_loss improved from 0.40544 to 0.33903, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/006-0.3390.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.6106 - acc: 0.8089 - val_loss: 0.3390 - val_acc: 0.9064\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5146 - acc: 0.8413\n",
      "Epoch 00007: val_loss did not improve from 0.33903\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.5147 - acc: 0.8412 - val_loss: 0.4514 - val_acc: 0.8749\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4640 - acc: 0.8585\n",
      "Epoch 00008: val_loss did not improve from 0.33903\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.4641 - acc: 0.8585 - val_loss: 0.3868 - val_acc: 0.8884\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4162 - acc: 0.8714\n",
      "Epoch 00009: val_loss improved from 0.33903 to 0.25017, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/009-0.2502.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.4161 - acc: 0.8714 - val_loss: 0.2502 - val_acc: 0.9259\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3813 - acc: 0.8827\n",
      "Epoch 00010: val_loss improved from 0.25017 to 0.24748, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/010-0.2475.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3813 - acc: 0.8827 - val_loss: 0.2475 - val_acc: 0.9306\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3496 - acc: 0.8912\n",
      "Epoch 00011: val_loss improved from 0.24748 to 0.22647, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/011-0.2265.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3496 - acc: 0.8912 - val_loss: 0.2265 - val_acc: 0.9348\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3559 - acc: 0.8896\n",
      "Epoch 00012: val_loss did not improve from 0.22647\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3559 - acc: 0.8896 - val_loss: 0.2804 - val_acc: 0.9222\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3502 - acc: 0.8899\n",
      "Epoch 00013: val_loss did not improve from 0.22647\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3502 - acc: 0.8898 - val_loss: 0.4735 - val_acc: 0.8649\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3095 - acc: 0.9033\n",
      "Epoch 00014: val_loss improved from 0.22647 to 0.22012, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/014-0.2201.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.3095 - acc: 0.9033 - val_loss: 0.2201 - val_acc: 0.9429\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2966 - acc: 0.9078\n",
      "Epoch 00015: val_loss did not improve from 0.22012\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2966 - acc: 0.9078 - val_loss: 0.2328 - val_acc: 0.9401\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.9144\n",
      "Epoch 00016: val_loss did not improve from 0.22012\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2756 - acc: 0.9144 - val_loss: 0.2223 - val_acc: 0.9380\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2645 - acc: 0.9163\n",
      "Epoch 00017: val_loss improved from 0.22012 to 0.20545, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/017-0.2054.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2645 - acc: 0.9163 - val_loss: 0.2054 - val_acc: 0.9439\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2551 - acc: 0.9192\n",
      "Epoch 00018: val_loss improved from 0.20545 to 0.20280, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/018-0.2028.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2551 - acc: 0.9193 - val_loss: 0.2028 - val_acc: 0.9392\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2431 - acc: 0.9239\n",
      "Epoch 00019: val_loss did not improve from 0.20280\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2430 - acc: 0.9239 - val_loss: 0.2051 - val_acc: 0.9415\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2324 - acc: 0.9258\n",
      "Epoch 00020: val_loss did not improve from 0.20280\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2324 - acc: 0.9258 - val_loss: 0.2318 - val_acc: 0.9390\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2347 - acc: 0.9257\n",
      "Epoch 00021: val_loss improved from 0.20280 to 0.17746, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/021-0.1775.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2348 - acc: 0.9256 - val_loss: 0.1775 - val_acc: 0.9436\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2111 - acc: 0.9322\n",
      "Epoch 00022: val_loss did not improve from 0.17746\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2110 - acc: 0.9322 - val_loss: 0.1926 - val_acc: 0.9429\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2100 - acc: 0.9330\n",
      "Epoch 00023: val_loss did not improve from 0.17746\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2100 - acc: 0.9330 - val_loss: 0.1902 - val_acc: 0.9492\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9329\n",
      "Epoch 00024: val_loss did not improve from 0.17746\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.2044 - acc: 0.9329 - val_loss: 0.1879 - val_acc: 0.9506\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1943 - acc: 0.9382\n",
      "Epoch 00025: val_loss did not improve from 0.17746\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1942 - acc: 0.9382 - val_loss: 0.1857 - val_acc: 0.9506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1898 - acc: 0.9392\n",
      "Epoch 00026: val_loss did not improve from 0.17746\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1899 - acc: 0.9391 - val_loss: 0.1841 - val_acc: 0.9529\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1848 - acc: 0.9421\n",
      "Epoch 00027: val_loss did not improve from 0.17746\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1849 - acc: 0.9421 - val_loss: 0.2074 - val_acc: 0.9420\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1862 - acc: 0.9398\n",
      "Epoch 00028: val_loss did not improve from 0.17746\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1862 - acc: 0.9398 - val_loss: 0.1934 - val_acc: 0.9478\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1789 - acc: 0.9426\n",
      "Epoch 00029: val_loss did not improve from 0.17746\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1789 - acc: 0.9426 - val_loss: 0.1780 - val_acc: 0.9527\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1701 - acc: 0.9450\n",
      "Epoch 00030: val_loss did not improve from 0.17746\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1701 - acc: 0.9450 - val_loss: 0.2126 - val_acc: 0.9504\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1687 - acc: 0.9460\n",
      "Epoch 00031: val_loss did not improve from 0.17746\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1688 - acc: 0.9460 - val_loss: 0.1949 - val_acc: 0.9453\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1723 - acc: 0.9444\n",
      "Epoch 00032: val_loss improved from 0.17746 to 0.17224, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/032-0.1722.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1724 - acc: 0.9444 - val_loss: 0.1722 - val_acc: 0.9511\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1596 - acc: 0.9493\n",
      "Epoch 00033: val_loss did not improve from 0.17224\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1596 - acc: 0.9492 - val_loss: 0.1966 - val_acc: 0.9481\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1635 - acc: 0.9483\n",
      "Epoch 00034: val_loss did not improve from 0.17224\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1635 - acc: 0.9483 - val_loss: 0.1927 - val_acc: 0.9485\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9515\n",
      "Epoch 00035: val_loss did not improve from 0.17224\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1532 - acc: 0.9515 - val_loss: 0.1799 - val_acc: 0.9515\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9519\n",
      "Epoch 00036: val_loss did not improve from 0.17224\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1513 - acc: 0.9519 - val_loss: 0.1816 - val_acc: 0.9478\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1469 - acc: 0.9539\n",
      "Epoch 00037: val_loss improved from 0.17224 to 0.17098, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_7_conv_checkpoint/037-0.1710.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1469 - acc: 0.9539 - val_loss: 0.1710 - val_acc: 0.9520\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1446 - acc: 0.9527\n",
      "Epoch 00038: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1446 - acc: 0.9527 - val_loss: 0.1993 - val_acc: 0.9525\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9554\n",
      "Epoch 00039: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1388 - acc: 0.9554 - val_loss: 0.2112 - val_acc: 0.9511\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1435 - acc: 0.9526\n",
      "Epoch 00040: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1435 - acc: 0.9526 - val_loss: 0.1808 - val_acc: 0.9525\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9572\n",
      "Epoch 00041: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1337 - acc: 0.9572 - val_loss: 0.1798 - val_acc: 0.9555\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9564\n",
      "Epoch 00042: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1338 - acc: 0.9564 - val_loss: 0.1759 - val_acc: 0.9550\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9577\n",
      "Epoch 00043: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1338 - acc: 0.9577 - val_loss: 0.1825 - val_acc: 0.9515\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9598\n",
      "Epoch 00044: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1260 - acc: 0.9598 - val_loss: 0.1935 - val_acc: 0.9499\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9577\n",
      "Epoch 00045: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1277 - acc: 0.9578 - val_loss: 0.2082 - val_acc: 0.9490\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9594\n",
      "Epoch 00046: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1246 - acc: 0.9594 - val_loss: 0.1854 - val_acc: 0.9485\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9587\n",
      "Epoch 00047: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1248 - acc: 0.9587 - val_loss: 0.1928 - val_acc: 0.9522\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9577\n",
      "Epoch 00048: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1298 - acc: 0.9577 - val_loss: 0.1943 - val_acc: 0.9460\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9611\n",
      "Epoch 00049: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1193 - acc: 0.9611 - val_loss: 0.2026 - val_acc: 0.9499\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1267 - acc: 0.9598\n",
      "Epoch 00050: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1267 - acc: 0.9598 - val_loss: 0.1989 - val_acc: 0.9483\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1192 - acc: 0.9603\n",
      "Epoch 00051: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1192 - acc: 0.9603 - val_loss: 0.1983 - val_acc: 0.9513\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1151 - acc: 0.9620\n",
      "Epoch 00052: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1151 - acc: 0.9620 - val_loss: 0.1814 - val_acc: 0.9541\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9633\n",
      "Epoch 00053: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1121 - acc: 0.9633 - val_loss: 0.1912 - val_acc: 0.9522\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9651\n",
      "Epoch 00054: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1083 - acc: 0.9651 - val_loss: 0.2226 - val_acc: 0.9513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9642\n",
      "Epoch 00055: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1104 - acc: 0.9642 - val_loss: 0.1909 - val_acc: 0.9483\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9634\n",
      "Epoch 00056: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1146 - acc: 0.9634 - val_loss: 0.1939 - val_acc: 0.9490\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9652\n",
      "Epoch 00057: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1067 - acc: 0.9652 - val_loss: 0.2170 - val_acc: 0.9469\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9645\n",
      "Epoch 00058: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1076 - acc: 0.9645 - val_loss: 0.1975 - val_acc: 0.9529\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9656\n",
      "Epoch 00059: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1056 - acc: 0.9656 - val_loss: 0.2040 - val_acc: 0.9546\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9646\n",
      "Epoch 00060: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1089 - acc: 0.9646 - val_loss: 0.2330 - val_acc: 0.9515\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1125 - acc: 0.9631\n",
      "Epoch 00061: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1125 - acc: 0.9631 - val_loss: 0.2096 - val_acc: 0.9513\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9657\n",
      "Epoch 00062: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1044 - acc: 0.9657 - val_loss: 0.1855 - val_acc: 0.9550\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1016 - acc: 0.9676\n",
      "Epoch 00063: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1015 - acc: 0.9676 - val_loss: 0.2262 - val_acc: 0.9481\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9670\n",
      "Epoch 00064: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1000 - acc: 0.9670 - val_loss: 0.2155 - val_acc: 0.9492\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9667\n",
      "Epoch 00065: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1029 - acc: 0.9666 - val_loss: 0.2319 - val_acc: 0.9467\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9648\n",
      "Epoch 00066: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1090 - acc: 0.9647 - val_loss: 0.4274 - val_acc: 0.9252\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9552\n",
      "Epoch 00067: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1433 - acc: 0.9553 - val_loss: 0.2552 - val_acc: 0.9443\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9650\n",
      "Epoch 00068: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1094 - acc: 0.9650 - val_loss: 0.3268 - val_acc: 0.9257\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1283 - acc: 0.9583\n",
      "Epoch 00069: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1283 - acc: 0.9583 - val_loss: 0.2382 - val_acc: 0.9462\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9668\n",
      "Epoch 00070: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1022 - acc: 0.9668 - val_loss: 0.2069 - val_acc: 0.9564\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9679\n",
      "Epoch 00071: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0964 - acc: 0.9679 - val_loss: 0.2167 - val_acc: 0.9515\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9675\n",
      "Epoch 00072: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0989 - acc: 0.9675 - val_loss: 0.1841 - val_acc: 0.9525\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9670\n",
      "Epoch 00073: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0980 - acc: 0.9670 - val_loss: 0.2277 - val_acc: 0.9532\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9683\n",
      "Epoch 00074: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0978 - acc: 0.9683 - val_loss: 0.2049 - val_acc: 0.9541\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9683\n",
      "Epoch 00075: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0981 - acc: 0.9683 - val_loss: 0.2308 - val_acc: 0.9509\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9666\n",
      "Epoch 00076: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1021 - acc: 0.9666 - val_loss: 0.1930 - val_acc: 0.9527\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9696\n",
      "Epoch 00077: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0975 - acc: 0.9696 - val_loss: 0.2008 - val_acc: 0.9571\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9709\n",
      "Epoch 00078: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0905 - acc: 0.9709 - val_loss: 0.2238 - val_acc: 0.9541\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9720\n",
      "Epoch 00079: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0860 - acc: 0.9720 - val_loss: 0.2091 - val_acc: 0.9550\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9704\n",
      "Epoch 00080: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0923 - acc: 0.9704 - val_loss: 0.2109 - val_acc: 0.9525\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9714\n",
      "Epoch 00081: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0908 - acc: 0.9714 - val_loss: 0.2195 - val_acc: 0.9539\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9697\n",
      "Epoch 00082: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0934 - acc: 0.9697 - val_loss: 0.2024 - val_acc: 0.9497\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9706\n",
      "Epoch 00083: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0878 - acc: 0.9706 - val_loss: 0.2327 - val_acc: 0.9515\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9713\n",
      "Epoch 00084: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0867 - acc: 0.9713 - val_loss: 0.2283 - val_acc: 0.9495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9701\n",
      "Epoch 00085: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0917 - acc: 0.9701 - val_loss: 0.2515 - val_acc: 0.9448\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9718\n",
      "Epoch 00086: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0863 - acc: 0.9718 - val_loss: 0.2109 - val_acc: 0.9569\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9722\n",
      "Epoch 00087: val_loss did not improve from 0.17098\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0867 - acc: 0.9722 - val_loss: 0.2171 - val_acc: 0.9539\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 635us/sample - loss: 0.2094 - acc: 0.9431\n",
      "Loss: 0.20942693221482409 Accuracy: 0.9430945\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.5522 - acc: 0.1508\n",
      "Epoch 00001: val_loss improved from inf to 2.03012, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/001-2.0301.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 2.5522 - acc: 0.1508 - val_loss: 2.0301 - val_acc: 0.3454\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5673 - acc: 0.4753\n",
      "Epoch 00002: val_loss improved from 2.03012 to 1.03297, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/002-1.0330.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 1.5673 - acc: 0.4753 - val_loss: 1.0330 - val_acc: 0.6751\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0853 - acc: 0.6446\n",
      "Epoch 00003: val_loss improved from 1.03297 to 0.91707, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/003-0.9171.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 1.0853 - acc: 0.6446 - val_loss: 0.9171 - val_acc: 0.7056\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7295 - acc: 0.7673\n",
      "Epoch 00004: val_loss improved from 0.91707 to 0.33195, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/004-0.3319.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.7294 - acc: 0.7673 - val_loss: 0.3319 - val_acc: 0.8917\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5115 - acc: 0.8406\n",
      "Epoch 00005: val_loss improved from 0.33195 to 0.24812, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/005-0.2481.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.5115 - acc: 0.8406 - val_loss: 0.2481 - val_acc: 0.9269\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4122 - acc: 0.8763\n",
      "Epoch 00006: val_loss did not improve from 0.24812\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.4122 - acc: 0.8762 - val_loss: 0.3066 - val_acc: 0.9038\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3576 - acc: 0.8906\n",
      "Epoch 00007: val_loss improved from 0.24812 to 0.18458, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/007-0.1846.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3576 - acc: 0.8906 - val_loss: 0.1846 - val_acc: 0.9469\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3169 - acc: 0.9041\n",
      "Epoch 00008: val_loss did not improve from 0.18458\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3170 - acc: 0.9041 - val_loss: 0.2593 - val_acc: 0.9175\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2850 - acc: 0.9131\n",
      "Epoch 00009: val_loss improved from 0.18458 to 0.17805, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/009-0.1780.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2850 - acc: 0.9131 - val_loss: 0.1780 - val_acc: 0.9548\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2705 - acc: 0.9157\n",
      "Epoch 00010: val_loss improved from 0.17805 to 0.16519, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/010-0.1652.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2705 - acc: 0.9157 - val_loss: 0.1652 - val_acc: 0.9532\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2436 - acc: 0.9248\n",
      "Epoch 00011: val_loss improved from 0.16519 to 0.14829, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/011-0.1483.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2436 - acc: 0.9248 - val_loss: 0.1483 - val_acc: 0.9546\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2282 - acc: 0.9310\n",
      "Epoch 00012: val_loss did not improve from 0.14829\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2283 - acc: 0.9310 - val_loss: 0.1818 - val_acc: 0.9485\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9365\n",
      "Epoch 00013: val_loss improved from 0.14829 to 0.14603, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/013-0.1460.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2061 - acc: 0.9365 - val_loss: 0.1460 - val_acc: 0.9583\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9384\n",
      "Epoch 00014: val_loss did not improve from 0.14603\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1993 - acc: 0.9384 - val_loss: 0.1511 - val_acc: 0.9576\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1843 - acc: 0.9429\n",
      "Epoch 00015: val_loss improved from 0.14603 to 0.14498, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/015-0.1450.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1843 - acc: 0.9429 - val_loss: 0.1450 - val_acc: 0.9574\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9446\n",
      "Epoch 00016: val_loss improved from 0.14498 to 0.12938, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/016-0.1294.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1767 - acc: 0.9446 - val_loss: 0.1294 - val_acc: 0.9620\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9461\n",
      "Epoch 00017: val_loss did not improve from 0.12938\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1704 - acc: 0.9461 - val_loss: 0.1506 - val_acc: 0.9623\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1653 - acc: 0.9484\n",
      "Epoch 00018: val_loss did not improve from 0.12938\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1652 - acc: 0.9484 - val_loss: 0.1342 - val_acc: 0.9651\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1488 - acc: 0.9524\n",
      "Epoch 00019: val_loss improved from 0.12938 to 0.12835, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/019-0.1284.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1488 - acc: 0.9525 - val_loss: 0.1284 - val_acc: 0.9613\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9529\n",
      "Epoch 00020: val_loss did not improve from 0.12835\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1497 - acc: 0.9529 - val_loss: 0.1411 - val_acc: 0.9639\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9540\n",
      "Epoch 00021: val_loss did not improve from 0.12835\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1442 - acc: 0.9540 - val_loss: 0.1397 - val_acc: 0.9620\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9558\n",
      "Epoch 00022: val_loss did not improve from 0.12835\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1375 - acc: 0.9558 - val_loss: 0.1299 - val_acc: 0.9634\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9582\n",
      "Epoch 00023: val_loss did not improve from 0.12835\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1345 - acc: 0.9582 - val_loss: 0.1326 - val_acc: 0.9665\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9588\n",
      "Epoch 00024: val_loss improved from 0.12835 to 0.11564, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_8_conv_checkpoint/024-0.1156.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1299 - acc: 0.9588 - val_loss: 0.1156 - val_acc: 0.9690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9619\n",
      "Epoch 00025: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1203 - acc: 0.9619 - val_loss: 0.1457 - val_acc: 0.9611\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9614\n",
      "Epoch 00026: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1215 - acc: 0.9614 - val_loss: 0.1517 - val_acc: 0.9611\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9621\n",
      "Epoch 00027: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1176 - acc: 0.9621 - val_loss: 0.1340 - val_acc: 0.9641\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9661\n",
      "Epoch 00028: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1057 - acc: 0.9661 - val_loss: 0.1342 - val_acc: 0.9632\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9623\n",
      "Epoch 00029: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1148 - acc: 0.9623 - val_loss: 0.1172 - val_acc: 0.9681\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9646\n",
      "Epoch 00030: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1098 - acc: 0.9645 - val_loss: 0.1908 - val_acc: 0.9527\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9616\n",
      "Epoch 00031: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1200 - acc: 0.9616 - val_loss: 0.1702 - val_acc: 0.9625\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9627\n",
      "Epoch 00032: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1155 - acc: 0.9627 - val_loss: 0.1699 - val_acc: 0.9569\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9694\n",
      "Epoch 00033: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0976 - acc: 0.9694 - val_loss: 0.1387 - val_acc: 0.9648\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9674\n",
      "Epoch 00034: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1023 - acc: 0.9674 - val_loss: 0.1462 - val_acc: 0.9658\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9696\n",
      "Epoch 00035: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0930 - acc: 0.9696 - val_loss: 0.1383 - val_acc: 0.9632\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9710\n",
      "Epoch 00036: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0912 - acc: 0.9710 - val_loss: 0.1421 - val_acc: 0.9606\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9698\n",
      "Epoch 00037: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0938 - acc: 0.9698 - val_loss: 0.1442 - val_acc: 0.9576\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9697\n",
      "Epoch 00038: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0937 - acc: 0.9697 - val_loss: 0.1182 - val_acc: 0.9660\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9723\n",
      "Epoch 00039: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0864 - acc: 0.9723 - val_loss: 0.1539 - val_acc: 0.9676\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9712\n",
      "Epoch 00040: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0893 - acc: 0.9712 - val_loss: 0.1585 - val_acc: 0.9578\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0836 - acc: 0.9724\n",
      "Epoch 00041: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0836 - acc: 0.9724 - val_loss: 0.1574 - val_acc: 0.9606\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9738\n",
      "Epoch 00042: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0825 - acc: 0.9738 - val_loss: 0.1527 - val_acc: 0.9655\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9764\n",
      "Epoch 00043: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0734 - acc: 0.9764 - val_loss: 0.1542 - val_acc: 0.9632\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9736\n",
      "Epoch 00044: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0787 - acc: 0.9736 - val_loss: 0.1690 - val_acc: 0.9611\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9753\n",
      "Epoch 00045: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0780 - acc: 0.9753 - val_loss: 0.1629 - val_acc: 0.9618\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9762\n",
      "Epoch 00046: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0757 - acc: 0.9762 - val_loss: 0.1471 - val_acc: 0.9648\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9776\n",
      "Epoch 00047: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0715 - acc: 0.9776 - val_loss: 0.1582 - val_acc: 0.9641\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9772\n",
      "Epoch 00048: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0704 - acc: 0.9772 - val_loss: 0.1616 - val_acc: 0.9662\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9791\n",
      "Epoch 00049: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0659 - acc: 0.9791 - val_loss: 0.1661 - val_acc: 0.9646\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9779\n",
      "Epoch 00050: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0694 - acc: 0.9779 - val_loss: 0.1551 - val_acc: 0.9630\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9778\n",
      "Epoch 00051: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0706 - acc: 0.9778 - val_loss: 0.1472 - val_acc: 0.9672\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9781\n",
      "Epoch 00052: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0682 - acc: 0.9781 - val_loss: 0.1858 - val_acc: 0.9620\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9779\n",
      "Epoch 00053: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0699 - acc: 0.9779 - val_loss: 0.1727 - val_acc: 0.9616\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9765\n",
      "Epoch 00054: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0738 - acc: 0.9765 - val_loss: 0.1528 - val_acc: 0.9653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9793\n",
      "Epoch 00055: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0654 - acc: 0.9793 - val_loss: 0.1773 - val_acc: 0.9583\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9765\n",
      "Epoch 00056: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0767 - acc: 0.9766 - val_loss: 0.1827 - val_acc: 0.9618\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9801\n",
      "Epoch 00057: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0636 - acc: 0.9801 - val_loss: 0.1780 - val_acc: 0.9648\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9783\n",
      "Epoch 00058: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0700 - acc: 0.9783 - val_loss: 0.1603 - val_acc: 0.9632\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9800\n",
      "Epoch 00059: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0652 - acc: 0.9800 - val_loss: 0.2141 - val_acc: 0.9543\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9803\n",
      "Epoch 00060: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0608 - acc: 0.9803 - val_loss: 0.1738 - val_acc: 0.9630\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9802\n",
      "Epoch 00061: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0617 - acc: 0.9802 - val_loss: 0.1592 - val_acc: 0.9618\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9811\n",
      "Epoch 00062: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0619 - acc: 0.9811 - val_loss: 0.1634 - val_acc: 0.9637\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9755\n",
      "Epoch 00063: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0774 - acc: 0.9755 - val_loss: 0.1899 - val_acc: 0.9602\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9808\n",
      "Epoch 00064: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0597 - acc: 0.9808 - val_loss: 0.1634 - val_acc: 0.9651\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9795\n",
      "Epoch 00065: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0625 - acc: 0.9795 - val_loss: 0.1814 - val_acc: 0.9646\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9817\n",
      "Epoch 00066: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0588 - acc: 0.9816 - val_loss: 0.2776 - val_acc: 0.9415\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9766\n",
      "Epoch 00067: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0753 - acc: 0.9766 - val_loss: 0.1963 - val_acc: 0.9616\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9764\n",
      "Epoch 00068: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0768 - acc: 0.9764 - val_loss: 0.1583 - val_acc: 0.9655\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9808\n",
      "Epoch 00069: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0612 - acc: 0.9808 - val_loss: 0.1778 - val_acc: 0.9613\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9818\n",
      "Epoch 00070: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0583 - acc: 0.9818 - val_loss: 0.2002 - val_acc: 0.9620\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9795\n",
      "Epoch 00071: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0649 - acc: 0.9795 - val_loss: 0.1812 - val_acc: 0.9630\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9808\n",
      "Epoch 00072: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0640 - acc: 0.9808 - val_loss: 0.2091 - val_acc: 0.9597\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9811\n",
      "Epoch 00073: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0623 - acc: 0.9811 - val_loss: 0.1503 - val_acc: 0.9667\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9827\n",
      "Epoch 00074: val_loss did not improve from 0.11564\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0551 - acc: 0.9827 - val_loss: 0.2105 - val_acc: 0.9532\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 646us/sample - loss: 0.1795 - acc: 0.9510\n",
      "Loss: 0.17948721637436782 Accuracy: 0.9509865\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4887 - acc: 0.1722\n",
      "Epoch 00001: val_loss improved from inf to 1.89354, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_9_conv_checkpoint/001-1.8935.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 2.4887 - acc: 0.1722 - val_loss: 1.8935 - val_acc: 0.3997\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3573 - acc: 0.5565\n",
      "Epoch 00002: val_loss improved from 1.89354 to 0.94862, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_9_conv_checkpoint/002-0.9486.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 1.3573 - acc: 0.5565 - val_loss: 0.9486 - val_acc: 0.6949\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8814 - acc: 0.7174\n",
      "Epoch 00003: val_loss improved from 0.94862 to 0.82334, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_9_conv_checkpoint/003-0.8233.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.8814 - acc: 0.7174 - val_loss: 0.8233 - val_acc: 0.7324\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5546 - acc: 0.8286\n",
      "Epoch 00004: val_loss improved from 0.82334 to 0.79649, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_9_conv_checkpoint/004-0.7965.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.5547 - acc: 0.8286 - val_loss: 0.7965 - val_acc: 0.7685\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3821 - acc: 0.8833\n",
      "Epoch 00005: val_loss improved from 0.79649 to 0.31798, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_9_conv_checkpoint/005-0.3180.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.3822 - acc: 0.8833 - val_loss: 0.3180 - val_acc: 0.9075\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2980 - acc: 0.9090\n",
      "Epoch 00006: val_loss improved from 0.31798 to 0.27973, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_9_conv_checkpoint/006-0.2797.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2980 - acc: 0.9090 - val_loss: 0.2797 - val_acc: 0.9140\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2555 - acc: 0.9226\n",
      "Epoch 00007: val_loss did not improve from 0.27973\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2556 - acc: 0.9226 - val_loss: 0.3297 - val_acc: 0.8970\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2321 - acc: 0.9299\n",
      "Epoch 00008: val_loss improved from 0.27973 to 0.16336, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_9_conv_checkpoint/008-0.1634.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2320 - acc: 0.9300 - val_loss: 0.1634 - val_acc: 0.9527\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1968 - acc: 0.9402\n",
      "Epoch 00009: val_loss did not improve from 0.16336\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1968 - acc: 0.9402 - val_loss: 0.2269 - val_acc: 0.9348\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1859 - acc: 0.9429\n",
      "Epoch 00010: val_loss did not improve from 0.16336\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1859 - acc: 0.9429 - val_loss: 0.2161 - val_acc: 0.9394\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1662 - acc: 0.9496\n",
      "Epoch 00011: val_loss improved from 0.16336 to 0.15270, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_9_conv_checkpoint/011-0.1527.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1662 - acc: 0.9496 - val_loss: 0.1527 - val_acc: 0.9513\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9529\n",
      "Epoch 00012: val_loss improved from 0.15270 to 0.14911, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_9_conv_checkpoint/012-0.1491.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1513 - acc: 0.9529 - val_loss: 0.1491 - val_acc: 0.9555\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1399 - acc: 0.9558\n",
      "Epoch 00013: val_loss improved from 0.14911 to 0.12249, saving model to model/checkpoint/1D_CNN_custom_DO_075_DO_SGD_9_conv_checkpoint/013-0.1225.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1399 - acc: 0.9558 - val_loss: 0.1225 - val_acc: 0.9630\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9585\n",
      "Epoch 00014: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1319 - acc: 0.9585 - val_loss: 0.1304 - val_acc: 0.9611\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1248 - acc: 0.9605\n",
      "Epoch 00015: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1248 - acc: 0.9605 - val_loss: 0.1600 - val_acc: 0.9555\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9650\n",
      "Epoch 00016: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1148 - acc: 0.9650 - val_loss: 0.1420 - val_acc: 0.9569\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9646\n",
      "Epoch 00017: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1126 - acc: 0.9646 - val_loss: 0.1289 - val_acc: 0.9667\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9655\n",
      "Epoch 00018: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1089 - acc: 0.9655 - val_loss: 0.1376 - val_acc: 0.9616\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9665\n",
      "Epoch 00019: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1039 - acc: 0.9666 - val_loss: 0.1247 - val_acc: 0.9672\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9713\n",
      "Epoch 00020: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0926 - acc: 0.9713 - val_loss: 0.1785 - val_acc: 0.9569\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9713\n",
      "Epoch 00021: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0951 - acc: 0.9713 - val_loss: 0.1413 - val_acc: 0.9595\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9721\n",
      "Epoch 00022: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0891 - acc: 0.9721 - val_loss: 0.1554 - val_acc: 0.9620\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9726\n",
      "Epoch 00023: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0859 - acc: 0.9726 - val_loss: 0.1670 - val_acc: 0.9602\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9743\n",
      "Epoch 00024: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0810 - acc: 0.9743 - val_loss: 0.1411 - val_acc: 0.9606\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9750\n",
      "Epoch 00025: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0768 - acc: 0.9750 - val_loss: 0.1511 - val_acc: 0.9592\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9764\n",
      "Epoch 00026: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0739 - acc: 0.9764 - val_loss: 0.1655 - val_acc: 0.9548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9780\n",
      "Epoch 00027: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0692 - acc: 0.9780 - val_loss: 0.1553 - val_acc: 0.9658\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9792\n",
      "Epoch 00028: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0666 - acc: 0.9792 - val_loss: 0.1575 - val_acc: 0.9623\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9790\n",
      "Epoch 00029: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0680 - acc: 0.9790 - val_loss: 0.1406 - val_acc: 0.9672\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9779\n",
      "Epoch 00030: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0714 - acc: 0.9779 - val_loss: 0.2010 - val_acc: 0.9560\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9783\n",
      "Epoch 00031: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0681 - acc: 0.9783 - val_loss: 0.1454 - val_acc: 0.9690\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9801\n",
      "Epoch 00032: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0632 - acc: 0.9801 - val_loss: 0.1840 - val_acc: 0.9597\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9789\n",
      "Epoch 00033: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0684 - acc: 0.9789 - val_loss: 0.1522 - val_acc: 0.9639\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9826\n",
      "Epoch 00034: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0562 - acc: 0.9826 - val_loss: 0.3226 - val_acc: 0.9241\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9715\n",
      "Epoch 00035: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0921 - acc: 0.9714 - val_loss: 0.2791 - val_acc: 0.9397\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9758\n",
      "Epoch 00036: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0774 - acc: 0.9758 - val_loss: 0.1820 - val_acc: 0.9597\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9832\n",
      "Epoch 00037: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0553 - acc: 0.9832 - val_loss: 0.1657 - val_acc: 0.9599\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9794\n",
      "Epoch 00038: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0668 - acc: 0.9794 - val_loss: 0.1655 - val_acc: 0.9623\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9829\n",
      "Epoch 00039: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0558 - acc: 0.9829 - val_loss: 0.1606 - val_acc: 0.9674\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9827\n",
      "Epoch 00040: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0566 - acc: 0.9827 - val_loss: 0.1893 - val_acc: 0.9637\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9816\n",
      "Epoch 00041: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0613 - acc: 0.9816 - val_loss: 0.2002 - val_acc: 0.9583\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9854\n",
      "Epoch 00042: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0504 - acc: 0.9854 - val_loss: 0.1746 - val_acc: 0.9627\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9838\n",
      "Epoch 00043: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0547 - acc: 0.9838 - val_loss: 0.1591 - val_acc: 0.9648\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9836\n",
      "Epoch 00044: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0539 - acc: 0.9836 - val_loss: 0.1835 - val_acc: 0.9618\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9851\n",
      "Epoch 00045: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0500 - acc: 0.9851 - val_loss: 0.1470 - val_acc: 0.9674\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9862\n",
      "Epoch 00046: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0458 - acc: 0.9863 - val_loss: 0.1915 - val_acc: 0.9609\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9863\n",
      "Epoch 00047: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0475 - acc: 0.9863 - val_loss: 0.2417 - val_acc: 0.9555\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9849\n",
      "Epoch 00048: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0527 - acc: 0.9849 - val_loss: 0.1770 - val_acc: 0.9658\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9853\n",
      "Epoch 00049: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0476 - acc: 0.9853 - val_loss: 0.1794 - val_acc: 0.9611\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9854\n",
      "Epoch 00050: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0464 - acc: 0.9854 - val_loss: 0.1989 - val_acc: 0.9627\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9823\n",
      "Epoch 00051: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0582 - acc: 0.9823 - val_loss: 0.1704 - val_acc: 0.9630\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9863\n",
      "Epoch 00052: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0446 - acc: 0.9863 - val_loss: 0.1826 - val_acc: 0.9620\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9877\n",
      "Epoch 00053: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0424 - acc: 0.9877 - val_loss: 0.1765 - val_acc: 0.9637\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9839\n",
      "Epoch 00054: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0552 - acc: 0.9839 - val_loss: 0.1666 - val_acc: 0.9648\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9862\n",
      "Epoch 00055: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0454 - acc: 0.9862 - val_loss: 0.1927 - val_acc: 0.9667\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9865\n",
      "Epoch 00056: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0450 - acc: 0.9865 - val_loss: 0.1754 - val_acc: 0.9665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9842\n",
      "Epoch 00057: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0529 - acc: 0.9842 - val_loss: 0.1850 - val_acc: 0.9641\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9858\n",
      "Epoch 00058: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0467 - acc: 0.9858 - val_loss: 0.1891 - val_acc: 0.9648\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9853\n",
      "Epoch 00059: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0512 - acc: 0.9852 - val_loss: 0.1863 - val_acc: 0.9641\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9846\n",
      "Epoch 00060: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0499 - acc: 0.9846 - val_loss: 0.2064 - val_acc: 0.9632\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9875\n",
      "Epoch 00061: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0407 - acc: 0.9875 - val_loss: 0.1924 - val_acc: 0.9686\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9872\n",
      "Epoch 00062: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0419 - acc: 0.9872 - val_loss: 0.1897 - val_acc: 0.9644\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9860\n",
      "Epoch 00063: val_loss did not improve from 0.12249\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0489 - acc: 0.9860 - val_loss: 0.1980 - val_acc: 0.9637\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 676us/sample - loss: 0.1746 - acc: 0.9479\n",
      "Loss: 0.1745570547538321 Accuracy: 0.9478712\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    base = '1D_CNN_custom_DO_075_DO_SGD'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO_075_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                  optimizer=SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=True),\n",
    "                  metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,136\n",
      "Trainable params: 1,861,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 590us/sample - loss: 1.2394 - acc: 0.6226\n",
      "Loss: 1.2393806066592288 Accuracy: 0.62263757\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 668,240\n",
      "Trainable params: 668,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 601us/sample - loss: 0.8214 - acc: 0.7726\n",
      "Loss: 0.82138472635798 Accuracy: 0.7725857\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 506,576\n",
      "Trainable params: 506,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 661us/sample - loss: 0.5893 - acc: 0.8351\n",
      "Loss: 0.5893327088742242 Accuracy: 0.8350986\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 318,288\n",
      "Trainable params: 318,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 665us/sample - loss: 0.3347 - acc: 0.9140\n",
      "Loss: 0.3347402188513014 Accuracy: 0.9140187\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 310,224\n",
      "Trainable params: 310,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 658us/sample - loss: 0.2094 - acc: 0.9431\n",
      "Loss: 0.20942693221482409 Accuracy: 0.9430945\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_70 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 363,600\n",
      "Trainable params: 363,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 692us/sample - loss: 0.1795 - acc: 0.9510\n",
      "Loss: 0.17948721637436782 Accuracy: 0.9509865\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 521,552\n",
      "Trainable params: 521,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 696us/sample - loss: 0.1746 - acc: 0.9479\n",
      "Loss: 0.1745570547538321 Accuracy: 0.9478712\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_DO_075_DO_SGD'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,136\n",
      "Trainable params: 1,861,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 636us/sample - loss: 1.6272 - acc: 0.6773\n",
      "Loss: 1.6272050820654673 Accuracy: 0.67725855\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 668,240\n",
      "Trainable params: 668,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 638us/sample - loss: 0.9059 - acc: 0.7826\n",
      "Loss: 0.9058617702154356 Accuracy: 0.7825545\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 506,576\n",
      "Trainable params: 506,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 678us/sample - loss: 0.7004 - acc: 0.8469\n",
      "Loss: 0.7004263863880439 Accuracy: 0.84693664\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 318,288\n",
      "Trainable params: 318,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 699us/sample - loss: 0.3550 - acc: 0.9124\n",
      "Loss: 0.35496825700546475 Accuracy: 0.9123572\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 310,224\n",
      "Trainable params: 310,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 699us/sample - loss: 0.2723 - acc: 0.9400\n",
      "Loss: 0.272340037137887 Accuracy: 0.93997926\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_70 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 363,600\n",
      "Trainable params: 363,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 712us/sample - loss: 0.2380 - acc: 0.9454\n",
      "Loss: 0.2379981842766751 Accuracy: 0.945379\n",
      "\n",
      "1D_CNN_custom_DO_075_DO_SGD_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 521,552\n",
      "Trainable params: 521,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 727us/sample - loss: 0.1966 - acc: 0.9599\n",
      "Loss: 0.19661172342202352 Accuracy: 0.95991695\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
