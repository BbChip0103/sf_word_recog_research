{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_BN_2(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, \n",
    "                      padding='same', kernel_initializer='he_uniform', \n",
    "                      input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same', kernel_initializer='he_uniform'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())    \n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,480,656\n",
      "Trainable params: 18,432,528\n",
      "Non-trainable params: 2,048,128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 6,847,696\n",
      "Trainable params: 6,164,816\n",
      "Non-trainable params: 682,880\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,316,816\n",
      "Trainable params: 2,088,976\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 820,816\n",
      "Trainable params: 744,528\n",
      "Non-trainable params: 76,288\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 608,976\n",
      "Trainable params: 557,776\n",
      "Non-trainable params: 51,200\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 353,616\n",
      "Trainable params: 335,952\n",
      "Non-trainable params: 17,664\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 323,536\n",
      "Trainable params: 316,880\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 370,256\n",
      "Trainable params: 366,928\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 527,696\n",
      "Trainable params: 524,624\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_BN_2(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3527 - acc: 0.4236\n",
      "Epoch 00001: val_loss improved from inf to 2.09511, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_3_conv_checkpoint/001-2.0951.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 2.3527 - acc: 0.4236 - val_loss: 2.0951 - val_acc: 0.4512\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0050 - acc: 0.7189\n",
      "Epoch 00002: val_loss improved from 2.09511 to 1.98180, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_3_conv_checkpoint/002-1.9818.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 1.0051 - acc: 0.7190 - val_loss: 1.9818 - val_acc: 0.5195\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4924 - acc: 0.8590\n",
      "Epoch 00003: val_loss improved from 1.98180 to 1.90014, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_3_conv_checkpoint/003-1.9001.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.4924 - acc: 0.8591 - val_loss: 1.9001 - val_acc: 0.5465\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2606 - acc: 0.9353\n",
      "Epoch 00004: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.2606 - acc: 0.9353 - val_loss: 2.3083 - val_acc: 0.5034\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9588\n",
      "Epoch 00005: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1897 - acc: 0.9587 - val_loss: 2.1282 - val_acc: 0.5448\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9639\n",
      "Epoch 00006: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1654 - acc: 0.9639 - val_loss: 2.3366 - val_acc: 0.5330\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9760\n",
      "Epoch 00007: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1183 - acc: 0.9760 - val_loss: 2.1528 - val_acc: 0.5604\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9793\n",
      "Epoch 00008: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1010 - acc: 0.9792 - val_loss: 2.3601 - val_acc: 0.5490\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9765\n",
      "Epoch 00009: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1081 - acc: 0.9764 - val_loss: 2.5464 - val_acc: 0.5423\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9691\n",
      "Epoch 00010: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1256 - acc: 0.9691 - val_loss: 2.5894 - val_acc: 0.5339\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9735\n",
      "Epoch 00011: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1117 - acc: 0.9735 - val_loss: 2.9158 - val_acc: 0.5169\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0980 - acc: 0.9760\n",
      "Epoch 00012: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0980 - acc: 0.9760 - val_loss: 2.7081 - val_acc: 0.5434\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9847\n",
      "Epoch 00013: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0718 - acc: 0.9847 - val_loss: 2.8173 - val_acc: 0.5348\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0943 - acc: 0.9774\n",
      "Epoch 00014: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0944 - acc: 0.9774 - val_loss: 3.1468 - val_acc: 0.5073\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9810\n",
      "Epoch 00015: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0823 - acc: 0.9810 - val_loss: 3.0188 - val_acc: 0.5390\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0821 - acc: 0.9835\n",
      "Epoch 00016: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0825 - acc: 0.9834 - val_loss: 3.1805 - val_acc: 0.5330\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9819\n",
      "Epoch 00017: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0832 - acc: 0.9819 - val_loss: 3.1065 - val_acc: 0.5395\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9824\n",
      "Epoch 00018: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0779 - acc: 0.9824 - val_loss: 3.1702 - val_acc: 0.5504\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9864\n",
      "Epoch 00019: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0670 - acc: 0.9864 - val_loss: 3.4654 - val_acc: 0.5155\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9857\n",
      "Epoch 00020: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0690 - acc: 0.9856 - val_loss: 3.3602 - val_acc: 0.5374\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9862\n",
      "Epoch 00021: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0666 - acc: 0.9862 - val_loss: 3.4533 - val_acc: 0.5250\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9869\n",
      "Epoch 00022: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0629 - acc: 0.9869 - val_loss: 3.3098 - val_acc: 0.5486\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9902\n",
      "Epoch 00023: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0507 - acc: 0.9902 - val_loss: 3.4918 - val_acc: 0.5413\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9875\n",
      "Epoch 00024: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0608 - acc: 0.9875 - val_loss: 4.1337 - val_acc: 0.4941\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9836\n",
      "Epoch 00025: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0778 - acc: 0.9836 - val_loss: 3.7401 - val_acc: 0.5162\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9858\n",
      "Epoch 00026: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0671 - acc: 0.9858 - val_loss: 3.6799 - val_acc: 0.5299\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9883\n",
      "Epoch 00027: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0620 - acc: 0.9883 - val_loss: 3.7900 - val_acc: 0.5199\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9893\n",
      "Epoch 00028: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0544 - acc: 0.9893 - val_loss: 3.5420 - val_acc: 0.5472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9923\n",
      "Epoch 00029: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0419 - acc: 0.9923 - val_loss: 3.6019 - val_acc: 0.5460\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9882\n",
      "Epoch 00030: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0596 - acc: 0.9882 - val_loss: 3.9206 - val_acc: 0.5274\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9901\n",
      "Epoch 00031: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0526 - acc: 0.9901 - val_loss: 3.9057 - val_acc: 0.5297\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9874\n",
      "Epoch 00032: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0632 - acc: 0.9874 - val_loss: 3.8325 - val_acc: 0.5430\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9901\n",
      "Epoch 00033: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0519 - acc: 0.9901 - val_loss: 3.8807 - val_acc: 0.5290\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9920\n",
      "Epoch 00034: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0435 - acc: 0.9920 - val_loss: 3.7430 - val_acc: 0.5462\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9873\n",
      "Epoch 00035: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0621 - acc: 0.9872 - val_loss: 4.0752 - val_acc: 0.5171\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9820\n",
      "Epoch 00036: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0877 - acc: 0.9819 - val_loss: 4.1216 - val_acc: 0.5299\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9889\n",
      "Epoch 00037: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0542 - acc: 0.9888 - val_loss: 4.0009 - val_acc: 0.5292\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9899\n",
      "Epoch 00038: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0552 - acc: 0.9899 - val_loss: 3.9676 - val_acc: 0.5399\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9932\n",
      "Epoch 00039: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0416 - acc: 0.9932 - val_loss: 3.9963 - val_acc: 0.5360\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9923\n",
      "Epoch 00040: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0460 - acc: 0.9923 - val_loss: 4.2022 - val_acc: 0.5201\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9913\n",
      "Epoch 00041: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0516 - acc: 0.9913 - val_loss: 4.2241 - val_acc: 0.5290\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9893\n",
      "Epoch 00042: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0549 - acc: 0.9893 - val_loss: 4.0157 - val_acc: 0.5493\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9942\n",
      "Epoch 00043: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0355 - acc: 0.9942 - val_loss: 4.0607 - val_acc: 0.5334\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9917\n",
      "Epoch 00044: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0444 - acc: 0.9917 - val_loss: 4.4246 - val_acc: 0.5097\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9915\n",
      "Epoch 00045: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0495 - acc: 0.9915 - val_loss: 4.4616 - val_acc: 0.5160\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9887\n",
      "Epoch 00046: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0589 - acc: 0.9887 - val_loss: 4.3331 - val_acc: 0.5274\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9885\n",
      "Epoch 00047: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0570 - acc: 0.9885 - val_loss: 4.0835 - val_acc: 0.5355\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9896\n",
      "Epoch 00048: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0560 - acc: 0.9896 - val_loss: 4.5195 - val_acc: 0.5181\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9951\n",
      "Epoch 00049: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0333 - acc: 0.9951 - val_loss: 4.1604 - val_acc: 0.5458\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9927\n",
      "Epoch 00050: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0433 - acc: 0.9927 - val_loss: 4.2681 - val_acc: 0.5360\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9923\n",
      "Epoch 00051: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0463 - acc: 0.9923 - val_loss: 4.8408 - val_acc: 0.4957\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9926\n",
      "Epoch 00052: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0442 - acc: 0.9926 - val_loss: 4.2630 - val_acc: 0.5392\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9913\n",
      "Epoch 00053: val_loss did not improve from 1.90014\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0492 - acc: 0.9913 - val_loss: 4.5288 - val_acc: 0.5099\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 842us/sample - loss: 2.0867 - acc: 0.4993\n",
      "Loss: 2.0866605542530525 Accuracy: 0.4992731\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8456 - acc: 0.4660\n",
      "Epoch 00001: val_loss improved from inf to 1.43883, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_4_conv_checkpoint/001-1.4388.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.8460 - acc: 0.4660 - val_loss: 1.4388 - val_acc: 0.5628\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1081 - acc: 0.6702\n",
      "Epoch 00002: val_loss improved from 1.43883 to 1.26832, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_4_conv_checkpoint/002-1.2683.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.1085 - acc: 0.6701 - val_loss: 1.2683 - val_acc: 0.6292\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7594 - acc: 0.7720\n",
      "Epoch 00003: val_loss improved from 1.26832 to 1.20628, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_4_conv_checkpoint/003-1.2063.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.7595 - acc: 0.7719 - val_loss: 1.2063 - val_acc: 0.6494\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5105 - acc: 0.8531\n",
      "Epoch 00004: val_loss did not improve from 1.20628\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5106 - acc: 0.8531 - val_loss: 1.2428 - val_acc: 0.6525\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3503 - acc: 0.9065\n",
      "Epoch 00005: val_loss did not improve from 1.20628\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3505 - acc: 0.9065 - val_loss: 1.2097 - val_acc: 0.6632\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2473 - acc: 0.9443\n",
      "Epoch 00006: val_loss improved from 1.20628 to 1.20309, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_4_conv_checkpoint/006-1.2031.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2475 - acc: 0.9442 - val_loss: 1.2031 - val_acc: 0.6737\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1851 - acc: 0.9619\n",
      "Epoch 00007: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1852 - acc: 0.9618 - val_loss: 1.3031 - val_acc: 0.6592\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1437 - acc: 0.9732\n",
      "Epoch 00008: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1438 - acc: 0.9732 - val_loss: 1.3852 - val_acc: 0.6506\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1088 - acc: 0.9833\n",
      "Epoch 00009: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1090 - acc: 0.9832 - val_loss: 1.3078 - val_acc: 0.6767\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9808\n",
      "Epoch 00010: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1070 - acc: 0.9808 - val_loss: 1.3590 - val_acc: 0.6573\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9890\n",
      "Epoch 00011: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0781 - acc: 0.9890 - val_loss: 1.3634 - val_acc: 0.6711\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9912\n",
      "Epoch 00012: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0687 - acc: 0.9911 - val_loss: 1.4474 - val_acc: 0.6655\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9898\n",
      "Epoch 00013: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0687 - acc: 0.9898 - val_loss: 1.4759 - val_acc: 0.6681\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9910\n",
      "Epoch 00014: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0581 - acc: 0.9910 - val_loss: 1.4878 - val_acc: 0.6706\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9930\n",
      "Epoch 00015: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0519 - acc: 0.9930 - val_loss: 1.5329 - val_acc: 0.6667\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9907\n",
      "Epoch 00016: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0571 - acc: 0.9907 - val_loss: 1.6547 - val_acc: 0.6494\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9921\n",
      "Epoch 00017: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0501 - acc: 0.9921 - val_loss: 1.5145 - val_acc: 0.6797\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9933\n",
      "Epoch 00018: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0447 - acc: 0.9932 - val_loss: 1.6928 - val_acc: 0.6650\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9879\n",
      "Epoch 00019: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0608 - acc: 0.9879 - val_loss: 1.6208 - val_acc: 0.6660\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9961\n",
      "Epoch 00020: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0313 - acc: 0.9961 - val_loss: 1.6227 - val_acc: 0.6702\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9941\n",
      "Epoch 00021: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0362 - acc: 0.9940 - val_loss: 1.8230 - val_acc: 0.6487\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9945\n",
      "Epoch 00022: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0364 - acc: 0.9945 - val_loss: 1.6701 - val_acc: 0.6718\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9971\n",
      "Epoch 00023: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0265 - acc: 0.9971 - val_loss: 1.6823 - val_acc: 0.6716\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9932\n",
      "Epoch 00024: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0392 - acc: 0.9931 - val_loss: 1.8245 - val_acc: 0.6494\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9923\n",
      "Epoch 00025: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0403 - acc: 0.9922 - val_loss: 1.7762 - val_acc: 0.6548\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9936\n",
      "Epoch 00026: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0379 - acc: 0.9936 - val_loss: 1.8384 - val_acc: 0.6473\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9955\n",
      "Epoch 00027: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0290 - acc: 0.9955 - val_loss: 1.7973 - val_acc: 0.6620\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9942\n",
      "Epoch 00028: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0336 - acc: 0.9942 - val_loss: 1.8025 - val_acc: 0.6622\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9946\n",
      "Epoch 00029: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0324 - acc: 0.9946 - val_loss: 1.8489 - val_acc: 0.6592\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9955\n",
      "Epoch 00030: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0300 - acc: 0.9955 - val_loss: 1.8827 - val_acc: 0.6578\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9944\n",
      "Epoch 00031: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0300 - acc: 0.9944 - val_loss: 1.8472 - val_acc: 0.6625\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9953\n",
      "Epoch 00032: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0291 - acc: 0.9952 - val_loss: 1.9266 - val_acc: 0.6546\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9957\n",
      "Epoch 00033: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0262 - acc: 0.9957 - val_loss: 1.9501 - val_acc: 0.6546\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9942\n",
      "Epoch 00034: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0332 - acc: 0.9942 - val_loss: 1.9449 - val_acc: 0.6520\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9985\n",
      "Epoch 00035: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0167 - acc: 0.9985 - val_loss: 1.8728 - val_acc: 0.6674\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9925\n",
      "Epoch 00036: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0395 - acc: 0.9925 - val_loss: 2.1816 - val_acc: 0.6285\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9943\n",
      "Epoch 00037: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0314 - acc: 0.9943 - val_loss: 2.1089 - val_acc: 0.6424\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9974\n",
      "Epoch 00038: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0227 - acc: 0.9974 - val_loss: 2.0156 - val_acc: 0.6548\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9948\n",
      "Epoch 00039: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0326 - acc: 0.9947 - val_loss: 2.0708 - val_acc: 0.6478\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9931\n",
      "Epoch 00040: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0352 - acc: 0.9931 - val_loss: 2.0158 - val_acc: 0.6648\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9961\n",
      "Epoch 00041: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0232 - acc: 0.9961 - val_loss: 2.0100 - val_acc: 0.6578\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9973\n",
      "Epoch 00042: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0196 - acc: 0.9973 - val_loss: 2.0317 - val_acc: 0.6613\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9969\n",
      "Epoch 00043: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0211 - acc: 0.9968 - val_loss: 2.1904 - val_acc: 0.6415\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9952\n",
      "Epoch 00044: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0245 - acc: 0.9952 - val_loss: 2.0563 - val_acc: 0.6578\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9980\n",
      "Epoch 00045: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0156 - acc: 0.9980 - val_loss: 2.1371 - val_acc: 0.6536\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9981\n",
      "Epoch 00046: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0167 - acc: 0.9981 - val_loss: 2.3191 - val_acc: 0.6327\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9921\n",
      "Epoch 00047: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0393 - acc: 0.9920 - val_loss: 2.2819 - val_acc: 0.6399\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9949\n",
      "Epoch 00048: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0268 - acc: 0.9949 - val_loss: 2.1470 - val_acc: 0.6601\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9974\n",
      "Epoch 00049: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0181 - acc: 0.9974 - val_loss: 2.1428 - val_acc: 0.6536\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9976\n",
      "Epoch 00050: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0166 - acc: 0.9976 - val_loss: 2.1138 - val_acc: 0.6471\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9952\n",
      "Epoch 00051: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0257 - acc: 0.9951 - val_loss: 2.1471 - val_acc: 0.6543\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9954\n",
      "Epoch 00052: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0257 - acc: 0.9954 - val_loss: 2.1846 - val_acc: 0.6464\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9970\n",
      "Epoch 00053: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0194 - acc: 0.9969 - val_loss: 2.2542 - val_acc: 0.6385\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9940\n",
      "Epoch 00054: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0283 - acc: 0.9940 - val_loss: 2.2167 - val_acc: 0.6350\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9970\n",
      "Epoch 00055: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0181 - acc: 0.9970 - val_loss: 2.1205 - val_acc: 0.6646\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9950\n",
      "Epoch 00056: val_loss did not improve from 1.20309\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.0277 - acc: 0.9950 - val_loss: 2.2069 - val_acc: 0.6515\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 837us/sample - loss: 1.3407 - acc: 0.6345\n",
      "Loss: 1.3407388262040643 Accuracy: 0.6344756\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7238 - acc: 0.4851\n",
      "Epoch 00001: val_loss improved from inf to 1.24444, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_5_conv_checkpoint/001-1.2444.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 1.7237 - acc: 0.4851 - val_loss: 1.2444 - val_acc: 0.6205\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0667 - acc: 0.6795\n",
      "Epoch 00002: val_loss improved from 1.24444 to 1.05356, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_5_conv_checkpoint/002-1.0536.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.0668 - acc: 0.6794 - val_loss: 1.0536 - val_acc: 0.7009\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8115 - acc: 0.7556\n",
      "Epoch 00003: val_loss did not improve from 1.05356\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8117 - acc: 0.7555 - val_loss: 1.0973 - val_acc: 0.6813\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6236 - acc: 0.8121\n",
      "Epoch 00004: val_loss improved from 1.05356 to 1.04170, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_5_conv_checkpoint/004-1.0417.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6237 - acc: 0.8121 - val_loss: 1.0417 - val_acc: 0.7114\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4772 - acc: 0.8603\n",
      "Epoch 00005: val_loss improved from 1.04170 to 0.95471, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_5_conv_checkpoint/005-0.9547.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4772 - acc: 0.8603 - val_loss: 0.9547 - val_acc: 0.7321\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3706 - acc: 0.8946\n",
      "Epoch 00006: val_loss improved from 0.95471 to 0.95133, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_5_conv_checkpoint/006-0.9513.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3707 - acc: 0.8946 - val_loss: 0.9513 - val_acc: 0.7386\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2897 - acc: 0.9237\n",
      "Epoch 00007: val_loss improved from 0.95133 to 0.94912, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_5_conv_checkpoint/007-0.9491.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2897 - acc: 0.9237 - val_loss: 0.9491 - val_acc: 0.7382\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2163 - acc: 0.9483\n",
      "Epoch 00008: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2164 - acc: 0.9482 - val_loss: 0.9975 - val_acc: 0.7375\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9609\n",
      "Epoch 00009: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1774 - acc: 0.9608 - val_loss: 1.0299 - val_acc: 0.7331\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1574 - acc: 0.9654\n",
      "Epoch 00010: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1574 - acc: 0.9654 - val_loss: 0.9805 - val_acc: 0.7461\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9791\n",
      "Epoch 00011: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1161 - acc: 0.9791 - val_loss: 1.0609 - val_acc: 0.7365\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1036 - acc: 0.9813\n",
      "Epoch 00012: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1037 - acc: 0.9813 - val_loss: 1.0676 - val_acc: 0.7400\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9826\n",
      "Epoch 00013: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0982 - acc: 0.9826 - val_loss: 1.0292 - val_acc: 0.7533\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9891\n",
      "Epoch 00014: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0729 - acc: 0.9891 - val_loss: 1.1004 - val_acc: 0.7459\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9880\n",
      "Epoch 00015: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0726 - acc: 0.9880 - val_loss: 1.1952 - val_acc: 0.7191\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9917\n",
      "Epoch 00016: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0587 - acc: 0.9917 - val_loss: 1.2149 - val_acc: 0.7249\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9906\n",
      "Epoch 00017: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0610 - acc: 0.9906 - val_loss: 1.1698 - val_acc: 0.7300\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9914\n",
      "Epoch 00018: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0534 - acc: 0.9914 - val_loss: 1.2709 - val_acc: 0.7221\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9922\n",
      "Epoch 00019: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0534 - acc: 0.9922 - val_loss: 1.1273 - val_acc: 0.7491\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9940\n",
      "Epoch 00020: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0443 - acc: 0.9939 - val_loss: 1.2395 - val_acc: 0.7209\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9924\n",
      "Epoch 00021: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0492 - acc: 0.9924 - val_loss: 1.4756 - val_acc: 0.6967\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9937\n",
      "Epoch 00022: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0413 - acc: 0.9936 - val_loss: 1.2694 - val_acc: 0.7338\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9923\n",
      "Epoch 00023: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0437 - acc: 0.9923 - val_loss: 1.2837 - val_acc: 0.7282\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9952\n",
      "Epoch 00024: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0366 - acc: 0.9951 - val_loss: 1.2663 - val_acc: 0.7358\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9920\n",
      "Epoch 00025: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0452 - acc: 0.9920 - val_loss: 1.3414 - val_acc: 0.7277\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9906\n",
      "Epoch 00026: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0482 - acc: 0.9906 - val_loss: 1.2853 - val_acc: 0.7361\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9940\n",
      "Epoch 00027: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0371 - acc: 0.9940 - val_loss: 1.2560 - val_acc: 0.7452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9967\n",
      "Epoch 00028: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0284 - acc: 0.9967 - val_loss: 1.3087 - val_acc: 0.7375\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9958\n",
      "Epoch 00029: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0326 - acc: 0.9958 - val_loss: 1.3411 - val_acc: 0.7349\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9954\n",
      "Epoch 00030: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0330 - acc: 0.9954 - val_loss: 1.3270 - val_acc: 0.7368\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9960\n",
      "Epoch 00031: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0266 - acc: 0.9960 - val_loss: 1.2785 - val_acc: 0.7512\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9962\n",
      "Epoch 00032: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0271 - acc: 0.9961 - val_loss: 1.6286 - val_acc: 0.6907\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9916\n",
      "Epoch 00033: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0429 - acc: 0.9916 - val_loss: 1.3603 - val_acc: 0.7389\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9970\n",
      "Epoch 00034: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0238 - acc: 0.9969 - val_loss: 1.2839 - val_acc: 0.7475\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9957\n",
      "Epoch 00035: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0274 - acc: 0.9956 - val_loss: 1.3839 - val_acc: 0.7324\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9946\n",
      "Epoch 00036: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0315 - acc: 0.9946 - val_loss: 1.3581 - val_acc: 0.7391\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9930\n",
      "Epoch 00037: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0344 - acc: 0.9930 - val_loss: 1.3779 - val_acc: 0.7372\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9976\n",
      "Epoch 00038: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0209 - acc: 0.9976 - val_loss: 1.3505 - val_acc: 0.7456\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9935\n",
      "Epoch 00039: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0347 - acc: 0.9935 - val_loss: 1.3674 - val_acc: 0.7431\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9937\n",
      "Epoch 00040: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0338 - acc: 0.9937 - val_loss: 1.4328 - val_acc: 0.7356\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9965\n",
      "Epoch 00041: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0223 - acc: 0.9965 - val_loss: 1.3630 - val_acc: 0.7461\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9962\n",
      "Epoch 00042: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0237 - acc: 0.9962 - val_loss: 1.3693 - val_acc: 0.7431\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9943\n",
      "Epoch 00043: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0295 - acc: 0.9943 - val_loss: 1.3943 - val_acc: 0.7428\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9977\n",
      "Epoch 00044: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0174 - acc: 0.9976 - val_loss: 1.3494 - val_acc: 0.7475\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9938\n",
      "Epoch 00045: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0301 - acc: 0.9938 - val_loss: 1.5490 - val_acc: 0.7133\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9917\n",
      "Epoch 00046: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0364 - acc: 0.9917 - val_loss: 1.4001 - val_acc: 0.7358\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9977\n",
      "Epoch 00047: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0171 - acc: 0.9977 - val_loss: 1.4261 - val_acc: 0.7456\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9979\n",
      "Epoch 00048: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0190 - acc: 0.9979 - val_loss: 1.4389 - val_acc: 0.7324\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9980\n",
      "Epoch 00049: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0172 - acc: 0.9980 - val_loss: 1.5567 - val_acc: 0.7200\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9912\n",
      "Epoch 00050: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0383 - acc: 0.9912 - val_loss: 1.4412 - val_acc: 0.7356\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9963\n",
      "Epoch 00051: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0237 - acc: 0.9963 - val_loss: 1.4962 - val_acc: 0.7279\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9934\n",
      "Epoch 00052: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0321 - acc: 0.9934 - val_loss: 1.4304 - val_acc: 0.7396\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9970\n",
      "Epoch 00053: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0218 - acc: 0.9970 - val_loss: 1.4443 - val_acc: 0.7417\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9954\n",
      "Epoch 00054: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0253 - acc: 0.9953 - val_loss: 1.4786 - val_acc: 0.7368\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9935\n",
      "Epoch 00055: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0308 - acc: 0.9935 - val_loss: 1.5216 - val_acc: 0.7338\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9980\n",
      "Epoch 00056: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0162 - acc: 0.9980 - val_loss: 1.4897 - val_acc: 0.7426\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9939\n",
      "Epoch 00057: val_loss did not improve from 0.94912\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0289 - acc: 0.9939 - val_loss: 1.5471 - val_acc: 0.7342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_he-uniform_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 892us/sample - loss: 1.0560 - acc: 0.7101\n",
      "Loss: 1.0560005102078367 Accuracy: 0.7100727\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7292 - acc: 0.4726\n",
      "Epoch 00001: val_loss improved from inf to 1.23245, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_6_conv_checkpoint/001-1.2324.hdf5\n",
      "36805/36805 [==============================] - 98s 3ms/sample - loss: 1.7293 - acc: 0.4726 - val_loss: 1.2324 - val_acc: 0.6124\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0728 - acc: 0.6757\n",
      "Epoch 00002: val_loss improved from 1.23245 to 0.94370, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_6_conv_checkpoint/002-0.9437.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.0728 - acc: 0.6758 - val_loss: 0.9437 - val_acc: 0.7219\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8646 - acc: 0.7451\n",
      "Epoch 00003: val_loss improved from 0.94370 to 0.83291, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_6_conv_checkpoint/003-0.8329.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8647 - acc: 0.7451 - val_loss: 0.8329 - val_acc: 0.7615\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7224 - acc: 0.7901\n",
      "Epoch 00004: val_loss did not improve from 0.83291\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7224 - acc: 0.7901 - val_loss: 0.8462 - val_acc: 0.7601\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6239 - acc: 0.8206\n",
      "Epoch 00005: val_loss improved from 0.83291 to 0.71876, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_6_conv_checkpoint/005-0.7188.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6239 - acc: 0.8206 - val_loss: 0.7188 - val_acc: 0.7943\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5480 - acc: 0.8421\n",
      "Epoch 00006: val_loss did not improve from 0.71876\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5481 - acc: 0.8421 - val_loss: 0.7314 - val_acc: 0.7941\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4806 - acc: 0.8627\n",
      "Epoch 00007: val_loss did not improve from 0.71876\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4806 - acc: 0.8627 - val_loss: 0.7606 - val_acc: 0.7808\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4216 - acc: 0.8782\n",
      "Epoch 00008: val_loss improved from 0.71876 to 0.63020, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_6_conv_checkpoint/008-0.6302.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4217 - acc: 0.8782 - val_loss: 0.6302 - val_acc: 0.8237\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3783 - acc: 0.8939\n",
      "Epoch 00009: val_loss did not improve from 0.63020\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3784 - acc: 0.8939 - val_loss: 0.6416 - val_acc: 0.8183\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3254 - acc: 0.9100\n",
      "Epoch 00010: val_loss did not improve from 0.63020\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3255 - acc: 0.9100 - val_loss: 0.7828 - val_acc: 0.7852\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2871 - acc: 0.9218\n",
      "Epoch 00011: val_loss did not improve from 0.63020\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2872 - acc: 0.9217 - val_loss: 0.6855 - val_acc: 0.8076\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2572 - acc: 0.9303\n",
      "Epoch 00012: val_loss improved from 0.63020 to 0.58371, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_6_conv_checkpoint/012-0.5837.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2572 - acc: 0.9303 - val_loss: 0.5837 - val_acc: 0.8383\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9412\n",
      "Epoch 00013: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2241 - acc: 0.9412 - val_loss: 0.5945 - val_acc: 0.8379\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1938 - acc: 0.9508\n",
      "Epoch 00014: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1938 - acc: 0.9508 - val_loss: 0.6030 - val_acc: 0.8393\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9569\n",
      "Epoch 00015: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1724 - acc: 0.9569 - val_loss: 0.6180 - val_acc: 0.8388\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9573\n",
      "Epoch 00016: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1668 - acc: 0.9573 - val_loss: 0.6304 - val_acc: 0.8369\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9689\n",
      "Epoch 00017: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1358 - acc: 0.9689 - val_loss: 0.5874 - val_acc: 0.8456\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9702\n",
      "Epoch 00018: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1262 - acc: 0.9702 - val_loss: 0.6362 - val_acc: 0.8353\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9762\n",
      "Epoch 00019: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1100 - acc: 0.9761 - val_loss: 0.6207 - val_acc: 0.8423\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1050 - acc: 0.9772\n",
      "Epoch 00020: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1050 - acc: 0.9772 - val_loss: 0.6316 - val_acc: 0.8409\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9835\n",
      "Epoch 00021: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0850 - acc: 0.9835 - val_loss: 0.6521 - val_acc: 0.8381\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9828\n",
      "Epoch 00022: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0835 - acc: 0.9827 - val_loss: 0.5996 - val_acc: 0.8532\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9830\n",
      "Epoch 00023: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0834 - acc: 0.9830 - val_loss: 0.6260 - val_acc: 0.8444\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9793\n",
      "Epoch 00024: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0988 - acc: 0.9793 - val_loss: 0.5924 - val_acc: 0.8532\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9907\n",
      "Epoch 00025: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0587 - acc: 0.9907 - val_loss: 0.6395 - val_acc: 0.8463\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9862\n",
      "Epoch 00026: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0682 - acc: 0.9861 - val_loss: 0.6623 - val_acc: 0.8421\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9887\n",
      "Epoch 00027: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0591 - acc: 0.9888 - val_loss: 0.7076 - val_acc: 0.8362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9899\n",
      "Epoch 00028: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0550 - acc: 0.9899 - val_loss: 0.6500 - val_acc: 0.8397\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9897\n",
      "Epoch 00029: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0569 - acc: 0.9897 - val_loss: 0.7321 - val_acc: 0.8253\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9933\n",
      "Epoch 00030: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0446 - acc: 0.9933 - val_loss: 0.6847 - val_acc: 0.8444\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9857\n",
      "Epoch 00031: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0651 - acc: 0.9857 - val_loss: 0.6907 - val_acc: 0.8470\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9890\n",
      "Epoch 00032: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0566 - acc: 0.9890 - val_loss: 0.6649 - val_acc: 0.8528\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9923\n",
      "Epoch 00033: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0453 - acc: 0.9923 - val_loss: 0.6701 - val_acc: 0.8502\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9947\n",
      "Epoch 00034: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0375 - acc: 0.9947 - val_loss: 0.6780 - val_acc: 0.8463\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9953\n",
      "Epoch 00035: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0331 - acc: 0.9953 - val_loss: 0.8069 - val_acc: 0.8293\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9934\n",
      "Epoch 00036: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0407 - acc: 0.9934 - val_loss: 0.7118 - val_acc: 0.8404\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9957\n",
      "Epoch 00037: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0313 - acc: 0.9956 - val_loss: 0.7455 - val_acc: 0.8353\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9883\n",
      "Epoch 00038: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0555 - acc: 0.9883 - val_loss: 0.6883 - val_acc: 0.8493\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9940\n",
      "Epoch 00039: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0358 - acc: 0.9940 - val_loss: 0.7470 - val_acc: 0.8393\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9934\n",
      "Epoch 00040: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0377 - acc: 0.9934 - val_loss: 0.6782 - val_acc: 0.8467\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9960\n",
      "Epoch 00041: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0283 - acc: 0.9960 - val_loss: 0.6893 - val_acc: 0.8498\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9955\n",
      "Epoch 00042: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0313 - acc: 0.9954 - val_loss: 0.7140 - val_acc: 0.8404\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9897\n",
      "Epoch 00043: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0475 - acc: 0.9896 - val_loss: 0.6724 - val_acc: 0.8493\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9927\n",
      "Epoch 00044: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0393 - acc: 0.9926 - val_loss: 0.6744 - val_acc: 0.8567\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9935\n",
      "Epoch 00045: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0358 - acc: 0.9935 - val_loss: 0.6805 - val_acc: 0.8530\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9930\n",
      "Epoch 00046: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0355 - acc: 0.9930 - val_loss: 0.7520 - val_acc: 0.8535\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9965\n",
      "Epoch 00047: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0240 - acc: 0.9965 - val_loss: 0.7246 - val_acc: 0.8514\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9956\n",
      "Epoch 00048: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0273 - acc: 0.9956 - val_loss: 0.6757 - val_acc: 0.8565\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9923\n",
      "Epoch 00049: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0361 - acc: 0.9923 - val_loss: 0.6747 - val_acc: 0.8530\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9971\n",
      "Epoch 00050: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0226 - acc: 0.9971 - val_loss: 0.6791 - val_acc: 0.8565\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9922\n",
      "Epoch 00051: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0348 - acc: 0.9922 - val_loss: 0.6988 - val_acc: 0.8572\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9980\n",
      "Epoch 00052: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0183 - acc: 0.9980 - val_loss: 0.7007 - val_acc: 0.8526\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9966\n",
      "Epoch 00053: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0222 - acc: 0.9966 - val_loss: 0.9445 - val_acc: 0.8099\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9960\n",
      "Epoch 00054: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0254 - acc: 0.9959 - val_loss: 0.8592 - val_acc: 0.8246\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9895\n",
      "Epoch 00055: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0435 - acc: 0.9895 - val_loss: 0.6712 - val_acc: 0.8612\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9976\n",
      "Epoch 00056: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0179 - acc: 0.9976 - val_loss: 0.6588 - val_acc: 0.8581\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9990\n",
      "Epoch 00057: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0142 - acc: 0.9989 - val_loss: 0.7126 - val_acc: 0.8563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9932\n",
      "Epoch 00058: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0334 - acc: 0.9931 - val_loss: 0.7040 - val_acc: 0.8551\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9935\n",
      "Epoch 00059: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0293 - acc: 0.9935 - val_loss: 0.7058 - val_acc: 0.8567\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9964\n",
      "Epoch 00060: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0217 - acc: 0.9964 - val_loss: 0.7149 - val_acc: 0.8516\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9941\n",
      "Epoch 00061: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0285 - acc: 0.9941 - val_loss: 0.7872 - val_acc: 0.8367\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9978\n",
      "Epoch 00062: val_loss did not improve from 0.58371\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0176 - acc: 0.9978 - val_loss: 0.8261 - val_acc: 0.8358\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 933us/sample - loss: 0.6609 - acc: 0.8102\n",
      "Loss: 0.6608560858733433 Accuracy: 0.81017655\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8204 - acc: 0.4466\n",
      "Epoch 00001: val_loss improved from inf to 1.26609, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/001-1.2661.hdf5\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 1.8203 - acc: 0.4467 - val_loss: 1.2661 - val_acc: 0.6087\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0293 - acc: 0.6973\n",
      "Epoch 00002: val_loss improved from 1.26609 to 0.90620, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/002-0.9062.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 1.0293 - acc: 0.6972 - val_loss: 0.9062 - val_acc: 0.7414\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7748 - acc: 0.7792\n",
      "Epoch 00003: val_loss improved from 0.90620 to 0.72262, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/003-0.7226.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.7749 - acc: 0.7792 - val_loss: 0.7226 - val_acc: 0.7990\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6253 - acc: 0.8249\n",
      "Epoch 00004: val_loss improved from 0.72262 to 0.62179, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/004-0.6218.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6252 - acc: 0.8249 - val_loss: 0.6218 - val_acc: 0.8293\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5191 - acc: 0.8543\n",
      "Epoch 00005: val_loss improved from 0.62179 to 0.55305, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/005-0.5530.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.5196 - acc: 0.8543 - val_loss: 0.5530 - val_acc: 0.8442\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4485 - acc: 0.8733\n",
      "Epoch 00006: val_loss improved from 0.55305 to 0.47847, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/006-0.4785.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4485 - acc: 0.8733 - val_loss: 0.4785 - val_acc: 0.8684\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3853 - acc: 0.8931\n",
      "Epoch 00007: val_loss improved from 0.47847 to 0.44432, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/007-0.4443.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3855 - acc: 0.8931 - val_loss: 0.4443 - val_acc: 0.8684\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3443 - acc: 0.9036\n",
      "Epoch 00008: val_loss did not improve from 0.44432\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3443 - acc: 0.9036 - val_loss: 0.4933 - val_acc: 0.8614\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3021 - acc: 0.9174\n",
      "Epoch 00009: val_loss improved from 0.44432 to 0.42862, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/009-0.4286.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3022 - acc: 0.9173 - val_loss: 0.4286 - val_acc: 0.8770\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2728 - acc: 0.9239\n",
      "Epoch 00010: val_loss improved from 0.42862 to 0.40425, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/010-0.4042.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2729 - acc: 0.9239 - val_loss: 0.4042 - val_acc: 0.8963\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2434 - acc: 0.9324\n",
      "Epoch 00011: val_loss improved from 0.40425 to 0.35389, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/011-0.3539.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2434 - acc: 0.9324 - val_loss: 0.3539 - val_acc: 0.8975\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2173 - acc: 0.9399\n",
      "Epoch 00012: val_loss improved from 0.35389 to 0.32720, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/012-0.3272.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2172 - acc: 0.9399 - val_loss: 0.3272 - val_acc: 0.9082\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9486\n",
      "Epoch 00013: val_loss did not improve from 0.32720\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1927 - acc: 0.9485 - val_loss: 0.3419 - val_acc: 0.9036\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1789 - acc: 0.9521\n",
      "Epoch 00014: val_loss improved from 0.32720 to 0.31177, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/014-0.3118.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1789 - acc: 0.9521 - val_loss: 0.3118 - val_acc: 0.9106\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1590 - acc: 0.9574\n",
      "Epoch 00015: val_loss did not improve from 0.31177\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1591 - acc: 0.9574 - val_loss: 0.3812 - val_acc: 0.8919\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1475 - acc: 0.9601\n",
      "Epoch 00016: val_loss did not improve from 0.31177\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1475 - acc: 0.9601 - val_loss: 0.3370 - val_acc: 0.9075\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9663\n",
      "Epoch 00017: val_loss did not improve from 0.31177\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1301 - acc: 0.9663 - val_loss: 0.3671 - val_acc: 0.8989\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9620\n",
      "Epoch 00018: val_loss improved from 0.31177 to 0.29053, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/018-0.2905.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1436 - acc: 0.9619 - val_loss: 0.2905 - val_acc: 0.9203\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9715\n",
      "Epoch 00019: val_loss did not improve from 0.29053\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1130 - acc: 0.9716 - val_loss: 0.2999 - val_acc: 0.9178\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0955 - acc: 0.9778\n",
      "Epoch 00020: val_loss did not improve from 0.29053\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0955 - acc: 0.9777 - val_loss: 0.2913 - val_acc: 0.9194\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9768\n",
      "Epoch 00021: val_loss did not improve from 0.29053\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0958 - acc: 0.9767 - val_loss: 0.3052 - val_acc: 0.9171\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9800\n",
      "Epoch 00022: val_loss did not improve from 0.29053\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0850 - acc: 0.9800 - val_loss: 0.2976 - val_acc: 0.9182\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9827\n",
      "Epoch 00023: val_loss did not improve from 0.29053\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0765 - acc: 0.9827 - val_loss: 0.3678 - val_acc: 0.9066\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9843\n",
      "Epoch 00024: val_loss did not improve from 0.29053\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0705 - acc: 0.9843 - val_loss: 0.2918 - val_acc: 0.9175\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9861\n",
      "Epoch 00025: val_loss did not improve from 0.29053\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0649 - acc: 0.9861 - val_loss: 0.3020 - val_acc: 0.9187\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9831\n",
      "Epoch 00026: val_loss improved from 0.29053 to 0.28061, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_7_conv_checkpoint/026-0.2806.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0707 - acc: 0.9830 - val_loss: 0.2806 - val_acc: 0.9231\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9869\n",
      "Epoch 00027: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0582 - acc: 0.9869 - val_loss: 0.2830 - val_acc: 0.9278\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9907\n",
      "Epoch 00028: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0475 - acc: 0.9907 - val_loss: 0.3464 - val_acc: 0.9154\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9809\n",
      "Epoch 00029: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0751 - acc: 0.9809 - val_loss: 0.2820 - val_acc: 0.9259\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9900\n",
      "Epoch 00030: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0476 - acc: 0.9900 - val_loss: 0.2919 - val_acc: 0.9273\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9924\n",
      "Epoch 00031: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0404 - acc: 0.9924 - val_loss: 0.3563 - val_acc: 0.9143\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9907\n",
      "Epoch 00032: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0448 - acc: 0.9907 - val_loss: 0.2962 - val_acc: 0.9273\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9894\n",
      "Epoch 00033: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0465 - acc: 0.9893 - val_loss: 0.2996 - val_acc: 0.9241\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9930\n",
      "Epoch 00034: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0373 - acc: 0.9930 - val_loss: 0.2982 - val_acc: 0.9238\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9942\n",
      "Epoch 00035: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0326 - acc: 0.9942 - val_loss: 0.2952 - val_acc: 0.9269\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9942\n",
      "Epoch 00036: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0330 - acc: 0.9942 - val_loss: 0.2951 - val_acc: 0.9236\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9951\n",
      "Epoch 00037: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0296 - acc: 0.9951 - val_loss: 0.2984 - val_acc: 0.9285\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9940\n",
      "Epoch 00038: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0314 - acc: 0.9939 - val_loss: 0.4091 - val_acc: 0.8991\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9926\n",
      "Epoch 00039: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0345 - acc: 0.9926 - val_loss: 0.2849 - val_acc: 0.9320\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9950\n",
      "Epoch 00040: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0274 - acc: 0.9950 - val_loss: 0.2906 - val_acc: 0.9280\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9960\n",
      "Epoch 00041: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0241 - acc: 0.9960 - val_loss: 0.3166 - val_acc: 0.9257\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9955\n",
      "Epoch 00042: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0242 - acc: 0.9955 - val_loss: 0.2894 - val_acc: 0.9276\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9962\n",
      "Epoch 00043: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0236 - acc: 0.9961 - val_loss: 0.3455 - val_acc: 0.9175\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9898\n",
      "Epoch 00044: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0400 - acc: 0.9898 - val_loss: 0.2848 - val_acc: 0.9306\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9969\n",
      "Epoch 00045: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0199 - acc: 0.9968 - val_loss: 0.3441 - val_acc: 0.9122\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9953\n",
      "Epoch 00046: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0257 - acc: 0.9953 - val_loss: 0.2970 - val_acc: 0.9266\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9971\n",
      "Epoch 00047: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0183 - acc: 0.9971 - val_loss: 0.3571 - val_acc: 0.9199\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9922\n",
      "Epoch 00048: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0343 - acc: 0.9921 - val_loss: 0.3184 - val_acc: 0.9287\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9933\n",
      "Epoch 00049: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0312 - acc: 0.9933 - val_loss: 0.2966 - val_acc: 0.9299\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9963\n",
      "Epoch 00050: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0209 - acc: 0.9963 - val_loss: 0.2986 - val_acc: 0.9290\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9945\n",
      "Epoch 00051: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0268 - acc: 0.9945 - val_loss: 0.3021 - val_acc: 0.9259\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9985\n",
      "Epoch 00052: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0127 - acc: 0.9985 - val_loss: 0.3311 - val_acc: 0.9224\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9949\n",
      "Epoch 00053: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0243 - acc: 0.9949 - val_loss: 0.2892 - val_acc: 0.9322\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9970\n",
      "Epoch 00054: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0173 - acc: 0.9970 - val_loss: 0.3098 - val_acc: 0.9299\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9969\n",
      "Epoch 00055: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0180 - acc: 0.9969 - val_loss: 0.3145 - val_acc: 0.9229\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9947\n",
      "Epoch 00056: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0256 - acc: 0.9946 - val_loss: 0.2985 - val_acc: 0.9252\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9914\n",
      "Epoch 00057: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0339 - acc: 0.9914 - val_loss: 0.2907 - val_acc: 0.9322\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9980\n",
      "Epoch 00058: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0139 - acc: 0.9980 - val_loss: 0.2959 - val_acc: 0.9304\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9986\n",
      "Epoch 00059: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0122 - acc: 0.9986 - val_loss: 0.3286 - val_acc: 0.9215\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9962\n",
      "Epoch 00060: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0180 - acc: 0.9962 - val_loss: 0.3189 - val_acc: 0.9273\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9968\n",
      "Epoch 00061: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0172 - acc: 0.9968 - val_loss: 0.2971 - val_acc: 0.9329\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9981\n",
      "Epoch 00062: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0132 - acc: 0.9981 - val_loss: 0.3404 - val_acc: 0.9175\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9977\n",
      "Epoch 00063: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0146 - acc: 0.9977 - val_loss: 0.3835 - val_acc: 0.9145\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9979\n",
      "Epoch 00064: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0132 - acc: 0.9979 - val_loss: 0.3079 - val_acc: 0.9313\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9977\n",
      "Epoch 00065: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0132 - acc: 0.9977 - val_loss: 0.4406 - val_acc: 0.9045\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9926\n",
      "Epoch 00066: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0282 - acc: 0.9926 - val_loss: 0.3065 - val_acc: 0.9271\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9990\n",
      "Epoch 00067: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0088 - acc: 0.9990 - val_loss: 0.2861 - val_acc: 0.9306\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9937\n",
      "Epoch 00068: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0263 - acc: 0.9937 - val_loss: 0.3334 - val_acc: 0.9257\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9967\n",
      "Epoch 00069: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0160 - acc: 0.9967 - val_loss: 0.3117 - val_acc: 0.9292\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9989\n",
      "Epoch 00070: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0092 - acc: 0.9989 - val_loss: 0.3206 - val_acc: 0.9276\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9976\n",
      "Epoch 00071: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0146 - acc: 0.9976 - val_loss: 0.3258 - val_acc: 0.9252\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9980\n",
      "Epoch 00072: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0115 - acc: 0.9980 - val_loss: 0.3443 - val_acc: 0.9266\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9974\n",
      "Epoch 00073: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0140 - acc: 0.9974 - val_loss: 0.3518 - val_acc: 0.9269\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9975\n",
      "Epoch 00074: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0127 - acc: 0.9975 - val_loss: 0.3266 - val_acc: 0.9262\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9993\n",
      "Epoch 00075: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0078 - acc: 0.9993 - val_loss: 0.3148 - val_acc: 0.9287\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9961\n",
      "Epoch 00076: val_loss did not improve from 0.28061\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0177 - acc: 0.9960 - val_loss: 0.3218 - val_acc: 0.9241\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 998us/sample - loss: 0.3381 - acc: 0.9024\n",
      "Loss: 0.3380721197135723 Accuracy: 0.9023884\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6414 - acc: 0.5047\n",
      "Epoch 00001: val_loss improved from inf to 1.06375, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/001-1.0638.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 1.6413 - acc: 0.5047 - val_loss: 1.0638 - val_acc: 0.6751\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8026 - acc: 0.7702\n",
      "Epoch 00002: val_loss improved from 1.06375 to 0.65917, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/002-0.6592.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.8026 - acc: 0.7702 - val_loss: 0.6592 - val_acc: 0.8146\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5493 - acc: 0.8447\n",
      "Epoch 00003: val_loss improved from 0.65917 to 0.47933, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/003-0.4793.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.5494 - acc: 0.8447 - val_loss: 0.4793 - val_acc: 0.8670\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4273 - acc: 0.8782\n",
      "Epoch 00004: val_loss improved from 0.47933 to 0.40640, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/004-0.4064.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.4274 - acc: 0.8782 - val_loss: 0.4064 - val_acc: 0.8828\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3491 - acc: 0.9013\n",
      "Epoch 00005: val_loss improved from 0.40640 to 0.35599, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/005-0.3560.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3492 - acc: 0.9013 - val_loss: 0.3560 - val_acc: 0.9010\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2921 - acc: 0.9183\n",
      "Epoch 00006: val_loss improved from 0.35599 to 0.30988, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/006-0.3099.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2922 - acc: 0.9182 - val_loss: 0.3099 - val_acc: 0.9131\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2533 - acc: 0.9293\n",
      "Epoch 00007: val_loss improved from 0.30988 to 0.30367, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/007-0.3037.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2534 - acc: 0.9292 - val_loss: 0.3037 - val_acc: 0.9129\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2213 - acc: 0.9376\n",
      "Epoch 00008: val_loss improved from 0.30367 to 0.25832, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/008-0.2583.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2213 - acc: 0.9376 - val_loss: 0.2583 - val_acc: 0.9234\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1874 - acc: 0.9478\n",
      "Epoch 00009: val_loss did not improve from 0.25832\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1874 - acc: 0.9478 - val_loss: 0.2825 - val_acc: 0.9154\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1652 - acc: 0.9554\n",
      "Epoch 00010: val_loss improved from 0.25832 to 0.23195, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/010-0.2320.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1653 - acc: 0.9554 - val_loss: 0.2320 - val_acc: 0.9327\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1448 - acc: 0.9602\n",
      "Epoch 00011: val_loss improved from 0.23195 to 0.23194, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/011-0.2319.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1448 - acc: 0.9602 - val_loss: 0.2319 - val_acc: 0.9341\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9656\n",
      "Epoch 00012: val_loss improved from 0.23194 to 0.21296, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/012-0.2130.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1289 - acc: 0.9655 - val_loss: 0.2130 - val_acc: 0.9408\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9672\n",
      "Epoch 00013: val_loss improved from 0.21296 to 0.21050, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/013-0.2105.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1211 - acc: 0.9672 - val_loss: 0.2105 - val_acc: 0.9378\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9748\n",
      "Epoch 00014: val_loss did not improve from 0.21050\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0992 - acc: 0.9748 - val_loss: 0.2193 - val_acc: 0.9352\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9762\n",
      "Epoch 00015: val_loss improved from 0.21050 to 0.19858, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/015-0.1986.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0919 - acc: 0.9762 - val_loss: 0.1986 - val_acc: 0.9432\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9812\n",
      "Epoch 00016: val_loss improved from 0.19858 to 0.19441, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/016-0.1944.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0786 - acc: 0.9812 - val_loss: 0.1944 - val_acc: 0.9418\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9824\n",
      "Epoch 00017: val_loss did not improve from 0.19441\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0708 - acc: 0.9824 - val_loss: 0.2056 - val_acc: 0.9383\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9856\n",
      "Epoch 00018: val_loss did not improve from 0.19441\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0628 - acc: 0.9855 - val_loss: 0.2092 - val_acc: 0.9380\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9820\n",
      "Epoch 00019: val_loss did not improve from 0.19441\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0708 - acc: 0.9820 - val_loss: 0.1992 - val_acc: 0.9439\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9895\n",
      "Epoch 00020: val_loss improved from 0.19441 to 0.18347, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/020-0.1835.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0474 - acc: 0.9895 - val_loss: 0.1835 - val_acc: 0.9457\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9912\n",
      "Epoch 00021: val_loss did not improve from 0.18347\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0441 - acc: 0.9912 - val_loss: 0.1883 - val_acc: 0.9478\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9911\n",
      "Epoch 00022: val_loss did not improve from 0.18347\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0419 - acc: 0.9911 - val_loss: 0.1962 - val_acc: 0.9432\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9935\n",
      "Epoch 00023: val_loss did not improve from 0.18347\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0347 - acc: 0.9935 - val_loss: 0.2467 - val_acc: 0.9285\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9938\n",
      "Epoch 00024: val_loss did not improve from 0.18347\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0334 - acc: 0.9938 - val_loss: 0.1919 - val_acc: 0.9460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9946\n",
      "Epoch 00025: val_loss did not improve from 0.18347\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0286 - acc: 0.9946 - val_loss: 0.2113 - val_acc: 0.9394\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9914\n",
      "Epoch 00026: val_loss did not improve from 0.18347\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0390 - acc: 0.9914 - val_loss: 0.1897 - val_acc: 0.9460\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9960\n",
      "Epoch 00027: val_loss did not improve from 0.18347\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0239 - acc: 0.9960 - val_loss: 0.2017 - val_acc: 0.9446\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0267 - acc: 0.9951\n",
      "Epoch 00028: val_loss did not improve from 0.18347\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0268 - acc: 0.9951 - val_loss: 0.2282 - val_acc: 0.9364\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9907\n",
      "Epoch 00029: val_loss did not improve from 0.18347\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0371 - acc: 0.9907 - val_loss: 0.1882 - val_acc: 0.9457\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9947\n",
      "Epoch 00030: val_loss did not improve from 0.18347\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0259 - acc: 0.9946 - val_loss: 0.1872 - val_acc: 0.9506\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9965\n",
      "Epoch 00031: val_loss did not improve from 0.18347\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0211 - acc: 0.9965 - val_loss: 0.1851 - val_acc: 0.9518\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9983\n",
      "Epoch 00032: val_loss did not improve from 0.18347\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0135 - acc: 0.9983 - val_loss: 0.2396 - val_acc: 0.9392\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9908\n",
      "Epoch 00033: val_loss did not improve from 0.18347\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0360 - acc: 0.9908 - val_loss: 0.1880 - val_acc: 0.9483\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9986\n",
      "Epoch 00034: val_loss improved from 0.18347 to 0.17689, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_8_conv_checkpoint/034-0.1769.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0116 - acc: 0.9986 - val_loss: 0.1769 - val_acc: 0.9532\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9980\n",
      "Epoch 00035: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0124 - acc: 0.9980 - val_loss: 0.2266 - val_acc: 0.9427\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9965\n",
      "Epoch 00036: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0180 - acc: 0.9965 - val_loss: 0.1888 - val_acc: 0.9471\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9882\n",
      "Epoch 00037: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0432 - acc: 0.9882 - val_loss: 0.1836 - val_acc: 0.9499\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9987\n",
      "Epoch 00038: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0113 - acc: 0.9987 - val_loss: 0.1850 - val_acc: 0.9509\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9990\n",
      "Epoch 00039: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0090 - acc: 0.9990 - val_loss: 0.1882 - val_acc: 0.9522\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9990\n",
      "Epoch 00040: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0087 - acc: 0.9990 - val_loss: 0.2033 - val_acc: 0.9471\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9989\n",
      "Epoch 00041: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0094 - acc: 0.9989 - val_loss: 0.2135 - val_acc: 0.9448\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9968\n",
      "Epoch 00042: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0158 - acc: 0.9968 - val_loss: 0.2177 - val_acc: 0.9464\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9973\n",
      "Epoch 00043: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0141 - acc: 0.9973 - val_loss: 0.2590 - val_acc: 0.9371\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9933\n",
      "Epoch 00044: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0258 - acc: 0.9933 - val_loss: 0.1987 - val_acc: 0.9453\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9987\n",
      "Epoch 00045: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0090 - acc: 0.9987 - val_loss: 0.1894 - val_acc: 0.9515\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9994\n",
      "Epoch 00046: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0063 - acc: 0.9994 - val_loss: 0.2181 - val_acc: 0.9478\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9971\n",
      "Epoch 00047: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0138 - acc: 0.9971 - val_loss: 0.2142 - val_acc: 0.9434\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9946\n",
      "Epoch 00048: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0209 - acc: 0.9946 - val_loss: 0.2166 - val_acc: 0.9413\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9943\n",
      "Epoch 00049: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0235 - acc: 0.9942 - val_loss: 0.1978 - val_acc: 0.9509\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9971\n",
      "Epoch 00050: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0131 - acc: 0.9971 - val_loss: 0.1952 - val_acc: 0.9502\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9978\n",
      "Epoch 00051: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0112 - acc: 0.9977 - val_loss: 0.2462 - val_acc: 0.9411\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9959\n",
      "Epoch 00052: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0160 - acc: 0.9959 - val_loss: 0.2069 - val_acc: 0.9455\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9979\n",
      "Epoch 00053: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0098 - acc: 0.9979 - val_loss: 0.1813 - val_acc: 0.9543\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9995\n",
      "Epoch 00054: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0049 - acc: 0.9995 - val_loss: 0.2029 - val_acc: 0.9525\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9991\n",
      "Epoch 00055: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0061 - acc: 0.9990 - val_loss: 0.2337 - val_acc: 0.9427\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9921\n",
      "Epoch 00056: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0262 - acc: 0.9920 - val_loss: 0.2577 - val_acc: 0.9362\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9923\n",
      "Epoch 00057: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0271 - acc: 0.9923 - val_loss: 0.1864 - val_acc: 0.9536\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9994\n",
      "Epoch 00058: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0059 - acc: 0.9993 - val_loss: 0.2155 - val_acc: 0.9506\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9956\n",
      "Epoch 00059: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0188 - acc: 0.9955 - val_loss: 0.1868 - val_acc: 0.9515\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9980\n",
      "Epoch 00060: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0098 - acc: 0.9980 - val_loss: 0.1923 - val_acc: 0.9543\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9992\n",
      "Epoch 00061: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0059 - acc: 0.9992 - val_loss: 0.1830 - val_acc: 0.9534\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9995\n",
      "Epoch 00062: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0042 - acc: 0.9995 - val_loss: 0.2637 - val_acc: 0.9399\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9977\n",
      "Epoch 00063: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0104 - acc: 0.9977 - val_loss: 0.2055 - val_acc: 0.9534\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9988\n",
      "Epoch 00064: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0067 - acc: 0.9988 - val_loss: 0.2485 - val_acc: 0.9404\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9980\n",
      "Epoch 00065: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0100 - acc: 0.9979 - val_loss: 0.2444 - val_acc: 0.9422\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9949\n",
      "Epoch 00066: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0193 - acc: 0.9949 - val_loss: 0.2174 - val_acc: 0.9499\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9975\n",
      "Epoch 00067: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0106 - acc: 0.9975 - val_loss: 0.1914 - val_acc: 0.9532\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9995\n",
      "Epoch 00068: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0039 - acc: 0.9995 - val_loss: 0.1953 - val_acc: 0.9488\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9940\n",
      "Epoch 00069: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0223 - acc: 0.9940 - val_loss: 0.1872 - val_acc: 0.9539\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9953\n",
      "Epoch 00070: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0163 - acc: 0.9953 - val_loss: 0.1941 - val_acc: 0.9548\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9996\n",
      "Epoch 00071: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0038 - acc: 0.9996 - val_loss: 0.1934 - val_acc: 0.9541\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9996\n",
      "Epoch 00072: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0036 - acc: 0.9995 - val_loss: 0.2228 - val_acc: 0.9476\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9963\n",
      "Epoch 00073: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0141 - acc: 0.9963 - val_loss: 0.2085 - val_acc: 0.9536\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 00074: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0037 - acc: 0.9995 - val_loss: 0.1958 - val_acc: 0.9539\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9989\n",
      "Epoch 00075: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0055 - acc: 0.9989 - val_loss: 0.2479 - val_acc: 0.9411\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9986\n",
      "Epoch 00076: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0074 - acc: 0.9986 - val_loss: 0.2371 - val_acc: 0.9471\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9971\n",
      "Epoch 00077: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0109 - acc: 0.9971 - val_loss: 0.1998 - val_acc: 0.9529\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9996\n",
      "Epoch 00078: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0037 - acc: 0.9996 - val_loss: 0.2235 - val_acc: 0.9495\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9974\n",
      "Epoch 00079: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0118 - acc: 0.9974 - val_loss: 0.2207 - val_acc: 0.9499\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9990\n",
      "Epoch 00080: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0051 - acc: 0.9990 - val_loss: 0.2108 - val_acc: 0.9511\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9994\n",
      "Epoch 00081: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0040 - acc: 0.9994 - val_loss: 0.2013 - val_acc: 0.9541\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9984\n",
      "Epoch 00082: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0065 - acc: 0.9984 - val_loss: 0.3145 - val_acc: 0.9280\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9983\n",
      "Epoch 00083: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0079 - acc: 0.9983 - val_loss: 0.2566 - val_acc: 0.9450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9992\n",
      "Epoch 00084: val_loss did not improve from 0.17689\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0048 - acc: 0.9992 - val_loss: 0.2079 - val_acc: 0.9557\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2418 - acc: 0.9379\n",
      "Loss: 0.24182108643765515 Accuracy: 0.9379024\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3090 - acc: 0.5948\n",
      "Epoch 00001: val_loss improved from inf to 0.74516, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_9_conv_checkpoint/001-0.7452.hdf5\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 1.3090 - acc: 0.5948 - val_loss: 0.7452 - val_acc: 0.7780\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5491 - acc: 0.8332\n",
      "Epoch 00002: val_loss improved from 0.74516 to 0.42370, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_9_conv_checkpoint/002-0.4237.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.5491 - acc: 0.8332 - val_loss: 0.4237 - val_acc: 0.8719\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3641 - acc: 0.8916\n",
      "Epoch 00003: val_loss improved from 0.42370 to 0.37884, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_9_conv_checkpoint/003-0.3788.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.3641 - acc: 0.8916 - val_loss: 0.3788 - val_acc: 0.8845\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2750 - acc: 0.9190\n",
      "Epoch 00004: val_loss improved from 0.37884 to 0.25652, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_9_conv_checkpoint/004-0.2565.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2750 - acc: 0.9190 - val_loss: 0.2565 - val_acc: 0.9276\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2182 - acc: 0.9354\n",
      "Epoch 00005: val_loss improved from 0.25652 to 0.22851, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_9_conv_checkpoint/005-0.2285.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2182 - acc: 0.9354 - val_loss: 0.2285 - val_acc: 0.9290\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1781 - acc: 0.9479\n",
      "Epoch 00006: val_loss improved from 0.22851 to 0.22578, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_9_conv_checkpoint/006-0.2258.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1782 - acc: 0.9479 - val_loss: 0.2258 - val_acc: 0.9336\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1515 - acc: 0.9560\n",
      "Epoch 00007: val_loss did not improve from 0.22578\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1515 - acc: 0.9560 - val_loss: 0.2415 - val_acc: 0.9294\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1292 - acc: 0.9631\n",
      "Epoch 00008: val_loss improved from 0.22578 to 0.19321, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_9_conv_checkpoint/008-0.1932.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1292 - acc: 0.9631 - val_loss: 0.1932 - val_acc: 0.9443\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9712\n",
      "Epoch 00009: val_loss did not improve from 0.19321\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1044 - acc: 0.9713 - val_loss: 0.2173 - val_acc: 0.9343\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9749\n",
      "Epoch 00010: val_loss did not improve from 0.19321\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0904 - acc: 0.9749 - val_loss: 0.2062 - val_acc: 0.9397\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9815\n",
      "Epoch 00011: val_loss improved from 0.19321 to 0.18319, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_9_conv_checkpoint/011-0.1832.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0736 - acc: 0.9816 - val_loss: 0.1832 - val_acc: 0.9441\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9826\n",
      "Epoch 00012: val_loss did not improve from 0.18319\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0664 - acc: 0.9826 - val_loss: 0.2106 - val_acc: 0.9371\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9811\n",
      "Epoch 00013: val_loss did not improve from 0.18319\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0708 - acc: 0.9811 - val_loss: 0.1888 - val_acc: 0.9455\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9867\n",
      "Epoch 00014: val_loss did not improve from 0.18319\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0531 - acc: 0.9867 - val_loss: 0.1982 - val_acc: 0.9427\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9862\n",
      "Epoch 00015: val_loss did not improve from 0.18319\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0548 - acc: 0.9862 - val_loss: 0.1972 - val_acc: 0.9422\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9930\n",
      "Epoch 00016: val_loss improved from 0.18319 to 0.16464, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_9_conv_checkpoint/016-0.1646.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0347 - acc: 0.9930 - val_loss: 0.1646 - val_acc: 0.9553\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9936\n",
      "Epoch 00017: val_loss did not improve from 0.16464\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0318 - acc: 0.9936 - val_loss: 0.2037 - val_acc: 0.9418\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9887\n",
      "Epoch 00018: val_loss did not improve from 0.16464\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0444 - acc: 0.9887 - val_loss: 0.1747 - val_acc: 0.9534\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9924\n",
      "Epoch 00019: val_loss did not improve from 0.16464\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0333 - acc: 0.9924 - val_loss: 0.1797 - val_acc: 0.9513\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9923\n",
      "Epoch 00020: val_loss did not improve from 0.16464\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0330 - acc: 0.9922 - val_loss: 0.1718 - val_acc: 0.9522\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9953\n",
      "Epoch 00021: val_loss did not improve from 0.16464\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0242 - acc: 0.9953 - val_loss: 0.1709 - val_acc: 0.9569\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9965\n",
      "Epoch 00022: val_loss did not improve from 0.16464\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0183 - acc: 0.9965 - val_loss: 0.1912 - val_acc: 0.9490\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9934\n",
      "Epoch 00023: val_loss did not improve from 0.16464\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0280 - acc: 0.9934 - val_loss: 0.1741 - val_acc: 0.9520\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9966\n",
      "Epoch 00024: val_loss did not improve from 0.16464\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0172 - acc: 0.9966 - val_loss: 0.1773 - val_acc: 0.9506\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9952\n",
      "Epoch 00025: val_loss did not improve from 0.16464\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0201 - acc: 0.9952 - val_loss: 0.1748 - val_acc: 0.9536\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9920\n",
      "Epoch 00026: val_loss improved from 0.16464 to 0.16054, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_9_conv_checkpoint/026-0.1605.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0295 - acc: 0.9920 - val_loss: 0.1605 - val_acc: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9988\n",
      "Epoch 00027: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0092 - acc: 0.9988 - val_loss: 0.1895 - val_acc: 0.9520\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9977\n",
      "Epoch 00028: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0122 - acc: 0.9977 - val_loss: 0.2231 - val_acc: 0.9418\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9946\n",
      "Epoch 00029: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0199 - acc: 0.9946 - val_loss: 0.1681 - val_acc: 0.9564\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9960\n",
      "Epoch 00030: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0173 - acc: 0.9960 - val_loss: 0.2436 - val_acc: 0.9413\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9901\n",
      "Epoch 00031: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0333 - acc: 0.9901 - val_loss: 0.1712 - val_acc: 0.9562\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9988\n",
      "Epoch 00032: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0080 - acc: 0.9988 - val_loss: 0.1720 - val_acc: 0.9588\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9993\n",
      "Epoch 00033: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0059 - acc: 0.9993 - val_loss: 0.1792 - val_acc: 0.9550\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9987\n",
      "Epoch 00034: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0078 - acc: 0.9987 - val_loss: 0.1892 - val_acc: 0.9518\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9971\n",
      "Epoch 00035: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0132 - acc: 0.9971 - val_loss: 0.2035 - val_acc: 0.9527\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9934\n",
      "Epoch 00036: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0232 - acc: 0.9934 - val_loss: 0.1984 - val_acc: 0.9520\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9943\n",
      "Epoch 00037: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0203 - acc: 0.9943 - val_loss: 0.2062 - val_acc: 0.9509\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9990\n",
      "Epoch 00038: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0059 - acc: 0.9990 - val_loss: 0.1724 - val_acc: 0.9574\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9995\n",
      "Epoch 00039: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0043 - acc: 0.9995 - val_loss: 0.1803 - val_acc: 0.9560\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9973\n",
      "Epoch 00040: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0113 - acc: 0.9973 - val_loss: 0.2047 - val_acc: 0.9495\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9975\n",
      "Epoch 00041: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0116 - acc: 0.9975 - val_loss: 0.2076 - val_acc: 0.9492\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9988\n",
      "Epoch 00042: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0067 - acc: 0.9988 - val_loss: 0.2173 - val_acc: 0.9446\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9936\n",
      "Epoch 00043: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0214 - acc: 0.9936 - val_loss: 0.1690 - val_acc: 0.9588\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9992\n",
      "Epoch 00044: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0048 - acc: 0.9992 - val_loss: 0.1847 - val_acc: 0.9590\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9990\n",
      "Epoch 00045: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0052 - acc: 0.9990 - val_loss: 0.1773 - val_acc: 0.9585\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9979\n",
      "Epoch 00046: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0095 - acc: 0.9979 - val_loss: 0.1738 - val_acc: 0.9583\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9984\n",
      "Epoch 00047: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0075 - acc: 0.9984 - val_loss: 0.1971 - val_acc: 0.9539\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9952\n",
      "Epoch 00048: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0161 - acc: 0.9952 - val_loss: 0.2372 - val_acc: 0.9427\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9951\n",
      "Epoch 00049: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0163 - acc: 0.9951 - val_loss: 0.2036 - val_acc: 0.9511\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9971\n",
      "Epoch 00050: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0104 - acc: 0.9971 - val_loss: 0.1696 - val_acc: 0.9588\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9992\n",
      "Epoch 00051: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0039 - acc: 0.9992 - val_loss: 0.1626 - val_acc: 0.9597\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9998\n",
      "Epoch 00052: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0024 - acc: 0.9998 - val_loss: 0.1867 - val_acc: 0.9588\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9961\n",
      "Epoch 00053: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0148 - acc: 0.9960 - val_loss: 0.1858 - val_acc: 0.9550\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9977\n",
      "Epoch 00054: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0099 - acc: 0.9977 - val_loss: 0.1829 - val_acc: 0.9588\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9980\n",
      "Epoch 00055: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0080 - acc: 0.9980 - val_loss: 0.1821 - val_acc: 0.9595\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9995\n",
      "Epoch 00056: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0032 - acc: 0.9995 - val_loss: 0.1762 - val_acc: 0.9613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9972\n",
      "Epoch 00057: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0100 - acc: 0.9972 - val_loss: 0.1898 - val_acc: 0.9553\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9991\n",
      "Epoch 00058: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0054 - acc: 0.9991 - val_loss: 0.2192 - val_acc: 0.9525\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9995\n",
      "Epoch 00059: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0039 - acc: 0.9995 - val_loss: 0.1700 - val_acc: 0.9602\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9953\n",
      "Epoch 00060: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0148 - acc: 0.9953 - val_loss: 0.1698 - val_acc: 0.9583\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9949\n",
      "Epoch 00061: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0182 - acc: 0.9949 - val_loss: 0.1766 - val_acc: 0.9574\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9996\n",
      "Epoch 00062: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0031 - acc: 0.9996 - val_loss: 0.1623 - val_acc: 0.9620\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9997\n",
      "Epoch 00063: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0019 - acc: 0.9997 - val_loss: 0.1699 - val_acc: 0.9618\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9998\n",
      "Epoch 00064: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0018 - acc: 0.9998 - val_loss: 0.1748 - val_acc: 0.9597\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9957\n",
      "Epoch 00065: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0147 - acc: 0.9957 - val_loss: 0.1786 - val_acc: 0.9574\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9998\n",
      "Epoch 00066: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0023 - acc: 0.9998 - val_loss: 0.1957 - val_acc: 0.9553\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9946\n",
      "Epoch 00067: val_loss did not improve from 0.16054\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0178 - acc: 0.9946 - val_loss: 0.1612 - val_acc: 0.9599\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 00068: val_loss improved from 0.16054 to 0.15754, saving model to model/checkpoint/1D_CNN_custom_he-uniform_BN_9_conv_checkpoint/068-0.1575.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0026 - acc: 0.9998 - val_loss: 0.1575 - val_acc: 0.9625\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9997\n",
      "Epoch 00069: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0022 - acc: 0.9997 - val_loss: 0.1719 - val_acc: 0.9602\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9986\n",
      "Epoch 00070: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0057 - acc: 0.9986 - val_loss: 0.1901 - val_acc: 0.9574\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9988\n",
      "Epoch 00071: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0057 - acc: 0.9988 - val_loss: 0.1805 - val_acc: 0.9588\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9995\n",
      "Epoch 00072: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0027 - acc: 0.9995 - val_loss: 0.1831 - val_acc: 0.9623\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9989\n",
      "Epoch 00073: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0047 - acc: 0.9989 - val_loss: 0.2431 - val_acc: 0.9467\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9945\n",
      "Epoch 00074: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0165 - acc: 0.9945 - val_loss: 0.2029 - val_acc: 0.9560\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9991\n",
      "Epoch 00075: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0039 - acc: 0.9991 - val_loss: 0.1840 - val_acc: 0.9620\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9992\n",
      "Epoch 00076: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0036 - acc: 0.9992 - val_loss: 0.1841 - val_acc: 0.9578\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9990\n",
      "Epoch 00077: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0040 - acc: 0.9990 - val_loss: 0.2186 - val_acc: 0.9495\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9961\n",
      "Epoch 00078: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0126 - acc: 0.9961 - val_loss: 0.1966 - val_acc: 0.9557\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9995\n",
      "Epoch 00079: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0027 - acc: 0.9995 - val_loss: 0.1669 - val_acc: 0.9630\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9994\n",
      "Epoch 00080: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0027 - acc: 0.9994 - val_loss: 0.1831 - val_acc: 0.9609\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9997\n",
      "Epoch 00081: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0020 - acc: 0.9997 - val_loss: 0.1662 - val_acc: 0.9639\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9957\n",
      "Epoch 00082: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0152 - acc: 0.9957 - val_loss: 0.1636 - val_acc: 0.9613\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0018 - acc: 0.9997\n",
      "Epoch 00083: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0018 - acc: 0.9997 - val_loss: 0.1681 - val_acc: 0.9646\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9984\n",
      "Epoch 00084: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0058 - acc: 0.9984 - val_loss: 0.2019 - val_acc: 0.9578\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 00085: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0027 - acc: 0.9993 - val_loss: 0.1966 - val_acc: 0.9569\n",
      "Epoch 86/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9990\n",
      "Epoch 00086: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0046 - acc: 0.9990 - val_loss: 0.1767 - val_acc: 0.9639\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 00087: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0035 - acc: 0.9990 - val_loss: 0.2357 - val_acc: 0.9488\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9964\n",
      "Epoch 00088: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0118 - acc: 0.9964 - val_loss: 0.1676 - val_acc: 0.9627\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 00089: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0020 - acc: 0.9996 - val_loss: 0.1621 - val_acc: 0.9651\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.8935e-04 - acc: 0.9999\n",
      "Epoch 00090: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 9.8924e-04 - acc: 0.9999 - val_loss: 0.1613 - val_acc: 0.9644\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9997\n",
      "Epoch 00091: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0013 - acc: 0.9997 - val_loss: 0.2008 - val_acc: 0.9557\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9971\n",
      "Epoch 00092: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0096 - acc: 0.9971 - val_loss: 0.2001 - val_acc: 0.9562\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9988\n",
      "Epoch 00093: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0049 - acc: 0.9988 - val_loss: 0.2286 - val_acc: 0.9532\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9995\n",
      "Epoch 00094: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0024 - acc: 0.9995 - val_loss: 0.1741 - val_acc: 0.9632\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9978\n",
      "Epoch 00095: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0072 - acc: 0.9977 - val_loss: 0.2330 - val_acc: 0.9502\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9967\n",
      "Epoch 00096: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0100 - acc: 0.9967 - val_loss: 0.1855 - val_acc: 0.9578\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9996\n",
      "Epoch 00097: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1847 - val_acc: 0.9623\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9993\n",
      "Epoch 00098: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0026 - acc: 0.9993 - val_loss: 0.1676 - val_acc: 0.9646\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9986\n",
      "Epoch 00099: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0046 - acc: 0.9986 - val_loss: 0.2870 - val_acc: 0.9406\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9988\n",
      "Epoch 00100: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0051 - acc: 0.9988 - val_loss: 0.2939 - val_acc: 0.9413\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9987\n",
      "Epoch 00101: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0049 - acc: 0.9987 - val_loss: 0.2019 - val_acc: 0.9599\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9976\n",
      "Epoch 00102: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0078 - acc: 0.9976 - val_loss: 0.1897 - val_acc: 0.9623\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9994\n",
      "Epoch 00103: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0025 - acc: 0.9994 - val_loss: 0.1891 - val_acc: 0.9604\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9994\n",
      "Epoch 00104: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0025 - acc: 0.9994 - val_loss: 0.2212 - val_acc: 0.9571\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9991\n",
      "Epoch 00105: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0037 - acc: 0.9991 - val_loss: 0.2285 - val_acc: 0.9518\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9978\n",
      "Epoch 00106: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0077 - acc: 0.9978 - val_loss: 0.1898 - val_acc: 0.9606\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9964\n",
      "Epoch 00107: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0120 - acc: 0.9964 - val_loss: 0.1955 - val_acc: 0.9599\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9998\n",
      "Epoch 00108: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0013 - acc: 0.9998 - val_loss: 0.1712 - val_acc: 0.9653\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.6626e-04 - acc: 0.9999\n",
      "Epoch 00109: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 8.6628e-04 - acc: 0.9999 - val_loss: 0.1812 - val_acc: 0.9662\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.0847e-04 - acc: 0.9999\n",
      "Epoch 00110: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 6.6638e-04 - acc: 0.9999 - val_loss: 0.1742 - val_acc: 0.9653\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9975\n",
      "Epoch 00111: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0091 - acc: 0.9975 - val_loss: 0.2043 - val_acc: 0.9562\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9995\n",
      "Epoch 00112: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0023 - acc: 0.9995 - val_loss: 0.1715 - val_acc: 0.9648\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9985\n",
      "Epoch 00113: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0048 - acc: 0.9984 - val_loss: 0.2428 - val_acc: 0.9515\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9974\n",
      "Epoch 00114: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0095 - acc: 0.9974 - val_loss: 0.1759 - val_acc: 0.9634\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9975\n",
      "Epoch 00115: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0086 - acc: 0.9975 - val_loss: 0.1798 - val_acc: 0.9632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 00116: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0017 - acc: 0.9997 - val_loss: 0.1714 - val_acc: 0.9641\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.2192e-04 - acc: 0.9999\n",
      "Epoch 00117: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 8.2182e-04 - acc: 0.9999 - val_loss: 0.1671 - val_acc: 0.9648\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.2278e-04 - acc: 0.9999\n",
      "Epoch 00118: val_loss did not improve from 0.15754\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 6.2270e-04 - acc: 0.9999 - val_loss: 0.1755 - val_acc: 0.9641\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2236 - acc: 0.9495\n",
      "Loss: 0.22355228183812317 Accuracy: 0.9495327\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    base = '1D_CNN_custom_he-uniform_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_BN_2(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_he-uniform_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,316,816\n",
      "Trainable params: 2,088,976\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 959us/sample - loss: 2.0867 - acc: 0.4993\n",
      "Loss: 2.0866605542530525 Accuracy: 0.4992731\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 820,816\n",
      "Trainable params: 744,528\n",
      "Non-trainable params: 76,288\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.3407 - acc: 0.6345\n",
      "Loss: 1.3407388262040643 Accuracy: 0.6344756\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 608,976\n",
      "Trainable params: 557,776\n",
      "Non-trainable params: 51,200\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.0560 - acc: 0.7101\n",
      "Loss: 1.0560005102078367 Accuracy: 0.7100727\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 353,616\n",
      "Trainable params: 335,952\n",
      "Non-trainable params: 17,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.6609 - acc: 0.8102\n",
      "Loss: 0.6608560858733433 Accuracy: 0.81017655\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 323,536\n",
      "Trainable params: 316,880\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3381 - acc: 0.9024\n",
      "Loss: 0.3380721197135723 Accuracy: 0.9023884\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_70 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 370,256\n",
      "Trainable params: 366,928\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2418 - acc: 0.9379\n",
      "Loss: 0.24182108643765515 Accuracy: 0.9379024\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 527,696\n",
      "Trainable params: 524,624\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2236 - acc: 0.9495\n",
      "Loss: 0.22355228183812317 Accuracy: 0.9495327\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_he-uniform_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_he-uniform_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,316,816\n",
      "Trainable params: 2,088,976\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 4.9522 - acc: 0.4773\n",
      "Loss: 4.952173681447316 Accuracy: 0.47725856\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 820,816\n",
      "Trainable params: 744,528\n",
      "Non-trainable params: 76,288\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.3808 - acc: 0.6145\n",
      "Loss: 2.3808169884597525 Accuracy: 0.6145379\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 608,976\n",
      "Trainable params: 557,776\n",
      "Non-trainable params: 51,200\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.8046 - acc: 0.6872\n",
      "Loss: 1.8046407324007614 Accuracy: 0.6872274\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 353,616\n",
      "Trainable params: 335,952\n",
      "Non-trainable params: 17,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.9231 - acc: 0.8087\n",
      "Loss: 0.9230782985934834 Accuracy: 0.80872273\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 323,536\n",
      "Trainable params: 316,880\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3690 - acc: 0.9126\n",
      "Loss: 0.36902239811011933 Accuracy: 0.9125649\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_70 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 370,256\n",
      "Trainable params: 366,928\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2736 - acc: 0.9383\n",
      "Loss: 0.27357635242228134 Accuracy: 0.9383178\n",
      "\n",
      "1D_CNN_custom_he-uniform_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 527,696\n",
      "Trainable params: 524,624\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.2154 - acc: 0.9524\n",
      "Loss: 0.21542760161054345 Accuracy: 0.95244026\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_BN_2'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
