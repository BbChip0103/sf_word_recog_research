{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_BN_2(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, \n",
    "                      padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(BatchNormalization())    \n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,480,656\n",
      "Trainable params: 18,432,528\n",
      "Non-trainable params: 2,048,128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 6,847,696\n",
      "Trainable params: 6,164,816\n",
      "Non-trainable params: 682,880\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,316,816\n",
      "Trainable params: 2,088,976\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 820,816\n",
      "Trainable params: 744,528\n",
      "Non-trainable params: 76,288\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 608,976\n",
      "Trainable params: 557,776\n",
      "Non-trainable params: 51,200\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 353,616\n",
      "Trainable params: 335,952\n",
      "Non-trainable params: 17,664\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 323,536\n",
      "Trainable params: 316,880\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 370,256\n",
      "Trainable params: 366,928\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 527,696\n",
      "Trainable params: 524,624\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_BN_2(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 11.7719 - acc: 0.2139\n",
      "Epoch 00001: val_loss improved from inf to 12.57896, saving model to model/checkpoint/1D_CNN_custom_BN_2_1_conv_checkpoint/001-12.5790.hdf5\n",
      "36805/36805 [==============================] - 55s 2ms/sample - loss: 11.7713 - acc: 0.2139 - val_loss: 12.5790 - val_acc: 0.1691\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 10.6552 - acc: 0.3026\n",
      "Epoch 00002: val_loss improved from 12.57896 to 11.23500, saving model to model/checkpoint/1D_CNN_custom_BN_2_1_conv_checkpoint/002-11.2350.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 10.6552 - acc: 0.3026 - val_loss: 11.2350 - val_acc: 0.2648\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.9582 - acc: 0.3492\n",
      "Epoch 00003: val_loss improved from 11.23500 to 10.97121, saving model to model/checkpoint/1D_CNN_custom_BN_2_1_conv_checkpoint/003-10.9712.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 9.9586 - acc: 0.3491 - val_loss: 10.9712 - val_acc: 0.2772\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.4882 - acc: 0.3813\n",
      "Epoch 00004: val_loss improved from 10.97121 to 10.84606, saving model to model/checkpoint/1D_CNN_custom_BN_2_1_conv_checkpoint/004-10.8461.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 9.4882 - acc: 0.3813 - val_loss: 10.8461 - val_acc: 0.2921\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 9.1255 - acc: 0.4079\n",
      "Epoch 00005: val_loss improved from 10.84606 to 10.48011, saving model to model/checkpoint/1D_CNN_custom_BN_2_1_conv_checkpoint/005-10.4801.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 9.1258 - acc: 0.4079 - val_loss: 10.4801 - val_acc: 0.3189\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.8565 - acc: 0.4270\n",
      "Epoch 00006: val_loss did not improve from 10.48011\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 8.8570 - acc: 0.4270 - val_loss: 10.8618 - val_acc: 0.3003\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.6879 - acc: 0.4395\n",
      "Epoch 00007: val_loss did not improve from 10.48011\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 8.6876 - acc: 0.4395 - val_loss: 11.4281 - val_acc: 0.2653\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.4035 - acc: 0.4579\n",
      "Epoch 00008: val_loss did not improve from 10.48011\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 8.4041 - acc: 0.4579 - val_loss: 10.6318 - val_acc: 0.3140\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.2292 - acc: 0.4679\n",
      "Epoch 00009: val_loss did not improve from 10.48011\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 8.2292 - acc: 0.4679 - val_loss: 10.6418 - val_acc: 0.3131\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 8.0179 - acc: 0.4847\n",
      "Epoch 00010: val_loss did not improve from 10.48011\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 8.0185 - acc: 0.4846 - val_loss: 11.0202 - val_acc: 0.2954\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.8954 - acc: 0.4923\n",
      "Epoch 00011: val_loss improved from 10.48011 to 10.37598, saving model to model/checkpoint/1D_CNN_custom_BN_2_1_conv_checkpoint/011-10.3760.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.8957 - acc: 0.4923 - val_loss: 10.3760 - val_acc: 0.3322\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.7683 - acc: 0.5005\n",
      "Epoch 00012: val_loss did not improve from 10.37598\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.7686 - acc: 0.5004 - val_loss: 10.9014 - val_acc: 0.3024\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.5817 - acc: 0.5127\n",
      "Epoch 00013: val_loss did not improve from 10.37598\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.5824 - acc: 0.5127 - val_loss: 10.4416 - val_acc: 0.3259\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.4091 - acc: 0.5233\n",
      "Epoch 00014: val_loss did not improve from 10.37598\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.4100 - acc: 0.5232 - val_loss: 10.4632 - val_acc: 0.3268\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.3335 - acc: 0.5286\n",
      "Epoch 00015: val_loss did not improve from 10.37598\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.3334 - acc: 0.5287 - val_loss: 10.8677 - val_acc: 0.3063\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.1408 - acc: 0.5418\n",
      "Epoch 00016: val_loss did not improve from 10.37598\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.1417 - acc: 0.5417 - val_loss: 11.2718 - val_acc: 0.2828\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 7.1126 - acc: 0.5435\n",
      "Epoch 00017: val_loss did not improve from 10.37598\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 7.1138 - acc: 0.5434 - val_loss: 11.3640 - val_acc: 0.2744\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.8700 - acc: 0.5586\n",
      "Epoch 00018: val_loss did not improve from 10.37598\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.8692 - acc: 0.5586 - val_loss: 10.7322 - val_acc: 0.3168\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.8193 - acc: 0.5611\n",
      "Epoch 00019: val_loss did not improve from 10.37598\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.8197 - acc: 0.5611 - val_loss: 11.4037 - val_acc: 0.2751\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.6710 - acc: 0.5727\n",
      "Epoch 00020: val_loss did not improve from 10.37598\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.6723 - acc: 0.5727 - val_loss: 10.5172 - val_acc: 0.3249\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.6497 - acc: 0.5744\n",
      "Epoch 00021: val_loss did not improve from 10.37598\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.6497 - acc: 0.5744 - val_loss: 11.1576 - val_acc: 0.2919\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.5025 - acc: 0.5832\n",
      "Epoch 00022: val_loss did not improve from 10.37598\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.5026 - acc: 0.5832 - val_loss: 10.3855 - val_acc: 0.3331\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.4453 - acc: 0.5877\n",
      "Epoch 00023: val_loss did not improve from 10.37598\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.4457 - acc: 0.5877 - val_loss: 10.7269 - val_acc: 0.3140\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.3829 - acc: 0.5918\n",
      "Epoch 00024: val_loss did not improve from 10.37598\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.3833 - acc: 0.5917 - val_loss: 10.4247 - val_acc: 0.3324\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.2965 - acc: 0.5975\n",
      "Epoch 00025: val_loss improved from 10.37598 to 10.16129, saving model to model/checkpoint/1D_CNN_custom_BN_2_1_conv_checkpoint/025-10.1613.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.2965 - acc: 0.5975 - val_loss: 10.1613 - val_acc: 0.3475\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.1611 - acc: 0.6059\n",
      "Epoch 00026: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.1611 - acc: 0.6059 - val_loss: 10.4381 - val_acc: 0.3324\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.1218 - acc: 0.6095\n",
      "Epoch 00027: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.1215 - acc: 0.6096 - val_loss: 10.3843 - val_acc: 0.3322\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.0685 - acc: 0.6121\n",
      "Epoch 00028: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.0682 - acc: 0.6121 - val_loss: 10.9309 - val_acc: 0.3031\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 6.0686 - acc: 0.6123\n",
      "Epoch 00029: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 6.0696 - acc: 0.6122 - val_loss: 10.3776 - val_acc: 0.3361\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.9175 - acc: 0.6220\n",
      "Epoch 00030: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.9167 - acc: 0.6221 - val_loss: 10.6789 - val_acc: 0.3142\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.8676 - acc: 0.6245\n",
      "Epoch 00031: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.8686 - acc: 0.6245 - val_loss: 10.6536 - val_acc: 0.3240\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.8181 - acc: 0.6286\n",
      "Epoch 00032: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.8183 - acc: 0.6286 - val_loss: 10.5884 - val_acc: 0.3263\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.6942 - acc: 0.6370\n",
      "Epoch 00033: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.6952 - acc: 0.6370 - val_loss: 10.5485 - val_acc: 0.3280\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.6613 - acc: 0.6398\n",
      "Epoch 00034: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.6622 - acc: 0.6397 - val_loss: 10.4094 - val_acc: 0.3310\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.6329 - acc: 0.6416\n",
      "Epoch 00035: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.6330 - acc: 0.6416 - val_loss: 10.2492 - val_acc: 0.3454\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.5916 - acc: 0.6431\n",
      "Epoch 00036: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.5913 - acc: 0.6431 - val_loss: 10.2809 - val_acc: 0.3403\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.6164 - acc: 0.6430\n",
      "Epoch 00037: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.6161 - acc: 0.6430 - val_loss: 10.4994 - val_acc: 0.3289\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.5277 - acc: 0.6481\n",
      "Epoch 00038: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.5273 - acc: 0.6481 - val_loss: 10.9081 - val_acc: 0.3038\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.5123 - acc: 0.6490\n",
      "Epoch 00039: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.5124 - acc: 0.6490 - val_loss: 10.8159 - val_acc: 0.3086\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.5149 - acc: 0.6488\n",
      "Epoch 00040: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.5164 - acc: 0.6487 - val_loss: 11.4692 - val_acc: 0.2702\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.3907 - acc: 0.6567\n",
      "Epoch 00041: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.3913 - acc: 0.6567 - val_loss: 11.8566 - val_acc: 0.2504\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.3628 - acc: 0.6589\n",
      "Epoch 00042: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.3642 - acc: 0.6588 - val_loss: 10.6329 - val_acc: 0.3219\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.3488 - acc: 0.6599\n",
      "Epoch 00043: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.3493 - acc: 0.6599 - val_loss: 11.0613 - val_acc: 0.2928\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.3033 - acc: 0.6632\n",
      "Epoch 00044: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.3034 - acc: 0.6631 - val_loss: 10.8163 - val_acc: 0.3077\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.2312 - acc: 0.6681\n",
      "Epoch 00045: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.2322 - acc: 0.6680 - val_loss: 11.4285 - val_acc: 0.2795\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.2265 - acc: 0.6674\n",
      "Epoch 00046: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.2271 - acc: 0.6674 - val_loss: 10.6703 - val_acc: 0.3154\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.2380 - acc: 0.6667\n",
      "Epoch 00047: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.2384 - acc: 0.6667 - val_loss: 10.6417 - val_acc: 0.3224\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.1593 - acc: 0.6724\n",
      "Epoch 00048: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.1595 - acc: 0.6724 - val_loss: 11.1853 - val_acc: 0.2888\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.0960 - acc: 0.6755\n",
      "Epoch 00049: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.0958 - acc: 0.6756 - val_loss: 10.5028 - val_acc: 0.3298\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.0882 - acc: 0.6765\n",
      "Epoch 00050: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 5.0884 - acc: 0.6765 - val_loss: 11.2950 - val_acc: 0.2842\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.0337 - acc: 0.6806\n",
      "Epoch 00051: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.0339 - acc: 0.6806 - val_loss: 10.3066 - val_acc: 0.3373\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.0364 - acc: 0.6804\n",
      "Epoch 00052: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 5.0370 - acc: 0.6803 - val_loss: 11.1242 - val_acc: 0.2900\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9608 - acc: 0.6861\n",
      "Epoch 00053: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.9619 - acc: 0.6861 - val_loss: 10.7424 - val_acc: 0.3124\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9663 - acc: 0.6844\n",
      "Epoch 00054: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.9665 - acc: 0.6844 - val_loss: 10.9885 - val_acc: 0.2975\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9372 - acc: 0.6871\n",
      "Epoch 00055: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.9370 - acc: 0.6871 - val_loss: 10.5728 - val_acc: 0.3235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.9058 - acc: 0.6890\n",
      "Epoch 00056: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.9064 - acc: 0.6890 - val_loss: 10.9439 - val_acc: 0.3038\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.8683 - acc: 0.6913\n",
      "Epoch 00057: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.8694 - acc: 0.6912 - val_loss: 10.2737 - val_acc: 0.3417\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.8546 - acc: 0.6921\n",
      "Epoch 00058: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.8548 - acc: 0.6921 - val_loss: 10.2655 - val_acc: 0.3413\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.7863 - acc: 0.6973\n",
      "Epoch 00059: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.7870 - acc: 0.6973 - val_loss: 10.4768 - val_acc: 0.3296\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.7925 - acc: 0.6961\n",
      "Epoch 00060: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.7931 - acc: 0.6961 - val_loss: 10.7400 - val_acc: 0.3170\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.7963 - acc: 0.6957\n",
      "Epoch 00061: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.7962 - acc: 0.6956 - val_loss: 11.1852 - val_acc: 0.2909\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.7991 - acc: 0.6954\n",
      "Epoch 00062: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.7997 - acc: 0.6954 - val_loss: 11.2986 - val_acc: 0.2805\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.7471 - acc: 0.6998\n",
      "Epoch 00063: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.7482 - acc: 0.6997 - val_loss: 10.9757 - val_acc: 0.3017\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.6969 - acc: 0.7026\n",
      "Epoch 00064: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.6980 - acc: 0.7026 - val_loss: 11.4700 - val_acc: 0.2737\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.6720 - acc: 0.7046\n",
      "Epoch 00065: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.6723 - acc: 0.7046 - val_loss: 10.7669 - val_acc: 0.3159\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.6476 - acc: 0.7057\n",
      "Epoch 00066: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.6474 - acc: 0.7057 - val_loss: 10.6700 - val_acc: 0.3194\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.6124 - acc: 0.7082\n",
      "Epoch 00067: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.6127 - acc: 0.7082 - val_loss: 11.0290 - val_acc: 0.2972\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.6722 - acc: 0.7043\n",
      "Epoch 00068: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.6720 - acc: 0.7044 - val_loss: 11.3955 - val_acc: 0.2763\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.6167 - acc: 0.7076\n",
      "Epoch 00069: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.6169 - acc: 0.7076 - val_loss: 10.8277 - val_acc: 0.3103\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.6192 - acc: 0.7071\n",
      "Epoch 00070: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.6199 - acc: 0.7071 - val_loss: 10.8637 - val_acc: 0.3086\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.5530 - acc: 0.7119\n",
      "Epoch 00071: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.5537 - acc: 0.7118 - val_loss: 10.9350 - val_acc: 0.3061\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.5512 - acc: 0.7118\n",
      "Epoch 00072: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.5521 - acc: 0.7118 - val_loss: 11.1019 - val_acc: 0.2942\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.5411 - acc: 0.7126\n",
      "Epoch 00073: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.5419 - acc: 0.7125 - val_loss: 10.8042 - val_acc: 0.3156\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.5187 - acc: 0.7142\n",
      "Epoch 00074: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.5198 - acc: 0.7142 - val_loss: 10.5245 - val_acc: 0.3280\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.4954 - acc: 0.7153\n",
      "Epoch 00075: val_loss did not improve from 10.16129\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 4.4961 - acc: 0.7153 - val_loss: 10.9066 - val_acc: 0.3056\n",
      "\n",
      "1D_CNN_custom_BN_2_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 556us/sample - loss: 10.5517 - acc: 0.3221\n",
      "Loss: 10.551671287005812 Accuracy: 0.32211837\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.4247 - acc: 0.3315\n",
      "Epoch 00001: val_loss improved from inf to 3.98134, saving model to model/checkpoint/1D_CNN_custom_BN_2_2_conv_checkpoint/001-3.9813.hdf5\n",
      "36805/36805 [==============================] - 76s 2ms/sample - loss: 4.4247 - acc: 0.3315 - val_loss: 3.9813 - val_acc: 0.3110\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2503 - acc: 0.6245\n",
      "Epoch 00002: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 2.2510 - acc: 0.6245 - val_loss: 6.4390 - val_acc: 0.2916\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3551 - acc: 0.7657\n",
      "Epoch 00003: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 1.3553 - acc: 0.7656 - val_loss: 5.2195 - val_acc: 0.3562\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9795 - acc: 0.8358\n",
      "Epoch 00004: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.9796 - acc: 0.8357 - val_loss: 5.6623 - val_acc: 0.3545\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7913 - acc: 0.8724\n",
      "Epoch 00005: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.7912 - acc: 0.8724 - val_loss: 5.1173 - val_acc: 0.3857\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6554 - acc: 0.8997\n",
      "Epoch 00006: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.6555 - acc: 0.8996 - val_loss: 5.8194 - val_acc: 0.3662\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6134 - acc: 0.9082\n",
      "Epoch 00007: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.6140 - acc: 0.9081 - val_loss: 5.7239 - val_acc: 0.3892\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6420 - acc: 0.9030\n",
      "Epoch 00008: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.6430 - acc: 0.9029 - val_loss: 7.1688 - val_acc: 0.3385\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6392 - acc: 0.9077\n",
      "Epoch 00009: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.6394 - acc: 0.9077 - val_loss: 6.3607 - val_acc: 0.3818\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5506 - acc: 0.9249\n",
      "Epoch 00010: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5506 - acc: 0.9249 - val_loss: 6.7745 - val_acc: 0.3720\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5446 - acc: 0.9275\n",
      "Epoch 00011: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5447 - acc: 0.9275 - val_loss: 6.4160 - val_acc: 0.3962\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5244 - acc: 0.9327\n",
      "Epoch 00012: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5247 - acc: 0.9327 - val_loss: 7.0839 - val_acc: 0.3776\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5378 - acc: 0.9301\n",
      "Epoch 00013: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.5385 - acc: 0.9300 - val_loss: 6.4713 - val_acc: 0.3997\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4915 - acc: 0.9390\n",
      "Epoch 00014: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4914 - acc: 0.9390 - val_loss: 7.6522 - val_acc: 0.3436\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4549 - acc: 0.9449\n",
      "Epoch 00015: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4549 - acc: 0.9449 - val_loss: 7.1120 - val_acc: 0.3813\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4498 - acc: 0.9449\n",
      "Epoch 00016: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.4502 - acc: 0.9449 - val_loss: 7.0736 - val_acc: 0.3850\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4209 - acc: 0.9518\n",
      "Epoch 00017: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.4213 - acc: 0.9517 - val_loss: 7.1530 - val_acc: 0.3836\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4270 - acc: 0.9498\n",
      "Epoch 00018: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.4269 - acc: 0.9498 - val_loss: 7.0510 - val_acc: 0.3876\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3838 - acc: 0.9573\n",
      "Epoch 00019: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.3846 - acc: 0.9572 - val_loss: 7.0821 - val_acc: 0.3967\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4573 - acc: 0.9470\n",
      "Epoch 00020: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4581 - acc: 0.9470 - val_loss: 7.8966 - val_acc: 0.3638\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3798 - acc: 0.9580\n",
      "Epoch 00021: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.3798 - acc: 0.9580 - val_loss: 7.0436 - val_acc: 0.4074\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3801 - acc: 0.9578\n",
      "Epoch 00022: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3803 - acc: 0.9578 - val_loss: 7.4400 - val_acc: 0.3946\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3766 - acc: 0.9583\n",
      "Epoch 00023: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3770 - acc: 0.9583 - val_loss: 7.4892 - val_acc: 0.3834\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3569 - acc: 0.9616\n",
      "Epoch 00024: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 75s 2ms/sample - loss: 0.3573 - acc: 0.9616 - val_loss: 7.7577 - val_acc: 0.3736\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3764 - acc: 0.9589\n",
      "Epoch 00025: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3764 - acc: 0.9589 - val_loss: 7.8243 - val_acc: 0.3827\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3485 - acc: 0.9640\n",
      "Epoch 00026: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3485 - acc: 0.9639 - val_loss: 8.0671 - val_acc: 0.3662\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3555 - acc: 0.9631\n",
      "Epoch 00027: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3556 - acc: 0.9631 - val_loss: 7.9142 - val_acc: 0.3764\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3636 - acc: 0.9624\n",
      "Epoch 00028: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3636 - acc: 0.9623 - val_loss: 8.3061 - val_acc: 0.3601\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3660 - acc: 0.9611\n",
      "Epoch 00029: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3663 - acc: 0.9610 - val_loss: 8.4949 - val_acc: 0.3364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3643 - acc: 0.9623\n",
      "Epoch 00030: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3642 - acc: 0.9623 - val_loss: 7.4873 - val_acc: 0.4025\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3075 - acc: 0.9699\n",
      "Epoch 00031: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3075 - acc: 0.9699 - val_loss: 8.0003 - val_acc: 0.3839\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3189 - acc: 0.9693\n",
      "Epoch 00032: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3190 - acc: 0.9693 - val_loss: 7.6662 - val_acc: 0.4009\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3394 - acc: 0.9667\n",
      "Epoch 00033: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3398 - acc: 0.9667 - val_loss: 8.2539 - val_acc: 0.3757\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3436 - acc: 0.9657\n",
      "Epoch 00034: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3436 - acc: 0.9657 - val_loss: 8.1849 - val_acc: 0.3687\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3153 - acc: 0.9706\n",
      "Epoch 00035: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3156 - acc: 0.9706 - val_loss: 7.7194 - val_acc: 0.3932\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3158 - acc: 0.9700\n",
      "Epoch 00036: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3167 - acc: 0.9699 - val_loss: 7.8172 - val_acc: 0.3988\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3530 - acc: 0.9654\n",
      "Epoch 00037: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3530 - acc: 0.9654 - val_loss: 8.0327 - val_acc: 0.3764\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3099 - acc: 0.9715\n",
      "Epoch 00038: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3099 - acc: 0.9715 - val_loss: 7.4327 - val_acc: 0.4181\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2995 - acc: 0.9729\n",
      "Epoch 00039: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2999 - acc: 0.9729 - val_loss: 8.2251 - val_acc: 0.3906\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2863 - acc: 0.9750\n",
      "Epoch 00040: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2862 - acc: 0.9750 - val_loss: 7.6696 - val_acc: 0.4156\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3093 - acc: 0.9722\n",
      "Epoch 00041: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3092 - acc: 0.9722 - val_loss: 7.6758 - val_acc: 0.4069\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2810 - acc: 0.9750\n",
      "Epoch 00042: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2813 - acc: 0.9749 - val_loss: 8.0063 - val_acc: 0.3925\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3040 - acc: 0.9710\n",
      "Epoch 00043: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3042 - acc: 0.9710 - val_loss: 8.1226 - val_acc: 0.3881\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3250 - acc: 0.9690\n",
      "Epoch 00044: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3259 - acc: 0.9689 - val_loss: 9.3289 - val_acc: 0.3387\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3085 - acc: 0.9722\n",
      "Epoch 00045: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3086 - acc: 0.9722 - val_loss: 7.4389 - val_acc: 0.4253\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3105 - acc: 0.9717\n",
      "Epoch 00046: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3105 - acc: 0.9717 - val_loss: 7.7212 - val_acc: 0.4167\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2866 - acc: 0.9742\n",
      "Epoch 00047: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2866 - acc: 0.9742 - val_loss: 8.2128 - val_acc: 0.3846\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2715 - acc: 0.9764\n",
      "Epoch 00048: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2717 - acc: 0.9764 - val_loss: 8.8749 - val_acc: 0.3634\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2860 - acc: 0.9753\n",
      "Epoch 00049: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2859 - acc: 0.9753 - val_loss: 8.5236 - val_acc: 0.3806\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2859 - acc: 0.9745\n",
      "Epoch 00050: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2868 - acc: 0.9745 - val_loss: 8.7244 - val_acc: 0.3746\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2831 - acc: 0.9752\n",
      "Epoch 00051: val_loss did not improve from 3.98134\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2837 - acc: 0.9751 - val_loss: 8.2852 - val_acc: 0.3874\n",
      "\n",
      "1D_CNN_custom_BN_2_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 722us/sample - loss: 4.1062 - acc: 0.2987\n",
      "Loss: 4.1062096585861 Accuracy: 0.29865006\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3246 - acc: 0.4257\n",
      "Epoch 00001: val_loss improved from inf to 2.18126, saving model to model/checkpoint/1D_CNN_custom_BN_2_3_conv_checkpoint/001-2.1813.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 2.3247 - acc: 0.4257 - val_loss: 2.1813 - val_acc: 0.3969\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0400 - acc: 0.7112\n",
      "Epoch 00002: val_loss improved from 2.18126 to 1.93862, saving model to model/checkpoint/1D_CNN_custom_BN_2_3_conv_checkpoint/002-1.9386.hdf5\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 1.0403 - acc: 0.7112 - val_loss: 1.9386 - val_acc: 0.5250\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5116 - acc: 0.8543\n",
      "Epoch 00003: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.5116 - acc: 0.8543 - val_loss: 2.0474 - val_acc: 0.5323\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2877 - acc: 0.9265\n",
      "Epoch 00004: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.2877 - acc: 0.9265 - val_loss: 2.2553 - val_acc: 0.4985\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2053 - acc: 0.9531\n",
      "Epoch 00005: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.2054 - acc: 0.9531 - val_loss: 2.2290 - val_acc: 0.5190\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9633\n",
      "Epoch 00006: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1605 - acc: 0.9633 - val_loss: 2.3262 - val_acc: 0.5243\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9737\n",
      "Epoch 00007: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1252 - acc: 0.9736 - val_loss: 2.6225 - val_acc: 0.4948\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9655\n",
      "Epoch 00008: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1468 - acc: 0.9655 - val_loss: 2.8572 - val_acc: 0.4885\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9771\n",
      "Epoch 00009: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1064 - acc: 0.9770 - val_loss: 2.8598 - val_acc: 0.4969\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9717\n",
      "Epoch 00010: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1194 - acc: 0.9717 - val_loss: 2.7692 - val_acc: 0.5220\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9792\n",
      "Epoch 00011: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0970 - acc: 0.9791 - val_loss: 3.0830 - val_acc: 0.4801\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9768\n",
      "Epoch 00012: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1005 - acc: 0.9767 - val_loss: 3.0246 - val_acc: 0.5050\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9780\n",
      "Epoch 00013: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0967 - acc: 0.9780 - val_loss: 3.1734 - val_acc: 0.5153\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9809\n",
      "Epoch 00014: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0855 - acc: 0.9808 - val_loss: 3.8826 - val_acc: 0.4659\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9748\n",
      "Epoch 00015: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1011 - acc: 0.9747 - val_loss: 3.2551 - val_acc: 0.5022\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9779\n",
      "Epoch 00016: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.1003 - acc: 0.9778 - val_loss: 3.2514 - val_acc: 0.5148\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9823\n",
      "Epoch 00017: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0786 - acc: 0.9823 - val_loss: 3.1278 - val_acc: 0.5325\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9840\n",
      "Epoch 00018: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0726 - acc: 0.9840 - val_loss: 3.4550 - val_acc: 0.5022\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9837\n",
      "Epoch 00019: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0760 - acc: 0.9836 - val_loss: 3.5142 - val_acc: 0.5115\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9843\n",
      "Epoch 00020: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0739 - acc: 0.9843 - val_loss: 3.6970 - val_acc: 0.5010\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9860\n",
      "Epoch 00021: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0667 - acc: 0.9860 - val_loss: 3.8302 - val_acc: 0.4831\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9835\n",
      "Epoch 00022: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0771 - acc: 0.9835 - val_loss: 4.0007 - val_acc: 0.4850\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9865\n",
      "Epoch 00023: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0654 - acc: 0.9865 - val_loss: 3.5897 - val_acc: 0.5064\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9802\n",
      "Epoch 00024: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0884 - acc: 0.9802 - val_loss: 3.8217 - val_acc: 0.5013\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9870\n",
      "Epoch 00025: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0612 - acc: 0.9870 - val_loss: 3.6052 - val_acc: 0.5257\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9894\n",
      "Epoch 00026: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0526 - acc: 0.9893 - val_loss: 3.6664 - val_acc: 0.5264\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9804\n",
      "Epoch 00027: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0904 - acc: 0.9804 - val_loss: 3.9296 - val_acc: 0.5122\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9847\n",
      "Epoch 00028: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0706 - acc: 0.9846 - val_loss: 3.9481 - val_acc: 0.5083\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9895\n",
      "Epoch 00029: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0522 - acc: 0.9894 - val_loss: 3.6724 - val_acc: 0.5379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9867\n",
      "Epoch 00030: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0646 - acc: 0.9867 - val_loss: 3.8466 - val_acc: 0.5225\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9893\n",
      "Epoch 00031: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0551 - acc: 0.9893 - val_loss: 4.3648 - val_acc: 0.4775\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0917 - acc: 0.9818\n",
      "Epoch 00032: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0918 - acc: 0.9818 - val_loss: 4.4986 - val_acc: 0.5006\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9885\n",
      "Epoch 00033: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0608 - acc: 0.9885 - val_loss: 3.7945 - val_acc: 0.5372\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9915\n",
      "Epoch 00034: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0468 - acc: 0.9914 - val_loss: 4.0968 - val_acc: 0.5113\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9863\n",
      "Epoch 00035: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0702 - acc: 0.9863 - val_loss: 4.2950 - val_acc: 0.5020\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9879\n",
      "Epoch 00036: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0609 - acc: 0.9879 - val_loss: 3.9797 - val_acc: 0.5297\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9903\n",
      "Epoch 00037: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0536 - acc: 0.9902 - val_loss: 4.1847 - val_acc: 0.5108\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0505 - acc: 0.9911\n",
      "Epoch 00038: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0511 - acc: 0.9910 - val_loss: 4.5212 - val_acc: 0.4950\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9850\n",
      "Epoch 00039: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0783 - acc: 0.9849 - val_loss: 4.2914 - val_acc: 0.5155\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9877\n",
      "Epoch 00040: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0661 - acc: 0.9877 - val_loss: 4.2292 - val_acc: 0.5208\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9933\n",
      "Epoch 00041: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0399 - acc: 0.9932 - val_loss: 4.4150 - val_acc: 0.5136\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9839\n",
      "Epoch 00042: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0754 - acc: 0.9838 - val_loss: 4.1004 - val_acc: 0.5290\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9927\n",
      "Epoch 00043: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0416 - acc: 0.9927 - val_loss: 4.1619 - val_acc: 0.5355\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9932\n",
      "Epoch 00044: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0419 - acc: 0.9932 - val_loss: 4.2033 - val_acc: 0.5274\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9893\n",
      "Epoch 00045: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0547 - acc: 0.9892 - val_loss: 4.2109 - val_acc: 0.5327\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9888\n",
      "Epoch 00046: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0555 - acc: 0.9888 - val_loss: 4.1697 - val_acc: 0.5372\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9904\n",
      "Epoch 00047: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0527 - acc: 0.9904 - val_loss: 4.3234 - val_acc: 0.5278\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9901\n",
      "Epoch 00048: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0548 - acc: 0.9901 - val_loss: 4.5415 - val_acc: 0.4997\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9914\n",
      "Epoch 00049: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0493 - acc: 0.9914 - val_loss: 4.3976 - val_acc: 0.5181\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9915\n",
      "Epoch 00050: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0466 - acc: 0.9915 - val_loss: 4.4969 - val_acc: 0.5141\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9948\n",
      "Epoch 00051: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0359 - acc: 0.9947 - val_loss: 4.1028 - val_acc: 0.5476\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9898\n",
      "Epoch 00052: val_loss did not improve from 1.93862\n",
      "36805/36805 [==============================] - 82s 2ms/sample - loss: 0.0564 - acc: 0.9897 - val_loss: 4.4631 - val_acc: 0.5236\n",
      "\n",
      "1D_CNN_custom_BN_2_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 811us/sample - loss: 2.0156 - acc: 0.4870\n",
      "Loss: 2.0155845355888515 Accuracy: 0.48701972\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8403 - acc: 0.4719\n",
      "Epoch 00001: val_loss improved from inf to 1.65539, saving model to model/checkpoint/1D_CNN_custom_BN_2_4_conv_checkpoint/001-1.6554.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.8403 - acc: 0.4719 - val_loss: 1.6554 - val_acc: 0.4726\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0896 - acc: 0.6790\n",
      "Epoch 00002: val_loss improved from 1.65539 to 1.27591, saving model to model/checkpoint/1D_CNN_custom_BN_2_4_conv_checkpoint/002-1.2759.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.0896 - acc: 0.6790 - val_loss: 1.2759 - val_acc: 0.6471\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7522 - acc: 0.7732\n",
      "Epoch 00003: val_loss improved from 1.27591 to 1.27330, saving model to model/checkpoint/1D_CNN_custom_BN_2_4_conv_checkpoint/003-1.2733.hdf5\n",
      "36805/36805 [==============================] - 86s 2ms/sample - loss: 0.7526 - acc: 0.7731 - val_loss: 1.2733 - val_acc: 0.6389\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5247 - acc: 0.8442\n",
      "Epoch 00004: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5247 - acc: 0.8442 - val_loss: 1.3545 - val_acc: 0.6334\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3538 - acc: 0.9030\n",
      "Epoch 00005: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3539 - acc: 0.9029 - val_loss: 1.3766 - val_acc: 0.6352\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2619 - acc: 0.9339\n",
      "Epoch 00006: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2621 - acc: 0.9339 - val_loss: 1.3235 - val_acc: 0.6597\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1939 - acc: 0.9564\n",
      "Epoch 00007: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1940 - acc: 0.9563 - val_loss: 1.3552 - val_acc: 0.6527\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9662\n",
      "Epoch 00008: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1588 - acc: 0.9661 - val_loss: 1.4249 - val_acc: 0.6618\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1233 - acc: 0.9771\n",
      "Epoch 00009: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1235 - acc: 0.9770 - val_loss: 1.8630 - val_acc: 0.5772\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9811\n",
      "Epoch 00010: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1050 - acc: 0.9811 - val_loss: 1.3420 - val_acc: 0.6774\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9864\n",
      "Epoch 00011: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0880 - acc: 0.9863 - val_loss: 1.5805 - val_acc: 0.6424\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9832\n",
      "Epoch 00012: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0878 - acc: 0.9832 - val_loss: 1.5223 - val_acc: 0.6520\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9896\n",
      "Epoch 00013: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0651 - acc: 0.9895 - val_loss: 1.5155 - val_acc: 0.6632\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9890\n",
      "Epoch 00014: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0662 - acc: 0.9890 - val_loss: 1.6275 - val_acc: 0.6452\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9885\n",
      "Epoch 00015: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0669 - acc: 0.9885 - val_loss: 2.0927 - val_acc: 0.5784\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9913\n",
      "Epoch 00016: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0542 - acc: 0.9912 - val_loss: 1.5499 - val_acc: 0.6716\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9887\n",
      "Epoch 00017: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0607 - acc: 0.9887 - val_loss: 1.5800 - val_acc: 0.6704\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9918\n",
      "Epoch 00018: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0465 - acc: 0.9918 - val_loss: 1.5998 - val_acc: 0.6655\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9939\n",
      "Epoch 00019: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0417 - acc: 0.9939 - val_loss: 1.6192 - val_acc: 0.6688\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9949\n",
      "Epoch 00020: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0366 - acc: 0.9949 - val_loss: 1.8167 - val_acc: 0.6457\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9911\n",
      "Epoch 00021: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0468 - acc: 0.9911 - val_loss: 1.7729 - val_acc: 0.6455\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9939\n",
      "Epoch 00022: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0404 - acc: 0.9939 - val_loss: 1.8467 - val_acc: 0.6520\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9947\n",
      "Epoch 00023: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0313 - acc: 0.9946 - val_loss: 1.8929 - val_acc: 0.6431\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9927\n",
      "Epoch 00024: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0421 - acc: 0.9926 - val_loss: 1.8620 - val_acc: 0.6392\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9921\n",
      "Epoch 00025: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0395 - acc: 0.9920 - val_loss: 1.6962 - val_acc: 0.6713\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9934\n",
      "Epoch 00026: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0360 - acc: 0.9933 - val_loss: 1.7167 - val_acc: 0.6776\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9933\n",
      "Epoch 00027: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0348 - acc: 0.9932 - val_loss: 1.8541 - val_acc: 0.6571\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9929\n",
      "Epoch 00028: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0373 - acc: 0.9928 - val_loss: 1.9807 - val_acc: 0.6375\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9950\n",
      "Epoch 00029: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0317 - acc: 0.9950 - val_loss: 1.9144 - val_acc: 0.6548\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9942\n",
      "Epoch 00030: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0331 - acc: 0.9942 - val_loss: 1.8625 - val_acc: 0.6606\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9965\n",
      "Epoch 00031: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0264 - acc: 0.9964 - val_loss: 1.9927 - val_acc: 0.6401\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9923\n",
      "Epoch 00032: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0400 - acc: 0.9923 - val_loss: 1.9441 - val_acc: 0.6504\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9948\n",
      "Epoch 00033: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0305 - acc: 0.9948 - val_loss: 2.3651 - val_acc: 0.6021\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0317 - acc: 0.9938\n",
      "Epoch 00034: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0321 - acc: 0.9938 - val_loss: 2.3514 - val_acc: 0.6115\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0366 - acc: 0.9924\n",
      "Epoch 00035: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0367 - acc: 0.9924 - val_loss: 1.8946 - val_acc: 0.6620\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9943\n",
      "Epoch 00036: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0292 - acc: 0.9942 - val_loss: 1.9586 - val_acc: 0.6532\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9935\n",
      "Epoch 00037: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0325 - acc: 0.9935 - val_loss: 2.0661 - val_acc: 0.6434\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9976\n",
      "Epoch 00038: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0192 - acc: 0.9976 - val_loss: 1.9808 - val_acc: 0.6676\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9962\n",
      "Epoch 00039: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0239 - acc: 0.9963 - val_loss: 1.9814 - val_acc: 0.6576\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9954\n",
      "Epoch 00040: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0279 - acc: 0.9953 - val_loss: 2.1186 - val_acc: 0.6403\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9955\n",
      "Epoch 00041: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0238 - acc: 0.9955 - val_loss: 2.0936 - val_acc: 0.6459\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9941\n",
      "Epoch 00042: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0299 - acc: 0.9941 - val_loss: 1.9836 - val_acc: 0.6653\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9966\n",
      "Epoch 00043: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0222 - acc: 0.9966 - val_loss: 2.2156 - val_acc: 0.6445\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9960\n",
      "Epoch 00044: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0239 - acc: 0.9960 - val_loss: 2.2426 - val_acc: 0.6483\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9960\n",
      "Epoch 00045: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0247 - acc: 0.9959 - val_loss: 2.1806 - val_acc: 0.6546\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9927\n",
      "Epoch 00046: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0331 - acc: 0.9926 - val_loss: 2.1694 - val_acc: 0.6553\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9944\n",
      "Epoch 00047: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0282 - acc: 0.9943 - val_loss: 2.1095 - val_acc: 0.6653\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9957\n",
      "Epoch 00048: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0245 - acc: 0.9957 - val_loss: 2.1379 - val_acc: 0.6592\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9954\n",
      "Epoch 00049: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0257 - acc: 0.9953 - val_loss: 2.3394 - val_acc: 0.6343\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9959\n",
      "Epoch 00050: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0233 - acc: 0.9958 - val_loss: 2.1719 - val_acc: 0.6527\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9943\n",
      "Epoch 00051: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0288 - acc: 0.9943 - val_loss: 2.2731 - val_acc: 0.6399\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9961\n",
      "Epoch 00052: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0213 - acc: 0.9961 - val_loss: 2.1199 - val_acc: 0.6611\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9981\n",
      "Epoch 00053: val_loss did not improve from 1.27330\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0148 - acc: 0.9980 - val_loss: 2.1666 - val_acc: 0.6629\n",
      "\n",
      "1D_CNN_custom_BN_2_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 873us/sample - loss: 1.3403 - acc: 0.6160\n",
      "Loss: 1.340295346404657 Accuracy: 0.6159917\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6920 - acc: 0.4971\n",
      "Epoch 00001: val_loss improved from inf to 1.39239, saving model to model/checkpoint/1D_CNN_custom_BN_2_5_conv_checkpoint/001-1.3924.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 1.6918 - acc: 0.4971 - val_loss: 1.3924 - val_acc: 0.5763\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0587 - acc: 0.6837\n",
      "Epoch 00002: val_loss improved from 1.39239 to 1.11347, saving model to model/checkpoint/1D_CNN_custom_BN_2_5_conv_checkpoint/002-1.1135.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 1.0588 - acc: 0.6837 - val_loss: 1.1135 - val_acc: 0.6716\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8155 - acc: 0.7568\n",
      "Epoch 00003: val_loss did not improve from 1.11347\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.8157 - acc: 0.7567 - val_loss: 1.1402 - val_acc: 0.6860\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6371 - acc: 0.8073\n",
      "Epoch 00004: val_loss improved from 1.11347 to 1.06874, saving model to model/checkpoint/1D_CNN_custom_BN_2_5_conv_checkpoint/004-1.0687.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6373 - acc: 0.8072 - val_loss: 1.0687 - val_acc: 0.6935\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4895 - acc: 0.8524\n",
      "Epoch 00005: val_loss did not improve from 1.06874\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.4895 - acc: 0.8524 - val_loss: 1.1160 - val_acc: 0.6937\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3761 - acc: 0.8901\n",
      "Epoch 00006: val_loss improved from 1.06874 to 1.00700, saving model to model/checkpoint/1D_CNN_custom_BN_2_5_conv_checkpoint/006-1.0070.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.3762 - acc: 0.8900 - val_loss: 1.0070 - val_acc: 0.7200\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2973 - acc: 0.9175\n",
      "Epoch 00007: val_loss did not improve from 1.00700\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2977 - acc: 0.9174 - val_loss: 1.0961 - val_acc: 0.7063\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2324 - acc: 0.9413\n",
      "Epoch 00008: val_loss improved from 1.00700 to 0.98199, saving model to model/checkpoint/1D_CNN_custom_BN_2_5_conv_checkpoint/008-0.9820.hdf5\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2325 - acc: 0.9413 - val_loss: 0.9820 - val_acc: 0.7389\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1815 - acc: 0.9565\n",
      "Epoch 00009: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1815 - acc: 0.9565 - val_loss: 1.0346 - val_acc: 0.7268\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9697\n",
      "Epoch 00010: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1431 - acc: 0.9696 - val_loss: 1.0703 - val_acc: 0.7249\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9672\n",
      "Epoch 00011: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1449 - acc: 0.9672 - val_loss: 1.0473 - val_acc: 0.7363\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9808\n",
      "Epoch 00012: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1029 - acc: 0.9807 - val_loss: 1.1423 - val_acc: 0.7237\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9810\n",
      "Epoch 00013: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0956 - acc: 0.9810 - val_loss: 1.1404 - val_acc: 0.7235\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9865\n",
      "Epoch 00014: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0817 - acc: 0.9864 - val_loss: 1.1928 - val_acc: 0.7193\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0901 - acc: 0.9817\n",
      "Epoch 00015: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0906 - acc: 0.9816 - val_loss: 1.1943 - val_acc: 0.7209\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9823\n",
      "Epoch 00016: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0837 - acc: 0.9823 - val_loss: 1.1975 - val_acc: 0.7247\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9904\n",
      "Epoch 00017: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0586 - acc: 0.9903 - val_loss: 1.1265 - val_acc: 0.7393\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9864\n",
      "Epoch 00018: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0713 - acc: 0.9863 - val_loss: 1.1754 - val_acc: 0.7263\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9901\n",
      "Epoch 00019: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0555 - acc: 0.9900 - val_loss: 1.1673 - val_acc: 0.7400\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9876\n",
      "Epoch 00020: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0609 - acc: 0.9876 - val_loss: 1.1887 - val_acc: 0.7317\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9895\n",
      "Epoch 00021: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0589 - acc: 0.9894 - val_loss: 1.2229 - val_acc: 0.7286\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9900\n",
      "Epoch 00022: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0529 - acc: 0.9900 - val_loss: 1.2742 - val_acc: 0.7268\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9965\n",
      "Epoch 00023: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0318 - acc: 0.9965 - val_loss: 1.2898 - val_acc: 0.7219\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9949\n",
      "Epoch 00024: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0332 - acc: 0.9949 - val_loss: 1.2468 - val_acc: 0.7452\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9909\n",
      "Epoch 00025: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0450 - acc: 0.9908 - val_loss: 1.3361 - val_acc: 0.7244\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9891\n",
      "Epoch 00026: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0506 - acc: 0.9891 - val_loss: 1.3793 - val_acc: 0.7258\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9955\n",
      "Epoch 00027: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0314 - acc: 0.9955 - val_loss: 1.4425 - val_acc: 0.7091\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9912\n",
      "Epoch 00028: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0445 - acc: 0.9913 - val_loss: 1.3762 - val_acc: 0.7135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9957\n",
      "Epoch 00029: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0281 - acc: 0.9956 - val_loss: 1.4959 - val_acc: 0.7021\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9930\n",
      "Epoch 00030: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0389 - acc: 0.9929 - val_loss: 1.6597 - val_acc: 0.6890\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9917\n",
      "Epoch 00031: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0403 - acc: 0.9917 - val_loss: 1.4139 - val_acc: 0.7226\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9937\n",
      "Epoch 00032: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0345 - acc: 0.9936 - val_loss: 1.4002 - val_acc: 0.7247\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9921\n",
      "Epoch 00033: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0401 - acc: 0.9921 - val_loss: 1.3665 - val_acc: 0.7303\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9880\n",
      "Epoch 00034: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0523 - acc: 0.9880 - val_loss: 1.3352 - val_acc: 0.7370\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9948\n",
      "Epoch 00035: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0298 - acc: 0.9948 - val_loss: 1.3362 - val_acc: 0.7365\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9953\n",
      "Epoch 00036: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0295 - acc: 0.9953 - val_loss: 1.3447 - val_acc: 0.7391\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9980\n",
      "Epoch 00037: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0177 - acc: 0.9980 - val_loss: 1.4034 - val_acc: 0.7300\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9974\n",
      "Epoch 00038: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0189 - acc: 0.9974 - val_loss: 1.4980 - val_acc: 0.7195\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9937\n",
      "Epoch 00039: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0309 - acc: 0.9936 - val_loss: 1.4588 - val_acc: 0.7265\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9945\n",
      "Epoch 00040: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0302 - acc: 0.9944 - val_loss: 1.6021 - val_acc: 0.6993\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9947\n",
      "Epoch 00041: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0279 - acc: 0.9947 - val_loss: 1.5131 - val_acc: 0.7272\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9953\n",
      "Epoch 00042: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0247 - acc: 0.9953 - val_loss: 1.5795 - val_acc: 0.7067\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9954\n",
      "Epoch 00043: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0270 - acc: 0.9954 - val_loss: 1.5350 - val_acc: 0.7149\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9947\n",
      "Epoch 00044: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0273 - acc: 0.9947 - val_loss: 1.4354 - val_acc: 0.7417\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9960\n",
      "Epoch 00045: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0232 - acc: 0.9960 - val_loss: 1.5448 - val_acc: 0.7179\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0295 - acc: 0.9941\n",
      "Epoch 00046: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0297 - acc: 0.9940 - val_loss: 1.6994 - val_acc: 0.7128\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9946\n",
      "Epoch 00047: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0274 - acc: 0.9946 - val_loss: 1.4396 - val_acc: 0.7403\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9967\n",
      "Epoch 00048: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0210 - acc: 0.9967 - val_loss: 1.4737 - val_acc: 0.7300\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9943\n",
      "Epoch 00049: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0285 - acc: 0.9943 - val_loss: 1.4656 - val_acc: 0.7410\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9964\n",
      "Epoch 00050: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0200 - acc: 0.9964 - val_loss: 1.5877 - val_acc: 0.7193\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9972\n",
      "Epoch 00051: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0181 - acc: 0.9972 - val_loss: 1.5680 - val_acc: 0.7275\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9936\n",
      "Epoch 00052: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0292 - acc: 0.9935 - val_loss: 1.4292 - val_acc: 0.7515\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9924\n",
      "Epoch 00053: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0336 - acc: 0.9924 - val_loss: 1.4626 - val_acc: 0.7398\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9954\n",
      "Epoch 00054: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0250 - acc: 0.9954 - val_loss: 1.5536 - val_acc: 0.7321\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9942\n",
      "Epoch 00055: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0276 - acc: 0.9942 - val_loss: 1.5049 - val_acc: 0.7375\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9980\n",
      "Epoch 00056: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0151 - acc: 0.9980 - val_loss: 1.5349 - val_acc: 0.7331\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9979\n",
      "Epoch 00057: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0148 - acc: 0.9979 - val_loss: 1.5061 - val_acc: 0.7414\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9933\n",
      "Epoch 00058: val_loss did not improve from 0.98199\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0290 - acc: 0.9933 - val_loss: 1.5589 - val_acc: 0.7324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_BN_2_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 907us/sample - loss: 1.0246 - acc: 0.7134\n",
      "Loss: 1.0246255337387353 Accuracy: 0.71339566\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7004 - acc: 0.4772\n",
      "Epoch 00001: val_loss improved from inf to 1.48658, saving model to model/checkpoint/1D_CNN_custom_BN_2_6_conv_checkpoint/001-1.4866.hdf5\n",
      "36805/36805 [==============================] - 99s 3ms/sample - loss: 1.7004 - acc: 0.4772 - val_loss: 1.4866 - val_acc: 0.5220\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0422 - acc: 0.6865\n",
      "Epoch 00002: val_loss improved from 1.48658 to 0.99574, saving model to model/checkpoint/1D_CNN_custom_BN_2_6_conv_checkpoint/002-0.9957.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.0423 - acc: 0.6865 - val_loss: 0.9957 - val_acc: 0.6995\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8401 - acc: 0.7530\n",
      "Epoch 00003: val_loss improved from 0.99574 to 0.82857, saving model to model/checkpoint/1D_CNN_custom_BN_2_6_conv_checkpoint/003-0.8286.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.8400 - acc: 0.7530 - val_loss: 0.8286 - val_acc: 0.7447\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7044 - acc: 0.7941\n",
      "Epoch 00004: val_loss did not improve from 0.82857\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7044 - acc: 0.7941 - val_loss: 0.8642 - val_acc: 0.7626\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6060 - acc: 0.8268\n",
      "Epoch 00005: val_loss improved from 0.82857 to 0.77978, saving model to model/checkpoint/1D_CNN_custom_BN_2_6_conv_checkpoint/005-0.7798.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.6061 - acc: 0.8268 - val_loss: 0.7798 - val_acc: 0.7761\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5291 - acc: 0.8483\n",
      "Epoch 00006: val_loss improved from 0.77978 to 0.68097, saving model to model/checkpoint/1D_CNN_custom_BN_2_6_conv_checkpoint/006-0.6810.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5290 - acc: 0.8484 - val_loss: 0.6810 - val_acc: 0.8097\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4671 - acc: 0.8635\n",
      "Epoch 00007: val_loss did not improve from 0.68097\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4673 - acc: 0.8634 - val_loss: 0.6816 - val_acc: 0.8211\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4145 - acc: 0.8808\n",
      "Epoch 00008: val_loss improved from 0.68097 to 0.64049, saving model to model/checkpoint/1D_CNN_custom_BN_2_6_conv_checkpoint/008-0.6405.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4145 - acc: 0.8809 - val_loss: 0.6405 - val_acc: 0.8132\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3506 - acc: 0.9015\n",
      "Epoch 00009: val_loss did not improve from 0.64049\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3507 - acc: 0.9015 - val_loss: 0.6412 - val_acc: 0.8171\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3141 - acc: 0.9117\n",
      "Epoch 00010: val_loss did not improve from 0.64049\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3143 - acc: 0.9116 - val_loss: 0.7246 - val_acc: 0.7999\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2903 - acc: 0.9193\n",
      "Epoch 00011: val_loss did not improve from 0.64049\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2904 - acc: 0.9193 - val_loss: 0.6753 - val_acc: 0.8223\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2486 - acc: 0.9302\n",
      "Epoch 00012: val_loss improved from 0.64049 to 0.55889, saving model to model/checkpoint/1D_CNN_custom_BN_2_6_conv_checkpoint/012-0.5589.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2488 - acc: 0.9302 - val_loss: 0.5589 - val_acc: 0.8463\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2205 - acc: 0.9396\n",
      "Epoch 00013: val_loss did not improve from 0.55889\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2205 - acc: 0.9396 - val_loss: 0.6224 - val_acc: 0.8290\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9484\n",
      "Epoch 00014: val_loss did not improve from 0.55889\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1910 - acc: 0.9484 - val_loss: 0.7350 - val_acc: 0.8053\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9563\n",
      "Epoch 00015: val_loss did not improve from 0.55889\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1710 - acc: 0.9563 - val_loss: 0.5757 - val_acc: 0.8456\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9611\n",
      "Epoch 00016: val_loss did not improve from 0.55889\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1517 - acc: 0.9611 - val_loss: 0.6862 - val_acc: 0.8169\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9646\n",
      "Epoch 00017: val_loss did not improve from 0.55889\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1375 - acc: 0.9646 - val_loss: 0.6017 - val_acc: 0.8400\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9730\n",
      "Epoch 00018: val_loss did not improve from 0.55889\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1154 - acc: 0.9730 - val_loss: 0.5694 - val_acc: 0.8481\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1285 - acc: 0.9680\n",
      "Epoch 00019: val_loss did not improve from 0.55889\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1286 - acc: 0.9679 - val_loss: 0.6016 - val_acc: 0.8400\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9753\n",
      "Epoch 00020: val_loss did not improve from 0.55889\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1044 - acc: 0.9753 - val_loss: 0.5947 - val_acc: 0.8477\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9823\n",
      "Epoch 00021: val_loss did not improve from 0.55889\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0866 - acc: 0.9823 - val_loss: 0.6719 - val_acc: 0.8237\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0953 - acc: 0.9776\n",
      "Epoch 00022: val_loss did not improve from 0.55889\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0955 - acc: 0.9776 - val_loss: 0.6314 - val_acc: 0.8428\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9779\n",
      "Epoch 00023: val_loss did not improve from 0.55889\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0920 - acc: 0.9779 - val_loss: 0.5836 - val_acc: 0.8479\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9893\n",
      "Epoch 00024: val_loss did not improve from 0.55889\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0606 - acc: 0.9892 - val_loss: 0.6074 - val_acc: 0.8449\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9808\n",
      "Epoch 00025: val_loss improved from 0.55889 to 0.54146, saving model to model/checkpoint/1D_CNN_custom_BN_2_6_conv_checkpoint/025-0.5415.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0840 - acc: 0.9808 - val_loss: 0.5415 - val_acc: 0.8656\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9910\n",
      "Epoch 00026: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0515 - acc: 0.9909 - val_loss: 0.7039 - val_acc: 0.8204\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9877\n",
      "Epoch 00027: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0607 - acc: 0.9877 - val_loss: 0.6366 - val_acc: 0.8526\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9901\n",
      "Epoch 00028: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0524 - acc: 0.9900 - val_loss: 0.7290 - val_acc: 0.8213\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9807\n",
      "Epoch 00029: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0854 - acc: 0.9807 - val_loss: 0.6420 - val_acc: 0.8400\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9931\n",
      "Epoch 00030: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0433 - acc: 0.9930 - val_loss: 0.6806 - val_acc: 0.8451\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9912\n",
      "Epoch 00031: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0463 - acc: 0.9911 - val_loss: 0.6383 - val_acc: 0.8488\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9891\n",
      "Epoch 00032: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0528 - acc: 0.9891 - val_loss: 0.7100 - val_acc: 0.8425\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9848\n",
      "Epoch 00033: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0637 - acc: 0.9848 - val_loss: 0.6724 - val_acc: 0.8395\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9923\n",
      "Epoch 00034: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0408 - acc: 0.9923 - val_loss: 0.7127 - val_acc: 0.8318\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9883\n",
      "Epoch 00035: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0535 - acc: 0.9883 - val_loss: 0.5892 - val_acc: 0.8558\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9907\n",
      "Epoch 00036: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0451 - acc: 0.9907 - val_loss: 0.6233 - val_acc: 0.8574\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9943\n",
      "Epoch 00037: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0337 - acc: 0.9942 - val_loss: 0.6678 - val_acc: 0.8477\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9908\n",
      "Epoch 00038: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0451 - acc: 0.9908 - val_loss: 0.6754 - val_acc: 0.8532\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9934\n",
      "Epoch 00039: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0356 - acc: 0.9934 - val_loss: 0.6664 - val_acc: 0.8532\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9919\n",
      "Epoch 00040: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0403 - acc: 0.9918 - val_loss: 0.6234 - val_acc: 0.8526\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9923\n",
      "Epoch 00041: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0379 - acc: 0.9922 - val_loss: 0.7351 - val_acc: 0.8477\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9923\n",
      "Epoch 00042: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0386 - acc: 0.9923 - val_loss: 0.6875 - val_acc: 0.8523\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9940\n",
      "Epoch 00043: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0337 - acc: 0.9940 - val_loss: 0.6814 - val_acc: 0.8491\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9912\n",
      "Epoch 00044: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0403 - acc: 0.9912 - val_loss: 0.6159 - val_acc: 0.8672\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9958\n",
      "Epoch 00045: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0266 - acc: 0.9958 - val_loss: 0.6826 - val_acc: 0.8463\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9958\n",
      "Epoch 00046: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0238 - acc: 0.9957 - val_loss: 0.7909 - val_acc: 0.8304\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9912\n",
      "Epoch 00047: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0384 - acc: 0.9912 - val_loss: 0.6704 - val_acc: 0.8470\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9932\n",
      "Epoch 00048: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0355 - acc: 0.9932 - val_loss: 0.7399 - val_acc: 0.8416\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9941\n",
      "Epoch 00049: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0304 - acc: 0.9941 - val_loss: 0.5857 - val_acc: 0.8742\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9974\n",
      "Epoch 00050: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0188 - acc: 0.9973 - val_loss: 0.7802 - val_acc: 0.8269\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9890\n",
      "Epoch 00051: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0462 - acc: 0.9889 - val_loss: 0.6627 - val_acc: 0.8516\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9951\n",
      "Epoch 00052: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0265 - acc: 0.9951 - val_loss: 0.7155 - val_acc: 0.8549\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9952\n",
      "Epoch 00053: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0274 - acc: 0.9951 - val_loss: 0.7989 - val_acc: 0.8344\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9902\n",
      "Epoch 00054: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0423 - acc: 0.9901 - val_loss: 0.6197 - val_acc: 0.8651\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9927\n",
      "Epoch 00055: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0334 - acc: 0.9926 - val_loss: 0.6810 - val_acc: 0.8546\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9943\n",
      "Epoch 00056: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0281 - acc: 0.9943 - val_loss: 0.6447 - val_acc: 0.8728\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9952\n",
      "Epoch 00057: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0262 - acc: 0.9952 - val_loss: 0.9562 - val_acc: 0.8034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9949\n",
      "Epoch 00058: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0264 - acc: 0.9949 - val_loss: 0.6593 - val_acc: 0.8523\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9972\n",
      "Epoch 00059: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0175 - acc: 0.9972 - val_loss: 0.7025 - val_acc: 0.8514\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9915\n",
      "Epoch 00060: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0374 - acc: 0.9915 - val_loss: 0.6543 - val_acc: 0.8654\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9985\n",
      "Epoch 00061: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0144 - acc: 0.9985 - val_loss: 0.7874 - val_acc: 0.8428\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9957\n",
      "Epoch 00062: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0252 - acc: 0.9957 - val_loss: 0.7528 - val_acc: 0.8411\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9926\n",
      "Epoch 00063: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0335 - acc: 0.9926 - val_loss: 0.6292 - val_acc: 0.8656\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9957\n",
      "Epoch 00064: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0228 - acc: 0.9957 - val_loss: 0.6569 - val_acc: 0.8661\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9932\n",
      "Epoch 00065: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0299 - acc: 0.9932 - val_loss: 0.6681 - val_acc: 0.8619\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9957\n",
      "Epoch 00066: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0231 - acc: 0.9957 - val_loss: 0.7237 - val_acc: 0.8542\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9984\n",
      "Epoch 00067: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0132 - acc: 0.9984 - val_loss: 0.7492 - val_acc: 0.8446\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9957\n",
      "Epoch 00068: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0225 - acc: 0.9957 - val_loss: 0.6939 - val_acc: 0.8535\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9958\n",
      "Epoch 00069: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0227 - acc: 0.9957 - val_loss: 0.7010 - val_acc: 0.8612\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9924\n",
      "Epoch 00070: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0333 - acc: 0.9923 - val_loss: 0.7141 - val_acc: 0.8551\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9941\n",
      "Epoch 00071: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0264 - acc: 0.9941 - val_loss: 0.6574 - val_acc: 0.8605\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9972\n",
      "Epoch 00072: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0181 - acc: 0.9971 - val_loss: 0.8744 - val_acc: 0.8300\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9924\n",
      "Epoch 00073: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0329 - acc: 0.9923 - val_loss: 0.6433 - val_acc: 0.8668\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9925\n",
      "Epoch 00074: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0314 - acc: 0.9925 - val_loss: 0.7096 - val_acc: 0.8505\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9973\n",
      "Epoch 00075: val_loss did not improve from 0.54146\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0166 - acc: 0.9973 - val_loss: 0.7363 - val_acc: 0.8616\n",
      "\n",
      "1D_CNN_custom_BN_2_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 953us/sample - loss: 0.6375 - acc: 0.8314\n",
      "Loss: 0.6375187798700105 Accuracy: 0.83136034\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7287 - acc: 0.4675\n",
      "Epoch 00001: val_loss improved from inf to 1.38389, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/001-1.3839.hdf5\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 1.7286 - acc: 0.4675 - val_loss: 1.3839 - val_acc: 0.5744\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9928 - acc: 0.7057\n",
      "Epoch 00002: val_loss improved from 1.38389 to 0.83451, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/002-0.8345.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.9927 - acc: 0.7057 - val_loss: 0.8345 - val_acc: 0.7533\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7345 - acc: 0.7910\n",
      "Epoch 00003: val_loss improved from 0.83451 to 0.73968, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/003-0.7397.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.7347 - acc: 0.7910 - val_loss: 0.7397 - val_acc: 0.7950\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5816 - acc: 0.8336\n",
      "Epoch 00004: val_loss improved from 0.73968 to 0.58425, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/004-0.5843.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.5816 - acc: 0.8336 - val_loss: 0.5843 - val_acc: 0.8281\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4835 - acc: 0.8631\n",
      "Epoch 00005: val_loss improved from 0.58425 to 0.48815, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/005-0.4881.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4836 - acc: 0.8630 - val_loss: 0.4881 - val_acc: 0.8642\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4149 - acc: 0.8824\n",
      "Epoch 00006: val_loss improved from 0.48815 to 0.44445, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/006-0.4444.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4151 - acc: 0.8824 - val_loss: 0.4444 - val_acc: 0.8696\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3634 - acc: 0.8976\n",
      "Epoch 00007: val_loss improved from 0.44445 to 0.40137, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/007-0.4014.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3637 - acc: 0.8976 - val_loss: 0.4014 - val_acc: 0.8863\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3224 - acc: 0.9091\n",
      "Epoch 00008: val_loss improved from 0.40137 to 0.36565, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/008-0.3656.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3224 - acc: 0.9091 - val_loss: 0.3656 - val_acc: 0.8926\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.9232\n",
      "Epoch 00009: val_loss did not improve from 0.36565\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2756 - acc: 0.9231 - val_loss: 0.4531 - val_acc: 0.8740\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2550 - acc: 0.9279\n",
      "Epoch 00010: val_loss improved from 0.36565 to 0.34944, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/010-0.3494.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2550 - acc: 0.9279 - val_loss: 0.3494 - val_acc: 0.8982\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2216 - acc: 0.9386\n",
      "Epoch 00011: val_loss did not improve from 0.34944\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2217 - acc: 0.9385 - val_loss: 0.3953 - val_acc: 0.8912\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2009 - acc: 0.9454\n",
      "Epoch 00012: val_loss improved from 0.34944 to 0.34560, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/012-0.3456.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2012 - acc: 0.9453 - val_loss: 0.3456 - val_acc: 0.9015\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1867 - acc: 0.9489\n",
      "Epoch 00013: val_loss did not improve from 0.34560\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1867 - acc: 0.9489 - val_loss: 0.3530 - val_acc: 0.9043\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1570 - acc: 0.9578\n",
      "Epoch 00014: val_loss improved from 0.34560 to 0.31998, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/014-0.3200.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1570 - acc: 0.9578 - val_loss: 0.3200 - val_acc: 0.9094\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1451 - acc: 0.9607\n",
      "Epoch 00015: val_loss did not improve from 0.31998\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1451 - acc: 0.9607 - val_loss: 0.3808 - val_acc: 0.8854\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9653\n",
      "Epoch 00016: val_loss improved from 0.31998 to 0.31154, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/016-0.3115.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1302 - acc: 0.9653 - val_loss: 0.3115 - val_acc: 0.9108\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9695\n",
      "Epoch 00017: val_loss did not improve from 0.31154\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1202 - acc: 0.9695 - val_loss: 0.3585 - val_acc: 0.8980\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9712\n",
      "Epoch 00018: val_loss did not improve from 0.31154\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1127 - acc: 0.9712 - val_loss: 0.3713 - val_acc: 0.8984\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9724\n",
      "Epoch 00019: val_loss did not improve from 0.31154\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1068 - acc: 0.9724 - val_loss: 0.3274 - val_acc: 0.9194\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9796\n",
      "Epoch 00020: val_loss did not improve from 0.31154\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0867 - acc: 0.9796 - val_loss: 0.3819 - val_acc: 0.8935\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9753\n",
      "Epoch 00021: val_loss improved from 0.31154 to 0.30642, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/021-0.3064.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0946 - acc: 0.9752 - val_loss: 0.3064 - val_acc: 0.9115\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9821\n",
      "Epoch 00022: val_loss did not improve from 0.30642\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0763 - acc: 0.9820 - val_loss: 0.3245 - val_acc: 0.9133\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9777\n",
      "Epoch 00023: val_loss improved from 0.30642 to 0.30329, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/023-0.3033.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0900 - acc: 0.9777 - val_loss: 0.3033 - val_acc: 0.9159\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9849\n",
      "Epoch 00024: val_loss did not improve from 0.30329\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0667 - acc: 0.9849 - val_loss: 0.3464 - val_acc: 0.9078\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9855\n",
      "Epoch 00025: val_loss improved from 0.30329 to 0.29746, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/025-0.2975.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0633 - acc: 0.9855 - val_loss: 0.2975 - val_acc: 0.9236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9914\n",
      "Epoch 00026: val_loss did not improve from 0.29746\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0480 - acc: 0.9914 - val_loss: 0.3680 - val_acc: 0.9087\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9787\n",
      "Epoch 00027: val_loss did not improve from 0.29746\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0843 - acc: 0.9787 - val_loss: 0.3330 - val_acc: 0.9131\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9911\n",
      "Epoch 00028: val_loss did not improve from 0.29746\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0446 - acc: 0.9911 - val_loss: 0.3100 - val_acc: 0.9217\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9920\n",
      "Epoch 00029: val_loss did not improve from 0.29746\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0435 - acc: 0.9919 - val_loss: 0.3517 - val_acc: 0.9129\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9892\n",
      "Epoch 00030: val_loss did not improve from 0.29746\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0500 - acc: 0.9892 - val_loss: 0.3004 - val_acc: 0.9224\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9942\n",
      "Epoch 00031: val_loss did not improve from 0.29746\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0357 - acc: 0.9942 - val_loss: 0.3753 - val_acc: 0.9064\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9898\n",
      "Epoch 00032: val_loss did not improve from 0.29746\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0464 - acc: 0.9898 - val_loss: 0.3401 - val_acc: 0.9131\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9921\n",
      "Epoch 00033: val_loss did not improve from 0.29746\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0388 - acc: 0.9921 - val_loss: 0.3453 - val_acc: 0.9157\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9960\n",
      "Epoch 00034: val_loss did not improve from 0.29746\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0275 - acc: 0.9960 - val_loss: 0.3758 - val_acc: 0.9122\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9943\n",
      "Epoch 00035: val_loss did not improve from 0.29746\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0316 - acc: 0.9943 - val_loss: 0.3544 - val_acc: 0.9150\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9824\n",
      "Epoch 00036: val_loss did not improve from 0.29746\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0662 - acc: 0.9823 - val_loss: 0.3156 - val_acc: 0.9208\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9937\n",
      "Epoch 00037: val_loss did not improve from 0.29746\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0325 - acc: 0.9937 - val_loss: 0.3165 - val_acc: 0.9194\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0349 - acc: 0.9924\n",
      "Epoch 00038: val_loss improved from 0.29746 to 0.28237, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/038-0.2824.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0349 - acc: 0.9924 - val_loss: 0.2824 - val_acc: 0.9266\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9974\n",
      "Epoch 00039: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0193 - acc: 0.9974 - val_loss: 0.2930 - val_acc: 0.9324\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9974\n",
      "Epoch 00040: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0201 - acc: 0.9974 - val_loss: 0.3132 - val_acc: 0.9245\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9951\n",
      "Epoch 00041: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0278 - acc: 0.9951 - val_loss: 0.3438 - val_acc: 0.9196\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9930\n",
      "Epoch 00042: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0305 - acc: 0.9930 - val_loss: 0.3279 - val_acc: 0.9238\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9950\n",
      "Epoch 00043: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0264 - acc: 0.9949 - val_loss: 0.4060 - val_acc: 0.9045\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9917\n",
      "Epoch 00044: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0346 - acc: 0.9917 - val_loss: 0.3005 - val_acc: 0.9290\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9951\n",
      "Epoch 00045: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0240 - acc: 0.9951 - val_loss: 0.3346 - val_acc: 0.9208\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9973\n",
      "Epoch 00046: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0172 - acc: 0.9973 - val_loss: 0.3766 - val_acc: 0.9092\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9877\n",
      "Epoch 00047: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0487 - acc: 0.9877 - val_loss: 0.3178 - val_acc: 0.9236\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9981\n",
      "Epoch 00048: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0151 - acc: 0.9981 - val_loss: 0.3500 - val_acc: 0.9259\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9976\n",
      "Epoch 00049: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0171 - acc: 0.9976 - val_loss: 0.3153 - val_acc: 0.9259\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9921\n",
      "Epoch 00050: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0322 - acc: 0.9921 - val_loss: 0.3212 - val_acc: 0.9250\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9986\n",
      "Epoch 00051: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0131 - acc: 0.9986 - val_loss: 0.2976 - val_acc: 0.9311\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9965\n",
      "Epoch 00052: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0199 - acc: 0.9964 - val_loss: 0.3150 - val_acc: 0.9273\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9920\n",
      "Epoch 00053: val_loss did not improve from 0.28237\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0335 - acc: 0.9920 - val_loss: 0.2936 - val_acc: 0.9343\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9952\n",
      "Epoch 00054: val_loss improved from 0.28237 to 0.27760, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/054-0.2776.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0226 - acc: 0.9952 - val_loss: 0.2776 - val_acc: 0.9331\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9939\n",
      "Epoch 00055: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0257 - acc: 0.9939 - val_loss: 0.3057 - val_acc: 0.9324\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9966\n",
      "Epoch 00056: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0167 - acc: 0.9966 - val_loss: 0.2890 - val_acc: 0.9341\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9961\n",
      "Epoch 00057: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0190 - acc: 0.9961 - val_loss: 0.3159 - val_acc: 0.9311\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9945\n",
      "Epoch 00058: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0246 - acc: 0.9945 - val_loss: 0.2865 - val_acc: 0.9350\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9960\n",
      "Epoch 00059: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0197 - acc: 0.9960 - val_loss: 0.2862 - val_acc: 0.9304\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9971\n",
      "Epoch 00060: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0159 - acc: 0.9971 - val_loss: 0.3211 - val_acc: 0.9262\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9961\n",
      "Epoch 00061: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0178 - acc: 0.9961 - val_loss: 0.2904 - val_acc: 0.9364\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9959\n",
      "Epoch 00062: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0200 - acc: 0.9959 - val_loss: 0.2936 - val_acc: 0.9315\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9943\n",
      "Epoch 00063: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0244 - acc: 0.9943 - val_loss: 0.3633 - val_acc: 0.9185\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9973\n",
      "Epoch 00064: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0150 - acc: 0.9973 - val_loss: 0.2802 - val_acc: 0.9327\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9982\n",
      "Epoch 00065: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0123 - acc: 0.9981 - val_loss: 0.3675 - val_acc: 0.9215\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9911\n",
      "Epoch 00066: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0359 - acc: 0.9911 - val_loss: 0.2944 - val_acc: 0.9329\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9983\n",
      "Epoch 00067: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0110 - acc: 0.9983 - val_loss: 0.2802 - val_acc: 0.9392\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9988\n",
      "Epoch 00068: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0100 - acc: 0.9988 - val_loss: 0.3302 - val_acc: 0.9276\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9973\n",
      "Epoch 00069: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0137 - acc: 0.9973 - val_loss: 0.3592 - val_acc: 0.9206\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9954\n",
      "Epoch 00070: val_loss did not improve from 0.27760\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0207 - acc: 0.9953 - val_loss: 0.3299 - val_acc: 0.9248\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9922\n",
      "Epoch 00071: val_loss improved from 0.27760 to 0.27442, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/071-0.2744.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0299 - acc: 0.9922 - val_loss: 0.2744 - val_acc: 0.9362\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9987\n",
      "Epoch 00072: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0088 - acc: 0.9987 - val_loss: 0.2913 - val_acc: 0.9369\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9993\n",
      "Epoch 00073: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0073 - acc: 0.9993 - val_loss: 0.3107 - val_acc: 0.9329\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9939\n",
      "Epoch 00074: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0243 - acc: 0.9939 - val_loss: 0.2952 - val_acc: 0.9285\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9957\n",
      "Epoch 00075: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0193 - acc: 0.9957 - val_loss: 0.3138 - val_acc: 0.9313\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9950\n",
      "Epoch 00076: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0206 - acc: 0.9950 - val_loss: 0.3023 - val_acc: 0.9311\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9980\n",
      "Epoch 00077: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0109 - acc: 0.9980 - val_loss: 0.3079 - val_acc: 0.9313\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9994\n",
      "Epoch 00078: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0069 - acc: 0.9994 - val_loss: 0.3142 - val_acc: 0.9278\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9933\n",
      "Epoch 00079: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0266 - acc: 0.9933 - val_loss: 0.3086 - val_acc: 0.9304\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9977\n",
      "Epoch 00080: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0128 - acc: 0.9977 - val_loss: 0.3017 - val_acc: 0.9329\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9970\n",
      "Epoch 00081: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0148 - acc: 0.9970 - val_loss: 0.3157 - val_acc: 0.9348\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9946\n",
      "Epoch 00082: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0223 - acc: 0.9946 - val_loss: 0.3007 - val_acc: 0.9317\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9946\n",
      "Epoch 00083: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0216 - acc: 0.9946 - val_loss: 0.3112 - val_acc: 0.9285\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9950\n",
      "Epoch 00084: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0214 - acc: 0.9950 - val_loss: 0.3137 - val_acc: 0.9306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9995\n",
      "Epoch 00085: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0066 - acc: 0.9994 - val_loss: 0.2978 - val_acc: 0.9327\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9939\n",
      "Epoch 00086: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0238 - acc: 0.9939 - val_loss: 0.3025 - val_acc: 0.9280\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9991\n",
      "Epoch 00087: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0076 - acc: 0.9991 - val_loss: 0.2772 - val_acc: 0.9380\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9995\n",
      "Epoch 00088: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0053 - acc: 0.9995 - val_loss: 0.3045 - val_acc: 0.9343\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9988\n",
      "Epoch 00089: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0080 - acc: 0.9988 - val_loss: 0.4083 - val_acc: 0.9150\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9958\n",
      "Epoch 00090: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0181 - acc: 0.9958 - val_loss: 0.3774 - val_acc: 0.9210\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9959\n",
      "Epoch 00091: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0167 - acc: 0.9959 - val_loss: 0.3276 - val_acc: 0.9278\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9967\n",
      "Epoch 00092: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0143 - acc: 0.9966 - val_loss: 0.3275 - val_acc: 0.9273\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9942\n",
      "Epoch 00093: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0205 - acc: 0.9941 - val_loss: 0.3764 - val_acc: 0.9196\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9926\n",
      "Epoch 00094: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0283 - acc: 0.9926 - val_loss: 0.2891 - val_acc: 0.9343\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9996\n",
      "Epoch 00095: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0057 - acc: 0.9996 - val_loss: 0.3048 - val_acc: 0.9341\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9955\n",
      "Epoch 00096: val_loss did not improve from 0.27442\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0182 - acc: 0.9955 - val_loss: 0.3104 - val_acc: 0.9311\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9961\n",
      "Epoch 00097: val_loss improved from 0.27442 to 0.26641, saving model to model/checkpoint/1D_CNN_custom_BN_2_7_conv_checkpoint/097-0.2664.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0166 - acc: 0.9961 - val_loss: 0.2664 - val_acc: 0.9378\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9994\n",
      "Epoch 00098: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0061 - acc: 0.9994 - val_loss: 0.2841 - val_acc: 0.9364\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9961\n",
      "Epoch 00099: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0164 - acc: 0.9961 - val_loss: 0.2823 - val_acc: 0.9366\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9983\n",
      "Epoch 00100: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0096 - acc: 0.9983 - val_loss: 0.3075 - val_acc: 0.9324\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9989\n",
      "Epoch 00101: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0069 - acc: 0.9989 - val_loss: 0.3374 - val_acc: 0.9278\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9991\n",
      "Epoch 00102: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0071 - acc: 0.9991 - val_loss: 0.3531 - val_acc: 0.9255\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9984\n",
      "Epoch 00103: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0088 - acc: 0.9984 - val_loss: 0.4880 - val_acc: 0.8940\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9922\n",
      "Epoch 00104: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0279 - acc: 0.9922 - val_loss: 0.3100 - val_acc: 0.9324\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9990\n",
      "Epoch 00105: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0073 - acc: 0.9990 - val_loss: 0.3086 - val_acc: 0.9350\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0051 - acc: 0.9992\n",
      "Epoch 00106: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0051 - acc: 0.9992 - val_loss: 0.3028 - val_acc: 0.9359\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9993\n",
      "Epoch 00107: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0057 - acc: 0.9993 - val_loss: 0.2905 - val_acc: 0.9345\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9948\n",
      "Epoch 00108: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0177 - acc: 0.9948 - val_loss: 0.4136 - val_acc: 0.9159\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9974\n",
      "Epoch 00109: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0112 - acc: 0.9974 - val_loss: 0.3732 - val_acc: 0.9182\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9959\n",
      "Epoch 00110: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0172 - acc: 0.9959 - val_loss: 0.3050 - val_acc: 0.9359\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9998\n",
      "Epoch 00111: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0042 - acc: 0.9998 - val_loss: 0.3031 - val_acc: 0.9369\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9991\n",
      "Epoch 00112: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0061 - acc: 0.9991 - val_loss: 0.3029 - val_acc: 0.9364\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9985\n",
      "Epoch 00113: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0072 - acc: 0.9985 - val_loss: 0.4970 - val_acc: 0.9052\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9956\n",
      "Epoch 00114: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0171 - acc: 0.9956 - val_loss: 0.3577 - val_acc: 0.9238\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9944\n",
      "Epoch 00115: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0204 - acc: 0.9944 - val_loss: 0.2949 - val_acc: 0.9376\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9996\n",
      "Epoch 00116: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0045 - acc: 0.9996 - val_loss: 0.3267 - val_acc: 0.9320\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9990\n",
      "Epoch 00117: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0063 - acc: 0.9989 - val_loss: 0.3199 - val_acc: 0.9320\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9961\n",
      "Epoch 00118: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0182 - acc: 0.9961 - val_loss: 0.2793 - val_acc: 0.9422\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9995\n",
      "Epoch 00119: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0047 - acc: 0.9994 - val_loss: 0.3010 - val_acc: 0.9378\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9960\n",
      "Epoch 00120: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0164 - acc: 0.9959 - val_loss: 0.3337 - val_acc: 0.9250\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9952\n",
      "Epoch 00121: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0181 - acc: 0.9952 - val_loss: 0.3046 - val_acc: 0.9348\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9984\n",
      "Epoch 00122: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0076 - acc: 0.9984 - val_loss: 0.3018 - val_acc: 0.9343\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9995\n",
      "Epoch 00123: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0047 - acc: 0.9994 - val_loss: 0.2994 - val_acc: 0.9399\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9951\n",
      "Epoch 00124: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0182 - acc: 0.9951 - val_loss: 0.3119 - val_acc: 0.9313\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9995\n",
      "Epoch 00125: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0049 - acc: 0.9995 - val_loss: 0.3187 - val_acc: 0.9380\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9967\n",
      "Epoch 00126: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0137 - acc: 0.9966 - val_loss: 0.3067 - val_acc: 0.9371\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9982\n",
      "Epoch 00127: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0080 - acc: 0.9982 - val_loss: 0.3023 - val_acc: 0.9387\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9991\n",
      "Epoch 00128: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0049 - acc: 0.9991 - val_loss: 0.3314 - val_acc: 0.9285\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9994\n",
      "Epoch 00129: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0060 - acc: 0.9994 - val_loss: 0.4076 - val_acc: 0.9194\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9980\n",
      "Epoch 00130: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0097 - acc: 0.9979 - val_loss: 0.3687 - val_acc: 0.9259\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9963\n",
      "Epoch 00131: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0143 - acc: 0.9963 - val_loss: 0.3542 - val_acc: 0.9301\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9991\n",
      "Epoch 00132: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0063 - acc: 0.9991 - val_loss: 0.3287 - val_acc: 0.9306\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9960\n",
      "Epoch 00133: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0147 - acc: 0.9960 - val_loss: 0.3282 - val_acc: 0.9283\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9974\n",
      "Epoch 00134: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0113 - acc: 0.9974 - val_loss: 0.3162 - val_acc: 0.9376\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9989\n",
      "Epoch 00135: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0060 - acc: 0.9989 - val_loss: 0.3255 - val_acc: 0.9352\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9970\n",
      "Epoch 00136: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0115 - acc: 0.9970 - val_loss: 0.3064 - val_acc: 0.9394\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9994\n",
      "Epoch 00137: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0045 - acc: 0.9994 - val_loss: 0.2956 - val_acc: 0.9385\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9986\n",
      "Epoch 00138: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0076 - acc: 0.9986 - val_loss: 0.3429 - val_acc: 0.9348\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9991\n",
      "Epoch 00139: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0060 - acc: 0.9991 - val_loss: 0.3260 - val_acc: 0.9362\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9962\n",
      "Epoch 00140: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0145 - acc: 0.9962 - val_loss: 0.3635 - val_acc: 0.9257\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9971\n",
      "Epoch 00141: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0131 - acc: 0.9971 - val_loss: 0.3328 - val_acc: 0.9313\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9968\n",
      "Epoch 00142: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0127 - acc: 0.9968 - val_loss: 0.3443 - val_acc: 0.9287\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9963\n",
      "Epoch 00143: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0139 - acc: 0.9963 - val_loss: 0.3007 - val_acc: 0.9378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9995\n",
      "Epoch 00144: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0042 - acc: 0.9995 - val_loss: 0.3179 - val_acc: 0.9364\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9996\n",
      "Epoch 00145: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0044 - acc: 0.9996 - val_loss: 0.3143 - val_acc: 0.9378\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9995\n",
      "Epoch 00146: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0040 - acc: 0.9995 - val_loss: 0.3287 - val_acc: 0.9315\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9989\n",
      "Epoch 00147: val_loss did not improve from 0.26641\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0058 - acc: 0.9989 - val_loss: 0.4012 - val_acc: 0.9187\n",
      "\n",
      "1D_CNN_custom_BN_2_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.3183 - acc: 0.9192\n",
      "Loss: 0.3183324581172669 Accuracy: 0.9192108\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5725 - acc: 0.5220\n",
      "Epoch 00001: val_loss improved from inf to 1.21897, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/001-1.2190.hdf5\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 1.5726 - acc: 0.5220 - val_loss: 1.2190 - val_acc: 0.6217\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7177 - acc: 0.7943\n",
      "Epoch 00002: val_loss improved from 1.21897 to 0.56147, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/002-0.5615.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.7177 - acc: 0.7943 - val_loss: 0.5615 - val_acc: 0.8411\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4860 - acc: 0.8639\n",
      "Epoch 00003: val_loss improved from 0.56147 to 0.41822, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/003-0.4182.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.4861 - acc: 0.8638 - val_loss: 0.4182 - val_acc: 0.8805\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3742 - acc: 0.8938\n",
      "Epoch 00004: val_loss improved from 0.41822 to 0.32913, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/004-0.3291.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.3742 - acc: 0.8937 - val_loss: 0.3291 - val_acc: 0.9059\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3044 - acc: 0.9144\n",
      "Epoch 00005: val_loss improved from 0.32913 to 0.28104, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/005-0.2810.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.3044 - acc: 0.9144 - val_loss: 0.2810 - val_acc: 0.9227\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2587 - acc: 0.9285\n",
      "Epoch 00006: val_loss did not improve from 0.28104\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2588 - acc: 0.9284 - val_loss: 0.2913 - val_acc: 0.9178\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9374\n",
      "Epoch 00007: val_loss improved from 0.28104 to 0.26693, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/007-0.2669.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.2194 - acc: 0.9374 - val_loss: 0.2669 - val_acc: 0.9206\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1888 - acc: 0.9466\n",
      "Epoch 00008: val_loss improved from 0.26693 to 0.25983, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/008-0.2598.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1889 - acc: 0.9465 - val_loss: 0.2598 - val_acc: 0.9241\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1736 - acc: 0.9505\n",
      "Epoch 00009: val_loss improved from 0.25983 to 0.21492, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/009-0.2149.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1736 - acc: 0.9506 - val_loss: 0.2149 - val_acc: 0.9378\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9576\n",
      "Epoch 00010: val_loss improved from 0.21492 to 0.19522, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/010-0.1952.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1500 - acc: 0.9575 - val_loss: 0.1952 - val_acc: 0.9462\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9622\n",
      "Epoch 00011: val_loss did not improve from 0.19522\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.1354 - acc: 0.9622 - val_loss: 0.2205 - val_acc: 0.9341\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1214 - acc: 0.9668\n",
      "Epoch 00012: val_loss improved from 0.19522 to 0.19159, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/012-0.1916.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1214 - acc: 0.9668 - val_loss: 0.1916 - val_acc: 0.9429\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9719\n",
      "Epoch 00013: val_loss improved from 0.19159 to 0.18558, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/013-0.1856.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1049 - acc: 0.9719 - val_loss: 0.1856 - val_acc: 0.9457\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0954 - acc: 0.9747\n",
      "Epoch 00014: val_loss improved from 0.18558 to 0.17671, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/014-0.1767.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0954 - acc: 0.9747 - val_loss: 0.1767 - val_acc: 0.9492\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9795\n",
      "Epoch 00015: val_loss did not improve from 0.17671\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0783 - acc: 0.9795 - val_loss: 0.1956 - val_acc: 0.9401\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9822\n",
      "Epoch 00016: val_loss did not improve from 0.17671\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0714 - acc: 0.9822 - val_loss: 0.2252 - val_acc: 0.9352\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9823\n",
      "Epoch 00017: val_loss did not improve from 0.17671\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0712 - acc: 0.9823 - val_loss: 0.1907 - val_acc: 0.9404\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9851\n",
      "Epoch 00018: val_loss did not improve from 0.17671\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0605 - acc: 0.9851 - val_loss: 0.1917 - val_acc: 0.9408\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9890\n",
      "Epoch 00019: val_loss did not improve from 0.17671\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0498 - acc: 0.9889 - val_loss: 0.2281 - val_acc: 0.9315\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9882\n",
      "Epoch 00020: val_loss improved from 0.17671 to 0.17282, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/020-0.1728.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0509 - acc: 0.9882 - val_loss: 0.1728 - val_acc: 0.9485\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9909\n",
      "Epoch 00021: val_loss did not improve from 0.17282\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0419 - acc: 0.9909 - val_loss: 0.1800 - val_acc: 0.9471\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9927\n",
      "Epoch 00022: val_loss did not improve from 0.17282\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0343 - acc: 0.9927 - val_loss: 0.1795 - val_acc: 0.9471\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9920\n",
      "Epoch 00023: val_loss did not improve from 0.17282\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0370 - acc: 0.9920 - val_loss: 0.1939 - val_acc: 0.9446\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9940\n",
      "Epoch 00024: val_loss did not improve from 0.17282\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0301 - acc: 0.9940 - val_loss: 0.2224 - val_acc: 0.9348\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9924\n",
      "Epoch 00025: val_loss did not improve from 0.17282\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0343 - acc: 0.9923 - val_loss: 0.2243 - val_acc: 0.9359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9924\n",
      "Epoch 00026: val_loss did not improve from 0.17282\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0338 - acc: 0.9924 - val_loss: 0.1851 - val_acc: 0.9495\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9948\n",
      "Epoch 00027: val_loss did not improve from 0.17282\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0256 - acc: 0.9948 - val_loss: 0.1991 - val_acc: 0.9474\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9969\n",
      "Epoch 00028: val_loss did not improve from 0.17282\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0193 - acc: 0.9969 - val_loss: 0.1996 - val_acc: 0.9439\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9960\n",
      "Epoch 00029: val_loss did not improve from 0.17282\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0229 - acc: 0.9960 - val_loss: 0.1808 - val_acc: 0.9527\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9968\n",
      "Epoch 00030: val_loss did not improve from 0.17282\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0178 - acc: 0.9968 - val_loss: 0.2343 - val_acc: 0.9357\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9968\n",
      "Epoch 00031: val_loss did not improve from 0.17282\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0183 - acc: 0.9968 - val_loss: 0.2615 - val_acc: 0.9287\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9887\n",
      "Epoch 00032: val_loss improved from 0.17282 to 0.17120, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/032-0.1712.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0406 - acc: 0.9888 - val_loss: 0.1712 - val_acc: 0.9511\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9960\n",
      "Epoch 00033: val_loss did not improve from 0.17120\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0198 - acc: 0.9960 - val_loss: 0.1835 - val_acc: 0.9492\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9921\n",
      "Epoch 00034: val_loss improved from 0.17120 to 0.16813, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/034-0.1681.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0301 - acc: 0.9920 - val_loss: 0.1681 - val_acc: 0.9504\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9940\n",
      "Epoch 00035: val_loss did not improve from 0.16813\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0254 - acc: 0.9940 - val_loss: 0.1865 - val_acc: 0.9511\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9992\n",
      "Epoch 00036: val_loss improved from 0.16813 to 0.15778, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/036-0.1578.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0078 - acc: 0.9992 - val_loss: 0.1578 - val_acc: 0.9571\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9982\n",
      "Epoch 00037: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0123 - acc: 0.9982 - val_loss: 0.1720 - val_acc: 0.9518\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9935\n",
      "Epoch 00038: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0257 - acc: 0.9935 - val_loss: 0.1948 - val_acc: 0.9502\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9965\n",
      "Epoch 00039: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0171 - acc: 0.9965 - val_loss: 0.1709 - val_acc: 0.9553\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9983\n",
      "Epoch 00040: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0109 - acc: 0.9983 - val_loss: 0.2013 - val_acc: 0.9481\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9989\n",
      "Epoch 00041: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0079 - acc: 0.9989 - val_loss: 0.2606 - val_acc: 0.9331\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9953\n",
      "Epoch 00042: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0191 - acc: 0.9953 - val_loss: 0.2534 - val_acc: 0.9345\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9986\n",
      "Epoch 00043: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0096 - acc: 0.9986 - val_loss: 0.1773 - val_acc: 0.9557\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9947\n",
      "Epoch 00044: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0205 - acc: 0.9946 - val_loss: 0.2671 - val_acc: 0.9334\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9939\n",
      "Epoch 00045: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0222 - acc: 0.9939 - val_loss: 0.1747 - val_acc: 0.9515\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9991\n",
      "Epoch 00046: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0068 - acc: 0.9991 - val_loss: 0.1873 - val_acc: 0.9497\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9938\n",
      "Epoch 00047: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0224 - acc: 0.9937 - val_loss: 0.1674 - val_acc: 0.9576\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9950\n",
      "Epoch 00048: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0194 - acc: 0.9950 - val_loss: 0.1608 - val_acc: 0.9555\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9986\n",
      "Epoch 00049: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0076 - acc: 0.9986 - val_loss: 0.1901 - val_acc: 0.9513\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9953\n",
      "Epoch 00050: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0186 - acc: 0.9953 - val_loss: 0.1698 - val_acc: 0.9557\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9981\n",
      "Epoch 00051: val_loss did not improve from 0.15778\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0093 - acc: 0.9980 - val_loss: 0.1905 - val_acc: 0.9502\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9930\n",
      "Epoch 00052: val_loss improved from 0.15778 to 0.15448, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/052-0.1545.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0256 - acc: 0.9930 - val_loss: 0.1545 - val_acc: 0.9597\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9991\n",
      "Epoch 00053: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0058 - acc: 0.9991 - val_loss: 0.1868 - val_acc: 0.9527\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9984\n",
      "Epoch 00054: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0085 - acc: 0.9984 - val_loss: 0.1577 - val_acc: 0.9578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9995\n",
      "Epoch 00055: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0045 - acc: 0.9995 - val_loss: 0.2188 - val_acc: 0.9469\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9917\n",
      "Epoch 00056: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0304 - acc: 0.9917 - val_loss: 0.1845 - val_acc: 0.9520\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9946\n",
      "Epoch 00057: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0200 - acc: 0.9945 - val_loss: 0.1706 - val_acc: 0.9548\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9946\n",
      "Epoch 00058: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0191 - acc: 0.9946 - val_loss: 0.1610 - val_acc: 0.9588\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9997\n",
      "Epoch 00059: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0044 - acc: 0.9996 - val_loss: 0.1863 - val_acc: 0.9522\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9951\n",
      "Epoch 00060: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0198 - acc: 0.9951 - val_loss: 0.1986 - val_acc: 0.9548\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9967\n",
      "Epoch 00061: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0138 - acc: 0.9967 - val_loss: 0.1727 - val_acc: 0.9562\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9994\n",
      "Epoch 00062: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0043 - acc: 0.9994 - val_loss: 0.1668 - val_acc: 0.9590\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9997\n",
      "Epoch 00063: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0035 - acc: 0.9996 - val_loss: 0.1759 - val_acc: 0.9548\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9931\n",
      "Epoch 00064: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0233 - acc: 0.9931 - val_loss: 0.1814 - val_acc: 0.9543\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9995\n",
      "Epoch 00065: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0048 - acc: 0.9995 - val_loss: 0.1600 - val_acc: 0.9599\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9991\n",
      "Epoch 00066: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0054 - acc: 0.9991 - val_loss: 0.1655 - val_acc: 0.9588\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9977\n",
      "Epoch 00067: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0102 - acc: 0.9977 - val_loss: 0.1708 - val_acc: 0.9571\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9991\n",
      "Epoch 00068: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0057 - acc: 0.9991 - val_loss: 0.1581 - val_acc: 0.9585\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9986\n",
      "Epoch 00069: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0075 - acc: 0.9986 - val_loss: 0.1990 - val_acc: 0.9497\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9949\n",
      "Epoch 00070: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0167 - acc: 0.9949 - val_loss: 0.1614 - val_acc: 0.9592\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9979\n",
      "Epoch 00071: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0098 - acc: 0.9978 - val_loss: 0.2093 - val_acc: 0.9446\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9938\n",
      "Epoch 00072: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0232 - acc: 0.9938 - val_loss: 0.1627 - val_acc: 0.9576\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9996\n",
      "Epoch 00073: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0037 - acc: 0.9996 - val_loss: 0.1624 - val_acc: 0.9606\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9960\n",
      "Epoch 00074: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0150 - acc: 0.9960 - val_loss: 0.1576 - val_acc: 0.9588\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9996\n",
      "Epoch 00075: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0036 - acc: 0.9996 - val_loss: 0.1576 - val_acc: 0.9627\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9992\n",
      "Epoch 00076: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0040 - acc: 0.9992 - val_loss: 0.2023 - val_acc: 0.9525\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9961\n",
      "Epoch 00077: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0148 - acc: 0.9961 - val_loss: 0.1593 - val_acc: 0.9616\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 00078: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0027 - acc: 0.9998 - val_loss: 0.1848 - val_acc: 0.9567\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9955\n",
      "Epoch 00079: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0163 - acc: 0.9955 - val_loss: 0.1688 - val_acc: 0.9548\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9998\n",
      "Epoch 00080: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0026 - acc: 0.9998 - val_loss: 0.1549 - val_acc: 0.9641\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 00081: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0024 - acc: 0.9998 - val_loss: 0.1621 - val_acc: 0.9618\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9974\n",
      "Epoch 00082: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0097 - acc: 0.9974 - val_loss: 0.2362 - val_acc: 0.9425\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9979\n",
      "Epoch 00083: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0084 - acc: 0.9979 - val_loss: 0.1659 - val_acc: 0.9585\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9996\n",
      "Epoch 00084: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0036 - acc: 0.9996 - val_loss: 0.1813 - val_acc: 0.9560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9951\n",
      "Epoch 00085: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0165 - acc: 0.9951 - val_loss: 0.1600 - val_acc: 0.9585\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0043 - acc: 0.9992\n",
      "Epoch 00086: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0043 - acc: 0.9992 - val_loss: 0.1980 - val_acc: 0.9539\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 00087: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0037 - acc: 0.9995 - val_loss: 0.1556 - val_acc: 0.9630\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9996\n",
      "Epoch 00088: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0027 - acc: 0.9996 - val_loss: 0.1760 - val_acc: 0.9562\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9963\n",
      "Epoch 00089: val_loss did not improve from 0.15448\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0129 - acc: 0.9963 - val_loss: 0.2460 - val_acc: 0.9408\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9953\n",
      "Epoch 00090: val_loss improved from 0.15448 to 0.15407, saving model to model/checkpoint/1D_CNN_custom_BN_2_8_conv_checkpoint/090-0.1541.hdf5\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0164 - acc: 0.9953 - val_loss: 0.1541 - val_acc: 0.9630\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0019 - acc: 0.9998\n",
      "Epoch 00091: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0019 - acc: 0.9998 - val_loss: 0.1655 - val_acc: 0.9592\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9984\n",
      "Epoch 00092: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0070 - acc: 0.9984 - val_loss: 0.1881 - val_acc: 0.9550\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9995\n",
      "Epoch 00093: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0033 - acc: 0.9995 - val_loss: 0.1694 - val_acc: 0.9606\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9988\n",
      "Epoch 00094: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0058 - acc: 0.9988 - val_loss: 0.1867 - val_acc: 0.9564\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9962\n",
      "Epoch 00095: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0144 - acc: 0.9962 - val_loss: 0.1682 - val_acc: 0.9597\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9984\n",
      "Epoch 00096: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0067 - acc: 0.9983 - val_loss: 0.1922 - val_acc: 0.9576\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9984\n",
      "Epoch 00097: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0083 - acc: 0.9984 - val_loss: 0.1650 - val_acc: 0.9602\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9996\n",
      "Epoch 00098: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0023 - acc: 0.9996 - val_loss: 0.1618 - val_acc: 0.9581\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 00099: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0022 - acc: 0.9998 - val_loss: 0.1686 - val_acc: 0.9597\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9956\n",
      "Epoch 00100: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0145 - acc: 0.9956 - val_loss: 0.1670 - val_acc: 0.9581\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9994\n",
      "Epoch 00101: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0038 - acc: 0.9993 - val_loss: 0.1684 - val_acc: 0.9613\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9963\n",
      "Epoch 00102: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0133 - acc: 0.9963 - val_loss: 0.1720 - val_acc: 0.9613\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9998\n",
      "Epoch 00103: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0020 - acc: 0.9998 - val_loss: 0.1620 - val_acc: 0.9632\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9997\n",
      "Epoch 00104: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0024 - acc: 0.9997 - val_loss: 0.1667 - val_acc: 0.9641\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 00105: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0037 - acc: 0.9991 - val_loss: 0.2516 - val_acc: 0.9406\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9953\n",
      "Epoch 00106: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0174 - acc: 0.9952 - val_loss: 0.1888 - val_acc: 0.9555\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9980\n",
      "Epoch 00107: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0078 - acc: 0.9980 - val_loss: 0.1736 - val_acc: 0.9604\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9997\n",
      "Epoch 00108: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1687 - val_acc: 0.9592\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9975\n",
      "Epoch 00109: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0100 - acc: 0.9975 - val_loss: 0.1768 - val_acc: 0.9611\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9997\n",
      "Epoch 00110: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0021 - acc: 0.9997 - val_loss: 0.1688 - val_acc: 0.9604\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9997\n",
      "Epoch 00111: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0020 - acc: 0.9997 - val_loss: 0.1881 - val_acc: 0.9590\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9983\n",
      "Epoch 00112: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0069 - acc: 0.9983 - val_loss: 0.1744 - val_acc: 0.9618\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9995\n",
      "Epoch 00113: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0027 - acc: 0.9995 - val_loss: 0.1938 - val_acc: 0.9557\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9975\n",
      "Epoch 00114: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0084 - acc: 0.9975 - val_loss: 0.2436 - val_acc: 0.9490\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9968\n",
      "Epoch 00115: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0118 - acc: 0.9968 - val_loss: 0.1784 - val_acc: 0.9543\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9995\n",
      "Epoch 00116: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0029 - acc: 0.9995 - val_loss: 0.1591 - val_acc: 0.9616\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9987\n",
      "Epoch 00117: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0056 - acc: 0.9986 - val_loss: 0.1815 - val_acc: 0.9567\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9952\n",
      "Epoch 00118: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0156 - acc: 0.9952 - val_loss: 0.1664 - val_acc: 0.9620\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9997\n",
      "Epoch 00119: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0025 - acc: 0.9997 - val_loss: 0.1639 - val_acc: 0.9604\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0014 - acc: 0.9999\n",
      "Epoch 00120: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0014 - acc: 0.9999 - val_loss: 0.1593 - val_acc: 0.9616\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9997\n",
      "Epoch 00121: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0020 - acc: 0.9997 - val_loss: 0.1813 - val_acc: 0.9604\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9992\n",
      "Epoch 00122: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0031 - acc: 0.9992 - val_loss: 0.2376 - val_acc: 0.9513\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9987\n",
      "Epoch 00123: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0054 - acc: 0.9987 - val_loss: 0.1727 - val_acc: 0.9632\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9997\n",
      "Epoch 00124: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0022 - acc: 0.9996 - val_loss: 0.2362 - val_acc: 0.9462\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9961\n",
      "Epoch 00125: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0142 - acc: 0.9961 - val_loss: 0.1874 - val_acc: 0.9602\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9992\n",
      "Epoch 00126: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0039 - acc: 0.9992 - val_loss: 0.1739 - val_acc: 0.9618\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9994\n",
      "Epoch 00127: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0036 - acc: 0.9994 - val_loss: 0.1731 - val_acc: 0.9604\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9990\n",
      "Epoch 00128: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0038 - acc: 0.9990 - val_loss: 0.1868 - val_acc: 0.9588\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9977\n",
      "Epoch 00129: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0085 - acc: 0.9977 - val_loss: 0.1897 - val_acc: 0.9618\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9982\n",
      "Epoch 00130: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0080 - acc: 0.9982 - val_loss: 0.1743 - val_acc: 0.9576\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9995\n",
      "Epoch 00131: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0024 - acc: 0.9995 - val_loss: 0.1782 - val_acc: 0.9620\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 00132: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0019 - acc: 0.9997 - val_loss: 0.2119 - val_acc: 0.9550\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9958\n",
      "Epoch 00133: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0140 - acc: 0.9957 - val_loss: 0.2019 - val_acc: 0.9546\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9974\n",
      "Epoch 00134: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0085 - acc: 0.9974 - val_loss: 0.1634 - val_acc: 0.9634\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0015 - acc: 0.9998\n",
      "Epoch 00135: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0015 - acc: 0.9998 - val_loss: 0.1569 - val_acc: 0.9644\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 00136: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 0.0018 - acc: 0.9997 - val_loss: 0.1950 - val_acc: 0.9567\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9966\n",
      "Epoch 00137: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0128 - acc: 0.9966 - val_loss: 0.1772 - val_acc: 0.9597\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0021 - acc: 0.9997\n",
      "Epoch 00138: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0022 - acc: 0.9996 - val_loss: 0.1779 - val_acc: 0.9625\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9979\n",
      "Epoch 00139: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 0.0076 - acc: 0.9979 - val_loss: 0.1705 - val_acc: 0.9602\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0013 - acc: 0.9999\n",
      "Epoch 00140: val_loss did not improve from 0.15407\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0013 - acc: 0.9999 - val_loss: 0.1637 - val_acc: 0.9620\n",
      "\n",
      "1D_CNN_custom_BN_2_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2246 - acc: 0.9458\n",
      "Loss: 0.2246089458840813 Accuracy: 0.9457944\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1173 - acc: 0.6551\n",
      "Epoch 00001: val_loss improved from inf to 0.77742, saving model to model/checkpoint/1D_CNN_custom_BN_2_9_conv_checkpoint/001-0.7774.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 1.1173 - acc: 0.6551 - val_loss: 0.7774 - val_acc: 0.7785\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4391 - acc: 0.8668\n",
      "Epoch 00002: val_loss improved from 0.77742 to 0.32458, saving model to model/checkpoint/1D_CNN_custom_BN_2_9_conv_checkpoint/002-0.3246.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.4391 - acc: 0.8668 - val_loss: 0.3246 - val_acc: 0.9017\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2931 - acc: 0.9132\n",
      "Epoch 00003: val_loss improved from 0.32458 to 0.25507, saving model to model/checkpoint/1D_CNN_custom_BN_2_9_conv_checkpoint/003-0.2551.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2931 - acc: 0.9132 - val_loss: 0.2551 - val_acc: 0.9224\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2266 - acc: 0.9329\n",
      "Epoch 00004: val_loss improved from 0.25507 to 0.24044, saving model to model/checkpoint/1D_CNN_custom_BN_2_9_conv_checkpoint/004-0.2404.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2266 - acc: 0.9329 - val_loss: 0.2404 - val_acc: 0.9304\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1838 - acc: 0.9452\n",
      "Epoch 00005: val_loss did not improve from 0.24044\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1838 - acc: 0.9451 - val_loss: 0.2908 - val_acc: 0.9099\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9533\n",
      "Epoch 00006: val_loss improved from 0.24044 to 0.23451, saving model to model/checkpoint/1D_CNN_custom_BN_2_9_conv_checkpoint/006-0.2345.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1581 - acc: 0.9533 - val_loss: 0.2345 - val_acc: 0.9320\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9621\n",
      "Epoch 00007: val_loss improved from 0.23451 to 0.17920, saving model to model/checkpoint/1D_CNN_custom_BN_2_9_conv_checkpoint/007-0.1792.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1282 - acc: 0.9621 - val_loss: 0.1792 - val_acc: 0.9462\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9672\n",
      "Epoch 00008: val_loss did not improve from 0.17920\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1113 - acc: 0.9672 - val_loss: 0.1955 - val_acc: 0.9394\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9753\n",
      "Epoch 00009: val_loss did not improve from 0.17920\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0880 - acc: 0.9753 - val_loss: 0.1876 - val_acc: 0.9446\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9800\n",
      "Epoch 00010: val_loss did not improve from 0.17920\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0745 - acc: 0.9799 - val_loss: 0.2216 - val_acc: 0.9366\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9782\n",
      "Epoch 00011: val_loss did not improve from 0.17920\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0750 - acc: 0.9782 - val_loss: 0.2008 - val_acc: 0.9418\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9808\n",
      "Epoch 00012: val_loss improved from 0.17920 to 0.16082, saving model to model/checkpoint/1D_CNN_custom_BN_2_9_conv_checkpoint/012-0.1608.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0688 - acc: 0.9808 - val_loss: 0.1608 - val_acc: 0.9504\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9885\n",
      "Epoch 00013: val_loss did not improve from 0.16082\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0460 - acc: 0.9885 - val_loss: 0.1914 - val_acc: 0.9448\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9904\n",
      "Epoch 00014: val_loss did not improve from 0.16082\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0404 - acc: 0.9904 - val_loss: 0.1982 - val_acc: 0.9439\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9907\n",
      "Epoch 00015: val_loss did not improve from 0.16082\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0377 - acc: 0.9906 - val_loss: 0.2681 - val_acc: 0.9257\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9829\n",
      "Epoch 00016: val_loss did not improve from 0.16082\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0580 - acc: 0.9829 - val_loss: 0.1993 - val_acc: 0.9425\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0284 - acc: 0.9940\n",
      "Epoch 00017: val_loss did not improve from 0.16082\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0285 - acc: 0.9940 - val_loss: 0.2157 - val_acc: 0.9390\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9868\n",
      "Epoch 00018: val_loss did not improve from 0.16082\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0480 - acc: 0.9868 - val_loss: 0.1805 - val_acc: 0.9518\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9906\n",
      "Epoch 00019: val_loss improved from 0.16082 to 0.15003, saving model to model/checkpoint/1D_CNN_custom_BN_2_9_conv_checkpoint/019-0.1500.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0357 - acc: 0.9906 - val_loss: 0.1500 - val_acc: 0.9585\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9972\n",
      "Epoch 00020: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0161 - acc: 0.9972 - val_loss: 0.1789 - val_acc: 0.9557\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9967\n",
      "Epoch 00021: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0173 - acc: 0.9967 - val_loss: 0.2099 - val_acc: 0.9429\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9961\n",
      "Epoch 00022: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0184 - acc: 0.9961 - val_loss: 0.2217 - val_acc: 0.9420\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0269 - acc: 0.9931\n",
      "Epoch 00023: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0269 - acc: 0.9931 - val_loss: 0.1741 - val_acc: 0.9499\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9962\n",
      "Epoch 00024: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0165 - acc: 0.9962 - val_loss: 0.1988 - val_acc: 0.9460\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9874\n",
      "Epoch 00025: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0418 - acc: 0.9874 - val_loss: 0.1979 - val_acc: 0.9497\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9983\n",
      "Epoch 00026: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0106 - acc: 0.9983 - val_loss: 0.1701 - val_acc: 0.9588\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9983\n",
      "Epoch 00027: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0106 - acc: 0.9982 - val_loss: 0.2361 - val_acc: 0.9385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9900\n",
      "Epoch 00028: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0356 - acc: 0.9900 - val_loss: 0.1773 - val_acc: 0.9562\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9980\n",
      "Epoch 00029: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0098 - acc: 0.9979 - val_loss: 0.1690 - val_acc: 0.9576\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9930\n",
      "Epoch 00030: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0266 - acc: 0.9930 - val_loss: 0.2310 - val_acc: 0.9411\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9934\n",
      "Epoch 00031: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0250 - acc: 0.9934 - val_loss: 0.1701 - val_acc: 0.9578\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9983\n",
      "Epoch 00032: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0105 - acc: 0.9983 - val_loss: 0.1973 - val_acc: 0.9539\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9991\n",
      "Epoch 00033: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0066 - acc: 0.9991 - val_loss: 0.1823 - val_acc: 0.9541\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9990\n",
      "Epoch 00034: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0065 - acc: 0.9990 - val_loss: 0.2285 - val_acc: 0.9422\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9951\n",
      "Epoch 00035: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0191 - acc: 0.9951 - val_loss: 0.1765 - val_acc: 0.9557\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9979\n",
      "Epoch 00036: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0102 - acc: 0.9979 - val_loss: 0.1655 - val_acc: 0.9564\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9987\n",
      "Epoch 00037: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0070 - acc: 0.9987 - val_loss: 0.1959 - val_acc: 0.9536\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9965\n",
      "Epoch 00038: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0122 - acc: 0.9965 - val_loss: 0.2614 - val_acc: 0.9392\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9932\n",
      "Epoch 00039: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0242 - acc: 0.9932 - val_loss: 0.1675 - val_acc: 0.9590\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9981\n",
      "Epoch 00040: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0091 - acc: 0.9981 - val_loss: 0.1687 - val_acc: 0.9560\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9986\n",
      "Epoch 00041: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0068 - acc: 0.9986 - val_loss: 0.1733 - val_acc: 0.9597\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9983\n",
      "Epoch 00042: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0083 - acc: 0.9983 - val_loss: 0.1866 - val_acc: 0.9576\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9941\n",
      "Epoch 00043: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0219 - acc: 0.9941 - val_loss: 0.1708 - val_acc: 0.9576\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9992\n",
      "Epoch 00044: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0053 - acc: 0.9992 - val_loss: 0.1866 - val_acc: 0.9571\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9992\n",
      "Epoch 00045: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0048 - acc: 0.9992 - val_loss: 0.2667 - val_acc: 0.9385\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9922\n",
      "Epoch 00046: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0244 - acc: 0.9922 - val_loss: 0.1720 - val_acc: 0.9585\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9993\n",
      "Epoch 00047: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0038 - acc: 0.9993 - val_loss: 0.1689 - val_acc: 0.9602\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9993\n",
      "Epoch 00048: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0041 - acc: 0.9993 - val_loss: 0.1714 - val_acc: 0.9609\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9974\n",
      "Epoch 00049: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0106 - acc: 0.9974 - val_loss: 0.1710 - val_acc: 0.9595\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9953\n",
      "Epoch 00050: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0155 - acc: 0.9953 - val_loss: 0.1770 - val_acc: 0.9606\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9993\n",
      "Epoch 00051: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0036 - acc: 0.9993 - val_loss: 0.1851 - val_acc: 0.9590\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0027 - acc: 0.9996\n",
      "Epoch 00052: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0027 - acc: 0.9996 - val_loss: 0.1698 - val_acc: 0.9609\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9953\n",
      "Epoch 00053: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0158 - acc: 0.9953 - val_loss: 0.2126 - val_acc: 0.9471\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9989\n",
      "Epoch 00054: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0055 - acc: 0.9989 - val_loss: 0.1826 - val_acc: 0.9576\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9985\n",
      "Epoch 00055: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0052 - acc: 0.9985 - val_loss: 0.2164 - val_acc: 0.9527\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9968\n",
      "Epoch 00056: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0111 - acc: 0.9967 - val_loss: 0.1770 - val_acc: 0.9592\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9958\n",
      "Epoch 00057: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0142 - acc: 0.9958 - val_loss: 0.1878 - val_acc: 0.9592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9968\n",
      "Epoch 00058: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0105 - acc: 0.9968 - val_loss: 0.2076 - val_acc: 0.9529\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9995\n",
      "Epoch 00059: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0032 - acc: 0.9995 - val_loss: 0.1678 - val_acc: 0.9632\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9996\n",
      "Epoch 00060: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0027 - acc: 0.9996 - val_loss: 0.1786 - val_acc: 0.9588\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9948\n",
      "Epoch 00061: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0167 - acc: 0.9948 - val_loss: 0.1962 - val_acc: 0.9557\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9990\n",
      "Epoch 00062: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0042 - acc: 0.9990 - val_loss: 0.1901 - val_acc: 0.9562\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9976\n",
      "Epoch 00063: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0083 - acc: 0.9976 - val_loss: 0.1858 - val_acc: 0.9578\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9950\n",
      "Epoch 00064: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0172 - acc: 0.9950 - val_loss: 0.2171 - val_acc: 0.9460\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9962\n",
      "Epoch 00065: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0134 - acc: 0.9962 - val_loss: 0.1709 - val_acc: 0.9571\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0048 - acc: 0.9990\n",
      "Epoch 00066: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0048 - acc: 0.9990 - val_loss: 0.1528 - val_acc: 0.9625\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0020 - acc: 0.9996\n",
      "Epoch 00067: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0021 - acc: 0.9996 - val_loss: 0.1682 - val_acc: 0.9616\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9974\n",
      "Epoch 00068: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0104 - acc: 0.9974 - val_loss: 0.1653 - val_acc: 0.9620\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9970\n",
      "Epoch 00069: val_loss did not improve from 0.15003\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0103 - acc: 0.9970 - val_loss: 0.1538 - val_acc: 0.9651\n",
      "\n",
      "1D_CNN_custom_BN_2_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1964 - acc: 0.9408\n",
      "Loss: 0.196356212396488 Accuracy: 0.94080997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    base = '1D_CNN_custom_BN_2'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_BN_2(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_BN_2_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,480,656\n",
      "Trainable params: 18,432,528\n",
      "Non-trainable params: 2,048,128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 800us/sample - loss: 10.5517 - acc: 0.3221\n",
      "Loss: 10.551671287005812 Accuracy: 0.32211837\n",
      "\n",
      "1D_CNN_custom_BN_2_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 6,847,696\n",
      "Trainable params: 6,164,816\n",
      "Non-trainable params: 682,880\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 929us/sample - loss: 4.1062 - acc: 0.2987\n",
      "Loss: 4.1062096585861 Accuracy: 0.29865006\n",
      "\n",
      "1D_CNN_custom_BN_2_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,316,816\n",
      "Trainable params: 2,088,976\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 2.0156 - acc: 0.4870\n",
      "Loss: 2.0155845355888515 Accuracy: 0.48701972\n",
      "\n",
      "1D_CNN_custom_BN_2_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 820,816\n",
      "Trainable params: 744,528\n",
      "Non-trainable params: 76,288\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.3403 - acc: 0.6160\n",
      "Loss: 1.340295346404657 Accuracy: 0.6159917\n",
      "\n",
      "1D_CNN_custom_BN_2_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 608,976\n",
      "Trainable params: 557,776\n",
      "Non-trainable params: 51,200\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.0246 - acc: 0.7134\n",
      "Loss: 1.0246255337387353 Accuracy: 0.71339566\n",
      "\n",
      "1D_CNN_custom_BN_2_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 353,616\n",
      "Trainable params: 335,952\n",
      "Non-trainable params: 17,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.6375 - acc: 0.8314\n",
      "Loss: 0.6375187798700105 Accuracy: 0.83136034\n",
      "\n",
      "1D_CNN_custom_BN_2_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 323,536\n",
      "Trainable params: 316,880\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.3183 - acc: 0.9192\n",
      "Loss: 0.3183324581172669 Accuracy: 0.9192108\n",
      "\n",
      "1D_CNN_custom_BN_2_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 370,256\n",
      "Trainable params: 366,928\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2246 - acc: 0.9458\n",
      "Loss: 0.2246089458840813 Accuracy: 0.9457944\n",
      "\n",
      "1D_CNN_custom_BN_2_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 527,696\n",
      "Trainable params: 524,624\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.1964 - acc: 0.9408\n",
      "Loss: 0.196356212396488 Accuracy: 0.94080997\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_BN_2'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_BN_2_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 1024000)           4096000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 20,480,656\n",
      "Trainable params: 18,432,528\n",
      "Non-trainable params: 2,048,128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 876us/sample - loss: 11.1887 - acc: 0.2860\n",
      "Loss: 11.188731413392635 Accuracy: 0.2859813\n",
      "\n",
      "1D_CNN_custom_BN_2_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 341312)            1365248   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 6,847,696\n",
      "Trainable params: 6,164,816\n",
      "Non-trainable params: 682,880\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 8.9978 - acc: 0.3402\n",
      "Loss: 8.997824006957057 Accuracy: 0.34018692\n",
      "\n",
      "1D_CNN_custom_BN_2_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 113728)            454912    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 2,316,816\n",
      "Trainable params: 2,088,976\n",
      "Non-trainable params: 227,840\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 4.8559 - acc: 0.4893\n",
      "Loss: 4.855926860678604 Accuracy: 0.48930424\n",
      "\n",
      "1D_CNN_custom_BN_2_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 37888)             151552    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 820,816\n",
      "Trainable params: 744,528\n",
      "Non-trainable params: 76,288\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 2.3427 - acc: 0.6291\n",
      "Loss: 2.3426765838020933 Accuracy: 0.6290758\n",
      "\n",
      "1D_CNN_custom_BN_2_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 25216)             100864    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 608,976\n",
      "Trainable params: 557,776\n",
      "Non-trainable params: 51,200\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.7004 - acc: 0.7022\n",
      "Loss: 1.7003940422339354 Accuracy: 0.7021807\n",
      "\n",
      "1D_CNN_custom_BN_2_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 8320)              33280     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 353,616\n",
      "Trainable params: 335,952\n",
      "Non-trainable params: 17,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.8719 - acc: 0.8233\n",
      "Loss: 0.8719426944248402 Accuracy: 0.82326066\n",
      "\n",
      "1D_CNN_custom_BN_2_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 2688)              10752     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 323,536\n",
      "Trainable params: 316,880\n",
      "Non-trainable params: 6,656\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4342 - acc: 0.9061\n",
      "Loss: 0.43415780395486026 Accuracy: 0.9061267\n",
      "\n",
      "1D_CNN_custom_BN_2_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 896)               3584      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 370,256\n",
      "Trainable params: 366,928\n",
      "Non-trainable params: 3,328\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2104 - acc: 0.9508\n",
      "Loss: 0.2103977923824037 Accuracy: 0.95077884\n",
      "\n",
      "1D_CNN_custom_BN_2_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 527,696\n",
      "Trainable params: 524,624\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2075 - acc: 0.9464\n",
      "Loss: 0.2074711796256055 Accuracy: 0.94641745\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_BN_2'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
