{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_VGG_DO(conv_num=1):\n",
    "    channel_size = 128\n",
    "    \n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=channel_size, strides=1, padding='same', \n",
    "                      activation='relu', input_shape=input_shape)) \n",
    "    model.add(Conv1D (kernel_size=3, filters=channel_size, strides=1, padding='same', \n",
    "                  activation='relu')) \n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=channel_size*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))\n",
    "        model.add(Conv1D (kernel_size=3, filters=channel_size*(2**int((i+1)/4)), strides=1, padding='same', \n",
    "                          activation='relu'))         \n",
    "#         model.add(BatchNormalization())\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2048000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 2048000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                32768016  \n",
      "=================================================================\n",
      "Total params: 32,817,808\n",
      "Trainable params: 32,817,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 682624)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 682624)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                10922000  \n",
      "=================================================================\n",
      "Total params: 11,070,352\n",
      "Trainable params: 11,070,352\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 3,886,224\n",
      "Trainable params: 3,886,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,557,904\n",
      "Trainable params: 1,557,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 256)          98560     \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 256)          196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                806928    \n",
      "=================================================================\n",
      "Total params: 1,447,824\n",
      "Trainable params: 1,447,824\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 256)          98560     \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 256)          196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 256)          196864    \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 256)          196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                266256    \n",
      "=================================================================\n",
      "Total params: 1,300,880\n",
      "Trainable params: 1,300,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 256)          98560     \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 256)          196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 256)          196864    \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 256)          196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 256)           196864    \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 1,514,384\n",
      "Trainable params: 1,514,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 256)          98560     \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 256)          196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 256)          196864    \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 256)          196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 256)           196864    \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 256)           196864    \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,850,768\n",
      "Trainable params: 1,850,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 128)        49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 128)         49280     \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 128)         49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 256)          98560     \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 256)          196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 256)          196864    \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 256)          196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 256)           196864    \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 256)           196864    \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 256)           196864    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 512)            393728    \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 512)            786944    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 3,019,152\n",
      "Trainable params: 3,019,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9805 - acc: 0.3597\n",
      "Epoch 00001: val_loss improved from inf to 1.45919, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_4_conv_checkpoint/001-1.4592.hdf5\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 1.9804 - acc: 0.3598 - val_loss: 1.4592 - val_acc: 0.5292\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2934 - acc: 0.5961\n",
      "Epoch 00002: val_loss improved from 1.45919 to 1.17337, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_4_conv_checkpoint/002-1.1734.hdf5\n",
      "36805/36805 [==============================] - 100s 3ms/sample - loss: 1.2934 - acc: 0.5961 - val_loss: 1.1734 - val_acc: 0.6471\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0061 - acc: 0.6943\n",
      "Epoch 00003: val_loss improved from 1.17337 to 1.02466, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_4_conv_checkpoint/003-1.0247.hdf5\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 1.0061 - acc: 0.6943 - val_loss: 1.0247 - val_acc: 0.6834\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7930 - acc: 0.7600\n",
      "Epoch 00004: val_loss improved from 1.02466 to 0.98317, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_4_conv_checkpoint/004-0.9832.hdf5\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.7933 - acc: 0.7600 - val_loss: 0.9832 - val_acc: 0.7016\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6125 - acc: 0.8147\n",
      "Epoch 00005: val_loss improved from 0.98317 to 0.97897, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_4_conv_checkpoint/005-0.9790.hdf5\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.6124 - acc: 0.8147 - val_loss: 0.9790 - val_acc: 0.7200\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4646 - acc: 0.8559\n",
      "Epoch 00006: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.4645 - acc: 0.8559 - val_loss: 1.0096 - val_acc: 0.7163\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3557 - acc: 0.8893\n",
      "Epoch 00007: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.3557 - acc: 0.8893 - val_loss: 0.9910 - val_acc: 0.7342\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2727 - acc: 0.9152\n",
      "Epoch 00008: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.2728 - acc: 0.9152 - val_loss: 1.2251 - val_acc: 0.7039\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2280 - acc: 0.9250\n",
      "Epoch 00009: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.2281 - acc: 0.9250 - val_loss: 1.1721 - val_acc: 0.7240\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1854 - acc: 0.9400\n",
      "Epoch 00010: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.1853 - acc: 0.9400 - val_loss: 1.2879 - val_acc: 0.7338\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1652 - acc: 0.9474\n",
      "Epoch 00011: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.1652 - acc: 0.9474 - val_loss: 1.3516 - val_acc: 0.7263\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1441 - acc: 0.9555\n",
      "Epoch 00012: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.1440 - acc: 0.9555 - val_loss: 1.3505 - val_acc: 0.7296\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9589\n",
      "Epoch 00013: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.1299 - acc: 0.9589 - val_loss: 1.3743 - val_acc: 0.7356\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9638\n",
      "Epoch 00014: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.1174 - acc: 0.9638 - val_loss: 1.3949 - val_acc: 0.7312\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9656\n",
      "Epoch 00015: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.1131 - acc: 0.9656 - val_loss: 1.3022 - val_acc: 0.7524\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9687\n",
      "Epoch 00016: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.1010 - acc: 0.9687 - val_loss: 1.4105 - val_acc: 0.7393\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9700\n",
      "Epoch 00017: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0994 - acc: 0.9700 - val_loss: 1.4601 - val_acc: 0.7163\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9716\n",
      "Epoch 00018: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0932 - acc: 0.9716 - val_loss: 1.4786 - val_acc: 0.7365\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9731\n",
      "Epoch 00019: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0848 - acc: 0.9731 - val_loss: 1.5303 - val_acc: 0.7277\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9730\n",
      "Epoch 00020: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0865 - acc: 0.9730 - val_loss: 1.5264 - val_acc: 0.7417\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9773\n",
      "Epoch 00021: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0778 - acc: 0.9773 - val_loss: 1.4861 - val_acc: 0.7407\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9772\n",
      "Epoch 00022: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0774 - acc: 0.9772 - val_loss: 1.5702 - val_acc: 0.7319\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9785\n",
      "Epoch 00023: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0732 - acc: 0.9785 - val_loss: 1.4688 - val_acc: 0.7547\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9745\n",
      "Epoch 00024: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 0.0855 - acc: 0.9745 - val_loss: 1.3865 - val_acc: 0.7582\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9790\n",
      "Epoch 00025: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0698 - acc: 0.9790 - val_loss: 1.4353 - val_acc: 0.7508\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9813\n",
      "Epoch 00026: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0666 - acc: 0.9813 - val_loss: 1.5330 - val_acc: 0.7454\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9812\n",
      "Epoch 00027: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0658 - acc: 0.9812 - val_loss: 1.3859 - val_acc: 0.7503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0598 - acc: 0.9835\n",
      "Epoch 00028: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0598 - acc: 0.9835 - val_loss: 1.4015 - val_acc: 0.7447\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9819\n",
      "Epoch 00029: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0636 - acc: 0.9819 - val_loss: 1.5635 - val_acc: 0.7452\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9833\n",
      "Epoch 00030: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0588 - acc: 0.9833 - val_loss: 1.4922 - val_acc: 0.7643\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9841\n",
      "Epoch 00031: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0590 - acc: 0.9841 - val_loss: 1.4447 - val_acc: 0.7480\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9832\n",
      "Epoch 00032: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0591 - acc: 0.9832 - val_loss: 1.4886 - val_acc: 0.7531\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9845\n",
      "Epoch 00033: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0565 - acc: 0.9845 - val_loss: 1.5117 - val_acc: 0.7556\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9847\n",
      "Epoch 00034: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0556 - acc: 0.9847 - val_loss: 1.5097 - val_acc: 0.7591\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9855\n",
      "Epoch 00035: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0544 - acc: 0.9854 - val_loss: 1.4779 - val_acc: 0.7531\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9866\n",
      "Epoch 00036: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0495 - acc: 0.9866 - val_loss: 1.5499 - val_acc: 0.7552\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9857\n",
      "Epoch 00037: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0507 - acc: 0.9857 - val_loss: 1.5877 - val_acc: 0.7424\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9854\n",
      "Epoch 00038: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0531 - acc: 0.9854 - val_loss: 1.5178 - val_acc: 0.7594\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9874\n",
      "Epoch 00039: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0479 - acc: 0.9874 - val_loss: 1.4415 - val_acc: 0.7661\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9867\n",
      "Epoch 00040: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0487 - acc: 0.9867 - val_loss: 1.4981 - val_acc: 0.7577\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9851\n",
      "Epoch 00041: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0541 - acc: 0.9851 - val_loss: 1.5184 - val_acc: 0.7580\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9871\n",
      "Epoch 00042: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0473 - acc: 0.9871 - val_loss: 1.5107 - val_acc: 0.7587\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9883\n",
      "Epoch 00043: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0434 - acc: 0.9883 - val_loss: 1.5390 - val_acc: 0.7580\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9865\n",
      "Epoch 00044: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0488 - acc: 0.9865 - val_loss: 1.4834 - val_acc: 0.7587\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9893\n",
      "Epoch 00045: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0416 - acc: 0.9893 - val_loss: 1.5144 - val_acc: 0.7591\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9890\n",
      "Epoch 00046: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0427 - acc: 0.9890 - val_loss: 1.5402 - val_acc: 0.7538\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9891\n",
      "Epoch 00047: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0427 - acc: 0.9891 - val_loss: 1.6455 - val_acc: 0.7545\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9882\n",
      "Epoch 00048: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0440 - acc: 0.9882 - val_loss: 1.5470 - val_acc: 0.7484\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9905\n",
      "Epoch 00049: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0382 - acc: 0.9905 - val_loss: 1.5267 - val_acc: 0.7603\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9889\n",
      "Epoch 00050: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0424 - acc: 0.9889 - val_loss: 1.6452 - val_acc: 0.7477\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9886\n",
      "Epoch 00051: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0446 - acc: 0.9886 - val_loss: 1.4768 - val_acc: 0.7584\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9890\n",
      "Epoch 00052: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0416 - acc: 0.9890 - val_loss: 1.5491 - val_acc: 0.7610\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9903\n",
      "Epoch 00053: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0394 - acc: 0.9903 - val_loss: 1.6442 - val_acc: 0.7605\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9890\n",
      "Epoch 00054: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0413 - acc: 0.9890 - val_loss: 1.5659 - val_acc: 0.7566\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9899\n",
      "Epoch 00055: val_loss did not improve from 0.97897\n",
      "36805/36805 [==============================] - 101s 3ms/sample - loss: 0.0397 - acc: 0.9899 - val_loss: 1.4555 - val_acc: 0.7612\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 1.0946 - acc: 0.6825\n",
      "Loss: 1.094621503080782 Accuracy: 0.68245065\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9554 - acc: 0.3641\n",
      "Epoch 00001: val_loss improved from inf to 1.36096, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_5_conv_checkpoint/001-1.3610.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 1.9553 - acc: 0.3641 - val_loss: 1.3610 - val_acc: 0.5651\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2928 - acc: 0.5907\n",
      "Epoch 00002: val_loss improved from 1.36096 to 1.13281, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_5_conv_checkpoint/002-1.1328.hdf5\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 1.2927 - acc: 0.5908 - val_loss: 1.1328 - val_acc: 0.6464\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0430 - acc: 0.6793\n",
      "Epoch 00003: val_loss improved from 1.13281 to 0.91902, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_5_conv_checkpoint/003-0.9190.hdf5\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 1.0429 - acc: 0.6794 - val_loss: 0.9190 - val_acc: 0.7214\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8472 - acc: 0.7432\n",
      "Epoch 00004: val_loss improved from 0.91902 to 0.75672, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_5_conv_checkpoint/004-0.7567.hdf5\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.8471 - acc: 0.7432 - val_loss: 0.7567 - val_acc: 0.7768\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6836 - acc: 0.7954\n",
      "Epoch 00005: val_loss improved from 0.75672 to 0.74459, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_5_conv_checkpoint/005-0.7446.hdf5\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.6836 - acc: 0.7954 - val_loss: 0.7446 - val_acc: 0.7801\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5809 - acc: 0.8270\n",
      "Epoch 00006: val_loss improved from 0.74459 to 0.66123, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_5_conv_checkpoint/006-0.6612.hdf5\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.5809 - acc: 0.8270 - val_loss: 0.6612 - val_acc: 0.8118\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4846 - acc: 0.8561\n",
      "Epoch 00007: val_loss improved from 0.66123 to 0.63804, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_5_conv_checkpoint/007-0.6380.hdf5\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.4846 - acc: 0.8561 - val_loss: 0.6380 - val_acc: 0.8258\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3969 - acc: 0.8816\n",
      "Epoch 00008: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.3968 - acc: 0.8816 - val_loss: 0.6819 - val_acc: 0.8164\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3228 - acc: 0.9022\n",
      "Epoch 00009: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.3228 - acc: 0.9022 - val_loss: 0.6914 - val_acc: 0.8318\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2663 - acc: 0.9187\n",
      "Epoch 00010: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.2662 - acc: 0.9187 - val_loss: 0.6880 - val_acc: 0.8218\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2207 - acc: 0.9318\n",
      "Epoch 00011: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.2208 - acc: 0.9318 - val_loss: 0.7970 - val_acc: 0.8036\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9388\n",
      "Epoch 00012: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.1960 - acc: 0.9388 - val_loss: 0.7404 - val_acc: 0.8253\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1609 - acc: 0.9509\n",
      "Epoch 00013: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.1609 - acc: 0.9509 - val_loss: 0.7571 - val_acc: 0.8272\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9546\n",
      "Epoch 00014: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.1419 - acc: 0.9546 - val_loss: 0.7751 - val_acc: 0.8360\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9621\n",
      "Epoch 00015: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.1211 - acc: 0.9621 - val_loss: 0.8031 - val_acc: 0.8251\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9648\n",
      "Epoch 00016: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.1141 - acc: 0.9648 - val_loss: 0.8052 - val_acc: 0.8330\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9674\n",
      "Epoch 00017: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.1080 - acc: 0.9674 - val_loss: 0.7980 - val_acc: 0.8358\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9690\n",
      "Epoch 00018: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.1028 - acc: 0.9691 - val_loss: 0.8597 - val_acc: 0.8248\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9725\n",
      "Epoch 00019: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0896 - acc: 0.9725 - val_loss: 0.7809 - val_acc: 0.8421\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9743\n",
      "Epoch 00020: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0868 - acc: 0.9743 - val_loss: 0.8702 - val_acc: 0.8237\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9743\n",
      "Epoch 00021: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0861 - acc: 0.9743 - val_loss: 1.0112 - val_acc: 0.8176\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9775\n",
      "Epoch 00022: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0750 - acc: 0.9775 - val_loss: 0.8830 - val_acc: 0.8272\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9799\n",
      "Epoch 00023: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0691 - acc: 0.9799 - val_loss: 0.9132 - val_acc: 0.8248\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9779\n",
      "Epoch 00024: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0755 - acc: 0.9779 - val_loss: 0.8921 - val_acc: 0.8344\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9802\n",
      "Epoch 00025: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0697 - acc: 0.9802 - val_loss: 0.8178 - val_acc: 0.8379\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9795\n",
      "Epoch 00026: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0701 - acc: 0.9795 - val_loss: 0.8320 - val_acc: 0.8465\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9819\n",
      "Epoch 00027: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0601 - acc: 0.9819 - val_loss: 0.8281 - val_acc: 0.8467\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9819\n",
      "Epoch 00028: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0621 - acc: 0.9819 - val_loss: 0.8482 - val_acc: 0.8321\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9821\n",
      "Epoch 00029: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0621 - acc: 0.9821 - val_loss: 0.8795 - val_acc: 0.8432\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9854\n",
      "Epoch 00030: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0507 - acc: 0.9854 - val_loss: 0.8971 - val_acc: 0.8376\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9823\n",
      "Epoch 00031: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0611 - acc: 0.9823 - val_loss: 0.8373 - val_acc: 0.8418\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9840\n",
      "Epoch 00032: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0577 - acc: 0.9841 - val_loss: 0.7535 - val_acc: 0.8551\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9844\n",
      "Epoch 00033: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0551 - acc: 0.9844 - val_loss: 0.8701 - val_acc: 0.8463\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9852\n",
      "Epoch 00034: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0516 - acc: 0.9852 - val_loss: 0.8005 - val_acc: 0.8460\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9873\n",
      "Epoch 00035: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0463 - acc: 0.9873 - val_loss: 0.9379 - val_acc: 0.8339\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9854\n",
      "Epoch 00036: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0506 - acc: 0.9854 - val_loss: 0.9037 - val_acc: 0.8437\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9861\n",
      "Epoch 00037: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0501 - acc: 0.9861 - val_loss: 0.8310 - val_acc: 0.8460\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9855\n",
      "Epoch 00038: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0532 - acc: 0.9855 - val_loss: 0.8032 - val_acc: 0.8519\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9891\n",
      "Epoch 00039: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0411 - acc: 0.9891 - val_loss: 0.8873 - val_acc: 0.8423\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9864\n",
      "Epoch 00040: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0491 - acc: 0.9864 - val_loss: 0.8703 - val_acc: 0.8446\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9890\n",
      "Epoch 00041: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 0.0423 - acc: 0.9890 - val_loss: 0.8988 - val_acc: 0.8411\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9865\n",
      "Epoch 00042: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 0.0477 - acc: 0.9865 - val_loss: 0.8641 - val_acc: 0.8435\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9890\n",
      "Epoch 00043: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 0.0400 - acc: 0.9890 - val_loss: 0.8527 - val_acc: 0.8521\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9882\n",
      "Epoch 00044: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0429 - acc: 0.9882 - val_loss: 0.8167 - val_acc: 0.8544\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9892\n",
      "Epoch 00045: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 0.0399 - acc: 0.9892 - val_loss: 0.9023 - val_acc: 0.8451\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9892\n",
      "Epoch 00046: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 0.0390 - acc: 0.9892 - val_loss: 0.8972 - val_acc: 0.8421\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9893\n",
      "Epoch 00047: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0412 - acc: 0.9893 - val_loss: 0.8998 - val_acc: 0.8465\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9888\n",
      "Epoch 00048: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0428 - acc: 0.9888 - val_loss: 0.9318 - val_acc: 0.8404\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9894\n",
      "Epoch 00049: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0390 - acc: 0.9894 - val_loss: 0.9026 - val_acc: 0.8546\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9902\n",
      "Epoch 00050: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0375 - acc: 0.9902 - val_loss: 0.8560 - val_acc: 0.8505\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9880\n",
      "Epoch 00051: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0432 - acc: 0.9880 - val_loss: 0.8997 - val_acc: 0.8421\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9908\n",
      "Epoch 00052: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 0.0347 - acc: 0.9908 - val_loss: 0.9384 - val_acc: 0.8474\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9901\n",
      "Epoch 00053: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 0.0363 - acc: 0.9901 - val_loss: 0.8279 - val_acc: 0.8535\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9917\n",
      "Epoch 00054: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 0.0312 - acc: 0.9917 - val_loss: 0.9407 - val_acc: 0.8500\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9912\n",
      "Epoch 00055: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 104s 3ms/sample - loss: 0.0334 - acc: 0.9912 - val_loss: 0.8360 - val_acc: 0.8640\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9914\n",
      "Epoch 00056: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 0.0334 - acc: 0.9914 - val_loss: 0.8932 - val_acc: 0.8486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9899\n",
      "Epoch 00057: val_loss did not improve from 0.63804\n",
      "36805/36805 [==============================] - 103s 3ms/sample - loss: 0.0373 - acc: 0.9899 - val_loss: 0.8537 - val_acc: 0.8579\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.7625 - acc: 0.7769\n",
      "Loss: 0.7625076849760173 Accuracy: 0.776947\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1040 - acc: 0.3122\n",
      "Epoch 00001: val_loss improved from inf to 1.40235, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/001-1.4023.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 2.1040 - acc: 0.3122 - val_loss: 1.4023 - val_acc: 0.5637\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3887 - acc: 0.5545\n",
      "Epoch 00002: val_loss improved from 1.40235 to 1.22103, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/002-1.2210.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 1.3887 - acc: 0.5545 - val_loss: 1.2210 - val_acc: 0.6252\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1641 - acc: 0.6337\n",
      "Epoch 00003: val_loss improved from 1.22103 to 0.95902, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/003-0.9590.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 1.1642 - acc: 0.6336 - val_loss: 0.9590 - val_acc: 0.7032\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9445 - acc: 0.7109\n",
      "Epoch 00004: val_loss improved from 0.95902 to 0.76548, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/004-0.7655.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.9445 - acc: 0.7109 - val_loss: 0.7655 - val_acc: 0.7857\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7482 - acc: 0.7732\n",
      "Epoch 00005: val_loss improved from 0.76548 to 0.59580, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/005-0.5958.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.7481 - acc: 0.7732 - val_loss: 0.5958 - val_acc: 0.8297\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6195 - acc: 0.8127\n",
      "Epoch 00006: val_loss improved from 0.59580 to 0.56034, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/006-0.5603.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.6195 - acc: 0.8127 - val_loss: 0.5603 - val_acc: 0.8339\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5259 - acc: 0.8436\n",
      "Epoch 00007: val_loss improved from 0.56034 to 0.50890, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/007-0.5089.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.5259 - acc: 0.8436 - val_loss: 0.5089 - val_acc: 0.8640\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4698 - acc: 0.8583\n",
      "Epoch 00008: val_loss improved from 0.50890 to 0.44533, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/008-0.4453.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.4698 - acc: 0.8583 - val_loss: 0.4453 - val_acc: 0.8768\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4150 - acc: 0.8737\n",
      "Epoch 00009: val_loss improved from 0.44533 to 0.40305, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/009-0.4031.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.4149 - acc: 0.8738 - val_loss: 0.4031 - val_acc: 0.8908\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3720 - acc: 0.8880\n",
      "Epoch 00010: val_loss improved from 0.40305 to 0.39954, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/010-0.3995.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.3720 - acc: 0.8880 - val_loss: 0.3995 - val_acc: 0.8982\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3291 - acc: 0.9005\n",
      "Epoch 00011: val_loss improved from 0.39954 to 0.33972, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/011-0.3397.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.3292 - acc: 0.9004 - val_loss: 0.3397 - val_acc: 0.9085\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3025 - acc: 0.9074\n",
      "Epoch 00012: val_loss did not improve from 0.33972\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.3028 - acc: 0.9074 - val_loss: 0.3538 - val_acc: 0.8973\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2789 - acc: 0.9142\n",
      "Epoch 00013: val_loss improved from 0.33972 to 0.33505, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/013-0.3351.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.2789 - acc: 0.9142 - val_loss: 0.3351 - val_acc: 0.9092\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2475 - acc: 0.9237\n",
      "Epoch 00014: val_loss did not improve from 0.33505\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.2475 - acc: 0.9237 - val_loss: 0.3533 - val_acc: 0.9140\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2285 - acc: 0.9292\n",
      "Epoch 00015: val_loss did not improve from 0.33505\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.2284 - acc: 0.9292 - val_loss: 0.3542 - val_acc: 0.9138\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2057 - acc: 0.9369\n",
      "Epoch 00016: val_loss improved from 0.33505 to 0.32958, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/016-0.3296.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.2056 - acc: 0.9369 - val_loss: 0.3296 - val_acc: 0.9099\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1882 - acc: 0.9406\n",
      "Epoch 00017: val_loss improved from 0.32958 to 0.31347, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/017-0.3135.hdf5\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.1882 - acc: 0.9406 - val_loss: 0.3135 - val_acc: 0.9262\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9428\n",
      "Epoch 00018: val_loss did not improve from 0.31347\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1758 - acc: 0.9428 - val_loss: 0.3300 - val_acc: 0.9189\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1610 - acc: 0.9505\n",
      "Epoch 00019: val_loss did not improve from 0.31347\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1609 - acc: 0.9505 - val_loss: 0.3436 - val_acc: 0.9038\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9518\n",
      "Epoch 00020: val_loss did not improve from 0.31347\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1502 - acc: 0.9518 - val_loss: 0.3169 - val_acc: 0.9175\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9568\n",
      "Epoch 00021: val_loss did not improve from 0.31347\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.1369 - acc: 0.9568 - val_loss: 0.3752 - val_acc: 0.9196\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9594\n",
      "Epoch 00022: val_loss did not improve from 0.31347\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.1226 - acc: 0.9594 - val_loss: 0.3565 - val_acc: 0.9052\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9629\n",
      "Epoch 00023: val_loss did not improve from 0.31347\n",
      "36805/36805 [==============================] - 107s 3ms/sample - loss: 0.1168 - acc: 0.9629 - val_loss: 0.3492 - val_acc: 0.9297\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9613\n",
      "Epoch 00024: val_loss improved from 0.31347 to 0.30766, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv_checkpoint/024-0.3077.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1176 - acc: 0.9613 - val_loss: 0.3077 - val_acc: 0.9236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9659\n",
      "Epoch 00025: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1023 - acc: 0.9659 - val_loss: 0.3348 - val_acc: 0.9278\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9691\n",
      "Epoch 00026: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0967 - acc: 0.9691 - val_loss: 0.3557 - val_acc: 0.9180\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9695\n",
      "Epoch 00027: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0938 - acc: 0.9695 - val_loss: 0.4047 - val_acc: 0.9187\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9721\n",
      "Epoch 00028: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0866 - acc: 0.9721 - val_loss: 0.3901 - val_acc: 0.9259\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9733\n",
      "Epoch 00029: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0834 - acc: 0.9733 - val_loss: 0.4160 - val_acc: 0.9196\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9749\n",
      "Epoch 00030: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0762 - acc: 0.9749 - val_loss: 0.3584 - val_acc: 0.9278\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9749\n",
      "Epoch 00031: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0735 - acc: 0.9749 - val_loss: 0.3645 - val_acc: 0.9238\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9780\n",
      "Epoch 00032: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0677 - acc: 0.9780 - val_loss: 0.3790 - val_acc: 0.9297\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9787\n",
      "Epoch 00033: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0666 - acc: 0.9788 - val_loss: 0.3567 - val_acc: 0.9315\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9790\n",
      "Epoch 00034: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0662 - acc: 0.9790 - val_loss: 0.4017 - val_acc: 0.9187\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9798\n",
      "Epoch 00035: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0628 - acc: 0.9798 - val_loss: 0.3730 - val_acc: 0.9278\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9799\n",
      "Epoch 00036: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0631 - acc: 0.9799 - val_loss: 0.3643 - val_acc: 0.9329\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9811\n",
      "Epoch 00037: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0580 - acc: 0.9811 - val_loss: 0.4368 - val_acc: 0.9131\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9811\n",
      "Epoch 00038: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0593 - acc: 0.9811 - val_loss: 0.3824 - val_acc: 0.9255\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9828\n",
      "Epoch 00039: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0542 - acc: 0.9828 - val_loss: 0.3980 - val_acc: 0.9199\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9843\n",
      "Epoch 00040: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0501 - acc: 0.9843 - val_loss: 0.4034 - val_acc: 0.9273\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9836\n",
      "Epoch 00041: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0518 - acc: 0.9836 - val_loss: 0.4014 - val_acc: 0.9255\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9837\n",
      "Epoch 00042: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0504 - acc: 0.9837 - val_loss: 0.3981 - val_acc: 0.9278\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9839\n",
      "Epoch 00043: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0516 - acc: 0.9839 - val_loss: 0.3938 - val_acc: 0.9290\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9863\n",
      "Epoch 00044: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0433 - acc: 0.9863 - val_loss: 0.4122 - val_acc: 0.9322\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9839\n",
      "Epoch 00045: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0521 - acc: 0.9839 - val_loss: 0.3557 - val_acc: 0.9306\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9868\n",
      "Epoch 00046: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0427 - acc: 0.9868 - val_loss: 0.3966 - val_acc: 0.9276\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9856\n",
      "Epoch 00047: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0451 - acc: 0.9856 - val_loss: 0.3994 - val_acc: 0.9276\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9858\n",
      "Epoch 00048: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0449 - acc: 0.9858 - val_loss: 0.3578 - val_acc: 0.9299\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9875\n",
      "Epoch 00049: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0415 - acc: 0.9875 - val_loss: 0.3972 - val_acc: 0.9222\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9868\n",
      "Epoch 00050: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0406 - acc: 0.9868 - val_loss: 0.4068 - val_acc: 0.9306\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9892\n",
      "Epoch 00051: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0365 - acc: 0.9892 - val_loss: 0.3901 - val_acc: 0.9343\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9876\n",
      "Epoch 00052: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0391 - acc: 0.9876 - val_loss: 0.4316 - val_acc: 0.9227\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9874\n",
      "Epoch 00053: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0395 - acc: 0.9874 - val_loss: 0.3608 - val_acc: 0.9338\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9895\n",
      "Epoch 00054: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0337 - acc: 0.9895 - val_loss: 0.4407 - val_acc: 0.9301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9885\n",
      "Epoch 00055: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0377 - acc: 0.9885 - val_loss: 0.4328 - val_acc: 0.9266\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9905\n",
      "Epoch 00056: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0301 - acc: 0.9905 - val_loss: 0.4316 - val_acc: 0.9311\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9890\n",
      "Epoch 00057: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0379 - acc: 0.9890 - val_loss: 0.4158 - val_acc: 0.9287\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9899\n",
      "Epoch 00058: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0343 - acc: 0.9899 - val_loss: 0.3983 - val_acc: 0.9283\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9894\n",
      "Epoch 00059: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0345 - acc: 0.9894 - val_loss: 0.4188 - val_acc: 0.9215\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9892\n",
      "Epoch 00060: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0344 - acc: 0.9892 - val_loss: 0.4684 - val_acc: 0.9222\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9902\n",
      "Epoch 00061: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0313 - acc: 0.9902 - val_loss: 0.4149 - val_acc: 0.9338\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9892\n",
      "Epoch 00062: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0345 - acc: 0.9892 - val_loss: 0.3867 - val_acc: 0.9308\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9904\n",
      "Epoch 00063: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0326 - acc: 0.9904 - val_loss: 0.3914 - val_acc: 0.9336\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9905\n",
      "Epoch 00064: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0299 - acc: 0.9905 - val_loss: 0.4128 - val_acc: 0.9299\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9901\n",
      "Epoch 00065: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0302 - acc: 0.9901 - val_loss: 0.3971 - val_acc: 0.9315\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9896\n",
      "Epoch 00066: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0325 - acc: 0.9896 - val_loss: 0.3965 - val_acc: 0.9362\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0279 - acc: 0.9914\n",
      "Epoch 00067: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0279 - acc: 0.9914 - val_loss: 0.4050 - val_acc: 0.9313\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9926\n",
      "Epoch 00068: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0240 - acc: 0.9926 - val_loss: 0.4371 - val_acc: 0.9324\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9907\n",
      "Epoch 00069: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0329 - acc: 0.9907 - val_loss: 0.3808 - val_acc: 0.9338\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9927\n",
      "Epoch 00070: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0256 - acc: 0.9927 - val_loss: 0.4013 - val_acc: 0.9341\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9916\n",
      "Epoch 00071: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0281 - acc: 0.9916 - val_loss: 0.4964 - val_acc: 0.9262\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9914\n",
      "Epoch 00072: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0277 - acc: 0.9914 - val_loss: 0.4247 - val_acc: 0.9345\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9922\n",
      "Epoch 00073: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0261 - acc: 0.9922 - val_loss: 0.4239 - val_acc: 0.9297\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9914\n",
      "Epoch 00074: val_loss did not improve from 0.30766\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0292 - acc: 0.9914 - val_loss: 0.4232 - val_acc: 0.9369\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.3721 - acc: 0.9011\n",
      "Loss: 0.37210325110986103 Accuracy: 0.90114224\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2670 - acc: 0.2445\n",
      "Epoch 00001: val_loss improved from inf to 1.43495, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/001-1.4349.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 2.2669 - acc: 0.2445 - val_loss: 1.4349 - val_acc: 0.5383\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3307 - acc: 0.5589\n",
      "Epoch 00002: val_loss improved from 1.43495 to 1.04387, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/002-1.0439.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 1.3308 - acc: 0.5588 - val_loss: 1.0439 - val_acc: 0.6625\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9656 - acc: 0.6886\n",
      "Epoch 00003: val_loss improved from 1.04387 to 0.69862, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/003-0.6986.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.9656 - acc: 0.6886 - val_loss: 0.6986 - val_acc: 0.7810\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7290 - acc: 0.7695\n",
      "Epoch 00004: val_loss improved from 0.69862 to 0.48308, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/004-0.4831.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.7290 - acc: 0.7695 - val_loss: 0.4831 - val_acc: 0.8605\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5891 - acc: 0.8139\n",
      "Epoch 00005: val_loss improved from 0.48308 to 0.45857, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/005-0.4586.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.5890 - acc: 0.8139 - val_loss: 0.4586 - val_acc: 0.8619\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4788 - acc: 0.8510\n",
      "Epoch 00006: val_loss improved from 0.45857 to 0.33025, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/006-0.3302.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.4787 - acc: 0.8510 - val_loss: 0.3302 - val_acc: 0.9057\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4101 - acc: 0.8719\n",
      "Epoch 00007: val_loss did not improve from 0.33025\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.4100 - acc: 0.8719 - val_loss: 0.3593 - val_acc: 0.8910\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3578 - acc: 0.8903\n",
      "Epoch 00008: val_loss improved from 0.33025 to 0.29603, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/008-0.2960.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.3578 - acc: 0.8903 - val_loss: 0.2960 - val_acc: 0.9136\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3149 - acc: 0.9048\n",
      "Epoch 00009: val_loss improved from 0.29603 to 0.23972, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/009-0.2397.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.3148 - acc: 0.9048 - val_loss: 0.2397 - val_acc: 0.9322\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2837 - acc: 0.9120\n",
      "Epoch 00010: val_loss improved from 0.23972 to 0.22278, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/010-0.2228.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2837 - acc: 0.9120 - val_loss: 0.2228 - val_acc: 0.9366\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2620 - acc: 0.9179\n",
      "Epoch 00011: val_loss did not improve from 0.22278\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2620 - acc: 0.9179 - val_loss: 0.2338 - val_acc: 0.9390\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2373 - acc: 0.9262\n",
      "Epoch 00012: val_loss improved from 0.22278 to 0.20522, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/012-0.2052.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2372 - acc: 0.9262 - val_loss: 0.2052 - val_acc: 0.9422\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2231 - acc: 0.9305\n",
      "Epoch 00013: val_loss did not improve from 0.20522\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2231 - acc: 0.9305 - val_loss: 0.2215 - val_acc: 0.9350\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2033 - acc: 0.9360\n",
      "Epoch 00014: val_loss improved from 0.20522 to 0.18038, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/014-0.1804.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2032 - acc: 0.9360 - val_loss: 0.1804 - val_acc: 0.9495\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1869 - acc: 0.9423\n",
      "Epoch 00015: val_loss did not improve from 0.18038\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1869 - acc: 0.9423 - val_loss: 0.1915 - val_acc: 0.9441\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9440\n",
      "Epoch 00016: val_loss did not improve from 0.18038\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1752 - acc: 0.9440 - val_loss: 0.2023 - val_acc: 0.9385\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1665 - acc: 0.9470\n",
      "Epoch 00017: val_loss improved from 0.18038 to 0.17664, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/017-0.1766.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1665 - acc: 0.9470 - val_loss: 0.1766 - val_acc: 0.9462\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1536 - acc: 0.9508\n",
      "Epoch 00018: val_loss improved from 0.17664 to 0.17359, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/018-0.1736.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1536 - acc: 0.9508 - val_loss: 0.1736 - val_acc: 0.9490\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9529\n",
      "Epoch 00019: val_loss did not improve from 0.17359\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1424 - acc: 0.9529 - val_loss: 0.1765 - val_acc: 0.9495\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1392 - acc: 0.9548\n",
      "Epoch 00020: val_loss did not improve from 0.17359\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1392 - acc: 0.9548 - val_loss: 0.1758 - val_acc: 0.9522\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9568\n",
      "Epoch 00021: val_loss improved from 0.17359 to 0.17335, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/021-0.1734.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1314 - acc: 0.9569 - val_loss: 0.1734 - val_acc: 0.9536\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9605\n",
      "Epoch 00022: val_loss improved from 0.17335 to 0.16585, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/022-0.1658.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1203 - acc: 0.9605 - val_loss: 0.1658 - val_acc: 0.9527\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9642\n",
      "Epoch 00023: val_loss did not improve from 0.16585\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1083 - acc: 0.9642 - val_loss: 0.1819 - val_acc: 0.9534\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9653\n",
      "Epoch 00024: val_loss did not improve from 0.16585\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1069 - acc: 0.9653 - val_loss: 0.1762 - val_acc: 0.9546\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9657\n",
      "Epoch 00025: val_loss did not improve from 0.16585\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1057 - acc: 0.9657 - val_loss: 0.1760 - val_acc: 0.9532\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9698\n",
      "Epoch 00026: val_loss did not improve from 0.16585\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0932 - acc: 0.9698 - val_loss: 0.1785 - val_acc: 0.9529\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9704\n",
      "Epoch 00027: val_loss did not improve from 0.16585\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0915 - acc: 0.9704 - val_loss: 0.1792 - val_acc: 0.9567\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9720\n",
      "Epoch 00028: val_loss did not improve from 0.16585\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0856 - acc: 0.9720 - val_loss: 0.1843 - val_acc: 0.9506\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9707\n",
      "Epoch 00029: val_loss did not improve from 0.16585\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0872 - acc: 0.9707 - val_loss: 0.1785 - val_acc: 0.9539\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9710\n",
      "Epoch 00030: val_loss improved from 0.16585 to 0.16488, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/030-0.1649.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0820 - acc: 0.9710 - val_loss: 0.1649 - val_acc: 0.9536\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9745\n",
      "Epoch 00031: val_loss did not improve from 0.16488\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0742 - acc: 0.9745 - val_loss: 0.1805 - val_acc: 0.9555\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9764\n",
      "Epoch 00032: val_loss did not improve from 0.16488\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0711 - acc: 0.9764 - val_loss: 0.1685 - val_acc: 0.9550\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9761\n",
      "Epoch 00033: val_loss improved from 0.16488 to 0.15797, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv_checkpoint/033-0.1580.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0711 - acc: 0.9761 - val_loss: 0.1580 - val_acc: 0.9564\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9785\n",
      "Epoch 00034: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0643 - acc: 0.9785 - val_loss: 0.1778 - val_acc: 0.9515\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0627 - acc: 0.9782\n",
      "Epoch 00035: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0627 - acc: 0.9782 - val_loss: 0.1695 - val_acc: 0.9578\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9792\n",
      "Epoch 00036: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0630 - acc: 0.9792 - val_loss: 0.1873 - val_acc: 0.9525\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9798\n",
      "Epoch 00037: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0588 - acc: 0.9798 - val_loss: 0.2024 - val_acc: 0.9474\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9782\n",
      "Epoch 00038: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0670 - acc: 0.9782 - val_loss: 0.1915 - val_acc: 0.9583\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9830\n",
      "Epoch 00039: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0510 - acc: 0.9830 - val_loss: 0.1848 - val_acc: 0.9564\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9831\n",
      "Epoch 00040: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0501 - acc: 0.9831 - val_loss: 0.1998 - val_acc: 0.9571\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9834\n",
      "Epoch 00041: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0507 - acc: 0.9834 - val_loss: 0.1884 - val_acc: 0.9539\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9832\n",
      "Epoch 00042: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0497 - acc: 0.9832 - val_loss: 0.1957 - val_acc: 0.9560\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9850\n",
      "Epoch 00043: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0458 - acc: 0.9850 - val_loss: 0.2187 - val_acc: 0.9504\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9838\n",
      "Epoch 00044: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0483 - acc: 0.9838 - val_loss: 0.1958 - val_acc: 0.9548\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9854\n",
      "Epoch 00045: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0440 - acc: 0.9854 - val_loss: 0.2001 - val_acc: 0.9597\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9836\n",
      "Epoch 00046: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0479 - acc: 0.9836 - val_loss: 0.1848 - val_acc: 0.9557\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9872\n",
      "Epoch 00047: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0395 - acc: 0.9872 - val_loss: 0.1785 - val_acc: 0.9585\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9865\n",
      "Epoch 00048: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0403 - acc: 0.9865 - val_loss: 0.1660 - val_acc: 0.9583\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9874\n",
      "Epoch 00049: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0389 - acc: 0.9874 - val_loss: 0.2552 - val_acc: 0.9504\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9877\n",
      "Epoch 00050: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0382 - acc: 0.9877 - val_loss: 0.1975 - val_acc: 0.9602\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9872\n",
      "Epoch 00051: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0378 - acc: 0.9872 - val_loss: 0.2004 - val_acc: 0.9602\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9872\n",
      "Epoch 00052: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0370 - acc: 0.9872 - val_loss: 0.1945 - val_acc: 0.9560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9881\n",
      "Epoch 00053: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0377 - acc: 0.9881 - val_loss: 0.1903 - val_acc: 0.9571\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9876\n",
      "Epoch 00054: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0372 - acc: 0.9876 - val_loss: 0.1961 - val_acc: 0.9595\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9895\n",
      "Epoch 00055: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0310 - acc: 0.9895 - val_loss: 0.2236 - val_acc: 0.9557\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9879\n",
      "Epoch 00056: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0353 - acc: 0.9879 - val_loss: 0.2001 - val_acc: 0.9616\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9896\n",
      "Epoch 00057: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0312 - acc: 0.9896 - val_loss: 0.2117 - val_acc: 0.9560\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9888\n",
      "Epoch 00058: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0324 - acc: 0.9888 - val_loss: 0.1999 - val_acc: 0.9564\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9890\n",
      "Epoch 00059: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0316 - acc: 0.9890 - val_loss: 0.2219 - val_acc: 0.9581\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9909\n",
      "Epoch 00060: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0298 - acc: 0.9909 - val_loss: 0.2047 - val_acc: 0.9571\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9894\n",
      "Epoch 00061: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0324 - acc: 0.9894 - val_loss: 0.1977 - val_acc: 0.9588\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9906\n",
      "Epoch 00062: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0292 - acc: 0.9906 - val_loss: 0.2100 - val_acc: 0.9592\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9911\n",
      "Epoch 00063: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0276 - acc: 0.9911 - val_loss: 0.2089 - val_acc: 0.9613\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9913\n",
      "Epoch 00064: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0277 - acc: 0.9913 - val_loss: 0.2199 - val_acc: 0.9588\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9913\n",
      "Epoch 00065: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0258 - acc: 0.9913 - val_loss: 0.2062 - val_acc: 0.9592\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9903\n",
      "Epoch 00066: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0297 - acc: 0.9903 - val_loss: 0.1993 - val_acc: 0.9574\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9926\n",
      "Epoch 00067: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0224 - acc: 0.9926 - val_loss: 0.2429 - val_acc: 0.9532\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9905\n",
      "Epoch 00068: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 108s 3ms/sample - loss: 0.0291 - acc: 0.9905 - val_loss: 0.2033 - val_acc: 0.9623\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9904\n",
      "Epoch 00069: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0286 - acc: 0.9904 - val_loss: 0.2570 - val_acc: 0.9518\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9915\n",
      "Epoch 00070: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0259 - acc: 0.9915 - val_loss: 0.2184 - val_acc: 0.9611\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9920\n",
      "Epoch 00071: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0232 - acc: 0.9920 - val_loss: 0.2253 - val_acc: 0.9604\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9931\n",
      "Epoch 00072: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0224 - acc: 0.9931 - val_loss: 0.2447 - val_acc: 0.9588\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9917\n",
      "Epoch 00073: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0257 - acc: 0.9917 - val_loss: 0.2172 - val_acc: 0.9597\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9933\n",
      "Epoch 00074: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0214 - acc: 0.9933 - val_loss: 0.2261 - val_acc: 0.9595\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9924\n",
      "Epoch 00075: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0232 - acc: 0.9924 - val_loss: 0.2299 - val_acc: 0.9602\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9922\n",
      "Epoch 00076: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0248 - acc: 0.9922 - val_loss: 0.2261 - val_acc: 0.9574\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9921\n",
      "Epoch 00077: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0235 - acc: 0.9921 - val_loss: 0.2188 - val_acc: 0.9620\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9940\n",
      "Epoch 00078: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0189 - acc: 0.9940 - val_loss: 0.2312 - val_acc: 0.9623\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9932\n",
      "Epoch 00079: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0206 - acc: 0.9932 - val_loss: 0.2554 - val_acc: 0.9574\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9937\n",
      "Epoch 00080: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0198 - acc: 0.9937 - val_loss: 0.1987 - val_acc: 0.9627\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9939\n",
      "Epoch 00081: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0194 - acc: 0.9939 - val_loss: 0.2325 - val_acc: 0.9581\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9931\n",
      "Epoch 00082: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0208 - acc: 0.9931 - val_loss: 0.2460 - val_acc: 0.9588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9934\n",
      "Epoch 00083: val_loss did not improve from 0.15797\n",
      "36805/36805 [==============================] - 109s 3ms/sample - loss: 0.0207 - acc: 0.9934 - val_loss: 0.2402 - val_acc: 0.9574\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.2035 - acc: 0.9443\n",
      "Loss: 0.2035303854187206 Accuracy: 0.9443406\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4215 - acc: 0.2027\n",
      "Epoch 00001: val_loss improved from inf to 1.67682, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/001-1.6768.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 2.4215 - acc: 0.2027 - val_loss: 1.6768 - val_acc: 0.4619\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2551 - acc: 0.5874\n",
      "Epoch 00002: val_loss improved from 1.67682 to 0.71508, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/002-0.7151.hdf5\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 1.2551 - acc: 0.5874 - val_loss: 0.7151 - val_acc: 0.7806\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7976 - acc: 0.7406\n",
      "Epoch 00003: val_loss improved from 0.71508 to 0.56260, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/003-0.5626.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.7975 - acc: 0.7406 - val_loss: 0.5626 - val_acc: 0.8220\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6168 - acc: 0.7998\n",
      "Epoch 00004: val_loss improved from 0.56260 to 0.46656, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/004-0.4666.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.6169 - acc: 0.7998 - val_loss: 0.4666 - val_acc: 0.8509\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4896 - acc: 0.8417\n",
      "Epoch 00005: val_loss improved from 0.46656 to 0.32809, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/005-0.3281.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.4896 - acc: 0.8417 - val_loss: 0.3281 - val_acc: 0.8947\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4021 - acc: 0.8729\n",
      "Epoch 00006: val_loss improved from 0.32809 to 0.24717, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/006-0.2472.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.4022 - acc: 0.8729 - val_loss: 0.2472 - val_acc: 0.9255\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3375 - acc: 0.8933\n",
      "Epoch 00007: val_loss improved from 0.24717 to 0.21672, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/007-0.2167.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.3375 - acc: 0.8933 - val_loss: 0.2167 - val_acc: 0.9355\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2911 - acc: 0.9086\n",
      "Epoch 00008: val_loss did not improve from 0.21672\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2911 - acc: 0.9086 - val_loss: 0.2323 - val_acc: 0.9301\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2623 - acc: 0.9164\n",
      "Epoch 00009: val_loss improved from 0.21672 to 0.17053, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/009-0.1705.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2623 - acc: 0.9164 - val_loss: 0.1705 - val_acc: 0.9518\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2345 - acc: 0.9255\n",
      "Epoch 00010: val_loss did not improve from 0.17053\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2345 - acc: 0.9256 - val_loss: 0.2093 - val_acc: 0.9380\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2070 - acc: 0.9339\n",
      "Epoch 00011: val_loss improved from 0.17053 to 0.16614, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/011-0.1661.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.2071 - acc: 0.9339 - val_loss: 0.1661 - val_acc: 0.9499\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1874 - acc: 0.9399\n",
      "Epoch 00012: val_loss improved from 0.16614 to 0.16593, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/012-0.1659.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1874 - acc: 0.9399 - val_loss: 0.1659 - val_acc: 0.9490\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9452\n",
      "Epoch 00013: val_loss improved from 0.16593 to 0.14703, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/013-0.1470.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1720 - acc: 0.9453 - val_loss: 0.1470 - val_acc: 0.9527\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9483\n",
      "Epoch 00014: val_loss improved from 0.14703 to 0.13202, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/014-0.1320.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1580 - acc: 0.9483 - val_loss: 0.1320 - val_acc: 0.9595\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1436 - acc: 0.9533\n",
      "Epoch 00015: val_loss improved from 0.13202 to 0.13067, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/015-0.1307.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1437 - acc: 0.9532 - val_loss: 0.1307 - val_acc: 0.9597\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9565\n",
      "Epoch 00016: val_loss improved from 0.13067 to 0.12237, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/016-0.1224.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1362 - acc: 0.9565 - val_loss: 0.1224 - val_acc: 0.9620\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1257 - acc: 0.9586\n",
      "Epoch 00017: val_loss did not improve from 0.12237\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1257 - acc: 0.9586 - val_loss: 0.1303 - val_acc: 0.9609\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9617\n",
      "Epoch 00018: val_loss did not improve from 0.12237\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1159 - acc: 0.9617 - val_loss: 0.1282 - val_acc: 0.9616\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1071 - acc: 0.9639\n",
      "Epoch 00019: val_loss improved from 0.12237 to 0.12151, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/019-0.1215.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1070 - acc: 0.9639 - val_loss: 0.1215 - val_acc: 0.9648\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9663\n",
      "Epoch 00020: val_loss did not improve from 0.12151\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.1041 - acc: 0.9663 - val_loss: 0.1248 - val_acc: 0.9632\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9676\n",
      "Epoch 00021: val_loss did not improve from 0.12151\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0969 - acc: 0.9676 - val_loss: 0.1301 - val_acc: 0.9660\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9690\n",
      "Epoch 00022: val_loss improved from 0.12151 to 0.11983, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/022-0.1198.hdf5\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0922 - acc: 0.9691 - val_loss: 0.1198 - val_acc: 0.9660\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9709\n",
      "Epoch 00023: val_loss improved from 0.11983 to 0.10445, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv_checkpoint/023-0.1044.hdf5\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0880 - acc: 0.9709 - val_loss: 0.1044 - val_acc: 0.9706\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9724\n",
      "Epoch 00024: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0797 - acc: 0.9724 - val_loss: 0.1124 - val_acc: 0.9697\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9751\n",
      "Epoch 00025: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0743 - acc: 0.9751 - val_loss: 0.1329 - val_acc: 0.9655\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9755\n",
      "Epoch 00026: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0737 - acc: 0.9755 - val_loss: 0.1089 - val_acc: 0.9690\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9764\n",
      "Epoch 00027: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0707 - acc: 0.9764 - val_loss: 0.1172 - val_acc: 0.9686\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9777\n",
      "Epoch 00028: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0669 - acc: 0.9777 - val_loss: 0.1079 - val_acc: 0.9695\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9793\n",
      "Epoch 00029: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0617 - acc: 0.9793 - val_loss: 0.1299 - val_acc: 0.9639\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9807\n",
      "Epoch 00030: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0579 - acc: 0.9807 - val_loss: 0.1524 - val_acc: 0.9613\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0563 - acc: 0.9806\n",
      "Epoch 00031: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0563 - acc: 0.9806 - val_loss: 0.1117 - val_acc: 0.9683\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9824\n",
      "Epoch 00032: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0537 - acc: 0.9824 - val_loss: 0.1087 - val_acc: 0.9702\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9830\n",
      "Epoch 00033: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0494 - acc: 0.9830 - val_loss: 0.1212 - val_acc: 0.9676\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9827\n",
      "Epoch 00034: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0491 - acc: 0.9827 - val_loss: 0.1234 - val_acc: 0.9658\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9822\n",
      "Epoch 00035: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0538 - acc: 0.9822 - val_loss: 0.1278 - val_acc: 0.9674\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9846\n",
      "Epoch 00036: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0449 - acc: 0.9846 - val_loss: 0.1433 - val_acc: 0.9620\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9843\n",
      "Epoch 00037: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0454 - acc: 0.9843 - val_loss: 0.1343 - val_acc: 0.9639\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9866\n",
      "Epoch 00038: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0416 - acc: 0.9866 - val_loss: 0.1335 - val_acc: 0.9667\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9868\n",
      "Epoch 00039: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0401 - acc: 0.9868 - val_loss: 0.1285 - val_acc: 0.9709\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9842\n",
      "Epoch 00040: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0478 - acc: 0.9842 - val_loss: 0.1232 - val_acc: 0.9706\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9884\n",
      "Epoch 00041: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0340 - acc: 0.9884 - val_loss: 0.1392 - val_acc: 0.9688\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9876\n",
      "Epoch 00042: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0369 - acc: 0.9876 - val_loss: 0.1118 - val_acc: 0.9713\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9879\n",
      "Epoch 00043: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0376 - acc: 0.9879 - val_loss: 0.1565 - val_acc: 0.9653\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0373 - acc: 0.9873\n",
      "Epoch 00044: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0373 - acc: 0.9873 - val_loss: 0.1338 - val_acc: 0.9693\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9884\n",
      "Epoch 00045: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0353 - acc: 0.9884 - val_loss: 0.1419 - val_acc: 0.9683\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9888\n",
      "Epoch 00046: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0334 - acc: 0.9888 - val_loss: 0.1482 - val_acc: 0.9683\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9890\n",
      "Epoch 00047: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0346 - acc: 0.9890 - val_loss: 0.1294 - val_acc: 0.9706\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9904\n",
      "Epoch 00048: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0297 - acc: 0.9904 - val_loss: 0.1334 - val_acc: 0.9644\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9898\n",
      "Epoch 00049: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0322 - acc: 0.9898 - val_loss: 0.1319 - val_acc: 0.9716\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9913\n",
      "Epoch 00050: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0285 - acc: 0.9913 - val_loss: 0.1244 - val_acc: 0.9688\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9904\n",
      "Epoch 00051: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0288 - acc: 0.9904 - val_loss: 0.1226 - val_acc: 0.9693\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9898\n",
      "Epoch 00052: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0317 - acc: 0.9898 - val_loss: 0.1431 - val_acc: 0.9669\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9915\n",
      "Epoch 00053: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0252 - acc: 0.9915 - val_loss: 0.1605 - val_acc: 0.9644\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9912\n",
      "Epoch 00054: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0265 - acc: 0.9913 - val_loss: 0.1489 - val_acc: 0.9665\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9914\n",
      "Epoch 00055: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0276 - acc: 0.9914 - val_loss: 0.1407 - val_acc: 0.9702\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9920\n",
      "Epoch 00056: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0237 - acc: 0.9920 - val_loss: 0.1321 - val_acc: 0.9718\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9915\n",
      "Epoch 00057: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0262 - acc: 0.9915 - val_loss: 0.1511 - val_acc: 0.9669\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9927\n",
      "Epoch 00058: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0224 - acc: 0.9927 - val_loss: 0.1706 - val_acc: 0.9686\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9914\n",
      "Epoch 00059: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0266 - acc: 0.9914 - val_loss: 0.1196 - val_acc: 0.9693\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9919\n",
      "Epoch 00060: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0250 - acc: 0.9919 - val_loss: 0.1260 - val_acc: 0.9720\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9936\n",
      "Epoch 00061: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0193 - acc: 0.9936 - val_loss: 0.1312 - val_acc: 0.9727\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9926\n",
      "Epoch 00062: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0236 - acc: 0.9926 - val_loss: 0.1490 - val_acc: 0.9709\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9924\n",
      "Epoch 00063: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0253 - acc: 0.9924 - val_loss: 0.1467 - val_acc: 0.9706\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0305 - acc: 0.9905\n",
      "Epoch 00064: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0305 - acc: 0.9905 - val_loss: 0.1677 - val_acc: 0.9641\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9940\n",
      "Epoch 00065: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0196 - acc: 0.9940 - val_loss: 0.1349 - val_acc: 0.9681\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9932\n",
      "Epoch 00066: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0198 - acc: 0.9932 - val_loss: 0.1541 - val_acc: 0.9676\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9948\n",
      "Epoch 00067: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0170 - acc: 0.9948 - val_loss: 0.1574 - val_acc: 0.9683\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9943\n",
      "Epoch 00068: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0175 - acc: 0.9943 - val_loss: 0.1453 - val_acc: 0.9732\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9940\n",
      "Epoch 00069: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0200 - acc: 0.9940 - val_loss: 0.1625 - val_acc: 0.9681\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9939\n",
      "Epoch 00070: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0196 - acc: 0.9939 - val_loss: 0.1555 - val_acc: 0.9727\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9940\n",
      "Epoch 00071: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0192 - acc: 0.9940 - val_loss: 0.1571 - val_acc: 0.9695\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9946\n",
      "Epoch 00072: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0176 - acc: 0.9946 - val_loss: 0.1473 - val_acc: 0.9720\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9937\n",
      "Epoch 00073: val_loss did not improve from 0.10445\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0180 - acc: 0.9937 - val_loss: 0.1386 - val_acc: 0.9706\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.1582 - acc: 0.9570\n",
      "Loss: 0.15822456661584716 Accuracy: 0.9570094\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0728 - acc: 0.3237\n",
      "Epoch 00001: val_loss improved from inf to 1.19666, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv_checkpoint/001-1.1967.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 2.0727 - acc: 0.3238 - val_loss: 1.1967 - val_acc: 0.6245\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9728 - acc: 0.6819\n",
      "Epoch 00002: val_loss improved from 1.19666 to 0.60869, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv_checkpoint/002-0.6087.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.9728 - acc: 0.6819 - val_loss: 0.6087 - val_acc: 0.7973\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5852 - acc: 0.8111\n",
      "Epoch 00003: val_loss improved from 0.60869 to 0.37249, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv_checkpoint/003-0.3725.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.5852 - acc: 0.8111 - val_loss: 0.3725 - val_acc: 0.8819\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4194 - acc: 0.8662\n",
      "Epoch 00004: val_loss improved from 0.37249 to 0.28885, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv_checkpoint/004-0.2889.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4194 - acc: 0.8662 - val_loss: 0.2889 - val_acc: 0.9073\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3398 - acc: 0.8907\n",
      "Epoch 00005: val_loss improved from 0.28885 to 0.27497, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv_checkpoint/005-0.2750.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3398 - acc: 0.8907 - val_loss: 0.2750 - val_acc: 0.9122\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2777 - acc: 0.9115\n",
      "Epoch 00006: val_loss improved from 0.27497 to 0.20488, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv_checkpoint/006-0.2049.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.2777 - acc: 0.9115 - val_loss: 0.2049 - val_acc: 0.9371\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2356 - acc: 0.9244\n",
      "Epoch 00007: val_loss improved from 0.20488 to 0.20106, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv_checkpoint/007-0.2011.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.2356 - acc: 0.9244 - val_loss: 0.2011 - val_acc: 0.9376\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2059 - acc: 0.9326\n",
      "Epoch 00008: val_loss did not improve from 0.20106\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.2059 - acc: 0.9326 - val_loss: 0.2083 - val_acc: 0.9366\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1788 - acc: 0.9418\n",
      "Epoch 00009: val_loss improved from 0.20106 to 0.17522, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv_checkpoint/009-0.1752.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1789 - acc: 0.9417 - val_loss: 0.1752 - val_acc: 0.9499\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9473\n",
      "Epoch 00010: val_loss improved from 0.17522 to 0.17508, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv_checkpoint/010-0.1751.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1644 - acc: 0.9473 - val_loss: 0.1751 - val_acc: 0.9490\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9543\n",
      "Epoch 00011: val_loss improved from 0.17508 to 0.13756, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv_checkpoint/011-0.1376.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1390 - acc: 0.9543 - val_loss: 0.1376 - val_acc: 0.9536\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9577\n",
      "Epoch 00012: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1252 - acc: 0.9577 - val_loss: 0.1953 - val_acc: 0.9415\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1247 - acc: 0.9596\n",
      "Epoch 00013: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.1247 - acc: 0.9596 - val_loss: 0.1852 - val_acc: 0.9436\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9656\n",
      "Epoch 00014: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1066 - acc: 0.9656 - val_loss: 0.1575 - val_acc: 0.9532\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0983 - acc: 0.9677\n",
      "Epoch 00015: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0983 - acc: 0.9677 - val_loss: 0.1488 - val_acc: 0.9555\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9714\n",
      "Epoch 00016: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0870 - acc: 0.9714 - val_loss: 0.1631 - val_acc: 0.9555\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9720\n",
      "Epoch 00017: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0846 - acc: 0.9720 - val_loss: 0.1543 - val_acc: 0.9567\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9754\n",
      "Epoch 00018: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0726 - acc: 0.9754 - val_loss: 0.1631 - val_acc: 0.9550\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9744\n",
      "Epoch 00019: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0747 - acc: 0.9744 - val_loss: 0.1753 - val_acc: 0.9553\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9781\n",
      "Epoch 00020: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0642 - acc: 0.9781 - val_loss: 0.1500 - val_acc: 0.9602\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9795\n",
      "Epoch 00021: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0606 - acc: 0.9795 - val_loss: 0.1572 - val_acc: 0.9588\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9811\n",
      "Epoch 00022: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0591 - acc: 0.9810 - val_loss: 0.1392 - val_acc: 0.9620\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9821\n",
      "Epoch 00023: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0555 - acc: 0.9821 - val_loss: 0.1412 - val_acc: 0.9616\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9844\n",
      "Epoch 00024: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0483 - acc: 0.9844 - val_loss: 0.1780 - val_acc: 0.9560\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9836\n",
      "Epoch 00025: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0499 - acc: 0.9836 - val_loss: 0.1897 - val_acc: 0.9569\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9821\n",
      "Epoch 00026: val_loss did not improve from 0.13756\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0547 - acc: 0.9821 - val_loss: 0.1487 - val_acc: 0.9658\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9870\n",
      "Epoch 00027: val_loss improved from 0.13756 to 0.13588, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv_checkpoint/027-0.1359.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0405 - acc: 0.9870 - val_loss: 0.1359 - val_acc: 0.9669\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9873\n",
      "Epoch 00028: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0392 - acc: 0.9873 - val_loss: 0.1895 - val_acc: 0.9585\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9854\n",
      "Epoch 00029: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0455 - acc: 0.9854 - val_loss: 0.1561 - val_acc: 0.9627\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9883\n",
      "Epoch 00030: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0385 - acc: 0.9883 - val_loss: 0.1865 - val_acc: 0.9595\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9876\n",
      "Epoch 00031: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0390 - acc: 0.9876 - val_loss: 0.1472 - val_acc: 0.9632\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9893\n",
      "Epoch 00032: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0333 - acc: 0.9893 - val_loss: 0.1566 - val_acc: 0.9672\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9891\n",
      "Epoch 00033: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0365 - acc: 0.9891 - val_loss: 0.1596 - val_acc: 0.9639\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9881\n",
      "Epoch 00034: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0367 - acc: 0.9881 - val_loss: 0.1887 - val_acc: 0.9592\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9903\n",
      "Epoch 00035: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0314 - acc: 0.9903 - val_loss: 0.1625 - val_acc: 0.9611\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9915\n",
      "Epoch 00036: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0289 - acc: 0.9916 - val_loss: 0.1663 - val_acc: 0.9630\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9912\n",
      "Epoch 00037: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0282 - acc: 0.9913 - val_loss: 0.1945 - val_acc: 0.9616\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9904\n",
      "Epoch 00038: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0307 - acc: 0.9904 - val_loss: 0.2031 - val_acc: 0.9567\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9925\n",
      "Epoch 00039: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0252 - acc: 0.9925 - val_loss: 0.1863 - val_acc: 0.9632\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9921\n",
      "Epoch 00040: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0250 - acc: 0.9921 - val_loss: 0.2186 - val_acc: 0.9632\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9925\n",
      "Epoch 00041: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0250 - acc: 0.9924 - val_loss: 0.2063 - val_acc: 0.9623\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9888\n",
      "Epoch 00042: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0365 - acc: 0.9888 - val_loss: 0.1850 - val_acc: 0.9613\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9929\n",
      "Epoch 00043: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0223 - acc: 0.9929 - val_loss: 0.1503 - val_acc: 0.9693\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9931\n",
      "Epoch 00044: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0222 - acc: 0.9931 - val_loss: 0.1463 - val_acc: 0.9665\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9926\n",
      "Epoch 00045: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0244 - acc: 0.9926 - val_loss: 0.1609 - val_acc: 0.9693\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9934\n",
      "Epoch 00046: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0207 - acc: 0.9934 - val_loss: 0.1718 - val_acc: 0.9653\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9946\n",
      "Epoch 00047: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0171 - acc: 0.9946 - val_loss: 0.1857 - val_acc: 0.9613\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9927\n",
      "Epoch 00048: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0216 - acc: 0.9927 - val_loss: 0.2405 - val_acc: 0.9590\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9930\n",
      "Epoch 00049: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0232 - acc: 0.9930 - val_loss: 0.1863 - val_acc: 0.9611\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9940\n",
      "Epoch 00050: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0192 - acc: 0.9940 - val_loss: 0.2041 - val_acc: 0.9583\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9935\n",
      "Epoch 00051: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0201 - acc: 0.9935 - val_loss: 0.1695 - val_acc: 0.9658\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9944\n",
      "Epoch 00052: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0178 - acc: 0.9944 - val_loss: 0.2136 - val_acc: 0.9616\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9943\n",
      "Epoch 00053: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0168 - acc: 0.9943 - val_loss: 0.1973 - val_acc: 0.9627\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9947\n",
      "Epoch 00054: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0174 - acc: 0.9947 - val_loss: 0.1957 - val_acc: 0.9620\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9948\n",
      "Epoch 00055: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0174 - acc: 0.9948 - val_loss: 0.2046 - val_acc: 0.9585\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9940\n",
      "Epoch 00056: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0191 - acc: 0.9940 - val_loss: 0.1483 - val_acc: 0.9695\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9950\n",
      "Epoch 00057: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0170 - acc: 0.9950 - val_loss: 0.2202 - val_acc: 0.9630\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9945\n",
      "Epoch 00058: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0184 - acc: 0.9945 - val_loss: 0.1518 - val_acc: 0.9669\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9940\n",
      "Epoch 00059: val_loss did not improve from 0.13588\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0192 - acc: 0.9940 - val_loss: 0.1625 - val_acc: 0.9665\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9956\n",
      "Epoch 00060: val_loss improved from 0.13588 to 0.12759, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv_checkpoint/060-0.1276.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0156 - acc: 0.9956 - val_loss: 0.1276 - val_acc: 0.9690\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9955\n",
      "Epoch 00061: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0135 - acc: 0.9955 - val_loss: 0.1746 - val_acc: 0.9674\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9955\n",
      "Epoch 00062: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0155 - acc: 0.9955 - val_loss: 0.1653 - val_acc: 0.9688\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9958\n",
      "Epoch 00063: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0134 - acc: 0.9958 - val_loss: 0.1686 - val_acc: 0.9690\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9946\n",
      "Epoch 00064: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0189 - acc: 0.9946 - val_loss: 0.1663 - val_acc: 0.9630\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9962\n",
      "Epoch 00065: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0118 - acc: 0.9963 - val_loss: 0.1688 - val_acc: 0.9655\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9956\n",
      "Epoch 00066: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0141 - acc: 0.9956 - val_loss: 0.1807 - val_acc: 0.9686\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9964\n",
      "Epoch 00067: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0117 - acc: 0.9964 - val_loss: 0.2094 - val_acc: 0.9634\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9950\n",
      "Epoch 00068: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0168 - acc: 0.9950 - val_loss: 0.1539 - val_acc: 0.9674\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9960\n",
      "Epoch 00069: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0132 - acc: 0.9960 - val_loss: 0.1516 - val_acc: 0.9683\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9961\n",
      "Epoch 00070: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0139 - acc: 0.9961 - val_loss: 0.1982 - val_acc: 0.9641\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9967\n",
      "Epoch 00071: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0114 - acc: 0.9967 - val_loss: 0.1757 - val_acc: 0.9681\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9963\n",
      "Epoch 00072: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0123 - acc: 0.9963 - val_loss: 0.1870 - val_acc: 0.9674\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9955\n",
      "Epoch 00073: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0162 - acc: 0.9955 - val_loss: 0.1774 - val_acc: 0.9637\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9958\n",
      "Epoch 00074: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0139 - acc: 0.9958 - val_loss: 0.1877 - val_acc: 0.9609\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9967\n",
      "Epoch 00075: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0112 - acc: 0.9967 - val_loss: 0.1973 - val_acc: 0.9648\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9972\n",
      "Epoch 00076: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0095 - acc: 0.9972 - val_loss: 0.1944 - val_acc: 0.9672\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9963\n",
      "Epoch 00077: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0124 - acc: 0.9963 - val_loss: 0.2038 - val_acc: 0.9672\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9960\n",
      "Epoch 00078: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0135 - acc: 0.9960 - val_loss: 0.1809 - val_acc: 0.9676\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9956\n",
      "Epoch 00079: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0133 - acc: 0.9956 - val_loss: 0.1643 - val_acc: 0.9716\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9970\n",
      "Epoch 00080: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0104 - acc: 0.9970 - val_loss: 0.1893 - val_acc: 0.9674\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9967\n",
      "Epoch 00081: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0103 - acc: 0.9967 - val_loss: 0.1963 - val_acc: 0.9665\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9956\n",
      "Epoch 00082: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0149 - acc: 0.9956 - val_loss: 0.1503 - val_acc: 0.9693\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9980\n",
      "Epoch 00083: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0068 - acc: 0.9980 - val_loss: 0.1765 - val_acc: 0.9672\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9961\n",
      "Epoch 00084: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 111s 3ms/sample - loss: 0.0122 - acc: 0.9961 - val_loss: 0.2033 - val_acc: 0.9632\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9966\n",
      "Epoch 00085: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0119 - acc: 0.9966 - val_loss: 0.1824 - val_acc: 0.9695\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9965\n",
      "Epoch 00086: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0127 - acc: 0.9965 - val_loss: 0.1681 - val_acc: 0.9674\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9976\n",
      "Epoch 00087: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0090 - acc: 0.9976 - val_loss: 0.2481 - val_acc: 0.9606\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9961\n",
      "Epoch 00088: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0129 - acc: 0.9961 - val_loss: 0.2060 - val_acc: 0.9583\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9965\n",
      "Epoch 00089: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0120 - acc: 0.9965 - val_loss: 0.1663 - val_acc: 0.9676\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9977\n",
      "Epoch 00090: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0084 - acc: 0.9977 - val_loss: 0.1831 - val_acc: 0.9651\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9966\n",
      "Epoch 00091: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0126 - acc: 0.9966 - val_loss: 0.1719 - val_acc: 0.9667\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9983\n",
      "Epoch 00092: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0063 - acc: 0.9983 - val_loss: 0.1934 - val_acc: 0.9653\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9971\n",
      "Epoch 00093: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0114 - acc: 0.9971 - val_loss: 0.1866 - val_acc: 0.9676\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9968\n",
      "Epoch 00094: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0108 - acc: 0.9968 - val_loss: 0.1850 - val_acc: 0.9665\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9978\n",
      "Epoch 00095: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0077 - acc: 0.9978 - val_loss: 0.2189 - val_acc: 0.9648\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9963\n",
      "Epoch 00096: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0118 - acc: 0.9963 - val_loss: 0.1951 - val_acc: 0.9648\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9976\n",
      "Epoch 00097: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0072 - acc: 0.9976 - val_loss: 0.2069 - val_acc: 0.9660\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9966\n",
      "Epoch 00098: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0117 - acc: 0.9966 - val_loss: 0.1716 - val_acc: 0.9665\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9984\n",
      "Epoch 00099: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0064 - acc: 0.9984 - val_loss: 0.2202 - val_acc: 0.9637\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9967\n",
      "Epoch 00100: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0126 - acc: 0.9967 - val_loss: 0.1646 - val_acc: 0.9683\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9976\n",
      "Epoch 00101: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0079 - acc: 0.9976 - val_loss: 0.1934 - val_acc: 0.9660\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9969\n",
      "Epoch 00102: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0108 - acc: 0.9969 - val_loss: 0.1835 - val_acc: 0.9695\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9974\n",
      "Epoch 00103: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0100 - acc: 0.9974 - val_loss: 0.1824 - val_acc: 0.9695\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0061 - acc: 0.9985\n",
      "Epoch 00104: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0061 - acc: 0.9985 - val_loss: 0.1886 - val_acc: 0.9676\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9981\n",
      "Epoch 00105: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0063 - acc: 0.9981 - val_loss: 0.2157 - val_acc: 0.9665\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9976\n",
      "Epoch 00106: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0077 - acc: 0.9976 - val_loss: 0.1999 - val_acc: 0.9706\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9965\n",
      "Epoch 00107: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0118 - acc: 0.9965 - val_loss: 0.1913 - val_acc: 0.9690\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9980\n",
      "Epoch 00108: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0067 - acc: 0.9980 - val_loss: 0.1961 - val_acc: 0.9674\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9975\n",
      "Epoch 00109: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0089 - acc: 0.9975 - val_loss: 0.1986 - val_acc: 0.9639\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9963\n",
      "Epoch 00110: val_loss did not improve from 0.12759\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 0.0123 - acc: 0.9963 - val_loss: 0.1753 - val_acc: 0.9669\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.2249 - acc: 0.9549\n",
      "Loss: 0.22492090308500082 Accuracy: 0.9549325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_conv_3_VGG_ch_128_DO'\n",
    "    \n",
    "for i in range(4, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO(conv_num=i)\n",
    "        \n",
    "    model = multi_gpu_model(model, gpus=2)\n",
    "    \n",
    "    #         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_90_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 16000, 1)     0           conv1d_90_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16000, 1)     0           conv1d_90_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 16)           1557904     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Concatenate)           (None, 16)           0           sequential_9[1][0]               \n",
      "                                                                 sequential_9[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,557,904\n",
      "Trainable params: 1,557,904\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 1.0946 - acc: 0.6825\n",
      "Loss: 1.094621503080782 Accuracy: 0.68245065\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_98_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16000, 1)     0           conv1d_98_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 16000, 1)     0           conv1d_98_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 16)           1447824     lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Concatenate)          (None, 16)           0           sequential_10[1][0]              \n",
      "                                                                 sequential_10[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,447,824\n",
      "Trainable params: 1,447,824\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.7625 - acc: 0.7769\n",
      "Loss: 0.7625076849760173 Accuracy: 0.776947\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_108_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 16000, 1)     0           conv1d_108_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16000, 1)     0           conv1d_108_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 16)           1300880     lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Concatenate)          (None, 16)           0           sequential_11[1][0]              \n",
      "                                                                 sequential_11[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,300,880\n",
      "Trainable params: 1,300,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 3ms/sample - loss: 0.3721 - acc: 0.9011\n",
      "Loss: 0.37210325110986103 Accuracy: 0.90114224\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_120_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 16000, 1)     0           conv1d_120_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 16000, 1)     0           conv1d_120_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 16)           1514384     lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Concatenate)          (None, 16)           0           sequential_12[1][0]              \n",
      "                                                                 sequential_12[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,514,384\n",
      "Trainable params: 1,514,384\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 3ms/sample - loss: 0.2035 - acc: 0.9443\n",
      "Loss: 0.2035303854187206 Accuracy: 0.9443406\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_134_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 16000, 1)     0           conv1d_134_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 16000, 1)     0           conv1d_134_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 16)           1850768     lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Concatenate)          (None, 16)           0           sequential_13[1][0]              \n",
      "                                                                 sequential_13[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,850,768\n",
      "Trainable params: 1,850,768\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.1582 - acc: 0.9570\n",
      "Loss: 0.15822456661584716 Accuracy: 0.9570094\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_150_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 16000, 1)     0           conv1d_150_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 16000, 1)     0           conv1d_150_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_14 (Sequential)      (None, 16)           3019152     lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Concatenate)          (None, 16)           0           sequential_14[1][0]              \n",
      "                                                                 sequential_14[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,019,152\n",
      "Trainable params: 3,019,152\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.2249 - acc: 0.9549\n",
      "Loss: 0.22492090308500082 Accuracy: 0.9549325\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_ch_128_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(4, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_90_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 16000, 1)     0           conv1d_90_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16000, 1)     0           conv1d_90_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 16)           1557904     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Concatenate)           (None, 16)           0           sequential_9[1][0]               \n",
      "                                                                 sequential_9[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,557,904\n",
      "Trainable params: 1,557,904\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 1.6203 - acc: 0.7256\n",
      "Loss: 1.6202878656664617 Accuracy: 0.725649\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_98_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16000, 1)     0           conv1d_98_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 16000, 1)     0           conv1d_98_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 16)           1447824     lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Concatenate)          (None, 16)           0           sequential_10[1][0]              \n",
      "                                                                 sequential_10[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,447,824\n",
      "Trainable params: 1,447,824\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 3ms/sample - loss: 1.1479 - acc: 0.8139\n",
      "Loss: 1.1479153065419023 Accuracy: 0.81391484\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_108_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 16000, 1)     0           conv1d_108_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16000, 1)     0           conv1d_108_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 16)           1300880     lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Concatenate)          (None, 16)           0           sequential_11[1][0]              \n",
      "                                                                 sequential_11[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,300,880\n",
      "Trainable params: 1,300,880\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.4882 - acc: 0.9113\n",
      "Loss: 0.48815303007498584 Accuracy: 0.9113188\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_120_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 16000, 1)     0           conv1d_120_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 16000, 1)     0           conv1d_120_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 16)           1514384     lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Concatenate)          (None, 16)           0           sequential_12[1][0]              \n",
      "                                                                 sequential_12[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,514,384\n",
      "Trainable params: 1,514,384\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.2327 - acc: 0.9566\n",
      "Loss: 0.23273621863489227 Accuracy: 0.956594\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_134_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 16000, 1)     0           conv1d_134_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 16000, 1)     0           conv1d_134_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 16)           1850768     lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Concatenate)          (None, 16)           0           sequential_13[1][0]              \n",
      "                                                                 sequential_13[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,850,768\n",
      "Trainable params: 1,850,768\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 13s 3ms/sample - loss: 0.1911 - acc: 0.9622\n",
      "Loss: 0.19111805012529948 Accuracy: 0.9622015\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_ch_128_DO_9_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_150_input (InputLayer)   (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 16000, 1)     0           conv1d_150_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 16000, 1)     0           conv1d_150_input[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "sequential_14 (Sequential)      (None, 16)           3019152     lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Concatenate)          (None, 16)           0           sequential_14[1][0]              \n",
      "                                                                 sequential_14[2][0]              \n",
      "==================================================================================================\n",
      "Total params: 3,019,152\n",
      "Trainable params: 3,019,152\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 14s 3ms/sample - loss: 0.2279 - acc: 0.9587\n",
      "Loss: 0.22788542348278049 Accuracy: 0.9586708\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(4, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
