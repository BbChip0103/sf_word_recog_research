{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=2, strides=2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                4096016   \n",
      "=================================================================\n",
      "Total params: 4,138,256\n",
      "Trainable params: 4,137,872\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,111,056\n",
      "Trainable params: 2,110,544\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,152,656\n",
      "Trainable params: 2,151,888\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,211,216\n",
      "Trainable params: 1,210,192\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 781,776\n",
      "Trainable params: 780,496\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 608,336\n",
      "Trainable params: 606,800\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                253968    \n",
      "=================================================================\n",
      "Total params: 771,408\n",
      "Trainable params: 769,360\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 973,392\n",
      "Trainable params: 970,832\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                61456     \n",
      "=================================================================\n",
      "Total params: 1,236,816\n",
      "Trainable params: 1,233,744\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 15, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,533,008\n",
      "Trainable params: 1,529,424\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_72 (MaxPooling (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_73 (MaxPooling (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_74 (MaxPooling (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 15, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_75 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 7, 512)            2048      \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_76 (MaxPooling (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                24592     \n",
      "=================================================================\n",
      "Total params: 2,186,832\n",
      "Trainable params: 2,182,224\n",
      "Non-trainable params: 4,608\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 14):\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.8980 - acc: 0.3338\n",
      "Epoch 00001: val_loss improved from inf to 2.87125, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_3_conv_checkpoint/001-2.8713.hdf5\n",
      "36805/36805 [==============================] - 95s 3ms/sample - loss: 2.8981 - acc: 0.3337 - val_loss: 2.8713 - val_acc: 0.2956\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9906 - acc: 0.5322\n",
      "Epoch 00002: val_loss improved from 2.87125 to 2.39675, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_3_conv_checkpoint/002-2.3967.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.9904 - acc: 0.5322 - val_loss: 2.3967 - val_acc: 0.4435\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5874 - acc: 0.6396\n",
      "Epoch 00003: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.5875 - acc: 0.6396 - val_loss: 2.9385 - val_acc: 0.3785\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2778 - acc: 0.7284\n",
      "Epoch 00004: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.2777 - acc: 0.7284 - val_loss: 2.9785 - val_acc: 0.4207\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0540 - acc: 0.7951\n",
      "Epoch 00005: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.0544 - acc: 0.7950 - val_loss: 3.0746 - val_acc: 0.4426\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9569 - acc: 0.8276\n",
      "Epoch 00006: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9568 - acc: 0.8276 - val_loss: 2.9522 - val_acc: 0.4626\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8638 - acc: 0.8568\n",
      "Epoch 00007: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8642 - acc: 0.8568 - val_loss: 3.3106 - val_acc: 0.4302\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8074 - acc: 0.8751\n",
      "Epoch 00008: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8074 - acc: 0.8751 - val_loss: 3.0046 - val_acc: 0.4959\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7730 - acc: 0.8876\n",
      "Epoch 00009: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7729 - acc: 0.8877 - val_loss: 2.8567 - val_acc: 0.5069\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7438 - acc: 0.8959\n",
      "Epoch 00010: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7437 - acc: 0.8959 - val_loss: 2.8057 - val_acc: 0.5262\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7309 - acc: 0.9018\n",
      "Epoch 00011: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.7313 - acc: 0.9018 - val_loss: 3.2221 - val_acc: 0.4708\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7226 - acc: 0.9052\n",
      "Epoch 00012: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7226 - acc: 0.9051 - val_loss: 3.5501 - val_acc: 0.4724\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7125 - acc: 0.9084\n",
      "Epoch 00013: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7124 - acc: 0.9084 - val_loss: 4.3670 - val_acc: 0.4125\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6877 - acc: 0.9166\n",
      "Epoch 00014: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6877 - acc: 0.9166 - val_loss: 3.2595 - val_acc: 0.5115\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6782 - acc: 0.9198\n",
      "Epoch 00015: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6786 - acc: 0.9198 - val_loss: 3.4449 - val_acc: 0.4973\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6739 - acc: 0.9208\n",
      "Epoch 00016: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6738 - acc: 0.9207 - val_loss: 3.4540 - val_acc: 0.4964\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6668 - acc: 0.9230\n",
      "Epoch 00017: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6672 - acc: 0.9230 - val_loss: 3.7164 - val_acc: 0.4966\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6628 - acc: 0.9240\n",
      "Epoch 00018: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6627 - acc: 0.9240 - val_loss: 4.2956 - val_acc: 0.4566\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6419 - acc: 0.9312\n",
      "Epoch 00019: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6418 - acc: 0.9312 - val_loss: 3.7083 - val_acc: 0.5034\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6389 - acc: 0.9318\n",
      "Epoch 00020: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6393 - acc: 0.9318 - val_loss: 3.9710 - val_acc: 0.4927\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6366 - acc: 0.9339\n",
      "Epoch 00021: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6367 - acc: 0.9338 - val_loss: 3.6008 - val_acc: 0.5024\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6430 - acc: 0.9314\n",
      "Epoch 00022: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6429 - acc: 0.9314 - val_loss: 4.0060 - val_acc: 0.4929\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6251 - acc: 0.9356\n",
      "Epoch 00023: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6255 - acc: 0.9356 - val_loss: 3.3259 - val_acc: 0.5339\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6110 - acc: 0.9401\n",
      "Epoch 00024: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6111 - acc: 0.9401 - val_loss: 3.7704 - val_acc: 0.5020\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6341 - acc: 0.9344\n",
      "Epoch 00025: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6341 - acc: 0.9344 - val_loss: 3.9027 - val_acc: 0.4976\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6284 - acc: 0.9375\n",
      "Epoch 00026: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6283 - acc: 0.9375 - val_loss: 3.5536 - val_acc: 0.5211\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6009 - acc: 0.9450\n",
      "Epoch 00027: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6008 - acc: 0.9450 - val_loss: 3.9791 - val_acc: 0.5064\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6125 - acc: 0.9410\n",
      "Epoch 00028: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6126 - acc: 0.9410 - val_loss: 3.5338 - val_acc: 0.5318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6102 - acc: 0.9420\n",
      "Epoch 00029: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6101 - acc: 0.9420 - val_loss: 3.9890 - val_acc: 0.5155\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6120 - acc: 0.9427\n",
      "Epoch 00030: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6119 - acc: 0.9428 - val_loss: 4.0366 - val_acc: 0.5064\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6066 - acc: 0.9434\n",
      "Epoch 00031: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6065 - acc: 0.9434 - val_loss: 3.8892 - val_acc: 0.5176\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6042 - acc: 0.9443\n",
      "Epoch 00032: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6041 - acc: 0.9443 - val_loss: 4.2435 - val_acc: 0.5038\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5949 - acc: 0.9466\n",
      "Epoch 00033: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5948 - acc: 0.9466 - val_loss: 3.9139 - val_acc: 0.5199\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6012 - acc: 0.9449\n",
      "Epoch 00034: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6012 - acc: 0.9448 - val_loss: 4.0043 - val_acc: 0.5299\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6085 - acc: 0.9440\n",
      "Epoch 00035: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.6084 - acc: 0.9441 - val_loss: 4.1756 - val_acc: 0.4866\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5854 - acc: 0.9495\n",
      "Epoch 00036: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.5853 - acc: 0.9495 - val_loss: 3.6621 - val_acc: 0.5439\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5842 - acc: 0.9494\n",
      "Epoch 00037: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5843 - acc: 0.9494 - val_loss: 3.7350 - val_acc: 0.5292\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5667 - acc: 0.9477\n",
      "Epoch 00038: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5666 - acc: 0.9477 - val_loss: 3.8341 - val_acc: 0.5281\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2387 - acc: 0.9490\n",
      "Epoch 00039: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.2387 - acc: 0.9491 - val_loss: 3.3572 - val_acc: 0.5155\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9713\n",
      "Epoch 00040: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1138 - acc: 0.9713 - val_loss: 3.4146 - val_acc: 0.5313\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9770\n",
      "Epoch 00041: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0872 - acc: 0.9770 - val_loss: 3.2916 - val_acc: 0.5432\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9790\n",
      "Epoch 00042: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0779 - acc: 0.9791 - val_loss: 3.1506 - val_acc: 0.5537\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9822\n",
      "Epoch 00043: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0672 - acc: 0.9821 - val_loss: 3.6260 - val_acc: 0.5344\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9825\n",
      "Epoch 00044: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0685 - acc: 0.9824 - val_loss: 3.9333 - val_acc: 0.5134\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9781\n",
      "Epoch 00045: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0762 - acc: 0.9781 - val_loss: 3.4967 - val_acc: 0.5330\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9844\n",
      "Epoch 00046: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0596 - acc: 0.9844 - val_loss: 3.3429 - val_acc: 0.5472\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9814\n",
      "Epoch 00047: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0708 - acc: 0.9814 - val_loss: 3.4881 - val_acc: 0.5497\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9831\n",
      "Epoch 00048: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0643 - acc: 0.9831 - val_loss: 3.5852 - val_acc: 0.5248\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9841\n",
      "Epoch 00049: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0604 - acc: 0.9841 - val_loss: 3.6363 - val_acc: 0.5276\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9862\n",
      "Epoch 00050: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0521 - acc: 0.9862 - val_loss: 3.5423 - val_acc: 0.5358\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9851\n",
      "Epoch 00051: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0596 - acc: 0.9851 - val_loss: 3.7491 - val_acc: 0.5197\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9865\n",
      "Epoch 00052: val_loss did not improve from 2.39675\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0550 - acc: 0.9865 - val_loss: 3.4459 - val_acc: 0.5430\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 986us/sample - loss: 2.6129 - acc: 0.3994\n",
      "Loss: 2.6129125837720197 Accuracy: 0.39937696\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2803 - acc: 0.3623\n",
      "Epoch 00001: val_loss improved from inf to 1.70460, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_4_conv_checkpoint/001-1.7046.hdf5\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 2.2802 - acc: 0.3623 - val_loss: 1.7046 - val_acc: 0.4535\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4414 - acc: 0.5675\n",
      "Epoch 00002: val_loss improved from 1.70460 to 1.65134, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_4_conv_checkpoint/002-1.6513.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 1.4412 - acc: 0.5675 - val_loss: 1.6513 - val_acc: 0.5199\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0848 - acc: 0.6685\n",
      "Epoch 00003: val_loss improved from 1.65134 to 1.35716, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_4_conv_checkpoint/003-1.3572.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 1.0849 - acc: 0.6685 - val_loss: 1.3572 - val_acc: 0.5961\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8643 - acc: 0.7303\n",
      "Epoch 00004: val_loss did not improve from 1.35716\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.8643 - acc: 0.7303 - val_loss: 1.8756 - val_acc: 0.5192\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6827 - acc: 0.7832\n",
      "Epoch 00005: val_loss improved from 1.35716 to 1.32853, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_4_conv_checkpoint/005-1.3285.hdf5\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.6828 - acc: 0.7832 - val_loss: 1.3285 - val_acc: 0.6236\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5357 - acc: 0.8293\n",
      "Epoch 00006: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.5358 - acc: 0.8293 - val_loss: 1.5766 - val_acc: 0.6031\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4523 - acc: 0.8555\n",
      "Epoch 00007: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.4523 - acc: 0.8555 - val_loss: 1.4605 - val_acc: 0.6362\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3677 - acc: 0.8826\n",
      "Epoch 00008: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.3677 - acc: 0.8826 - val_loss: 1.5432 - val_acc: 0.6322\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3146 - acc: 0.8972\n",
      "Epoch 00009: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.3147 - acc: 0.8972 - val_loss: 1.6604 - val_acc: 0.6164\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2734 - acc: 0.9140\n",
      "Epoch 00010: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.2736 - acc: 0.9140 - val_loss: 1.8385 - val_acc: 0.5833\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2574 - acc: 0.9176\n",
      "Epoch 00011: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.2574 - acc: 0.9176 - val_loss: 1.7786 - val_acc: 0.6147\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2277 - acc: 0.9291\n",
      "Epoch 00012: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.2277 - acc: 0.9291 - val_loss: 1.8592 - val_acc: 0.5996\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2002 - acc: 0.9382\n",
      "Epoch 00013: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.2002 - acc: 0.9382 - val_loss: 1.7655 - val_acc: 0.6317\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1836 - acc: 0.9422\n",
      "Epoch 00014: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1837 - acc: 0.9422 - val_loss: 1.7030 - val_acc: 0.6382\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9442\n",
      "Epoch 00015: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1804 - acc: 0.9442 - val_loss: 1.9603 - val_acc: 0.6212\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1606 - acc: 0.9520\n",
      "Epoch 00016: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1608 - acc: 0.9520 - val_loss: 2.1463 - val_acc: 0.5875\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9516\n",
      "Epoch 00017: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1597 - acc: 0.9516 - val_loss: 1.9379 - val_acc: 0.6257\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1561 - acc: 0.9520\n",
      "Epoch 00018: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1561 - acc: 0.9520 - val_loss: 1.8729 - val_acc: 0.6364\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9567\n",
      "Epoch 00019: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1419 - acc: 0.9567 - val_loss: 1.8514 - val_acc: 0.6431\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9612\n",
      "Epoch 00020: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1242 - acc: 0.9612 - val_loss: 1.8394 - val_acc: 0.6452\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1330 - acc: 0.9595\n",
      "Epoch 00021: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1330 - acc: 0.9595 - val_loss: 2.0220 - val_acc: 0.6380\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9659\n",
      "Epoch 00022: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1168 - acc: 0.9659 - val_loss: 1.8487 - val_acc: 0.6592\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9658\n",
      "Epoch 00023: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1153 - acc: 0.9658 - val_loss: 2.1734 - val_acc: 0.6247\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9646\n",
      "Epoch 00024: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1202 - acc: 0.9646 - val_loss: 1.9247 - val_acc: 0.6522\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9644\n",
      "Epoch 00025: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1223 - acc: 0.9644 - val_loss: 2.0068 - val_acc: 0.6420\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9658\n",
      "Epoch 00026: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1159 - acc: 0.9658 - val_loss: 1.8340 - val_acc: 0.6746\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9733\n",
      "Epoch 00027: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0909 - acc: 0.9733 - val_loss: 2.1123 - val_acc: 0.6294\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9688\n",
      "Epoch 00028: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.1063 - acc: 0.9688 - val_loss: 1.9531 - val_acc: 0.6585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9719\n",
      "Epoch 00029: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0959 - acc: 0.9719 - val_loss: 2.0429 - val_acc: 0.6550\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9718\n",
      "Epoch 00030: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0987 - acc: 0.9719 - val_loss: 2.0750 - val_acc: 0.6494\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0945 - acc: 0.9721\n",
      "Epoch 00031: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0945 - acc: 0.9721 - val_loss: 2.5106 - val_acc: 0.5863\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9761\n",
      "Epoch 00032: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0843 - acc: 0.9761 - val_loss: 1.9488 - val_acc: 0.6664\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9721\n",
      "Epoch 00033: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0972 - acc: 0.9721 - val_loss: 2.5000 - val_acc: 0.6131\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9744\n",
      "Epoch 00034: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0926 - acc: 0.9744 - val_loss: 2.0371 - val_acc: 0.6606\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9755\n",
      "Epoch 00035: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0851 - acc: 0.9755 - val_loss: 1.9465 - val_acc: 0.6678\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9763\n",
      "Epoch 00036: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0829 - acc: 0.9763 - val_loss: 2.0586 - val_acc: 0.6625\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9787\n",
      "Epoch 00037: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0758 - acc: 0.9787 - val_loss: 1.9018 - val_acc: 0.6820\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9811\n",
      "Epoch 00038: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0686 - acc: 0.9811 - val_loss: 1.9687 - val_acc: 0.6737\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9785\n",
      "Epoch 00039: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0789 - acc: 0.9785 - val_loss: 2.5015 - val_acc: 0.6380\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9748\n",
      "Epoch 00040: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0868 - acc: 0.9747 - val_loss: 2.2621 - val_acc: 0.6343\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9791\n",
      "Epoch 00041: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0758 - acc: 0.9791 - val_loss: 2.2286 - val_acc: 0.6382\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9796\n",
      "Epoch 00042: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0743 - acc: 0.9796 - val_loss: 2.1286 - val_acc: 0.6587\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9810\n",
      "Epoch 00043: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0660 - acc: 0.9810 - val_loss: 2.3046 - val_acc: 0.6518\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9792\n",
      "Epoch 00044: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0756 - acc: 0.9792 - val_loss: 1.9260 - val_acc: 0.6820\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9819\n",
      "Epoch 00045: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0662 - acc: 0.9819 - val_loss: 2.0788 - val_acc: 0.6706\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9777\n",
      "Epoch 00046: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0803 - acc: 0.9777 - val_loss: 2.2592 - val_acc: 0.6455\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9830\n",
      "Epoch 00047: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0617 - acc: 0.9829 - val_loss: 2.4727 - val_acc: 0.6443\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9804\n",
      "Epoch 00048: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0695 - acc: 0.9804 - val_loss: 2.0113 - val_acc: 0.6792\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9844\n",
      "Epoch 00049: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0574 - acc: 0.9844 - val_loss: 2.3810 - val_acc: 0.6487\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9813\n",
      "Epoch 00050: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0694 - acc: 0.9813 - val_loss: 2.0233 - val_acc: 0.6753\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9850\n",
      "Epoch 00051: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0560 - acc: 0.9850 - val_loss: 2.1223 - val_acc: 0.6774\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9822\n",
      "Epoch 00052: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0662 - acc: 0.9821 - val_loss: 2.1582 - val_acc: 0.6671\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9839\n",
      "Epoch 00053: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0606 - acc: 0.9839 - val_loss: 2.4216 - val_acc: 0.6513\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9842\n",
      "Epoch 00054: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0586 - acc: 0.9842 - val_loss: 2.3807 - val_acc: 0.6546\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9822\n",
      "Epoch 00055: val_loss did not improve from 1.32853\n",
      "36805/36805 [==============================] - 96s 3ms/sample - loss: 0.0659 - acc: 0.9822 - val_loss: 2.2322 - val_acc: 0.6704\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.4578 - acc: 0.5961\n",
      "Loss: 1.4578398395302634 Accuracy: 0.596054\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1267 - acc: 0.4005\n",
      "Epoch 00001: val_loss improved from inf to 1.53038, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_5_conv_checkpoint/001-1.5304.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 2.1267 - acc: 0.4005 - val_loss: 1.5304 - val_acc: 0.5227\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3231 - acc: 0.6052\n",
      "Epoch 00002: val_loss improved from 1.53038 to 1.31169, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_5_conv_checkpoint/002-1.3117.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 1.3233 - acc: 0.6052 - val_loss: 1.3117 - val_acc: 0.6028\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9964 - acc: 0.6971\n",
      "Epoch 00003: val_loss did not improve from 1.31169\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.9965 - acc: 0.6971 - val_loss: 1.5934 - val_acc: 0.5493\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7913 - acc: 0.7558\n",
      "Epoch 00004: val_loss improved from 1.31169 to 1.19789, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_5_conv_checkpoint/004-1.1979.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.7913 - acc: 0.7558 - val_loss: 1.1979 - val_acc: 0.6641\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6047 - acc: 0.8078\n",
      "Epoch 00005: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.6046 - acc: 0.8078 - val_loss: 1.2383 - val_acc: 0.6592\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4848 - acc: 0.8457\n",
      "Epoch 00006: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.4848 - acc: 0.8457 - val_loss: 1.2298 - val_acc: 0.6737\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4065 - acc: 0.8691\n",
      "Epoch 00007: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.4068 - acc: 0.8690 - val_loss: 1.3165 - val_acc: 0.6583\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3453 - acc: 0.8898\n",
      "Epoch 00008: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.3454 - acc: 0.8897 - val_loss: 1.3339 - val_acc: 0.6657\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3039 - acc: 0.9027\n",
      "Epoch 00009: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.3039 - acc: 0.9027 - val_loss: 1.2502 - val_acc: 0.6962\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2439 - acc: 0.9200\n",
      "Epoch 00010: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.2439 - acc: 0.9200 - val_loss: 1.4628 - val_acc: 0.6769\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2302 - acc: 0.9262\n",
      "Epoch 00011: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.2301 - acc: 0.9263 - val_loss: 1.3466 - val_acc: 0.6911\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1936 - acc: 0.9387\n",
      "Epoch 00012: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.1937 - acc: 0.9387 - val_loss: 1.3792 - val_acc: 0.6988\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2006 - acc: 0.9351\n",
      "Epoch 00013: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.2007 - acc: 0.9351 - val_loss: 1.5137 - val_acc: 0.6774\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1855 - acc: 0.9405\n",
      "Epoch 00014: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.1855 - acc: 0.9406 - val_loss: 1.5927 - val_acc: 0.6774\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1523 - acc: 0.9520\n",
      "Epoch 00015: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.1523 - acc: 0.9520 - val_loss: 1.4143 - val_acc: 0.7056\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9551\n",
      "Epoch 00016: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.1432 - acc: 0.9551 - val_loss: 1.6453 - val_acc: 0.6760\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1495 - acc: 0.9520\n",
      "Epoch 00017: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.1494 - acc: 0.9520 - val_loss: 1.6439 - val_acc: 0.6986\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1261 - acc: 0.9619\n",
      "Epoch 00018: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.1260 - acc: 0.9619 - val_loss: 1.4805 - val_acc: 0.7014\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1345 - acc: 0.9575\n",
      "Epoch 00019: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.1345 - acc: 0.9575 - val_loss: 1.7436 - val_acc: 0.6830\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9643\n",
      "Epoch 00020: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.1179 - acc: 0.9643 - val_loss: 1.5433 - val_acc: 0.7035\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1133 - acc: 0.9662\n",
      "Epoch 00021: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.1133 - acc: 0.9662 - val_loss: 1.5062 - val_acc: 0.7065\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1171 - acc: 0.9635\n",
      "Epoch 00022: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.1173 - acc: 0.9635 - val_loss: 1.7475 - val_acc: 0.6965\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1191 - acc: 0.9646\n",
      "Epoch 00023: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.1191 - acc: 0.9646 - val_loss: 1.4774 - val_acc: 0.7279\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9683\n",
      "Epoch 00024: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.1034 - acc: 0.9683 - val_loss: 1.5442 - val_acc: 0.7160\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9727\n",
      "Epoch 00025: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0920 - acc: 0.9727 - val_loss: 1.6761 - val_acc: 0.7074\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9712\n",
      "Epoch 00026: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0965 - acc: 0.9712 - val_loss: 1.8764 - val_acc: 0.6781\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9729\n",
      "Epoch 00027: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0896 - acc: 0.9729 - val_loss: 1.5055 - val_acc: 0.7363\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9694\n",
      "Epoch 00028: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.1006 - acc: 0.9694 - val_loss: 1.6920 - val_acc: 0.7200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9737\n",
      "Epoch 00029: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0921 - acc: 0.9737 - val_loss: 1.7919 - val_acc: 0.7091\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9726\n",
      "Epoch 00030: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0912 - acc: 0.9725 - val_loss: 1.6187 - val_acc: 0.7163\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9729\n",
      "Epoch 00031: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0929 - acc: 0.9729 - val_loss: 1.5948 - val_acc: 0.7223\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9778\n",
      "Epoch 00032: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0755 - acc: 0.9778 - val_loss: 1.8940 - val_acc: 0.6995\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9776\n",
      "Epoch 00033: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0784 - acc: 0.9776 - val_loss: 2.0483 - val_acc: 0.6797\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0898 - acc: 0.9739\n",
      "Epoch 00034: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0899 - acc: 0.9739 - val_loss: 2.2237 - val_acc: 0.6660\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9769\n",
      "Epoch 00035: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0787 - acc: 0.9769 - val_loss: 1.7023 - val_acc: 0.7209\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9798\n",
      "Epoch 00036: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0721 - acc: 0.9798 - val_loss: 1.8045 - val_acc: 0.7156\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9800\n",
      "Epoch 00037: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0686 - acc: 0.9800 - val_loss: 1.8950 - val_acc: 0.6965\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9761\n",
      "Epoch 00038: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0796 - acc: 0.9761 - val_loss: 1.8080 - val_acc: 0.7128\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9771\n",
      "Epoch 00039: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0763 - acc: 0.9771 - val_loss: 1.6954 - val_acc: 0.7349\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9797\n",
      "Epoch 00040: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0698 - acc: 0.9797 - val_loss: 1.9311 - val_acc: 0.7067\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9811\n",
      "Epoch 00041: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0657 - acc: 0.9811 - val_loss: 1.7709 - val_acc: 0.7216\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9823\n",
      "Epoch 00042: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0630 - acc: 0.9823 - val_loss: 2.2305 - val_acc: 0.6739\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9788\n",
      "Epoch 00043: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0763 - acc: 0.9788 - val_loss: 1.6638 - val_acc: 0.7370\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9827\n",
      "Epoch 00044: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0602 - acc: 0.9827 - val_loss: 1.9037 - val_acc: 0.7130\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9833\n",
      "Epoch 00045: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0610 - acc: 0.9833 - val_loss: 1.9600 - val_acc: 0.7070\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9833\n",
      "Epoch 00046: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0614 - acc: 0.9833 - val_loss: 1.7226 - val_acc: 0.7300\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9845\n",
      "Epoch 00047: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0555 - acc: 0.9845 - val_loss: 1.7340 - val_acc: 0.7335\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9835\n",
      "Epoch 00048: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0593 - acc: 0.9835 - val_loss: 1.8409 - val_acc: 0.7228\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9844\n",
      "Epoch 00049: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0567 - acc: 0.9844 - val_loss: 1.9540 - val_acc: 0.7184\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0594 - acc: 0.9840\n",
      "Epoch 00050: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0595 - acc: 0.9839 - val_loss: 1.7989 - val_acc: 0.7214\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9798\n",
      "Epoch 00051: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0719 - acc: 0.9798 - val_loss: 1.8733 - val_acc: 0.7212\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9872\n",
      "Epoch 00052: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 0.0471 - acc: 0.9872 - val_loss: 1.8043 - val_acc: 0.7270\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9838\n",
      "Epoch 00053: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0591 - acc: 0.9838 - val_loss: 1.8560 - val_acc: 0.7230\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9849\n",
      "Epoch 00054: val_loss did not improve from 1.19789\n",
      "36805/36805 [==============================] - 105s 3ms/sample - loss: 0.0566 - acc: 0.9849 - val_loss: 1.6730 - val_acc: 0.7456\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.3127 - acc: 0.6222\n",
      "Loss: 1.3126934542710411 Accuracy: 0.62222224\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9610 - acc: 0.4175\n",
      "Epoch 00001: val_loss improved from inf to 1.64942, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_6_conv_checkpoint/001-1.6494.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 1.9611 - acc: 0.4174 - val_loss: 1.6494 - val_acc: 0.4580\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2200 - acc: 0.6243\n",
      "Epoch 00002: val_loss improved from 1.64942 to 1.04211, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_6_conv_checkpoint/002-1.0421.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 1.2201 - acc: 0.6243 - val_loss: 1.0421 - val_acc: 0.6748\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9834 - acc: 0.7001\n",
      "Epoch 00003: val_loss did not improve from 1.04211\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.9833 - acc: 0.7002 - val_loss: 1.0834 - val_acc: 0.6695\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8219 - acc: 0.7487\n",
      "Epoch 00004: val_loss did not improve from 1.04211\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.8220 - acc: 0.7487 - val_loss: 1.1554 - val_acc: 0.6746\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7072 - acc: 0.7807\n",
      "Epoch 00005: val_loss improved from 1.04211 to 0.98712, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_6_conv_checkpoint/005-0.9871.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.7072 - acc: 0.7807 - val_loss: 0.9871 - val_acc: 0.7188\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6208 - acc: 0.8096\n",
      "Epoch 00006: val_loss improved from 0.98712 to 0.87140, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_6_conv_checkpoint/006-0.8714.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.6209 - acc: 0.8096 - val_loss: 0.8714 - val_acc: 0.7498\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5258 - acc: 0.8371\n",
      "Epoch 00007: val_loss improved from 0.87140 to 0.79291, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_6_conv_checkpoint/007-0.7929.hdf5\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.5258 - acc: 0.8371 - val_loss: 0.7929 - val_acc: 0.7806\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4574 - acc: 0.8548\n",
      "Epoch 00008: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.4573 - acc: 0.8548 - val_loss: 0.9306 - val_acc: 0.7449\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3860 - acc: 0.8786\n",
      "Epoch 00009: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.3860 - acc: 0.8786 - val_loss: 0.8822 - val_acc: 0.7617\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3541 - acc: 0.8883\n",
      "Epoch 00010: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.3540 - acc: 0.8883 - val_loss: 0.8595 - val_acc: 0.7689\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3084 - acc: 0.9024\n",
      "Epoch 00011: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.3085 - acc: 0.9024 - val_loss: 1.0493 - val_acc: 0.7310\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2737 - acc: 0.9115\n",
      "Epoch 00012: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2738 - acc: 0.9115 - val_loss: 1.0051 - val_acc: 0.7573\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2411 - acc: 0.9225\n",
      "Epoch 00013: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2411 - acc: 0.9225 - val_loss: 0.8809 - val_acc: 0.7789\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2240 - acc: 0.9292\n",
      "Epoch 00014: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2240 - acc: 0.9292 - val_loss: 1.0792 - val_acc: 0.7489\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2095 - acc: 0.9327\n",
      "Epoch 00015: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.2095 - acc: 0.9327 - val_loss: 0.9406 - val_acc: 0.7745\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1949 - acc: 0.9370\n",
      "Epoch 00016: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1949 - acc: 0.9370 - val_loss: 0.9223 - val_acc: 0.7841\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9439\n",
      "Epoch 00017: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1751 - acc: 0.9439 - val_loss: 1.2109 - val_acc: 0.7361\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9484\n",
      "Epoch 00018: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1634 - acc: 0.9483 - val_loss: 1.0065 - val_acc: 0.7745\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1526 - acc: 0.9518\n",
      "Epoch 00019: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1526 - acc: 0.9519 - val_loss: 1.2074 - val_acc: 0.7426\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9527\n",
      "Epoch 00020: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1458 - acc: 0.9526 - val_loss: 1.2157 - val_acc: 0.7442\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9481\n",
      "Epoch 00021: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1605 - acc: 0.9481 - val_loss: 1.1682 - val_acc: 0.7575\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9623\n",
      "Epoch 00022: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1200 - acc: 0.9623 - val_loss: 0.9977 - val_acc: 0.7796\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9602\n",
      "Epoch 00023: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1248 - acc: 0.9602 - val_loss: 1.0533 - val_acc: 0.7773\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9582\n",
      "Epoch 00024: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1329 - acc: 0.9581 - val_loss: 1.2096 - val_acc: 0.7533\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9623\n",
      "Epoch 00025: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1251 - acc: 0.9622 - val_loss: 0.9792 - val_acc: 0.7871\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9641\n",
      "Epoch 00026: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1179 - acc: 0.9641 - val_loss: 1.1329 - val_acc: 0.7636\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9679\n",
      "Epoch 00027: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1042 - acc: 0.9679 - val_loss: 1.0455 - val_acc: 0.7829\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9682\n",
      "Epoch 00028: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1019 - acc: 0.9682 - val_loss: 1.2087 - val_acc: 0.7768\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9674\n",
      "Epoch 00029: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1033 - acc: 0.9673 - val_loss: 1.1701 - val_acc: 0.7608\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9675\n",
      "Epoch 00030: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1060 - acc: 0.9675 - val_loss: 1.1203 - val_acc: 0.7927\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1126 - acc: 0.9649\n",
      "Epoch 00031: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.1127 - acc: 0.9649 - val_loss: 1.0169 - val_acc: 0.7987\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9728\n",
      "Epoch 00032: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0890 - acc: 0.9727 - val_loss: 1.0210 - val_acc: 0.7964\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9723\n",
      "Epoch 00033: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0924 - acc: 0.9723 - val_loss: 1.1040 - val_acc: 0.7838\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0879 - acc: 0.9734\n",
      "Epoch 00034: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0879 - acc: 0.9734 - val_loss: 1.1961 - val_acc: 0.7694\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9762\n",
      "Epoch 00035: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0768 - acc: 0.9762 - val_loss: 1.1530 - val_acc: 0.7843\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9725\n",
      "Epoch 00036: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0925 - acc: 0.9725 - val_loss: 1.1231 - val_acc: 0.7899\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9760\n",
      "Epoch 00037: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0792 - acc: 0.9760 - val_loss: 1.1051 - val_acc: 0.7943\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9755\n",
      "Epoch 00038: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0825 - acc: 0.9755 - val_loss: 1.0735 - val_acc: 0.8032\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9750\n",
      "Epoch 00039: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0808 - acc: 0.9750 - val_loss: 1.1938 - val_acc: 0.7789\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9745\n",
      "Epoch 00040: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0879 - acc: 0.9745 - val_loss: 1.0828 - val_acc: 0.8046\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9732\n",
      "Epoch 00041: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0886 - acc: 0.9732 - val_loss: 1.0354 - val_acc: 0.8043\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9795\n",
      "Epoch 00042: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0701 - acc: 0.9795 - val_loss: 0.9788 - val_acc: 0.8088\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9810\n",
      "Epoch 00043: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0669 - acc: 0.9810 - val_loss: 1.2220 - val_acc: 0.7843\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9809\n",
      "Epoch 00044: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0652 - acc: 0.9809 - val_loss: 1.0792 - val_acc: 0.8083\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9740\n",
      "Epoch 00045: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0833 - acc: 0.9740 - val_loss: 1.1778 - val_acc: 0.7964\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9797\n",
      "Epoch 00046: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0694 - acc: 0.9797 - val_loss: 1.0176 - val_acc: 0.8097\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9795\n",
      "Epoch 00047: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0689 - acc: 0.9795 - val_loss: 1.1139 - val_acc: 0.8062\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9813\n",
      "Epoch 00048: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0652 - acc: 0.9813 - val_loss: 1.0939 - val_acc: 0.8013\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9787\n",
      "Epoch 00049: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0706 - acc: 0.9788 - val_loss: 1.2235 - val_acc: 0.7806\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9820\n",
      "Epoch 00050: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0619 - acc: 0.9820 - val_loss: 1.3305 - val_acc: 0.7775\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9805\n",
      "Epoch 00051: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0654 - acc: 0.9805 - val_loss: 1.1225 - val_acc: 0.7999\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9826\n",
      "Epoch 00052: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0618 - acc: 0.9825 - val_loss: 1.1568 - val_acc: 0.8015\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9805\n",
      "Epoch 00053: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0692 - acc: 0.9805 - val_loss: 1.0998 - val_acc: 0.8018\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9839\n",
      "Epoch 00054: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0561 - acc: 0.9839 - val_loss: 1.1286 - val_acc: 0.8022\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9816\n",
      "Epoch 00055: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0645 - acc: 0.9816 - val_loss: 1.5415 - val_acc: 0.7556\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9827\n",
      "Epoch 00056: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0608 - acc: 0.9827 - val_loss: 1.2553 - val_acc: 0.7906\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9837\n",
      "Epoch 00057: val_loss did not improve from 0.79291\n",
      "36805/36805 [==============================] - 110s 3ms/sample - loss: 0.0551 - acc: 0.9837 - val_loss: 1.1926 - val_acc: 0.7966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.8866 - acc: 0.7371\n",
      "Loss: 0.8865547987035749 Accuracy: 0.73707163\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8543 - acc: 0.4365\n",
      "Epoch 00001: val_loss improved from inf to 1.42687, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_7_conv_checkpoint/001-1.4269.hdf5\n",
      "36805/36805 [==============================] - 129s 4ms/sample - loss: 1.8541 - acc: 0.4365 - val_loss: 1.4269 - val_acc: 0.5451\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1212 - acc: 0.6545\n",
      "Epoch 00002: val_loss improved from 1.42687 to 0.91425, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_7_conv_checkpoint/002-0.9142.hdf5\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 1.1215 - acc: 0.6544 - val_loss: 0.9142 - val_acc: 0.7254\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9207 - acc: 0.7201\n",
      "Epoch 00003: val_loss improved from 0.91425 to 0.89610, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_7_conv_checkpoint/003-0.8961.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.9207 - acc: 0.7201 - val_loss: 0.8961 - val_acc: 0.7319\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7906 - acc: 0.7600\n",
      "Epoch 00004: val_loss improved from 0.89610 to 0.70593, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_7_conv_checkpoint/004-0.7059.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.7906 - acc: 0.7600 - val_loss: 0.7059 - val_acc: 0.7913\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7095 - acc: 0.7862\n",
      "Epoch 00005: val_loss did not improve from 0.70593\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.7098 - acc: 0.7861 - val_loss: 0.7570 - val_acc: 0.7876\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6428 - acc: 0.8061\n",
      "Epoch 00006: val_loss improved from 0.70593 to 0.66785, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_7_conv_checkpoint/006-0.6678.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.6429 - acc: 0.8060 - val_loss: 0.6678 - val_acc: 0.8074\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5854 - acc: 0.8233\n",
      "Epoch 00007: val_loss did not improve from 0.66785\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.5856 - acc: 0.8233 - val_loss: 0.7524 - val_acc: 0.7845\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5327 - acc: 0.8382\n",
      "Epoch 00008: val_loss improved from 0.66785 to 0.62059, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_7_conv_checkpoint/008-0.6206.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.5329 - acc: 0.8382 - val_loss: 0.6206 - val_acc: 0.8143\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4834 - acc: 0.8517\n",
      "Epoch 00009: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.4834 - acc: 0.8517 - val_loss: 0.6753 - val_acc: 0.8153\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4434 - acc: 0.8625\n",
      "Epoch 00010: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.4434 - acc: 0.8625 - val_loss: 0.6797 - val_acc: 0.8071\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3993 - acc: 0.8771\n",
      "Epoch 00011: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3993 - acc: 0.8771 - val_loss: 0.6849 - val_acc: 0.8130\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3669 - acc: 0.8858\n",
      "Epoch 00012: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3669 - acc: 0.8857 - val_loss: 0.7732 - val_acc: 0.7876\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3286 - acc: 0.8974\n",
      "Epoch 00013: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3286 - acc: 0.8974 - val_loss: 0.7647 - val_acc: 0.8020\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3044 - acc: 0.9049\n",
      "Epoch 00014: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.3045 - acc: 0.9048 - val_loss: 0.6761 - val_acc: 0.8279\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2873 - acc: 0.9097\n",
      "Epoch 00015: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.2872 - acc: 0.9097 - val_loss: 0.6640 - val_acc: 0.8302\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2561 - acc: 0.9183\n",
      "Epoch 00016: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.2563 - acc: 0.9182 - val_loss: 0.8377 - val_acc: 0.7843\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2544 - acc: 0.9186\n",
      "Epoch 00017: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.2544 - acc: 0.9186 - val_loss: 0.6431 - val_acc: 0.8302\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2189 - acc: 0.9308\n",
      "Epoch 00018: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.2190 - acc: 0.9308 - val_loss: 0.6254 - val_acc: 0.8311\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2189 - acc: 0.9322\n",
      "Epoch 00019: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.2189 - acc: 0.9322 - val_loss: 0.6959 - val_acc: 0.8262\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1867 - acc: 0.9411\n",
      "Epoch 00020: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1868 - acc: 0.9411 - val_loss: 0.6992 - val_acc: 0.8183\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1714 - acc: 0.9445\n",
      "Epoch 00021: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1716 - acc: 0.9445 - val_loss: 0.6580 - val_acc: 0.8402\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9428\n",
      "Epoch 00022: val_loss did not improve from 0.62059\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1755 - acc: 0.9428 - val_loss: 0.6242 - val_acc: 0.8470\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9510\n",
      "Epoch 00023: val_loss improved from 0.62059 to 0.59708, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_7_conv_checkpoint/023-0.5971.hdf5\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1583 - acc: 0.9510 - val_loss: 0.5971 - val_acc: 0.8512\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1509 - acc: 0.9511\n",
      "Epoch 00024: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1510 - acc: 0.9511 - val_loss: 0.6583 - val_acc: 0.8430\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1492 - acc: 0.9517\n",
      "Epoch 00025: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1492 - acc: 0.9517 - val_loss: 0.7740 - val_acc: 0.8176\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1359 - acc: 0.9558\n",
      "Epoch 00026: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1359 - acc: 0.9558 - val_loss: 0.6646 - val_acc: 0.8409\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9549\n",
      "Epoch 00027: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1386 - acc: 0.9549 - val_loss: 0.6720 - val_acc: 0.8446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9597\n",
      "Epoch 00028: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1253 - acc: 0.9597 - val_loss: 0.6571 - val_acc: 0.8395\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9562\n",
      "Epoch 00029: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1343 - acc: 0.9562 - val_loss: 0.8366 - val_acc: 0.8036\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1211 - acc: 0.9618\n",
      "Epoch 00030: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1211 - acc: 0.9618 - val_loss: 0.8440 - val_acc: 0.8141\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9665\n",
      "Epoch 00031: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1060 - acc: 0.9666 - val_loss: 0.7700 - val_acc: 0.8223\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9669\n",
      "Epoch 00032: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1051 - acc: 0.9668 - val_loss: 0.8282 - val_acc: 0.8178\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9616\n",
      "Epoch 00033: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1174 - acc: 0.9616 - val_loss: 0.8076 - val_acc: 0.8286\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9673\n",
      "Epoch 00034: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.1054 - acc: 0.9673 - val_loss: 0.8394 - val_acc: 0.8230\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9714\n",
      "Epoch 00035: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0923 - acc: 0.9714 - val_loss: 0.7408 - val_acc: 0.8435\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9705\n",
      "Epoch 00036: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0915 - acc: 0.9705 - val_loss: 0.8089 - val_acc: 0.8227\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9678\n",
      "Epoch 00037: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.1019 - acc: 0.9678 - val_loss: 0.9294 - val_acc: 0.8039\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9745\n",
      "Epoch 00038: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0832 - acc: 0.9745 - val_loss: 0.9384 - val_acc: 0.8134\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9715\n",
      "Epoch 00039: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0898 - acc: 0.9715 - val_loss: 0.8416 - val_acc: 0.8304\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9725\n",
      "Epoch 00040: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0865 - acc: 0.9725 - val_loss: 1.0699 - val_acc: 0.7999\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9742\n",
      "Epoch 00041: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0828 - acc: 0.9742 - val_loss: 0.6912 - val_acc: 0.8542\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9752\n",
      "Epoch 00042: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0804 - acc: 0.9752 - val_loss: 0.7180 - val_acc: 0.8444\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9760\n",
      "Epoch 00043: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0768 - acc: 0.9760 - val_loss: 1.0725 - val_acc: 0.7955\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9740\n",
      "Epoch 00044: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0822 - acc: 0.9740 - val_loss: 0.7485 - val_acc: 0.8425\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9784\n",
      "Epoch 00045: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0706 - acc: 0.9784 - val_loss: 0.8306 - val_acc: 0.8316\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9751\n",
      "Epoch 00046: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0791 - acc: 0.9751 - val_loss: 0.7779 - val_acc: 0.8374\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9755\n",
      "Epoch 00047: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0789 - acc: 0.9755 - val_loss: 0.7426 - val_acc: 0.8411\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9782\n",
      "Epoch 00048: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0696 - acc: 0.9781 - val_loss: 0.7180 - val_acc: 0.8565\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9755\n",
      "Epoch 00049: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0765 - acc: 0.9754 - val_loss: 0.8327 - val_acc: 0.8295\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9784\n",
      "Epoch 00050: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0686 - acc: 0.9784 - val_loss: 0.8015 - val_acc: 0.8367\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9757\n",
      "Epoch 00051: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0780 - acc: 0.9757 - val_loss: 0.8075 - val_acc: 0.8379\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9785\n",
      "Epoch 00052: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0693 - acc: 0.9785 - val_loss: 0.7899 - val_acc: 0.8458\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9786\n",
      "Epoch 00053: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0697 - acc: 0.9786 - val_loss: 0.7151 - val_acc: 0.8574\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9787\n",
      "Epoch 00054: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0674 - acc: 0.9787 - val_loss: 0.7157 - val_acc: 0.8528\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9831\n",
      "Epoch 00055: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0570 - acc: 0.9831 - val_loss: 0.7264 - val_acc: 0.8577\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9799\n",
      "Epoch 00056: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0619 - acc: 0.9799 - val_loss: 0.8094 - val_acc: 0.8304\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9810\n",
      "Epoch 00057: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0603 - acc: 0.9810 - val_loss: 0.6804 - val_acc: 0.8602\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9779\n",
      "Epoch 00058: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0713 - acc: 0.9778 - val_loss: 0.8590 - val_acc: 0.8379\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9812\n",
      "Epoch 00059: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0591 - acc: 0.9813 - val_loss: 0.8265 - val_acc: 0.8421\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9831\n",
      "Epoch 00060: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0547 - acc: 0.9831 - val_loss: 0.7630 - val_acc: 0.8549\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9785\n",
      "Epoch 00061: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0693 - acc: 0.9785 - val_loss: 0.8024 - val_acc: 0.8432\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9827\n",
      "Epoch 00062: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0558 - acc: 0.9827 - val_loss: 0.7134 - val_acc: 0.8630\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9825\n",
      "Epoch 00063: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0587 - acc: 0.9825 - val_loss: 0.6781 - val_acc: 0.8691\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9831\n",
      "Epoch 00064: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0550 - acc: 0.9831 - val_loss: 0.7092 - val_acc: 0.8661\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9837\n",
      "Epoch 00065: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0526 - acc: 0.9837 - val_loss: 0.6918 - val_acc: 0.8642\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9808\n",
      "Epoch 00066: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 114s 3ms/sample - loss: 0.0618 - acc: 0.9808 - val_loss: 0.8330 - val_acc: 0.8411\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9833\n",
      "Epoch 00067: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0529 - acc: 0.9833 - val_loss: 0.7737 - val_acc: 0.8572\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9847\n",
      "Epoch 00068: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0513 - acc: 0.9847 - val_loss: 0.7442 - val_acc: 0.8546\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9851\n",
      "Epoch 00069: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0509 - acc: 0.9851 - val_loss: 0.9467 - val_acc: 0.8293\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9839\n",
      "Epoch 00070: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0510 - acc: 0.9839 - val_loss: 0.9141 - val_acc: 0.8281\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9842\n",
      "Epoch 00071: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0507 - acc: 0.9842 - val_loss: 0.8403 - val_acc: 0.8397\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9849\n",
      "Epoch 00072: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0514 - acc: 0.9849 - val_loss: 0.7444 - val_acc: 0.8607\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9832\n",
      "Epoch 00073: val_loss did not improve from 0.59708\n",
      "36805/36805 [==============================] - 113s 3ms/sample - loss: 0.0545 - acc: 0.9832 - val_loss: 0.7644 - val_acc: 0.8602\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.7324 - acc: 0.8218\n",
      "Loss: 0.7324441032060581 Accuracy: 0.82180685\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9487 - acc: 0.3990\n",
      "Epoch 00001: val_loss improved from inf to 1.35321, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_8_conv_checkpoint/001-1.3532.hdf5\n",
      "36805/36805 [==============================] - 136s 4ms/sample - loss: 1.9489 - acc: 0.3991 - val_loss: 1.3532 - val_acc: 0.5574\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1530 - acc: 0.6386\n",
      "Epoch 00002: val_loss improved from 1.35321 to 1.15159, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_8_conv_checkpoint/002-1.1516.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 1.1529 - acc: 0.6386 - val_loss: 1.1516 - val_acc: 0.6473\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9228 - acc: 0.7161\n",
      "Epoch 00003: val_loss improved from 1.15159 to 1.12262, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_8_conv_checkpoint/003-1.1226.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.9230 - acc: 0.7161 - val_loss: 1.1226 - val_acc: 0.6723\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7805 - acc: 0.7626\n",
      "Epoch 00004: val_loss improved from 1.12262 to 0.68696, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_8_conv_checkpoint/004-0.6870.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.7805 - acc: 0.7626 - val_loss: 0.6870 - val_acc: 0.7983\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6880 - acc: 0.7932\n",
      "Epoch 00005: val_loss did not improve from 0.68696\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.6880 - acc: 0.7932 - val_loss: 0.8002 - val_acc: 0.7717\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6069 - acc: 0.8176\n",
      "Epoch 00006: val_loss improved from 0.68696 to 0.62762, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_8_conv_checkpoint/006-0.6276.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.6070 - acc: 0.8176 - val_loss: 0.6276 - val_acc: 0.8260\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5556 - acc: 0.8338\n",
      "Epoch 00007: val_loss improved from 0.62762 to 0.60087, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_8_conv_checkpoint/007-0.6009.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.5556 - acc: 0.8337 - val_loss: 0.6009 - val_acc: 0.8297\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4985 - acc: 0.8524\n",
      "Epoch 00008: val_loss improved from 0.60087 to 0.48600, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_8_conv_checkpoint/008-0.4860.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.4985 - acc: 0.8524 - val_loss: 0.4860 - val_acc: 0.8691\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4496 - acc: 0.8643\n",
      "Epoch 00009: val_loss did not improve from 0.48600\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.4496 - acc: 0.8643 - val_loss: 0.5605 - val_acc: 0.8428\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4089 - acc: 0.8780\n",
      "Epoch 00010: val_loss did not improve from 0.48600\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.4088 - acc: 0.8780 - val_loss: 0.5910 - val_acc: 0.8351\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3828 - acc: 0.8842\n",
      "Epoch 00011: val_loss did not improve from 0.48600\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.3827 - acc: 0.8842 - val_loss: 0.5063 - val_acc: 0.8577\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3459 - acc: 0.8961\n",
      "Epoch 00012: val_loss did not improve from 0.48600\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.3460 - acc: 0.8961 - val_loss: 0.5861 - val_acc: 0.8348\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3259 - acc: 0.9011\n",
      "Epoch 00013: val_loss improved from 0.48600 to 0.48515, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_8_conv_checkpoint/013-0.4851.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.3258 - acc: 0.9011 - val_loss: 0.4851 - val_acc: 0.8693\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3008 - acc: 0.9067\n",
      "Epoch 00014: val_loss did not improve from 0.48515\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.3008 - acc: 0.9066 - val_loss: 0.4878 - val_acc: 0.8630\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2829 - acc: 0.9126\n",
      "Epoch 00015: val_loss did not improve from 0.48515\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.2830 - acc: 0.9126 - val_loss: 0.5227 - val_acc: 0.8584\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2661 - acc: 0.9169\n",
      "Epoch 00016: val_loss improved from 0.48515 to 0.43940, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_8_conv_checkpoint/016-0.4394.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.2661 - acc: 0.9169 - val_loss: 0.4394 - val_acc: 0.8751\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.9254\n",
      "Epoch 00017: val_loss did not improve from 0.43940\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.2401 - acc: 0.9254 - val_loss: 0.6341 - val_acc: 0.8355\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.9274\n",
      "Epoch 00018: val_loss improved from 0.43940 to 0.41636, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_8_conv_checkpoint/018-0.4164.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.2285 - acc: 0.9274 - val_loss: 0.4164 - val_acc: 0.8912\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2183 - acc: 0.9318\n",
      "Epoch 00019: val_loss did not improve from 0.41636\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.2184 - acc: 0.9318 - val_loss: 0.4497 - val_acc: 0.8840\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2012 - acc: 0.9372\n",
      "Epoch 00020: val_loss improved from 0.41636 to 0.39869, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_8_conv_checkpoint/020-0.3987.hdf5\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.2012 - acc: 0.9372 - val_loss: 0.3987 - val_acc: 0.8984\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1860 - acc: 0.9415\n",
      "Epoch 00021: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.1860 - acc: 0.9415 - val_loss: 0.5954 - val_acc: 0.8607\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1856 - acc: 0.9417\n",
      "Epoch 00022: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.1858 - acc: 0.9416 - val_loss: 0.5013 - val_acc: 0.8696\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1843 - acc: 0.9415\n",
      "Epoch 00023: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1843 - acc: 0.9415 - val_loss: 0.4962 - val_acc: 0.8856\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1484 - acc: 0.9543\n",
      "Epoch 00024: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1484 - acc: 0.9544 - val_loss: 0.4665 - val_acc: 0.8805\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9523\n",
      "Epoch 00025: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1469 - acc: 0.9523 - val_loss: 0.5405 - val_acc: 0.8663\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9533\n",
      "Epoch 00026: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.1463 - acc: 0.9533 - val_loss: 0.4479 - val_acc: 0.8789\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1306 - acc: 0.9580\n",
      "Epoch 00027: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.1306 - acc: 0.9580 - val_loss: 0.4243 - val_acc: 0.8973\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1287 - acc: 0.9583\n",
      "Epoch 00028: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.1287 - acc: 0.9583 - val_loss: 0.5840 - val_acc: 0.8668\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9639\n",
      "Epoch 00029: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.1174 - acc: 0.9639 - val_loss: 0.4293 - val_acc: 0.8940\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1227 - acc: 0.9615\n",
      "Epoch 00030: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.1228 - acc: 0.9614 - val_loss: 0.4711 - val_acc: 0.8868\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9605\n",
      "Epoch 00031: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.1202 - acc: 0.9605 - val_loss: 0.4670 - val_acc: 0.8908\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9668\n",
      "Epoch 00032: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.1051 - acc: 0.9668 - val_loss: 0.4172 - val_acc: 0.8973\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9656\n",
      "Epoch 00033: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.1052 - acc: 0.9656 - val_loss: 0.4501 - val_acc: 0.8952\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9692\n",
      "Epoch 00034: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0951 - acc: 0.9692 - val_loss: 0.4308 - val_acc: 0.8975\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0936 - acc: 0.9708\n",
      "Epoch 00035: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0936 - acc: 0.9708 - val_loss: 0.4192 - val_acc: 0.8975\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9723\n",
      "Epoch 00036: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0888 - acc: 0.9723 - val_loss: 0.4979 - val_acc: 0.8859\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9719\n",
      "Epoch 00037: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0891 - acc: 0.9719 - val_loss: 0.4605 - val_acc: 0.8928\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9707\n",
      "Epoch 00038: val_loss did not improve from 0.39869\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0914 - acc: 0.9707 - val_loss: 0.4668 - val_acc: 0.8935\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1001 - acc: 0.9692\n",
      "Epoch 00039: val_loss improved from 0.39869 to 0.37669, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_8_conv_checkpoint/039-0.3767.hdf5\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.1003 - acc: 0.9691 - val_loss: 0.3767 - val_acc: 0.9089\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9732\n",
      "Epoch 00040: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0845 - acc: 0.9731 - val_loss: 0.4545 - val_acc: 0.8961\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9762\n",
      "Epoch 00041: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0772 - acc: 0.9763 - val_loss: 0.5095 - val_acc: 0.8889\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9773\n",
      "Epoch 00042: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0730 - acc: 0.9773 - val_loss: 0.4356 - val_acc: 0.9050\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9761\n",
      "Epoch 00043: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0780 - acc: 0.9761 - val_loss: 0.4487 - val_acc: 0.9045\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9756\n",
      "Epoch 00044: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0766 - acc: 0.9756 - val_loss: 0.5599 - val_acc: 0.8737\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9795\n",
      "Epoch 00045: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0666 - acc: 0.9795 - val_loss: 0.4734 - val_acc: 0.8980\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9797\n",
      "Epoch 00046: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0673 - acc: 0.9797 - val_loss: 0.4299 - val_acc: 0.9059\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9791\n",
      "Epoch 00047: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0687 - acc: 0.9791 - val_loss: 0.5029 - val_acc: 0.8949\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9810\n",
      "Epoch 00048: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0623 - acc: 0.9810 - val_loss: 0.5123 - val_acc: 0.8901\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9796\n",
      "Epoch 00049: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0671 - acc: 0.9796 - val_loss: 0.4790 - val_acc: 0.8966\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9807\n",
      "Epoch 00050: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0619 - acc: 0.9807 - val_loss: 0.5400 - val_acc: 0.8861\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9797\n",
      "Epoch 00051: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0632 - acc: 0.9797 - val_loss: 0.6369 - val_acc: 0.8703\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9790\n",
      "Epoch 00052: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0656 - acc: 0.9790 - val_loss: 0.4295 - val_acc: 0.9036\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9842\n",
      "Epoch 00053: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0533 - acc: 0.9841 - val_loss: 0.6331 - val_acc: 0.8737\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9832\n",
      "Epoch 00054: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0556 - acc: 0.9832 - val_loss: 0.4585 - val_acc: 0.9066\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9814\n",
      "Epoch 00055: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0600 - acc: 0.9813 - val_loss: 0.5635 - val_acc: 0.8877\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9810\n",
      "Epoch 00056: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0625 - acc: 0.9810 - val_loss: 0.4321 - val_acc: 0.9075\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9842\n",
      "Epoch 00057: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0496 - acc: 0.9842 - val_loss: 0.4855 - val_acc: 0.9024\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9853\n",
      "Epoch 00058: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0483 - acc: 0.9852 - val_loss: 0.5054 - val_acc: 0.8938\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9822\n",
      "Epoch 00059: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0592 - acc: 0.9822 - val_loss: 0.4613 - val_acc: 0.9005\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9847\n",
      "Epoch 00060: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0483 - acc: 0.9847 - val_loss: 0.5411 - val_acc: 0.8940\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9804\n",
      "Epoch 00061: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0614 - acc: 0.9804 - val_loss: 0.7134 - val_acc: 0.8724\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0489 - acc: 0.9846\n",
      "Epoch 00062: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0491 - acc: 0.9845 - val_loss: 0.6279 - val_acc: 0.8700\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9819\n",
      "Epoch 00063: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0587 - acc: 0.9819 - val_loss: 0.4777 - val_acc: 0.9033\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9870\n",
      "Epoch 00064: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0411 - acc: 0.9870 - val_loss: 0.4897 - val_acc: 0.8980\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9859\n",
      "Epoch 00065: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0456 - acc: 0.9859 - val_loss: 0.4699 - val_acc: 0.9010\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9862\n",
      "Epoch 00066: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0461 - acc: 0.9862 - val_loss: 0.5117 - val_acc: 0.9015\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9848\n",
      "Epoch 00067: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0492 - acc: 0.9848 - val_loss: 0.5016 - val_acc: 0.9089\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9852\n",
      "Epoch 00068: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0482 - acc: 0.9852 - val_loss: 0.4699 - val_acc: 0.9057\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9883\n",
      "Epoch 00069: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0402 - acc: 0.9883 - val_loss: 0.5934 - val_acc: 0.8866\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9857\n",
      "Epoch 00070: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0443 - acc: 0.9857 - val_loss: 0.4704 - val_acc: 0.9096\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9876\n",
      "Epoch 00071: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0407 - acc: 0.9876 - val_loss: 0.5182 - val_acc: 0.8998\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9851\n",
      "Epoch 00072: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0477 - acc: 0.9851 - val_loss: 0.5653 - val_acc: 0.8894\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9878\n",
      "Epoch 00073: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0400 - acc: 0.9878 - val_loss: 0.4726 - val_acc: 0.9099\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9873\n",
      "Epoch 00074: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0404 - acc: 0.9873 - val_loss: 0.6083 - val_acc: 0.8901\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9879\n",
      "Epoch 00075: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0385 - acc: 0.9879 - val_loss: 0.4634 - val_acc: 0.9022\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9867\n",
      "Epoch 00076: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0423 - acc: 0.9867 - val_loss: 0.5610 - val_acc: 0.8928\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9893\n",
      "Epoch 00077: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0363 - acc: 0.9893 - val_loss: 0.4630 - val_acc: 0.9092\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9884\n",
      "Epoch 00078: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0384 - acc: 0.9884 - val_loss: 0.5223 - val_acc: 0.9031\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9822\n",
      "Epoch 00079: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0551 - acc: 0.9822 - val_loss: 0.5107 - val_acc: 0.9026\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9883\n",
      "Epoch 00080: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0362 - acc: 0.9883 - val_loss: 0.4687 - val_acc: 0.9103\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9918\n",
      "Epoch 00081: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0293 - acc: 0.9918 - val_loss: 0.4235 - val_acc: 0.9166\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9886\n",
      "Epoch 00082: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0369 - acc: 0.9886 - val_loss: 0.5893 - val_acc: 0.8889\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9908\n",
      "Epoch 00083: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 116s 3ms/sample - loss: 0.0309 - acc: 0.9908 - val_loss: 0.4711 - val_acc: 0.9101\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9878\n",
      "Epoch 00084: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0385 - acc: 0.9878 - val_loss: 0.5888 - val_acc: 0.8931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9825\n",
      "Epoch 00085: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0562 - acc: 0.9825 - val_loss: 0.5145 - val_acc: 0.9059\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9919\n",
      "Epoch 00086: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0261 - acc: 0.9919 - val_loss: 0.5277 - val_acc: 0.9008\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9893\n",
      "Epoch 00087: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0350 - acc: 0.9893 - val_loss: 0.4635 - val_acc: 0.9103\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9882\n",
      "Epoch 00088: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0397 - acc: 0.9882 - val_loss: 0.4708 - val_acc: 0.9066\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9883\n",
      "Epoch 00089: val_loss did not improve from 0.37669\n",
      "36805/36805 [==============================] - 115s 3ms/sample - loss: 0.0389 - acc: 0.9883 - val_loss: 0.4855 - val_acc: 0.9119\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4655 - acc: 0.8820\n",
      "Loss: 0.4654835937550506 Accuracy: 0.8820353\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8965 - acc: 0.4240\n",
      "Epoch 00001: val_loss improved from inf to 1.40069, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_9_conv_checkpoint/001-1.4007.hdf5\n",
      "36805/36805 [==============================] - 143s 4ms/sample - loss: 1.8966 - acc: 0.4240 - val_loss: 1.4007 - val_acc: 0.5497\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0625 - acc: 0.6727\n",
      "Epoch 00002: val_loss improved from 1.40069 to 0.84915, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_9_conv_checkpoint/002-0.8492.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 1.0626 - acc: 0.6726 - val_loss: 0.8492 - val_acc: 0.7473\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8023 - acc: 0.7585\n",
      "Epoch 00003: val_loss improved from 0.84915 to 0.63883, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_9_conv_checkpoint/003-0.6388.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.8026 - acc: 0.7584 - val_loss: 0.6388 - val_acc: 0.8134\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6618 - acc: 0.8020\n",
      "Epoch 00004: val_loss improved from 0.63883 to 0.56494, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_9_conv_checkpoint/004-0.5649.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.6618 - acc: 0.8020 - val_loss: 0.5649 - val_acc: 0.8416\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5453 - acc: 0.8365\n",
      "Epoch 00005: val_loss did not improve from 0.56494\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.5453 - acc: 0.8365 - val_loss: 0.6187 - val_acc: 0.8188\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4764 - acc: 0.8570\n",
      "Epoch 00006: val_loss improved from 0.56494 to 0.49153, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_9_conv_checkpoint/006-0.4915.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.4765 - acc: 0.8569 - val_loss: 0.4915 - val_acc: 0.8654\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4171 - acc: 0.8760\n",
      "Epoch 00007: val_loss improved from 0.49153 to 0.42256, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_9_conv_checkpoint/007-0.4226.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.4170 - acc: 0.8760 - val_loss: 0.4226 - val_acc: 0.8810\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3686 - acc: 0.8895\n",
      "Epoch 00008: val_loss did not improve from 0.42256\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.3686 - acc: 0.8895 - val_loss: 0.4529 - val_acc: 0.8710\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3285 - acc: 0.9012\n",
      "Epoch 00009: val_loss improved from 0.42256 to 0.41854, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_9_conv_checkpoint/009-0.4185.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.3285 - acc: 0.9012 - val_loss: 0.4185 - val_acc: 0.8833\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2953 - acc: 0.9101\n",
      "Epoch 00010: val_loss did not improve from 0.41854\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2953 - acc: 0.9100 - val_loss: 0.4781 - val_acc: 0.8726\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2782 - acc: 0.9149\n",
      "Epoch 00011: val_loss did not improve from 0.41854\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2782 - acc: 0.9149 - val_loss: 0.4383 - val_acc: 0.8805\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2417 - acc: 0.9246\n",
      "Epoch 00012: val_loss improved from 0.41854 to 0.36546, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_9_conv_checkpoint/012-0.3655.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2417 - acc: 0.9246 - val_loss: 0.3655 - val_acc: 0.9089\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2233 - acc: 0.9309\n",
      "Epoch 00013: val_loss did not improve from 0.36546\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2233 - acc: 0.9309 - val_loss: 0.4567 - val_acc: 0.8733\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2044 - acc: 0.9370\n",
      "Epoch 00014: val_loss improved from 0.36546 to 0.35887, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_9_conv_checkpoint/014-0.3589.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.2044 - acc: 0.9370 - val_loss: 0.3589 - val_acc: 0.9078\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1898 - acc: 0.9401\n",
      "Epoch 00015: val_loss improved from 0.35887 to 0.32080, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_9_conv_checkpoint/015-0.3208.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1898 - acc: 0.9401 - val_loss: 0.3208 - val_acc: 0.9145\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1724 - acc: 0.9462\n",
      "Epoch 00016: val_loss did not improve from 0.32080\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1723 - acc: 0.9462 - val_loss: 0.3285 - val_acc: 0.9171\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9479\n",
      "Epoch 00017: val_loss did not improve from 0.32080\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1634 - acc: 0.9478 - val_loss: 0.3872 - val_acc: 0.9036\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1545 - acc: 0.9511\n",
      "Epoch 00018: val_loss did not improve from 0.32080\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1545 - acc: 0.9511 - val_loss: 0.3621 - val_acc: 0.9094\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9577\n",
      "Epoch 00019: val_loss did not improve from 0.32080\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1358 - acc: 0.9577 - val_loss: 0.4167 - val_acc: 0.8931\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9558\n",
      "Epoch 00020: val_loss did not improve from 0.32080\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1351 - acc: 0.9558 - val_loss: 0.3295 - val_acc: 0.9131\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1232 - acc: 0.9596\n",
      "Epoch 00021: val_loss did not improve from 0.32080\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1232 - acc: 0.9596 - val_loss: 0.3259 - val_acc: 0.9196\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9627\n",
      "Epoch 00022: val_loss improved from 0.32080 to 0.27686, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_9_conv_checkpoint/022-0.2769.hdf5\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1159 - acc: 0.9627 - val_loss: 0.2769 - val_acc: 0.9341\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9665\n",
      "Epoch 00023: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1042 - acc: 0.9665 - val_loss: 0.4734 - val_acc: 0.8873\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9671\n",
      "Epoch 00024: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.1007 - acc: 0.9671 - val_loss: 0.3363 - val_acc: 0.9189\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9708\n",
      "Epoch 00025: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0908 - acc: 0.9708 - val_loss: 0.3889 - val_acc: 0.9031\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9696\n",
      "Epoch 00026: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0927 - acc: 0.9696 - val_loss: 0.3529 - val_acc: 0.9157\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9713\n",
      "Epoch 00027: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0857 - acc: 0.9713 - val_loss: 0.3355 - val_acc: 0.9201\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9750\n",
      "Epoch 00028: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0779 - acc: 0.9750 - val_loss: 0.3333 - val_acc: 0.9208\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9779\n",
      "Epoch 00029: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0708 - acc: 0.9779 - val_loss: 0.3150 - val_acc: 0.9257\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0839 - acc: 0.9732\n",
      "Epoch 00030: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0839 - acc: 0.9732 - val_loss: 0.3106 - val_acc: 0.9266\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9771\n",
      "Epoch 00031: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0697 - acc: 0.9771 - val_loss: 0.3146 - val_acc: 0.9243\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9779\n",
      "Epoch 00032: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0673 - acc: 0.9779 - val_loss: 0.3304 - val_acc: 0.9194\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9798\n",
      "Epoch 00033: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0649 - acc: 0.9798 - val_loss: 0.3094 - val_acc: 0.9283\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9784\n",
      "Epoch 00034: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0660 - acc: 0.9784 - val_loss: 0.4385 - val_acc: 0.9061\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9809\n",
      "Epoch 00035: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0578 - acc: 0.9809 - val_loss: 0.2949 - val_acc: 0.9297\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9819\n",
      "Epoch 00036: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0550 - acc: 0.9819 - val_loss: 0.3929 - val_acc: 0.9201\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9808\n",
      "Epoch 00037: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0562 - acc: 0.9808 - val_loss: 0.3483 - val_acc: 0.9236\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9843\n",
      "Epoch 00038: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0522 - acc: 0.9843 - val_loss: 0.3176 - val_acc: 0.9345\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9855\n",
      "Epoch 00039: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0456 - acc: 0.9855 - val_loss: 0.3935 - val_acc: 0.9157\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9797\n",
      "Epoch 00040: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0635 - acc: 0.9797 - val_loss: 0.4163 - val_acc: 0.9157\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9858\n",
      "Epoch 00041: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0444 - acc: 0.9858 - val_loss: 0.3613 - val_acc: 0.9243\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9864\n",
      "Epoch 00042: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0430 - acc: 0.9864 - val_loss: 0.3441 - val_acc: 0.9331\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9851\n",
      "Epoch 00043: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0465 - acc: 0.9851 - val_loss: 0.3315 - val_acc: 0.9297\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9833\n",
      "Epoch 00044: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0516 - acc: 0.9833 - val_loss: 0.3635 - val_acc: 0.9187\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9857\n",
      "Epoch 00045: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0452 - acc: 0.9857 - val_loss: 0.2869 - val_acc: 0.9385\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9869\n",
      "Epoch 00046: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0397 - acc: 0.9869 - val_loss: 0.3464 - val_acc: 0.9329\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9883\n",
      "Epoch 00047: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0375 - acc: 0.9883 - val_loss: 0.3637 - val_acc: 0.9308\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9868\n",
      "Epoch 00048: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0413 - acc: 0.9868 - val_loss: 0.3526 - val_acc: 0.9304\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9867\n",
      "Epoch 00049: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0428 - acc: 0.9867 - val_loss: 0.3371 - val_acc: 0.9285\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9842\n",
      "Epoch 00050: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0470 - acc: 0.9842 - val_loss: 0.3224 - val_acc: 0.9350\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9902\n",
      "Epoch 00051: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0316 - acc: 0.9902 - val_loss: 0.3727 - val_acc: 0.9290\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9875\n",
      "Epoch 00052: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0407 - acc: 0.9875 - val_loss: 0.3536 - val_acc: 0.9350\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9901\n",
      "Epoch 00053: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0323 - acc: 0.9901 - val_loss: 0.3508 - val_acc: 0.9292\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9884\n",
      "Epoch 00054: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0356 - acc: 0.9883 - val_loss: 0.3801 - val_acc: 0.9231\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9886\n",
      "Epoch 00055: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0367 - acc: 0.9886 - val_loss: 0.3513 - val_acc: 0.9308\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9883\n",
      "Epoch 00056: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0362 - acc: 0.9883 - val_loss: 0.3945 - val_acc: 0.9262\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9902\n",
      "Epoch 00057: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0298 - acc: 0.9902 - val_loss: 0.4944 - val_acc: 0.8998\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9900\n",
      "Epoch 00058: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0335 - acc: 0.9900 - val_loss: 0.3622 - val_acc: 0.9243\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9895\n",
      "Epoch 00059: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0349 - acc: 0.9895 - val_loss: 0.4952 - val_acc: 0.9036\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9889\n",
      "Epoch 00060: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0364 - acc: 0.9889 - val_loss: 0.3495 - val_acc: 0.9304\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9920\n",
      "Epoch 00061: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0252 - acc: 0.9919 - val_loss: 0.3523 - val_acc: 0.9280\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9856\n",
      "Epoch 00062: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0458 - acc: 0.9856 - val_loss: 0.4201 - val_acc: 0.9250\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9931\n",
      "Epoch 00063: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0245 - acc: 0.9931 - val_loss: 0.3606 - val_acc: 0.9313\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0268 - acc: 0.9919\n",
      "Epoch 00064: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0268 - acc: 0.9919 - val_loss: 0.3716 - val_acc: 0.9269\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9913\n",
      "Epoch 00065: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0281 - acc: 0.9913 - val_loss: 0.3385 - val_acc: 0.9350\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9926\n",
      "Epoch 00066: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0244 - acc: 0.9926 - val_loss: 0.3753 - val_acc: 0.9341\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9924\n",
      "Epoch 00067: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0253 - acc: 0.9924 - val_loss: 0.4148 - val_acc: 0.9294\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9922\n",
      "Epoch 00068: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0264 - acc: 0.9922 - val_loss: 0.4145 - val_acc: 0.9266\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9908\n",
      "Epoch 00069: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0277 - acc: 0.9908 - val_loss: 0.5464 - val_acc: 0.8998\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0310 - acc: 0.9907\n",
      "Epoch 00070: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0310 - acc: 0.9907 - val_loss: 0.3328 - val_acc: 0.9387\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9920\n",
      "Epoch 00071: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0251 - acc: 0.9920 - val_loss: 0.3658 - val_acc: 0.9243\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9933\n",
      "Epoch 00072: val_loss did not improve from 0.27686\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0219 - acc: 0.9933 - val_loss: 0.3502 - val_acc: 0.9324\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.3272 - acc: 0.9092\n",
      "Loss: 0.32718686868406655 Accuracy: 0.909242\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8523 - acc: 0.4335\n",
      "Epoch 00001: val_loss improved from inf to 1.18483, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/001-1.1848.hdf5\n",
      "36805/36805 [==============================] - 153s 4ms/sample - loss: 1.8523 - acc: 0.4335 - val_loss: 1.1848 - val_acc: 0.6303\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9581 - acc: 0.7049\n",
      "Epoch 00002: val_loss improved from 1.18483 to 0.70324, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/002-0.7032.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.9580 - acc: 0.7049 - val_loss: 0.7032 - val_acc: 0.7945\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6635 - acc: 0.7992\n",
      "Epoch 00003: val_loss improved from 0.70324 to 0.52107, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/003-0.5211.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.6635 - acc: 0.7992 - val_loss: 0.5211 - val_acc: 0.8516\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5017 - acc: 0.8487\n",
      "Epoch 00004: val_loss improved from 0.52107 to 0.38646, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/004-0.3865.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.5020 - acc: 0.8486 - val_loss: 0.3865 - val_acc: 0.8924\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4131 - acc: 0.8736\n",
      "Epoch 00005: val_loss did not improve from 0.38646\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.4131 - acc: 0.8737 - val_loss: 0.6360 - val_acc: 0.8102\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3462 - acc: 0.8938\n",
      "Epoch 00006: val_loss improved from 0.38646 to 0.36666, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/006-0.3667.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.3464 - acc: 0.8937 - val_loss: 0.3667 - val_acc: 0.8921\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3047 - acc: 0.9052\n",
      "Epoch 00007: val_loss improved from 0.36666 to 0.26865, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/007-0.2686.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.3046 - acc: 0.9052 - val_loss: 0.2686 - val_acc: 0.9234\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2583 - acc: 0.9195\n",
      "Epoch 00008: val_loss did not improve from 0.26865\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2586 - acc: 0.9194 - val_loss: 0.3130 - val_acc: 0.9057\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2415 - acc: 0.9251\n",
      "Epoch 00009: val_loss improved from 0.26865 to 0.24234, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/009-0.2423.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2415 - acc: 0.9251 - val_loss: 0.2423 - val_acc: 0.9338\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2020 - acc: 0.9358\n",
      "Epoch 00010: val_loss improved from 0.24234 to 0.24036, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/010-0.2404.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2021 - acc: 0.9358 - val_loss: 0.2404 - val_acc: 0.9320\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1887 - acc: 0.9405\n",
      "Epoch 00011: val_loss improved from 0.24036 to 0.22569, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/011-0.2257.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1887 - acc: 0.9405 - val_loss: 0.2257 - val_acc: 0.9357\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1737 - acc: 0.9455\n",
      "Epoch 00012: val_loss did not improve from 0.22569\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.1738 - acc: 0.9455 - val_loss: 0.3280 - val_acc: 0.9154\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1590 - acc: 0.9497\n",
      "Epoch 00013: val_loss did not improve from 0.22569\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1590 - acc: 0.9497 - val_loss: 0.3082 - val_acc: 0.9124\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1432 - acc: 0.9536\n",
      "Epoch 00014: val_loss did not improve from 0.22569\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1433 - acc: 0.9536 - val_loss: 0.2267 - val_acc: 0.9378\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9584\n",
      "Epoch 00015: val_loss did not improve from 0.22569\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1312 - acc: 0.9584 - val_loss: 0.2968 - val_acc: 0.9238\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9607\n",
      "Epoch 00016: val_loss improved from 0.22569 to 0.22471, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/016-0.2247.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1223 - acc: 0.9607 - val_loss: 0.2247 - val_acc: 0.9408\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1124 - acc: 0.9649\n",
      "Epoch 00017: val_loss did not improve from 0.22471\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1128 - acc: 0.9648 - val_loss: 0.2964 - val_acc: 0.9208\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9622\n",
      "Epoch 00018: val_loss improved from 0.22471 to 0.21139, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/018-0.2114.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.1155 - acc: 0.9622 - val_loss: 0.2114 - val_acc: 0.9397\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9683\n",
      "Epoch 00019: val_loss did not improve from 0.21139\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0988 - acc: 0.9683 - val_loss: 0.2285 - val_acc: 0.9411\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9721\n",
      "Epoch 00020: val_loss did not improve from 0.21139\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0846 - acc: 0.9721 - val_loss: 0.3605 - val_acc: 0.8973\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9728\n",
      "Epoch 00021: val_loss did not improve from 0.21139\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0838 - acc: 0.9728 - val_loss: 0.2305 - val_acc: 0.9450\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9746\n",
      "Epoch 00022: val_loss did not improve from 0.21139\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0790 - acc: 0.9746 - val_loss: 0.2560 - val_acc: 0.9401\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9764\n",
      "Epoch 00023: val_loss did not improve from 0.21139\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0714 - acc: 0.9764 - val_loss: 0.2436 - val_acc: 0.9364\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9775\n",
      "Epoch 00024: val_loss did not improve from 0.21139\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0699 - acc: 0.9775 - val_loss: 0.2834 - val_acc: 0.9324\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9776\n",
      "Epoch 00025: val_loss did not improve from 0.21139\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0665 - acc: 0.9776 - val_loss: 0.2331 - val_acc: 0.9420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9754\n",
      "Epoch 00026: val_loss improved from 0.21139 to 0.19087, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/026-0.1909.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0767 - acc: 0.9754 - val_loss: 0.1909 - val_acc: 0.9534\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9820\n",
      "Epoch 00027: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0556 - acc: 0.9820 - val_loss: 0.2321 - val_acc: 0.9448\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9804\n",
      "Epoch 00028: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0609 - acc: 0.9804 - val_loss: 0.2090 - val_acc: 0.9502\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9834\n",
      "Epoch 00029: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0503 - acc: 0.9834 - val_loss: 0.2157 - val_acc: 0.9474\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9835\n",
      "Epoch 00030: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0506 - acc: 0.9835 - val_loss: 0.1976 - val_acc: 0.9539\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9842\n",
      "Epoch 00031: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0492 - acc: 0.9842 - val_loss: 0.2183 - val_acc: 0.9436\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9815\n",
      "Epoch 00032: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0587 - acc: 0.9816 - val_loss: 0.2049 - val_acc: 0.9525\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9876\n",
      "Epoch 00033: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0403 - acc: 0.9876 - val_loss: 0.2810 - val_acc: 0.9376\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9861\n",
      "Epoch 00034: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0445 - acc: 0.9861 - val_loss: 0.2006 - val_acc: 0.9553\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9887\n",
      "Epoch 00035: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0365 - acc: 0.9887 - val_loss: 0.2059 - val_acc: 0.9504\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9846\n",
      "Epoch 00036: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0478 - acc: 0.9846 - val_loss: 0.2231 - val_acc: 0.9511\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9885\n",
      "Epoch 00037: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0356 - acc: 0.9885 - val_loss: 0.2243 - val_acc: 0.9509\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9889\n",
      "Epoch 00038: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0344 - acc: 0.9889 - val_loss: 0.2056 - val_acc: 0.9502\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9893\n",
      "Epoch 00039: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0335 - acc: 0.9893 - val_loss: 0.2249 - val_acc: 0.9502\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9888\n",
      "Epoch 00040: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0351 - acc: 0.9888 - val_loss: 0.2464 - val_acc: 0.9450\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9898\n",
      "Epoch 00041: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0330 - acc: 0.9898 - val_loss: 0.2027 - val_acc: 0.9569\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9897\n",
      "Epoch 00042: val_loss did not improve from 0.19087\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0324 - acc: 0.9897 - val_loss: 0.2524 - val_acc: 0.9406\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9898\n",
      "Epoch 00043: val_loss improved from 0.19087 to 0.18933, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/043-0.1893.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0315 - acc: 0.9898 - val_loss: 0.1893 - val_acc: 0.9553\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9909\n",
      "Epoch 00044: val_loss did not improve from 0.18933\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0277 - acc: 0.9909 - val_loss: 0.2021 - val_acc: 0.9555\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9911\n",
      "Epoch 00045: val_loss improved from 0.18933 to 0.18329, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/045-0.1833.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0293 - acc: 0.9911 - val_loss: 0.1833 - val_acc: 0.9555\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9914\n",
      "Epoch 00046: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0271 - acc: 0.9914 - val_loss: 0.2273 - val_acc: 0.9492\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9936\n",
      "Epoch 00047: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0206 - acc: 0.9936 - val_loss: 0.1982 - val_acc: 0.9595\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9907\n",
      "Epoch 00048: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0278 - acc: 0.9907 - val_loss: 0.2907 - val_acc: 0.9469\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9907\n",
      "Epoch 00049: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0284 - acc: 0.9906 - val_loss: 0.2674 - val_acc: 0.9408\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9866\n",
      "Epoch 00050: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0427 - acc: 0.9866 - val_loss: 0.2410 - val_acc: 0.9492\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9939\n",
      "Epoch 00051: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0197 - acc: 0.9939 - val_loss: 0.2317 - val_acc: 0.9513\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9935\n",
      "Epoch 00052: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0212 - acc: 0.9935 - val_loss: 0.2387 - val_acc: 0.9543\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9919\n",
      "Epoch 00053: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0248 - acc: 0.9919 - val_loss: 0.2669 - val_acc: 0.9432\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9931\n",
      "Epoch 00054: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0224 - acc: 0.9931 - val_loss: 0.2120 - val_acc: 0.9581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9910\n",
      "Epoch 00055: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0293 - acc: 0.9910 - val_loss: 0.2446 - val_acc: 0.9488\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9954\n",
      "Epoch 00056: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0150 - acc: 0.9954 - val_loss: 0.2486 - val_acc: 0.9532\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9929\n",
      "Epoch 00057: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0225 - acc: 0.9928 - val_loss: 0.2929 - val_acc: 0.9411\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9868\n",
      "Epoch 00058: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0429 - acc: 0.9868 - val_loss: 0.1836 - val_acc: 0.9581\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9947\n",
      "Epoch 00059: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0168 - acc: 0.9947 - val_loss: 0.2017 - val_acc: 0.9562\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9958\n",
      "Epoch 00060: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0148 - acc: 0.9958 - val_loss: 0.2321 - val_acc: 0.9548\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9954\n",
      "Epoch 00061: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0152 - acc: 0.9954 - val_loss: 0.2315 - val_acc: 0.9536\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9946\n",
      "Epoch 00062: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0181 - acc: 0.9946 - val_loss: 0.3524 - val_acc: 0.9357\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9937\n",
      "Epoch 00063: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0198 - acc: 0.9937 - val_loss: 0.2420 - val_acc: 0.9497\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9894\n",
      "Epoch 00064: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0345 - acc: 0.9894 - val_loss: 0.1886 - val_acc: 0.9609\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9954\n",
      "Epoch 00065: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0153 - acc: 0.9954 - val_loss: 0.2913 - val_acc: 0.9460\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9944\n",
      "Epoch 00066: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0183 - acc: 0.9944 - val_loss: 0.2540 - val_acc: 0.9543\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9941\n",
      "Epoch 00067: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0185 - acc: 0.9940 - val_loss: 0.2111 - val_acc: 0.9564\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9919\n",
      "Epoch 00068: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0253 - acc: 0.9918 - val_loss: 0.2420 - val_acc: 0.9515\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9893\n",
      "Epoch 00069: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0365 - acc: 0.9893 - val_loss: 0.2339 - val_acc: 0.9520\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9960\n",
      "Epoch 00070: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0127 - acc: 0.9960 - val_loss: 0.2510 - val_acc: 0.9548\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9972\n",
      "Epoch 00071: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0099 - acc: 0.9972 - val_loss: 0.2040 - val_acc: 0.9625\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9932\n",
      "Epoch 00072: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0228 - acc: 0.9932 - val_loss: 0.2518 - val_acc: 0.9527\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9962\n",
      "Epoch 00073: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0125 - acc: 0.9963 - val_loss: 0.3048 - val_acc: 0.9460\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9954\n",
      "Epoch 00074: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0152 - acc: 0.9954 - val_loss: 0.2389 - val_acc: 0.9518\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9943\n",
      "Epoch 00075: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0178 - acc: 0.9943 - val_loss: 0.2216 - val_acc: 0.9550\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9932\n",
      "Epoch 00076: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0207 - acc: 0.9931 - val_loss: 0.2466 - val_acc: 0.9536\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9902\n",
      "Epoch 00077: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0302 - acc: 0.9902 - val_loss: 0.2265 - val_acc: 0.9599\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9961\n",
      "Epoch 00078: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0125 - acc: 0.9961 - val_loss: 0.2430 - val_acc: 0.9550\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9968\n",
      "Epoch 00079: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0107 - acc: 0.9968 - val_loss: 0.2325 - val_acc: 0.9529\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9912\n",
      "Epoch 00080: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0292 - acc: 0.9911 - val_loss: 0.2104 - val_acc: 0.9555\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9929\n",
      "Epoch 00081: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0229 - acc: 0.9929 - val_loss: 0.2241 - val_acc: 0.9574\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9952\n",
      "Epoch 00082: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0168 - acc: 0.9952 - val_loss: 0.2374 - val_acc: 0.9567\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9978\n",
      "Epoch 00083: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0084 - acc: 0.9978 - val_loss: 0.2924 - val_acc: 0.9427\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9969\n",
      "Epoch 00084: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0105 - acc: 0.9969 - val_loss: 0.2692 - val_acc: 0.9513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9941\n",
      "Epoch 00085: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0182 - acc: 0.9941 - val_loss: 0.2679 - val_acc: 0.9525\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9956\n",
      "Epoch 00086: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0137 - acc: 0.9956 - val_loss: 0.2332 - val_acc: 0.9536\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9962\n",
      "Epoch 00087: val_loss did not improve from 0.18329\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0121 - acc: 0.9962 - val_loss: 0.2087 - val_acc: 0.9571\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9935\n",
      "Epoch 00088: val_loss improved from 0.18329 to 0.18238, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_10_conv_checkpoint/088-0.1824.hdf5\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0212 - acc: 0.9935 - val_loss: 0.1824 - val_acc: 0.9588\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9963\n",
      "Epoch 00089: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0117 - acc: 0.9963 - val_loss: 0.2221 - val_acc: 0.9602\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9968\n",
      "Epoch 00090: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0097 - acc: 0.9968 - val_loss: 0.2382 - val_acc: 0.9520\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9960\n",
      "Epoch 00091: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0125 - acc: 0.9960 - val_loss: 0.3345 - val_acc: 0.9446\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9958\n",
      "Epoch 00092: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0131 - acc: 0.9958 - val_loss: 0.2504 - val_acc: 0.9564\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9950\n",
      "Epoch 00093: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0149 - acc: 0.9950 - val_loss: 0.3940 - val_acc: 0.9327\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9954\n",
      "Epoch 00094: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0161 - acc: 0.9954 - val_loss: 0.2419 - val_acc: 0.9581\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0122 - acc: 0.9964\n",
      "Epoch 00095: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0122 - acc: 0.9964 - val_loss: 0.2418 - val_acc: 0.9548\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9963\n",
      "Epoch 00096: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0127 - acc: 0.9963 - val_loss: 0.1972 - val_acc: 0.9634\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9974\n",
      "Epoch 00097: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0086 - acc: 0.9974 - val_loss: 0.2698 - val_acc: 0.9478\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9968\n",
      "Epoch 00098: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0094 - acc: 0.9968 - val_loss: 0.2458 - val_acc: 0.9550\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9970\n",
      "Epoch 00099: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0098 - acc: 0.9969 - val_loss: 0.3026 - val_acc: 0.9478\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9915\n",
      "Epoch 00100: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0285 - acc: 0.9915 - val_loss: 0.2620 - val_acc: 0.9557\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9935\n",
      "Epoch 00101: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0212 - acc: 0.9935 - val_loss: 0.2456 - val_acc: 0.9539\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9980\n",
      "Epoch 00102: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0070 - acc: 0.9980 - val_loss: 0.2035 - val_acc: 0.9662\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9959\n",
      "Epoch 00103: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0133 - acc: 0.9959 - val_loss: 0.2246 - val_acc: 0.9604\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9969\n",
      "Epoch 00104: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0095 - acc: 0.9969 - val_loss: 0.2451 - val_acc: 0.9564\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9972\n",
      "Epoch 00105: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0092 - acc: 0.9972 - val_loss: 0.2404 - val_acc: 0.9588\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9921\n",
      "Epoch 00106: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0257 - acc: 0.9920 - val_loss: 0.2013 - val_acc: 0.9606\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9955\n",
      "Epoch 00107: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0141 - acc: 0.9955 - val_loss: 0.2629 - val_acc: 0.9534\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9979\n",
      "Epoch 00108: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0069 - acc: 0.9979 - val_loss: 0.2563 - val_acc: 0.9564\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9957\n",
      "Epoch 00109: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0136 - acc: 0.9957 - val_loss: 0.2174 - val_acc: 0.9618\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9976\n",
      "Epoch 00110: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0081 - acc: 0.9976 - val_loss: 0.2880 - val_acc: 0.9506\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9963\n",
      "Epoch 00111: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0116 - acc: 0.9963 - val_loss: 0.3117 - val_acc: 0.9427\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9965\n",
      "Epoch 00112: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0116 - acc: 0.9965 - val_loss: 0.2282 - val_acc: 0.9527\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9961\n",
      "Epoch 00113: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0123 - acc: 0.9961 - val_loss: 0.2470 - val_acc: 0.9560\n",
      "Epoch 114/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9966\n",
      "Epoch 00114: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0111 - acc: 0.9965 - val_loss: 0.2405 - val_acc: 0.9581\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9934\n",
      "Epoch 00115: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0221 - acc: 0.9934 - val_loss: 0.2303 - val_acc: 0.9562\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9981\n",
      "Epoch 00116: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0063 - acc: 0.9981 - val_loss: 0.2530 - val_acc: 0.9571\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9981\n",
      "Epoch 00117: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0071 - acc: 0.9981 - val_loss: 0.2471 - val_acc: 0.9560\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9977\n",
      "Epoch 00118: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0088 - acc: 0.9976 - val_loss: 0.3667 - val_acc: 0.9399\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9940\n",
      "Epoch 00119: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0208 - acc: 0.9940 - val_loss: 0.2426 - val_acc: 0.9597\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9975\n",
      "Epoch 00120: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0084 - acc: 0.9975 - val_loss: 0.2107 - val_acc: 0.9620\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9973\n",
      "Epoch 00121: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0086 - acc: 0.9973 - val_loss: 0.2336 - val_acc: 0.9574\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9969\n",
      "Epoch 00122: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0098 - acc: 0.9968 - val_loss: 0.3364 - val_acc: 0.9436\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9955\n",
      "Epoch 00123: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0151 - acc: 0.9955 - val_loss: 0.2654 - val_acc: 0.9534\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9975\n",
      "Epoch 00124: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0091 - acc: 0.9975 - val_loss: 0.3043 - val_acc: 0.9495\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9964\n",
      "Epoch 00125: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0110 - acc: 0.9964 - val_loss: 0.3039 - val_acc: 0.9492\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9933\n",
      "Epoch 00126: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0227 - acc: 0.9932 - val_loss: 0.2194 - val_acc: 0.9590\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9966\n",
      "Epoch 00127: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0117 - acc: 0.9966 - val_loss: 0.2050 - val_acc: 0.9648\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0053 - acc: 0.9986\n",
      "Epoch 00128: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0053 - acc: 0.9986 - val_loss: 0.2188 - val_acc: 0.9644\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9984\n",
      "Epoch 00129: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0057 - acc: 0.9984 - val_loss: 0.2555 - val_acc: 0.9569\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9968\n",
      "Epoch 00130: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0101 - acc: 0.9968 - val_loss: 0.2955 - val_acc: 0.9464\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9979\n",
      "Epoch 00131: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0067 - acc: 0.9979 - val_loss: 0.2095 - val_acc: 0.9627\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9977\n",
      "Epoch 00132: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 117s 3ms/sample - loss: 0.0077 - acc: 0.9977 - val_loss: 0.2428 - val_acc: 0.9585\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9962\n",
      "Epoch 00133: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0111 - acc: 0.9963 - val_loss: 0.3065 - val_acc: 0.9504\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9963\n",
      "Epoch 00134: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0102 - acc: 0.9963 - val_loss: 0.2850 - val_acc: 0.9481\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9970\n",
      "Epoch 00135: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0100 - acc: 0.9970 - val_loss: 0.3315 - val_acc: 0.9469\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9954\n",
      "Epoch 00136: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0153 - acc: 0.9954 - val_loss: 0.2295 - val_acc: 0.9606\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9977\n",
      "Epoch 00137: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0072 - acc: 0.9977 - val_loss: 0.2368 - val_acc: 0.9590\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9973\n",
      "Epoch 00138: val_loss did not improve from 0.18238\n",
      "36805/36805 [==============================] - 118s 3ms/sample - loss: 0.0083 - acc: 0.9973 - val_loss: 0.2363 - val_acc: 0.9602\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_10_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 0.2416 - acc: 0.9497\n",
      "Loss: 0.2416394650371337 Accuracy: 0.9497404\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8434 - acc: 0.4337\n",
      "Epoch 00001: val_loss improved from inf to 1.28135, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_11_conv_checkpoint/001-1.2814.hdf5\n",
      "36805/36805 [==============================] - 161s 4ms/sample - loss: 1.8433 - acc: 0.4337 - val_loss: 1.2814 - val_acc: 0.5872\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8296 - acc: 0.7442\n",
      "Epoch 00002: val_loss improved from 1.28135 to 0.53162, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_11_conv_checkpoint/002-0.5316.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.8298 - acc: 0.7441 - val_loss: 0.5316 - val_acc: 0.8402\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5383 - acc: 0.8351\n",
      "Epoch 00003: val_loss improved from 0.53162 to 0.33302, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_11_conv_checkpoint/003-0.3330.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.5384 - acc: 0.8350 - val_loss: 0.3330 - val_acc: 0.9031\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3946 - acc: 0.8796\n",
      "Epoch 00004: val_loss improved from 0.33302 to 0.27813, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_11_conv_checkpoint/004-0.2781.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.3949 - acc: 0.8796 - val_loss: 0.2781 - val_acc: 0.9229\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3234 - acc: 0.9018\n",
      "Epoch 00005: val_loss did not improve from 0.27813\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.3234 - acc: 0.9018 - val_loss: 0.2811 - val_acc: 0.9168\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2690 - acc: 0.9171\n",
      "Epoch 00006: val_loss improved from 0.27813 to 0.23778, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_11_conv_checkpoint/006-0.2378.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2691 - acc: 0.9171 - val_loss: 0.2378 - val_acc: 0.9336\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2356 - acc: 0.9254\n",
      "Epoch 00007: val_loss did not improve from 0.23778\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.2356 - acc: 0.9254 - val_loss: 0.2384 - val_acc: 0.9338\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2002 - acc: 0.9384\n",
      "Epoch 00008: val_loss improved from 0.23778 to 0.16687, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_11_conv_checkpoint/008-0.1669.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.2002 - acc: 0.9384 - val_loss: 0.1669 - val_acc: 0.9504\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1773 - acc: 0.9447\n",
      "Epoch 00009: val_loss did not improve from 0.16687\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1773 - acc: 0.9447 - val_loss: 0.1847 - val_acc: 0.9453\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9509\n",
      "Epoch 00010: val_loss did not improve from 0.16687\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1549 - acc: 0.9509 - val_loss: 0.3177 - val_acc: 0.9033\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1510 - acc: 0.9520\n",
      "Epoch 00011: val_loss did not improve from 0.16687\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1510 - acc: 0.9520 - val_loss: 0.1861 - val_acc: 0.9446\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9601\n",
      "Epoch 00012: val_loss did not improve from 0.16687\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1249 - acc: 0.9601 - val_loss: 0.3533 - val_acc: 0.9059\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1244 - acc: 0.9594\n",
      "Epoch 00013: val_loss did not improve from 0.16687\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1246 - acc: 0.9594 - val_loss: 0.2051 - val_acc: 0.9429\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9645\n",
      "Epoch 00014: val_loss did not improve from 0.16687\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1098 - acc: 0.9644 - val_loss: 0.2697 - val_acc: 0.9229\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1118 - acc: 0.9643\n",
      "Epoch 00015: val_loss improved from 0.16687 to 0.15859, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_11_conv_checkpoint/015-0.1586.hdf5\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.1118 - acc: 0.9642 - val_loss: 0.1586 - val_acc: 0.9525\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9703\n",
      "Epoch 00016: val_loss did not improve from 0.15859\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0925 - acc: 0.9702 - val_loss: 0.1765 - val_acc: 0.9492\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9679\n",
      "Epoch 00017: val_loss improved from 0.15859 to 0.12182, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_11_conv_checkpoint/017-0.1218.hdf5\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0991 - acc: 0.9679 - val_loss: 0.1218 - val_acc: 0.9672\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9757\n",
      "Epoch 00018: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0740 - acc: 0.9757 - val_loss: 0.1692 - val_acc: 0.9504\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9771\n",
      "Epoch 00019: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0705 - acc: 0.9771 - val_loss: 0.1711 - val_acc: 0.9539\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9789\n",
      "Epoch 00020: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0666 - acc: 0.9789 - val_loss: 0.1701 - val_acc: 0.9539\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9798\n",
      "Epoch 00021: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0623 - acc: 0.9798 - val_loss: 0.1392 - val_acc: 0.9641\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9798\n",
      "Epoch 00022: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0640 - acc: 0.9798 - val_loss: 0.2287 - val_acc: 0.9401\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0601 - acc: 0.9804\n",
      "Epoch 00023: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0601 - acc: 0.9804 - val_loss: 0.1949 - val_acc: 0.9460\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9810\n",
      "Epoch 00024: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0576 - acc: 0.9810 - val_loss: 0.1751 - val_acc: 0.9564\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9833\n",
      "Epoch 00025: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0497 - acc: 0.9833 - val_loss: 0.1513 - val_acc: 0.9604\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9873\n",
      "Epoch 00026: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0410 - acc: 0.9873 - val_loss: 0.1932 - val_acc: 0.9488\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9859\n",
      "Epoch 00027: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0435 - acc: 0.9858 - val_loss: 0.1823 - val_acc: 0.9567\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9824\n",
      "Epoch 00028: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0522 - acc: 0.9824 - val_loss: 0.1398 - val_acc: 0.9644\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9881\n",
      "Epoch 00029: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0371 - acc: 0.9881 - val_loss: 0.1529 - val_acc: 0.9539\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9885\n",
      "Epoch 00030: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0368 - acc: 0.9885 - val_loss: 0.2005 - val_acc: 0.9504\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9891\n",
      "Epoch 00031: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0343 - acc: 0.9891 - val_loss: 0.1631 - val_acc: 0.9606\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9885\n",
      "Epoch 00032: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0377 - acc: 0.9885 - val_loss: 0.1963 - val_acc: 0.9532\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9901\n",
      "Epoch 00033: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0310 - acc: 0.9901 - val_loss: 0.2082 - val_acc: 0.9492\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9894\n",
      "Epoch 00034: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0321 - acc: 0.9894 - val_loss: 0.1735 - val_acc: 0.9555\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9908\n",
      "Epoch 00035: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0285 - acc: 0.9908 - val_loss: 0.2112 - val_acc: 0.9520\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9901\n",
      "Epoch 00036: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0320 - acc: 0.9901 - val_loss: 0.3372 - val_acc: 0.9394\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9870\n",
      "Epoch 00037: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0411 - acc: 0.9870 - val_loss: 0.1873 - val_acc: 0.9564\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9911\n",
      "Epoch 00038: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0287 - acc: 0.9911 - val_loss: 0.2247 - val_acc: 0.9504\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9936\n",
      "Epoch 00039: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0215 - acc: 0.9936 - val_loss: 0.2376 - val_acc: 0.9450\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9926\n",
      "Epoch 00040: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0228 - acc: 0.9926 - val_loss: 0.1731 - val_acc: 0.9634\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0282 - acc: 0.9913\n",
      "Epoch 00041: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0282 - acc: 0.9913 - val_loss: 0.2321 - val_acc: 0.9478\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9931\n",
      "Epoch 00042: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0222 - acc: 0.9931 - val_loss: 0.2168 - val_acc: 0.9504\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9920\n",
      "Epoch 00043: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0249 - acc: 0.9920 - val_loss: 0.1615 - val_acc: 0.9644\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9926\n",
      "Epoch 00044: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0232 - acc: 0.9926 - val_loss: 0.1814 - val_acc: 0.9590\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9941\n",
      "Epoch 00045: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0187 - acc: 0.9941 - val_loss: 0.1818 - val_acc: 0.9574\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9943\n",
      "Epoch 00046: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0183 - acc: 0.9943 - val_loss: 0.1915 - val_acc: 0.9567\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9922\n",
      "Epoch 00047: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0249 - acc: 0.9921 - val_loss: 0.1498 - val_acc: 0.9674\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9912\n",
      "Epoch 00048: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0270 - acc: 0.9912 - val_loss: 0.1831 - val_acc: 0.9595\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9951\n",
      "Epoch 00049: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0159 - acc: 0.9951 - val_loss: 0.1705 - val_acc: 0.9627\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9953\n",
      "Epoch 00050: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0151 - acc: 0.9953 - val_loss: 0.2947 - val_acc: 0.9464\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9937\n",
      "Epoch 00051: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0190 - acc: 0.9937 - val_loss: 0.1559 - val_acc: 0.9660\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9943\n",
      "Epoch 00052: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0180 - acc: 0.9943 - val_loss: 0.1684 - val_acc: 0.9602\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9960\n",
      "Epoch 00053: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0140 - acc: 0.9960 - val_loss: 0.2869 - val_acc: 0.9390\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9940\n",
      "Epoch 00054: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0180 - acc: 0.9940 - val_loss: 0.2226 - val_acc: 0.9555\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9948\n",
      "Epoch 00055: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0152 - acc: 0.9948 - val_loss: 0.2000 - val_acc: 0.9578\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9942\n",
      "Epoch 00056: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0171 - acc: 0.9942 - val_loss: 0.1809 - val_acc: 0.9599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9955\n",
      "Epoch 00057: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0143 - acc: 0.9955 - val_loss: 0.2055 - val_acc: 0.9546\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9944\n",
      "Epoch 00058: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0183 - acc: 0.9943 - val_loss: 0.2289 - val_acc: 0.9567\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9922\n",
      "Epoch 00059: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0248 - acc: 0.9921 - val_loss: 0.1798 - val_acc: 0.9627\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9940\n",
      "Epoch 00060: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0186 - acc: 0.9940 - val_loss: 0.1545 - val_acc: 0.9620\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9971\n",
      "Epoch 00061: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0100 - acc: 0.9971 - val_loss: 0.1797 - val_acc: 0.9662\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9969\n",
      "Epoch 00062: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0094 - acc: 0.9969 - val_loss: 0.1451 - val_acc: 0.9686\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0141 - acc: 0.9954\n",
      "Epoch 00063: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0141 - acc: 0.9954 - val_loss: 0.1763 - val_acc: 0.9660\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9958\n",
      "Epoch 00064: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0150 - acc: 0.9958 - val_loss: 0.4552 - val_acc: 0.9269\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9941\n",
      "Epoch 00065: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0177 - acc: 0.9941 - val_loss: 0.2307 - val_acc: 0.9527\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9954\n",
      "Epoch 00066: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0143 - acc: 0.9954 - val_loss: 0.1625 - val_acc: 0.9669\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9963\n",
      "Epoch 00067: val_loss did not improve from 0.12182\n",
      "36805/36805 [==============================] - 119s 3ms/sample - loss: 0.0116 - acc: 0.9963 - val_loss: 0.2013 - val_acc: 0.9557\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_11_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd8VFX6+PHPmfROCIHQuwUIhI6LFFdFbKiriNjW/vO7rqvrqou67rq6xba7rn3RxS6IKFYWbBQLKCCgVEMn1PTeZub5/XFmJpNkEkKSIYE879frviZz67mTmfPcU+65RkRQSimlDsfR0glQSil1bNCAoZRSqkE0YCillGoQDRhKKaUaRAOGUkqpBtGAoZRSqkE0YCillGoQDRhKKaUaRAOGUkqpBglt6QQ0pw4dOkivXr1aOhlKKXXMWL16dZaIJDdk3eMqYPTq1YtVq1a1dDKUUuqYYYzZ1dB1tUpKKaVUg2jAUEop1SAaMJRSSjXIcdWGEUhlZSUZGRmUlZW1dFKOSZGRkXTr1o2wsLCWTopSqoUd9wEjIyODuLg4evXqhTGmpZNzTBERsrOzycjIoHfv3i2dHKVUCzvuq6TKyspISkrSYNEIxhiSkpK0dKaUAtpAwAA0WDSBfnZKKa82ETAOp7x8H05nfksnQymlWjUNGEBFxQGczoKg7DsvL49nn322Uduec8455OXlNXj9Bx54gMcff7xRx1JKqcPRgAEY4wDcQdl3fQHD6XTWu+2CBQto165dMJKllFJHTAMGACGIuIKy5xkzZrBt2zbS0tK46667WLJkCePGjWPKlCkMGDAAgAsvvJDhw4czcOBAZs6c6du2V69eZGVlsXPnTk4++WRuvPFGBg4cyKRJkygtLa33uGvXrmXMmDEMHjyYiy66iNzcXACefPJJBgwYwODBg7nssssAWLp0KWlpaaSlpTF06FAKCwuD8lkopY5tx323Wn/p6bdTVLS21ny3uxhw4HBEHfE+Y2PT6N//iTqXP/zww6xfv561a+1xlyxZwvfff8/69et9XVVnzZpF+/btKS0tZeTIkVx88cUkJSXVSHs6s2fP5oUXXuDSSy/lnXfe4corr6zzuFdffTVPPfUUEyZM4I9//CN//vOfeeKJJ3j44YfZsWMHERERvuquxx9/nGeeeYaxY8dSVFREZGTkEX8OSqnjn5YwADi6PYFGjRpV7b6GJ598kiFDhjBmzBj27NlDenp6rW169+5NWloaAMOHD2fnzp117j8/P5+8vDwmTJgAwC9/+UuWLVsGwODBg7niiit4/fXXCQ211wtjx47ljjvu4MknnyQvL883Xyml/LWpnKGukkBJyRZEhJiYk45KOmJiYnx/L1myhM8++4zly5cTHR3NxIkTA973EBER4fs7JCTksFVSdfn4449ZtmwZH374IX/961/58ccfmTFjBueeey4LFixg7NixLFq0iJNOOjqfhVLq2KElDMB+DMFp9I6Li6u3TSA/P5/ExESio6PZvHkzK1asaPIxExISSExM5MsvvwTgtddeY8KECbjdbvbs2cNpp53GI488Qn5+PkVFRWzbto3U1FR+//vfM3LkSDZv3tzkNCiljj9BK2EYY2YB5wGHRGRQgOV3AVf4peNkIFlEcowxO4FCwAU4RWREsNJp0+LA7Q5Oo3dSUhJjx45l0KBBnH322Zx77rnVlk+ePJnnn3+ek08+mRNPPJExY8Y0y3FfeeUVbr75ZkpKSujTpw8vvfQSLpeLK6+8kvz8fESE3/zmN7Rr147777+fxYsX43A4GDhwIGeffXazpEEpdXwxIhKcHRszHigCXg0UMGqsez7wWxH5uef9TmCEiGQdyTFHjBghNR+gtGnTJk4++eR6tyst3YnLlU9s7JAjOVyb0ZDPUCl1bDLGrG7oRXnQqqREZBmQ08DVpwOzg5WWwzHGgUhwqqSUUup40eJtGMaYaGAy8I7fbAE+McasNsbcdJjtbzLGrDLGrMrMzGxkGoLXhqGUUseLFg8YwPnA1yLiXxo5VUSGAWcDt3iqtwISkZkiMkJERiQnN+g55gE4ANFShlJK1aM1BIzLqFEdJSJ7Pa+HgPnAqGAmwJYw0IChlFL1aNGAYYxJACYA7/vNizHGxHn/BiYB64ObkhDPqwYMpZSqSzC71c4GJgIdjDEZwJ+AMAARed6z2kXAJyJS7LdpJ2C+5zkMocCbIrIwWOm0adUShlJKHU7QAoaITG/AOi8DL9eYtx04yv1bvQWt1hEwYmNjKSoqavB8pZQ6GlpDG0aL0xKGUkodngYMoOpjaP67vWfMmMEzzzzje+99yFFRURGnn346w4YNIzU1lffff7+evVQnItx1110MGjSI1NRU3nrrLQD279/P+PHjSUtLY9CgQXz55Ze4XC6uueYa37r/+te/mv0clVJtQ5safJDbb4e1tYc3DxE3Ue5iO7y5OcKPJC0Nnqh7ePNp06Zx++23c8sttwAwd+5cFi1aRGRkJPPnzyc+Pp6srCzGjBnDlClTGvQM7XfffZe1a9eybt06srKyGDlyJOPHj+fNN9/krLPO4r777sPlclFSUsLatWvZu3cv69fbfgNH8gQ/pZTy17YCxmE1/zApQ4cO5dChQ+zbt4/MzEwSExPp3r07lZWV3HvvvSxbtgyHw8HevXs5ePAgKSkph93nV199xfTp0wkJCaFTp05MmDCBlStXMnLkSK677joqKyu58MILSUtLo0+fPmzfvp1bb72Vc889l0mTJjX7OSql2oa2FTDqKAmIu4LS4h+IiOhJeHhjb/6r29SpU5k3bx4HDhxg2rRpALzxxhtkZmayevVqwsLC6NWrV8BhzY/E+PHjWbZsGR9//DHXXHMNd9xxB1dffTXr1q1j0aJFPP/888ydO5dZs2Y1x2kppdoYbcMAgt1Latq0acyZM4d58+YxdepUwA5r3rFjR8LCwli8eDG7du1q8P7GjRvHW2+9hcvlIjMzk2XLljFq1Ch27dpFp06duPHGG7nhhhv4/vvvycrKwu12c/HFF/OXv/yF77//PijnqJQ6/rWtEkYdqnpJBWeI84EDB1JYWEjXrl3p3LkzAFdccQXnn38+qampjBgx4ogeWHTRRRexfPlyhgwZgjGGRx99lJSUFF555RUee+wxwsLCiI2N5dVXX2Xv3r1ce+21uN02GP79738PyjkqpY5/QRvevCU0dnhzgMLC1YSHdyIioluwknfM0uHNlTp+tYrhzY89OsS5UkrVRwOGhz4TQyml6qcBw0efiaGUUvXRgOFhSxjBafRWSqnjgQYMnxC0hKGUUnXTgOGhbRhKKVU/DRgewXqud15eHs8++2yjtj3nnHN07CelVKuhAcMnOCWM+gKG0+msd9sFCxbQrl27Zk+TUko1hgYMD2OC04YxY8YMtm3bRlpaGnfddRdLlixh3LhxTJkyhQEDBgBw4YUXMnz4cAYOHMjMmTN92/bq1YusrCx27tzJySefzI033sjAgQOZNGkSpaWltY714YcfMnr0aIYOHcoZZ5zBwYMHASgqKuLaa68lNTWVwYMH88477wCwcOFChg0bxpAhQzj99NOb/dyVUseXNjU0SB2jmwPgdndCpD0hIYGX1+Uwo5vz8MMPs379etZ6DrxkyRK+//571q9fT+/evQGYNWsW7du3p7S0lJEjR3LxxReTlJRUbT/p6enMnj2bF154gUsvvZR33nmHK6+8sto6p556KitWrMAYw4svvsijjz7KP/7xDx566CESEhL48ccfAcjNzSUzM5Mbb7yRZcuW0bt3b3Jyco7sxJVSbU4wn+k9CzgPOCQigwIsnwi8D+zwzHpXRB70LJsM/BvbdelFEXk4WOn0S5HnVfz+Do5Ro0b5ggXAk08+yfz58wHYs2cP6enptQJG7969SUtLA2D48OHs3Lmz1n4zMjKYNm0a+/fvp6KiwneMzz77jDlz5vjWS0xM5MMPP2T8+PG+ddq3b9+s56iUOv4Es4TxMvA08Go963wpIuf5zzC2bugZ4EwgA1hpjPlARDY2NUH1lQTKy3OoqNhLbOywBj3EqCliYmJ8fy9ZsoTPPvuM5cuXEx0dzcSJEwMOcx4REeH7OyQkJGCV1K233sodd9zBlClTWLJkCQ888EBQ0q+UapuC1oYhIsuAxtRzjAK2ish2EakA5gAXNGviAgjWc73j4uIoLCysc3l+fj6JiYlER0ezefNmVqxY0ehj5efn07VrVwBeeeUV3/wzzzyz2mNic3NzGTNmDMuWLWPHDlvA0yoppdThtHSj9ynGmHXGmP8ZYwZ65nUF9vitk+GZF5Ax5iZjzCpjzKrMzMwmJCU4z/VOSkpi7NixDBo0iLvuuqvW8smTJ+N0Ojn55JOZMWMGY8aMafSxHnjgAaZOncrw4cPp0KGDb/4f/vAHcnNzGTRoEEOGDGHx4sUkJyczc+ZMfvGLXzBkyBDfg52UUqouQR3e3BjTC/iojjaMeMAtIkXGmHOAf4tIf2PMJcBkEbnBs95VwGgR+fXhjteU4c0rK7MpK9tBdPRAQkKiGnB2bYcOb67U8euYGN5cRApEpMjz9wIgzBjTAdgLdPdbtZtnXpB5u0fp3d5KKRVIiwUMY0yK8bQuG2NGedKSDawE+htjehtjwoHLgA+Cn57gtGEopdTxIpjdamcDE4EOxpgM4E9AGICIPA9cAvyfMcYJlAKXia0fcxpjfg0swl72zxKRDcFKZ5XgPtdbKaWOdUELGCIy/TDLn8Z2uw20bAGwIBjpqkuwn+utlFLHupbuJdVqeAOGljCUUiowDRg+ttFb2zCUUiowDRgeranROzY2tqWToJRStWjA8NEqKaWUqo8GDA/bw9c0ewljxowZ1YbleOCBB3j88ccpKiri9NNPZ9iwYaSmpvL+++8fdl91DYMeaJjyuoY0V0qpxmpbw5svvJ21B+oY3xxwuYowJhSHI7LB+0xLSeOJyXWPajht2jRuv/12brnlFgDmzp3LokWLiIyMZP78+cTHx5OVlcWYMWOYMmVKvQMfBhoG3e12BxymPNCQ5kop1RRtKmAcXvOPUjt06FAOHTrEvn37yMzMJDExke7du1NZWcm9997LsmXLcDgc7N27l4MHD5KSklLnvgINg56ZmRlwmPJAQ5orpVRTtKmAUV9JAKC4eD0ORxRRUX2b9bhTp05l3rx5HDhwwDfI3xtvvEFmZiarV68mLCyMXr16BRzW3Kuhw6ArpVSwaBtGNcF5rve0adOYM2cO8+bNY+rUqYAdirxjx46EhYWxePFidu3aVe8+6hoGva5hygMNaa6UUk2hAcOP7Vrb/AFj4MCBFBYW0rVrVzp37gzAFVdcwapVq0hNTeXVV1/lpJNOqncfdQ2DXtcw5YGGNFdKqaYI6vDmR1tThjcHKClJR6SSmJgBwUjeMUuHN1fq+HVMDG/eGgWrhKGUUscDDRjVBKcNQymljgdtImA0tNpNSxi1HU9VlkqppjnuA0ZkZCTZ2dkNzPi0hOFPRMjOziYysuE3Miqljl/H/X0Y3bp1IyMjg8zMzMOu63Tm4XTmExm5kWDcxHcsioyMpFu3bi2dDKVUK3DcB4ywsDDfXdCHs3v3o2zf/ntSUwsJDdURY5VSyt9xXyXVIF26wP33ExISA4DbXdLCCVJKqdYnaAHDGDPLGHPIGLO+juVXGGN+MMb8aIz5xhgzxG/ZTs/8tcaYVYG2b1YVFZCTg8NhA4bLVRz0Qyql1LEmmCWMl4HJ9SzfAUwQkVTgIWBmjeWniUhaQ28oaZL4eMjP95UwNGAopVRtQWvDEJFlxphe9Sz/xu/tCqDlWlYTEqoFDLdbA4ZSStXUWtowrgf+5/degE+MMauNMTfVt6Ex5iZjzCpjzKqG9IQKKD4eCgpwOKIBLWEopVQgLd5LyhhzGjZgnOo3+1QR2WuM6Qh8aozZLCLLAm0vIjPxVGeNGDGicXeZJSTA7t1+VVLa6K2UUjW1aAnDGDMYeBG4QESyvfNFZK/n9RAwHxgV1IQkJEBBgVZJKaVUPVosYBhjegDvAleJyE9+82OMMXHev4FJQMCeVs1GG72VUuqwglYlZYyZDUwEOhhjMoA/AWEAIvI88EcgCXjW8xxrp6dHVCdgvmdeKPCmiCwMVjoBX6O3w2gbhlJK1SWYvaSmH2b5DcANAeZvB4bU3iKI4uPB5SKkwg4HogFDKaVqay29pFpWQgIAjsIKwOid3kopFYAGDPAFDFNYiMMRrSUMpZQKQAMG2Cop8DV8a8BQSqnaNGCAr4ThDRjarVYppWrTgAFVAcNzL4aWMJRSqjYNGFCtSsq2YWijt1JK1aQBA2qVMLRKSimlatOAARAXZ1+10VsppeqkAQMgNBRiYjxVUhowlFIqEA0YXn4DEGrAUEqp2jRgePkGIIzWO72VUioADRhenhKGVkkppVRgGjC8/IY4F6nA7Xa2dIqUUqpV0YDhpc/1VkqpemnA8Krx1D2tllJKqeo0YHh5qqQcDu9DlLThWyml/GnA8EpIgOJiQogEtEpKKaVqCmrAMMbMMsYcMsYEfCa3sZ40xmw1xvxgjBnmt+yXxph0z/TLYKYT8I0nFVqiT91TSqlAgl3CeBmYXM/ys4H+nukm4DkAY0x77DPARwOjgD8ZYxKDmlLPeFIhRQJowFBKqZqCGjBEZBmQU88qFwCvirUCaGeM6QycBXwqIjkikgt8Sv2Bp+m8AaPYDWjAUEqpmkJb+PhdgT1+7zM88+qaHzyeKqmQIieEaRuGUsFUVgYFBSACbrd9BQgPh+hoiIwERx2Xsy4XFBdDSYmdSkvt+rGxdoqOBmNrlnG7obISnE47LyTEDh3n3bfTadNSVgbl5Xb9iAi7v4gIm5660uHP6YScHDtlZ0Nenj0nY6qmsDCbtqioqldvGt1ue17GVF8eEWHXqay06fOms6LCzvO+AgwbFjhtzamlA0aTGWNuwlZn0aNHj8bvyFPCcBQ5IVF7SR1rnE7IzIQDB6oykKioqh9fu3b2x19TRQXs2gXbt9sMzPvj9f6AXS67b++riM1wvBlPSIjdh3/mVV5u54eF2XVCQ+3+vBmTdx2Ho2p5aKhNc/v2kJRkXxMTbcZ44ADs32+nQ4dsZpSfb9Obn28zjPDw6pM30/NODodNnzejLfZcD0VEVE1hYTadTmfVVFFh0+s/uVz2c/Bm9g6Hzajj4qqmqKjq6XE4ICsLDh6055Off/j/qTfT9v4f/Kf6GGOPWVlp01ffet5AVZ/o6OrnFhFhPz//qajo8PtpDG/gO1w6O3Wyn2uwNShgGGNuA14CCoEXgaHADBH5pInH3wt093vfzTNvLzCxxvwlgXYgIjOBmQAjRoxowL+/Dt6AUVjhCRhawmgIkaqM0JsZ1syYSkpqXxHV/CGLBM6ga76WlNiM0ptZ5uXZTDQz8/A/qvh46NDBThERsHMnZGQ0LNNoKG9m5U1vzWVRUVUZoUjV1a/TaT+7+jK4+HibMbRrZ7+uXbva17Cwqs+2oqLqCrSszGZkWVk2PdHRdlDmDh3s32DX9a5fUVEVuLwBMTy8KvB60x4aas/F4bCvLpc9TmFh1VRWZv/3ubl2vy6XDYSDB8OkSVXn4b8fqApQ3gDsDb7+U0SEPY/o6KrSSHm5TUNRkT1uWZn9XLxTqCen8/8uud1VAdUbYI2p+ky8V/Q1z628HFJSbBq8U7t2VYE+Kcn+XxyOqsDq/V97z837CvacHI6q9cvKqs6/pMSmyb/U4x/gw8Pta0xM832H69PQEsZ1IvJvY8xZQCJwFfAa0NSA8QHwa2PMHGwDd76I7DfGLAL+5tfQPQm4p4nHqp+nSspRWAa03Sqp3FzYtg22brVf3IQE+9HEx0N4hJv0nxysW4dv2r07uOnxXoV7M4uYmKr0xMdD374wdqzNgFJS7BQdXRW8vD/M3FybcWZl2eBSVgYTJ0KfPnbq3dv+2L0/XO9UszThzSD9M56IiKqSTERE9atCb5WIdx/eZYG43TZD8lZr5OTY8+3cueq8jgVlzjIcxkF4SIAiXRtS4aqgoLzAN4WLmy4RCSREJpAQkUBYSFij9usWNw7TMndENDRgeL/m5wCvicgGY+r76ns2MmY2tqTQwRiTge35FAYgIs8DCzz73AqUANd6luUYYx4CVnp29aCI1Nd43nS+KqkSjAk95koYIrZqZfNmm/H4V4eUlNiMffduu86ePfZKzvsfNMZmoNu320yqxp6h9xcw6hk48QPIGINZcyMnOqcydmw0v/xlVX2r9wooOtpWUXivvmz1hLC7ZDOrs75k1aGv6BDdgduGzyA5uqPvSP4Zs7eeuWb9sYiQW5bLgaIDHCw6SGFFIaO6jiIlNqWez0Y4UHSAHw7+YKdDP5BVkkXfrmMY33M8Y7qNISosqt7Pt9xZzsp9K8kuyWZgx4H06djnsD9ab515SEi9q/k4HPZrmJBgA9iREhG+3P0lc9bPYXCnwVw68FLaR7U/7HabMjfxzqZ3WLZrGckxyfRK6EWvdnZKiU0hOiya6LBoosKiiA6LJswRhv/Pv7SylG/2fMOSnUtYsmsJ32Z8C8DJySeTlpLGkE5DGJA8gNLKUrJLs8kqySK7JJv4iHiuGHwFfRL71ErThkMbeHz54yzauogucV3o274vfRPtNL7nePon9W/w5+IWN8UVxRRWFFJUUURheSGFFYVUuirpFt+Nnu16Eh1WdzTOLc1la85WtuZsJT0nnQNFBwh1hFab8svy2V+0n32F+9hftJ+DRQcpd5XXm67Y8FjuOfUe7jn1Hg6XnR4qPsS7m97l7Y1vs3TnUgYkD+D03qdzep/TmdBzAnERcQ3+PJrCSAPK48aYl7CNzr2BIUAIsEREhgc3eUdmxIgRsmrVqsZtLGJz2bvv5suznyUl5Zf07//v5k1gHfYV7mNP/h56JPSgU2ynWhlRXh6kp9vqE/8qhPJym8mvWQNr19r16hMSYqsxunWranATgdLw3WSnvE1KYiw9OyVxQtcOnNy7PesLlvHKxmfYUbSZ+NAOjIz9BemVS9hd/JP9sadewVl9zyKvLI/MkkwyizPJKsmiwl1R7bj5Zfksz1hOVkkWAB1jOpJdkk1MeAz3nnovt425jcjQyIBp3pO/h6W7lrJ051K+3P0l23O3U+murLXe4E6DmdRnEpP6TqJTbCfWHVjHuoPrWHtgLesOrvMdG6BbfDcSIxNZf2g9ghAeEs6orqMYmDyQ5OhkkmOSSY5OJiosilX7VvHl7i/5NuPbahlAdFg0A5IHkNoxlZ4JPUmJTaFTbCdSYlOICYthe+52fsr+yU45P1HpqiQ5JpkOUR1IjkkmJTaFcT3GMbTz0Fr/78ziTF5Z9wqv/fAaIkK/9v18U9/EvvRO7E33+O6+K9TSylJmr5/Nk98+ybqD6wgPCafCVUF4SDjnnXAeVw2+isn9JlPmLCO/LJ/88nxySnNYvGMx8zbNY2PmRgCGdBpCQXkBu/N345L6GwpCTIgvsyx3leN0O3EYByO6jGBCzwmEmBDf57+/aH+t7SNDIyl3liMIE3tN5Nq0a7n45ItZuW8lj33zGAvSFxAVGsUFJ11Abmku23K3sTNvJ063E4Nh2qBp3D/+fgYkD/DtU0RYuW8ls9bM4qvdX1W7uhfqz+eSo5Pp1a4XcRFxvqBSVFFEfnk+BeUF1dZNikrCLW6cbidOt5NKdyXxEfF0ju1M57jOdI7tTEpsCu0i2xEXHkd8RDzxEfE4jIP88nzyyvLIL8vnu33f8dFPH3HrqFt5YvITtb4HbnEz+8fZ/HfNf1m6aylucXNC0gmc1fcsNmZu5Os9X1PmLCPEhPCz7j9j8S8XE+Jo4NWJH2PMahEZ0aB1GxgwHEAasF1E8jz3SXQTkR+OOHVB1KSAAbbycfp0vrn8XZKSzuXEE19ovsTVUOGq4KOfPuK/a/7Lwq0LcYutvA414SRID8JLetP+x/s5uHIcWVmB9iAw6mnCy7syNPIXpKXB0KEwcGBVg5/TCen569lfuZnLh19Az25hvrpcsD+w1354jVv/d2utH4XXqK6juGXkLVw68FIiQyN9V7Evfv8ib298mzJnmW/d8JBwOkR3qJX5R4REMKrrKMb1GMf4nuPp174fW7K3cPend/PhTx/SM6Enf/n5X+gQ3YFtOdvYlmunHw7+wM68nQAkRCRwao9TGdRxEJ1ibMacEptCRGgEy3Yt45Ntn/D1nq+pcFVUO+6gjoMY0mkIQ1KGMLjTYFI7ppIUnQRAXlkeX+/+mqW7lrJs1zK2524nuzTb978AmzEO6zyMcT3GMa7nOFJiU9iYuZEfD/7I+sz1rD+0ngNFdbc2dozpSP/2/YkMjfQF1cySTJye0ZBTYlM4p985nHvCucSFx/HfNf/l3U3vUumu5JRup5Ack0x6djrbcrdVOzeHcdir44SebMzcSHZpNqkdU/nN6N9weerlbM7azGvrXuPN9W9yqPhQwLQ5jIPxPcdzycmXcNHJF9ElrgsATreTfYX72Jm3k0PFhyitLKWkssQ3VborfZml0+0kMjSSsd3HMrbHWOIj4msdJ7M4ky3ZW4gJi6FDdAeSopOIDosmoyCDV9e9yqw1s9iWu40wRxiV7kqSo5O5ddSt/Grkr3z/K2+6dubt5MXvX+Tp756mpLKEqQOnctvo2/hu73f8d81/WX9oPVGhUZzR5ww6RHfwZdZx4XHERcQRFx5HbHgscRFxhDpCySjIYGfeTnbm7WRH3g5KKkt868aGxxIXHkfPhJ70T+pPv/b96N2u92FLow3lFjd3fXIX/1zxT6YPms7LF77sq8Zbe2Attyy4hW/2fMMJSSdw6YBLmTpwKqkdU32lkTJnGd/s+YYvdnzBoeJDzDx/ZqPSEYyAMRZYKyLFxpgrgWHAv0VkV6NSGCRNDhh9+sDYsXz76xXExY1kwIA3m5SeksoS3tv8HnsL9iIIbnEjIuwv2s+c9XPILMkkTroSsekastaNgvg9kLAb2u0ipNc3SFQWk3M/YGKPM+jfH3r2tCWD0DA3f/v+dl7a+BQAj535GHf+7M5ax/9wy4dc9s5llFSW0COhB3eecifXD7ue6LBoskqy+H8f/T/e3fQeu5P6AAAgAElEQVQup/Y4lRfPf5HY8NhqVQZ9EvswvEvdhcjc0lzSc9JJikoiOSaZuPC4wxata/p8++f87pPfse7gOt+8qNAo+iT24aQOJzGuxzgm9JpAasfUw149FVcUs2zXMvLK8hjcaTAndjiRUMeRdQR0uV3kluWSWZxJYUUhA5IHEBseW+82la5KMksyOVB0gANFBygsL6RPYh/6J/WnXWS7Wut7q8g+3f4pH6d/zKKti8gvt92GEiMTuXrI1dw47EYGdhxYLV17C/eyNWcru/J22Uwufyc7cnfQKbYTt4y8hQk9J9T6/CtdlXy6/VNW7l1JfES8r/48ITKBwZ0G0zGmIy1NRPhq91e8vfFtBiYP5OohVx82U84qyeKfy//JU989RVGF7aI0sstIrh96PZcNuoyEyISjkfQmExEe++Yxfv/Z75nUdxKzpszi0a8f5emVT5MUlcSjZz7K1UOuDmqbRTACxg/YqqjB2Lu3XwQuFZEJTUhns2tywEhLgx49WHn/biIje5Ka+n6dq7rFzfI9y4kNj6Vv+77VMpXv93/PC6tf4M31bwa8cjcSSvj2KZSvuB7HjrOYMC6E006Dk06CE06Afv2ghExOf/V00nPSmT9tPpP72fsWXW4XN390My+ueZHbR9/OvqJ9zN0wlzvG3MFjkx7zfbGe+vYpbl90O8M6D+POU+7k6ZVP89Vu23Zw9eCreePHN8gty+Wh0x7id6f8rlFF2ebicrv4YscXRIVF0TexLymxKUcceI5lla5KvtnzDdml2ZzT/5w6q+dUbTmlOczfNJ9RXUeR2im1pZPTaLPWzOLGD28EbBC5ecTN/PXnfyUxKrgDXMCRBQxE5LAT8L3n9Y/A9f7zWtM0fPhwaZLx40UmTJDVq38ma9acHnCVssoyeWH1C3LCUycID+CbOj/eWcbNGidDnhsiPIBE/iVSznr+KrnwtqUyaFiRhEQWC6GlQkiZtGtfKdOni7z5pkhOTt3JySzOlLTn0yT8oXD5cMuHUumqlCvfvVJ4ALnv8/vE7XaLy+2SWxfcKjyAXPHOFVJaWSq3/+924QHkgtkXSFF5kW9/X+76Us578zzhAST12VRZd2Bd0z4vpVSz+WDzB3LRnItk5d6VR/W4wCppYB7b0BLGUmAhcB0wDjgErBORVhXSm1zCOP98yMhg3cvJuFyFDBu23LeooLyA51Y+xxPfPsGBogMM6zyM3475LREhEdV6UBQUOel08Eo2zb2cPentiIqCceNg+HB7J+awYbYHTEMvoHNKczjr9bNYd2Adp3Q/hWW7lvGX0/7CfePv860jIjz81cPc+8W9dIzpyKHiQ9w2+jb+MekfAUsOmcWZtIts1+hufUqp48eRlDAaWsE7Dbgcez/GAWNMD+Cxxiaw1UpIgI0bcTh6UlFx0De7wlXBxJcnsubAGib1ncTrF73Oz3v/vFq1yYoV8IenYN3ntnvkpEnwtz/ChRfaLqaN1T6qPZ9e9SmTX5/Msl3L+Oekf/LbU35bbR1jDPeMu4dOsZ347aLf8sRZT3DbmNvq3GdyTHLjE6SUarMaFDA8QeINYKQx5jzgOxF5NbhJawF+j2n1vw/joaUPsebAGt6e+jaXDLik2iZr18L998NHH0FyMjz6KFx9tb2RrLm0i2zHF7/8gp+yfyItJa3O9a4beh3Xpl3bpur/lVJHT4Oa3o0xlwLfAVOBS4FvjTGX1L/VMcjz1L0QR7TvTu/v9n7H37/6O9ekXVMtWBQVweWX266sX30Ff/ubvSfirruaN1h4RYdF1xssvDRYKKWCpaFVUvcBI0XkEIAxJhn4DJgXrIS1iIQEcDoJdUbichVTWlnK1fOvpktcF5446wnfaqWltrnjyy/hvvvgzjvtWDJKKXU8a2jAcHiDhUc2x+PjXT3Dg4QWh+ByFXPv5/eyJXsLn171qa9fd3k5/OIXsHQpvP66LWUopVRb0NCAsdAzIOBsz/tp2HGgji++x7Q6WJvv5t/r/s0tI2/hjD5nAPbu6csug4UL4cUXNVgopdqWhjZ632WMuRgY65k1U0TmBy9ZLcRTwigvqOTRLdAnsRePnPEIYEcmvfpqeO89ePJJuP76lkyoUkodfQ0eN0FE3gHeCWJaWp6nhPHxgZ/YXwYLL/w7MeF2oPm77oI5c+CRR+DWW1sykUop1TLqDRjGmEIIOMyjAUREao80dizzlDC2FGcT7oAxnU8E7HDgTz8NN9wAd9/dkglUSqmWU2/AEJGjM8h6a+ENGGW59IyGyopdQBr//Kd9xsQf/tCyyVNKqZZ0/PV0agpPldQmZxa9oqGk5Ceys2HmTNvA3bNnC6dPKaVakAYMf/Hx5EXCXimgb3wMpaU/8fTT9ol1v/99SydOKaValgYMf6GhbOwWAcCJ7XuQlZXBk0/ClCn2wURKKdWWBTVgGGMmG2O2GGO2GmNmBFj+L2PMWs/0kzEmz2+Zy2/ZB8FMp7/1PeyzCAYlD2Du3JHk5MCMWilXSqm258geR3YEjDEhwDPAmUAGsNIY84GIbPSuIyK/9Vv/VmCo3y5KReTwgyc1sw2dHMS4QugeP5zZs69k/HgXp5zScg8XUkqp1iKYJYxRwFYR2S4iFcAc4IJ61p9O1Z3kLWZDkosBpTEsWngmmZndue22HS2dJKWUahWCGTC6Anv83md45tVijOkJ9Aa+8JsdaYxZZYxZYYy5MHjJrG5DfBkD8iJ4+ulB9Ou3hrFjvz9ah1ZKqVattTR6XwbMExGX37yenqdAXQ48YYzpG2hDY8xNnsCyKjMzs0mJyC7J5kB4BeF7e5OeHsn06Y9QWvpTk/aplFLHi2AGjL1Ad7/33TzzArmMGtVRIrLX87odWEL19g3/9WaKyAgRGZGc3LQnyW3I3ACAc+/JAIwb94MGDKWU8ghmwFgJ9DfG9DbGhGODQq3eTsaYk4BEYLnfvERjTITn7w7YQQ831ty2uW04ZANGWUYqHTpAcnJnSkvTg31YpZQ6JgQtYIiIE/g1sAjYBMwVkQ3GmAeNMVP8Vr0MmCMi/mNWnQysMsasAxYDD/v3rgqW9YfWEy8RHMgZQt8+QlRUf0pKtIShlFIQxG61ACKygBrPzRCRP9Z4/0CA7b4BUoOZtkA2ZG5gYGhnttGfcT0riY4+Aaczh8rKbMLCko52cpRSqlVpLY3ercKGzA2cFN6DPXSnb+cSoqJOAKCkRKullFJKA4bHoeJDZJVkkSInITjo27GQ6Oj+ANrwrZRSaMDwWX9oPQAxFbYzVt/EHCIjewMh2vCtlFJowPDx9pBy5w0DoF9CJg5HOJGRvbThWyml0IDhsyFzA4mRiWRm9iWGIjoaexNgdPQJWsJQSik0YPhsyNzAoI6D2L4/hr5swxTkA/i61lbv9auUUm2PBgxARFh/aD0DkweybXc4/dgKBQWALWG43cVUVBxo4VQqpVTL0oAB7C/aT15ZHid3GMj2nYa+Zgfke0sYtmut9pRSSrV1GjCoavDuZAZRUWHoG7XPV8KIirJda7XhWynV1gX1Tu9jhbdLbXiefQ5rv7iDkG8fmhQZ2R1jIrThWynV5mnAwDZ4J0cnk73Hjnbbt30u5IcBYEwIUVF9tYShlGrzNGBQ1UNq6yYIC4PuSSVQYHzLo6NP0IChlGrz2nwbhoiw4dAG20NqG/TqBSHt4nyN3mDbMUpLt1L9+U5KKdW2tPmA4RIX/znvP1w15Cq2bYN+/YCEBF+jN9ieUiIVlJXtbrmEKqVUC2vzVVKhjlCmp05HBLZtg7FjAVd8tRJGdLS3a206UVG9WyilSinVstp8CcMrK8sWKvr2xZYw8vPBc3e3dq1VSikNGD7bttnXfv2A+HiorITycgDCw1MICYnVrrVKqTZNA4aHN2D4Shjgq5YyxnjGlNrcMolTSqlWIKgBwxgz2RizxRiz1RgzI8Dya4wxmcaYtZ7pBr9lvzTGpHumXwYznWADhjHQuzfQrp2dmZXlWx4fP5r8/K9xu8uDnRSllGqVghYwjDEhwDPA2cAAYLoxZkCAVd8SkTTP9KJn2/bAn4DRwCjgT8aYxGClFWDrVujaFSIjgUGD7Mw1a3zLk5LOw+0uJi9vaTCToZRSrVYwSxijgK0isl1EKoA5wAUN3PYs4FMRyRGRXOBTYHKQ0glQ1aUWYOBAiImBb7/1LW/X7uc4HFFkZ38YzGQopVSrFcyA0RXY4/c+wzOvpouNMT8YY+YZY7of4bbNZts2T/sFQEgIjBxZLWCEhESRmHgG2dkf6bMxlFJtUks3en8I9BKRwdhSxCtHugNjzE3GmFXGmFWZmZmNSkRRERw86BcwAEaPhrVroazMNysp6TzKynZSUrKxUcdRSqljWTADxl6gu9/7bp55PiKSLSLeVuQXgeEN3dZvHzNFZISIjEhOTm5UQqt1qfUaPdp2rV271jcrKelcALKytFpKKdX2BDNgrAT6G2N6G2PCgcuAD/xXMMZ09ns7Bdjk+XsRMMkYk+hp7J7kmRcU1brUeo0ebV9XrPDNiojoSmzsMLKzPwpWUpRSqtUKWsAQESfwa2xGvwmYKyIbjDEPGmOmeFb7jTFmgzFmHfAb4BrPtjnAQ9igsxJ40DMvKAIGjC5doFu3au0YYKulCgqWU1GRhVJKtSVBbcMQkQUicoKI9BWRv3rm/VFEPvD8fY+IDBSRISJymohs9tt2loj080wvBTOdW7dChw5V9+v5jB4dIGCcD7jJyflfMJOklGprvv4aJk3yjTDRGrV0o3erUK2HlL/Ro2HHDvBrTI+LG0Z4eIpWSymlmtcHH8Cnn8IPP7R0SuqkAYN6AsaYMfbVr5RhjIP27c8lJ2chbnfl0UmgUur4t2WLffXraNPatPmA4XKB01mjh5TX8OH2nowa1VIdOpyPy1VAfv6XRyeRSqnj32ZPjbzfCBOtTZt/HkZICOzZ4xvJvLroaEhNrdZTCqBdu9MxJoLs7I9ITPz50UmoUur4VVlZ1fumFQeMNl/C8DKmjgWjR8N334Hb7ZsVGhpLYuJp2o6hlGoeO3bYqo4OHWwbhqt1Pg5aA8bhjB5tn6zkrV/0SEo6n9LSdH2oklKq6bzVUVOnQkkJ/NQ68xUNGIfjvYEvYPdaBxkZ/z76aVJKHV+8F6SXXWZfW2nDtwaMwznpJPsEvhoBIzKyO1273sK+fc9TWNh66xyVUseALVugY0c45RQID2+17RgaMA7H4bAj19Zo+Abo1etBwsI6kJ5+CyLuABsrpVQDbNkCJ54IYWH2eTwaMI5hY8bAjz/aukU/YWHt6NPnEQoKlnPgwBEPtKuUUtbmzbY2A2DoUBswWuFjFDRgNMTo0bbXwurVtRalpFxNfPzP2L7991RW5rZA4vzs2QMjRtixTpRSx4acHPs46BNPtO+HDoXsbMjIaNl0BaABoyHqaPgGe+d3//7PUFmZzc6dfzzKCavhvfdsUJs9u2XToY6c02l746m2x9vg7R8woFU2fGvAaIiOHaFXL1i2LODiuLg0unb9FXv3PkthYQv+kxcvtq8LFrRcGlTj3HefrZJwOls6Jepo83ap9QaMwYPtjWGtsB1DA0ZDTZsGH34Ib78dcHGvXg8RFpZEevqvcLtb4EfvdsOSJbbR7NtvbRFXHRtcLnjtNdi/H5Yvb+nUqKNtyxb7u+3d276PjYX+/TVgHNMefNB2ebv2Wti0qdbisLB29Ov3LwoKlrNjx33Nf/yXX7YlnbqqLdatg9xcuPlm21i2KGjPm1LN7auvbLAA+J8Om9/mbNliB7ML9Rupydvw3cpowGio8HCYOxdiYuAXv4DCwlqrdOp0BV263MyePY+SmflO8x5/1iw7zPpHdQxH8sUX9vWuuyA5WauljiVvvWXHLRsxQgNGW7R5c1V1lNfQobBrl20Qb0U0YByJbt1gzhx72/511wXs9tav3xPExY1m8+ZrKC6uXRJplIMH7VUowDt1BKLFi+GEE6B7d5g8GRYubLXj0Sg/TifMmwfnnQcXX2wbOr2ljbbmueeq6vPbCqfTDjpYM2CkpdnXdeuOfprqoQHjSJ12Gjz8sP2R/+tfVfNdLsjJwVHqZODAeTgc0axffxFOZzP0fHn/fRucxo+3V6DFxdWXO522Qf7nnpFzzznHXpl8913Tj62Ca8kSW3K89FI4+2w7b+HCFk1Si9i8GX71K1v1eySKiuDKK2HjxuCkK9h27LAj1XrvwfDy9pRqZdVSQQ0YxpjJxpgtxpitxpgZAZbfYYzZaIz5wRjzuTGmp98ylzFmrWf6IJjpPGJ33mmrpe6+2z55KTHRNlolJUHXrkSu2cPAgXMpLd3K5s3XIE29Aefdd20d55/+BKWltastVq+2VWSnnWbfT5pk71DX6o3W7623bCPnOefY3jFdurTN/9tbb9nXBQtsBtpQc+fCG2/YoHEk27UWNbvUenXsaL8LbSVgGGNCgGeAs4EBwHRjzIAaq60BRojIYGAe8KjfslIRSfNMU4KVzkYxBl56CW64wTaEX3UV/PGP8MQTtv1g8mTa/RRF376PkZU1n23b7kSkkdVDubnw+ec2QI0fb4c/rlkt5e1OO3GifW3f3qYrUDtGYaEtidRVtaWOnspKezEwZQpERdnv1eTJ9jGdbal7rYit6o2Lg/x8WLq04du+9pod623NGlvyP9bU7FLrrzU2fItIUCbgFGCR3/t7gHvqWX8o8LXf+6IjPebw4cOlxe3ZI9Knj0hCgri/+062bPmVLF6MrF17ppSXZx75/l59VQREVqyw72+4QSQ2VqS0tGqdM88UGTSo+nZ//avdbv/+6vP/7//s/BEjjjwtqnktWGD/F++/XzXv7bftvC+/bLl0HW1r19pz/uc/RSIjRX7964Ztt2uX3e7PfxaZPl0kLExk3brgprW53XCDSIcOgZf94Q8iISEiJSVBTQKwShqYxwazSqorsMfvfYZnXl2uB/zL4pHGmFXGmBXGmAuDkcCg6NbNXvG3b4+ZNIkTiq7nhBNeIC9vKatXj6CwsPbwIvV69127z5Ej7fuLL7b1tp9+at9XVNgG8Z/XePLfOefYV//68MWLbcNinz6walWrfth8mzB3LiQkwFlnVc0780z7GMi21Mtt9mx7zlddZc/f22bXkO0ArrgCnnrKVg1fc82xVTW1ZUvt9guvtDTbNrp+/dFNUz1aRaO3MeZKYATwmN/sniIyArgceMIY07eObW/yBJZVmZmZRyG1DdCjh82cExLgjDPo8komo7+4ga4v5ZF962jyH5oO5eWH309Rkc3wL7rItkmADQwJCVVVSt9+a9s1vO0XXkOGQOfOVRlPURFcf71tC1myxHYTnjWr2U5ZHaHycpg/Hy68ECIiquYnJMDYsQ1rxygpsd2sV60KXjqDzVsddeaZtrr1ggvsmGiH6x0kYqujfvYz246YlATPP3/sVU0F6lLr1RobvhtaFDnSiQZWSQFnAJuAjvXs62XgksMds1VUSfnbvl2kb19bbK4xZd46Slyuivq391ZPLF5cff7VV4u0aydSXm6L48aI5OTU3v6660QSEkQqKkRuvdWut2yZXXbppSLt24uUlTXLqTaJ2y0yZ47Ivn0tnZKj54MP7P92wYLay/7+d7ss0OeRkSHy/PMi555rq29AJD7eVoXWZe5ckfHjbZVPa/uMly+35/DKK/b9gQP2e/rAA/Vvt2aN3e7ZZ6vPv+yy5quays8X+c9/bJqCISfHnsOjjwZe7nbb3++NNwbn+B4cQZVUMANGKLAd6A2EA+uAgTXWGQpsA/rXmJ8IRHj+7gCkAwMOd8xWFzBERJxOkeJimzE7neJ2VUrhOSeKMxzZ8NHPpKIiu+5tp08XSU62+/D3/vv2X7dwociECSLDhgXeft48u95DD9nX3/ymatnChXbe3LlNPsUm855PSkrbqbu/4gobsCsCXDR46/Rnzaqa53bb/6Mxdlnv3vb/OWeOSHS0yNln23Vq2rJFJCbGZjwg4nDYNq+XXw563XiD3HabSESESF5e1byf/Uxk6ND6t7vjDhsYsrKqz8/MFOnYUeSkkxr/XSovF3nqKfvbA5G0NJGCgsbtqz7eYPnBB3Wvc9llIlFRItu2Nf/xPVpFwLDp4BzgJ09QuM8z70Fgiufvz4CDwFrP9IFn/s+AHz1B5kfg+oYcr1UGjED27BFXdIRkjjWyYkU/KSraWHudsjKRuDjbKFZTaalt+L7qKpHwcJHf/S7wcfLyREJD7b+5Tx+RoqKqZU6nSPfuImed1Tzn1Fhut8ioUSI9eoj062fT+/TTgTO/Y0FOjsjmzfWvk5dn/3+B/rci9ty7dBGZOtW+r6gQuf56+3+cPl1k/frqn89TT9llL71UfT9lZTbjbd/elkw2bbINqb172/UnTBCprGzsmTad0ynSubPIRRdVn//IIzZ9u3bVvV1KisgFFwRe/umndjmInHOODcAN4XbbUn2/fnbbiRNF/v1v2/A8eXLzf1Yvv2yPs2VL3evs2WPzgbPOCtpvotUEjKM9HTMBQ0Tk4YdFQDY8liDLlsVLZuZ74vb/Qnz0kdRZZSEiMm1a1dXmxx/XfZyJEyVgtZaIyB//aPexe3eTTqVJPv/cpu/550Vyc0XOO8++v/rqlr0CLi+3pS//IBuI0ynyzTcif/qTyJgx9goeRG6/PXAGs2ePSGqqDYzenm+BXHedrXbMybGZBdjMPlCm4XLZKqeEBBsYvO64w2733nvV13e7RV54wS678876zy+YFi+2aXjrrerzN2+28596KvB2ixbZ5fPm1b3v4mL7G2vXrirQbtpU9/rffityyil23YED7W/K+1nPnGnn33RT82baM2bY70GgUqa/J5+0x589O/Dyr7+259pIGjCOBeXlIieeKK4+PWXVV4Nl8WJkzZqfS37+d3b5ddfZuuny8sDbe9s3QkLqLy5/953Ia68FXrZ9u93Hgw827Vya4uc/t1eZ3m7CLpetvwbbVfjtt2tXydXnvfdsJvjee4HbdRrC5bJVRt7ux3XVYX/5pUi3bnY9Y2xJ6f77q7oun3569SqTH34Q6drVXjF+8kn9afD+f7t1s//jF16of/30dFt1ce65NlP73//s9rfcUvc2v/qVXeedd+rfd12ysuyFzbx5jctIb7rJVpcFCsonnihyxhmBt7vqKhsc/buW1yU3V+Tee221HdjP5/PPq9KbkWH3560SffHFwN+3e+6x6/z97w0/v8O56CJ7nofjdIqMHGmr2mp+pz/4wLZlnXCCSGFho5KhAeNY8emnIiCuB/8ke/b8W776qoMs/gzZ+fTPxJ2YYDOtuhQV2QxizJimpeH0020VhcvVtP00hrcO9x//qL3s44+rqgb69hV57rnDlzj+85+qzNv7OmyYrbLzv/I+nDvvtNtfcYX9jHv1qn516nbbBuSQEJvG2bNr16XPmmWrC3v3toHis8/sBUCXLg2rIsnLs/uPjbWZf0M88YRN9yOP2MwlNbX+z6yszAa5uLjA1SI//mjP48UX7Wf73HP2GNdeazM6/44c/+//1f0dysqyaXr//argUFFhq8qmTw+8zd1326vv3Nzq84uKbJA50obgQ4fshYi3XWLIEFsKjI62/6cZM+q/8HK5RC6/3G775pv1H8vtrrs6zd+AAXVXq9W0Zo39Ptx0U9W8WbPsvBEj7Pk1kgaMY8kll9hMadUqcf7tz1LRzRahy5KQHfMulNLSeqqLXn9d5Isvmnb8N96wX4PPP7fvnU6RDz8UOf98+yM6nJwc++PYuFFk5UqRJUvs9M039v26dXX34Dn/fJtp1HVl5HTaq9eRI20aO3YUefzxwD27vPX4555rM9ulS20GMXFiVca9c+fhz+cf/xDflbnbbUtoHTuKJCbafRYU2B5mYH/s/o21NS1fbktPMTG2gXbQoCOr/lu4UGTDhoav73KJnHqqTVtkZMO23bVLJCnJpq2oyJ7z4sW2zj5A7z4Bu/7554v87W/2f/3739v5115b++p85UrbPuXdNiLC7vvXv5ZaNy36+/rrwJnz66/b+UuXNvxz8VdaagPggAF2P7/4RcMblMvKbLuPMSI331z7IkHEfuann273ffPNddcQbNhgvxN3393wtP/ud+K7qdPbk27SpEaXLLw0YBxLdu+uKi57GtoqZr8gP234lSxZEiZLlkRIevpvpby88VcQ9SopsfW8F15ou/d5G0RjY+3riy8G3s7lErnmmrozlZrTHXdUz+jXrbPz//znw6fRm4mdeab4egi99VZVtcI//1mVgQf6gX73na3C6NWr/qDhDZ6XXFI949u+3V5Rh4fbzgMOh60zbkipbO9em8mcc079waW5/PSTzaD9e1gdzqJFNhOcPFlk9Gj7GSQni/zlL3Z/u3bZEtq+ffZKtmb1k9tt23C8pbLKSjtv5kz7mfXoYQPA55+L/Pa3tvoE6u/W7XTaQH3ZZTaTX7jQdg3v1Mnur6klYre7cVflBQW2ZBISYtP/3HM2rXl59txCQ+3vado0e46nnlq9StP7uURF2c/4SLr/FhXZc4+PF1+7TF0B6QhowDjWzJljv2zr11ebXVq6UzZtulYWL3bIsmWxkp5+u2RkPCOHDs2TvLyvpLg4XdzuI6jfr8stt1Rl7BMm2Mbe0lJbhxwRIbJqVe1tvA2q//d/NqjMnm3rUz//3E4LF9r377xjr7TAVg95qz6mT7dBKbuebsWBfPKJyODBdn9jxtjPzZvJ19d4uHKl/SH36iWyY0f1ZS6XyPz59opvwoTAdePZ2bZhuWPHqtJYa9WY9oQHHxRfb7pnn21chwPvcDRTp9o2OO8VcGaAIXF++slO9bn+ehtwvBdUkZG2BOm9l6gl/fhjVYeSIUNsIDPGVpV5A9Gbb9rA0K2b/Q3l5trPBuxvqzH3xHz8sb1g+c1vmq0aWQPGcaaoaJOsXz9VFi92yOLFVJtWrDhRcnKamIHt3VTdciAAABAcSURBVGuvEH/8sfr8zEx7RdOzZ/Xi92OP2a/Orbc2PHN67z17RRYTYzMWh+PIiuP+nE57Bd25s/iutBrS5XHVKlu11LOnrUL76CP7A/d2wUxNrV1n7s/tbpYrulbJ7Rb5/vumdx19/PGqi48//OHIOizUtGKF7RZ8yy02o2wN9434895w2q+fyNix9qKkpu+/t7+hyEgbOEJDG146rUt939FG0IBxnHK5KqWsbJ8UFKyR7OyFsnfv87J8eR9ZvBjZsOFyKSsLwl28331nr/ImTbI/fu9giJdeeuRf+owMkdNOE19dds2BEY9UUZHtdnwkmdLq1TZoeDO12Fh71ffaa02uC1Ye8+bZRn5lHTpkewP261d/V+oWciQBw9j1jw8jRoyQVcfyuDqN4HKVsnv3w+ze/TAORyQ9e95PTMwgjHFgR5h3EBHRhejoOsaraYgXXoCbbrJjWn34IUyYAB9/XH0MpIYnGJ55xg5Jfc01jU9TU/z4ox3479RT7ZDwjTkPpY6EN581pmXTEYAxZrXYcfsOv64GjONDSUk66em/Jjf3k4DLY2JS6dhxOh07TiMqqs+RH+CGG+C//7UDoi1ZYjN8pdQxTwNGGyUiFBevx+UqAtyIuAE3RUU/cOjQHAoKvgEgLm4U4eGdcbmKcLkKcbmKcDjCSUm5jpSUawkNja2987IymDkTLrvMPg1MKXVc0IChAiot3Ulm5lwyM9/F7S4jJCTWN5WX76Gw8DtCQ9vRpcvNdO16KxERXXA6iygt/YmSks2Ul+8jOfkSoqJ6tfSpKKWaiQYM1Sj5+cvZs+cfZGXNx5gQwsM7UV6eUW0dhyOSHj1m0L373YSERLVQSpVSzeVIAkZosBOjjh0JCaeQkDCP0tJt7N37DJWVmURHn0R09ElERZ1ISEgU27ffx86dD7B//0v06/cPOnT4BaYVNuQppZqfljDUEcvLW0p6+q0UF/9ITEwqkZG9CAtLJiysA2FhyYSHdyI8PMX3GhbWAWNaxcMdlVI1aAlDBVW7dhMYPvx79u+fSVbWfMrKdlNYuJrKykxEAj1POcQTPDoTEdGF8PDOhIRE43KV4HaXel7LCA1N8KzXibCwToSHdyQ0NIGQkARCQ+M9f8driUapFqIBQzWKwxFK166/omvXX/nmiQguVwEVFQc90wG/aT8VFfspK9tNQcEK3O4yHI5oQkKicTiicTjCKSnZSEXFQdzukjqPGxrantjYIcTGpvmm6OgBOBwN+yqXl++nsHAVlZXZJCWdQ3i49vhSqqE0YKhmY4whNDSB0NAEoqNPaPR+nM4iKisPUlGRictVgNOZ75nyKC39iaKidezb9xxudxlgG+Jt8BhOXNxwIiK64nQW4HLZbSorcyku/pHCwlVUVOzzO1IIiYln0KnT5XTocCGhoa3n3hK3u4Li4g2eElmnlk6OUoC2YahjlNvtpLQ0naKiNRQWrqawcBVFRd977kGpyRAdfRJxcSN8U0hIDIcOzeXQoTcpK9uJwxFJVFR/393xts0lhNDQOE+VmJ3AQWVlJpWVWZ4pm/DwZKKiTvR1EIiM7AW4cLvLcbsrECnH4YgiLKyjp5qtHcY4PCWyQiorM6moyKSsbBsFBd9RUPAtRUVrEKkAIC5uBO3bn0NS0rnExY3Q9iDVrFpNt1pjzGTg30AI8KKIPFxjeQTwKjAcyAamichOz7J7/n979x4jV1nGcfz7m8vOzl7a7Q0sLZdCoQIKtRAEQaMQFIkhmmAAkRBDQowYITFRGu/+Y/xH5A/jJd6VKIKghBgrFIMxkbsF2uJChQotlC1le2Fn5/74x/vudrrd7Z5d2J2z7PNJTnbOmXfOPrt7dp55L+d9geuABvAFM9sw2ffzhDG/mTUplZ6lVntt9A0+9Hv0Tvgma2bs3/8QAwO/p1J5CbMGIzc9mtVoNA5Qr4daTqOxD7NG7OAf6eRfTLW6i1Kpf0ztZWJSjlxuEfX6fswqhzyXyXTR23s2CxacQ0/POsrl59mz5y/s3/8Q0CSXW0JPzxl0d7+L7u7T6eo6nY6Oo2g2y3ELfUKVyg7K5Rcol7dTLm+n0ThAZ+cqisXVFIsnUSyuRspTr+8d3cINnIVDmgpzuT4KhRUUCivI5RZP2H/UbNYpl1+gVOpneLifavXVeGNo2JrNKr29Z7Fo0YUsWHAumczcmY7FzKjVdlMq9VMq9VOvD1IsnkixeArF4uo5P7w8FQlD4aPas8DFwA7gUeAqM9vaUuZzwBlm9llJVwKfMLMrJJ0G/A44BzgGuB84xcJ/84Q8Ybh2qtf3Uyr1U6m8iJRH6ohvwB00GsOxZjJAtTpArbaHXG5BHFV2FPn8MgqFY+nqOnXc/phabQ+vv76BwcEHGBraTKm0ZYLa1EFSjkLhODo7TyCb7aVcfoHh4W1H7CM68vkKFArHkMkUYwIO85U1GiXK5ecPGfAgFWLtrIdstheAoaEtQJNMpsjChRfQ07OOTKYDKRe3LPX63tE+sFptgFptECkXy3WQyXSQyy2MgyLeEQdILKVe30e1uis2Ze6i0Rgil+sjl1sUtz6gSaMxFJPYUBxoseCwMqHPbaQP7mWGh7dRr++d8PdSKKyku/vd9Pae1dIsunLc5GrWoFp9lUplB5XKTprNUqyF1mg2qzSbZRqNfdRqg6OJPJPJxw8nB7eReMO2cPTr9P6u6UgY5wHfNLOPxP31AGb2nZYyG2KZf0nKAbuAZcDNrWVbyx3pe3rCcPOFmVGpvMjQ0Bbq9UEymWLcOslkOikUVtDRccxhycfMqFZ3MTy8jVBj6Rvdstme2Iw2MnKtRK22h0plJ5XKTqrVnVQqL2NWjTWwUBuT8hSLJ8cmuTV0da0hn198WMy12l727fsHg4MbGRzcyPDwczHJHHwPknKx6S6MlsvlFmPWwKw62rw3khyq1VdHm+2CTEy+R5PNdsd+r0Hq9UGazeF4/sLo7AaZTEesPQ6OOY9iDCEhFYsn0dW1JjY7riGXW0S5/DzDw89RKj072q82khAhDM7IZrsIb2tZpCzNZolK5RVCo8mRZA75u5jVR5tBxx+FCPn8Us4/f/ck5x1fWobVrgBeatnfAbx3ojJmVpe0D1gSjz805rUrZi5U5+YWSXR2Hk9n5/FTfl2hsJxCYfm4z2ezoTkqn1/yVoR5iHy+j6VLL2Pp0ssOOR6STx2zWkvtZXJmFgc17CaX6yOfXxL7oA7XbFaA7Li1NzOj2RymXh8EMuTzyyYddZfPr6O3d90hxxqNEm+88SQHDjxOqbSVZrMSf646Zo2YyFfGLTTzhebSfKxB5clkOslmeyaonRzs8wq1j32jtZDWpDuT5vwoKUnXA9cDHHfccW2Oxjk3VWEq/g6gY4qvE/n8IvL5RZOWPVKfiaTRRPlmZLNdcbaE897UeSYSRiEuaOtovpkcbrETOLZlf2U8Nm6Z2CS1kND5neS1AJjZT8zsbDM7e9myZW9R6M4558aayYTxKHCypFUKHx+uBO4ZU+Ye4Nr4+HLggbgC1D3AlZIKklYBJwOPzGCszjnnJjFjTVKxT+LzwAbCsNqfm9kWSd8mLAl4D/Az4DeStgGvE5IKsdwfgK1AHbhhshFSzjnnZpbfuOecc/PYVEZJ+S2jzjnnEvGE4ZxzLhFPGM455xLxhOGccy6Rt1Wnt6TdwP+m+fKlwGtvYTizxeOeXR737PK4Z97xZpboJra3VcJ4MyQ9lnSkQJp43LPL455dHne6eJOUc865RDxhOOecS8QTxkE/aXcA0+Rxzy6Pe3Z53CnifRjOOecS8RqGc865ROZ9wpB0iaR+Sdsk3dzueI5E0s8lDUja3HJssaT7JD0Xv06+OMAsknSspL9L2ippi6Qb4/FUxw0gqVPSI5KejLF/Kx5fJenheM3cHmdjThVJWUn/lnRv3E99zACStkt6WtImSY/FY3PhWumTdKek/0h6RtJ5cyHuqZrXCSOuO/4D4KPAacBVcT3xtPolcMmYYzcDG83sZGBj3E+TOvBFMzsNOBe4If6O0x43QAW40MzOBNYCl0g6F/gucIuZrQYGgevaGONEbgSeadmfCzGP+JCZrW0ZljoXrpVbgb+a2TuBMwm/+7kQ99SY2bzdgPOADS3764H17Y5rkphPADa37PcDy+Pj5UB/u2OcJP4/AxfPwbi7gCcIywy/BuTGu4bSsBEWHNsIXAjcCyjtMbfEvh1YOuZYqq8VwsJvLxD7hOdK3NPZ5nUNg/HXHZ9ra4cfbWavxMe7gKPbGcyRSDoBeA/wMHMk7ti0swkYAO4D/gvsNbN6LJLGa+b7wJeAZtxfQvpjHmHA3yQ9HpdfhvRfK6uA3cAvYjPgTyV1k/64p2y+J4y3FQsfZVI57E1SD/BH4CYz29/6XJrjNrOGma0lfGo/B3hnm0M6IkkfAwbM7PF2xzJNF5jZOkIz8Q2SPtD6ZEqvlRywDvihmb0HGGJM81NK456y+Z4wEq8dnmKvSloOEL8OtDmew0jKE5LFbWZ2Vzyc+rhbmdle4O+E5py+uAY9pO+aOR+4TNJ24PeEZqlbSXfMo8xsZ/w6ANxNSNJpv1Z2ADvM7OG4fychgaQ97imb7wkjybrjade6Lvq1hD6C1JAkwlK8z5jZ91qeSnXcAJKWSeqLj4uEvpdnCInj8lgsVbGb2XozW2lmJxCu5wfM7GpSHPMISd2SekceAx8GNpPya8XMdgEvSVoTD11EWF461XFPS7s7Udq9AZcCzxLapr/S7ngmifV3wCtAjfCp5jpC+/RG4DngfmBxu+McE/MFhKr4U8CmuF2a9rhj7GcA/46xbwa+Ho+fCDwCbAPuAArtjnWC+D8I3DtXYo4xPhm3LSP/j3PkWlkLPBavlT8Bi+ZC3FPd/E5v55xzicz3JinnnHMJecJwzjmXiCcM55xziXjCcM45l4gnDOecc4l4wnAuBSR9cGRmWefSyhOGc865RDxhODcFkj4d18jYJOnHcXLCNyTdEtfM2ChpWSy7VtJDkp6SdPfIegiSVku6P66z8YSkk+Lpe1rWVLgt3iXvXGp4wnAuIUmnAlcA51uYkLABXA10A4+Z2enAg8A34kt+DXzZzM4Anm45fhvwAwvrbLyPcPc+hJl8byKszXIiYV4o51IjN3kR51x0EXAW8Gj88F8kTCjXBG6PZX4L3CVpIdBnZg/G478C7ohzJa0ws7sBzKwMEM/3iJntiPubCGuf/HPmfyznkvGE4VxyAn5lZusPOSh9bUy56c63U2l53MD/P13KeJOUc8ltBC6XdBSMrjV9POH/aGQm2E8B/zSzfcCgpPfH49cAD5rZAWCHpI/HcxQkdc3qT+HcNPknGOcSMrOtkr5KWBEuQ5g1+AbCgjnnxOcGCP0cEKa0/lFMCM8Dn4nHrwF+LOnb8RyfnMUfw7lp89lqnXuTJL1hZj3tjsO5meZNUs455xLxGoZzzrlEvIbhnHMuEU8YzjnnEvGE4ZxzLhFPGM455xLxhOGccy4RTxjOOecS+T902Tt2FE6WnAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.1556 - acc: 0.9524\n",
      "Loss: 0.15557638902839965 Accuracy: 0.95244026\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7025 - acc: 0.4802\n",
      "Epoch 00001: val_loss improved from inf to 0.93837, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_12_conv_checkpoint/001-0.9384.hdf5\n",
      "36805/36805 [==============================] - 173s 5ms/sample - loss: 1.7024 - acc: 0.4802 - val_loss: 0.9384 - val_acc: 0.7254\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6814 - acc: 0.7883\n",
      "Epoch 00002: val_loss improved from 0.93837 to 0.42639, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_12_conv_checkpoint/002-0.4264.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.6815 - acc: 0.7882 - val_loss: 0.4264 - val_acc: 0.8654\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4439 - acc: 0.8635\n",
      "Epoch 00003: val_loss improved from 0.42639 to 0.27247, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_12_conv_checkpoint/003-0.2725.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.4440 - acc: 0.8634 - val_loss: 0.2725 - val_acc: 0.9196\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3311 - acc: 0.8970\n",
      "Epoch 00004: val_loss did not improve from 0.27247\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.3311 - acc: 0.8970 - val_loss: 0.4274 - val_acc: 0.8831\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2631 - acc: 0.9177\n",
      "Epoch 00005: val_loss did not improve from 0.27247\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.2631 - acc: 0.9177 - val_loss: 0.2869 - val_acc: 0.9150\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2218 - acc: 0.9311\n",
      "Epoch 00006: val_loss improved from 0.27247 to 0.22889, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_12_conv_checkpoint/006-0.2289.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.2219 - acc: 0.9311 - val_loss: 0.2289 - val_acc: 0.9329\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2015 - acc: 0.9370\n",
      "Epoch 00007: val_loss improved from 0.22889 to 0.19422, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_12_conv_checkpoint/007-0.1942.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.2016 - acc: 0.9369 - val_loss: 0.1942 - val_acc: 0.9427\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9464\n",
      "Epoch 00008: val_loss did not improve from 0.19422\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1705 - acc: 0.9464 - val_loss: 0.2004 - val_acc: 0.9418\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9512\n",
      "Epoch 00009: val_loss improved from 0.19422 to 0.18229, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_12_conv_checkpoint/009-0.1823.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1557 - acc: 0.9512 - val_loss: 0.1823 - val_acc: 0.9471\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1321 - acc: 0.9589\n",
      "Epoch 00010: val_loss improved from 0.18229 to 0.16406, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_12_conv_checkpoint/010-0.1641.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1321 - acc: 0.9589 - val_loss: 0.1641 - val_acc: 0.9518\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9626\n",
      "Epoch 00011: val_loss improved from 0.16406 to 0.16210, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_12_conv_checkpoint/011-0.1621.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1187 - acc: 0.9626 - val_loss: 0.1621 - val_acc: 0.9527\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9653\n",
      "Epoch 00012: val_loss improved from 0.16210 to 0.15270, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_12_conv_checkpoint/012-0.1527.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1089 - acc: 0.9653 - val_loss: 0.1527 - val_acc: 0.9543\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9681\n",
      "Epoch 00013: val_loss improved from 0.15270 to 0.13524, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_12_conv_checkpoint/013-0.1352.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.1025 - acc: 0.9681 - val_loss: 0.1352 - val_acc: 0.9604\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9714\n",
      "Epoch 00014: val_loss did not improve from 0.13524\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0912 - acc: 0.9714 - val_loss: 0.1499 - val_acc: 0.9541\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9729\n",
      "Epoch 00015: val_loss did not improve from 0.13524\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0848 - acc: 0.9729 - val_loss: 0.1700 - val_acc: 0.9497\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9751\n",
      "Epoch 00016: val_loss improved from 0.13524 to 0.11811, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_12_conv_checkpoint/016-0.1181.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0752 - acc: 0.9751 - val_loss: 0.1181 - val_acc: 0.9646\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9792\n",
      "Epoch 00017: val_loss did not improve from 0.11811\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0658 - acc: 0.9792 - val_loss: 0.1551 - val_acc: 0.9590\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9790\n",
      "Epoch 00018: val_loss did not improve from 0.11811\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0648 - acc: 0.9790 - val_loss: 0.1829 - val_acc: 0.9490\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9828\n",
      "Epoch 00019: val_loss did not improve from 0.11811\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0559 - acc: 0.9828 - val_loss: 0.1718 - val_acc: 0.9557\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0556 - acc: 0.9824\n",
      "Epoch 00020: val_loss improved from 0.11811 to 0.10959, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_12_conv_checkpoint/020-0.1096.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0556 - acc: 0.9824 - val_loss: 0.1096 - val_acc: 0.9697\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9854\n",
      "Epoch 00021: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0472 - acc: 0.9854 - val_loss: 0.1528 - val_acc: 0.9620\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9799\n",
      "Epoch 00022: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0621 - acc: 0.9799 - val_loss: 0.1792 - val_acc: 0.9562\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9847\n",
      "Epoch 00023: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0469 - acc: 0.9847 - val_loss: 0.1621 - val_acc: 0.9534\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9852\n",
      "Epoch 00024: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0482 - acc: 0.9852 - val_loss: 0.1717 - val_acc: 0.9578\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9901\n",
      "Epoch 00025: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0327 - acc: 0.9901 - val_loss: 0.1970 - val_acc: 0.9455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9832\n",
      "Epoch 00026: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0526 - acc: 0.9832 - val_loss: 0.1738 - val_acc: 0.9555\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9852\n",
      "Epoch 00027: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0460 - acc: 0.9852 - val_loss: 0.2052 - val_acc: 0.9390\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9903\n",
      "Epoch 00028: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0332 - acc: 0.9903 - val_loss: 0.2156 - val_acc: 0.9411\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9864\n",
      "Epoch 00029: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0444 - acc: 0.9864 - val_loss: 0.1608 - val_acc: 0.9602\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9908\n",
      "Epoch 00030: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0286 - acc: 0.9908 - val_loss: 0.1147 - val_acc: 0.9711\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9924\n",
      "Epoch 00031: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0251 - acc: 0.9924 - val_loss: 0.1669 - val_acc: 0.9574\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9923\n",
      "Epoch 00032: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0253 - acc: 0.9923 - val_loss: 0.1448 - val_acc: 0.9620\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9904\n",
      "Epoch 00033: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0303 - acc: 0.9904 - val_loss: 0.2332 - val_acc: 0.9471\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9908\n",
      "Epoch 00034: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0294 - acc: 0.9907 - val_loss: 0.1967 - val_acc: 0.9495\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9867\n",
      "Epoch 00035: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0394 - acc: 0.9867 - val_loss: 0.1616 - val_acc: 0.9560\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9930\n",
      "Epoch 00036: val_loss did not improve from 0.10959\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0211 - acc: 0.9930 - val_loss: 0.1530 - val_acc: 0.9639\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9897\n",
      "Epoch 00037: val_loss improved from 0.10959 to 0.10923, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_12_conv_checkpoint/037-0.1092.hdf5\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0329 - acc: 0.9897 - val_loss: 0.1092 - val_acc: 0.9695\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9927\n",
      "Epoch 00038: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0248 - acc: 0.9927 - val_loss: 0.1418 - val_acc: 0.9616\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9946\n",
      "Epoch 00039: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0170 - acc: 0.9946 - val_loss: 0.1151 - val_acc: 0.9695\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9947\n",
      "Epoch 00040: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0183 - acc: 0.9947 - val_loss: 0.1675 - val_acc: 0.9609\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9925\n",
      "Epoch 00041: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0231 - acc: 0.9925 - val_loss: 0.1527 - val_acc: 0.9651\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9946\n",
      "Epoch 00042: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0190 - acc: 0.9946 - val_loss: 0.1319 - val_acc: 0.9662\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9930\n",
      "Epoch 00043: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0215 - acc: 0.9930 - val_loss: 0.1733 - val_acc: 0.9595\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9933\n",
      "Epoch 00044: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0209 - acc: 0.9933 - val_loss: 0.1123 - val_acc: 0.9727\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9951\n",
      "Epoch 00045: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0162 - acc: 0.9951 - val_loss: 0.1323 - val_acc: 0.9632\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9950\n",
      "Epoch 00046: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0170 - acc: 0.9949 - val_loss: 0.1813 - val_acc: 0.9585\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0275 - acc: 0.9910\n",
      "Epoch 00047: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0275 - acc: 0.9910 - val_loss: 0.1308 - val_acc: 0.9686\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9940\n",
      "Epoch 00048: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0184 - acc: 0.9940 - val_loss: 0.1392 - val_acc: 0.9669\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9970\n",
      "Epoch 00049: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0111 - acc: 0.9970 - val_loss: 0.1295 - val_acc: 0.9704\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9953\n",
      "Epoch 00050: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0151 - acc: 0.9953 - val_loss: 0.1824 - val_acc: 0.9543\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9941\n",
      "Epoch 00051: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0178 - acc: 0.9941 - val_loss: 0.1593 - val_acc: 0.9658\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9953\n",
      "Epoch 00052: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0143 - acc: 0.9953 - val_loss: 0.1685 - val_acc: 0.9611\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9967\n",
      "Epoch 00053: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0113 - acc: 0.9967 - val_loss: 0.2697 - val_acc: 0.9425\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9932\n",
      "Epoch 00054: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0234 - acc: 0.9931 - val_loss: 0.1316 - val_acc: 0.9690\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9924\n",
      "Epoch 00055: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0251 - acc: 0.9924 - val_loss: 0.1509 - val_acc: 0.9667\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9975\n",
      "Epoch 00056: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0091 - acc: 0.9975 - val_loss: 0.1665 - val_acc: 0.9667\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9972\n",
      "Epoch 00057: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0096 - acc: 0.9971 - val_loss: 0.1599 - val_acc: 0.9623\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9940\n",
      "Epoch 00058: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0183 - acc: 0.9940 - val_loss: 0.1386 - val_acc: 0.9676\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9968\n",
      "Epoch 00059: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0103 - acc: 0.9968 - val_loss: 0.1517 - val_acc: 0.9653\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9964\n",
      "Epoch 00060: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0115 - acc: 0.9964 - val_loss: 0.2781 - val_acc: 0.9443\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9965\n",
      "Epoch 00061: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0112 - acc: 0.9965 - val_loss: 0.1647 - val_acc: 0.9665\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9965\n",
      "Epoch 00062: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0119 - acc: 0.9965 - val_loss: 0.2083 - val_acc: 0.9595\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9949\n",
      "Epoch 00063: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0153 - acc: 0.9949 - val_loss: 0.1347 - val_acc: 0.9695\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9974\n",
      "Epoch 00064: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0086 - acc: 0.9974 - val_loss: 0.1219 - val_acc: 0.9727\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9970\n",
      "Epoch 00065: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0102 - acc: 0.9970 - val_loss: 0.1360 - val_acc: 0.9693\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9972\n",
      "Epoch 00066: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0088 - acc: 0.9972 - val_loss: 0.1804 - val_acc: 0.9655\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9966\n",
      "Epoch 00067: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0110 - acc: 0.9965 - val_loss: 0.1863 - val_acc: 0.9630\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9944\n",
      "Epoch 00068: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0178 - acc: 0.9944 - val_loss: 0.1225 - val_acc: 0.9718\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9966\n",
      "Epoch 00069: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0122 - acc: 0.9966 - val_loss: 0.1654 - val_acc: 0.9658\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9948\n",
      "Epoch 00070: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0180 - acc: 0.9948 - val_loss: 0.1229 - val_acc: 0.9720\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9987\n",
      "Epoch 00071: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0056 - acc: 0.9986 - val_loss: 0.1161 - val_acc: 0.9746\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9942\n",
      "Epoch 00072: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0196 - acc: 0.9942 - val_loss: 0.1355 - val_acc: 0.9683\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9981\n",
      "Epoch 00073: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0064 - acc: 0.9981 - val_loss: 0.1418 - val_acc: 0.9686\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9981\n",
      "Epoch 00074: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0062 - acc: 0.9981 - val_loss: 0.1226 - val_acc: 0.9739\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9985\n",
      "Epoch 00075: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 120s 3ms/sample - loss: 0.0058 - acc: 0.9985 - val_loss: 0.1559 - val_acc: 0.9665\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9967\n",
      "Epoch 00076: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0118 - acc: 0.9967 - val_loss: 0.1983 - val_acc: 0.9625\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9972\n",
      "Epoch 00077: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0083 - acc: 0.9972 - val_loss: 0.1897 - val_acc: 0.9611\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9954\n",
      "Epoch 00078: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0151 - acc: 0.9954 - val_loss: 0.1737 - val_acc: 0.9595\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9970\n",
      "Epoch 00079: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0088 - acc: 0.9970 - val_loss: 0.1623 - val_acc: 0.9688\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9968\n",
      "Epoch 00080: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0097 - acc: 0.9968 - val_loss: 0.1485 - val_acc: 0.9720\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9970\n",
      "Epoch 00081: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0106 - acc: 0.9970 - val_loss: 0.1301 - val_acc: 0.9725\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9974\n",
      "Epoch 00082: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0096 - acc: 0.9973 - val_loss: 0.1827 - val_acc: 0.9613\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9956\n",
      "Epoch 00083: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0149 - acc: 0.9955 - val_loss: 0.1233 - val_acc: 0.9706\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9944\n",
      "Epoch 00084: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0192 - acc: 0.9944 - val_loss: 0.1281 - val_acc: 0.9727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9962\n",
      "Epoch 00085: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0124 - acc: 0.9962 - val_loss: 0.1299 - val_acc: 0.9727\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9987\n",
      "Epoch 00086: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0041 - acc: 0.9987 - val_loss: 0.1191 - val_acc: 0.9723\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9980\n",
      "Epoch 00087: val_loss did not improve from 0.10923\n",
      "36805/36805 [==============================] - 121s 3ms/sample - loss: 0.0068 - acc: 0.9980 - val_loss: 0.1300 - val_acc: 0.9706\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_12_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.1492 - acc: 0.9574\n",
      "Loss: 0.14923871945887648 Accuracy: 0.9574247\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3896 - acc: 0.5796\n",
      "Epoch 00001: val_loss improved from inf to 0.65481, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/001-0.6548.hdf5\n",
      "36805/36805 [==============================] - 183s 5ms/sample - loss: 1.3895 - acc: 0.5796 - val_loss: 0.6548 - val_acc: 0.8027\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5061 - acc: 0.8431\n",
      "Epoch 00002: val_loss improved from 0.65481 to 0.33597, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/002-0.3360.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.5061 - acc: 0.8431 - val_loss: 0.3360 - val_acc: 0.8998\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3360 - acc: 0.8936\n",
      "Epoch 00003: val_loss improved from 0.33597 to 0.30153, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/003-0.3015.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.3360 - acc: 0.8935 - val_loss: 0.3015 - val_acc: 0.9024\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2573 - acc: 0.9181\n",
      "Epoch 00004: val_loss improved from 0.30153 to 0.23383, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/004-0.2338.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.2573 - acc: 0.9181 - val_loss: 0.2338 - val_acc: 0.9311\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2115 - acc: 0.9339\n",
      "Epoch 00005: val_loss improved from 0.23383 to 0.18578, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/005-0.1858.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.2115 - acc: 0.9338 - val_loss: 0.1858 - val_acc: 0.9443\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1767 - acc: 0.9438\n",
      "Epoch 00006: val_loss did not improve from 0.18578\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1767 - acc: 0.9438 - val_loss: 0.2126 - val_acc: 0.9387\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1526 - acc: 0.9512\n",
      "Epoch 00007: val_loss did not improve from 0.18578\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1527 - acc: 0.9512 - val_loss: 0.1947 - val_acc: 0.9425\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9544\n",
      "Epoch 00008: val_loss improved from 0.18578 to 0.18202, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/008-0.1820.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1428 - acc: 0.9544 - val_loss: 0.1820 - val_acc: 0.9469\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9634\n",
      "Epoch 00009: val_loss did not improve from 0.18202\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.1139 - acc: 0.9634 - val_loss: 0.1893 - val_acc: 0.9448\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9664\n",
      "Epoch 00010: val_loss improved from 0.18202 to 0.17211, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/010-0.1721.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.1055 - acc: 0.9664 - val_loss: 0.1721 - val_acc: 0.9455\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9710\n",
      "Epoch 00011: val_loss improved from 0.17211 to 0.15303, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/011-0.1530.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0926 - acc: 0.9710 - val_loss: 0.1530 - val_acc: 0.9532\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9723\n",
      "Epoch 00012: val_loss did not improve from 0.15303\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0867 - acc: 0.9722 - val_loss: 0.2693 - val_acc: 0.9257\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0935 - acc: 0.9699\n",
      "Epoch 00013: val_loss did not improve from 0.15303\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0935 - acc: 0.9699 - val_loss: 0.1640 - val_acc: 0.9534\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9792\n",
      "Epoch 00014: val_loss did not improve from 0.15303\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0645 - acc: 0.9792 - val_loss: 0.1631 - val_acc: 0.9534\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9782\n",
      "Epoch 00015: val_loss did not improve from 0.15303\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0670 - acc: 0.9782 - val_loss: 0.1696 - val_acc: 0.9541\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9776\n",
      "Epoch 00016: val_loss did not improve from 0.15303\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0707 - acc: 0.9776 - val_loss: 0.1674 - val_acc: 0.9609\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9787\n",
      "Epoch 00017: val_loss improved from 0.15303 to 0.15282, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/017-0.1528.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0686 - acc: 0.9787 - val_loss: 0.1528 - val_acc: 0.9571\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9855\n",
      "Epoch 00018: val_loss did not improve from 0.15282\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0469 - acc: 0.9855 - val_loss: 0.1723 - val_acc: 0.9553\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9810\n",
      "Epoch 00019: val_loss improved from 0.15282 to 0.14880, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/019-0.1488.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0571 - acc: 0.9810 - val_loss: 0.1488 - val_acc: 0.9606\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9863\n",
      "Epoch 00020: val_loss improved from 0.14880 to 0.13430, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/020-0.1343.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0433 - acc: 0.9863 - val_loss: 0.1343 - val_acc: 0.9623\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9864\n",
      "Epoch 00021: val_loss did not improve from 0.13430\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0420 - acc: 0.9864 - val_loss: 0.1720 - val_acc: 0.9560\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9851\n",
      "Epoch 00022: val_loss improved from 0.13430 to 0.12897, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/022-0.1290.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0470 - acc: 0.9851 - val_loss: 0.1290 - val_acc: 0.9655\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9890\n",
      "Epoch 00023: val_loss did not improve from 0.12897\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0345 - acc: 0.9891 - val_loss: 0.1337 - val_acc: 0.9644\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9880\n",
      "Epoch 00024: val_loss did not improve from 0.12897\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0368 - acc: 0.9880 - val_loss: 0.1346 - val_acc: 0.9667\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9901\n",
      "Epoch 00025: val_loss did not improve from 0.12897\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0321 - acc: 0.9901 - val_loss: 0.2342 - val_acc: 0.9436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9906\n",
      "Epoch 00026: val_loss improved from 0.12897 to 0.12780, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/026-0.1278.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0307 - acc: 0.9906 - val_loss: 0.1278 - val_acc: 0.9679\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9889\n",
      "Epoch 00027: val_loss did not improve from 0.12780\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0352 - acc: 0.9889 - val_loss: 0.1880 - val_acc: 0.9560\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9914\n",
      "Epoch 00028: val_loss did not improve from 0.12780\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0274 - acc: 0.9914 - val_loss: 0.1657 - val_acc: 0.9616\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9885\n",
      "Epoch 00029: val_loss did not improve from 0.12780\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0351 - acc: 0.9885 - val_loss: 0.1430 - val_acc: 0.9623\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9918\n",
      "Epoch 00030: val_loss did not improve from 0.12780\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0262 - acc: 0.9918 - val_loss: 0.2055 - val_acc: 0.9536\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9897\n",
      "Epoch 00031: val_loss did not improve from 0.12780\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0328 - acc: 0.9897 - val_loss: 0.1588 - val_acc: 0.9592\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9920\n",
      "Epoch 00032: val_loss did not improve from 0.12780\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0258 - acc: 0.9920 - val_loss: 0.1355 - val_acc: 0.9651\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9950\n",
      "Epoch 00033: val_loss improved from 0.12780 to 0.11779, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/033-0.1178.hdf5\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0167 - acc: 0.9949 - val_loss: 0.1178 - val_acc: 0.9716\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9887\n",
      "Epoch 00034: val_loss did not improve from 0.11779\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0371 - acc: 0.9887 - val_loss: 0.1641 - val_acc: 0.9585\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9901\n",
      "Epoch 00035: val_loss did not improve from 0.11779\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0325 - acc: 0.9901 - val_loss: 0.1444 - val_acc: 0.9592\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9911\n",
      "Epoch 00036: val_loss did not improve from 0.11779\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0294 - acc: 0.9911 - val_loss: 0.1452 - val_acc: 0.9613\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9955\n",
      "Epoch 00037: val_loss did not improve from 0.11779\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0143 - acc: 0.9955 - val_loss: 0.1459 - val_acc: 0.9602\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9959\n",
      "Epoch 00038: val_loss did not improve from 0.11779\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0133 - acc: 0.9959 - val_loss: 0.1228 - val_acc: 0.9681\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9949\n",
      "Epoch 00039: val_loss did not improve from 0.11779\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0157 - acc: 0.9949 - val_loss: 0.2026 - val_acc: 0.9543\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9923\n",
      "Epoch 00040: val_loss did not improve from 0.11779\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0260 - acc: 0.9923 - val_loss: 0.1274 - val_acc: 0.9697\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9960\n",
      "Epoch 00041: val_loss did not improve from 0.11779\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0128 - acc: 0.9960 - val_loss: 0.1875 - val_acc: 0.9578\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0181 - acc: 0.9943\n",
      "Epoch 00042: val_loss did not improve from 0.11779\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0181 - acc: 0.9943 - val_loss: 0.1365 - val_acc: 0.9695\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9958\n",
      "Epoch 00043: val_loss did not improve from 0.11779\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0131 - acc: 0.9958 - val_loss: 0.2656 - val_acc: 0.9418\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9923\n",
      "Epoch 00044: val_loss did not improve from 0.11779\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0259 - acc: 0.9923 - val_loss: 0.1206 - val_acc: 0.9700\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9961\n",
      "Epoch 00045: val_loss improved from 0.11779 to 0.11378, saving model to model/checkpoint/1D_CNN_custom_pool_2_DO_BN_13_conv_checkpoint/045-0.1138.hdf5\n",
      "36805/36805 [==============================] - 123s 3ms/sample - loss: 0.0126 - acc: 0.9961 - val_loss: 0.1138 - val_acc: 0.9709\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9970\n",
      "Epoch 00046: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0102 - acc: 0.9970 - val_loss: 0.1826 - val_acc: 0.9597\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9938\n",
      "Epoch 00047: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0212 - acc: 0.9938 - val_loss: 0.1779 - val_acc: 0.9574\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9961\n",
      "Epoch 00048: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0130 - acc: 0.9961 - val_loss: 0.1802 - val_acc: 0.9590\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9942\n",
      "Epoch 00049: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0185 - acc: 0.9942 - val_loss: 0.1326 - val_acc: 0.9676\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9965\n",
      "Epoch 00050: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0110 - acc: 0.9965 - val_loss: 0.1397 - val_acc: 0.9672\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0101 - acc: 0.9972\n",
      "Epoch 00051: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0101 - acc: 0.9972 - val_loss: 0.1658 - val_acc: 0.9667\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9951\n",
      "Epoch 00052: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0149 - acc: 0.9951 - val_loss: 0.2110 - val_acc: 0.9518\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9948\n",
      "Epoch 00053: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0160 - acc: 0.9948 - val_loss: 0.1483 - val_acc: 0.9648\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9955\n",
      "Epoch 00054: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0149 - acc: 0.9955 - val_loss: 0.1384 - val_acc: 0.9702\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9979\n",
      "Epoch 00055: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0067 - acc: 0.9979 - val_loss: 0.1743 - val_acc: 0.9606\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9971\n",
      "Epoch 00056: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0094 - acc: 0.9971 - val_loss: 0.1365 - val_acc: 0.9693\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9958\n",
      "Epoch 00057: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0149 - acc: 0.9958 - val_loss: 0.1738 - val_acc: 0.9625\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9933\n",
      "Epoch 00058: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0220 - acc: 0.9933 - val_loss: 0.1528 - val_acc: 0.9644\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9971\n",
      "Epoch 00059: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0100 - acc: 0.9971 - val_loss: 0.1404 - val_acc: 0.9700\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9986\n",
      "Epoch 00060: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0055 - acc: 0.9986 - val_loss: 0.1439 - val_acc: 0.9683\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9976\n",
      "Epoch 00061: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0078 - acc: 0.9976 - val_loss: 0.2572 - val_acc: 0.9513\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9959\n",
      "Epoch 00062: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0136 - acc: 0.9959 - val_loss: 0.1447 - val_acc: 0.9686\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9974\n",
      "Epoch 00063: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0082 - acc: 0.9974 - val_loss: 0.1375 - val_acc: 0.9700\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9977\n",
      "Epoch 00064: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0077 - acc: 0.9977 - val_loss: 0.1448 - val_acc: 0.9700\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9957\n",
      "Epoch 00065: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0125 - acc: 0.9957 - val_loss: 0.1643 - val_acc: 0.9644\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9975\n",
      "Epoch 00066: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0078 - acc: 0.9975 - val_loss: 0.1651 - val_acc: 0.9658\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9968\n",
      "Epoch 00067: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0101 - acc: 0.9968 - val_loss: 0.1962 - val_acc: 0.9592\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9956\n",
      "Epoch 00068: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0138 - acc: 0.9956 - val_loss: 0.1426 - val_acc: 0.9683\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0046 - acc: 0.9987\n",
      "Epoch 00069: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0046 - acc: 0.9987 - val_loss: 0.1621 - val_acc: 0.9679\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9980\n",
      "Epoch 00070: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0073 - acc: 0.9980 - val_loss: 0.2358 - val_acc: 0.9550\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9977\n",
      "Epoch 00071: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0082 - acc: 0.9977 - val_loss: 0.1196 - val_acc: 0.9739\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9969\n",
      "Epoch 00072: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0089 - acc: 0.9969 - val_loss: 0.1566 - val_acc: 0.9646\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9966\n",
      "Epoch 00073: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0103 - acc: 0.9966 - val_loss: 0.1402 - val_acc: 0.9672\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9970\n",
      "Epoch 00074: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0097 - acc: 0.9970 - val_loss: 0.1384 - val_acc: 0.9695\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9980\n",
      "Epoch 00075: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0063 - acc: 0.9980 - val_loss: 0.1766 - val_acc: 0.9644\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9979\n",
      "Epoch 00076: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0072 - acc: 0.9979 - val_loss: 0.1608 - val_acc: 0.9667\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9975\n",
      "Epoch 00077: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0087 - acc: 0.9975 - val_loss: 0.1844 - val_acc: 0.9644\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9974\n",
      "Epoch 00078: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0083 - acc: 0.9974 - val_loss: 0.1695 - val_acc: 0.9655\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9971\n",
      "Epoch 00079: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0085 - acc: 0.9971 - val_loss: 0.1702 - val_acc: 0.9662\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9965\n",
      "Epoch 00080: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0126 - acc: 0.9965 - val_loss: 0.1496 - val_acc: 0.9706\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0032 - acc: 0.9990\n",
      "Epoch 00081: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0033 - acc: 0.9990 - val_loss: 0.1386 - val_acc: 0.9732\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9963\n",
      "Epoch 00082: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0131 - acc: 0.9963 - val_loss: 0.1201 - val_acc: 0.9711\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0038 - acc: 0.9991\n",
      "Epoch 00083: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0038 - acc: 0.9991 - val_loss: 0.1512 - val_acc: 0.9711\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9983\n",
      "Epoch 00084: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0054 - acc: 0.9983 - val_loss: 0.1786 - val_acc: 0.9641\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9974\n",
      "Epoch 00085: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0078 - acc: 0.9974 - val_loss: 0.1516 - val_acc: 0.9662\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0041 - acc: 0.9988\n",
      "Epoch 00086: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0041 - acc: 0.9988 - val_loss: 0.1864 - val_acc: 0.9630\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0052 - acc: 0.9984\n",
      "Epoch 00087: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0054 - acc: 0.9983 - val_loss: 0.1631 - val_acc: 0.9648\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0238 - acc: 0.9937\n",
      "Epoch 00088: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0238 - acc: 0.9937 - val_loss: 0.1478 - val_acc: 0.9700\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9982\n",
      "Epoch 00089: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0071 - acc: 0.9982 - val_loss: 0.1231 - val_acc: 0.9711\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0036 - acc: 0.9988\n",
      "Epoch 00090: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0036 - acc: 0.9988 - val_loss: 0.1478 - val_acc: 0.9709\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0049 - acc: 0.9986\n",
      "Epoch 00091: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0049 - acc: 0.9986 - val_loss: 0.1457 - val_acc: 0.9713\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0025 - acc: 0.9993\n",
      "Epoch 00092: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0026 - acc: 0.9993 - val_loss: 0.1389 - val_acc: 0.9723\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9957\n",
      "Epoch 00093: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0137 - acc: 0.9957 - val_loss: 0.1815 - val_acc: 0.9667\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9970\n",
      "Epoch 00094: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0102 - acc: 0.9970 - val_loss: 0.1346 - val_acc: 0.9720\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0031 - acc: 0.9991\n",
      "Epoch 00095: val_loss did not improve from 0.11378\n",
      "36805/36805 [==============================] - 122s 3ms/sample - loss: 0.0031 - acc: 0.9991 - val_loss: 0.1347 - val_acc: 0.9713\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_13_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3Xd4VFX++PH3mclk0ntCAgECAtIJEIoioOKyiIqKi+Da67pr/bnrV3TVtayr6+rquou6dqyIYENQXJQiCgpEkN5LEkghvU4mM+f3x8mkN0KGBPJ5Pc88ydx2zr1z7/ncc86dM0prjRBCCAFgae8MCCGE6DgkKAghhKgiQUEIIUQVCQpCCCGqSFAQQghRRYKCEEKIKhIUhBBCVJGgIIQQoooEBSGEEFV82jsDxyoqKkonJCS0dzaEEOKksmHDhqNa6+jmljvpgkJCQgLr169v72wIIcRJRSl1sCXLSfOREEKIKhIUhBBCVJGgIIQQoorX+hSUUm8AFwKZWuvBTSw3ClgDzNJaL2hNWk6nk9TUVMrKylqXWYGfnx/x8fHYbLb2zooQoh15s6P5LeA/wNuNLaCUsgJ/B74+noRSU1MJDg4mISEBpdTxbKpT0lqTnZ1NamoqvXr1au/sCCHakdeaj7TWq4CcZha7A1gIZB5PWmVlZURGRkpAaCWlFJGRkVLTEkK0X5+CUqobcCnwUhttry0202nJ8RNCQPt2ND8P3Ke1dje3oFLqFqXUeqXU+qysrFYl5nKV4nCk4XY7W7W+EEJ0Bu0ZFJKAeUqpA8BvgBeVUpc0tKDW+hWtdZLWOik6utkv5DXI7S6lvPwIWrd9UMjLy+PFF19s1bpTp04lLy+vxcs/8sgjPPPMM61KSwghmtNuQUFr3UtrnaC1TgAWAH/QWn/qvRQ9u6rbfMtNBYWKioom112yZAlhYWFtnichhGgNrwUFpdQHmEdNT1dKpSqlblRK3aqUutVbaTaTH8A8adPWZs+ezd69e0lMTOTee+9lxYoVjB8/nmnTpjFw4EAALrnkEkaOHMmgQYN45ZVXqtZNSEjg6NGjHDhwgAEDBnDzzTczaNAgJk+eTGlpaZPpbty4kbFjxzJ06FAuvfRScnNzAXjhhRcYOHAgQ4cOZdasWQCsXLmSxMREEhMTGT58OIWFhW1+HIQQJz+vPZKqtb7iGJa9rq3S3b37boqKNjaQhgu3uwSLJQDzJGzLBQUl0rfv843Of+qpp9iyZQsbN5p0V6xYQXJyMlu2bKl6xPONN94gIiKC0tJSRo0axWWXXUZkZGSdvO/mgw8+4NVXX+Xyyy9n4cKFXHXVVY2me8011/Dvf/+biRMn8vDDD/Poo4/y/PPP89RTT7F//37sdntV09QzzzzDnDlzGDduHEVFRfj5+R3TMRBCdA6d8BvNbV9TaMjo0aNrPfP/wgsvMGzYMMaOHUtKSgq7d++ut06vXr1ITEwEYOTIkRw4cKDR7efn55OXl8fEiRMBuPbaa1m1ahUAQ4cO5corr+Tdd9/Fx8fE/XHjxnHPPffwwgsvkJeXVzVdCCFqOuVKhsbu6F2uYkpKtuPn1webzftt+IGBgVX/r1ixgmXLlrFmzRoCAgI4++yzG/xOgN1ur/rfarU223zUmMWLF7Nq1SoWLVrEE088webNm5k9ezYXXHABS5YsYdy4cSxdupT+/fu3avtCiFNXJ6opeJ7Db/YJ2GMWHBzcZBt9fn4+4eHhBAQEsGPHDtauXXvcaYaGhhIeHs53330HwDvvvMPEiRNxu92kpKRwzjnn8Pe//538/HyKiorYu3cvQ4YM4b777mPUqFHs2LHjuPMghDj1nHI1hcZ57+mjyMhIxo0bx+DBgzn//PO54IILas2fMmUKL7/8MgMGDOD0009n7NixbZLu3LlzufXWWykpKaF37968+eabuFwurrrqKvLz89Fac+eddxIWFsZDDz3E8uXLsVgsDBo0iPPPP79N8iCEOLUobzyN401JSUm67o/sbN++nQEDBjS5ntvtoLh4M3Z7Ar6+Ud7M4kmrJcdRCHFyUkpt0FonNbecNB8JIYSo0omCgveaj4QQ4lTRaYKCN7+8JoQQp4pOExSk+UgIIZrXCYOC1BSEEKIxnSYomOYjJc1HQgjRhE4TFAxFR6kpBAUFHdN0IYQ4ETpVUFDKgvQpCCFE4zpVUPBW89Hs2bOZM2dO1XvPD+EUFRUxadIkRowYwZAhQ/jss89avE2tNffeey+DBw9myJAhfPjhhwAcOXKECRMmkJiYyODBg/nuu+9wuVxcd911Vcs+99xzbb6PQojO4dQb5uLuu2Fj/aGzAfxdxaCsYDnGYaMTE+H5xofOnjlzJnfffTe33XYbAPPnz2fp0qX4+fnxySefEBISwtGjRxk7dizTpk1r0e8hf/zxx2zcuJFNmzZx9OhRRo0axYQJE3j//ff59a9/zZ///GdcLhclJSVs3LiRtLQ0tmzZAnBMv+QmhBA1nXpBoVltX1MYPnw4mZmZHD58mKysLMLDw+nevTtOp5MHHniAVatWYbFYSEtLIyMjg9jY2Ga3uXr1aq644gqsVitdunRh4sSJrFu3jlGjRnHDDTfgdDq55JJLSExMpHfv3uzbt4877riDCy64gMmTJ7f5PgohOodTLyg0cUdfVrwVpewEBPRp82RnzJjBggULSE9PZ+bMmQC89957ZGVlsWHDBmw2GwkJCQ0OmX0sJkyYwKpVq1i8eDHXXXcd99xzD9dccw2bNm1i6dKlvPzyy8yfP5833nijLXZLCNHJdLI+Be91NM+cOZN58+axYMECZsyYAZghs2NiYrDZbCxfvpyDBw+2eHvjx4/nww8/xOVykZWVxapVqxg9ejQHDx6kS5cu3Hzzzdx0000kJydz9OhR3G43l112GX/9619JTk72yj4KIU59p15NoQmmLd87j6QOGjSIwsJCunXrRlxcHABXXnklF110EUOGDCEpKemYftTm0ksvZc2aNQwbNgylFE8//TSxsbHMnTuXf/zjH9hsNoKCgnj77bdJS0vj+uuvx+02Ae/JJ5/0yj4KIU59nWbobICSkp1orQkMlF8ca4gMnS3Eqavdh85WSr2hlMpUSm1pZP6VSqlflFKblVI/KKWGeSsv1eR7CkII0RRv9im8BUxpYv5+YKLWegjwOPCKF/NSqeN8o1kIIToir/UpaK1XKaUSmpj/Q423a4F4b+XFQymF2y1BQQghGtNRnj66EfiysZlKqVuUUuuVUuuzsrKOIxmpKQghRFPaPSgopc7BBIX7GltGa/2K1jpJa50UHR19HKlJn4IQQjSlXR9JVUoNBV4DztdaZ5+A9GTobCGEaEK71RSUUj2Aj4Grtda7Tkyq3qkp5OXl8eKLL7Zq3alTp8pYRUKIDsObj6R+AKwBTldKpSqlblRK3aqUurVykYeBSOBFpdRGpdT6RjfWdrnCG30KTQWFioqKJtddsmQJYWFhbZ4nIYRoDa8FBa31FVrrOK21TWsdr7V+XWv9stb65cr5N2mtw7XWiZWvZr9Ucbw832hu6yak2bNns3fvXhITE7n33ntZsWIF48ePZ9q0aQwcOBCASy65hJEjRzJo0CBeeaX66duEhASOHj3KgQMHGDBgADfffDODBg1i8uTJlJaW1ktr0aJFjBkzhuHDh3PeeeeRkZEBQFFREddffz1Dhgxh6NChLFy4EICvvvqKESNGMGzYMCZNmtSm+y2EOPWccsNcNDFyNm53FFqHYLUe2zabGTmbp556ii1btrCxMuEVK1aQnJzMli1b6NWrFwBvvPEGERERlJaWMmrUKC677DIiIyNrbWf37t188MEHvPrqq1x++eUsXLiQq666qtYyZ511FmvXrkUpxWuvvcbTTz/Ns88+y+OPP05oaCibN28GIDc3l6ysLG6++WZWrVpFr169yMnJObYdF0J0OqdcUGha879j0FZGjx5dFRAAXnjhBT755BMAUlJS2L17d72g0KtXLxITEwEYOXIkBw4cqLfd1NRUZs6cyZEjRygvL69KY9myZcybN69qufDwcBYtWsSECROqlomIiGjTfRRCnHpOuaDQ1B19eXkuDkcKgYGJWCze3fXAwMCq/1esWMGyZctYs2YNAQEBnH322Q0OoW2326v+t1qtDTYf3XHHHdxzzz1MmzaNFStW8Mgjj3gl/0KIzqndv6dwYnl2t22fQAoODqawsLDR+fn5+YSHhxMQEMCOHTtYu3Ztq9PKz8+nW7duAMydO7dq+q9+9ataPwmam5vL2LFjWbVqFfv37weQ5iMhRLM6WVDwNB+1bUdzZGQk48aNY/Dgwdx777315k+ZMoWKigoGDBjA7NmzGTt2bKvTeuSRR5gxYwYjR44kKiqqavqDDz5Ibm4ugwcPZtiwYSxfvpzo6GheeeUVpk+fzrBhw6p+/EcIIRrTqYbOdjqzKSvbT0DAYKzWY/yd5k5Ahs4W4tTV7kNnd0zeaT4SQohTRScLCt5pPhJCiFNFpwoK5stryPhHQgjRiE4VFKT5SAghmtbJgoI0HwkhRFM6VVCQ5iMhhGhapwoKHan5KCgoqL2zIIQQ9XSyoCDNR0II0ZROFRS81Xw0e/bsWkNMPPLIIzzzzDMUFRUxadIkRowYwZAhQ/jss8+a3VZjQ2w3NAR2Y8NlCyFEa51yA+Ld/dXdbExvZOxsNC5XERaLH0rZWrzNxNhEnp/S+Eh7M2fO5O677+a2224DYP78+SxduhQ/Pz8++eQTQkJCOHr0KGPHjmXatGlVwakhDQ2x7Xa7GxwCu6HhsoUQ4nicckGhZdq2pjB8+HAyMzM5fPgwWVlZhIeH0717d5xOJw888ACrVq3CYrGQlpZGRkYGsbGxjW6roSG2s7KyGhwCu6HhsoUQ4nicckGhqTt6rV0UFf2Mr288dnvjBXNrzJgxgwULFpCenl418Nx7771HVlYWGzZswGazkZCQ0OCQ2R4tHWJbCCG8pVP1KXjz6aOZM2cyb948FixYwIwZMwAzzHVMTAw2m43ly5dz8ODBJrfR2BDbjQ2B3dBw2UIIcTy8FhSUUm8opTKVUlsama+UUi8opfYopX5RSo3wVl7qa/unjwYNGkRhYSHdunUjLi4OgCuvvJL169czZMgQ3n77bfr379/kNhobYruxIbAbGi5bCCGOh9eGzlZKTQCKgLe11oMbmD8VuAOYCowB/qW1HtPcdo9n6GyAwsIN2Gxd8POLb9HynYkMnS3Eqavdh87WWq8Cmvqpr4sxAUNrrdcCYUqpOG/lp5qFjvDlNSGE6Ijas6O5G5BS431q5bQj3kzUPA4qX17rKLSGo0dh/34IDISBA6GJJ3arZGXBzz9DRgZUVIDTadYLCICgIAgOhm7doHt3M624GHbuhO3bobwcIiIgMhJ8fSEvD3JzoawMeveG/v0hKgqKimDbNvPKyjLbKC426/TpY15xcWbe4cOQmWnSjY42r5ISOHLEzMvJMdsvKzP7HBMDsbHmr90OFgtYrWZfPMvl5EBamlk/Nxf8/My+BASYdEJDzatLF7Ov8fEmf9u2wdatcOBA9b4VFpr1AwPN8QkPN/sfFQVut1kmN9fss8tl8qGUmd+lS/XxOHrU7K/LBf7+1XkKCTF5slrNZ7lvHxw8aPbLz8+8fHyq99NmM+v5+5uX1Vr98qTvdEJpqUm3qMi8B5Mvi8Vsw2ar3q5nutVqpvn4mPm+vuYYl5eb45mSYvYjNhZ69jTHLjfX5PfQIXA4TH49eQsIMMfN1xcKCsyy+fkmPV9fk0bPnpCUZF5BQebcTE4251xpqdmm5xy1WMyrosLMKyszafTvDwMGmHO2qMiklZdnzqv0dHOu33gjNPDjjm3qpHj6SCl1C3ALQI8ePRpcRmvd5PP/NbbWqcY+0tpc9DV5LiAwJ2pZGZSWagoL4YMPzEldUmJOxPR0c2KWl5uX211doISFmYsrLc28AgMhIcG8LBbYvdu8MjNNIdmli1kvJ8cUdIcPmwuxuLg6b3FxMHkyjBplpufnm1dRkXlfUGAKvdTUlh+D0FCzjWMRFGTSrCsw0FzgFRXHtj2oLkS1Nse0JaxWU3iFh5t0S0rMq6DAFJ5NiYkxwS8szBTaZWXm8ywqMgVbTk71NiwWs1xQkCnkrFbzWWdl1T52vr4mQPj4eM4b87nUPMdsNnMO9OxptltWBtnZJi2XyyzrcJh1Pa+a82oW6p4COSjIpK119TntdFYHD880t7t6W06neZWXm/R8fEzgjI+Hfv1MIfv11+Y8DAkx+e3Z06TpKaxLSsz8khKzndBQc5wqnw6nvNwst3q1uXZqCg42NzmBgWY9X18z3ZNHm606+OTlwY4d8MUX1eeWxWLyFRNjrp2hQ6GR4q9NtWdQSAO613gfXzmtHq31K8ArYPoU6s738/MjOzubyMjIFgSGjt985IlZze2K01ldaBYXm7uhwEBzkjkc1XdYdYMCmAtPKc8JqKmoyOann/y4667ay9ls5iKw26tPas9dpWc7cXHQtaspcJYtqy7kg4PNxde1qwkeO3eav5GRZp1+/eBXvzIXWK9eZt7XX8OiRTB3bvX2Q0NNoRAUZPZv4kQYPty8evSovlvU2ly8RUXmmKSlmTu/tDRTsA4YYF6BgaaQyskxxyk83Lx8fWHvXnNx7tlj8jhokLmwu3Y1x9Vzh3fokAl46enmgu3a1QS+oiJTkGZlmcLFc2zCw2t/ng6HCZaZmdXBtmZB4edXXQuwWhs+R0pKzH6mp5sgmZZm1hs40OxnSEjT54/bbda3WMxnZWmkMdnhMMfLUwOre15qbQrRwkJzTsbFNZzn9tTUNeVytU1+MzJg/Xpz/g8fDqed1vgxbUx5ubkOgoPN8W7RfW4b8+pvNCulEoAvGulovgC4neqO5he01qOb22ZDHc1Op5PU1NQWPdPvcBzGYrFhs0W3aB+8pe5JqrW54ygqMhe7Z57nrr7myeF2164BWK2m0K6oMCeVh6eA8QQATzqedbWuroL7+fkRFBRPSYmNwkJToHnuUBs6sSsqzN1qaGjtC8rTHOR2mzuc1pzULpcpLENCTD7a48IQ3pNZnEl+WT59I/ue8LS11mSXZnO05CiR/pFEBkRiUe33ZL7WGqfbiVVZsVrqR6aWt4A0r6UdzV6rKSilPgDOBqKUUqnAXwAbgNb6ZWAJJiDsAUqA61ubls1mq/q2b3PWrbsCP7+eDBjQ/DhExys319xNJiebO4jkZHM3UVBgCv+ad9nZ2eYuNTISfvtbUyAWF5vlHI7ql49P9V1zXBycf765K/GcN+XlsGuXqSKHhTWdvwJHAXarHbuPHQCny0lGcSpFRekkRA0g0Dew1vL5Zfn8b9//uLDfhfj5+FH5xepalDJ3zC3hdDn5PuV7luxewtK9SwnzC+OpSU9xRvcziDuGRw7c2s3qQ6vJKc3hon4X1bq4jhQe4bm1zzGsyzBmDZ5VNc/pcjJ301yOlhzlvnH31brwCh2F3PXVXezL3Uexs5gSZwmjuo7igfEP0C+yX4v2a9m+ZWSVZGGz2LBZbdgsNnytvtisNuKC4hgUM6jB/diWtY3Vh1bzfcr3BNoC+d3I3zE8bjgALreLr/d+zbJ9y0jqmsSUPlMI96/9Lfbskmy+O/QdKw+sZH/efsL9w4nwiyA+JJ6bR95MkG/t0XkXblvIDyk/kFeWR54jj1JnadU8Px8/xnQbw8SEiYyMG4nNaqOsooy8sjwi/CPwtfrW2taGwxv4Zv83KBQ2q40AWwDTB0wnKiCqapkfUn7g0g8vJbM4kwk9J/D7pN9zaf9LySvLI6UghdSCVNIK0jhceJj0onTiQ+I5s/uZjIkfQ6g9lNyyXNIK0igqLyIuOI64oLha529heSGlzlLKKsooqyhjf95+ko8kk3wkme1Ht5OSn0JpRfU+WpWV6MBo7FZ71bQ+EX2Ydvo0pp0+jYSwBJwuJ1klWRQ6Cuke2p0AW0Ct/dZaszd3Lz+k/MCalDXsztlNYXkhhY5CSitKUSisFisKRYW7AqfbidPlpLSilOLyYlzaRbBvMON6jGNiz4n0Du/Nj6k/sjplNclHkgGwW+34+fhx99i7eXDCg82eg8fDqzUFb2iopnAsNmwYg49POMOGfdWGuTIOHIDXX4clS0wBX7MtNjISRo40zR0hIeZVXl7dtg5w9dXwm9+Yu/u6isuL+Xb/txQ7ixkYPZB+kf3w86m9oNaag/kHWZu6lsOFh8kpzSGnNIeuwV2ZfNpkRsaNxKVdfLz9Y+asm8PqQ6sBsFlsBPoGkl+Wj67shO8X2Y8V164gLtiUzkXlRUx+ZzJrUtcQHxLPwxMe5rrE61BKkXwkme8OfkdGcQZlFWU4Khx0De7KVUOv4rSI06ry53K72JSxiW/3f8u3+7/lu0PfUVRehM1iY1yPcew8upMjRUf47ZDf8tCEh/Dz8aOsoowSZwmZxZmkF6WTWZyJVVkJtgcT7BvMhiMb+HDrh6QWmE6GpK5JvHTBS4yMG8m8LfO4bclt5JaZtq7BMYN5/JzHyS/L57FVj7Evdx8AT016ivvOug8wBfNl8y9j0c5FjOsxjkBbID4WH5btW4bD5WDW4FncOvJWEsISiA2KxWa14XK7yCvL42D+Qd7f/D7v/PIOmcWZTZ4rNyTewLO/fpYwvzDc2s0Hmz/g/m/uJ6XAPHsRGxRLgaOAEmcJZ8SfwZhuY5i/bT6HCw9jURbc2o1VWTmj+xkE+QaRVZxFVkkWh/IPAaZAPy38NAocBeSU5lDsLKZ/VH8+mvERg2MGU+Is4bYlt/HWxrfw9/Enwj+CUL9QAmwBqMrRhPMd+ezK3gVQVWg6XA4Agn2DmdR7ElP7TEWjeWXDK2w4sqHefobaQ3lwwoPcMfoOPtz6ITcvupkeoT24Zug1vLnxTfbn7W/w+FiVlZjAGDKKM3BrNwqFr9W3Kv26aZRVlDU4D0Ch6BfZjyFdhtAjpAfdQ7sTHRBNblku6UXpZBRl4HQ7qz7/9YfXs/3odgDC/cLJK8urui4AugV3o3d4b8oqysgqySKzOJMSp6neh9hDGBg9kFB7KMH2YPx9/NFo3NqNW7vxsfiYGwWLDX+bP4G2QAJsAaQVprHy4Eq2ZW2rOt5j4scwuuvoqv0uqyjjvN7ncUn/Sxo9r5rS0ppCpwsKP/88HqVsJCZ+e1z5qKgwQcDTmfrFF6Y9HeDss027bu/e5pWYCN26V/Bj2loGRQ+qd3dX6Cjkyz1fUuE2PUxa66qToNBRyMqDK/l2/7e1TnqLstAjtAcxgTFEB0Rj97HzU9pPVYUjmAsrzC+MnNIcNJoI/whsFhsZxRn0Du/NNUOvwWa1UegopKi8iMiASLoGd8WqrNz11V30CO3B8muXE+oXykUfXMS3+7/lr+f8lc93fc7a1LV0C+5GviOfonLTI+vv44/dx47daiezOBONZkLPCZyTcA7rDq9j9aHVFDgKAOgf1Z9zEs5h8mmTmdRrEsH2YIrKi3jyuyd5ds2zjV7gddksNn7d59f8dvBvcWkX9/7vXjKKMhjZdSTrD69nbPxY3rz4TTalb+Kh5Q+xO2c3AMNjh/PYOY/x7i/vMn/rfD6/4nMu7Hchj654lEdWPsLzv36eu8ZWd7BkFmfy7A/PMmfdHIqd1T3jwb7BFJYXVr33sfhwUb+LuC7xOgZFD6q6K/T8LXeVs2T3Ev7xwz+ICYzhwQkP8vamt/kx7UdGxo3k9tG3M77HeHqH9ybfkc9bG99izro57Mvdx9S+U7k+8Xqm9p3KpvRNfLHrC5buXQpAdGA00QHR9I3oy8SEiYzqOqrqDhpg+f7l/Pbj35JXlsejZz/KO7+8w9bMrTw04SEenvhwg00Xnv1edXAVa1PXVp1PwfZgtmRuYcnuJVVBbEjMEH438nfMGjwLPx8/yl3lHMw/yAPfPMCXe76kS2AXMoozOLfXuXw04yMi/CNwazdf7/2a1YdWExsUS/eQ7sSHxNMtpBvRAdFYLVYKHYWsO7yOH1J+IL8sn24h3ega3JUg3yDSi9I5XHiYzOJM/H38q24UAmwB+Pn4Yfex0zW4K4mxifVqSM3Znb2bz3d+zt7cvXQJ7EKXoC4E+QZxIO8Au3N2cyDvAAG2AKIDzHE/Pep0zux+JgOjBx5Xc1RmcSaH8g8xJGZIrc+vLUhQaMTGjefhdpcyYsT3LVrerd1VH3JJCSxdCgsXms7QggIN4fshLpnwuDymnBXLFRd1YUCvcMpd5TgqHGSVZPHpjk9ZsG0BWSVZJHVNYtV1q/C3+QNQ7irn3Lnn8n1K4/npE9GHi/pdxIX9LiQqIIrtWdvZlrWNvbl7ySrJIqs4i2JnMcNjhzO+x3jG9RhHr7BeBNuDsSgLR0uOsmzfMpbuXUqho5Abht/AlD5Tmjx5Vx1cxfnvnU+vsF70Du/Nol2LeOvit7g28Vq01izevZiX1r9EQmgCExMmMqHnBGKDqseTSi1I5e1Nb/PmxjfZk7OH0yNPZ2LPiUxMmMjZCWfTNbhro2kfyDvA13u/xtfqi91qx9/mT0xgDF0CuxATGINbu6uq57FBsbWCbH5ZPn9Z8Rfe2vgW9591P386809VBV6Fu4KF2xYSYAvgwn4XopSixFnC+DfHszt7Nw9NeIj/W/Z/XDvsWt68+M0G23KzS7KramKe2liYXxiRAZFEBURxXu/ziAmMaXTfPDYc3sANn9/ALxm/EBsUy5OTnuSaYdc0+Jm4tZtSZ2m95rxjlVGUwZUfX8k3+78hKiCK96a/x+TTJrd6e1prtmVtw+FyMDx2eKNt30v3LOXhFQ8ztttYnpn8DDZry0coFm1HgkIjfvnlAsrLM0hKanobB/IO8Kev/8SnOz7l9LCh+B6eyPZlY3FYs7DHbyO83zYK/DdRopt/ttBTCA2NGcpDyx9i5uCZvD/9fQBuWXQLr/38Gq9e9CoTek6oWsfPx6/qFWJv5jESL1m+fzkXvH8BpRWl/GvKv7hzzJ3HvA2tNQWOAkL9Qr2Qw6bTbWkHXUp+CqNeHUVGcQajuo5i1fWr6jXNeUO5q5yv9nzFOQnnEGwP9np6YJrwFmxbwFk9zqJbSLcTkqboGNq9o7mjslh80brVY+ehAAAgAElEQVS80fklzhKe/v5p/v7931HaQnzmTWzbtwviX4aLzAisfvZQekUPZFiXWYyIG8HwuOFEB0RXtXvnleVh9zEdQ4G2QMbGj626y7NarNz/zf0MiRlCiD2E135+jQfOeoCbRtx0Qvb/WJzT6xyWX7uc/Xn7mTV4Vqu2oZQ64QHBk25LdQ/tzmezPuPJ1U/yn6n/OSEBAcDX6su006edkLQ8rBYrMwfPPKFpipNLp6spbN06i6KinxkzZme9eU6Xk8nvTmbFgRWMsF3BlueeJtAVz+23ww23OMi1biM2KJbYoNhWPyamtebqT67mvc3vYVVWpvadyqezPm3Xx+KEEKc+qSk0oqmawn3L7mPFgRUM2PkmyR9cx4UXwquvmuf1wU4Cw487faUUr017jYP5Byl0FPLu9HclIAghOoxOGBTsuN31n2x5f/P7PLf2OUK238GhL67j1VfNOCPe+OKUn48fK69bWfWImhBCdBSdrkRSyhe3u3ZN4ecjP3PT5zcRkDWeiiXPsvxbGN3sd6uPj0VZpIYghOhwOl1QsFjsOF1lXP3J1WxK30RKQQp5ZXn4lnVDv/8RSz62eT0gCCFER9XpblUtFjvb8st495d3CfcP58ohVzI4/Umcr67kg1e7cN557Z1DIYRoP52upqCUL7/kmfGCP5rxEYd3xzDnZXjsMbjssnbOnBBCtLNOWVPYUgD9IvoSExjDs8+aweXuuKO9cyaEEO2v0wUFjQ9b8uHM7mNJTYV58+Cmm5ofUVQIITqDThcU9hfmU1ABZ8Yn8cILZvz/uj8sI4QQnVWnCwrrM83QwkNDR/Df/5qhqhMS2jdPQgjRUXS6oLAufR/hNljxcX8KCuCPf2zvHAkhRMfR6YLCTxl7GBQCL74Yyvjx5gfihRBCGJ0qKBwuPMzBgkx6WsI5dMjG1Ve3d46EEKJj6VRB4ftD5odsujrNT0zGx7dnboQQouPpVEFh9aHV+PvYCSrsBUBM8z+QJYQQnYpXg4JSaopSaqdSao9SanYD83sopZYrpX5WSv2ilJrqzfysTllNUuxACvPNz0ZKUBBCiNq8FhSUUlZgDnA+MBC4Qik1sM5iDwLztdbDgVnAi97KT6GjkI3pGxnbLZHcXBMNoqO9lZoQQpycvFlTGA3s0Vrv0+ZXbeYBF9dZRgOeHyAOBQ57KzM/pv2IW7s5s9tI8vJiCA524ndifnVRCCFOGt4MCt2AlBrvUyun1fQIcJVSKhVYAjQ4ApFS6hal1Hql1PqsrKxWZSbIN4gZA2cwplsSubkxREWVtWo7QghxKmvvjuYrgLe01vHAVOAdper/8ozW+hWtdZLWOim6lW0+Y+PHMn/GfEL9IsjLiyEqqvT4ci6EEKcgbwaFNKB7jffxldNquhGYD6C1XgP4AVFezBMWi528vBgiI0u8mYwQQpyUvBkU1gF9lVK9lFK+mI7kz+sscwiYBKCUGoAJCq1rH2ohi8VObm4MkZHF3kxGCCFOSl4LClrrCuB2YCmwHfOU0Val1GNKqWmVi/0RuFkptQn4ALhOa629lSeTL1/y86OJjCzyZjJCCHFS8uovr2mtl2A6kGtOe7jG/9uAcd7MQ115eXbcbisREQUnMlkhhDgptHdH8wmXleULQGSkBAUhhKirEwYFUzkKD89r55wIIUTH06KgoJS6SykVoozXlVLJSqnJ3s6cN2Rmmr8REbntmxEhhOiAWlpTuEFrXQBMBsKBq4GnvJYrL6oOCjntmxEhhOiAWhoUVOXfqcA7WuutNaadVDIzwWJxERIiNQUhhKirpUFhg1Lqa0xQWKqUCgbc3suW92RmQlhYNko52jsrQgjR4bT0kdQbgURgn9a6RCkVAVzvvWx5T2YmhIfn4HZLUBBCiLpaWlM4A9iptc5TSl2FGfI633vZ8p7MTNPJbAZuFUIIUVNLg8JLQIlSahjmW8h7gbe9lisvMkEhT2oKQgjRgJYGhYrK4ScuBv6jtZ4DBHsvW95jgkK+BAUhhGhAS/sUCpVS92MeRR1fOby1zXvZ8o6yMigogIiIAmk+EkKIBrS0pjATcGC+r5COGQb7H17LlZd4fp8nMrJIagpCCNGAFgWFykDwHhCqlLoQKNNan3R9ChkZ5q8JClJTEEKIulo6zMXlwE/ADOBy4Eel1G+8mTFv8HybOTKyBK2lpiCEEHW1tE/hz8AorXUmgFIqGlgGLPBWxtrc//5H5h++Bx4hKqpUmo+EEKIBLe1TsHgCQqXsY1i3Y3A4yDxofoIzMrJUmo+EEKIBLa0pfKWUWor5dTQwHc9Lmli+44mIIJMY/O0ugoIgJ0dqCkIIUVeLgoLW+l6l1GVU/0raK1rrT7yXLS+oDAoxwaVYLL5SUxBCiAa0+Oc4tdYLgYVezIt3RUaaoBBQjMVilz4FIYRoQJP9AkqpQqVUQQOvQqVUs79nqZSaopTaqZTao5Sa3cgylyultimltiql3m/tjjQrPNwEBb98LBZf+fKaEEI0oMmagta61UNZKKWswBzgV0AqsE4p9bnWeluNZfoC9wPjtNa5SqmY1qbXLB8fMlUXhvukoJQdrZ1o7cZ8OVsIIQR49wmi0cAerfU+bW7L52HGTqrpZmCO1joXoM4TTm1Ka8jU0cSoLCwWO4D0KwghRB3eDArdgJQa71Mrp9XUD+inlPpeKbVWKTXFW5nJzwcnvsS407FYfAGkCUkIIepocUezF9PvC5yNGU9plVJqiNY6r+ZCSqlbgFsAevTo0aqEPENcxDhTMd+9QzqbhRCiDm/WFNKA7jXex1dOqykV+Fxr7dRa7wd2YYJELVrrV7TWSVrrpOjo6FZlxjPERUzpIakpCCFEI7wZFNYBfZVSvZRSvsAs4PM6y3yKqSWglIrCNCft80ZmqoJC0b4afQpSUxBCiJq8FhS01hXA7cBSYDswX2u9VSn1mFJqWuViS4FspdQ2YDlwr9Y62xv5GTYMXpj8BQkFv6C0+SkICQpCCFGbV/sUtNZLqDMchtb64Rr/a+CeypdX9ekDd0zZDV/n4Sx2VaYvzUdCCFFT53pIPyICAGu+CQZSUxBCiNo6ZVCw5JYC8j0FIYSoq1MGBWt+GYD80I4QQtTRuYJCZCQAljzzuwrSfCSEELV1rqDgaT6qCgrSfCSEEDV1rqAQHg6AJa8YkOYjIYSoq3MFBZsNgoNROYWA1BSEEKKuzhUUACIjseR5goLUFIQQoqbOFxQiIlCVzUcVFTntnBkhhOhYOmVQsOQW4OMTSWmpV4ZZEkKIk1anDApkZ+Pv35uyMgkKQghRU+cMCjk5+PufJjUFIYSoo/MFhchIyMnBz7cXDsdB3O6K9s6REEJ0GJ0vKEREgNtNgCsOrStwOFLbO0dCCNFhdM6gAPiXmL9lZXvbMzdCCNGhdNqg4FcSAiD9CkIIUUPnCwqVg+L5FvmglE2eQBJCiBo6X1CorCmo3Hz8/BKkpiCEEDV02qBAdjZ+fvJdBSGEqKnzBYXKkVLNdxV6S01BCCFq8GpQUEpNUUrtVErtUUrNbmK5y5RSWimV5M38AODrC0FB5rsKfr2pqMjB6czzerJCCHEy8FpQUEpZgTnA+cBA4Aql1MAGlgsG7gJ+9FZe6qn8Apu//2kA0oQkhBCVvFlTGA3s0Vrv01qXA/OAixtY7nHg70CZF/NSW43xj0AeSxVCCA9vBoVuQEqN96mV06oopUYA3bXWi5vakFLqFqXUeqXU+qysrOPPWeX4R35+vQCpKQghhEe7dTQrpSzAP4E/Nres1voVrXWS1jopOjr6+BOvDAo+PiHYbFFSUxBCiEreDAppQPca7+Mrp3kEA4OBFUqpA8BY4PMT0tlc2acAyGOpQghRgzeDwjqgr1Kql1LKF5gFfO6ZqbXO11pHaa0TtNYJwFpgmtZ6vRfzZFTWFNC6cghtGf9ICCHAi0FBa10B3A4sBbYD87XWW5VSjymlpnkr3RaJiACXCwoKKmsKMoS2EEIA+Hhz41rrJcCSOtMebmTZs72Zl1o832qu/AIbuHA4UvD373XCsiCEEB1R5/tGM1QNiuf5AhvIE0hCCAGdNSjUqynIdxWEEAI6e1DIzsZu74ZSvlJTEEIIOmtQiIsDqxW+/BKlrPj7n0ZR0ab2zpUQQrS7zhkUwsPhvvvg7bfhyy8JDz+PvLwVuFyl7Z0zIYRoV50zKAA8/DAMHAi33EKkbSJudyl5eSvbO1dCCNGuOm9QsNvhzTfh8GHC/rYEi8WfnJwlza8nhBCnsM4bFABGj4Y//hHLq28Qv3Mo2dkSFIQQnVvnDgoAjz4KvXrR7Y0cysr2UlKyu71zJIQQ7UaCgr8/XHMNvj/uwTcHaUISQnRqEhQAZsxAaU3XNV2kCUkI0alJUAAYNAgGDaLLSp/KR1OL2ztHQgjRLiQoeFx+OX7rD2PLKic391vvp/fPf8Ijj3g/HdEybjds2NDeuRCi3UlQ8KhsQuqy2vfE9Cv897/wwgugtffTEs376CNISoLt29s7J95XVibnnWiUBAWPAQNgyBBivwvm6NHPcLsd3kuroAB27YLcXNgtTzt1COsrf9tp8+b2zYe3FRSYYV7efru9cyI6KAkKNV1+OYHJ2ZB2hCNH3vReOptqjLP044/eS0e0nCcY7NjRvvnwtuRkyMuDZcvaOyeig5KgUNOMGQB0/zGBQ4eexO0u9046ycnmr68vrF3rnTTEseksQcHTb3Ki+0/c7hObnmg1CQo1nX46DBtG3Eo/HI5DpKe/5Z10kpNNFX7cuI5fU5g7F+68s71z4V05OXD4sPn/VA8KnmayHTugsPDEpOl2w+DB8NhjJyY9cVwkKNR17bX4rN9B7IGBHDz4N+/UFpKTYcQIGDPGNCWVduDRWV9+GV58EUpK2jsn3uOpJfTvbwrLU/mudsMGCA01Hc0bN56YNNevNx340mR1UvBqUFBKTVFK7VRK7VFKzW5g/j1KqW1KqV+UUt8opXp6Mz8tcvPNEBFB7w9DcDgOkp7exh1yJSWwbVt1UKiogJ9/bts02kppqSlEXK5T+3FNT1C4/HKzzykp7Zsfb8nPNw82XHONee+pNXjbZ5+Zvz//fGoH3FOE14KCUsoKzAHOBwYCVyilBtZZ7GcgSWs9FFgAPO2t/LRYUBDccQe+X60lOmMQhw49YWoLGRlwxRXw9dfHt/3Nm82F4QkK0HGbkDZsAKfT/P/TT+2bF2/avNn8xsa555r3J6oJyeGAf/3rxDXjePqypk6Fbt1ObFCwWqGoCPbsOTFpilbzZk1hNLBHa71Pa10OzAMurrmA1nq51trTLrEWiPdiflrujjsgMJA+C2MpKztAyq7H4OKLYd48mDIFnnii9Xc8ngtzxAjTr9CjR8cNCt9/b/5GRrY+jxs2wLXXmgLwRHG7Td5b+iz+5s0wdKh5LBlOXFB4+WW4+27znZUTwVPbGznSfCfjRNT+9u6FrVvh6qvNe8/5LzosbwaFbkDNenhq5bTG3Ah86cX8tFxkJNxyC/aPV9DNMQ3/P/wN/dNP8O67prbw4IMwfbp5tO9YJSeb7Xfvbt6PGdNxn0D64Qfo1w8mTWp9TeGpp8wz8XPntm3emvLRR3DWWbB8efPLag1btsCQIRAdbWoMJyIolJaaYwPwzjveTw9MEOjRw+xnUhLs3Gm+t3A8Dh1qOrh8/rn5O3u2edpOgkKH1yE6mpVSVwFJwD8amX+LUmq9Ump9VlbWicnUPfeAxUKfW5KJWa5Ju70r7itmmsDw/POweLF5Wunll02/AJg71DVrYMEC0w7fEE8ns1Lm/ZgxcPCgaZ7qSLQ2QeHMMxvP4/79je8nmKC5aJH5/8knq5uivG3xYvP300/rz8vPr91pfvCgab4ZMsR8Jp7OZm/7738hPR1mzoRffjEvb1u/3tQSoPrv8RTSubkwYQJMnNj4DdJnn5knj04/3dTGTpWgcAp/I9ybQSEN6F7jfXzltFqUUucBfwamaa0bbGPQWr+itU7SWidFR0d7JbP1xMfDNdegDqVSesU57Lk0jdTU50zBcddd5u7+9NPh97+HYcPg1lvNOmeeab7vMHly/UK0vNw0VYwYUT2to/Yr7N4NR4+a/Rk92kyrmccNG+C000yh1lhh/9FHptnoL3+BAwfg/fe9nm3cbvjqK/P/55/Xvni1hvHj4Te/qZ7m6WQeMsT8bS4obN0Kc+aYgFnzqbHiYkhNbVlhUVJiagnnngv/+Q/4+JibDW/Kzzft+UlJ5r0nKLS2CUlr81BGSorZ94ZqgtnZ8N13pukVzHmfnNy2BeqOHeYcXHkCf0p3507o2tXc6LS1kpL277/TWnvlBfgA+4BegC+wCRhUZ5nhwF6gb0u3O3LkSH3CZGZq/e9/a3dZmd68+VK9cqWfLiraUj3f7db644+17tNHa39/radP1/rdd7X+73+19vPTOjZW6+XLq5dPTtYatP7ww+ppxcVa+/ho/cADx5dXt/v41q/rzTdNXrduNXm0WrX+85+r5//hD2YaaH3JJVo7HPW3MX681v37m7wlJmrdr5/WFRVtm8+61q0zeZo40fz95Zfqed9/b6bVnP7EE+Z9QYF5//e/m/e5uQ1v37NdMPvfq5fWISHV095+u/k8/vOfZtlVq8z7iy7SumvXxo+Nw6H1rl0Nz0tL07q8vPk0v/3WpPnVV9XTevTQetas5tdtyMsvm+39/e9ajx2rdd++WrtctZeZO9cs89NPtdfZv//Y01uwQOt//7v2Mdqzxxw3z7H/wx+qP8e28NhjWp93Xu1tulxajxtXnebTT7ddelprfeutZrs//9y229VaA+t1S8rulizU2hcwFdhVWfD/uXLaY5haAcAyIAPYWPn6vLltntCgUENZ2WG9enUX/f333XRJyb7aM93u+hfmpk2mELRYtH7uObPMa6+ZQ757d+1lR4zQetKk2tMKCrT+5BOtb79d6zvuMIXX66/XLxzcbq2ff17rqCitP/+86Z146ilTUDdUgNd1001ah4VVX+jDh5sLRGutS0vNvN/+VusXXjD7dOGFWpeVVa+/f7+Z/sQT5v2CBeb9vHnNp308HntMa6XM8Qet//rX6nk336x1QIB5XX+9mTZrltYJCdXLfPaZWW/t2vrbPnLEbPuuu7T+9FMTJGfN0vrOO82xHTTIFI5NBb7iYq27dKn9ec+fb9L83/8aXmfmTBOANm6sPX3HDq3tdq3POqvxIObx9NMmjays6mmXXmpuaI7V5s3mpmfyZHN+vPee2faXX9Zebvp0U2h7zqGffjLLLVx4bOnt32/SA7Ov+/ZpfeiQ1j17ah0RofWaNVrffbf5bHr2NOfl9OlaX3CB1s8+27obJs9Nkefc9nym//63mfb66+ZzAa3/9a9j335Ddu2qvtGaMaNttllDhwgK3ni1V1DQWuvCwl/0d9+F6zVreuuysrTmVygoMBceaH3LLaZQCgmpf0f1+99rbbNpPXKkKbTPOMPUHkDrwECtQ0OrT1CbTeu//MUUwE6n1rfdZqaHhGjt61v7TrCmLVuqt/nii83nfeBAradOrX7/u99V5/3DD2sXYi+9ZN6ff74JGFpr/fjjZtqBA+a9y6X1gAFaDx5cf//rWrxY61//2lz8x+qMM7QeNcr8P2qU1mPGmP+Li7UODtb62mvNMfP1NYX8oEHmTt1j506T77feqr/tF1808zZvbjjtjz7S9WqCdf2//2eW+e676mmlpeYzvvba+st/8YVZXilzh+o5dm631ueeq3VQkDknhg41+9OYmTNNgVmTp5bUXEBJTjY1vagok57FonVMTHV6DocJdBdcUL1Ofr45d2+9tfZ+1q1xtsT06SaQP/ecOQeDgsy+hIRovX599XKrV2s9erTWp51mPtf+/auvvWOpoa5ebc6PSZNMgQ9a33OPCU6BgVpPmVJ9I+i5vp988vhrwTNnmv288UbzeW/bdnzbq0OCgpfk5/+oV60K0j/+OFA7HBnNr+ByaX3//dWF+sSJ9ZfZtMnccV5wgdbnnGMCw//9n2l68tzVl5SYAuvKK812Bg40d+6g9Z/+pPXRo+bC9fMzTQU1ud1an3221uHhWiclaR0XZwrJxmRn63p32W+8YaZt324uiu7da18Er7xi5k+dai7+fv3q7+u771ZfQI1xOs3dNpiCx9P00BLZ2abAevhh8/7xx83FdeSI1u+8Y7a5YoW5I1NK6/vuq990V15uCtnZs+tv/5xzqpvDGuJymfnDhjW8zH/+Y/Jw++315910kynsan4uhYXmOA8caJokawar99+vDvBff20Kq969TZNKQ/r0MYVrTUuXmm18803D62htap+BgSYfv/+9KRz//OfazXJam2OulEn/0CETpKxW02RX09Ch5ubBY9UqrS+7zNR6GuLJo6fGefCgOZeDg+tvuy63u/rau/TS6huWphw4YM67Pn3M+aS1+bzA1CiDgkwePBwOc1cPJmg31szXnPXrzTYefNA0WwcEaH311a3bViMkKHhRTs5yvXKln165MlDv2nW7Li7e2fxKc+eau4+HHjr+DCxZYi5Sq9UUFh6ZmeYOKSDAND15eAqQl14yd6hgmjsas3ixWaZmcNm6tfritFjMyVuXJzCMGGH+vvZa7fkuV3WV+/nnG07bEzieespchP7+pukpI8NcsNu3m/bWtWtNAX/0aPW6H3xg1l2zxrzfuLE6H+eeawpNz532xRebwh/MejUNGGDm15SR0fh+1/TWW2abixfXnv7ZZ2b9adMavqNcudKs98gj1c1wd91lCtrvvzf5PuMMraOjzXGIjTUB3rOttWtNU4q/vwlyeXnV287NrV2wehw9qhttF3e7zV2yxWJqsIcPN73faWkmwF58sbnpCA42BXpd111nCl232wTAXr1MHgICTJNMzWDqcGh9+ummgK7ZNOlZt6X+9S9zHEePNudMY0G9rMw0k4aGmvPMw+k0NVfQes6c+uu53eamIyzMHP+XX66/TGmpacr6xz/Msv/7X+1zd/JkrSMjqz+3e+4x13djQb4VJCh4WWHhZr1t27V6xQpfvXw5evv2G7Tb3UyzSFZWy9rzW6KoSOu9e+tPP3LE3Kl62iV37TIXac0CZOpUcwLn5DS87QceMCdkUVH1tIoKc6EHBuoG+0U8PIHBz692weRRXm7uWBtqxqqoMHfaQ4aYQjA93VzInlpWQ6+4uOq7s2uuMQWjZz/dbtOZOnKkWfbRR6vT8hTCYJrWapo+3RRGNXnu1Ddtani/a+5fjx5an3mmSb+iwgQIf3/TnFXzmNbkcmk9YYJJo0sX00+hlOk89UhONoV0dLSZt25d7W3s32/a08EUMH/4gwlCp52m63Uye5x2mikEr7nG3EisWWNqqX36mHUuvrjxPNflCfg9ejTexObpg0pLM+cZmD6Jc881/192mamVLlpk8tFQgG2N+fPNcfX0SzR0LO66y8xvqG+usNDkqammz7S06uBR82bN6TQPY9Q9dy0Wk5c77zTvn3229rbsdtPk3EYkKJwgDke63rXrLr18OfrAgb82v8KJ4HCYph+73RQeStVuhvn5Z/PR33+/uQP87DNTYN59t2l/9RSkdXku3PHjm05/4UJTM2oqfxddZLb1z39W37l5+irqPp313/+aO7TXXzcFyMcfm4Li449NO3e3biZIdelS/2kaT5+LUtX9G1qbNEeMMLWFug8JPPCAueutOf2880yzVks6LT3NRNOnmwIcTC0lPb3p9dxuc3c9dapZp2vX+oHV05RRM1jUtWGD1r/6lQnMgwaZfDz6aMNPKW3YYJopwsKqCysfH3Pn+tprx9ZOvnOn6XtqqlaxerWuqp3YbNVNJBUVpnboqb15XjX7e45XSYn5bLp3rz6GnmOyaJGZduedx5dGebn5/JQyfUxut+kj8HRI5+ebprJvvjGtBsOHVwfSus1bf/iDOR4zZmj9m9+YgPnuu63OmgSFE8jtduutW3+rly9X+ujRL5tf4UTZudOcoA01ecyaVfviU8p03MXGmir9Sy/VX2f2bF315MXxKiur7qS74grTKT94sGm6OZaCaNMmc1ccEWG2VTcYffWVmV736S6tTYHY0COkb7+tq/pPtDY1PKvVBNGWKCkxBU9IiNm3Dz80d5rHYs+e2m3XHgUFJpDm5ze/jWN56qa83DRpzJvXeA2yLRQWmnPNajWBKKNOv1xxsXnA4KefzNNMDdU2j5fDofW99+qqPr6NG805lJhYu5mqtYqLTU3R19cU5tB0s3FqasM3DIcOmZuz008318XAgeazbyUJCidYRUWR/umnofq778LrP7LaER06ZGoF//ynuXtrSRvtpk2mOeJYC7jGuFxa/+1vphodG2tOx9bcCf38s+lEh/oXV1mZuett7HHPhngenbz7btNE9+qr5n1ycsu3UVTUdk2Fp5oBA8zxbKjt/UR6553q2nRAQOOd3a2Rk2NucsA8gdXW3yNqhZYGBWWWPXkkJSXp9SdqdMdjVFq6lw0bkvD17UqvXo8TGXkBFou9vbPV8S1bZsaUiow04xD5+Bz7NrZvN0OSX3bZ8eentNSMneQZksHPz3yDdc+e6uFJROv9+c/m2C5eDJZ2Hmln3Tr43e/g3nvNOdiWMjPNt+uvvNKMEtvOlFIbtNZJzS4nQaFt5eT8jx07rqW8/Ag+PhHExMyiR4//w8+vZ3tnrWPLyzPjKEVGtndOqu3dC198YS7syy+H669v7xwJ0WoSFNqR211Bbu4yMjLmkpX1CQDdu/+JHj1m4+MT1M65E0J0Ri0NCq2op4vmWCw+REZOITJyCmVlKezbN5tDh54gPf114uJuJizsXEJCxgJucnO/ITt7EU5nDgMGzMVqDWzv7AshOjGpKZwg+flr2b//fvLyVgFuLBY/ANzuMqzWYFyuYmJiLmfAgPdR0m4thGhjUlPoYEJDx5KYuJyKinzy8laRl/ctABERF2X8gdAAABCJSURBVBAWNoGUlGfZv/8BQkLGEh9/VzvnVgjRWUlQOMF8fEKJirqIqKiLak3v0eM+Cgp+ZO/ePxEUNIKwsPGA6Z8oK9tLcfF2Skq243Y78PWNxdc3lqCgIfj7n9YeuyGEOEVJUOgglLIwYMBcNmwYzZYtlxIQ0BeHIxWH4wjQ8K+bKWVjwID3iYn5TYPzhRDiWElQ6EB8fEIZPPgTdu36PUrZCAubhN0eT0BAXwICBhIQ0B+LxQ+nM4vy8iPs3n0X27bNxO1+k9jYawAoKdlFZuY8wsImEhY2sZ33SAhxspGg0MEEBg5k+PCmf1rQbu+K3d6VYcOWsnnzxezYcS2lpbspKvqF7OxFgHl4ICbmSk477Rns9th623C7nVRU5ODr28UbuyGEOElJUDiJWa2BDBnyBdu2zeDgwb/i4xNJz54PEht7Penpb3Do0NNkZy8iOno6Pj7hWK0huFyFFBT8SFHRBtzuMqKiLqN37ycJCOjb3rsjhOgA5JHUU4Db7SQvbzmhoeOxWv2rppeU7Gbv3nspLFyPy5WPy1WEUnaCg0cQEjIWi8VOauq/0dpBXNwt2O3xlJcfxuE4jM0WQXDwKIKDRxEYOLDWcB3l5VkUFm6gpGQ7ISFjCQkZW/UYrctVRm7uUtxuB5GRF9XKj9aa8vIMfH27NPnYbVbWJ2RkvE1AwECCg5MIDh6J3R6PUu08JIIQJzH5RrOoR2sXWmssluoKosORzoEDj3DkyGuACx+fMHx94ygvT6eiIrdqOYslAB+fMADKyw/X2q7d3pPo6N9QXp5OdvZnuFxFAPj4hBETcyVhYRPJy1tBdvZiHI6D2O3xREZOIyrqEsLCzsZisVVtKzX1BfbsuRubLRqnMxtPJ7vF4o+fX2/8/fsQF3cTUVEXtni/nc5cfHxCUKrl48+4XMVYLAHynRFxypCgII6J05mHxeKL1RoAmLv60tK9FBauo7R0Ly5XPhUVebjd5QQFDSUoaCQBAX3Jzf2WzMx55OZ+jdUaQnT0dKKjL0cpH44ceZ2srAVo7cBiCSA8/DxCQ8+koGAtOTlLcbtL8fWNJTb2BuLibuTw4f+SkvI0UVGXMGDA+wAUFW2iqOhnSkv3UFq6l6Kin3E4DtGly9X06fM8NltEg/ujtSYvbyUpKc+Qk7OYwMBh9O37r1qd7+bcd9cKFg5HGvv3P0h6+lxCQs6gb98XCA4e2WAaxcVbyctbRUTEr/H3711rngkqfscUiFpLa01x8Raysxdhs0USG3udDMTYDtxuJ/v23U9p6R769ZuD3d6tvbNUS4cICkqpKcC/ACvwmtb6qTrz7cDbwEggG5iptT7Q1DYlKHRMLlcxSvnWuusHc5deUrKNoKCRWK1+NZYvISdnKenpb5CdvQRwA9C166307fufRgtTt7ucgwef4NChv2GzRdG1661YraGVw4NoHI7DlJenUVi4nqKijdhs0XTpciVZWQtxOFKIjp5BSMgY8vO/Jz9/NRUVBVXNaUr5kpb2b7SuoEuXK8nOXozTmUVc3I1VzWu+vjEUFW3i4MEnOHr046p8hYSMIzp6OmVlh8j//+3dfZBdZX3A8e/vvu/du3c32ZdwkyVZIggBJSBCTVGGAVuxKmKH1+LLIIzYSoudvoljbWWmrY6Otk6ZqoMvKaK1RZhS6mhbRESrkBCIhYUQDGQ3G/bFTXb3vt977vn1j/PsdbPZhE1w98Y9v89MJvec8+yZ5zznOfd3z/Oc8zzTP6RQ2Ek83k1Pz7vo67uazs43EYkkgOCOrVgcJJ/fRqGwE887gOflaTQKRCJxotEM0WiGdHoTfX3XkUqdfFg51OuT7iXIHzA5+R9UKi80t6VSAwwMfII1a64/alCq1w8wPf0IIgmy2S3E411HPLfF4iCp1PoFH0wI3qV5gVJpEM+borv7HUcM1q2g2qBcfh5Vj/b2sw7Z5vseMzP/Szp9+it66KJWm2Bw8Gqmpn6ASJJoNMOmTVvp7n7bMe2nXH6B6ekfkkoNkE6fQTze9yu7W215UJCgNj4H/BawD9gGXKeqg3PS/AFwtqp+UESuBd6lqtccbb8WFFaeSmWY0dGvEYt1sW7dLYu6CPL5J9m160YKhR3ztgjxeB+p1AC53A2sWfNeotE2Go0Sw8OfZmjoU/h+mVRqI52dbyQe7yGff4x8fju+X6G39yo2bvwkbW0b8bxpXnzxdkZGPo+q5/YfBRpEo530999Kb++VTE7+J2Njd1EqDRKJpMhmt9DZeSGl0m4mJx/A94tBziROJNKGah3fLwd7i2aIx3uIRjuIRjOoejQaBTxvhlptBBD3ePGl1OvjVCpDlMu7KZWCyygSSdHVdQk9PVfQ3f0OisWd7NnzUQqFHSST68lmt9DR8TrS6U143hS12n4qlWFmZn5MobCT2SfVQGhvP5tM5rXuDieO71fI5x+nWHyK2aCdTJ5MR8f5RCIp1/80QqUyhGq1eQYikRS9vVdz0kk3IBKlWh2mUhnC8w7i+yUajSK+X8b3K/h+hUajhOdNu7vRPCIxIpEEkUiKRGIt6fSraWt7NfH4KhqNkttHgXr9IJ53kEYjD0Tc3wU/SoKmUp9qdZhi8Sl8vwRAJnMea9d+kNWrL2N8/JuMjPwj1eoQInF6en6Xdet+n0zmXDzvIPX6Qer1cfe+0D48b4q2tlObj4eDj+dNU60OsWvXzdRqo5x++p1ks+fz9NPXUCzuJJe7mdWr30I6fQZtba9CteGOdcad+z4ikRil0nPs3fu3jI19nbnvJcViq1i16rfd+X0rsVjnoq6phZwIQWEL8Neq+ha3fBuAqv7dnDTfc2l+IiIxYBTo1aNkyoKCmcv3azQaRRqNIqAkEicddrcyV70+ie/XSCZz8/ZTp16fXPDx3XL5RYrFne4uZD+x2CpyuRsPuUBVlWp1iEQi17wjgNk7ou+6L6YyjUYZkQiZzLlksxfQ1nbaETvQy+WfMzb2DcbG7qJc3k002kkqtZ5UaoMLPBeRzZ5/WFORqjIx8W3Gx79BPr+DanXvIduj0SwdHefR1XUJXV0Xo1pnevoRpqcfoVTajWod1RoQJZM5h2z2AjKZzVQqe8nnt5HPb0fVJ5lcSyKxllRqA+n0mbS3bwKijI5+hbGxu5p9S7OCX9BpotF2IpE29y9FJNJGLNZJLNZJNNrhvtCr+H6FSmWYcnkX9fov5pWOEIt1EYutIhbLugli6qjWAXFlGiGR6KO9fTOZzGZ8v8T+/V9wQS7Q1XUxudxN5PPbGR39Gp43teC5gKBfazaYz5dM9nPWWfeRzb7enfcKe/b8GSMjd/DLwLvgXkkk1lCrjRGJJMjlbiaXez+12iil0rMUCk8yOfkA9foEInE2bPg4AwMfO8r+juxECApXApep6k1u+T3Ab6jqLXPSPOXS7HPLP3dpfjFvXx8APgCwfv368/buPbSSG7OSqSq+XzruEXTr9UlKpd3E490kErllGb7d8/Kun6mDZHI9qdTJr2gE4Hr9AI1GnkiknWg07e5mjv1pNFVlevrHTE09RE/P5WQym5vbGo0SExP3UquNEo+vIhZbTTzeQzLZTzK5FpEEtdp+isVBSqVdiMSawSxoflu1QDnMUCo9R6n0LJXKHiKRJNFo1g2CWaBWG6FaHSGRWEt//x8u2ISl2mBm5qdMTNxHV9dF9PRcfszHDSssKMxldwrGGHPsFhsUlvLB7xFgbg9Zv1u3YBrXfNRJ0OFsjDGmBZYyKGwDThORU0QkAVwL3D8vzf3A+9znK4HvH60/wRhjzNJasmEuVNUTkVuA7xE8svEVVX1aRG4Htqvq/cCXgbtE5HngAEHgMMYY0yJLOvaRqn4H+M68dR+f87kCXLWUeTDGGLN4NpiMMcaYJgsKxhhjmiwoGGOMabKgYIwxpunXbpRUEZkAjveV5h7giC/GhYSVgZUBWBmE8fg3qGrvyyX6tQsKr4SIbF/MG30rmZWBlQFYGYT9+I/Gmo+MMcY0WVAwxhjTFLag8KVWZ+AEYGVgZQBWBmE//iMKVZ+CMcaYowvbnYIxxpijCE1QEJHLRGSXiDwvIh9pdX6Wg4icLCIPicigiDwtIre69atF5L9FZLf7//DZQVYQEYmKyBMi8oBbPkVEHnV14VtuFN8VS0S6ROQeEXlWRJ4RkS0hrAN/7K6Bp0TkmyKSCls9WKxQBAU3X/QdwFuBM4HrROTM1uZqWXjAn6jqmcAbgA+54/4I8KCqngY86JZXsluBZ+Ysfwr4nKqeChwEbmxJrpbPPwDfVdUzgM0EZRGaOiAi64A/Al6vqq8hGLX5WsJXDxYlFEEBuAB4XlX3aDD57L8A72xxnpacqr6kqjvc5zzBl8E6gmPf6pJtBa5oTQ6Xnoj0A28D7nTLAlwC3OOSrPTj7wQuIhimHlWtqeoUIaoDTgxoc5N5pYGXCFE9OBZhCQrrgOE5y/vcutAQkQHgXOBRYI2qvuQ2jQKHTwy7cvw98OeA75a7gSlV9dzySq8LpwATwFddE9qdItJOiOqAqo4AnwGGCILBNPA44aoHixaWoBBqIpIBvg18WFVn5m5zM92tyEfQROTtwLiqPt7qvLRQDHgd8E+qei5QZF5T0UquAwCuv+SdBAFyLdAOXNbSTJ3AwhIUFjNf9IokInGCgHC3qt7rVo+JSM5tzwHjrcrfErsQuFxEXiRoMryEoH29yzUjwMqvC/uAfar6qFu+hyBIhKUOALwZeEFVJ1S1DtxLUDfCVA8WLSxBYTHzRa84rv38y8AzqvrZOZvmzo39PuDflztvy0FVb1PVflUdIDjn31fV64GHCOYEhxV8/ACqOgoMi8jpbtWlwCAhqQPOEPAGEUm7a2K2DEJTD45FaF5eE5HfIWhfnp0v+m9anKUlJyJvBB4B/o9ftql/lKBf4V+B9QQjzl6tqgdaksllIiIXA3+qqm8XkY0Edw6rgSeAd6tqtZX5W0oicg5BR3sC2APcQPCDMDR1QEQ+AVxD8ETeE8BNBH0IoakHixWaoGCMMeblhaX5yBhjzCJYUDDGGNNkQcEYY0yTBQVjjDFNFhSMMcY0WVAwZhmJyMWzo7UacyKyoGCMMabJgoIxCxCRd4vIYyLypIh80c3JUBCRz7lx+R8UkV6X9hwR+amI/ExE7pudm0BEThWR/xGRnSKyQ0Re5XafmTO/wd3uLVtjTggWFIyZR0Q2Ebz9eqGqngM0gOsJBlLbrqpnAQ8Df+X+5J+Bv1DVswneHp9dfzdwh6puBn6TYIROCEar/TDB3B4bCcbhMeaEEHv5JMaEzqXAecA29yO+jWDAOB/4lkvzdeBeN19Bl6o+7NZvBf5NRDqAdap6H4CqVgDc/h5T1X1u+UlgAPjR0h+WMS/PgoIxhxNgq6redshKkb+cl+54x4iZO75OA7sOzQnEmo+MOdyDwJUi0gfNOa03EFwvs6Nq/h7wI1WdBg6KyJvc+vcAD7uZ7vaJyBVuH0kRSS/rURhzHOwXijHzqOqgiHwM+C8RiQB14EMEE9Rc4LaNE/Q7QDDs8hfcl/7sKKQQBIgvisjtbh9XLeNhGHNcbJRUYxZJRAqqmml1PoxZStZ8ZIwxpsnuFIwxxjTZnYIxxpgmCwrGGGOaLCgYY4xpsqBgjDGmyYKCMcaYJgsKxhhjmv4f+Q0jgg6zWPwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.1541 - acc: 0.9630\n",
      "Loss: 0.1540566892566465 Accuracy: 0.9630322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_pool_2_DO_BN'\n",
    "\n",
    "for i in range(3, 14):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_88 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                4096016   \n",
      "=================================================================\n",
      "Total params: 4,138,256\n",
      "Trainable params: 4,137,872\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 2.6129 - acc: 0.3994\n",
      "Loss: 2.6129125837720197 Accuracy: 0.39937696\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,111,056\n",
      "Trainable params: 2,110,544\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 1.4578 - acc: 0.5961\n",
      "Loss: 1.4578398395302634 Accuracy: 0.596054\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,152,656\n",
      "Trainable params: 2,151,888\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 1.3127 - acc: 0.6222\n",
      "Loss: 1.3126934542710411 Accuracy: 0.62222224\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_100 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,211,216\n",
      "Trainable params: 1,210,192\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.8866 - acc: 0.7371\n",
      "Loss: 0.8865547987035749 Accuracy: 0.73707163\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_106 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 781,776\n",
      "Trainable params: 780,496\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.7324 - acc: 0.8218\n",
      "Loss: 0.7324441032060581 Accuracy: 0.82180685\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_120 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 608,336\n",
      "Trainable params: 606,800\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.4655 - acc: 0.8820\n",
      "Loss: 0.4654835937550506 Accuracy: 0.8820353\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_121 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_121 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_122 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_123 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_124 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_125 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_126 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_127 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_128 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_129 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                253968    \n",
      "=================================================================\n",
      "Total params: 771,408\n",
      "Trainable params: 769,360\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.3272 - acc: 0.9092\n",
      "Loss: 0.32718686868406655 Accuracy: 0.909242\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_10_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_130 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_130 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_131 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_132 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_133 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_134 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_135 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_136 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_137 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_138 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_139 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 973,392\n",
      "Trainable params: 970,832\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2416 - acc: 0.9497\n",
      "Loss: 0.2416394650371337 Accuracy: 0.9497404\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_11_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_140 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_140 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_141 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_142 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_143 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_144 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_145 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_146 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_126 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_147 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_127 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_148 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_128 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_149 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_129 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_150 ( (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_130 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                61456     \n",
      "=================================================================\n",
      "Total params: 1,236,816\n",
      "Trainable params: 1,233,744\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.1556 - acc: 0.9524\n",
      "Loss: 0.15557638902839965 Accuracy: 0.95244026\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_12_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_151 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_151 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_152 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_131 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_153 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_132 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_154 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_155 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_156 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_157 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_158 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_159 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_160 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_161 ( (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_162 ( (None, 15, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_141 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,533,008\n",
      "Trainable params: 1,529,424\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.1492 - acc: 0.9574\n",
      "Loss: 0.14923871945887648 Accuracy: 0.9574247\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_13_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_163 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_163 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_164 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_142 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_165 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_166 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_167 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_168 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_169 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_170 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_171 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_149 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_172 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_150 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_173 ( (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_151 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_174 ( (None, 15, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_152 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_175 ( (None, 7, 512)            2048      \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                24592     \n",
      "=================================================================\n",
      "Total params: 2,186,832\n",
      "Trainable params: 2,182,224\n",
      "Non-trainable params: 4,608\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.1541 - acc: 0.9630\n",
      "Loss: 0.1540566892566465 Accuracy: 0.9630322\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_pool_2_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 14):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_88 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_77 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_90 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_78 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 256000)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                4096016   \n",
      "=================================================================\n",
      "Total params: 4,138,256\n",
      "Trainable params: 4,137,872\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 3.8100 - acc: 0.5047\n",
      "Loss: 3.8099762235227526 Accuracy: 0.5046729\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_79 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_80 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_81 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,111,056\n",
      "Trainable params: 2,110,544\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 2.6194 - acc: 0.6199\n",
      "Loss: 2.619422897990495 Accuracy: 0.6199377\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_82 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_83 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_84 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_85 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 128000)            0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                2048016   \n",
      "=================================================================\n",
      "Total params: 2,152,656\n",
      "Trainable params: 2,151,888\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 1.9202 - acc: 0.7026\n",
      "Loss: 1.9202102008514563 Accuracy: 0.70259607\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_100 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_86 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_102 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_87 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_88 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_89 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_90 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                1024016   \n",
      "=================================================================\n",
      "Total params: 1,211,216\n",
      "Trainable params: 1,210,192\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 1.3422 - acc: 0.7610\n",
      "Loss: 1.342212540090765 Accuracy: 0.76095533\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_106 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_91 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_92 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_93 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_110 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_94 (MaxPooling (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_95 (MaxPooling (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_96 (MaxPooling (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                512016    \n",
      "=================================================================\n",
      "Total params: 781,776\n",
      "Trainable params: 780,496\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.9249 - acc: 0.8197\n",
      "Loss: 0.9248774629020493 Accuracy: 0.81973\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_97 (MaxPooling (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_98 (MaxPooling (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_99 (MaxPooling (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_100 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_101 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_102 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_120 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_120 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_103 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 16000)             0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                256016    \n",
      "=================================================================\n",
      "Total params: 608,336\n",
      "Trainable params: 606,800\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.5954 - acc: 0.8833\n",
      "Loss: 0.5954484297157974 Accuracy: 0.8832814\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_121 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_121 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_122 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_104 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_123 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_105 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_124 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_106 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_125 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_107 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_126 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_108 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_127 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_109 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_128 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_110 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_129 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_111 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 15872)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                253968    \n",
      "=================================================================\n",
      "Total params: 771,408\n",
      "Trainable params: 769,360\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 0.4588 - acc: 0.9107\n",
      "Loss: 0.45877491665853193 Accuracy: 0.91069573\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_10_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_130 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_130 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_131 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_112 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_132 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_132 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_113 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_133 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_114 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_134 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_115 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_135 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_116 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_136 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_117 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_137 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_118 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_138 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_119 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_139 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_120 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 7936)              0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                126992    \n",
      "=================================================================\n",
      "Total params: 973,392\n",
      "Trainable params: 970,832\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.2747 - acc: 0.9470\n",
      "Loss: 0.27471610594807755 Accuracy: 0.9470405\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_11_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_140 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_140 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_141 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_121 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_142 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_122 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_143 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_123 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_144 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_124 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_145 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_125 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_146 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_146 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_126 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_147 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_127 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_148 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_128 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_149 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_129 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_150 ( (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_130 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 3840)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                61456     \n",
      "=================================================================\n",
      "Total params: 1,236,816\n",
      "Trainable params: 1,233,744\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.2276 - acc: 0.9460\n",
      "Loss: 0.22758685567281822 Accuracy: 0.94600207\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_12_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_151 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_151 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_152 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_131 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_153 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_132 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_154 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_133 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_155 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_134 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_156 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_135 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_157 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_136 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_158 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_137 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_159 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_138 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_160 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_139 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_161 ( (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_140 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_162 (Conv1D)          (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_162 ( (None, 15, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_141 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,533,008\n",
      "Trainable params: 1,529,424\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.1597 - acc: 0.9626\n",
      "Loss: 0.159744357028038 Accuracy: 0.9626168\n",
      "\n",
      "1D_CNN_custom_pool_2_DO_BN_13_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_163 (Conv1D)          (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_163 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_164 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_142 (MaxPoolin (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 8000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_165 ( (None, 8000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 8000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_143 (MaxPoolin (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 4000, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_166 ( (None, 4000, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 4000, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_144 (MaxPoolin (None, 2000, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 2000, 128)         41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_167 ( (None, 2000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 2000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_145 (MaxPoolin (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1000, 128)         82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_168 ( (None, 1000, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 1000, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_146 (MaxPoolin (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 500, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_169 ( (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_147 (MaxPoolin (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 250, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_170 ( (None, 250, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 250, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_148 (MaxPoolin (None, 125, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 125, 256)          164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_171 ( (None, 125, 256)          1024      \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 125, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_149 (MaxPoolin (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 62, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_172 ( (None, 62, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 62, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_150 (MaxPoolin (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 31, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_173 ( (None, 31, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 31, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_151 (MaxPoolin (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 15, 256)           327936    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_174 ( (None, 15, 256)           1024      \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 15, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_152 (MaxPoolin (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_175 ( (None, 7, 512)            2048      \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_153 (MaxPoolin (None, 3, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                24592     \n",
      "=================================================================\n",
      "Total params: 2,186,832\n",
      "Trainable params: 2,182,224\n",
      "Non-trainable params: 4,608\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 12s 2ms/sample - loss: 0.1556 - acc: 0.9639\n",
      "Loss: 0.15560738798055296 Accuracy: 0.96386296\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 14):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
