{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, padding='same', \n",
    "                      kernel_initializer='he_uniform', input_shape=input_shape)) \n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same', kernel_initializer='he_uniform'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,400\n",
      "Trainable params: 16,384,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,481,936\n",
      "Trainable params: 5,481,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,136\n",
      "Trainable params: 1,861,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 668,240\n",
      "Trainable params: 668,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 506,576\n",
      "Trainable params: 506,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 318,288\n",
      "Trainable params: 318,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 310,224\n",
      "Trainable params: 310,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 363,600\n",
      "Trainable params: 363,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 521,552\n",
      "Trainable params: 521,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9296 - acc: 0.3972\n",
      "Epoch 00001: val_loss improved from inf to 1.52296, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_3_conv_checkpoint/001-1.5230.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 1.9296 - acc: 0.3972 - val_loss: 1.5230 - val_acc: 0.5351\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3306 - acc: 0.5909\n",
      "Epoch 00002: val_loss improved from 1.52296 to 1.36017, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_3_conv_checkpoint/002-1.3602.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.3306 - acc: 0.5909 - val_loss: 1.3602 - val_acc: 0.5765\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0709 - acc: 0.6735\n",
      "Epoch 00003: val_loss improved from 1.36017 to 1.35445, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_3_conv_checkpoint/003-1.3544.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.0709 - acc: 0.6735 - val_loss: 1.3544 - val_acc: 0.5814\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8752 - acc: 0.7350\n",
      "Epoch 00004: val_loss improved from 1.35445 to 1.31997, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_3_conv_checkpoint/004-1.3200.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.8752 - acc: 0.7350 - val_loss: 1.3200 - val_acc: 0.5875\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7232 - acc: 0.7801\n",
      "Epoch 00005: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.7231 - acc: 0.7801 - val_loss: 1.3376 - val_acc: 0.5938\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5882 - acc: 0.8210\n",
      "Epoch 00006: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.5883 - acc: 0.8210 - val_loss: 1.4470 - val_acc: 0.5744\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4944 - acc: 0.8516\n",
      "Epoch 00007: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.4944 - acc: 0.8516 - val_loss: 1.4757 - val_acc: 0.5835\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4119 - acc: 0.8776\n",
      "Epoch 00008: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.4120 - acc: 0.8775 - val_loss: 1.5022 - val_acc: 0.5786\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3500 - acc: 0.8983\n",
      "Epoch 00009: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.3500 - acc: 0.8983 - val_loss: 1.5782 - val_acc: 0.5779\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2985 - acc: 0.9153\n",
      "Epoch 00010: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.2985 - acc: 0.9153 - val_loss: 1.6037 - val_acc: 0.5933\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2552 - acc: 0.9273\n",
      "Epoch 00011: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2551 - acc: 0.9273 - val_loss: 1.6425 - val_acc: 0.5889\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9374\n",
      "Epoch 00012: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.2242 - acc: 0.9374 - val_loss: 1.7176 - val_acc: 0.5942\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9434\n",
      "Epoch 00013: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1995 - acc: 0.9434 - val_loss: 1.7519 - val_acc: 0.5898\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1827 - acc: 0.9500\n",
      "Epoch 00014: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1827 - acc: 0.9500 - val_loss: 1.8211 - val_acc: 0.5931\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1711 - acc: 0.9524\n",
      "Epoch 00015: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1711 - acc: 0.9524 - val_loss: 1.8465 - val_acc: 0.5884\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9580\n",
      "Epoch 00016: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1494 - acc: 0.9580 - val_loss: 1.9104 - val_acc: 0.5993\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1367 - acc: 0.9614\n",
      "Epoch 00017: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1367 - acc: 0.9614 - val_loss: 1.8883 - val_acc: 0.6105\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9628\n",
      "Epoch 00018: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.1331 - acc: 0.9628 - val_loss: 2.0082 - val_acc: 0.5854\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1223 - acc: 0.9663\n",
      "Epoch 00019: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1223 - acc: 0.9663 - val_loss: 1.9547 - val_acc: 0.6098\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1131 - acc: 0.9692\n",
      "Epoch 00020: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1131 - acc: 0.9692 - val_loss: 2.0068 - val_acc: 0.6073\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9706\n",
      "Epoch 00021: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1073 - acc: 0.9706 - val_loss: 2.0289 - val_acc: 0.5982\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9724\n",
      "Epoch 00022: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.1022 - acc: 0.9724 - val_loss: 2.0466 - val_acc: 0.6154\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0976 - acc: 0.9730\n",
      "Epoch 00023: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0976 - acc: 0.9730 - val_loss: 2.0747 - val_acc: 0.6066\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0993 - acc: 0.9719\n",
      "Epoch 00024: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0993 - acc: 0.9719 - val_loss: 2.0306 - val_acc: 0.6161\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9752\n",
      "Epoch 00025: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0921 - acc: 0.9752 - val_loss: 2.0724 - val_acc: 0.6152\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9769\n",
      "Epoch 00026: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0857 - acc: 0.9769 - val_loss: 2.0973 - val_acc: 0.6075\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9779\n",
      "Epoch 00027: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 0.0805 - acc: 0.9779 - val_loss: 2.1086 - val_acc: 0.6089\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9802\n",
      "Epoch 00028: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0753 - acc: 0.9802 - val_loss: 2.1273 - val_acc: 0.6105\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9798\n",
      "Epoch 00029: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0752 - acc: 0.9798 - val_loss: 2.1188 - val_acc: 0.6154\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9786\n",
      "Epoch 00030: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0771 - acc: 0.9786 - val_loss: 2.1200 - val_acc: 0.6147\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9816\n",
      "Epoch 00031: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0706 - acc: 0.9816 - val_loss: 2.2130 - val_acc: 0.6136\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9792\n",
      "Epoch 00032: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0752 - acc: 0.9792 - val_loss: 2.2352 - val_acc: 0.6094\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9814\n",
      "Epoch 00033: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0685 - acc: 0.9814 - val_loss: 2.2355 - val_acc: 0.6122\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9827\n",
      "Epoch 00034: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0657 - acc: 0.9827 - val_loss: 2.3093 - val_acc: 0.6073\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9822\n",
      "Epoch 00035: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0684 - acc: 0.9822 - val_loss: 2.2218 - val_acc: 0.6168\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9851\n",
      "Epoch 00036: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0575 - acc: 0.9851 - val_loss: 2.2091 - val_acc: 0.6173\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0606 - acc: 0.9839\n",
      "Epoch 00037: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0606 - acc: 0.9839 - val_loss: 2.2994 - val_acc: 0.6145\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9843\n",
      "Epoch 00038: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0591 - acc: 0.9843 - val_loss: 2.3351 - val_acc: 0.6045\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9845\n",
      "Epoch 00039: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0602 - acc: 0.9845 - val_loss: 2.3356 - val_acc: 0.6056\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9849\n",
      "Epoch 00040: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0593 - acc: 0.9849 - val_loss: 2.2965 - val_acc: 0.6233\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9847\n",
      "Epoch 00041: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0593 - acc: 0.9847 - val_loss: 2.2656 - val_acc: 0.6226\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0535 - acc: 0.9861\n",
      "Epoch 00042: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0535 - acc: 0.9861 - val_loss: 2.3961 - val_acc: 0.6177\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9870\n",
      "Epoch 00043: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0515 - acc: 0.9870 - val_loss: 2.2772 - val_acc: 0.6275\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9854\n",
      "Epoch 00044: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0544 - acc: 0.9854 - val_loss: 2.3469 - val_acc: 0.6226\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9864\n",
      "Epoch 00045: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0532 - acc: 0.9864 - val_loss: 2.3442 - val_acc: 0.6191\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9875\n",
      "Epoch 00046: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0502 - acc: 0.9874 - val_loss: 2.3582 - val_acc: 0.6254\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9874\n",
      "Epoch 00047: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0502 - acc: 0.9874 - val_loss: 2.3542 - val_acc: 0.6252\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9870\n",
      "Epoch 00048: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0524 - acc: 0.9870 - val_loss: 2.4150 - val_acc: 0.6210\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9871\n",
      "Epoch 00049: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0496 - acc: 0.9871 - val_loss: 2.3795 - val_acc: 0.6222\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9869\n",
      "Epoch 00050: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0512 - acc: 0.9869 - val_loss: 2.3284 - val_acc: 0.6171\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9870\n",
      "Epoch 00051: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0496 - acc: 0.9870 - val_loss: 2.3777 - val_acc: 0.6273\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9894\n",
      "Epoch 00052: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0435 - acc: 0.9894 - val_loss: 2.3835 - val_acc: 0.6287\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9891\n",
      "Epoch 00053: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0431 - acc: 0.9891 - val_loss: 2.3510 - val_acc: 0.6271\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9896\n",
      "Epoch 00054: val_loss did not improve from 1.31997\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 0.0421 - acc: 0.9896 - val_loss: 2.4301 - val_acc: 0.6336\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 530us/sample - loss: 1.4107 - acc: 0.5529\n",
      "Loss: 1.4106930673308091 Accuracy: 0.5528557\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9515 - acc: 0.3754\n",
      "Epoch 00001: val_loss improved from inf to 1.40711, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_4_conv_checkpoint/001-1.4071.hdf5\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 1.9516 - acc: 0.3754 - val_loss: 1.4071 - val_acc: 0.5709\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3392 - acc: 0.5805\n",
      "Epoch 00002: val_loss improved from 1.40711 to 1.22253, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_4_conv_checkpoint/002-1.2225.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 1.3393 - acc: 0.5805 - val_loss: 1.2225 - val_acc: 0.6215\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1282 - acc: 0.6502\n",
      "Epoch 00003: val_loss improved from 1.22253 to 1.13650, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_4_conv_checkpoint/003-1.1365.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 1.1282 - acc: 0.6502 - val_loss: 1.1365 - val_acc: 0.6406\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9735 - acc: 0.7015\n",
      "Epoch 00004: val_loss improved from 1.13650 to 1.00893, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_4_conv_checkpoint/004-1.0089.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.9735 - acc: 0.7015 - val_loss: 1.0089 - val_acc: 0.6907\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8484 - acc: 0.7423\n",
      "Epoch 00005: val_loss improved from 1.00893 to 0.98142, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_4_conv_checkpoint/005-0.9814.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.8484 - acc: 0.7423 - val_loss: 0.9814 - val_acc: 0.6997\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7410 - acc: 0.7747\n",
      "Epoch 00006: val_loss did not improve from 0.98142\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.7410 - acc: 0.7747 - val_loss: 0.9994 - val_acc: 0.6895\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6489 - acc: 0.7994\n",
      "Epoch 00007: val_loss improved from 0.98142 to 0.96347, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_4_conv_checkpoint/007-0.9635.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.6489 - acc: 0.7993 - val_loss: 0.9635 - val_acc: 0.7007\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5717 - acc: 0.8258\n",
      "Epoch 00008: val_loss improved from 0.96347 to 0.95018, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_4_conv_checkpoint/008-0.9502.hdf5\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.5717 - acc: 0.8258 - val_loss: 0.9502 - val_acc: 0.7133\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5018 - acc: 0.8455\n",
      "Epoch 00009: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.5018 - acc: 0.8455 - val_loss: 0.9808 - val_acc: 0.7121\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4478 - acc: 0.8609\n",
      "Epoch 00010: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.4480 - acc: 0.8609 - val_loss: 0.9707 - val_acc: 0.7142\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3987 - acc: 0.8765\n",
      "Epoch 00011: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.3987 - acc: 0.8765 - val_loss: 1.0107 - val_acc: 0.7163\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3586 - acc: 0.8877\n",
      "Epoch 00012: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.3586 - acc: 0.8877 - val_loss: 1.0499 - val_acc: 0.7065\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3237 - acc: 0.8977\n",
      "Epoch 00013: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.3237 - acc: 0.8977 - val_loss: 1.0176 - val_acc: 0.7268\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2911 - acc: 0.9079\n",
      "Epoch 00014: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2911 - acc: 0.9079 - val_loss: 1.0497 - val_acc: 0.7195\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2723 - acc: 0.9146\n",
      "Epoch 00015: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2722 - acc: 0.9146 - val_loss: 1.0465 - val_acc: 0.7202\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2433 - acc: 0.9238\n",
      "Epoch 00016: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2433 - acc: 0.9238 - val_loss: 1.0758 - val_acc: 0.7226\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2256 - acc: 0.9273\n",
      "Epoch 00017: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2256 - acc: 0.9273 - val_loss: 1.1098 - val_acc: 0.7158\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2069 - acc: 0.9349\n",
      "Epoch 00018: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2070 - acc: 0.9349 - val_loss: 1.1752 - val_acc: 0.7128\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9357\n",
      "Epoch 00019: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.2005 - acc: 0.9356 - val_loss: 1.1221 - val_acc: 0.7282\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1853 - acc: 0.9400\n",
      "Epoch 00020: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1853 - acc: 0.9400 - val_loss: 1.1390 - val_acc: 0.7216\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9448\n",
      "Epoch 00021: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1739 - acc: 0.9448 - val_loss: 1.2358 - val_acc: 0.7163\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9471\n",
      "Epoch 00022: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1669 - acc: 0.9470 - val_loss: 1.1860 - val_acc: 0.7338\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9508\n",
      "Epoch 00023: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1548 - acc: 0.9508 - val_loss: 1.1924 - val_acc: 0.7312\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9520\n",
      "Epoch 00024: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1500 - acc: 0.9520 - val_loss: 1.2450 - val_acc: 0.7254\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9541\n",
      "Epoch 00025: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1429 - acc: 0.9541 - val_loss: 1.2222 - val_acc: 0.7293\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9571\n",
      "Epoch 00026: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1380 - acc: 0.9571 - val_loss: 1.2256 - val_acc: 0.7345\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1373 - acc: 0.9582\n",
      "Epoch 00027: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1373 - acc: 0.9582 - val_loss: 1.2002 - val_acc: 0.7431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9587\n",
      "Epoch 00028: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1279 - acc: 0.9587 - val_loss: 1.2112 - val_acc: 0.7442\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9603\n",
      "Epoch 00029: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1221 - acc: 0.9603 - val_loss: 1.2601 - val_acc: 0.7298\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9627\n",
      "Epoch 00030: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1160 - acc: 0.9626 - val_loss: 1.2444 - val_acc: 0.7421\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9624\n",
      "Epoch 00031: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1181 - acc: 0.9624 - val_loss: 1.2961 - val_acc: 0.7312\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1121 - acc: 0.9651\n",
      "Epoch 00032: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1121 - acc: 0.9651 - val_loss: 1.2895 - val_acc: 0.7354\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9670\n",
      "Epoch 00033: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1086 - acc: 0.9670 - val_loss: 1.3026 - val_acc: 0.7391\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9669\n",
      "Epoch 00034: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1061 - acc: 0.9669 - val_loss: 1.2816 - val_acc: 0.7414\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9669\n",
      "Epoch 00035: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1058 - acc: 0.9669 - val_loss: 1.3168 - val_acc: 0.7358\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9676\n",
      "Epoch 00036: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.1011 - acc: 0.9676 - val_loss: 1.3017 - val_acc: 0.7433\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0956 - acc: 0.9698\n",
      "Epoch 00037: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0956 - acc: 0.9698 - val_loss: 1.2728 - val_acc: 0.7524\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9692\n",
      "Epoch 00038: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0981 - acc: 0.9692 - val_loss: 1.3327 - val_acc: 0.7410\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9698\n",
      "Epoch 00039: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0966 - acc: 0.9698 - val_loss: 1.3009 - val_acc: 0.7438\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9715\n",
      "Epoch 00040: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0912 - acc: 0.9715 - val_loss: 1.3506 - val_acc: 0.7419\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9733\n",
      "Epoch 00041: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0888 - acc: 0.9733 - val_loss: 1.3468 - val_acc: 0.7440\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0846 - acc: 0.9739\n",
      "Epoch 00042: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0846 - acc: 0.9739 - val_loss: 1.3382 - val_acc: 0.7419\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9726\n",
      "Epoch 00043: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0871 - acc: 0.9726 - val_loss: 1.2916 - val_acc: 0.7484\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9728\n",
      "Epoch 00044: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0877 - acc: 0.9727 - val_loss: 1.3376 - val_acc: 0.7463\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9729\n",
      "Epoch 00045: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0886 - acc: 0.9729 - val_loss: 1.3824 - val_acc: 0.7412\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9736\n",
      "Epoch 00046: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0832 - acc: 0.9736 - val_loss: 1.3411 - val_acc: 0.7452\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9762\n",
      "Epoch 00047: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0783 - acc: 0.9763 - val_loss: 1.3707 - val_acc: 0.7494\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9757\n",
      "Epoch 00048: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0809 - acc: 0.9757 - val_loss: 1.3282 - val_acc: 0.7519\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9751\n",
      "Epoch 00049: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0829 - acc: 0.9751 - val_loss: 1.3689 - val_acc: 0.7473\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9758\n",
      "Epoch 00050: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0784 - acc: 0.9758 - val_loss: 1.3321 - val_acc: 0.7498\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9769\n",
      "Epoch 00051: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0768 - acc: 0.9769 - val_loss: 1.3826 - val_acc: 0.7468\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9767\n",
      "Epoch 00052: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0745 - acc: 0.9767 - val_loss: 1.3990 - val_acc: 0.7545\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9779\n",
      "Epoch 00053: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0740 - acc: 0.9779 - val_loss: 1.3933 - val_acc: 0.7449\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9774\n",
      "Epoch 00054: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0727 - acc: 0.9774 - val_loss: 1.4346 - val_acc: 0.7449\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9784\n",
      "Epoch 00055: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0707 - acc: 0.9784 - val_loss: 1.3611 - val_acc: 0.7538\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9781\n",
      "Epoch 00056: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0718 - acc: 0.9781 - val_loss: 1.4041 - val_acc: 0.7533\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9758\n",
      "Epoch 00057: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0770 - acc: 0.9758 - val_loss: 1.3678 - val_acc: 0.7575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9786\n",
      "Epoch 00058: val_loss did not improve from 0.95018\n",
      "36805/36805 [==============================] - 48s 1ms/sample - loss: 0.0707 - acc: 0.9786 - val_loss: 1.3714 - val_acc: 0.7591\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd4lGW6+PHvM5PJpIcQAgmhJEivAUJRFHBdEXXFLmtZu6y7luNxjz/R9airu2dtu/ayqFj2qOiinBXFLgELKEWqlNBJgFTS+8z9++NJhSQkIcMEcn+u670m89Z7QnjveZ9qRASllFLqSBz+DkAppdTxQROGUkqpFtGEoZRSqkU0YSillGoRTRhKKaVaRBOGUkqpFtGEoZRSqkU0YSillGoRTRhKKaVaJMDfAbSnbt26SUJCgr/DUEqp48aqVauyRSSmJfv6LGEYY3oDbwI9AAHmiMjTh+xjgKeBc4AS4FoRWV297Rrgvupd/ywibxzpmgkJCaxcubL9PoRSSp3gjDG7W7qvL58wqoA/iMhqY0w4sMoY84WI/Fxvn7OBAdXLBOBFYIIxpivwAJCMTTarjDEfishBH8arlFKqGT6rwxCR/TVPCyJSCGwC4g/Z7XzgTbGWA12MMXHAWcAXIpJbnSS+AKb7KlallFJHdkwqvY0xCcBo4IdDNsUDe+u9T6te19R6pZRSfuLzSm9jTBjwPnCHiBT44PyzgFkAffr0OWx7ZWUlaWlplJWVtfelO4WgoCB69eqFy+XydyhKKT/zacIwxriwyeItEfmgkV3Sgd713veqXpcOTD1kfUpj1xCROcAcgOTk5MMm90hLSyM8PJyEhARsHbtqKREhJyeHtLQ0EhMT/R2OUsrPfFYkVd0C6lVgk4j8vYndPgSuNtZEIF9E9gOfAdOMMVHGmChgWvW6VisrKyM6OlqTRRsYY4iOjtanM6UU4NsnjEnAb4D1xpg11evuBfoAiMhLwCJsk9pt2Ga111VvyzXGPAysqD7uIRHJbWsgmizaTn93SqkaPksYIvIt0OzdRuz8sLc0sW0uMNcHoR16HSoq9uN0hhIQEOnryyml1HGr0w8NYoyhoiKDqqp8n5w/Ly+PF154oU3HnnPOOeTl5bV4/wcffJAnnniiTddSSqkj6fQJA8CYAESqfHLu5hJGVVXz11y0aBFdunTxRVhKKdVqmjCoSRiVPjn37Nmz2b59O0lJSdx1112kpKRw2mmnMWPGDIYOHQrABRdcwNixYxk2bBhz5sypPTYhIYHs7Gx27drFkCFDuOmmmxg2bBjTpk2jtLS02euuWbOGiRMnMnLkSC688EIOHrSd5J955hmGDh3KyJEj+fWvfw3AkiVLSEpKIikpidGjR1NYWOiT34VS6vh2Qg0+eCSpqXdQVLTmsPVebyngxeEIbfU5w8KSGDDgqSa3P/LII2zYsIE1a+x1U1JSWL16NRs2bKhtqjp37ly6du1KaWkp48aN4+KLLyY6OvqQ2FN55513ePnll7nssst4//33ueqqq5q87tVXX82zzz7LlClTuP/++/nTn/7EU089xSOPPMLOnTtxu921xV1PPPEEzz//PJMmTaKoqIigoKBW/x6UUic+fcIAwGDr34+N8ePHN+jX8MwzzzBq1CgmTpzI3r17SU1NPeyYxMREkpKSABg7diy7du1q8vz5+fnk5eUxZcoUAK655hqWLl0KwMiRI7nyyiv53//9XwIC7PeFSZMmceedd/LMM8+Ql5dXu14pperrVHeGpp4EysvTqKjIICxszDFpRhoaWvckk5KSwpdffsmyZcsICQlh6tSpjfZ7cLvdtT87nc4jFkk15eOPP2bp0qUsXLiQv/zlL6xfv57Zs2dz7rnnsmjRIiZNmsRnn33G4MGD23R+pdSJS58wANshXRDxtPu5w8PDm60TyM/PJyoqipCQEDZv3szy5cuP+pqRkZFERUXxzTffAPDPf/6TKVOm4PV62bt3L6effjqPPvoo+fn5FBUVsX37dkaMGMHdd9/NuHHj2Lx581HHoJQ68XSqJ4ymGGN/DbalVPv+SqKjo5k0aRLDhw/n7LPP5txzz22wffr06bz00ksMGTKEQYMGMXHixHa57htvvMHNN99MSUkJ/fr147XXXsPj8XDVVVeRn5+PiHD77bfTpUsX/vu//5vFixfjcDgYNmwYZ599drvEoJQ6sZhjWXbva8nJyXLoBEqbNm1iyJAhzR5XVZVPaWkqwcGDCQgI82WIx6WW/A6VUscnY8wqEUluyb5aJEX9JwzfNK1VSqkTgSYMauow8FnnPaWUOhFowuDQOgyllFKN0YQBGOMAHFokpZRSzdCEUc0Ylz5hKKVUMzRhVPPlAIRKKXUi0IRRzZcDELZWWFjjTXubWq+UUseCJoxqWiSllFLN04RRraZIqr07Ms6ePZvnn3++9n3NJEdFRUWcccYZjBkzhhEjRvDvf/+7xecUEe666y6GDx/OiBEjePfddwHYv38/kydPJikpieHDh/PNN9/g8Xi49tpra/d98skn2/XzKaU6D58NDWKMmQv8CsgUkeGNbL8LuLJeHEOAmOr5vHcBhYAHqGppL8QjuuMOWHP48OYAgVJBgLccnGEcYWbZhpKS4KmmhzefOXMmd9xxB7fcYmeife+99/jss88ICgpiwYIFREREkJ2dzcSJE5kxY0aLBj/84IMPWLNmDWvXriU7O5tx48YxefJk3n77bc466yz++Mc/4vF4KCkpYc2aNaSnp7NhwwaAVs3gp5RS9flyLKnXgeeANxvbKCKPA48DGGPOA/5TRHLr7XK6iGT7ML5DmJrAoB1HrB09ejSZmZns27ePrKwsoqKi6N27N5WVldx7770sXboUh8NBeno6GRkZxMbGHvGc3377LZdffjlOp5MePXowZcoUVqxYwbhx47j++uuprKzkggsuICkpiX79+rFjxw5uu+02zj33XKZNm9Zun00p1bn4LGGIyFJjTEILd78ceMdXsdRq5knA68PxpC699FLmz5/PgQMHmDlzJgBvvfUWWVlZrFq1CpfLRUJCQqPDmrfG5MmTWbp0KR9//DHXXnstd955J1dffTVr167ls88+46WXXuK9995j7ty57fGxlFKdjN/rMIwxIcB04P16qwX43Bizyhgz6wjHzzLGrDTGrMzKyjqKOHzX23vmzJnMmzeP+fPnc+mllwJ2WPPu3bvjcrlYvHgxu3fvbvH5TjvtNN599108Hg9ZWVksXbqU8ePHs3v3bnr06MFNN93EjTfeyOrVq8nOzsbr9XLxxRfz5z//mdWrV7f751NKdQ4dYXjz84DvDimOOlVE0o0x3YEvjDGbRWRpYweLyBxgDtjRatsaRN14Uu3ftHbYsGEUFhYSHx9PXFwcAFdeeSXnnXceI0aMIDk5uVUTFl144YUsW7aMUaNGYYzhscceIzY2ljfeeIPHH38cl8tFWFgYb775Junp6Vx33XV4vV4A/vrXv7b751NKdQ4+Hd68ukjqo8YqvevtswD4l4i83cT2B4EiEXniSNdr6/DmACJeiopWExgYj9sdd8T9OxMd3lypE9dxM7y5MSYSmAL8u966UGNMeM3PwDRgg+9jqRlPSvtiKKVUY3zZrPYdYCrQzRiTBjwAuABE5KXq3S4EPheR4nqH9gAWVDcvDQDeFpFPfRVnw5hdHaa3t1JKdTS+bCV1eQv2eR3b/Lb+uh3AKN9E1TwdT0oppZrm91ZSHYkmDKWUapomjHq0SEoppZqmCaMeX40npZRSJwJNGPU4HAHYPoOedjtnXl4eL7zwQpuOPeecc3TsJ6VUh6EJo56a3t5eb/vVYzSXMKqqmr/OokWL6NKlS7vFopRSR0MTRj11vb3bL2HMnj2b7du3k5SUxF133UVKSgqnnXYaM2bMYOjQoQBccMEFjB07lmHDhjFnzpzaYxMSEsjOzmbXrl0MGTKEm266iWHDhjFt2jRKS0sPu9bChQuZMGECo0eP5pe//CUZGRkAFBUVcd111zFixAhGjhzJ++/bUVg+/fRTxowZw6hRozjjjDPa7TMrpU5MHWFokGOmmdHNARAJw+sdhMMR1OIBa48wujmPPPIIGzZsYE31hVNSUli9ejUbNmwgMTERgLlz59K1a1dKS0sZN24cF198MdHR0Q3Ok5qayjvvvMPLL7/MZZddxvvvv89VV13VYJ9TTz2V5cuXY4zhlVde4bHHHuNvf/sbDz/8MJGRkaxfvx6AgwcPkpWVxU033cTSpUtJTEwkNzcXpZRqTqdKGEdSNxeF16fXGT9+fG2yAHjmmWdYsGABAHv37iU1NfWwhJGYmEhSUhIAY8eOZdeuXYedNy0tjZkzZ7J//34qKipqr/Hll18yb9682v2ioqJYuHAhkydPrt2na9eu7foZlVInnk6VMJp7EgA7FUZR0RafjycVGhpa+3NKSgpffvkly5YtIyQkhKlTpzY6zLnb7a792el0Nlokddttt3HnnXcyY8YMUlJSePDBB30Sv1Kqc9I6jHp8MZ5UeHg4hYWFTW7Pz88nKiqKkJAQNm/ezPLly9t8rfz8fOLj4wF44403atefeeaZDaaJPXjwIBMnTmTp0qXs3LkTQIuklFJHpAnjELYvRvt13ouOjmbSpEkMHz6cu+6667Dt06dPp6qqiiFDhjB79mwmTpzY5ms9+OCDXHrppYwdO5Zu3brVrr/vvvs4ePAgw4cPZ9SoUSxevJiYmBjmzJnDRRddxKhRo2ondlJKqab4dHjzY+1ohjevUVy8CWOchIQMbO/wjls6vLlSJ67jZnjzjkjHk1JKqcZpwjiEJgyllGqcJoxD1AxAeCIV1SmlVHvQhHEIOzyI4Ou+GEopdbzRhHEIOwAhOsy5UkodwmcJwxgz1xiTaYxpdD5uY8xUY0y+MWZN9XJ/vW3TjTFbjDHbjDGzfRVj43HZ8aTacwBCpZQ6EfjyCeN1YPoR9vlGRJKql4cAjDFO4HngbGAocLkxZqgP42ygZsRaf1Z8h4WF+e3aSinVFJ8lDBFZCrSl+/B4YJuI7BCRCmAecH67BteMjpAwlFKqI/J3HcbJxpi1xphPjDHDqtfFA3vr7ZNWve6YqEsY7VOHMXv27AbDcjz44IM88cQTFBUVccYZZzBmzBhGjBjBv//97yOeq6lh0BsbprypIc2VUqqt/Dn44Gqgr4gUGWPOAf4PGNDakxhjZgGzAPr06dPsvnd8egdrDjQzvnk1j6cIY1w4HO4j7psUm8RT05se1XDmzJnccccd3HLLLQC89957fPbZZwQFBbFgwQIiIiLIzs5m4sSJzJgxo96IuYdrbBh0r9fb6DDljQ1prpRSR8NvCUNECur9vMgY84IxphuQDvSut2uv6nVNnWcOMAfs0CDtE53BNq09eqNHjyYzM5N9+/aRlZVFVFQUvXv3prKyknvvvZelS5ficDhIT08nIyOD2NjYJs/V2DDoWVlZjQ5T3tiQ5kopdTT8ljCMMbFAhoiIMWY8tngsB8gDBhhjErGJ4tfAFe1xzeaeBOpr7/GkLr30UubPn8+BAwdqB/l76623yMrKYtWqVbhcLhISEhod1rxGS4dBV0opX/Fls9p3gGXAIGNMmjHmBmPMzcaYm6t3uQTYYIxZCzwD/FqsKuBW4DNgE/CeiGz0VZyNx96+w4PMnDmTefPmMX/+fC699FLADkXevXt3XC4XixcvZvfu3c2eo6lh0JsapryxIc2VUupo+OwJQ0QuP8L254Dnmti2CFjki7hawpgAvN7DJyhqq2HDhlFYWEh8fDxxcXZipiuvvJLzzjuPESNGkJyczODBg5s9x/Tp03nppZcYMmQIgwYNqh0Gvf4w5V6vl+7du/PFF19w3333ccsttzB8+HCcTicPPPAAF110Ubt9JqVU56PDmzeirGwvlZWZhIWNabYSurPQ4c2VaicHD0JEBDid/o6klg5vfpRsb28dT0op1Y7mzYP4ePjNb/wdSZtpwmiEdt5TSrUbjwfuuQcuvxyiouCdd+xyHOoUCaPZYjcRKCyE0ro6Cx2AsM6JVGSp1DGXnw8zZsAjj8BvfwvbtsHEifD730Namr+ja7UTPmEEBQWRk5PT9I1PBFJTISurdpUOQGiJCDk5OQQFBfk7FKU6pooK+OwzmDMHFi2C9eshL8/eV7ZuhQkT4PPP4cUX4aWXIDgY/vlPe9z114O3iWLv116D3r3h+eftuToIf/b0PiZ69epFWloaWfUSwmEKCyE3F4qLAVsUVV6ejcslOJ2deyDAoKAgevXq5e8wlOo4SkttkvjgA/jwQ/sUcaiwMFsUFRoKX30FkyfXbevfH/72N/jd7+CFF+DWW+u2eb22+Oqxx6B7d7vt009h7lyIifH9ZzsSETlhlrFjx0qbPPOMCIhs3247glQVyeLFyO7dj7btfEqp9ldYKPKf/ymyaJF/rl9aKnLDDSKhofZ+ERUlcs01Ih9+KLJrl8h334nMmyfy+OMit98uMmuWXd8Yr1fk7LNFgoNFNm2y64qKRC680J775ptFystFnnpKJDBQpEcPkU8/9cnHAlZKC++xfr/Jt+fS5oSxebP9Vbz4Yu2qJUuCJTX1D207n1Kqfe3fLzJmjP1/aozIX/5ib7pN2bdP5LXXRMrKjnzu7GyRnTub36ekRGTaNHvtG28U+fxzkYqK1nyCxmPs2lUkOdkmljFjRBwOmyTqf7a1a0WGDbOf/Y47RH74QeSTT0TeflvkuedEHnpI5M9/bnMYmjBay+sV6dvXZvdq33/fR37++eq2nU8p1X42bRJJSBAJCRGZP1/kiivsreuyy+y38vrKykQefVQkLMzuc+qpIpmZTZ/7229FYmPtt/hDb9Q1SkpEzjzTJou5c9v3s/3rXzZOt9vG/NFHje9XUiJy661238aWPn3aHIImjLa46SaRiIjabw0rVoyVtWvPbvv5lOosdu8WWbBAZMkSkfXr7Tfn8vL2Ofc339iin+7dRVassOu8XpHHHrM38KQk++3c6xVZuFCkf397W5sxQ+TZZ0WCgmyy2bDh8HO/9JKIy2WPOecce9w554hkZNTtU1ws8stf2mu99lr7fKZD3XSTSL9+9kniSH780SaV776ziTQj46h/15ow2qIm03/7rYiIrF17tqxcmdz28ynVGfz4o0iXLtLot94uXUQmTrRFOE8+KfLFF7ZoqaX+9S/7zXvgwNr6xQY++UQkMlKkWzd7UweRwYMblvX/8IN9gggPr6v7KCuzN2mw9Qi5uTbhPPusvV5srC1yKi4WOeMMmyxef/3ofk/N8XqbL17zMU0YbZGba8sP779fREQ2bbpWvvsutu3nU+p4lp1tv1GXlDS9z7Jl9qk8IUEkJUXkyy9F3n1X5IUXRB5+WOT3vxeZOlUkOrphIvnd70Sqqpq//tNP2xv1pEk2lqZs2WKTRGSkTUqN1Svs3SsyerT9//3wwyInn2zjuOeew+NYu1Zk6FC7feBAG8MbbzQf63FOE0ZbTZwoMmGCiIjs3fusLF6MlJbuOrpzKnW8KSmx/w/AFpV8/vnh+3z7rf3WftJJInv2NH8+r1fkwAGRr74SueUWe95LLmm8QtrrFZk92+5z4YXNJ6waZWUiBQXN71NUJHLRRfa8oaH26aUpxcUiv/2tLa56880jX/84pwmjrR54wH4LycmRwsI1sngxsn//if8Ho04wXq8tQjn7bPuN+qefWl7k4fGIzJxpbw1/+pPIgAH25yuvrCvbT0mxN92BA0XS0lof39//bs/5i180vNFXVopcd53UNis90lNIa3k89qlp48aW7d+SFlYnAE0YbfXdd/ZX8t574vVWyTffdJHNm286unMq1V7y8+3NOje36X0yM0UuuMD+HcfH2yKVmp9nzbJ9BpprDvrf/233f+QR+7601K5zuWzl8x//aPsODBnSuvqIQ735pojTKTJ2rE1ExcUi555rr/3gg34t0+9sNGG0VWWlLQu98UYREVm37leyfPmgozunUkfy1lsi//Eftlnnv/9tWxoVFdmb9Vdf2Zv0xIn2Bgv2hn3DDSKrVjU8z8KFtjVRYKDtPFZVZYuCXntN5OKL65qaDhpkW9ocelP+5z/t9uuvP3zbzz+LnHaa3T5iRMOWRG310Uf2swwcaD+fw9GgL5Q6NjRhHI2LLhLp3VvE65Xdux+VxYuR8vIDR39epRpTUzwTGCiHtTKqSRBOp62o/eMfbfPVWbNsnwSwdQ2vvWa/5IDIqFEi69Y1fq3ycpEPPrA3aLAd0Wqam37zjY1h6tSmm2l6PLYFUnNPOK317be2NZXbLfL+++13XtViHSJhAHOBTGBDE9uvBNYB64HvgVH1tu2qXr+mNR+mXRLGP/5hfy2bNkle3jJZvBjJzJx/9OdV6lDPPiu1FcAVFbY46YcfRN55R+R//se24vnoI1sUdai8PNuSaNAgqe39fPfdLSt3rxlyoksX+63+xhtt09QBA0Ryctr/cx7Jrl32CUb5RUdJGJOBMc0kjFOAqOqfzwZ+qLdtF9Cttddsl4Sxc6f9tTz1lHg85bJkSbBs3Xr70Z9XqfpefNH+nV1wwdENMeH1iixdKrJmTeuPzc62vYedTjtExdatbY9DHbdakzB8Nry5iCwFcpvZ/r2IHKx+uxzoGEOiJiTAwIHw+ec4HIFERJxMfv5Sf0eljjfvvANnnAEPPACrVzccovqVV+xIpeedB+++Cy5X269jDJx2Gowa1fpjo6Ph2Wdh82ZYsQIGDGh7HKpT6CjzYdwAfFLvvQCfG2NWGWNmHfNopk2DlBQoL6dLl8kUFa2lqqqRIYzV8WfTJigv9+015syBK6+ELVvgz3+GsWOhb187VPXDD8OsWXD22fCvf0FgoG9jaYn+/aFfP39HoY4Dfk8YxpjTsQnj7nqrTxWRMdiiqluMMZMbPdgeP8sYs9IYs7LZOS9a46yzoKQEvvuOyMjTACE//7v2Obc6Ops2QVUbJ7Z68kkYOhQSE+Gvf7VzoLS3p5+2M6udfbadmOvAATsZztixdk6D+++HX/7SzqXgdrf/9ZXyIb8mDGPMSOAV4HwRyalZLyLp1a+ZwAJgfFPnEJE5IpIsIskx7TXByNSptpjgs8+IiJiIMQHk53/TPudWbffpp/aGP3OmnbGsNV58Ee68E845B0aMgHvvtTOa3XYbbN9et19ZGezfDz//DDt2tO4ajzwCd9wBF10ECxbY2dViYuDaa+37nBz75Prhh6CzGKrjUUsrO9qyAAk0XendB9gGnHLI+lAgvN7P3wPTW3K9dqn0rjF1qu2c5PHIqlUny6pVp7TfuVXreTx2PKDISKkdjbSlPXFffdUec955dU1G160TufZa2yHNGJGePW2fgEObtp53nsjKlc2f3+ut6/B2xRW2P49SxwlaUentsylajTHvAFOBbsaYNOABwFWdpF4C7geigReMMQBVIpIM9AAWVK8LAN4WkU99FWeTbrgBfvMbeOMNIiefRlrak3g8pTidwcc8FAW8/z789BO8+SYUFNj6gIsusuub+7b+9ttw4422Xuq99+rqDEaMsEVF//M/dq7l9HSIimq4bN0KTz0Fycm2gvqBB2zREthisY0b4Ycf6qbrvP56W3/hdPr+96GUP7Q0sxwPS7s+YXi9IqecItK9u+TseFcWL0Zycxe33/lVy1VW2v4Gw4bVjS9U019m2rSmB6ibP982GZ061Q490RZ5eXY8pqiouutNnlzXcQ7saKx3322fgpQ6ztARnjCOe8bYJofJyUQ+lQIXGvLzlxIVNdXfkXU+b75pWxwtWFD37X3WLFvPdMMN8KtfwfPP26eEXbvssnOnbbI6YQIsXAghIW27dmQk3Hefret49ln7BBEXZ687YQJMnGhbGNknYqVOaEbqtw8/ziUnJ8vKlSvb96Q33wyvvMKG/z2JqsG9SUr6sn3Pr5pXXm77B8TFwfLlh9+Y//lPW6ns9datczpthfa4cfDyy/amr5RqlDFmldjqgCPye7PaDu8vf4HISPo9XUJB/vd4vZX+juj4tXGjrQNYuLDlx7z0Euzda+saGvsW/5vfwNKl8Oqr8PXX9smitNS+vveeJgul2pE+YbTEiy/C73/Pxgeg953LiYiY0P7XONEVFNhv/Fu32ornhQttRXRziopscc+IEfDVV8cmTqU6GX3CaG+zZuEdNZyTXoT8fXrjajURuO4629/h//4PhgyBCy6Ab47Qt+WppyAryz7lKaX8ThNGSzidOJ57kaBMcD/5ur+jOf787W+22emjj8L558Pnn9uhMs49F378sfFjcnPh8cft/hMnHtt4lVKN0oTRUqeeSv55J9Ht9VRk9y5/R3P8WLIEZs+GSy6xPa0BuneHL7+0vaCnT4d16+x6j8fWR9x2GwwbBoWFduwlpVSHoAmjFcrvvwVTBRXPaRFJi+zbZ4fx6N/fjqNUv9I6Pt7WS4SG2rGVbrnFtmyaMsWO5nrKKbBoka2/UEp1CFrp3Qrl5QcoPD2OLtvDCEjLPbphqU90lZVw+umwZo0tdho6tPH9tm6FyZMhP98O2HfZZbZfRVjYsY1XqU6qNZXe2nGvFdzuWNIuG0a3/9wIH39sK27V4dLT7XAc331n54VoKlmAnXtkyxbbd0KThFIdmhZJtZL7ghsp7wZVL/7d36F0PCLwxhu2/mHJEtv7+te/PvJxkZGaLJQ6DmjCaKWYuMvYfw44v/gWdu/2dzgdx759doC+a6+19Q7r1sHvf+/vqJRS7UgTRiu53T0pvCwZENu7uLPzeuH11+1Txddf20mKliyxFd1KqRNKixKGMeY/jDERxnrVGLPaGHOEbronri4jryR3PHhf+UfbZ387ESxfDiefbDvlDRsGa9faCYQc+j1EqRNRS/9nXy8iBcA0IAr4DfCIz6Lq4GJiLmLfr8CxP9M2/exs0tPtGE4nn2zHeXrjDdt/YsAAf0emlPKhlraSqmlAfw7wTxHZaEznHc85KKgPFWeOp+LpnwicMwdmzPB3SC2zZo0dZuOmm5ofx8nrtcN4L1oE4eG2UrpLF7scPAjPPGM72d17L9xzj1ZYK9VJtDRhrDLGfA4kAvcYY8IB7xGOOaHFxF3KvrN/pO9bn2C8jLtpAAAgAElEQVT27IE+ffwdUvPmzrWd48rLYf58uOoqW9/QrVvD/davt3NNLF9u6yFEIC/P9pOoKX67+GI7bEdi4rH/HEopv2lpkdQNwGxgnIiUYKdavc5nUR0HYmIu5sA52Bvq3Ln+DqdppaV2sp8bbrC9p3ftshMCzZsHgwfb+SRE7H5//COMGQOpqXbSoq1bYds2yM6Gigo7emxOjk04miyU6nRamjBOBraISJ4x5irgPiD/SAcZY+YaYzKNMRua2G6MMc8YY7YZY9YZY8bU23aNMSa1ermmhXEeM8HBiQT0H0vByRG2tVRHrPzescMmiblzbTL4/HP7JPTww3Z+7AED4Oqr4cwzYeRIO+fElVfC5s22jqJ+qaMxdhiPrl3993mUUn7V0oTxIlBijBkF/AHYDrzZguNeB6Y3s/1sYED1Mqv6OhhjugIPABOA8cADxpioFsZ6zHTvfil7p+dDWpodjbUj+egjO1nRrl127ok//7luelOA4cNtT+znnqsbMfbLL20T2UOLqZRSipYnjKrqycLPB54TkeeB8CMdJCJLgdxmdjkfeLN6LvLlQBdjTBxwFvCFiOSKyEHgC5pPPH7RrdvF5JwMlX272R7NV1/dfGe+1FR4+21btOMrHg/cf7/tRJeYCKtX27GZGuNw2HqNtDQ7G94ZZ/guLqXUca+lCaPQGHMPtjntx8YYB7Ye42jFA3vrvU+rXtfU+sMYY2YZY1YaY1ZmZWW1Q0gtFxLSn9AuSfz8+klw1112StCBA+G//suW9QMcOABPPw3jx9ttV14Jo0c3PQ/E0cjNtcnh4Ydtj+vvvmtZXUNEhJ0FTymlmtHSVlIzgSuw/TEOGGP6AI/7LqyWE5E5wBywo9Ue6+vHxFzCzqL7KH/ofdy33goPPAB//7sdonvMGNvr2euFpCTbsmjAADvfwymnwJ/+ZOeKqF9U1JzsbHj3XTsM+Nix0LNnXT3DmjVw0UX2aeHFF+G3v218DmylOgmv1/4XONr/Bl6vbfNRUWEHYRapO2/NIlK3vf6+DkfDxem01Z2VlQ2XmlgdjrpXpxNCQmyr9ZrF5bL7FhXZWY/z8+1rZaUd9NnXWpQwqpPEW8A4Y8yvgB9FpCV1GEeSDvSu975X9bp0YOoh61Pa4XrtLibmEnbuvI+srPfp1ft2W8F85522kjk11fZTuOKKhiO2Tplix1m67z749FPbUikhoemLeDy2Yv2ee+xTRI3u3W3iOOkkm6Cio20HOp2h7oRUc1OqPyPBoe0SDt2/qsr++Xg89ueqKtsgrqgIiovrXisr7Q3q0MXjsTeomnN4PLZldmlp3VJWZl9LSg5fX/+4miUgANxu+1Bb8xoQUPe56r82tni9DT+Xx2OvVVhob54FBfbn0lJ7nsY+V/2l5iZd8/up/7uqqLDX6yhcLhvXobNSdO8OGRm+v36L5sMwxlyGfaJIwXbiOw24S0Tmt+DYBOAjERneyLZzgVuxHQInAM+IyPjqSu9VQE2rqdXAWBFprj7E5/NhNGXlyjGIeElO/olW9Wd86626AfpuvdVOJHTyyRAUVLfPihW2nmHFCpg6FZ54wv6PXbXK1k+sWgU//2yT0NtvQ48e7frZOjORum+M9b851txEaxaPx24vK2u41NyYa5biYrt4vXU3qZpvk+Xlh9/wam56JSV1S0edvsblguBgu4SE2NegoMZv0DU34vJyu1RU2HX1nwbqvx66OBw2wdQ/p9ttS1YjImxf04gIG4dI40mrZqn59xOxn8HptOeuOX9goF1crrrXmieK+osxdfvWLDVJsP7fiddrz+tyNVwcjoYJsSbZl5Q0/PspKrLnrvmskZH2NSoKJkxo279da+bDaGnCWAucKSKZ1e9jgC9FZNQRjnsH+6TQDcjAtnxyAYjIS9W9xZ/DVmiXANeJyMrqY68H7q0+1V9E5LUjxemvhLFv3z/YuvVmxoxZTkREK//Vdu2C3/0OvvjC/kUFBcGpp9oK6F27bI/rHj3svNiXX97483VlZaefzEnE3mhzcuqW/Py6m3zNTb+83P4nrLl5Fxfb9zWP9/WX4uL2jTEgwLZMrrk51NwYam5WkZF1N7uICFsEERJSdwMOCam7Cdd85vqfv6lr1twEa26uNcUcoaF1ry5X4zfTmqKRmteam3NNcggKsq8tLVVVHY8vEsZ6ERlR770DWFt/XUfgr4RRVVXIsmU9iYm5hMGDj5jXGldQYOs7vvrKLhs22P+Ft98ODz5o7yCdgIj9Zp2ZaZf9+227gQMH7M8ZGXZ7/Rt+cXHDjugt4XbbG2XNUjMCSv0lLKyuyKT+N836RRk1S2CgvXkeutQvf9Z2Baoj8sWMe58aYz4D3ql+PxPohKPuNS4gIJwePa7iwIHXOemkv+NytaHLSESEbQp73nn2fUaG/Urcq1f7BnuM5eXZCfW2brWvO3bY4pr6ZcUej73h1ySJsrLDz+Nw2HLaHj3szTwmxlb71NzwIyNtFU50tO1GEh1t19Xc8OsXKYSE6DdipdqipZXedxljLgYmVa+aIyILfBfW8adnz5vZt+8lMjLepFev/zj6Ex4HdRHZ2XZE8/Xr7fxJubl2bMKa1/37bQKo4XTajuahoQ3LiZ1OmwCGDbNJoWaJiYG4OLt066Y3eaX8rcVzeovI+8D7PozluBYWNoqIiIns2/cS8fG3t67yuwOrrIQ9e+yTwc6ddmip9ettoti/v26/oCA7akhUlH3t2xfGjbNdTwYNsq/9+mmxjFLHs2YThjGmEGisksMAIiKdo2C9hXr2vJnNm68lP38pXbpM8Xc4rbZ/v210tXKlfd2wwSaL+s0KAwNtC+Ezz4RRo+wQVCNGHBcPREqpo9RswhCRIw7/oerExFzGtm13sG/fSx06YYjUJYealrmrVtliJbANsYYMsS18f/Mb+2SQmGhfe/bUoiGlOqsWF0mpI3M6g4mNvZb09OepqMgkMLC7v0MCbIXyjz/aKS6WL7fJoaaTjzG2yOj00yE52S5JSTonklLqcJow2llc3CzS0p7iwIHX6NPnbr/EkJ9vO5B/+SUsW2b79dV0LhoyBM46y3YQHzNGk4NSquU0YbSz0NAhREZOYd++f9C7913YLiu+t3u3HcX83/+GlBTbXDUqyo4SMnOmfR0/3jY1VUqpttCE4QM9e97Mpk2Xc/DgF3TtepZPruH12qKlhQvhww9tqyWwk+j94Q92mvEJE7S+QSnVfjRh+EBMzIVs2xZDevqL7ZowKirspHkffmgTxYEDtkPbpEl2INwZM2zzVaWU8gVNGD7gcLiJi7uRPXsepaQklZCQAUd1vs2b7WC1b7wBWVl2GIvp022n8HPOsb2alVLK145NAXsnZDvvudi797E2HV9SAq+9ZschHDIEnnrKPkksXGh7WL/3nm3yqslCKXWsaMLwEbc7lri46zlw4A3Ky9NbfFx5uZ1m+6ST4Prr7RPFo4/C3r2wYIGdUE97Syul/EEThg/17n0XIl727v37EfetqrJzLw0caCfkGzgQvv7aFkf9v/8HsbHHIGCllGqGJgwfCg5OpHv3X7Nv3z+orMxpdB+PB955xw68d8MNdtC9zz6zTWNPP11nWVVKdRyaMHysT5/ZeL3FpKc/12B9ZSW8+aZNFFdcYYuZFiywPbKnTdNEoZTqeDRh+FhY2HCio2eQlvY0VVVFlJfbSfQGDYJrrrGjvP7rX7YfxQUXaKJQSnVcPk0YxpjpxpgtxphtxpjZjWx/0hizpnrZaozJq7fNU2/bh76M09f69LmHysqDvPzyYgYMgN/+1s7v8OGH8NNPcMkltj+FUkp1ZD7rh2GMcQLPA2cCacAKY8yHIvJzzT4i8p/19r8NGF3vFKUikuSr+I6lgoKJPPjgtyxdOonRo7288oqDM8/UpwmlVOt4xUtpZSllVWUNFq94GdHD9zNm+7Lj3nhgm4jsADDGzAPOB35uYv/LgQd8GM8x5/HACy/AvfeC1zuR3/3uD8yePZQ+fW7wd2hKUVheyIbMDazLWIfT4eTkXiczJGYIjmM0/lmNKm8VZVVlBAcE43Qc/Vg2Vd4qskuyySnJoaC8gKKKIgorCiksL6Sooohwdzg9QnsQGxZLj7AexITE4HQ4qfJW1e5TWFFIaWUp4e5wIt2RRAZFEhQQBEB5VTnbD25nS/YWtuZsZUvOFio8FYzqMYrRcaNJik2iW0i3ZmOs8FSwOXsz6zPWsyFzA/uL9uMwDpzGicM4cBgHgpBTmkNWcRZZJVlkFWeRU5qDV7yHnS82LJb9f9jfyJXaly8TRjywt977NGBCYzsaY/oCicDX9VYHGWNWAlXAIyLyf74K1Bc2bbL9KJYvt5XYL77oIDc3hf37F9K797XYBzB1PKjyVrE9dzsbszayOXszRRVFVHgqqPRUUuGpoMJTQe/I3kzvP51xPcc1etMTEbblbmPFvhX0jujN2J5jCXGFtCoOj9dDXlkehRX2plZUUURxRTFFFUW4A9z0iuhF74jeRLgjGsz4mFuaS2pOKltztrI1ZyvrM9ezPnM9Ow7uOOwake5IJvaayMm9TmZkj5GUVZVRWFFIQXlB7eI0TkJcIQS7gu1rQDAAJZUlFFcWU1JZQkllCeVV5QS7ggl1hRLiCiE0MJSggCAyijLYmbfTLgd3klaQhkc8AAQFBNl9XaGEu8OJDYulZ3hPeob1JC48jtiwWCo8FWSXZDdYam6oWSVZ5Jbmtur36jAOAp2BlFU1Mpl8PYHOQCLcEeSW5ja4aceGxeI0Tt5a/1btuvjweIZ1H4bb6W5wDq942Zm3k605W6nyVgHgcriIDYtFELzirV1EhOiQaGJCYhjcbTCn9TmNmJAYItwRBAUE1S7BrmDCA4/N1EVGpLEJ9drhxMZcAkwXkRur3/8GmCAitzay791ALxG5rd66eBFJN8b0wyaSM0RkeyPHzgJmAfTp02fs7t27ffJ5WmPBArj6anC7bQ/tK6+0xU9ZWe+zceMlDB78BrGxV/s7zBNCRlEGH2z6gMziTMLd4YQHhhPuDicsMIyooCh6R/amZ3hPAhxNfzcqryonoziD/YX72Ve4r3bZlb+LjZk2SZR7ymv3D3AEEOgMrF1cDhf7i/bjFS/RwdFMO2ka0/tPZ2jMUH5I+4Gle5aydPdSDhQdqD2H0zgZ0WMEE+InMLHXRKKDoxvc9DKLM+235NIcckpyyC3NJa8sD2l0AsyGwgLD6BXRi/DAcHYc3EFOaV2TbodxMDB6ICN7jGRk95GM6DGCkT1GUuGpYNneZSxLW8b3e79nQ+aGw65lMIS7w/F4PZRUljQZi8vhIsQVQqAzkNKqUkoqSw77VhwXFkdiVCKJXRJJ6JJApDuyNtEUVxZTXFlMQXkBB4oO1P57VHgqGpwjwBFAt5ButUtMSIxdQmPoHtqd6OBoItwRh/1dFJYXcqDoABnFGfa1KIPSqlLCA+32mv2DAoIoqigivzyf/LL82teY0BgGRQ9iYPRABkYPJDLIDgGdXZLN2gNrWXNgDWsy1rA5ezMer+ew30/vyN4MjxnOiB4jGNF9BAOiBxDo9F9vXGPMKhFJbtG+PkwYJwMPishZ1e/vARCRvzay70/ALSLyfRPneh34SETmN3fN5ORkWbly5dGG3mZeLzz4IDz8sB1K/IMPID6+bruIl1WrxlNZmcn48VtwOoP9FivYb86fpH7C62tfp6yqjAFdB9C/a3/6d+3PgK4DiAuPwyteqrxVeLweqrxVVHorKaksafDttqiiiMigSPpF9aNPZJ8W/fFXeav4fu/3LNyykI9TP6asqqz2BpLYJZHEqET6RvYlPiKenuE9G5wztzSXBZsWMG/jPL7e+XWjj+j1OYyDuLC42uRRUllS+800pySHworCw44JcAQQHx7P0JihDO8+nGExwxjWfRhDug0hNDD0sP1zSnL4YscXfLLtEz7d9imZxZm123pF9GJK3ylM7juZCfET2Fuwl+Vpy/kh/Qd+TP+RgvKCBucKDggmJtTe/KJDookOtkvX4K50De5KZFAkoa5QwgLDCAsMIzQwlLKqMtIK0tibv5e0gjTSCtPIL8unX1Q/BnQdwMDogQyIHkC/qH4t+vfJL8tnW+42QgNDiXBHEOGOINQVWvvkIiJUeCpqEwJQ+yThcroanEtEKPeU1yaE6OBogl2t+9sXEXJLczlQdICggCC6hXQ77ElKtU1HSRgBwFbgDCAdWAFcISIbD9lvMPApkCjVwRhjooASESk3xnQDlgHn168wb4w/E0Z+Plx1FXz0kS2Kev5522T2UAcPprB27ekkJv6Vvn0PazgG2PLNlftWsuPgDlwOV4Nvs06Hk7KqMoorihsUARz2vrIYt9NdW646OnY0UcFRAOzJ38Orq1/l1Z9eJb0wndiwWGLDYknNSaW4sviofg8O46B3RG/6RfWjd2Rvuri70CWoC5FBkUS6I3E6nHy18ysWpS4itzQXl8PF1ISpdAvpVltEkVGccdh5Y0JiiI+IJzwwnOVpy6n0VtK/a38uH345M4fNZHC3wQ3KqgsrCsktzWVv/l72FuxlT/4e9hbsZV/hPsICw+q+mQbb1+6h3WuTU8/wnnQL6dbmsnyveFlzYA2pOalM6DWBvpF9m7yxecXLluwtFFUU1SaJxhKSUr7SIRJGdSDnAE8BTmCuiPzFGPMQsFJEPqze50EgSERm1zvuFOAfgBfb9PcpEXn1SNfzV8LYvNn2odi+3RZB/f73zbeAWr9+Bnl5S5gwYRuBgTGUV5WzYt8KluxaQsruFL7f+33tt7bWcDvdhAaG1n7TK6ooIr2wbhyrhC4JxIfHsyxtGSLCWf3P4rdjf8u5A87F5XQhImQUZ7AtdxupOalkFGcQ4AjAaZz21WFfD/12G+oKJa8sjx0Hd9glz76mFdhvuQXlBQ2KL6KDozl34LmcN/A8pp00jQh3RIPPUVJZwu683ezO3016QTrphemkFaSRXphOTkkOp/U5jV8P/zVj4sboN0yljlKHSRjHmj8SxsqV8MszvQRE7+bOR9fh6baO9ZnrWZexjuLKYkbHjia5ZzLJPZMZGzeWHmE92LL/a9759kz2eEeyuSiY1ftX15aRj+wxkil9pzCl7xSGdx+ORzy1FasVngqqvFUEBwTXViLWVBCGuEIarWzNKs7ipwM/8dP+n/jpwE9sP7id6SdN54YxN5DQJeGY/I684qWwvJD88nxKKksY0HVAu7SGUUodPU0Yx8jq1TD1wp2UXnwWVZGptetPijqJkT1GEuyyyWBL9pbab9gR7ojaMmuXgeSeYzilz+lM6j2JyX0nEx2i45UrpY6d1iQMnUCpjdasgdMv3k7JZb8grGshf/3lC4yOG83w7sMJCwxrsG9heSE/HfiJlftWkpqTytCYoYzpMYDy3ZfQPTqB4cOf8NOnUEqpltOE0Qbr1sHpF6dSfMkvCO9awtfXfsXouNFN7h/uDmdy38lM7ju5wfpd3M2uXfeTn/8dkZGTfB22UkodFR3BqJU2bIApF2+h4OKpRESXkXLd180mi+b07n0ngYFxbN/+X5xIRYNKqROTJoxW2L4dJl+0mYKLptKlayVLr1/MqNhRbT6f0xlKYuLDFBQsJyvrX+0YqVJKtT9NGC10ID+XX9z9PHkXTKFrV+GbG1IY3n34UZ83NvZawsKS2LbtDiorD7ZDpEop5RuaMJpR5a1iUeoiLvvXZfR6Mo49I24lITqeb25IYWjM0Ha5hjFOBg16lYqKTLZvv7NdzqmUUr6gld5NeH3N69z71b3sL9pPREA3PD/8jksHXMt7z7T/iOvh4WPo0+du9uz5H2JiLiM6+ux2v4ZSSh0tfcJoxAsrXuC6f1/HSV1P4tVpH+B+Lp0R6U/xxqO+m54jIeF+QkKGsHXrLKqqCo58gFJKHWOaMA7x/I/Pc8uiWzhv4Hl8fuWXvHP/hRTlBzJvHgT7cKxAh8PN4MGvUV6+j+3b7/LdhZRSqo00YdTz3I/Pcesnt3L+oPOZf9l8nnnSzZdfwtNPw9D2qbJoVkTEBHr3vpP9++dw8OBXvr+gUkq1giaMas/+8Cy3fXIbFwy+gPcufY81qwK57z649FK48cZjF0dCwkMEBw9gy5YbqaoqOnYXVkqpI9CEATzzwzPc/untXDj4Qt695F0CnYE88gh06wZz5hzbubedzmAGDZpLWdludu6859hdWCmljqDTJ4yckhweWvIQFw25qDZZeL2wZAmccw506XLsY+rS5VTi428jPf05cnI+PfYBKKVUIzp9wogOiWbZDcuYd/G82pnCNmyA3FyYMsV/cfXr9wihocPZvPkayssPHPkApZTysU6fMAAGRA9oMK3kkiX21Z8Jw+kMZujQeXg8BWzefA1yhGlIlVLK1zRhNCIlBRISoG9f/8YRGjqM/v2f4uDBz9m79+/+DUYp1en5NGEYY6YbY7YYY7YZYw6bwNoYc60xJssYs6Z6ubHetmuMManVyzW+jLM+EVi61L9PF/XFxc2iW7eL2LnzHgoKVvg7HKVUJ+azhGGMcQLPA2cDQ4HLjTGN9WZ4V0SSqpdXqo/tCjwATADGAw8YY6J8FWt9P/8M2dkwdeqxuNqRGWMYNOhlAgPj+Pnny6mqKvR3SEqpTsqXTxjjgW0iskNEKoB5wPktPPYs4AsRyRWRg8AXwHQfxdlASop97ShPGAAuV1eGDHmLsrKdpKbe4u9wlFKdlC8TRjywt977tOp1h7rYGLPOGDPfGNO7lce2uyVLoE8fW4fRkXTpchoJCfeTkfFP9u590t/hKKU6IX9Xei8EEkRkJPYp4o3WnsAYM8sYs9IYszIrK+uoghGxCWPKlGPbWa+l+va9j5iYS9i+/U727XvF3+EopToZXyaMdKB3vfe9qtfVEpEcESmvfvsKMLalx9Y7xxwRSRaR5JiYmKMKePNmyMzsWMVR9RnjZMiQt+jadTpbt84iM/Ndf4eklOpEfJkwVgADjDGJxphA4NfAh/V3MMbE1Xs7A9hU/fNnwDRjTFR1Zfe06nU+VdP/oqNUeDfG4Qhk2LD3iYw8jU2briI7+yN/h6SU6iR8ljBEpAq4FXuj3wS8JyIbjTEPGWNmVO92uzFmozFmLXA7cG31sbnAw9ikswJ4qHqdT6WkQHw89Ovn6ysdHaczhBEjFhIWlsTGjZdw8OBif4eklOoEjIj4O4Z2k5ycLCtXrmzTsSLQsyf84hfw1lvtHJiPVFbm8NNPUygr28WoUV8SGTnR3yEppY4zxphVIpLckn39XendYaSmwoEDHbs46lAuVzSjRn2B2x3HunXTyMv71t8hKaVOYJowqnXE/hct4XbHkZSUQmBgHOvWncXBg1/7OySl1AlKE0a1JUsgLg4GDPB3JK3ndseTlLSEoKBE1q8/l9xcn7cPUEp1QpowsPUXKSkdt/9FS7jdsSQlpRASMpj162eQnb3Q3yEppU4wmjCA7dth377jrzjqUIGB3Rg16ivCwkaxceNFZGbO93dISqkTiCYMjo/+Fy3lcnVl1KgvCA8fz88/X8auXX/WuTSUUu1CEwa2OKpHDxg0yN+RtI+AgEhGjfqC7t2vYNeu/2bDhgupqsr3d1hKqeNcp08YNeNHTZ58/NZfNMbpDGHIkH/Sv/8z5OYuYtWqcRQXb/R3WEqp41inTxjl5XDOOXDxxf6OpP0ZY+jV6zZGjfqKqqoCVq2aQGbmv/wdllLqOKU9vTuJ8vJ0Nm68hIKC5fTseTP9+j1OQECYv8NSSvmZ9vRWh7F9NVLo1esP7Nv3D1auTCI//zt/h6WUOo5owuhEHA43/fs/QVJSCuDhp58ms337bLze8iMdqpRSmjA6oy5dJpOcvI64uOvZu/dRVq0aR2HhGn+HpZTq4DRhdFIBAeEMGvQyI0Z8RGVlFqtWJbNjxz14PKX+Dk0p1UFpwujkoqPPZdy4jcTGXs2ePY+wcuUo8vKW+DsspVQHpAlD4XJ1ZfDguYwc+QUiHtasmcqWLb+lsjLP36EppToQTRiqVteuv2TcuPX07v1f7N//Cj/8cBKpqbdRULCSE6n5tVKqbXyaMIwx040xW4wx24wxsxvZfqcx5mdjzDpjzFfGmL71tnmMMWuqlw8PPVb5htMZwkknPc7YsT8SFXUm+/a9zOrV41ixYjh79jxGefk+f4eolPITn3XcM8Y4ga3AmUAadm7uy0Xk53r7nA78ICIlxpjfAVNFZGb1tiIRaVXPMu241/4qK/PIynqPAwdep6BgGeAgLu4mEhMfIjCwu7/DU0odpY7ScW88sE1EdohIBTAPOL/+DiKyWERKqt8uB3r5MB7VBi5XF3r2nMWYMd8zfvwW4uN/X11cNYA9e57QPhxKdSK+TBjxwN5679Oq1zXlBuCTeu+DjDErjTHLjTEX+CJA1TohIQMZMOBZxo1bT2TkqezYcRc//jiMrKz/0zoOpTqBDlHpbYy5CkgGHq+3um/1Y9IVwFPGmJOaOHZWdWJZmZWVdQyiVaGhQxg58mNGjvwUh8PNxo0XsnJlEnv2PEpZ2W5/h6eU8hFfJox0oHe9972q1zVgjPkl8EdghojUlm+ISHr16w4gBRjd2EVEZI6IJItIckxMTPtFr46oa9ezSE5ey8CBc3A4gtmxYzbLlyewevWppKc/T0VFpr9DVEq1I19WegdgK73PwCaKFcAVIrKx3j6jgfnAdBFJrbc+CigRkXJjTDdgGXB+/Qrzxmilt3+Vlu4gM3MemZnvUFy8AXDStet0YmOvJjp6Bk5nkL9DVEodojWV3j4d3twYcw7wFOAE5orIX4wxDwErReRDY8yXwAhgf/Uhe0RkhjHmFOAfgBf7FPSUiLx6pOtpwug4iorWk5HxFhkZ/0tFRTpOZyTdu19Gjx5XEhY2hoCAcH+HqJSiAyWMY00TRscj4iEvL4UDB94kK+t9vN5iAAICuhIUlEhQUALBwaW8m3UAAAx+SURBVImEhY2la9fpuFxd/ByxUp2LJgzVIVVVFXHw4OeUlqZSVraL0tKdlJXtoqxsFyLlGBNAZORpREefR3T0eYSE9Pd3yEqd8DRhqOOKiIeCgh/IyVlIdvZCSkpsNVdw8AAiIycREXEKkZGnEBIyBGM6RMM+pU4YmjDUca20dCc5OR9x8OAXFBQso7IyGwCnM5KIiAmEhAwhOPik2iUoKBGHI9DPUSt1fNKEoU4YIkJp6TYKCpaRn/89hYU/UFKSWlsXYjkICRlMZOSpREaeRpcup+F298EY47e4lTpeaMJQJzQRobIyk9LS7dVLKoWFK8nP/w6PpwAAt7sX4eHjcbvjCQyMrV7iCAyMJSgoUSvXlarWmoQR4OtglGpvxhgCA3sQGNiDyMhTateLeCgu3kB+/rfk5X1DUdEaDh78Co8n/7BzBAREExzcv3o5iaCgvtUJJQ63Ow6XK0brS5Q6hD5hqBOex1NKRcWB6mUfpaU7qp9MtlFWtp2ysj3YLj/1OXG5ojEmAGOc2MGXnTgcgQQH9ycsLKl6GUVQUKImF3Xc0icMpepxOoMJDk4kODix0e1ebznl5fupqNhPRcW+2p8rK3MQqQI8iHgQqcLrLaOkZDM5OR9Tk2ScznCCgwcSFNQbt7tuCQrqg9vdB7c7rjrhKHV804ShOj2Hw01wcALBwQktPsbjKaG4eCNFRWspKlpDaek2SkpSOXjw69p6lBrGuKoTSF/c7t6AF4+nGI+nBK+3GI+nGIcjuHp7H4KC+lYnm14EBETjcnXF4QjWSnzld5owlGoDpzOEiIhxRESMO2xbVVUB5eV7KSvbQ1nZbsrLd1NWZpe8vBSMceJ0huJwhOJ0huB2x+PxFFNQ8APl5fMRqTzsnMYE4nJ1JSAgCqczgoCAcJzOsOolHIfDDTiqi8YM4MDhCMTl6l5d31NT8d8DpzNck49qE00YSrWzgIAIAgKGERo6rNXHinipqMigrGw3FRXpVFbmUlV1sPo1l8rKXDyeQjyeIioqMvB4ivB4CqsnshJEvIAXEcHOW3Z4HaXTGUZgYDxud6/qJR6nM4SqqsLa83k8RXi9ZTgcgRjjxuEIwuGwry5XDG53fO2x9vgITUKdgCYMpToQYxy43bal1tES8VBZmUNFRUa9Sv8D1fU0aZSXp5OX93X1PO0ejAnE6az/5BKM11uB1/v/27vbGLmqOo7j39/Mzmy3LQ+23RYLSK2QaAnYRtKgYIIQtSoRYgCRhxBjQkxqAolGwfgQSXjhG9EXGCFCrAoCIlViSBQrQXghUKDKs1bEQCndBQu2LruzO/fvi3tmd7ou9Ha30907+/skk/sw986c0969/znn3vs/w2TZCBEjNJtvTnnXmVSbtO9ienoOp1ZbRq3Wn1o6/dRqy4ho0mzu2SdAZdkwEU0mrhe1XqNEjLVNx+jpWTIeqPLbplvTFQf0AGeWjZJlQzSbQ0itmxx8rentOGCYdSmpSr2+PI29ftJbbtc6ORc92Tabwyno7BgPPGNjr6WT/8RrbOwNhodfoNEYnDLITJQzb7m07kZr3ZGWz9eoVGrpbrUaUGFo6FlGRnakFtS+enqWjne/1WpLU0DYm4JT6zVElg1N0fVXoVZbRr2+nFptBfV6P5VKX2pdTbwmuhMnguNE+SvkXYOt8tdTy6y3bb6PSqW233/niGBsbDcjIy+nf++XaTR2Uq0uGk/cuWDBqkOa+dkBw2yemzhJF1OtLqCvbzV9fasL75NlDUZHX2V0dDC1RhaPt0iKnDwnyx/efJWRkR00GjvSybTVgtpJo/EKe/e+SLW6kGr1sHTt5vi2k/xCKpWF49OIUUZHB2k0djE6OkCjsYs9ex5NrauJ11TXl6ZD6tnn+6UeIhpk2WiaNsiyN6cMipP19Cxh0aI1rFv3wEEp29t+V8e/wczmvUqlTm/vSnp7Vx6Uz8sf3uynXu8H1h6Uzywiy8bIsjf/rzWVZcPk146abdeRxsiyRgoAI+PTfP+h8e6wLBsiy0bT9aJ6mtaoVBZQrx9Fb+/K1O22knr9KJrNveNZnieyPR+cQLY/DhhmZgVVKj1UKofN6gBg1epC6vXlHH74+kP+3X481czMCnHAMDOzQjoaMCRtkPScpO2Srpri/V5Jt6f3H5K0qu29q9P65yR9vJPlNDOz/etYwFB+28X1wCeANcDnJK2ZtNkXgN0RcTxwHfDdtO8a4ELgRGAD8EP5Bmkzs1nVyRbGemB7RDwf+b1htwHnTNrmHGBTmr8TOEv546LnALdFxEhE/BPYnj7PzMxmSScDxtHAi23LL6V1U24TeVrQN4ClBfcFQNLlkrZK2jo4OHiQim5mZpOV/qJ3RNwYEadExCn9/f2zXRwzs67VyYCxAzi2bfmYtG7KbST1AEcArxXc18zMDqGOjbiXAsDfgLPIT/aPABdFxFNt22wEToqIL0q6EPhMRFwg6UTgVvLrFiuBLcAJkWcne7vvHAT+Nc0iLwNenea+c1U31gm6s16uU3l0W72Oi4hC3TMde9I7IsYkfQn4HVAFbo6IpyRdA2yNiLuBm4CfSdoO/Jv8zijSdncATwNjwMb9BYu037T7pCRtLTpMYVl0Y52gO+vlOpVHt9ariI6mBomIe4B7Jq37Vtv8MHD+W+x7LXBtJ8tnZmbFlf6it5mZHRoOGBNunO0CdEA31gm6s16uU3l0a732q2MXvc3MrLu4hWFmZoXM+4CxvwSJZSHpZkkDkp5sW7dE0r2S/p6m75jNMh4oScdKuk/S05KeknRFWl/aeklaIOlhSX9JdfpOWv/ulIBze0rIWXxw6jlEUlXS45J+m5ZLXS9JL0h6QtI2SVvTutIefzM1rwNGwQSJZfET8kSN7a4CtkTECeTPspQtII4BX46INcCpwMb0/1Pmeo0AZ0bE+8mHitsg6VTyxJvXpUScu8kTc5bRFcAzbcvdUK+PRMTatltpy3z8zci8DhgUS5BYChHxJ/JnWdq1J3fcBJx7SAs1QxGxMyIeS/N7yE9ER1PiekVub1qspVcAZ5In4ISS1alF0jHAp4Afp2XRBfWaQmmPv5ma7wGjcJLDkloRETvT/CvAitkszEyksVLWAQ9R8nqlbpttwABwL/AP4PWUgBPKexx+H/gqkKXlpZS/XgH8XtKjki5P60p9/M2Ex/SeJyIiJJXyljhJi4FfAVdGxH/yH665MtYrZS1YK+lIYDPw3lku0oxJOhsYiIhHJZ0x2+U5iE6PiB2SlgP3Snq2/c0yHn8zMd9bGN2e5HCXpHcCpOnALJfngEmqkQeLWyLirrS69PUCiIjXgfuADwJHpvxrUM7j8DTg05JeIO/aPRP4ASWvV0TsSNMB8uC+ni45/qZjvgeMR4AT0p0cdfJcVnfPcpkOpruBy9L8ZcBvZrEsByz1gd8EPBMR32t7q7T1ktSfWhZI6gM+Sn5t5j7gvLRZqeoEEBFXR8QxEbGK/O/ojxFxMSWul6RFkg5rzQMfA56kxMffTM37B/ckfZK877WVILGU+ask/QI4gzyT5i7g28CvgTuAd5Fn8b0gIiZfGJ+zJJ0OPAA8wUS/+NfJr2OUsl6STia/UFol/8F2R0RcI2k1+S/zJcDjwCURMTJ7JZ2+1CX1lYg4u8z1SmXfnBZ7gFsj4lpJSynp8TdT8z5gmJlZMfO9S8rMzApywDAzs0IcMMzMrBAHDDMzK8QBw8zMCnHAMJsDJJ3RyvBqNlc5YJiZWSEOGGYHQNIlaTyLbZJuSIkE90q6Lo1vsUVSf9p2raQ/S/qrpM2tcRMkHS/pD2lMjMckvSd9/GJJd0p6VtItak+aZTYHOGCYFSTpfcBngdMiYi3QBC4GFgFbI+JE4H7yp+wBfgp8LSJOJn9avbX+FuD6NCbGh4BW5tN1wJXkY7OsJs/PZDZnOFutWXFnAR8AHkk//vvIE89lwO1pm58Dd0k6AjgyIu5P6zcBv0y5iY6OiM0AETEMkD7v4Yh4KS1vA1YBD3a+WmbFOGCYFSdgU0Rcvc9K6ZuTtptuvp32HEtN/Pdpc4y7pMyK2wKcl8ZGaI3tfBz531ErI+tFwIMR8QawW9KH0/pLgfvTyIEvSTo3fUavpIWHtBZm0+RfMGYFRcTTkr5BPgJbBRgFNgL/Bdan9wbIr3NAnvr6RykgPA98Pq2/FLhB0jXpM84/hNUwmzZnqzWbIUl7I2LxbJfDrNPcJWVmZoW4hWFmZoW4hWFmZoU4YJiZWSEOGGZmVogDhpmZFeKAYWZmhThgmJlZIf8DzMJ8th7OO38AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 553us/sample - loss: 1.0678 - acc: 0.6733\n",
      "Loss: 1.0678083244142502 Accuracy: 0.67331254\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9160 - acc: 0.3856\n",
      "Epoch 00001: val_loss improved from inf to 1.36921, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_5_conv_checkpoint/001-1.3692.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 1.9158 - acc: 0.3856 - val_loss: 1.3692 - val_acc: 0.5747\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2912 - acc: 0.5956\n",
      "Epoch 00002: val_loss improved from 1.36921 to 1.08592, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_5_conv_checkpoint/002-1.0859.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 1.2911 - acc: 0.5956 - val_loss: 1.0859 - val_acc: 0.6720\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0766 - acc: 0.6660\n",
      "Epoch 00003: val_loss improved from 1.08592 to 0.95164, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_5_conv_checkpoint/003-0.9516.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 1.0766 - acc: 0.6660 - val_loss: 0.9516 - val_acc: 0.7195\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9331 - acc: 0.7133\n",
      "Epoch 00004: val_loss improved from 0.95164 to 0.89870, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_5_conv_checkpoint/004-0.8987.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.9330 - acc: 0.7132 - val_loss: 0.8987 - val_acc: 0.7347\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8273 - acc: 0.7496\n",
      "Epoch 00005: val_loss improved from 0.89870 to 0.85854, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_5_conv_checkpoint/005-0.8585.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.8273 - acc: 0.7496 - val_loss: 0.8585 - val_acc: 0.7424\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7451 - acc: 0.7733\n",
      "Epoch 00006: val_loss improved from 0.85854 to 0.80527, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_5_conv_checkpoint/006-0.8053.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.7452 - acc: 0.7733 - val_loss: 0.8053 - val_acc: 0.7619\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6709 - acc: 0.7953\n",
      "Epoch 00007: val_loss improved from 0.80527 to 0.79806, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_5_conv_checkpoint/007-0.7981.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.6710 - acc: 0.7953 - val_loss: 0.7981 - val_acc: 0.7582\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5997 - acc: 0.8182\n",
      "Epoch 00008: val_loss improved from 0.79806 to 0.75520, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_5_conv_checkpoint/008-0.7552.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.5997 - acc: 0.8182 - val_loss: 0.7552 - val_acc: 0.7792\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5450 - acc: 0.8346\n",
      "Epoch 00009: val_loss improved from 0.75520 to 0.72514, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_5_conv_checkpoint/009-0.7251.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.5450 - acc: 0.8346 - val_loss: 0.7251 - val_acc: 0.7855\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4953 - acc: 0.8492\n",
      "Epoch 00010: val_loss improved from 0.72514 to 0.71996, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_5_conv_checkpoint/010-0.7200.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.4953 - acc: 0.8492 - val_loss: 0.7200 - val_acc: 0.7850\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4492 - acc: 0.8630\n",
      "Epoch 00011: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.4494 - acc: 0.8630 - val_loss: 0.7418 - val_acc: 0.7817\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4025 - acc: 0.8763\n",
      "Epoch 00012: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.4025 - acc: 0.8763 - val_loss: 0.7667 - val_acc: 0.7813\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3670 - acc: 0.8881\n",
      "Epoch 00013: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3670 - acc: 0.8881 - val_loss: 0.7231 - val_acc: 0.7962\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3381 - acc: 0.8943\n",
      "Epoch 00014: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3381 - acc: 0.8943 - val_loss: 0.7749 - val_acc: 0.7843\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3064 - acc: 0.9048\n",
      "Epoch 00015: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.3064 - acc: 0.9048 - val_loss: 0.7562 - val_acc: 0.7939\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2814 - acc: 0.9120\n",
      "Epoch 00016: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2813 - acc: 0.9120 - val_loss: 0.7457 - val_acc: 0.7969\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2630 - acc: 0.9173\n",
      "Epoch 00017: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2630 - acc: 0.9173 - val_loss: 0.7330 - val_acc: 0.8039\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2449 - acc: 0.9228\n",
      "Epoch 00018: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2449 - acc: 0.9228 - val_loss: 0.7845 - val_acc: 0.7957\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2228 - acc: 0.9302\n",
      "Epoch 00019: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2228 - acc: 0.9303 - val_loss: 0.7873 - val_acc: 0.7959\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2131 - acc: 0.9329\n",
      "Epoch 00020: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2131 - acc: 0.9329 - val_loss: 0.7804 - val_acc: 0.8041\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1952 - acc: 0.9388\n",
      "Epoch 00021: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1952 - acc: 0.9388 - val_loss: 0.7555 - val_acc: 0.8116\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1853 - acc: 0.9414\n",
      "Epoch 00022: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1853 - acc: 0.9414 - val_loss: 0.8061 - val_acc: 0.8011\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1732 - acc: 0.9446\n",
      "Epoch 00023: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1732 - acc: 0.9446 - val_loss: 0.7927 - val_acc: 0.8050\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9483\n",
      "Epoch 00024: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1620 - acc: 0.9483 - val_loss: 0.8235 - val_acc: 0.7973\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9511\n",
      "Epoch 00025: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1551 - acc: 0.9511 - val_loss: 0.8645 - val_acc: 0.7987\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1569 - acc: 0.9495\n",
      "Epoch 00026: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1569 - acc: 0.9495 - val_loss: 0.8636 - val_acc: 0.8062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9556\n",
      "Epoch 00027: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1379 - acc: 0.9556 - val_loss: 0.8398 - val_acc: 0.8064\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9566\n",
      "Epoch 00028: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1361 - acc: 0.9566 - val_loss: 0.8886 - val_acc: 0.8027\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9579\n",
      "Epoch 00029: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1280 - acc: 0.9579 - val_loss: 0.8104 - val_acc: 0.8106\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1266 - acc: 0.9601\n",
      "Epoch 00030: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1266 - acc: 0.9601 - val_loss: 0.8349 - val_acc: 0.8141\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9616\n",
      "Epoch 00031: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.1219 - acc: 0.9616 - val_loss: 0.9302 - val_acc: 0.7971\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9619\n",
      "Epoch 00032: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1190 - acc: 0.9619 - val_loss: 0.8322 - val_acc: 0.8185\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1139 - acc: 0.9627\n",
      "Epoch 00033: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1139 - acc: 0.9627 - val_loss: 0.8697 - val_acc: 0.8178\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1094 - acc: 0.9654\n",
      "Epoch 00034: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1094 - acc: 0.9654 - val_loss: 0.8712 - val_acc: 0.8050\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9632\n",
      "Epoch 00035: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1100 - acc: 0.9632 - val_loss: 0.8882 - val_acc: 0.8055\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9689\n",
      "Epoch 00036: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0989 - acc: 0.9689 - val_loss: 0.8938 - val_acc: 0.8123\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9666\n",
      "Epoch 00037: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1044 - acc: 0.9666 - val_loss: 0.8935 - val_acc: 0.8099\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1030 - acc: 0.9678\n",
      "Epoch 00038: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1030 - acc: 0.9677 - val_loss: 0.9282 - val_acc: 0.8132\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9694\n",
      "Epoch 00039: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0968 - acc: 0.9694 - val_loss: 0.9036 - val_acc: 0.8171\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9698\n",
      "Epoch 00040: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0970 - acc: 0.9698 - val_loss: 0.8900 - val_acc: 0.8148\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9705\n",
      "Epoch 00041: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0921 - acc: 0.9705 - val_loss: 0.8816 - val_acc: 0.8143\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9719\n",
      "Epoch 00042: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0888 - acc: 0.9719 - val_loss: 0.8810 - val_acc: 0.8181\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9714\n",
      "Epoch 00043: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0883 - acc: 0.9714 - val_loss: 0.8898 - val_acc: 0.8223\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9717\n",
      "Epoch 00044: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0897 - acc: 0.9717 - val_loss: 0.9156 - val_acc: 0.8127\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9731\n",
      "Epoch 00045: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0844 - acc: 0.9731 - val_loss: 0.8812 - val_acc: 0.8209\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9758\n",
      "Epoch 00046: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0777 - acc: 0.9758 - val_loss: 0.9270 - val_acc: 0.8199\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9729\n",
      "Epoch 00047: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0853 - acc: 0.9729 - val_loss: 0.8737 - val_acc: 0.8213\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9753\n",
      "Epoch 00048: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0804 - acc: 0.9753 - val_loss: 0.9493 - val_acc: 0.8162\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9759\n",
      "Epoch 00049: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0786 - acc: 0.9759 - val_loss: 1.0445 - val_acc: 0.7962\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9762\n",
      "Epoch 00050: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0797 - acc: 0.9762 - val_loss: 0.8893 - val_acc: 0.8262\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9766\n",
      "Epoch 00051: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 49s 1ms/sample - loss: 0.0741 - acc: 0.9766 - val_loss: 1.0023 - val_acc: 0.8141\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9733\n",
      "Epoch 00052: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0819 - acc: 0.9733 - val_loss: 0.8720 - val_acc: 0.8255\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9771\n",
      "Epoch 00053: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0711 - acc: 0.9771 - val_loss: 0.9017 - val_acc: 0.8265\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9762\n",
      "Epoch 00054: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0762 - acc: 0.9762 - val_loss: 0.9102 - val_acc: 0.8232\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9775\n",
      "Epoch 00055: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0722 - acc: 0.9775 - val_loss: 0.9244 - val_acc: 0.8234\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9780\n",
      "Epoch 00056: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0711 - acc: 0.9780 - val_loss: 0.9615 - val_acc: 0.8176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0718 - acc: 0.9784\n",
      "Epoch 00057: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0718 - acc: 0.9784 - val_loss: 0.8722 - val_acc: 0.8293\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9801\n",
      "Epoch 00058: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0656 - acc: 0.9801 - val_loss: 0.9353 - val_acc: 0.8246\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9796\n",
      "Epoch 00059: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0667 - acc: 0.9796 - val_loss: 0.9019 - val_acc: 0.8325\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9783\n",
      "Epoch 00060: val_loss did not improve from 0.71996\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0688 - acc: 0.9783 - val_loss: 0.9743 - val_acc: 0.8244\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 609us/sample - loss: 0.8189 - acc: 0.7466\n",
      "Loss: 0.8188534947199242 Accuracy: 0.7466251\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0260 - acc: 0.3452\n",
      "Epoch 00001: val_loss improved from inf to 1.38156, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/001-1.3816.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 2.0258 - acc: 0.3453 - val_loss: 1.3816 - val_acc: 0.5691\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3407 - acc: 0.5764\n",
      "Epoch 00002: val_loss improved from 1.38156 to 1.07189, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/002-1.0719.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 1.3406 - acc: 0.5764 - val_loss: 1.0719 - val_acc: 0.6788\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1032 - acc: 0.6569\n",
      "Epoch 00003: val_loss improved from 1.07189 to 0.89209, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/003-0.8921.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 1.1031 - acc: 0.6569 - val_loss: 0.8921 - val_acc: 0.7447\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9380 - acc: 0.7129\n",
      "Epoch 00004: val_loss improved from 0.89209 to 0.80418, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/004-0.8042.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.9379 - acc: 0.7129 - val_loss: 0.8042 - val_acc: 0.7643\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8223 - acc: 0.7514\n",
      "Epoch 00005: val_loss improved from 0.80418 to 0.70601, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/005-0.7060.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.8224 - acc: 0.7514 - val_loss: 0.7060 - val_acc: 0.7932\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7353 - acc: 0.7800\n",
      "Epoch 00006: val_loss improved from 0.70601 to 0.62147, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/006-0.6215.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.7353 - acc: 0.7799 - val_loss: 0.6215 - val_acc: 0.8269\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6536 - acc: 0.8038\n",
      "Epoch 00007: val_loss did not improve from 0.62147\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.6536 - acc: 0.8038 - val_loss: 0.6929 - val_acc: 0.8022\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6013 - acc: 0.8190\n",
      "Epoch 00008: val_loss improved from 0.62147 to 0.57991, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/008-0.5799.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.6013 - acc: 0.8190 - val_loss: 0.5799 - val_acc: 0.8379\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5436 - acc: 0.8364\n",
      "Epoch 00009: val_loss improved from 0.57991 to 0.51384, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/009-0.5138.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.5435 - acc: 0.8364 - val_loss: 0.5138 - val_acc: 0.8570\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5063 - acc: 0.8472\n",
      "Epoch 00010: val_loss improved from 0.51384 to 0.47663, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/010-0.4766.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.5063 - acc: 0.8472 - val_loss: 0.4766 - val_acc: 0.8693\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4719 - acc: 0.8596\n",
      "Epoch 00011: val_loss improved from 0.47663 to 0.46290, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/011-0.4629.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.4719 - acc: 0.8596 - val_loss: 0.4629 - val_acc: 0.8719\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4350 - acc: 0.8682\n",
      "Epoch 00012: val_loss improved from 0.46290 to 0.44044, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/012-0.4404.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.4350 - acc: 0.8682 - val_loss: 0.4404 - val_acc: 0.8805\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4142 - acc: 0.8737\n",
      "Epoch 00013: val_loss improved from 0.44044 to 0.42751, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/013-0.4275.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.4142 - acc: 0.8737 - val_loss: 0.4275 - val_acc: 0.8814\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3907 - acc: 0.8798\n",
      "Epoch 00014: val_loss did not improve from 0.42751\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3907 - acc: 0.8797 - val_loss: 0.4329 - val_acc: 0.8842\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3652 - acc: 0.8892\n",
      "Epoch 00015: val_loss improved from 0.42751 to 0.40603, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/015-0.4060.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3652 - acc: 0.8892 - val_loss: 0.4060 - val_acc: 0.8889\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3460 - acc: 0.8947\n",
      "Epoch 00016: val_loss did not improve from 0.40603\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3460 - acc: 0.8947 - val_loss: 0.4404 - val_acc: 0.8775\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3297 - acc: 0.8992\n",
      "Epoch 00017: val_loss improved from 0.40603 to 0.40413, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/017-0.4041.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3296 - acc: 0.8992 - val_loss: 0.4041 - val_acc: 0.8940\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3061 - acc: 0.9057\n",
      "Epoch 00018: val_loss improved from 0.40413 to 0.40053, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/018-0.4005.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.3061 - acc: 0.9057 - val_loss: 0.4005 - val_acc: 0.8915\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2929 - acc: 0.9092\n",
      "Epoch 00019: val_loss did not improve from 0.40053\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2929 - acc: 0.9091 - val_loss: 0.4134 - val_acc: 0.8873\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2808 - acc: 0.9133\n",
      "Epoch 00020: val_loss did not improve from 0.40053\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2807 - acc: 0.9133 - val_loss: 0.4095 - val_acc: 0.8952\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2652 - acc: 0.9190\n",
      "Epoch 00021: val_loss improved from 0.40053 to 0.39826, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/021-0.3983.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2651 - acc: 0.9190 - val_loss: 0.3983 - val_acc: 0.8989\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2539 - acc: 0.9201\n",
      "Epoch 00022: val_loss improved from 0.39826 to 0.38585, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/022-0.3858.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2540 - acc: 0.9200 - val_loss: 0.3858 - val_acc: 0.8963\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2432 - acc: 0.9230\n",
      "Epoch 00023: val_loss did not improve from 0.38585\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2431 - acc: 0.9230 - val_loss: 0.4169 - val_acc: 0.8919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2321 - acc: 0.9274\n",
      "Epoch 00024: val_loss did not improve from 0.38585\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2321 - acc: 0.9274 - val_loss: 0.3956 - val_acc: 0.9029\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2210 - acc: 0.9308\n",
      "Epoch 00025: val_loss improved from 0.38585 to 0.37360, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/025-0.3736.hdf5\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2210 - acc: 0.9309 - val_loss: 0.3736 - val_acc: 0.9066\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2101 - acc: 0.9327\n",
      "Epoch 00026: val_loss improved from 0.37360 to 0.36352, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_6_conv_checkpoint/026-0.3635.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2101 - acc: 0.9328 - val_loss: 0.3635 - val_acc: 0.9080\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9352\n",
      "Epoch 00027: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.2039 - acc: 0.9353 - val_loss: 0.3662 - val_acc: 0.9080\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1978 - acc: 0.9380\n",
      "Epoch 00028: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1978 - acc: 0.9380 - val_loss: 0.3765 - val_acc: 0.9061\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1899 - acc: 0.9399\n",
      "Epoch 00029: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1899 - acc: 0.9399 - val_loss: 0.3747 - val_acc: 0.9064\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1770 - acc: 0.9445\n",
      "Epoch 00030: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1770 - acc: 0.9445 - val_loss: 0.3772 - val_acc: 0.9064\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9442\n",
      "Epoch 00031: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1752 - acc: 0.9442 - val_loss: 0.4056 - val_acc: 0.9001\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9447\n",
      "Epoch 00032: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1690 - acc: 0.9447 - val_loss: 0.3942 - val_acc: 0.9022\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9502\n",
      "Epoch 00033: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1576 - acc: 0.9502 - val_loss: 0.3983 - val_acc: 0.9080\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1591 - acc: 0.9479\n",
      "Epoch 00034: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1591 - acc: 0.9479 - val_loss: 0.3904 - val_acc: 0.9038\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1522 - acc: 0.9516\n",
      "Epoch 00035: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1521 - acc: 0.9516 - val_loss: 0.3764 - val_acc: 0.9052\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9529\n",
      "Epoch 00036: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1442 - acc: 0.9529 - val_loss: 0.3768 - val_acc: 0.9136\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9542\n",
      "Epoch 00037: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1415 - acc: 0.9542 - val_loss: 0.4065 - val_acc: 0.9059\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1374 - acc: 0.9547\n",
      "Epoch 00038: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1374 - acc: 0.9547 - val_loss: 0.3767 - val_acc: 0.9113\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1326 - acc: 0.9561\n",
      "Epoch 00039: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1326 - acc: 0.9561 - val_loss: 0.4001 - val_acc: 0.9043\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9569\n",
      "Epoch 00040: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1272 - acc: 0.9569 - val_loss: 0.4022 - val_acc: 0.9089\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9606\n",
      "Epoch 00041: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1238 - acc: 0.9606 - val_loss: 0.3829 - val_acc: 0.9143\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9605\n",
      "Epoch 00042: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1199 - acc: 0.9605 - val_loss: 0.4484 - val_acc: 0.9047\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1157 - acc: 0.9613\n",
      "Epoch 00043: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1157 - acc: 0.9613 - val_loss: 0.4017 - val_acc: 0.9052\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9602\n",
      "Epoch 00044: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1179 - acc: 0.9602 - val_loss: 0.3956 - val_acc: 0.9115\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1105 - acc: 0.9627\n",
      "Epoch 00045: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1105 - acc: 0.9627 - val_loss: 0.3964 - val_acc: 0.9113\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9638\n",
      "Epoch 00046: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1082 - acc: 0.9638 - val_loss: 0.3957 - val_acc: 0.9092\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9647\n",
      "Epoch 00047: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1076 - acc: 0.9647 - val_loss: 0.3853 - val_acc: 0.9159\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9664\n",
      "Epoch 00048: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1031 - acc: 0.9664 - val_loss: 0.4471 - val_acc: 0.9036\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9665\n",
      "Epoch 00049: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.1032 - acc: 0.9665 - val_loss: 0.4422 - val_acc: 0.8987\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9673\n",
      "Epoch 00050: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0990 - acc: 0.9673 - val_loss: 0.3869 - val_acc: 0.9166\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9678\n",
      "Epoch 00051: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0984 - acc: 0.9678 - val_loss: 0.3867 - val_acc: 0.9166\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9678\n",
      "Epoch 00052: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0987 - acc: 0.9677 - val_loss: 0.4197 - val_acc: 0.9133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9703\n",
      "Epoch 00053: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0897 - acc: 0.9703 - val_loss: 0.3942 - val_acc: 0.9129\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9702\n",
      "Epoch 00054: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0924 - acc: 0.9702 - val_loss: 0.4184 - val_acc: 0.9085\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0873 - acc: 0.9715\n",
      "Epoch 00055: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0873 - acc: 0.9716 - val_loss: 0.3981 - val_acc: 0.9143\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9720\n",
      "Epoch 00056: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0849 - acc: 0.9720 - val_loss: 0.4067 - val_acc: 0.9187\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0861 - acc: 0.9712\n",
      "Epoch 00057: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0862 - acc: 0.9711 - val_loss: 0.4310 - val_acc: 0.9159\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9706\n",
      "Epoch 00058: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0880 - acc: 0.9706 - val_loss: 0.4048 - val_acc: 0.9178\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9723\n",
      "Epoch 00059: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0816 - acc: 0.9723 - val_loss: 0.3853 - val_acc: 0.9199\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9748\n",
      "Epoch 00060: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0773 - acc: 0.9748 - val_loss: 0.4017 - val_acc: 0.9166\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9732\n",
      "Epoch 00061: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0805 - acc: 0.9732 - val_loss: 0.4113 - val_acc: 0.9194\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9739\n",
      "Epoch 00062: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0797 - acc: 0.9739 - val_loss: 0.4039 - val_acc: 0.9140\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9751\n",
      "Epoch 00063: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0755 - acc: 0.9751 - val_loss: 0.4481 - val_acc: 0.9071\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9741\n",
      "Epoch 00064: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0763 - acc: 0.9741 - val_loss: 0.4606 - val_acc: 0.9133\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0765 - acc: 0.9757\n",
      "Epoch 00065: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0765 - acc: 0.9757 - val_loss: 0.4125 - val_acc: 0.9199\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0678 - acc: 0.9782\n",
      "Epoch 00066: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0678 - acc: 0.9782 - val_loss: 0.4412 - val_acc: 0.9147\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9784\n",
      "Epoch 00067: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0702 - acc: 0.9784 - val_loss: 0.4192 - val_acc: 0.9159\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9762\n",
      "Epoch 00068: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0726 - acc: 0.9762 - val_loss: 0.4074 - val_acc: 0.9215\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9784\n",
      "Epoch 00069: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0658 - acc: 0.9784 - val_loss: 0.4130 - val_acc: 0.9245\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9783\n",
      "Epoch 00070: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0674 - acc: 0.9783 - val_loss: 0.3919 - val_acc: 0.9234\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9778\n",
      "Epoch 00071: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0670 - acc: 0.9778 - val_loss: 0.4153 - val_acc: 0.9189\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9775\n",
      "Epoch 00072: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0683 - acc: 0.9775 - val_loss: 0.4605 - val_acc: 0.9133\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9770\n",
      "Epoch 00073: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0710 - acc: 0.9770 - val_loss: 0.4395 - val_acc: 0.9138\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9800\n",
      "Epoch 00074: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0620 - acc: 0.9800 - val_loss: 0.4257 - val_acc: 0.9173\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9801\n",
      "Epoch 00075: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0636 - acc: 0.9801 - val_loss: 0.4540 - val_acc: 0.9124\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9786\n",
      "Epoch 00076: val_loss did not improve from 0.36352\n",
      "36805/36805 [==============================] - 50s 1ms/sample - loss: 0.0646 - acc: 0.9786 - val_loss: 0.4371 - val_acc: 0.9187\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 620us/sample - loss: 0.4431 - acc: 0.8800\n",
      "Loss: 0.4431484981241751 Accuracy: 0.87995845\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2147 - acc: 0.2780\n",
      "Epoch 00001: val_loss improved from inf to 1.43896, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/001-1.4390.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 2.2146 - acc: 0.2781 - val_loss: 1.4390 - val_acc: 0.5698\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4064 - acc: 0.5439\n",
      "Epoch 00002: val_loss improved from 1.43896 to 1.01498, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/002-1.0150.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 1.4063 - acc: 0.5439 - val_loss: 1.0150 - val_acc: 0.6995\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0556 - acc: 0.6649\n",
      "Epoch 00003: val_loss improved from 1.01498 to 0.74542, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/003-0.7454.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 1.0554 - acc: 0.6650 - val_loss: 0.7454 - val_acc: 0.7880\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8421 - acc: 0.7418\n",
      "Epoch 00004: val_loss improved from 0.74542 to 0.61179, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/004-0.6118.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.8422 - acc: 0.7417 - val_loss: 0.6118 - val_acc: 0.8251\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7082 - acc: 0.7863\n",
      "Epoch 00005: val_loss improved from 0.61179 to 0.53746, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/005-0.5375.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.7081 - acc: 0.7863 - val_loss: 0.5375 - val_acc: 0.8523\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6119 - acc: 0.8144\n",
      "Epoch 00006: val_loss improved from 0.53746 to 0.45978, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/006-0.4598.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.6119 - acc: 0.8144 - val_loss: 0.4598 - val_acc: 0.8724\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5450 - acc: 0.8339\n",
      "Epoch 00007: val_loss improved from 0.45978 to 0.40442, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/007-0.4044.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.5449 - acc: 0.8339 - val_loss: 0.4044 - val_acc: 0.8928\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4858 - acc: 0.8519\n",
      "Epoch 00008: val_loss improved from 0.40442 to 0.37801, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/008-0.3780.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.4858 - acc: 0.8519 - val_loss: 0.3780 - val_acc: 0.8931\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4411 - acc: 0.8655\n",
      "Epoch 00009: val_loss improved from 0.37801 to 0.34828, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/009-0.3483.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.4411 - acc: 0.8655 - val_loss: 0.3483 - val_acc: 0.9019\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4084 - acc: 0.8757\n",
      "Epoch 00010: val_loss improved from 0.34828 to 0.32059, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/010-0.3206.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.4084 - acc: 0.8758 - val_loss: 0.3206 - val_acc: 0.9178\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3721 - acc: 0.8846\n",
      "Epoch 00011: val_loss improved from 0.32059 to 0.29367, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/011-0.2937.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.3721 - acc: 0.8846 - val_loss: 0.2937 - val_acc: 0.9194\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3540 - acc: 0.8912\n",
      "Epoch 00012: val_loss did not improve from 0.29367\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.3540 - acc: 0.8912 - val_loss: 0.3085 - val_acc: 0.9152\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3312 - acc: 0.9002\n",
      "Epoch 00013: val_loss improved from 0.29367 to 0.28780, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/013-0.2878.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.3311 - acc: 0.9003 - val_loss: 0.2878 - val_acc: 0.9217\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3052 - acc: 0.9044\n",
      "Epoch 00014: val_loss improved from 0.28780 to 0.27677, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/014-0.2768.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.3052 - acc: 0.9044 - val_loss: 0.2768 - val_acc: 0.9250\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2871 - acc: 0.9097\n",
      "Epoch 00015: val_loss did not improve from 0.27677\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2871 - acc: 0.9097 - val_loss: 0.2824 - val_acc: 0.9245\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2787 - acc: 0.9130\n",
      "Epoch 00016: val_loss improved from 0.27677 to 0.26067, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/016-0.2607.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2786 - acc: 0.9130 - val_loss: 0.2607 - val_acc: 0.9297\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2597 - acc: 0.9182\n",
      "Epoch 00017: val_loss did not improve from 0.26067\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2598 - acc: 0.9182 - val_loss: 0.2665 - val_acc: 0.9266\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2446 - acc: 0.9223\n",
      "Epoch 00018: val_loss improved from 0.26067 to 0.25357, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/018-0.2536.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2447 - acc: 0.9223 - val_loss: 0.2536 - val_acc: 0.9294\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2303 - acc: 0.9259\n",
      "Epoch 00019: val_loss improved from 0.25357 to 0.23232, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/019-0.2323.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2304 - acc: 0.9259 - val_loss: 0.2323 - val_acc: 0.9348\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2235 - acc: 0.9297\n",
      "Epoch 00020: val_loss did not improve from 0.23232\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2234 - acc: 0.9297 - val_loss: 0.2376 - val_acc: 0.9350\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2151 - acc: 0.9320\n",
      "Epoch 00021: val_loss improved from 0.23232 to 0.22910, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/021-0.2291.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2152 - acc: 0.9320 - val_loss: 0.2291 - val_acc: 0.9364\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2071 - acc: 0.9338\n",
      "Epoch 00022: val_loss did not improve from 0.22910\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.2071 - acc: 0.9338 - val_loss: 0.2395 - val_acc: 0.9350\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9372\n",
      "Epoch 00023: val_loss improved from 0.22910 to 0.22775, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/023-0.2278.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1984 - acc: 0.9372 - val_loss: 0.2278 - val_acc: 0.9376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9383\n",
      "Epoch 00024: val_loss did not improve from 0.22775\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1936 - acc: 0.9382 - val_loss: 0.2332 - val_acc: 0.9311\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1829 - acc: 0.9399\n",
      "Epoch 00025: val_loss improved from 0.22775 to 0.21563, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/025-0.2156.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1829 - acc: 0.9399 - val_loss: 0.2156 - val_acc: 0.9408\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1764 - acc: 0.9434\n",
      "Epoch 00026: val_loss improved from 0.21563 to 0.21265, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/026-0.2126.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1764 - acc: 0.9434 - val_loss: 0.2126 - val_acc: 0.9436\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1738 - acc: 0.9439\n",
      "Epoch 00027: val_loss improved from 0.21265 to 0.19783, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/027-0.1978.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1739 - acc: 0.9439 - val_loss: 0.1978 - val_acc: 0.9462\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1658 - acc: 0.9454\n",
      "Epoch 00028: val_loss did not improve from 0.19783\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1658 - acc: 0.9454 - val_loss: 0.2158 - val_acc: 0.9411\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1611 - acc: 0.9472\n",
      "Epoch 00029: val_loss improved from 0.19783 to 0.19502, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/029-0.1950.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1611 - acc: 0.9472 - val_loss: 0.1950 - val_acc: 0.9474\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9511\n",
      "Epoch 00030: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1480 - acc: 0.9511 - val_loss: 0.2014 - val_acc: 0.9467\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9511\n",
      "Epoch 00031: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1483 - acc: 0.9511 - val_loss: 0.2011 - val_acc: 0.9462\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9535\n",
      "Epoch 00032: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1415 - acc: 0.9535 - val_loss: 0.2228 - val_acc: 0.9441\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1385 - acc: 0.9548\n",
      "Epoch 00033: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1385 - acc: 0.9548 - val_loss: 0.2060 - val_acc: 0.9474\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9569\n",
      "Epoch 00034: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1290 - acc: 0.9569 - val_loss: 0.2084 - val_acc: 0.9467\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1298 - acc: 0.9574\n",
      "Epoch 00035: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1298 - acc: 0.9574 - val_loss: 0.2267 - val_acc: 0.9418\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1252 - acc: 0.9582\n",
      "Epoch 00036: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1252 - acc: 0.9582 - val_loss: 0.1975 - val_acc: 0.9481\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9576\n",
      "Epoch 00037: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1258 - acc: 0.9576 - val_loss: 0.2024 - val_acc: 0.9446\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9602\n",
      "Epoch 00038: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1170 - acc: 0.9602 - val_loss: 0.1989 - val_acc: 0.9509\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1190 - acc: 0.9605\n",
      "Epoch 00039: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1191 - acc: 0.9604 - val_loss: 0.2066 - val_acc: 0.9446\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9626\n",
      "Epoch 00040: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1118 - acc: 0.9626 - val_loss: 0.2046 - val_acc: 0.9499\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9616\n",
      "Epoch 00041: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1145 - acc: 0.9616 - val_loss: 0.2116 - val_acc: 0.9513\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1039 - acc: 0.9652\n",
      "Epoch 00042: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1040 - acc: 0.9652 - val_loss: 0.2067 - val_acc: 0.9488\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9635\n",
      "Epoch 00043: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1077 - acc: 0.9635 - val_loss: 0.1985 - val_acc: 0.9488\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1007 - acc: 0.9657\n",
      "Epoch 00044: val_loss did not improve from 0.19502\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.1007 - acc: 0.9657 - val_loss: 0.1972 - val_acc: 0.9506\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9666\n",
      "Epoch 00045: val_loss improved from 0.19502 to 0.19006, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/045-0.1901.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0997 - acc: 0.9666 - val_loss: 0.1901 - val_acc: 0.9527\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9670\n",
      "Epoch 00046: val_loss did not improve from 0.19006\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0982 - acc: 0.9670 - val_loss: 0.1927 - val_acc: 0.9509\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9686\n",
      "Epoch 00047: val_loss did not improve from 0.19006\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0948 - acc: 0.9686 - val_loss: 0.1902 - val_acc: 0.9518\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0907 - acc: 0.9695\n",
      "Epoch 00048: val_loss did not improve from 0.19006\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0908 - acc: 0.9695 - val_loss: 0.1969 - val_acc: 0.9506\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9687\n",
      "Epoch 00049: val_loss did not improve from 0.19006\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0930 - acc: 0.9687 - val_loss: 0.2096 - val_acc: 0.9462\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9707\n",
      "Epoch 00050: val_loss did not improve from 0.19006\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0885 - acc: 0.9707 - val_loss: 0.1919 - val_acc: 0.9509\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9704\n",
      "Epoch 00051: val_loss improved from 0.19006 to 0.18420, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_7_conv_checkpoint/051-0.1842.hdf5\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0881 - acc: 0.9704 - val_loss: 0.1842 - val_acc: 0.9520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9724\n",
      "Epoch 00052: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0826 - acc: 0.9724 - val_loss: 0.1923 - val_acc: 0.9527\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9711\n",
      "Epoch 00053: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0848 - acc: 0.9711 - val_loss: 0.2023 - val_acc: 0.9506\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9731\n",
      "Epoch 00054: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0824 - acc: 0.9731 - val_loss: 0.1892 - val_acc: 0.9534\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9739\n",
      "Epoch 00055: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0766 - acc: 0.9739 - val_loss: 0.2032 - val_acc: 0.9520\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9765\n",
      "Epoch 00056: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0710 - acc: 0.9765 - val_loss: 0.1936 - val_acc: 0.9550\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0713 - acc: 0.9765\n",
      "Epoch 00057: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0713 - acc: 0.9765 - val_loss: 0.2261 - val_acc: 0.9497\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9751\n",
      "Epoch 00058: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0732 - acc: 0.9751 - val_loss: 0.2231 - val_acc: 0.9506\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9748\n",
      "Epoch 00059: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0749 - acc: 0.9748 - val_loss: 0.1927 - val_acc: 0.9548\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9760\n",
      "Epoch 00060: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0703 - acc: 0.9760 - val_loss: 0.2078 - val_acc: 0.9525\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9755\n",
      "Epoch 00061: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0716 - acc: 0.9755 - val_loss: 0.2246 - val_acc: 0.9490\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9787\n",
      "Epoch 00062: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0642 - acc: 0.9787 - val_loss: 0.2335 - val_acc: 0.9506\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9770\n",
      "Epoch 00063: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0676 - acc: 0.9770 - val_loss: 0.2281 - val_acc: 0.9513\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9786\n",
      "Epoch 00064: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0648 - acc: 0.9786 - val_loss: 0.2280 - val_acc: 0.9495\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9780\n",
      "Epoch 00065: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0649 - acc: 0.9780 - val_loss: 0.2172 - val_acc: 0.9534\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9777\n",
      "Epoch 00066: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0669 - acc: 0.9777 - val_loss: 0.2403 - val_acc: 0.9520\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9794\n",
      "Epoch 00067: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0600 - acc: 0.9794 - val_loss: 0.2208 - val_acc: 0.9532\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9790\n",
      "Epoch 00068: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0622 - acc: 0.9791 - val_loss: 0.2180 - val_acc: 0.9550\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9804\n",
      "Epoch 00069: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0586 - acc: 0.9804 - val_loss: 0.2270 - val_acc: 0.9515\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9786\n",
      "Epoch 00070: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0617 - acc: 0.9786 - val_loss: 0.2330 - val_acc: 0.9518\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9814\n",
      "Epoch 00071: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0549 - acc: 0.9814 - val_loss: 0.2250 - val_acc: 0.9522\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9807\n",
      "Epoch 00072: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0568 - acc: 0.9807 - val_loss: 0.2082 - val_acc: 0.9550\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9819\n",
      "Epoch 00073: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0548 - acc: 0.9819 - val_loss: 0.2271 - val_acc: 0.9522\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9811\n",
      "Epoch 00074: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0562 - acc: 0.9811 - val_loss: 0.2396 - val_acc: 0.9529\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9812\n",
      "Epoch 00075: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0537 - acc: 0.9813 - val_loss: 0.2513 - val_acc: 0.9483\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9816\n",
      "Epoch 00076: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0566 - acc: 0.9816 - val_loss: 0.2401 - val_acc: 0.9502\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9816\n",
      "Epoch 00077: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0544 - acc: 0.9816 - val_loss: 0.2174 - val_acc: 0.9553\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9847\n",
      "Epoch 00078: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0478 - acc: 0.9847 - val_loss: 0.2322 - val_acc: 0.9529\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9835\n",
      "Epoch 00079: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0510 - acc: 0.9835 - val_loss: 0.2165 - val_acc: 0.9546\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9834\n",
      "Epoch 00080: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0496 - acc: 0.9834 - val_loss: 0.2229 - val_acc: 0.9546\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9845\n",
      "Epoch 00081: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0493 - acc: 0.9845 - val_loss: 0.2183 - val_acc: 0.9539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9842\n",
      "Epoch 00082: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0461 - acc: 0.9841 - val_loss: 0.2474 - val_acc: 0.9509\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0544 - acc: 0.9828\n",
      "Epoch 00083: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0544 - acc: 0.9828 - val_loss: 0.2099 - val_acc: 0.9560\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9839\n",
      "Epoch 00084: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0470 - acc: 0.9839 - val_loss: 0.2161 - val_acc: 0.9548\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9850\n",
      "Epoch 00085: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0446 - acc: 0.9850 - val_loss: 0.2275 - val_acc: 0.9562\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9842\n",
      "Epoch 00086: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0467 - acc: 0.9842 - val_loss: 0.2228 - val_acc: 0.9532\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9848\n",
      "Epoch 00087: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0457 - acc: 0.9848 - val_loss: 0.2055 - val_acc: 0.9567\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9847\n",
      "Epoch 00088: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0459 - acc: 0.9847 - val_loss: 0.2453 - val_acc: 0.9541\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9855\n",
      "Epoch 00089: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0429 - acc: 0.9855 - val_loss: 0.2418 - val_acc: 0.9553\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9851\n",
      "Epoch 00090: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0441 - acc: 0.9851 - val_loss: 0.2273 - val_acc: 0.9562\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9858\n",
      "Epoch 00091: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0419 - acc: 0.9858 - val_loss: 0.2216 - val_acc: 0.9569\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9862\n",
      "Epoch 00092: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0408 - acc: 0.9862 - val_loss: 0.2321 - val_acc: 0.9574\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9849\n",
      "Epoch 00093: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0454 - acc: 0.9849 - val_loss: 0.2264 - val_acc: 0.9581\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9870\n",
      "Epoch 00094: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0391 - acc: 0.9870 - val_loss: 0.2195 - val_acc: 0.9534\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9859\n",
      "Epoch 00095: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0428 - acc: 0.9859 - val_loss: 0.2175 - val_acc: 0.9560\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9872\n",
      "Epoch 00096: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0389 - acc: 0.9872 - val_loss: 0.2292 - val_acc: 0.9562\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9882\n",
      "Epoch 00097: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0372 - acc: 0.9882 - val_loss: 0.2373 - val_acc: 0.9536\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9865\n",
      "Epoch 00098: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0418 - acc: 0.9865 - val_loss: 0.2353 - val_acc: 0.9539\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9862\n",
      "Epoch 00099: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0409 - acc: 0.9862 - val_loss: 0.2386 - val_acc: 0.9548\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9868\n",
      "Epoch 00100: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0393 - acc: 0.9868 - val_loss: 0.2448 - val_acc: 0.9515\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9881\n",
      "Epoch 00101: val_loss did not improve from 0.18420\n",
      "36805/36805 [==============================] - 51s 1ms/sample - loss: 0.0346 - acc: 0.9881 - val_loss: 0.2227 - val_acc: 0.9576\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xl8VNXd+PHPmX3JvgIJEDYFEQiboAhabd1FrVW02rpU7WKt/nzqU2tbS2vbx63V2tpaF1z6uD5aq7ZY6wKiFq2AKChQtiAECNkzyexzz++PM9kggQCZBDLf9+s1r2Rmzr33e2e53znLPVdprRFCCCEAbP0dgBBCiEOHJAUhhBBtJCkIIYRoI0lBCCFEG0kKQggh2khSEEII0UaSghBCiDaSFIQQQrSRpCCEEKKNo78D2F8FBQW6rKysv8MQQojDyvLly2u01oX7KnfYJYWysjKWLVvW32EIIcRhRSm1pSflpPlICCFEG0kKQggh2khSEEII0eaw61PoSiwWY9u2bYTD4f4O5bDl8XgoLS3F6XT2dyhCiH40IJLCtm3byMzMpKysDKVUf4dz2NFaU1tby7Zt2xgxYkR/hyOE6EcDovkoHA6Tn58vCeEAKaXIz8+XmpYQYmAkBUASwkGS108IAQMoKexLIhEiEqnEsmL9HYoQQhyy0iYpWFaYaHQHWvd+UmhoaOAPf/jDAS17xhln0NDQ0OPy8+fP5+677z6gbQkhxL6kTVJQyuyq1lavr3tvSSEej+912YULF5KTk9PrMQkhxIFIm6TQvqu9nxRuvvlmNm7cSHl5OTfddBOLFy9m9uzZzJ07l6OOOgqAc889l6lTpzJ+/HgefPDBtmXLysqoqamhoqKCcePGcfXVVzN+/HhOOeUUQqHQXre7cuVKZs6cycSJEznvvPOor68H4L777uOoo45i4sSJXHTRRQC8/fbblJeXU15ezuTJkwkEAr3+OgghDn8DYkhqR+vX30Bz88ounkmQSASx2bwotX+7nZFRzpgx93b7/O23387q1atZudJsd/HixaxYsYLVq1e3DfFcsGABeXl5hEIhpk+fzvnnn09+fv5usa/n6aef5qGHHuLCCy/khRde4NJLL+12u1//+tf53e9+xwknnMCtt97Kz372M+69915uv/12Nm/ejNvtbmuauvvuu7n//vuZNWsWzc3NeDye/XoNhBDpIY1qCn07uuaYY47pNOb/vvvuY9KkScycOZOtW7eyfv36PZYZMWIE5eXlAEydOpWKiopu19/Y2EhDQwMnnHACAJdddhlLliwBYOLEiVxyySX87//+Lw6HSYCzZs3ixhtv5L777qOhoaHtcSGE6GjAHRm6+0VvWRFaWlbhdg/H5drn7LEHze/3t/2/ePFi3njjDZYuXYrP5+PEE0/s8pwAt9vd9r/dbt9n81F3/v73v7NkyRJeeeUVfvnLX7Jq1SpuvvlmzjzzTBYuXMisWbN47bXXGDt27AGtXwgxcKVRTSF1fQqZmZl7baNvbGwkNzcXn8/H2rVref/99w96m9nZ2eTm5vLOO+8A8Oc//5kTTjgBy7LYunUrX/jCF7jjjjtobGykubmZjRs3MmHCBH7wgx8wffp01q5de9AxCCEGngFXU+iOUnYgNaOP8vPzmTVrFkcffTSnn346Z555ZqfnTzvtNB544AHGjRvHkUceycyZM3tlu48//jjf+ta3CAaDjBw5kkcffZREIsGll15KY2MjWmu+973vkZOTw09+8hMWLVqEzWZj/PjxnH766b0SgxBiYFFa6/6OYb9MmzZN736RnTVr1jBu3Li9Lqe1prl5OS7XYNzuklSGeNjqyesohDg8KaWWa62n7atc2jQfmWkcbCmpKQghxECRNkkBWk9gk6QghBDdSaukAHa0TvR3EEIIcchKq6QgNQUhhNi7tEoK0qcghBB7l1ZJQWoKQgixd2mVFA6lmkJGRsZ+PS6EEH0hZUlBKTVUKbVIKfWZUupTpdT1XZRRSqn7lFIblFKfKKWmpCoes71DJykIIcShKJU1hTjwX1rro4CZwLVKqaN2K3M6MCZ5uwb4YwrjwexuaqbOvv/++9vut14Ip7m5mZNPPpkpU6YwYcIEXnrppR6vU2vNTTfdxNFHH82ECRN49tlnAdixYwdz5syhvLyco48+mnfeeYdEIsHll1/eVvaee+7p9X0UQqSHlE1zobXeAexI/h9QSq0BSoDPOhQ7B3hCm9Oq31dK5SilBieXPTA33AAru5o6G9xWBEvHwL6fTTTl5XBv91Nnz5s3jxtuuIFrr70WgOeee47XXnsNj8fDiy++SFZWFjU1NcycOZO5c+f26HrIf/nLX1i5ciUff/wxNTU1TJ8+nTlz5vDUU09x6qmn8qMf/YhEIkEwGGTlypVUVlayevVqgP26kpsQQnTUJ3MfKaXKgMnAB7s9VQJs7XB/W/KxA08K+9T703pMnjyZXbt2sX37dqqrq8nNzWXo0KHEYjFuueUWlixZgs1mo7KykqqqKgYNGrTPdb777rtcfPHF2O12iouLOeGEE/jwww+ZPn06V155JbFYjHPPPZfy8nJGjhzJpk2buO666zjzzDM55ZRTen0fhRDpIeVJQSmVAbwA3KC1bjrAdVyDaV5i2LBhey+8l1/0sch2otHtZGRM7dGv9f1xwQUX8Pzzz7Nz507mzZsHwJNPPkl1dTXLly/H6XRSVlbW5ZTZ+2POnDksWbKEv//971x++eXceOONfP3rX+fjjz/mtdde44EHHuC5555jwYIFvbFbQog0k9LRR0opJyYhPKm1/ksXRSqBoR3ulyYf60Rr/aDWeprWelph4cFcCyF102fPmzePZ555hueff54LLrgAMFNmFxUV4XQ6WbRoEVu2bOnx+mbPns2zzz5LIpGgurqaJUuWcMwxx7BlyxaKi4u5+uqrueqqq1ixYgU1NTVYlsX555/PL37xC1asWNHr+yeESA8pqyko81P8EWCN1vo33RR7GfiuUuoZYAbQeFD9CfuMySQFra22qbR7y/jx4wkEApSUlDB48GAALrnkEs4++2wmTJjAtGnT9uuiNueddx5Lly5l0qRJKKW48847GTRoEI8//jh33XUXTqeTjIwMnnjiCSorK7niiiuwLJPs/ud//qdX900IkT5SNnW2Uup44B1gFe0/zW8BhgForR9IJo7fA6cBQeAKrfWyLlbX5kCnzgaIxWoIhyvw+ydgs7n3WT7dyNTZQgxcPZ06O5Wjj95lHxdGTo46ujZVMeyptaYgk+IJIURX0uqM5lRefU0IIQaCtEoKqexoFkKIgSCtkkLHjmYhhBB7SqukIDUFIYTYu7RKClJTEEKIvUurpNC+u707+qihoYE//OEPB7TsGWecIXMVCSEOGWmVFFJVU9hbUojH43tdduHCheTk5PRqPEIIcaDSKimkqk/h5ptvZuPGjZSXl3PTTTexePFiZs+ezdy5cznqKDNb+LnnnsvUqVMZP348Dz74YNuyZWVl1NTUUFFRwbhx47j66qsZP348p5xyCqFQaI9tvfLKK8yYMYPJkyfzxS9+kaqqKgCam5u54oormDBhAhMnTuSFF14A4B//+AdTpkxh0qRJnHzyyb2630KIgadPZkntS3uZORtQJBJHopQT236kw33MnM3tt9/O6tWrWZnc8OLFi1mxYgWrV69mxIgRACxYsIC8vDxCoRDTp0/n/PPPJz8/v9N61q9fz9NPP81DDz3EhRdeyAsvvMCll17aqczxxx/P+++/j1KKhx9+mDvvvJNf//rX3HbbbWRnZ7Nq1SoA6uvrqa6u5uqrr2bJkiWMGDGCurq6nu+0ECItDbiksG+9Oztqd4455pi2hABw33338eKLLwKwdetW1q9fv0dSGDFiBOXl5QBMnTqVioqKPda7bds25s2bx44dO4hGo23beOONN3jmmWfayuXm5vLKK68wZ86ctjJ5eXm9uo9CiIFnwCWFvf2iB2hu3oTdnonXO2LvBQ+S3+9v+3/x4sW88cYbLF26FJ/Px4knntjlFNpud/t8THa7vcvmo+uuu44bb7yRuXPnsnjxYubPn5+S+IUQ6SnN+hRap7ro3dFHmZmZBAKBbp9vbGwkNzcXn8/H2rVref/99w94W42NjZSUlADw+OOPtz3+pS99qdMlQevr65k5cyZLlixh8+bNANJ8JITYp7RLCmDr9dFH+fn5zJo1i6OPPpqbbrppj+dPO+004vE448aN4+abb2bmzJkHvK358+dzwQUXMHXqVAoKCtoe//GPf0x9fT1HH300kyZNYtGiRRQWFvLggw/y5S9/mUmTJrVd/EcIIbqTsqmzU+Vgps4GCAbXARqfr+fXNkgXMnW2EANXT6fOlpqCEEKINmmXFMwJbJIUhBCiK2mXFKSmIIQQ3Uu7pKCUJAUhhOhO2iUF6P0hqUIIMVCkXVIwfQqaw23UlRBC9IW0SwqHyoV2MjIy+nX7QgjRlbRLCnKhHSGE6F7aJoXerCncfPPNnaaYmD9/PnfffTfNzc2cfPLJTJkyhQkTJvDSSy/tc13dTbHd1RTY3U2XLYQQB2rATYh3wz9uYOXObufORus4lhXCZvN3SBB7Vz6onHtP636mvXnz5nHDDTdw7bXXAvDcc8/x2muv4fF4ePHFF8nKyqKmpoaZM2cyd+5clOp+ptaupti2LKvLKbC7mi5bCCEOxoBLCj3Xex3NkydPZteuXWzfvp3q6mpyc3MZOnQosViMW265hSVLlmCz2aisrKSqqopBgwZ1u66uptiurq7ucgrsrqbLFkKIgzHgksLeftEDxOMBQqF1eL1H4HBk9dp2L7jgAp5//nl27tzZNvHck08+SXV1NcuXL8fpdFJWVtbllNmtejrFthBCpEra9in0dkfzvHnzeOaZZ3j++ee54IILADPNdVFREU6nk0WLFrFly5a9rqO7Kba7mwK7q+myhRDiYKRdUkjVkNTx48cTCAQoKSlh8ODBAFxyySUsW7aMCRMm8MQTTzB27N5nZu1uiu3upsDuarpsIYQ4GGk3dbZlRWhpWYXbXYbLVbDvBdKITJ0txMAlU2d369A4eU0IIQ5FaZcU2vsUZP4jIYTY3YBJCj1vBpOaQlcOt2ZEIURqDIik4PF4qK2t7dGBzZw4JtNnd6S1pra2Fo/H09+hCCH62YA4T6G0tJRt27ZRXV3do/KRSA02WxCnsznFkR0+PB4PpaWl/R2GEKKfDYik4HQ628727YmlS08nJ+cExo17PIVRCSHE4WdANB/tL7vdTyLR0t9hCCHEISdlSUEptUAptUsptbqb509USjUqpVYmb7emKpbd2e1+LCvYV5sTQojDRiqbjx4Dfg88sZcy72itz0phDF2y2XxSUxBCiC6krKagtV4C1KVq/QdDmo+EEKJr/d2ncKxS6mOl1KtKqfF9tVFpPhJCiK715+ijFcBwrXWzUuoM4K/AmK4KKqWuAa4BGDZs2EFvWJqPhBCia/1WU9BaN2mtm5P/LwScSqkuZ6jTWj+otZ6mtZ5WWFh40NuW5iMhhOhavyUFpdQglbwupVLqmGQstX2xbbvdJ81HQgjRhZQ1HymlngZOBAqUUtuAnwJOAK31A8BXgG8rpeJACLhI99EEPDabH8sKobXV4+s0CyFEOkhZUtBaX7yP53+PGbLaNwIB2LQJxo7FbvcDYFmhtv+FEEL0/+ijvrNwIZSXw6ZN2O0+AOlXEEKI3aRPUihI9mFXV2OzmdqBJAUhhOgs/ZJCTU2H5iPpbBZCiI7SJym0DmWtqcFuzwAgHg/0Y0BCCHHoSZ+kkJ9v/lZX43IVARCLVfVjQEIIcehJn6TgdkNmJtTU4HINAiAa3dnPQQkhxKElfZICmH6FmhqcziJAEYns6O+IhBDikJJeSaGwEGpqsNmcOJ0FUlMQQojdpFdSKCiA5HWcXa7BRKNSUxBCiI7SLynU1ADgcg2SmoIQQuwmjZOC1BSEEGJ36ZUUCguhpQVCobaaQh/NwSeEEIeF9EoKHc5qdrkGoXWMeLy+f2MSQohDSNomBbd7MIA0IQkhRAdpmxTkBDYhhNhTeiWFDvMfuVympiAnsAkhRLv0Sgodps+WmoIQQuwpvZJCTg7YbMmZUjOx2XzSpyCEEB2kV1Kw2yEvD2pqUErJCWxCCLGb9EoKYPoVZKoLIYToUvolBZnqQgghupXWScHtlpqCEEJ01KOkoJS6XimVpYxHlFIrlFKnpDq4lNitphCPN5BIhPs5KCGEODT0tKZwpda6CTgFyAW+BtyesqhSKXlNBbRuO1dBmpCEEMLoaVJQyb9nAH/WWn/a4bHDS0EBxOPQ2CjnKgghxG56mhSWK6X+iUkKrymlMgErdWGlUKepLmT+IyGE6MjRw3LfAMqBTVrroFIqD7gidWGlUMekMHQ4IDUFIYRo1dOawrHAOq11g1LqUuDHQGPqwkqh1vmPqqtxuYoAm9QUhBAiqadJ4Y9AUCk1CfgvYCPwRMqiSqUONQWl7DidhVJTEEKIpJ4mhbg2lyg7B/i91vp+IDN1YaVQh6QAcq6CEEJ01NM+hYBS6oeYoaizlVI2wJm6sFLI7we3W85qFkKILvS0pjAPiGDOV9gJlAJ3pSyqVFJqj/mP5JoKQghh9CgpJBPBk0C2UuosIKy1Pjz7FGCPs5pjsSq0PjxH2AohRG/q6TQXFwL/Bi4ALgQ+UEp9JZWBpVSnpDAYrePEYrX9HJQQQvS/nvYp/AiYrrXeBaCUKgTeAJ5PVWApVVAAFRUAnc5qdrkK+zEoIYTofz3tU7C1JoSk2v1Y9tDTOv8R4HaXABCJbO3PiIQQ4pDQ0wP7P5RSrymlLldKXQ78HViYurBSrKAAGhogFsPnOxKAYHBtPwclhBD9r6cdzTcBDwITk7cHtdY/2NsySqkFSqldSqnV3TyvlFL3KaU2KKU+UUpN2d/gD1jruQp1dTid+TidBZIUhBCCnvcpoLV+AXhhP9b9GPB7uj/z+XRgTPI2A3PW9Iz9WP+Ba00K1dVQXIzPN1aSghBCsI+aglIqoJRq6uIWUEo17W1ZrfUSoG4vRc4BntDG+0COUmrw/u/CARic3Mz27QD4fOMIBtf0yaaFEOJQtteagtY6lVNZlAAde3e3JR/b40wypdQ1wDUAw4YNO/gtl5WZv8kRSD7fWGKxGqLRGlyugoNfvxDikKK1+at6cBWYRAKiUXPZFZsN7HbzeCxmbvG4uSUSZr1eL/h84HJBU5PprmxuNvc9HjOBQjgMwaC5hcMQiZh1eTyQmQkZGeB0mu3ZbO3biMU6L1tWBuPGpexlAvaj+ag/aa0fxPRpMG3aNH3QKxwyBByOTkkBIBRaJ0lB9BmtobHRDISrqTEHolYulznQ+P3m/9aDUzwOoZC5WZb5GDsc5oCxYwfs3GkOIhkZ5mBjt5sDVEuLWX9reYej/QBkWRAImFs43PlA2HowisXa1+l2Q12daX2trzflnU6zTDhsYotEzDZcLnNr3V/LMrdEwvxtZVlmnVVV5gZm/71es55WsZhZfzhslrHbzfNutynv85ly4XB7LK3/a90ek93efoBvjUMp878++CNMyvzgB3B7iq952Z9JoRIY2uF+afKx1LPbYdiwDknBpN5gcC3Z2bP6JASRWsEgVFaag27rwczpNL/i6uvNL7pIxNyiUXOQSiTMQaKlxRwgW1ray8RinQ8ogYBZdyBgtmdLNsQ2N7c/7nSag5THYw5ODQ1mu+Gw2WbHJHCostlMYnI6218PMK9BYSHk5ZkDaesB1uMxB3KPx7yera9v67qUak86rfdb5ebCmDFQVGSeCwbN65ZImOe1bv/17fGYMq3vWTRqyre0mLKtZbze9nhsNhNnJGKWczrNe2q3d65JtCay1sdbawROp3m8dZnWxNn6Sz4ahawsyMkxn7nWBBaJmO23Jq3W2oPTaZ5vbjafl9ZE2THZOZ3tNRGfD0pLU/+e92dSeBn4rlLqGUwHc6PWuu8mISora0sKHs8wbDYPLS3Sr9CbLMscIOvqzAe/9VdnaxW7ocF8oTpWlaNR87f1V53DYb44tbXmFgy2f3FCIXOAb2ho/+K53Wb5+vqeRKjBEQZnCKIZkHB1etbhaF+nw9G5WSEjA7KzTbJp/bWd0DF8mVGKhsUYkRmHaAaRFg+hEOTkakaNa8aVU4PXY8fv9ONzefFkBbBnV4F/F/m+XIb6xuKx+Tsd5CJRi4ZYFbtiFShbnDxfHvm+XHJcBSjLRTxuYhw82Nw8HrNcc3N7rK01jnhcU9NST12wAY/dh8vmw2134fCGsLtDWPYgDaEmGsNNROJRSnMGUZpVQp43D6VUMi6NLyOBJkEkEaE2WMuull00hBvI8eRQ6C8k35uPRhNLxEjoBAW+Ahy2PQ83cSvOloYtbKjbgN1mJ8+bR64nl4ROEIgEaI42k9CJtvI2ZcNld+G0Ocn2ZFPsLybDlUHMirGhbgPratYRiAbwOrx4nV4AgrEgLdEW7DY7xf5iijOKcdgcbA9sp7KpkmAsSL4vn3xvPn6Xn3A8TDgeJhQLEUlEiMQjRBIRYokY0USUkBUn3uEWs2LEEjEAsnKGU5A3mqFZQwlEA9QEa6gL1RG3EjRoiwYgx5NDvi+fDG8ePmUnV1tY2iKaiBJJRIgmouR4chicMZgifxHbmrbxSdUnvFP1MTNCMyjh1AP9SvZIypKCUupp4ESgQCm1DfgpyZlVtdYPYM5zOAPYAATp6yu5lZXBq68mY7Xj9R4hI5CAWCLG57U1fFqxi007q6kN1dIQqSEQC5Cth5KTOBJPZDhbA5vZHFpJZexTAi1xWhpdNDc5ScQcoO1gOYg2Z0AoByLZ4ApA5g7I2Am2uDkAJ5zQPAjqxkDtGOz+RmwlK1HFH4M9hg4MQTeU4MhowlG6ksSElSibRWZwElnBctzKjyd7DVm+tbTYK4nRQiNBQJNnyyfXXUCmK4tEQpGIQ8yKEbc3EaGJkNVIc6KBmNX+c91t9+B1+IhZUaKJiPnSO9w4HV5crgyGZQ9jZO5IhmQOoTJQyYa6DVQ0VBCIBAjHw50OXu3rdJPlziIQNWX20Jy8dTAsexiZrsy2A9Kull1EEpH2Ah1mZCnyFzEkcwg+p4/mqmYCHwQIxUNEE1FiiRg2ZSPLnUWWOwtLW2xt2kpzdLcN9oBN2VAoLG2h2f/2FafNSVlOGSNyR2Bpi8ZwIw3hBrY0biGaOLgqk9fhJZqIdvn694XWJGVpi1A8lLLtKBS3zL6FU0cfpklBa33xPp7XwLWp2v4+lZWZRthIBNxufL6xBALL+y2cA9ESbWFd7TrWVK+hMlBpvrBaE47FqAu0UN8cpDkcxZbwYYv7iYYd7ArUURuqIRiJ4G0ej6dhMipQwi7/WzQW/Z1I0VKw9fDL5QR0BvYsNyo3hrZH0cSxSIDq+sDht2fhtLtI6BhxHe30JUokb9nubLxOL1XNVWg0caA0q5TyQeXYlI2Pd77P+sZnIVl2XOE4hmWXk+HMwOc0jcq1oVpqgjUEooG29duVnWxPMVnuMWS5ssj15pLjycHr8NIcbaYp0kRLrAWX3YXb7sZhcxBJRAjFQjRFm9jSsIXFFYvZHthOSVYJo3JHccboM8j2ZLf9Mm09QDhsDlpiLTSEG2gMN5LhyqDIX0SBrwBLW7TEWgjGgmS6MinOKKbIX0R1SzVratawtmYtoXgIt92N2+Gm0FdIWU4Zw7OH43a4qQvVtf063x7YTmWgknA8TJG/iAxXBl5HexwJnSAQDdAUMYMFTx11KsOyh5HnzSMUD9ESbSFmxfA4PHgdXnxOX1sScdqd7GzeSWVTJdVBM6twa3Jw2Bw4bA6cdif53nyK/EXkeHJoCDdQHaymNljb9qteKcXWxq1sqDdJ1GV3ke/LZ0TuCM4bex5jC8YyJn8MWmvqQnXUh+tx2BxkuDLwO/047e2z9CesBNFElGgiSmOkkarmKqpaqvA6vBxZcCRH5h9Jrje37Zc+gN/lx+f0EbfibeVjiRglWSUMyRyC3+mnLlRHTbCGllhL23vpcXja3gO33Y3T7sRld7Xtu8PmwKbaB3BqrakOVrOhbgOVTZVkubMo8BWQ683FaXNiUzY0moZwQ1sNQmuNUqrttWrdTn2onh3NO6hqrmJw5mAmFU9ifNF4MlwZPftuHoTDoqM5JYab6zPz+ecwZgw+3ziqq58nkQhjt3t6bTOWtgjGgngdXuw2e9vj4XiY1btWs6l+EzsCO9jZvJNgLNj2YasN1bK2Zi3ratcRjAXbqr1O5WJHUzW7WnbRFN/LJH5xF8T85te4MwiuFnOgDuVgi+TjsDmIlvwVStt7+/Iikxkf/j6lGcMZml9IWWEhhf5C8jz5ZLozaWQLO+PrqIpu5sjiMqaXljMitwzVxZAOS1sEIgEawg00hBvIdGcyKGNQ20G7VV2ojvW161lft54MVwaTB01mWPYwlFLErTg7m3ficXgo8HUeAFAfqiccDzMoY1CX20+l1i+yOPyMzhvd5ePFGcUHvW6lFEX+Ior8RXstV5rVBx0DByF9k0LHYaljxiRHIFmEQuvJyJhwwKuNJqI8+cmT3PvBvWys20hLzPR8OWwOhmUPY3j2cGpDtXxW/RlxK962nMPmwOf0kbASxK0EPnsWgxxHMiZ+LpHmTHbu2MXKaBXhWBSax0PwRGgqgZqxZEXHUZIxjKEldoaW2hgyxE5RsYO8PNPplZUFmZmazCyLkiF23G6zzWAsyKqqVXze+Dmzhs1iSOaQfezduORt32zKRrYnm2xPNsMZ3m25PG8eM0pnMKN0z/MWHTZHt1+gXG9uj+JIBUkIYiCTpLDbsNRgcO1+JwWtNZ9Wf8rC9Qv53b9/x7ambUwqnsQ3p37TVIFdfhrCDVQ0VFDRUMHgjMGcPuosMgJTiG4/gqbtg6mqyGPDehtr10Kk2VzRqLWv1OeDI46AOWNh9GgTelmZGUBVUtI+DG/vFGDv9IjP6ev2gCyESE/pmxT2OFfhCEDt88zmrY1bueO9O6gOVmNpi0g8wr8r/01VixlcPWf4HB46+yFOHXVqp1+UjY3w0UewvAIWL4b7F5vRIWDCGDYMRo6EK66AsWPN/0OGmNGjE47VAAAgAElEQVQk+fntQx6FECKV0jcpOBwwdGhbUrDbfXg8w7sdgRRLxPjtB79l/uL5JHSCspwybMqGTdk4eeTJfHHEFzl55MkMyzZnXDc0mIP/G2/AW2/Bmg65ZtQouPRS+NKXYPp0c/C327vcrBBC9Kn0TQrQ6VwFoNuJ8d6ueJvvvvpdVu9azdlHnM19p99HWU7ZHuW2bIHfPgYvvwxLlpgx4j4fzJkDX/0qTJ1qbkV774cSQoh+I0nhtdfa7vp8Y2loWILWFkrZ2B7Yzvf/+X2eXv00w7OH89d5f+Wcsed0WkUsBq+8An/6E/zzn+axo46Cm26C006DmTPbT/MXQohDnSSFTucqjMOygkQiW3l18wou++tlRBNRbp1zKz84/gedhlPG4/DYY/Czn8G2beb08/nz4ZJLTGewEEIcjiQpaA1bt8Lo0fh8Y7E03PrWLdz14VPMKJnBk19+klF5o9oW0Rpeegl++ENYu9bUBO6/H844o/PEXUIIcThK78NY6wlsFRUwejR29zjmf6Z4p+YpLpt0GQ+c9QAeR/uJbKtWwfXXw6JFZoTQX/4C557bs+l4hRDicJDeAx07nKsQt+Jc+tJVvFuj+a/xZTx6zqNtCSEUguuug/Jy+PhjUzNYtQrOO08SghBiYEnvmkJJCdjt6IrNfPtv3+bldS9z6/QvcZJ/EYlECw5HBjt2mNrAhx/CtdeaPoS8vP4OXAghUiO9k0LyXIVbm17m4Y9W86PZP+L68jl88snrNDX9iy1bTmHuXDP1c2tTkRBCDGTp3XwEvD0ph1/kr+Ybk7/BbV+4jays41DKwb/+tZbZs02Z996ThCCESA/pXVMAHhrTRE5E8bvTf4dSCocjA6VO4DvfOY/sbPjgA3PGsRBCpIO0TgqN4UZeyPicKz7UeLWZZ0JruOOO31BZOZg33wwyZEiPZpsTQogBIa2bj5799FnCxLniI8y5CsAf/wgLF07kqqt+xMSJ7/RvgEII0cfSOik8uvJRxvtHMG07sHYt69fD//t/cPrpcS666B4aGhb3d4hCCNGn0jYprKlew/vb3ueK6VejnE5YsoTf/tY8t2CBg+zs6ZIUhBBpJ22TwmMrH8Ou7Fw69UqYMYP615fx6KNmNtNBgyAn50Samj4kHt//i5wLIcThKi2TQtyK88QnT3DmEWeaa7N+4Qs8snIKwaCZxgJMUoAEjY1L+jNUIYToU2mZFN7a/BY7m3dyRfkVAMRnf4Hf6e9y4oRaystNmezs47HbM6mufr4fIxVCiL6Vlknh9Y2v47K7OGXUKQD8tfo4Pmc4N4x6pa2M3e6loOA8qqv/gmVF+itUIYToU2mZFN6qeItjS49tuz7CvX9wM9JTyVlb/9ipXHHxV0kkGqmtfbU/whRCiD6XdkmhLlTHRzs+4qQRJwFm1tP33oPvnfAJ9o+WQWNjW9mcnJNxOgvZtevp/gpXCCH6VNolhbcr3kajOXnEyYC5lCbAxddkgmXBO+0nrNlsDgoLL6C29mXi8UB/hCuEEH0q7ZLCm5vfxO/0M71kOmAu0TxlChSdPtVcTHnx4k7li4u/imWFqal5qR+iFUKIvpV2SeGtzW8xe/hsXHYXjY2wdCmceirg9cKxx+6RFLKyjsXtHiZNSEKItJBWSWFHYAdratZwUpnpT3jrLUgkkkkB4MQT4aOPoKGhbRmlbBQVXUR9/T+JxWr7PmghhOhDaZUUFlUsAmjrZH7tNcjIMBUEAL7wBdOv8Grn0UbFxV9F6zg7dz7el+EKIUSfS6uk8Nbmt8j15FI+qBytTVI46STTlQDA8cfDmDFwzz1mDu2kjIxJ5OScxNatd5FIhPoneCGE6ANplRTe3PwmJ5adiN1mZ8MGqKjo0HQEYLebaVI//BDefbfTsmVlPyUa3cn27Q/0acxCCNGX0iYpbK7fTEVDRaemI9gtKQBcdhnk58Ovf93p4ZycOeTknMTnn99BIhHsg4iFEKLvpU1SWFyxGOjcnzByJIwatVtBnw++8x14+WX4z386PVVWNp9YrIrt2//UBxELIUTfS5ukcFn5Zaz85krGFYwjGoVFi7qoJbS69lrT0XDPPZ0ezsmZTU7OyVJbEEIMWGmTFGzKxqRBk1BK8cEH0NKyl6RQXAxf+xo89hhUV3d6qrW2UFn5u5THLIQQfS2lSUEpdZpSap1SaoNS6uYunr9cKVWtlFqZvF2VynharVtn/rZOk92lG2+EcBj+1LmpKCfnePLzz2LLll8Sje5KXZBCCNEPUpYUlFJ24H7gdOAo4GKl1FFdFH1Wa12evD2cqng62rzZDDQqKdlLoXHjTFXiD3+AaLTTU6NG3Y1lhdi8+dbUBiqEEH0slTWFY4ANWutNWuso8AxwTgq312MVFTBsGDgc+yh4/fWwYwe88EKnh32+Ixky5Dvs2PEQzc2rUhanEEL0tVQmhRJga4f725KP7e58pdQnSqnnlVJDUxhPm4oKKCvrQcFTT4UjjoDf/naPp8rKforDkc3GjTeiO5zoJoQQh7P+7mh+BSjTWk8EXge6nEdCKXWNUmqZUmpZ9W4dvweix0nBZoPrroMPPjC3DpzOPMrKfkp9/Rsyg6oQYsBIZVKoBDr+8i9NPtZGa12rtW691uXDwNSuVqS1flBrPU1rPa2wsPCgggqHYft2GDGihwtcdhlkZXVZWxgy5Dv4/ZNYt+4qwuFtBxWXEEIcClKZFD4ExiilRiilXMBFwMsdCyilBne4OxdYk8J4APj8c/O3RzUFgMxMuPJK+L//M9mkA5vNyfjxz6F1hM8+uwjLivVqrEII0ddSlhS01nHgu8BrmIP9c1rrT5VSP1dKzU0W+55S6lOl1MfA94DLUxVPq4oK87fHSQFME5LW8LOf7fGUz3cERxzxIE1N77F58096I0QhhOg3+xp/c1C01guBhbs9dmuH/38I/DCVMexu82bzt8fNR2Dmw/je9+Dee+Eb34Bjjun0dHHxxTQ0vM3WrXeQlTWDwsLzei9gIYToQ/3d0dznKirA6YTBg/dZtLP582HQIPj2t82VeXYzevQ9ZGYew2efzaO6+sXeCFUIIfpcWiaF4cPNyWv7JSsLfvMbWLFij7OcAex2L5Mm/ZPMzKl8+ukF7Nr1bK/EK4QQfSntksLmzfvZn9DRvHnmqjw/+hFUVe3xtMORzcSJ/yQ7+zg+++yrVFXJdZ2FEIeXtEsKPT5HoStKwf33QygEs2bBJ5/sUcThyGTixFfJzp7N2rVfp7Z2YRcrEkKIQ1NaJYVQyPzA369O5t2NHQtvvQXBIMycCU89tUcRu93PhAkv4/dP4tNPz6eh4d0uViSEEIeetEoKBzQctSvHHWf6FqZNg0sugR/8ACyrUxGHI4uJE1/F7R7GqlVn0di49CA3KoQQqSdJ4UANGgRvvgnf+hbceae5/kIk0qmIy1XIpEmv43Bk89FHx/HZZ5cQCm3qhY0LIURqpGVSOKjmo46cTjO19v/8j2lGOv10aGzsVMTjGcb06Z8wbNgt1NS8yL//PZaNG39AIhHupSCEEKL3pFVS2LwZ3G5zYbVeoxTcfDM88QS88w4ceyxs2NCpiMORzciRv2TGjA0UF1/K1q13snz5NAKBFb0YiBBCHLy0Sgqt5yjYUrHXX/savP666ck+5hjTGb0bt3sIY8cuYMKEV4nH61mxYgZbtvwSra0uViiEEH0v7ZJCrzUddeXEE+HDD2HIEDjlFPjd78ycSbvJzz+N6dNXU1j4FTZv/jGrVp1NLFaXwsCEEKJn0iopHNSJaz01ciT8619wxhlmvqQrrzTzdbcG8OMfw5/+hNOWxbhxTzFmzB+or3+dZcum0Nj4foqDE0KIvUubpNDcDDU1fZAUwEyJ8de/wq23wmOPwZw58OUvw+jR8KtfmRFLM2agli+npOTbTJ78LqD56KNj+fTTiwgGN+xrC0IIkRJpkxS2bDF/U9p81JHNZqbafvFFWLsW3n7bdEhv3QrPPGOuzXDMMXDRRWS9Wcn0o//N8OE/oWHLy6x7bCzrX5/Ljh0LCIU2y+U+hRB9Rh1uB5xp06bpZcuW7fdyf/sbnH02vP8+zJiRgsD2prYWfD7wetsfa2yE226Dxx83VRi/H3JyoNJcnM5ywpZL4POvgi9nEqNG3UVe3pf6OHAhxEChlFqutZ62r3IpvZ7CoWTQIHMphFGj+mHj+fl7PpadDXffDbffDkuWwAsvQCAA48fD2LGoZ59lxGNPU7p0MJWnbSO0+RRaPs/Fkzka++XfggsvhIyMPt8VIcTAljY1hcPSK6+Y6zdUVmJleQmURXHWJ/BtBe33wNevQP3iF5CX19+RCrFvmzbBa6/B0UebCSV7a2x4NGrOF3I6e2d9A1RPawpp06dwWDr7bHMiXGUltoYWvB/upGrxrXzyh2x2zg7Dg38kceQIrKeeMENfEwkzwmnVqs4XAtIaPvrI9GXU1vbf/ohDz7p18Oije0zR0mt27YLf/tZMHjlqFHznO2bgxdChcP317dMMHKhVq2DMGDMfWSBwcOu66y4T15Qp5rt3003m9UmFWMzE/tlnpn8xEDAXkP/gA9MPedttcP75puXgv//bzObZR6SmcBhKJEJUVf2ZurfuYNgvNpG1DmKlWThqQqhwzBTKzjZfvpISWLjQfOAAHA447TT40pdMp/eaNSZRfPOb5gS8/b76UC/5/HMzaisnp3+2fyiprzfvSXGxaSJUau/lEwkzQeMbb5hbfT0ceSSMGwelpWZ5pcz6vvAF8HjMBI733Qc//KEZMj1mDNxzD5x55p7rr62Fd9+Fjz8208Vv3QqTJ5vP15w5ZhsdWZap5T76KPz97xCPQ3k5XHwxzJ0LK1fCc8+Zz6XTaS5eddVVZtnFi2HBAhPPd7+791rwG2+YA6fHY2I86STTeehy7Vn200/NwXfUKBg2zHwPOnrySbj0Upg923wOKyvNATsaNd+Xa66B6dPN9wnM6/DXv8KyZWad48ebGtCkSab/sCv/+Y9pJl68GN57D1paut83pcxoxdJSWLTIvB4LFsDxx3e/zD70tKaA1vqwuk2dOlULw7IsXVf9T1158wRdPUvpzy9Er/0+et1PsnTt+WU6NrxAWx63tuaerfUjj2j93ntaf//7WpeWag1au1xaT5ig9fjx5v64cVo/9ZTWn32mdW2t1pbV1Ua1/s9/tI5Gexbku+9qfeKJWl9xhdbr1+/5/PbtWn/zm1rb7VoPG6b16tUH96Ic7v71L62zssz7AVp7PFpfeaXWkcieZaNR876OGNFeftIkrU87TeuyMq2Van+89ZaRofWFF2p9wgnm/tlna/3cc1ofeaS5f9xx5r367/82n5UpU9rXo5TWY8aYZTMz29d5/vlaf/yxientt7WeOtU8PmiQ1jfd1P17WlGh9UknmbInn2xiB62zs81fv1/rG27Q+le/0vqCC7Q+4gjzWT3nHK2vvlprh8N8fj//XOtHHzXLXHqp1omE1sGg1v/+t9Y/+5nWRx3V+TVwOs1+vvqq+Ty/9575LpxwQufXeedOrX/+c7MfrctmZ7d/f5Qyr5vP1/683a71xIlaX365eQ1/+Uutb7vNvI6tZSZM0Praa7V+8kmtn35a6wce0PrOO7V+8EGtX3lF62XLtA4E2uN4/fX29/NXvzrgjxawTPfgGNvvB/n9vUlS6FoiEdFNTcv0tm1/1J999jX9r38N04sWoRe9hX7nnVz9ySdn6y1b7tJNTcu1FY+aL1IsZha2LK1feMEkhY5fHq9X6298Q+tVq0y5t9/W+thjzXMTJ2q9dGn3ATU1af3d75oP8pAh5uBmt5svy333af3Tn5ovts9nvtxXX22+fNnZWr/5Zvt64nFz66iqSusXXzRfpqefNl/uZ57R+sYbtZ492+zH2Web+488YpJYVwlufwUC5uBz+eXtB5SD0dzced8WLzYHwtGjtV6wQOu77jIJAbQ+5RTzmmqtdShkDiCtyWDqVK3//GfzunTU0mIOvJs3a71pk4n5mmu0LioyB/VHHmnfh2hU69/8RuvJk8375XSa92XOHHNgfPfdzgeqeFzrFSu0/vGP25NYebn5W1qq9RNPtH++9iaR0Pr3vzf7PX681g8/bPZv1Sqtv/Y185kBc1A891yt58415Xw+rc86S+uGhvZ1/eIXpuzQoVrbbO0H7jlzzDYWLTL7fPPNZn2tSbCw0LzmNTVdxxiJmM/+/fdr/Z3vmKT60EMmabTuw8aN5jP5ox9pfeqpWg8ebD7zrd+l6dPN67tt275fk64EAub79MYbB7a87nlSkOajASwUqqCx8W0aGt6hsXEJodB6AByOXLKzj8fnG4fPdwQ+3zgyM4/BppWp1lZWmjmcVq82s7+GQubiQmvXmurzVVfBI4+YcldcYarbK1eaNtJIxHQgRqPm/+uug1/+0pw9eOed8Mc/tp/hnZMDp54Kv/iFqSpv2WLOBF+/3jRvbd4MGzea5odBg8y26+v3mHCwjdttmjWKi81yGza0b2vwYJg61cTq9ZoRYVOnmnNFhg83bby1taZtNyenvdlizRpYvtycZ/J//2eq/B6PWe+cOeZkxOOO27OJZ/Nm0zzyt7+Z5oLJk83rduGF5rW6/37TlJCRYaZEKS+Hn//cnF355psm3lYLFpjmi8mT4ayzzMy8u3aZ+OfPN00++2pi6iiRME08e+uY1ck+qt2bWbpSVwf33mv25+KL4cYbu29C6Y5ltTdzdVRdbWLIzd0zvt3Lag133GHGnU+caJpyjj3WTDuzu2jUNG/ddpu5YNbSpabJrbeFw+Z7kJ3d++veTz1tPpKkkEYike00NCymvv4tmpr+RSi0Ea2jADgceRQUzCU//xyysmbidg8yC9XWwoMPwksvmbOyr7vOHFSbm+GnPzWdiC6X+RJOnAiZme2d3PPmmS9lR4GA+ULm5HTdf9HQYMYOr1tn2lHHjDHrr6w0N5/PjFw57jhzMG9qMud8eDymTbfjgc6yzHreeccc1FevNgeAYNCcGxI1+952kN+dw2ESEphk8pWvmCQ4fTo8/LA5oFRVmYQ1a5bpoFyzxgwxbu3DOeII046/ZIl5zuk0CSg7G77+dfM6/uMfsGOHef1efx2KivaM5ZVXTEIJh03i/P73zVxb+5MMxJ4iEfN52D3pDECSFMQ+aZ0gHP6c5uYV1NT8lZqaV0gkzPUgXK5B+P2TcLsH43Dk43IVkZk5jaysmdjtHX4FNjWZA3VPflEeSlpHf3zwgalR5OZCQYH55d7QYJJhKGQSzbRp5uC++xDKlhbTQblkialhVVSYWsqcOabD8tRTzXJgfsUuXWo6WI86ylyxz+9vf279etMB6vF0H3PrSJhU/KIVA54kBbHfLCtKU9P7BAIraG7+iJaWVcRi1cRidVhWEAClnGRmTsPvH4/XOxqvdwy5uSfjcPR/9bjfNTaaGoX8eheHIDmjWew3m81FTs4ccnLm7PFcLNZAU9NSGhuX0Nj4LjU1LxOL7Uou56Ww8AIGD74Sj6cMrROAxu0uxWZz9/Fe9KNDoN1YiIMlSUH0iNOZQ37+6eTnn972WDweoKXlE3bu/DO7dj1FVdUTnZZRyonfP5HMzKl4vSNxOotxuQaRkVHe3mchhDikSFIQB8zhyCQ7exbZ2bMYPfrX1NYuJJEIoJQdrTXB4FoCgWVUVz9HPN7QadmMjMnk5Z2G2z0UraNYVgynMxePZxRe7ygcjiwsK4bWMRyOXOz2vbS1CyF6jSQF0Svsdj9FRRd0+3w83kwsVkUksp3Gxnepq/sHW7fehdbxfa7bZvOQnX08OTkn4/WOJB5vJB5vwG73k5U1A79/IjabGXVkWZHkMmnUbCVEL5KOZtFv4vFmLKsFpVwo5SQWqyEU2kA4vJFEogWlnCjlIBRaT339G7S0rOpyPTabB5drMLFYDYlEAJvNQ27ulygoOJfMzGlEozuJRLZiWREyMqaQkVEuNQ+RdqSjWRzyHI4MIKPTfa+3DPhil+Wj0Sqi0V04HLk4HDnE47U0NX1AU9NSotFdOJ0FOJ2FxGK7qKl5idraV7pcj1IOvN4jsNv92GwebDYPdrsfuz0Duz0Tl2swLtdg3O4SPJ5huN3DcTgy0NoiHm/CsoI4nUXYbPL1EQOP1BTEgKS1prn5I0Kh9bhcJbjdpShlIxBYTiDwIcHgWiwrnLyFSCRaSCSak01TdXusz2bzY1khwEo+YsfjGY7HMxybzYtSdpRy4vGMwO8fh9d7JJAgFqsnkWjEZvPhdObjdObj8YzE4cjsy5dDCKkpiPSmlCIzcwqZmVM6Pe7xDKOw8Ly9LmtZkWST0zbC4a1EIluIRndit2fgcORis3mJRCoJhzcRDm8hHm8CElhWhNrav6P1vqeh9njK8Psn4PePx+c7Cp9vXPJcDwutLSwrSDzeRCLRlPwbIJFoxm7PwOMZidc7Ers9C8sKkkgEcTrzcLu7mM5BiP0kSUGI3dhs7rZawP6eemDOEq8gGPwPNpsbhyMHhyObRCJILFZLLFZNKPQfmptX0dKyirq6f6B1rFfidruHkpU1E5drMNHoDiKR7WgdweksxOksxOHIMrNgotE6mqwVNaKUjYyMyWRmTsPnO5J4PEA8Xo9lRXC7B+N2l+Jw5BGL1RCN7iSRCOD3j8flKu6VuMWhRZKCEL1IKTterxlW2xOWFSMU2kgw+BmJRBClbIANu92Hw5GN3Z6J3Z6Fw5GJzeYnkWgiFNrU1hlv+kW8RKM7aGxcSlPTUuLxelyuIbjdg1Eqg2h0Fy0tq0kkApjrailsNid2ezYORzaWFaG+/o0ejQTryO0uxe8/Gq3jxOONyXgy2uK2rAiW1YJlhbHbM3E683E4conHm4jFdhGL1WCzeZKJMxef70gyMtprd9HoDqLRnWitk30+/uSgBPMaORzZuFzF2Gwu4vEAjY3v0dj4NlpbZGXNJCvrWDkf5gBIn4IQgkQiRHPzx4TDm3E4spPNZO5kjWMbsVgtTmchLtcgbDYvLS2rCASWEQyuSR7Ys7HZfMm+mUbi8QA2mzuZtNzJ2kctsVg9DkcWTmcRTmcBWkeIxxuIxWoJhyuA/T8eORz5yfNgEihlhia31r4cjjyczjwcjjyUchCPNxCPN2BZkbZBBjabE60twEIpFy5XEU5ncTJhhrGsIFpbba+Lw5GDzebFZjMj2MLhzYRCG4jFqvH5jsTvn4TPdwSxWF3ytduF01mUHLRQmjzvJhO73TRDhkIbCYe3ABqbzYVS7k4DH9zuUrzeEQc9zPqQmPtIKXUa8FvADjystb59t+fdwBPAVKAWmKe1rtjbOiUpCDEwxeMBmps/prn5I5RyJEeADQZsJBItyVpHDNPvkiAeb0jWJnbgdBaQk3MiWVnHAjaamz9KzgS8iXi8nlisDq3jyVpJDjabO1mTCaN1LFn7UFhWhFhsF9FoFfF4U3Jkmi8ZQyOxWD2W1fmKaTabF49nJE5nAcHgWmKxqt2e97XNHXbgFG53KaWl1zN06H8d2Br6u6NZKWUH7ge+BGwDPlRKvay1/qxDsW8A9Vrr0Uqpi4A7gHmpikkIcehyODLJyTmenJwDv+Rkq+zsY8nOPnbfBQ+AZcXbRq5BAqezMJlUjEhkJ6HQBlyuQlyuEhyODOLxZiKRrUQi25JNbQEsK4jLNRivdxQeTxlKObCsaFuzWzweIJFoIhz+nHB4Y3Kdg7sPrJeksk/hGGCD1noTgFLqGeAcoGNSOAeYn/z/eeD3SimlD7c2LSFE2rDZHNhsnc+x6cjtHrRHX4bDkYHDMQ6/f9xe1223+3srzANm23eRA1YCbO1wf1vysS7LaNPL1QjkpzAmIYQQe5HKpNBrlFLXKKWWKaWWVVdX93c4QggxYKUyKVQCQzvcL00+1mUZpZQDyMZ0OHeitX5Qaz1Naz2tsLAwReEKIYRIZVL4EBijlBqhlHIBFwEv71bmZeCy5P9fAd6S/gQhhOg/Keto1lrHlVLfBV7DDEldoLX+VCn1c2CZ1vpl4BHgz0qpDUAdJnEIIYToJyk9o1lrvRBYuNtjt3b4Pwx0Pwm/EEKIPnVYdDQLIYToG5IUhBBCtDns5j5SSlUDWw5w8QKgphfDORzIPqcH2ef0cDD7PFxrvc/hm4ddUjgYSqllPZn7YyCRfU4Pss/poS/2WZqPhBBCtJGkIIQQok26JYUH+zuAfiD7nB5kn9NDyvc5rfoUhBBC7F261RSEEELsRdokBaXUaUqpdUqpDUqpm/s7nlRQSg1VSi1SSn2mlPpUKXV98vE8pdTrSqn1yb+5/R1rb1JK2ZVSHyml/pa8P0Ip9UHyvX42OffWgKGUylFKPa+UWquUWqOUOjYN3uP/l/xMr1ZKPa2U8gy091kptUAptUsptbrDY12+r8q4L7nvnyilpvRWHGmRFDpcBe504CjgYqXUUf0bVUrEgf/SWh8FzASuTe7nzcCbWusxwJvJ+wPJ9cCaDvfvAO7RWo8G6jFX+BtIfgv8Q2s9FpiE2fcB+x4rpUqA7wHTtNZHY+ZSa71S40B6nx8DTtvtse7e19OBMcnbNcAfeyuItEgKdLgKnNY6CrReBW5A0Vrv0FqvSP4fwBwsSjD7+niy2OPAuf0TYe9TSpUCZwIPJ+8r4CTMlfxg4O1vNjAHM5kkWuuo1rqBAfweJzkAb3KKfR+wgwH2Pmutl2AmBu2ou/f1HOAJbbwP5CileuVanemSFHpyFbgBRSlVBkwGPgCKtdY7kk/tBIr7KaxUuBf4b8BK3s8HGpJX8oOB916PAKqBR5NNZg8rpfwM4PdYa10J3A18jkkGjcByBvb73Kq79zVlx7R0SQppRSmVAbwA3KC1bur4XPJ6FQNiyJlS6ixgl9Z6eX/H0occwBTgj1rryUALuzUVDaT3GCDZjn4OJiEOAfzs2cwy4PXV+5ouSaEnV4EbEJRSTkxCeFJr/aHrTHcAAANDSURBVJfkw1WtVcvk3139FV8vmwXMVUpVYJoET8K0t+ckmxlg4L3X24BtWusPkvefxySJgfoeA3wR2Ky1rtZax4C/YN77gfw+t+rufU3ZMS1dkkJPrgJ32Eu2pz8CrNFa/6bDUx2vcHcZ8FJfx5YKWusfaq1LtdZlmPf0La31JcAizJX8YADtL4DWeiewVSl1ZPKhk4HPGKDvcdLnwEyllC/5GW/d5wH7PnfQ3fv6MvD15CikmUBjh2amg5I2J68ppc7AtD+3XgXul/0cUq9TSh0PvAOsor2N/RZMv8JzwDDMDLMXaq1379A6rCmlTgS+r7U+Syk1ElNzyAM+Ai7VWkf6M77epJQqx3Ssu4BNwBWYH3gD9j3+/+3dz4uNURzH8fdHSkTZsLEgbKRQyoLUlH/AgpQfC2VnYydF4h+woViOTJLCWmYxZaEx+bHxF9iwkZKU+FqcM09jqJkmxmTer90993S6T0/P/TzPufd8T5IrwDHaP+xeAmdoc+j/zXlOchcYoVVCfQdcBh7xm/Paw/E6bRrtM3C6qqb+yOdYLqEgSZrbcpk+kiTNg6EgSRoYCpKkgaEgSRoYCpKkgaEgLaIkI9PVXKWlyFCQJA0MBek3kpxMMpnkVZJbfc+GT0mu9br+40k29L57kjzrde0fzqh5vz3JkySvk7xIsq0Pv3bGfghjfSGStCQYCtIsSXbQVs8eqKo9wDfgBK0Q21RV7QQmaCtOAW4D56tqF201+XT7GHCjqnYD+2kVPqFVrz1H29tjK62Oj7QkrJy7i7TsHAL2As/7TfxqWiGy78C93ucO8KDvb7C+qiZ6+yhwP8k6YFNVPQSoqi8AfbzJqnrbX78CtgBP//5hSXMzFKRfBRitqgs/NSaXZvVbaI2YmfV5vuF1qCXE6SPpV+PAkSQbYdgndzPtepmuynkceFpVH4EPSQ729lPARN/57m2Sw32MVUnWLOpRSAvgHYo0S1W9SXIReJxkBfAVOEvb0GZff+897XcHaCWNb/Yv/emqpdAC4laSq32Mo4t4GNKCWCVVmqckn6pq7b/+HNLf5PSRJGngk4IkaeCTgiRpYChIkgaGgiRpYChIkgaGgiRpYChIkgY/ALosizFbNV7ZAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 650us/sample - loss: 0.2270 - acc: 0.9404\n",
      "Loss: 0.22697225112027003 Accuracy: 0.9403946\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2006 - acc: 0.2885\n",
      "Epoch 00001: val_loss improved from inf to 1.32087, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/001-1.3209.hdf5\n",
      "36805/36805 [==============================] - 59s 2ms/sample - loss: 2.2004 - acc: 0.2886 - val_loss: 1.3209 - val_acc: 0.6198\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2927 - acc: 0.5854\n",
      "Epoch 00002: val_loss improved from 1.32087 to 0.79492, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/002-0.7949.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 1.2928 - acc: 0.5854 - val_loss: 0.7949 - val_acc: 0.7768\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9221 - acc: 0.7102\n",
      "Epoch 00003: val_loss improved from 0.79492 to 0.59887, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/003-0.5989.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.9222 - acc: 0.7102 - val_loss: 0.5989 - val_acc: 0.8267\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7287 - acc: 0.7695\n",
      "Epoch 00004: val_loss improved from 0.59887 to 0.45209, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/004-0.4521.hdf5\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.7287 - acc: 0.7694 - val_loss: 0.4521 - val_acc: 0.8744\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5934 - acc: 0.8136\n",
      "Epoch 00005: val_loss improved from 0.45209 to 0.36027, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/005-0.3603.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.5934 - acc: 0.8136 - val_loss: 0.3603 - val_acc: 0.8949\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5040 - acc: 0.8441\n",
      "Epoch 00006: val_loss improved from 0.36027 to 0.32834, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/006-0.3283.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.5040 - acc: 0.8441 - val_loss: 0.3283 - val_acc: 0.9040\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4437 - acc: 0.8587\n",
      "Epoch 00007: val_loss improved from 0.32834 to 0.28395, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/007-0.2839.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.4437 - acc: 0.8587 - val_loss: 0.2839 - val_acc: 0.9131\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3929 - acc: 0.8758\n",
      "Epoch 00008: val_loss improved from 0.28395 to 0.27233, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/008-0.2723.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.3930 - acc: 0.8758 - val_loss: 0.2723 - val_acc: 0.9185\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3549 - acc: 0.8904\n",
      "Epoch 00009: val_loss improved from 0.27233 to 0.23101, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/009-0.2310.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.3549 - acc: 0.8904 - val_loss: 0.2310 - val_acc: 0.9317\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3222 - acc: 0.8995\n",
      "Epoch 00010: val_loss improved from 0.23101 to 0.22213, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/010-0.2221.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.3222 - acc: 0.8995 - val_loss: 0.2221 - val_acc: 0.9366\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3036 - acc: 0.9055\n",
      "Epoch 00011: val_loss improved from 0.22213 to 0.20886, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/011-0.2089.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.3036 - acc: 0.9055 - val_loss: 0.2089 - val_acc: 0.9371\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2839 - acc: 0.9105\n",
      "Epoch 00012: val_loss improved from 0.20886 to 0.20751, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/012-0.2075.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2839 - acc: 0.9105 - val_loss: 0.2075 - val_acc: 0.9371\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2641 - acc: 0.9164\n",
      "Epoch 00013: val_loss improved from 0.20751 to 0.17963, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/013-0.1796.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2641 - acc: 0.9164 - val_loss: 0.1796 - val_acc: 0.9476\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2425 - acc: 0.9238\n",
      "Epoch 00014: val_loss improved from 0.17963 to 0.17027, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/014-0.1703.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2425 - acc: 0.9238 - val_loss: 0.1703 - val_acc: 0.9513\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2282 - acc: 0.9273\n",
      "Epoch 00015: val_loss did not improve from 0.17027\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2282 - acc: 0.9273 - val_loss: 0.1803 - val_acc: 0.9446\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2178 - acc: 0.9295\n",
      "Epoch 00016: val_loss improved from 0.17027 to 0.16018, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/016-0.1602.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2177 - acc: 0.9295 - val_loss: 0.1602 - val_acc: 0.9522\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2059 - acc: 0.9329\n",
      "Epoch 00017: val_loss did not improve from 0.16018\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2060 - acc: 0.9329 - val_loss: 0.1849 - val_acc: 0.9429\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1938 - acc: 0.9376\n",
      "Epoch 00018: val_loss improved from 0.16018 to 0.15656, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/018-0.1566.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1938 - acc: 0.9376 - val_loss: 0.1566 - val_acc: 0.9518\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1850 - acc: 0.9399\n",
      "Epoch 00019: val_loss improved from 0.15656 to 0.15246, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/019-0.1525.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1850 - acc: 0.9399 - val_loss: 0.1525 - val_acc: 0.9546\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1797 - acc: 0.9420\n",
      "Epoch 00020: val_loss did not improve from 0.15246\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1797 - acc: 0.9420 - val_loss: 0.1579 - val_acc: 0.9504\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9437\n",
      "Epoch 00021: val_loss improved from 0.15246 to 0.14285, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/021-0.1428.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1711 - acc: 0.9437 - val_loss: 0.1428 - val_acc: 0.9567\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1613 - acc: 0.9469\n",
      "Epoch 00022: val_loss did not improve from 0.14285\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1613 - acc: 0.9469 - val_loss: 0.1447 - val_acc: 0.9583\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1588 - acc: 0.9479\n",
      "Epoch 00023: val_loss improved from 0.14285 to 0.14169, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/023-0.1417.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.1588 - acc: 0.9479 - val_loss: 0.1417 - val_acc: 0.9595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1516 - acc: 0.9493\n",
      "Epoch 00024: val_loss improved from 0.14169 to 0.13725, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/024-0.1373.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1516 - acc: 0.9493 - val_loss: 0.1373 - val_acc: 0.9613\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1426 - acc: 0.9543\n",
      "Epoch 00025: val_loss did not improve from 0.13725\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1426 - acc: 0.9543 - val_loss: 0.1474 - val_acc: 0.9557\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1333 - acc: 0.9564\n",
      "Epoch 00026: val_loss did not improve from 0.13725\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1332 - acc: 0.9564 - val_loss: 0.1444 - val_acc: 0.9599\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9590\n",
      "Epoch 00027: val_loss improved from 0.13725 to 0.12677, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/027-0.1268.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1274 - acc: 0.9590 - val_loss: 0.1268 - val_acc: 0.9646\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9575\n",
      "Epoch 00028: val_loss did not improve from 0.12677\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1279 - acc: 0.9575 - val_loss: 0.1532 - val_acc: 0.9555\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1242 - acc: 0.9586\n",
      "Epoch 00029: val_loss did not improve from 0.12677\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1243 - acc: 0.9586 - val_loss: 0.1324 - val_acc: 0.9595\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9584\n",
      "Epoch 00030: val_loss did not improve from 0.12677\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1215 - acc: 0.9584 - val_loss: 0.1372 - val_acc: 0.9609\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9614\n",
      "Epoch 00031: val_loss did not improve from 0.12677\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1146 - acc: 0.9614 - val_loss: 0.1585 - val_acc: 0.9534\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9647\n",
      "Epoch 00032: val_loss did not improve from 0.12677\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1059 - acc: 0.9647 - val_loss: 0.1432 - val_acc: 0.9604\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9642\n",
      "Epoch 00033: val_loss did not improve from 0.12677\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1091 - acc: 0.9642 - val_loss: 0.1439 - val_acc: 0.9597\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1057 - acc: 0.9649\n",
      "Epoch 00034: val_loss did not improve from 0.12677\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1056 - acc: 0.9649 - val_loss: 0.1456 - val_acc: 0.9616\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9657\n",
      "Epoch 00035: val_loss did not improve from 0.12677\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1000 - acc: 0.9657 - val_loss: 0.1442 - val_acc: 0.9602\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9679\n",
      "Epoch 00036: val_loss did not improve from 0.12677\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0962 - acc: 0.9679 - val_loss: 0.1613 - val_acc: 0.9513\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9676\n",
      "Epoch 00037: val_loss improved from 0.12677 to 0.12002, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_8_conv_checkpoint/037-0.1200.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0963 - acc: 0.9676 - val_loss: 0.1200 - val_acc: 0.9658\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9705\n",
      "Epoch 00038: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0910 - acc: 0.9705 - val_loss: 0.1532 - val_acc: 0.9634\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9700\n",
      "Epoch 00039: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0899 - acc: 0.9700 - val_loss: 0.1390 - val_acc: 0.9592\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9721\n",
      "Epoch 00040: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0843 - acc: 0.9721 - val_loss: 0.1332 - val_acc: 0.9655\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9712\n",
      "Epoch 00041: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0825 - acc: 0.9712 - val_loss: 0.1448 - val_acc: 0.9625\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9725\n",
      "Epoch 00042: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0803 - acc: 0.9725 - val_loss: 0.1408 - val_acc: 0.9609\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0794 - acc: 0.9733\n",
      "Epoch 00043: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0794 - acc: 0.9733 - val_loss: 0.1272 - val_acc: 0.9637\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9723\n",
      "Epoch 00044: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0801 - acc: 0.9723 - val_loss: 0.1434 - val_acc: 0.9606\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9749\n",
      "Epoch 00045: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0723 - acc: 0.9749 - val_loss: 0.1305 - val_acc: 0.9700\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9760\n",
      "Epoch 00046: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0726 - acc: 0.9760 - val_loss: 0.1366 - val_acc: 0.9655\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0670 - acc: 0.9769\n",
      "Epoch 00047: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0670 - acc: 0.9769 - val_loss: 0.1278 - val_acc: 0.9648\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9776\n",
      "Epoch 00048: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0652 - acc: 0.9776 - val_loss: 0.1297 - val_acc: 0.9665\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9767\n",
      "Epoch 00049: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0679 - acc: 0.9767 - val_loss: 0.1475 - val_acc: 0.9665\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9788\n",
      "Epoch 00050: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0632 - acc: 0.9788 - val_loss: 0.1521 - val_acc: 0.9653\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9785\n",
      "Epoch 00051: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0648 - acc: 0.9785 - val_loss: 0.1433 - val_acc: 0.9655\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9784\n",
      "Epoch 00052: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0623 - acc: 0.9784 - val_loss: 0.1326 - val_acc: 0.9700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9800\n",
      "Epoch 00053: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0599 - acc: 0.9800 - val_loss: 0.1369 - val_acc: 0.9646\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9803\n",
      "Epoch 00054: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0568 - acc: 0.9803 - val_loss: 0.1356 - val_acc: 0.9679\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9797\n",
      "Epoch 00055: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0591 - acc: 0.9797 - val_loss: 0.1588 - val_acc: 0.9576\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9820\n",
      "Epoch 00056: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0513 - acc: 0.9820 - val_loss: 0.1471 - val_acc: 0.9604\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9808\n",
      "Epoch 00057: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0551 - acc: 0.9808 - val_loss: 0.1370 - val_acc: 0.9676\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9827\n",
      "Epoch 00058: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0516 - acc: 0.9827 - val_loss: 0.1279 - val_acc: 0.9667\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9815\n",
      "Epoch 00059: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0534 - acc: 0.9815 - val_loss: 0.1364 - val_acc: 0.9676\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9814\n",
      "Epoch 00060: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0542 - acc: 0.9814 - val_loss: 0.1563 - val_acc: 0.9604\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9824\n",
      "Epoch 00061: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0512 - acc: 0.9824 - val_loss: 0.1463 - val_acc: 0.9672\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9820\n",
      "Epoch 00062: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0527 - acc: 0.9820 - val_loss: 0.1602 - val_acc: 0.9627\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9846\n",
      "Epoch 00063: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0454 - acc: 0.9846 - val_loss: 0.1476 - val_acc: 0.9651\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9844\n",
      "Epoch 00064: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0472 - acc: 0.9844 - val_loss: 0.1553 - val_acc: 0.9662\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9845\n",
      "Epoch 00065: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0457 - acc: 0.9844 - val_loss: 0.1559 - val_acc: 0.9639\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9839\n",
      "Epoch 00066: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0497 - acc: 0.9839 - val_loss: 0.1392 - val_acc: 0.9676\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9855\n",
      "Epoch 00067: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0442 - acc: 0.9855 - val_loss: 0.1508 - val_acc: 0.9662\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9851\n",
      "Epoch 00068: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0437 - acc: 0.9851 - val_loss: 0.1465 - val_acc: 0.9681\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9864\n",
      "Epoch 00069: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0395 - acc: 0.9864 - val_loss: 0.1522 - val_acc: 0.9632\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9850\n",
      "Epoch 00070: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0438 - acc: 0.9850 - val_loss: 0.1410 - val_acc: 0.9676\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9864\n",
      "Epoch 00071: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0395 - acc: 0.9864 - val_loss: 0.1652 - val_acc: 0.9658\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9855\n",
      "Epoch 00072: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0427 - acc: 0.9855 - val_loss: 0.1528 - val_acc: 0.9651\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9870\n",
      "Epoch 00073: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0384 - acc: 0.9870 - val_loss: 0.1400 - val_acc: 0.9676\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9864\n",
      "Epoch 00074: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0388 - acc: 0.9864 - val_loss: 0.1662 - val_acc: 0.9648\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9882\n",
      "Epoch 00075: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0363 - acc: 0.9882 - val_loss: 0.1526 - val_acc: 0.9690\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9868\n",
      "Epoch 00076: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0376 - acc: 0.9868 - val_loss: 0.1698 - val_acc: 0.9646\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9871\n",
      "Epoch 00077: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0391 - acc: 0.9871 - val_loss: 0.1428 - val_acc: 0.9690\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9874\n",
      "Epoch 00078: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0382 - acc: 0.9874 - val_loss: 0.1605 - val_acc: 0.9618\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9879\n",
      "Epoch 00079: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0353 - acc: 0.9879 - val_loss: 0.1524 - val_acc: 0.9669\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9880\n",
      "Epoch 00080: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0351 - acc: 0.9880 - val_loss: 0.1468 - val_acc: 0.9669\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0329 - acc: 0.9889\n",
      "Epoch 00081: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0329 - acc: 0.9889 - val_loss: 0.1576 - val_acc: 0.9653\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9882\n",
      "Epoch 00082: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0348 - acc: 0.9882 - val_loss: 0.1596 - val_acc: 0.9609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9885\n",
      "Epoch 00083: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0355 - acc: 0.9885 - val_loss: 0.1731 - val_acc: 0.9625\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9893\n",
      "Epoch 00084: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0326 - acc: 0.9893 - val_loss: 0.1594 - val_acc: 0.9655\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9889\n",
      "Epoch 00085: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0342 - acc: 0.9889 - val_loss: 0.1581 - val_acc: 0.9695\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9898\n",
      "Epoch 00086: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0319 - acc: 0.9898 - val_loss: 0.1502 - val_acc: 0.9623\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9903\n",
      "Epoch 00087: val_loss did not improve from 0.12002\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0303 - acc: 0.9903 - val_loss: 0.1569 - val_acc: 0.9653\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 666us/sample - loss: 0.1595 - acc: 0.9502\n",
      "Loss: 0.159542751186919 Accuracy: 0.95015574\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8383 - acc: 0.4091\n",
      "Epoch 00001: val_loss improved from inf to 0.88675, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/001-0.8867.hdf5\n",
      "36805/36805 [==============================] - 61s 2ms/sample - loss: 1.8382 - acc: 0.4091 - val_loss: 0.8867 - val_acc: 0.7438\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9004 - acc: 0.7151\n",
      "Epoch 00002: val_loss improved from 0.88675 to 0.52569, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/002-0.5257.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.9004 - acc: 0.7151 - val_loss: 0.5257 - val_acc: 0.8486\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6375 - acc: 0.7985\n",
      "Epoch 00003: val_loss improved from 0.52569 to 0.36489, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/003-0.3649.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.6375 - acc: 0.7985 - val_loss: 0.3649 - val_acc: 0.9003\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4864 - acc: 0.8475\n",
      "Epoch 00004: val_loss improved from 0.36489 to 0.30829, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/004-0.3083.hdf5\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.4864 - acc: 0.8475 - val_loss: 0.3083 - val_acc: 0.9150\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4046 - acc: 0.8713\n",
      "Epoch 00005: val_loss improved from 0.30829 to 0.27431, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/005-0.2743.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.4046 - acc: 0.8713 - val_loss: 0.2743 - val_acc: 0.9180\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3449 - acc: 0.8903\n",
      "Epoch 00006: val_loss improved from 0.27431 to 0.22379, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/006-0.2238.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.3449 - acc: 0.8903 - val_loss: 0.2238 - val_acc: 0.9287\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3109 - acc: 0.9000\n",
      "Epoch 00007: val_loss improved from 0.22379 to 0.20300, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/007-0.2030.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.3109 - acc: 0.9000 - val_loss: 0.2030 - val_acc: 0.9401\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2725 - acc: 0.9135\n",
      "Epoch 00008: val_loss improved from 0.20300 to 0.18944, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/008-0.1894.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2724 - acc: 0.9135 - val_loss: 0.1894 - val_acc: 0.9415\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2448 - acc: 0.9209\n",
      "Epoch 00009: val_loss did not improve from 0.18944\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2447 - acc: 0.9209 - val_loss: 0.2109 - val_acc: 0.9341\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2205 - acc: 0.9278\n",
      "Epoch 00010: val_loss improved from 0.18944 to 0.18850, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/010-0.1885.hdf5\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.2205 - acc: 0.9278 - val_loss: 0.1885 - val_acc: 0.9425\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.9325\n",
      "Epoch 00011: val_loss improved from 0.18850 to 0.16223, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/011-0.1622.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.2101 - acc: 0.9325 - val_loss: 0.1622 - val_acc: 0.9492\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1877 - acc: 0.9388\n",
      "Epoch 00012: val_loss did not improve from 0.16223\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1877 - acc: 0.9388 - val_loss: 0.1798 - val_acc: 0.9453\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1791 - acc: 0.9424\n",
      "Epoch 00013: val_loss improved from 0.16223 to 0.15984, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/013-0.1598.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1791 - acc: 0.9424 - val_loss: 0.1598 - val_acc: 0.9506\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1649 - acc: 0.9465\n",
      "Epoch 00014: val_loss improved from 0.15984 to 0.15705, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/014-0.1570.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1649 - acc: 0.9465 - val_loss: 0.1570 - val_acc: 0.9525\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1509 - acc: 0.9506\n",
      "Epoch 00015: val_loss improved from 0.15705 to 0.14416, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/015-0.1442.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1509 - acc: 0.9506 - val_loss: 0.1442 - val_acc: 0.9562\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9525\n",
      "Epoch 00016: val_loss did not improve from 0.14416\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1421 - acc: 0.9525 - val_loss: 0.1726 - val_acc: 0.9471\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9560\n",
      "Epoch 00017: val_loss did not improve from 0.14416\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1339 - acc: 0.9560 - val_loss: 0.1449 - val_acc: 0.9564\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9582\n",
      "Epoch 00018: val_loss did not improve from 0.14416\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1240 - acc: 0.9582 - val_loss: 0.1465 - val_acc: 0.9550\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9609\n",
      "Epoch 00019: val_loss improved from 0.14416 to 0.14203, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/019-0.1420.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1202 - acc: 0.9609 - val_loss: 0.1420 - val_acc: 0.9590\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9648\n",
      "Epoch 00020: val_loss improved from 0.14203 to 0.13069, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/020-0.1307.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1061 - acc: 0.9648 - val_loss: 0.1307 - val_acc: 0.9597\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9651\n",
      "Epoch 00021: val_loss did not improve from 0.13069\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.1060 - acc: 0.9651 - val_loss: 0.1430 - val_acc: 0.9571\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9671\n",
      "Epoch 00022: val_loss did not improve from 0.13069\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0988 - acc: 0.9671 - val_loss: 0.1413 - val_acc: 0.9592\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9692\n",
      "Epoch 00023: val_loss did not improve from 0.13069\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0931 - acc: 0.9692 - val_loss: 0.1409 - val_acc: 0.9599\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9719\n",
      "Epoch 00024: val_loss did not improve from 0.13069\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0850 - acc: 0.9719 - val_loss: 0.1374 - val_acc: 0.9581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9715\n",
      "Epoch 00025: val_loss improved from 0.13069 to 0.12761, saving model to model/checkpoint/1D_CNN_custom_he-uniform_DO_9_conv_checkpoint/025-0.1276.hdf5\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0847 - acc: 0.9715 - val_loss: 0.1276 - val_acc: 0.9620\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9742\n",
      "Epoch 00026: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0760 - acc: 0.9742 - val_loss: 0.1456 - val_acc: 0.9555\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9735\n",
      "Epoch 00027: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0777 - acc: 0.9735 - val_loss: 0.1309 - val_acc: 0.9644\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9760\n",
      "Epoch 00028: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0705 - acc: 0.9760 - val_loss: 0.1337 - val_acc: 0.9651\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9772\n",
      "Epoch 00029: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0702 - acc: 0.9772 - val_loss: 0.1432 - val_acc: 0.9611\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9784\n",
      "Epoch 00030: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0646 - acc: 0.9784 - val_loss: 0.1304 - val_acc: 0.9644\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9789\n",
      "Epoch 00031: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0621 - acc: 0.9789 - val_loss: 0.1359 - val_acc: 0.9634\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9807\n",
      "Epoch 00032: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0558 - acc: 0.9807 - val_loss: 0.1442 - val_acc: 0.9597\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9810\n",
      "Epoch 00033: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0577 - acc: 0.9810 - val_loss: 0.1515 - val_acc: 0.9623\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9825\n",
      "Epoch 00034: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0529 - acc: 0.9825 - val_loss: 0.1414 - val_acc: 0.9599\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9823\n",
      "Epoch 00035: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0534 - acc: 0.9823 - val_loss: 0.1436 - val_acc: 0.9634\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9840\n",
      "Epoch 00036: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0483 - acc: 0.9841 - val_loss: 0.1334 - val_acc: 0.9644\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9837\n",
      "Epoch 00037: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0498 - acc: 0.9837 - val_loss: 0.1287 - val_acc: 0.9627\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9832\n",
      "Epoch 00038: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0480 - acc: 0.9832 - val_loss: 0.1403 - val_acc: 0.9641\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9856\n",
      "Epoch 00039: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0455 - acc: 0.9856 - val_loss: 0.1570 - val_acc: 0.9588\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9846\n",
      "Epoch 00040: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0439 - acc: 0.9846 - val_loss: 0.1451 - val_acc: 0.9632\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9868\n",
      "Epoch 00041: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0400 - acc: 0.9868 - val_loss: 0.1507 - val_acc: 0.9620\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9865\n",
      "Epoch 00042: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0404 - acc: 0.9866 - val_loss: 0.1343 - val_acc: 0.9641\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0380 - acc: 0.9869\n",
      "Epoch 00043: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0380 - acc: 0.9869 - val_loss: 0.1435 - val_acc: 0.9658\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9868\n",
      "Epoch 00044: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0376 - acc: 0.9868 - val_loss: 0.1531 - val_acc: 0.9641\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9835\n",
      "Epoch 00045: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0507 - acc: 0.9835 - val_loss: 0.1499 - val_acc: 0.9641\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9894\n",
      "Epoch 00046: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0330 - acc: 0.9894 - val_loss: 0.1550 - val_acc: 0.9620\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9891\n",
      "Epoch 00047: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0333 - acc: 0.9891 - val_loss: 0.1473 - val_acc: 0.9639\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9891\n",
      "Epoch 00048: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0327 - acc: 0.9891 - val_loss: 0.1711 - val_acc: 0.9623\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9888\n",
      "Epoch 00049: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 55s 1ms/sample - loss: 0.0328 - acc: 0.9888 - val_loss: 0.1809 - val_acc: 0.9569\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9898\n",
      "Epoch 00050: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0320 - acc: 0.9898 - val_loss: 0.1480 - val_acc: 0.9648\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9896\n",
      "Epoch 00051: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0321 - acc: 0.9896 - val_loss: 0.1675 - val_acc: 0.9637\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9900\n",
      "Epoch 00052: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0298 - acc: 0.9900 - val_loss: 0.1492 - val_acc: 0.9655\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0290 - acc: 0.9903\n",
      "Epoch 00053: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0290 - acc: 0.9903 - val_loss: 0.1540 - val_acc: 0.9655\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9912\n",
      "Epoch 00054: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0277 - acc: 0.9912 - val_loss: 0.1957 - val_acc: 0.9606\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9902\n",
      "Epoch 00055: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0286 - acc: 0.9902 - val_loss: 0.1584 - val_acc: 0.9660\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9905\n",
      "Epoch 00056: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0272 - acc: 0.9905 - val_loss: 0.1770 - val_acc: 0.9627\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9926\n",
      "Epoch 00057: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0243 - acc: 0.9926 - val_loss: 0.1651 - val_acc: 0.9641\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9920\n",
      "Epoch 00058: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0228 - acc: 0.9920 - val_loss: 0.1728 - val_acc: 0.9646\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9908\n",
      "Epoch 00059: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0271 - acc: 0.9908 - val_loss: 0.1614 - val_acc: 0.9651\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9901\n",
      "Epoch 00060: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0292 - acc: 0.9901 - val_loss: 0.1610 - val_acc: 0.9639\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9923\n",
      "Epoch 00061: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0234 - acc: 0.9923 - val_loss: 0.1352 - val_acc: 0.9669\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9926\n",
      "Epoch 00062: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0227 - acc: 0.9926 - val_loss: 0.1861 - val_acc: 0.9632\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9929\n",
      "Epoch 00063: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0218 - acc: 0.9929 - val_loss: 0.1602 - val_acc: 0.9646\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9922\n",
      "Epoch 00064: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0239 - acc: 0.9922 - val_loss: 0.1690 - val_acc: 0.9655\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9924\n",
      "Epoch 00065: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0236 - acc: 0.9924 - val_loss: 0.1774 - val_acc: 0.9623\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9924\n",
      "Epoch 00066: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0240 - acc: 0.9924 - val_loss: 0.1870 - val_acc: 0.9611\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9945\n",
      "Epoch 00067: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0177 - acc: 0.9945 - val_loss: 0.1741 - val_acc: 0.9658\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9933\n",
      "Epoch 00068: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0206 - acc: 0.9933 - val_loss: 0.2134 - val_acc: 0.9625\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9923\n",
      "Epoch 00069: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0236 - acc: 0.9923 - val_loss: 0.1399 - val_acc: 0.9662\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9940\n",
      "Epoch 00070: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0178 - acc: 0.9940 - val_loss: 0.1746 - val_acc: 0.9667\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9936\n",
      "Epoch 00071: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 54s 1ms/sample - loss: 0.0202 - acc: 0.9936 - val_loss: 0.1827 - val_acc: 0.9616\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9930\n",
      "Epoch 00072: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 53s 1ms/sample - loss: 0.0208 - acc: 0.9930 - val_loss: 0.1460 - val_acc: 0.9695\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9935\n",
      "Epoch 00073: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0207 - acc: 0.9935 - val_loss: 0.1893 - val_acc: 0.9672\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9957\n",
      "Epoch 00074: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0136 - acc: 0.9957 - val_loss: 0.1892 - val_acc: 0.9644\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9929\n",
      "Epoch 00075: val_loss did not improve from 0.12761\n",
      "36805/36805 [==============================] - 52s 1ms/sample - loss: 0.0212 - acc: 0.9929 - val_loss: 0.1790 - val_acc: 0.9662\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 683us/sample - loss: 0.1838 - acc: 0.9491\n",
      "Loss: 0.18381216147854568 Accuracy: 0.94911736\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    base = '1D_CNN_custom_he-uniform_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_he-uniform_DO_3_conv Model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,136\n",
      "Trainable params: 1,861,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 682us/sample - loss: 1.4107 - acc: 0.5529\n",
      "Loss: 1.4106930673308091 Accuracy: 0.5528557\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 668,240\n",
      "Trainable params: 668,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 517us/sample - loss: 1.0678 - acc: 0.6733\n",
      "Loss: 1.0678083244142502 Accuracy: 0.67331254\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 506,576\n",
      "Trainable params: 506,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 545us/sample - loss: 0.8189 - acc: 0.7466\n",
      "Loss: 0.8188534947199242 Accuracy: 0.7466251\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 318,288\n",
      "Trainable params: 318,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 575us/sample - loss: 0.4431 - acc: 0.8800\n",
      "Loss: 0.4431484981241751 Accuracy: 0.87995845\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 310,224\n",
      "Trainable params: 310,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 593us/sample - loss: 0.2270 - acc: 0.9404\n",
      "Loss: 0.22697225112027003 Accuracy: 0.9403946\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_70 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 363,600\n",
      "Trainable params: 363,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 594us/sample - loss: 0.1595 - acc: 0.9502\n",
      "Loss: 0.159542751186919 Accuracy: 0.95015574\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 521,552\n",
      "Trainable params: 521,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 600us/sample - loss: 0.1838 - acc: 0.9491\n",
      "Loss: 0.18381216147854568 Accuracy: 0.94911736\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_he-uniform_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_he-uniform_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,136\n",
      "Trainable params: 1,861,136\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 555us/sample - loss: 2.6819 - acc: 0.5904\n",
      "Loss: 2.681864995401844 Accuracy: 0.59044653\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 668,240\n",
      "Trainable params: 668,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 561us/sample - loss: 1.5575 - acc: 0.7221\n",
      "Loss: 1.5574848469915419 Accuracy: 0.7221184\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 506,576\n",
      "Trainable params: 506,576\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 609us/sample - loss: 1.2034 - acc: 0.7859\n",
      "Loss: 1.2033549621840505 Accuracy: 0.78587747\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 318,288\n",
      "Trainable params: 318,288\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 674us/sample - loss: 0.5081 - acc: 0.8928\n",
      "Loss: 0.5080954434839489 Accuracy: 0.8928349\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_63 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 310,224\n",
      "Trainable params: 310,224\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 634us/sample - loss: 0.2644 - acc: 0.9433\n",
      "Loss: 0.2643548199690163 Accuracy: 0.94330215\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_70 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 363,600\n",
      "Trainable params: 363,600\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 696us/sample - loss: 0.1918 - acc: 0.9587\n",
      "Loss: 0.1917990298926258 Accuracy: 0.9586708\n",
      "\n",
      "1D_CNN_custom_he-uniform_DO_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_78 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 521,552\n",
      "Trainable params: 521,552\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 662us/sample - loss: 0.2724 - acc: 0.9541\n",
      "Loss: 0.2724173130824275 Accuracy: 0.95410174\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO'\n",
    "\n",
    "with open(path.join(log_dir, base)+'_last', 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
