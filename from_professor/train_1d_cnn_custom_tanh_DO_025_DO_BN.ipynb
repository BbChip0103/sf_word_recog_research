{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=64, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=64*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_28 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_36 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_42 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 4.0430 - acc: 0.1143\n",
      "Epoch 00001: val_loss improved from inf to 3.00625, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_1_conv_checkpoint/001-3.0062.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 4.0429 - acc: 0.1143 - val_loss: 3.0062 - val_acc: 0.1148\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2237 - acc: 0.3670\n",
      "Epoch 00002: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 2.2239 - acc: 0.3670 - val_loss: 3.6684 - val_acc: 0.1109\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7341 - acc: 0.4910\n",
      "Epoch 00003: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.7341 - acc: 0.4910 - val_loss: 4.0622 - val_acc: 0.1151\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4777 - acc: 0.5657\n",
      "Epoch 00004: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.4777 - acc: 0.5657 - val_loss: 4.4157 - val_acc: 0.1204\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2908 - acc: 0.6209\n",
      "Epoch 00005: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.2909 - acc: 0.6209 - val_loss: 4.8458 - val_acc: 0.1130\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1450 - acc: 0.6636\n",
      "Epoch 00006: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.1449 - acc: 0.6636 - val_loss: 5.4128 - val_acc: 0.0974\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0183 - acc: 0.6983\n",
      "Epoch 00007: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 1.0183 - acc: 0.6983 - val_loss: 5.7781 - val_acc: 0.1016\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9105 - acc: 0.7298\n",
      "Epoch 00008: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.9108 - acc: 0.7297 - val_loss: 6.6873 - val_acc: 0.1186\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8104 - acc: 0.7585\n",
      "Epoch 00009: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.8105 - acc: 0.7584 - val_loss: 6.6066 - val_acc: 0.1111\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7118 - acc: 0.7880\n",
      "Epoch 00010: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.7118 - acc: 0.7880 - val_loss: 6.9432 - val_acc: 0.1104\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6306 - acc: 0.8116\n",
      "Epoch 00011: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.6307 - acc: 0.8116 - val_loss: 7.7148 - val_acc: 0.0834\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5642 - acc: 0.8308\n",
      "Epoch 00012: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.5642 - acc: 0.8308 - val_loss: 7.8573 - val_acc: 0.0855\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4900 - acc: 0.8577\n",
      "Epoch 00013: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4900 - acc: 0.8578 - val_loss: 7.9068 - val_acc: 0.1160\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4335 - acc: 0.8731\n",
      "Epoch 00014: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.4335 - acc: 0.8731 - val_loss: 8.7585 - val_acc: 0.0804\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3873 - acc: 0.8858\n",
      "Epoch 00015: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3873 - acc: 0.8858 - val_loss: 8.5654 - val_acc: 0.0992\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3478 - acc: 0.8972\n",
      "Epoch 00016: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3478 - acc: 0.8972 - val_loss: 8.6163 - val_acc: 0.1088\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3107 - acc: 0.9082\n",
      "Epoch 00017: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3107 - acc: 0.9082 - val_loss: 8.9644 - val_acc: 0.1053\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3006 - acc: 0.9130\n",
      "Epoch 00018: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3005 - acc: 0.9130 - val_loss: 9.3573 - val_acc: 0.1109\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2738 - acc: 0.9192\n",
      "Epoch 00019: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2738 - acc: 0.9192 - val_loss: 9.3920 - val_acc: 0.1006\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2448 - acc: 0.9285\n",
      "Epoch 00020: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2447 - acc: 0.9285 - val_loss: 9.4413 - val_acc: 0.1179\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9407\n",
      "Epoch 00021: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2074 - acc: 0.9407 - val_loss: 9.6858 - val_acc: 0.1069\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1917 - acc: 0.9455\n",
      "Epoch 00022: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1917 - acc: 0.9455 - val_loss: 9.8279 - val_acc: 0.1118\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1725 - acc: 0.9514\n",
      "Epoch 00023: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1725 - acc: 0.9514 - val_loss: 10.2685 - val_acc: 0.0885\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1818 - acc: 0.9476\n",
      "Epoch 00024: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1818 - acc: 0.9476 - val_loss: 10.2476 - val_acc: 0.0925\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1719 - acc: 0.9500\n",
      "Epoch 00025: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1719 - acc: 0.9500 - val_loss: 10.1452 - val_acc: 0.1190\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1546 - acc: 0.9546\n",
      "Epoch 00026: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1546 - acc: 0.9546 - val_loss: 10.6236 - val_acc: 0.1139\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9616\n",
      "Epoch 00027: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1343 - acc: 0.9616 - val_loss: 11.7780 - val_acc: 0.0778\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1243 - acc: 0.9650\n",
      "Epoch 00028: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1243 - acc: 0.9650 - val_loss: 10.9665 - val_acc: 0.0934\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1262 - acc: 0.9648\n",
      "Epoch 00029: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1262 - acc: 0.9648 - val_loss: 10.4632 - val_acc: 0.1106\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1331 - acc: 0.9611\n",
      "Epoch 00030: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1331 - acc: 0.9611 - val_loss: 10.5193 - val_acc: 0.1153\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1254 - acc: 0.9642\n",
      "Epoch 00031: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1254 - acc: 0.9642 - val_loss: 10.9249 - val_acc: 0.0978\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9669\n",
      "Epoch 00032: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1162 - acc: 0.9669 - val_loss: 11.7573 - val_acc: 0.0850\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9702\n",
      "Epoch 00033: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1026 - acc: 0.9702 - val_loss: 11.3832 - val_acc: 0.1209\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1052 - acc: 0.9702\n",
      "Epoch 00034: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1052 - acc: 0.9702 - val_loss: 10.8395 - val_acc: 0.1118\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9736\n",
      "Epoch 00035: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0951 - acc: 0.9736 - val_loss: 11.0840 - val_acc: 0.1132\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0915 - acc: 0.9732\n",
      "Epoch 00036: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0915 - acc: 0.9732 - val_loss: 10.9345 - val_acc: 0.1018\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9746\n",
      "Epoch 00037: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0885 - acc: 0.9746 - val_loss: 11.0152 - val_acc: 0.1169\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9745\n",
      "Epoch 00038: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0889 - acc: 0.9745 - val_loss: 11.2130 - val_acc: 0.1048\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9716\n",
      "Epoch 00039: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0949 - acc: 0.9716 - val_loss: 11.3807 - val_acc: 0.1204\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9758\n",
      "Epoch 00040: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0850 - acc: 0.9758 - val_loss: 11.2296 - val_acc: 0.1153\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9776\n",
      "Epoch 00041: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0744 - acc: 0.9776 - val_loss: 12.5064 - val_acc: 0.0808\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9819\n",
      "Epoch 00042: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0645 - acc: 0.9819 - val_loss: 11.0817 - val_acc: 0.1207\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9818\n",
      "Epoch 00043: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0643 - acc: 0.9818 - val_loss: 11.2504 - val_acc: 0.1113\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9774\n",
      "Epoch 00044: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0782 - acc: 0.9774 - val_loss: 11.5149 - val_acc: 0.1062\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9745\n",
      "Epoch 00045: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0857 - acc: 0.9745 - val_loss: 11.9569 - val_acc: 0.0971\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9742\n",
      "Epoch 00046: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0841 - acc: 0.9742 - val_loss: 11.7677 - val_acc: 0.1088\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9795\n",
      "Epoch 00047: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0719 - acc: 0.9795 - val_loss: 11.3211 - val_acc: 0.1172\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9831\n",
      "Epoch 00048: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0618 - acc: 0.9831 - val_loss: 11.5643 - val_acc: 0.1123\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9803\n",
      "Epoch 00049: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0677 - acc: 0.9803 - val_loss: 11.5586 - val_acc: 0.1095\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9809\n",
      "Epoch 00050: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0649 - acc: 0.9809 - val_loss: 11.5941 - val_acc: 0.1109\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9824\n",
      "Epoch 00051: val_loss did not improve from 3.00625\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0613 - acc: 0.9824 - val_loss: 11.5825 - val_acc: 0.1106\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 426us/sample - loss: 3.0644 - acc: 0.1020\n",
      "Loss: 3.0644077859068464 Accuracy: 0.101973005\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.0026 - acc: 0.2427\n",
      "Epoch 00001: val_loss improved from inf to 3.17719, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_2_conv_checkpoint/001-3.1772.hdf5\n",
      "36805/36805 [==============================] - 73s 2ms/sample - loss: 3.0026 - acc: 0.2427 - val_loss: 3.1772 - val_acc: 0.2348\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8908 - acc: 0.4863\n",
      "Epoch 00002: val_loss improved from 3.17719 to 2.72158, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_2_conv_checkpoint/002-2.7216.hdf5\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.8911 - acc: 0.4863 - val_loss: 2.7216 - val_acc: 0.3657\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2185 - acc: 0.6470\n",
      "Epoch 00003: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 1.2183 - acc: 0.6470 - val_loss: 4.5265 - val_acc: 0.2455\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7837 - acc: 0.7689\n",
      "Epoch 00004: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.7837 - acc: 0.7689 - val_loss: 4.2376 - val_acc: 0.3336\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5353 - acc: 0.8454\n",
      "Epoch 00005: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.5354 - acc: 0.8453 - val_loss: 3.2514 - val_acc: 0.3659\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3823 - acc: 0.8948\n",
      "Epoch 00006: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.3823 - acc: 0.8948 - val_loss: 3.3709 - val_acc: 0.3736\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2920 - acc: 0.9233\n",
      "Epoch 00007: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2920 - acc: 0.9233 - val_loss: 4.1110 - val_acc: 0.3364\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2704 - acc: 0.9270\n",
      "Epoch 00008: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2704 - acc: 0.9270 - val_loss: 3.5871 - val_acc: 0.3839\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2134 - acc: 0.9458\n",
      "Epoch 00009: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2134 - acc: 0.9458 - val_loss: 5.1930 - val_acc: 0.3170\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2181 - acc: 0.9426\n",
      "Epoch 00010: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 70s 2ms/sample - loss: 0.2181 - acc: 0.9426 - val_loss: 5.3703 - val_acc: 0.3096\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2246 - acc: 0.9377\n",
      "Epoch 00011: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2247 - acc: 0.9377 - val_loss: 4.8213 - val_acc: 0.3415\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2053 - acc: 0.9440\n",
      "Epoch 00012: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.2054 - acc: 0.9440 - val_loss: 6.6906 - val_acc: 0.2714\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9542\n",
      "Epoch 00013: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1680 - acc: 0.9542 - val_loss: 4.9801 - val_acc: 0.3515\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9650\n",
      "Epoch 00014: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1359 - acc: 0.9650 - val_loss: 5.4652 - val_acc: 0.3343\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9596\n",
      "Epoch 00015: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1550 - acc: 0.9596 - val_loss: 6.4055 - val_acc: 0.2888\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9664\n",
      "Epoch 00016: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1376 - acc: 0.9664 - val_loss: 5.0292 - val_acc: 0.3776\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9654\n",
      "Epoch 00017: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1312 - acc: 0.9654 - val_loss: 7.0292 - val_acc: 0.2949\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9660\n",
      "Epoch 00018: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1240 - acc: 0.9660 - val_loss: 5.2614 - val_acc: 0.3802\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9663\n",
      "Epoch 00019: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1302 - acc: 0.9663 - val_loss: 5.9417 - val_acc: 0.3273\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9649\n",
      "Epoch 00020: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1362 - acc: 0.9649 - val_loss: 6.8539 - val_acc: 0.2977\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9703\n",
      "Epoch 00021: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1155 - acc: 0.9702 - val_loss: 5.8364 - val_acc: 0.3492\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9674\n",
      "Epoch 00022: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1305 - acc: 0.9674 - val_loss: 6.0490 - val_acc: 0.3543\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9698\n",
      "Epoch 00023: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1220 - acc: 0.9698 - val_loss: 6.1816 - val_acc: 0.3461\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9724\n",
      "Epoch 00024: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1115 - acc: 0.9724 - val_loss: 5.9486 - val_acc: 0.3664\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1009 - acc: 0.9766\n",
      "Epoch 00025: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.1008 - acc: 0.9766 - val_loss: 5.7951 - val_acc: 0.3708\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9761\n",
      "Epoch 00026: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0992 - acc: 0.9761 - val_loss: 6.3217 - val_acc: 0.3629\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9780\n",
      "Epoch 00027: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0912 - acc: 0.9780 - val_loss: 6.3006 - val_acc: 0.3531\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0968 - acc: 0.9777\n",
      "Epoch 00028: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0968 - acc: 0.9777 - val_loss: 6.0876 - val_acc: 0.3715\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9785\n",
      "Epoch 00029: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0919 - acc: 0.9785 - val_loss: 6.2480 - val_acc: 0.3720\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9780\n",
      "Epoch 00030: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0925 - acc: 0.9780 - val_loss: 6.0199 - val_acc: 0.3757\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9820\n",
      "Epoch 00031: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0701 - acc: 0.9820 - val_loss: 6.1340 - val_acc: 0.3659\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9820\n",
      "Epoch 00032: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0719 - acc: 0.9820 - val_loss: 6.8678 - val_acc: 0.3555\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9760\n",
      "Epoch 00033: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0957 - acc: 0.9760 - val_loss: 6.7799 - val_acc: 0.3522\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9798\n",
      "Epoch 00034: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0874 - acc: 0.9798 - val_loss: 7.3339 - val_acc: 0.3431\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9792\n",
      "Epoch 00035: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0843 - acc: 0.9792 - val_loss: 6.0975 - val_acc: 0.3816\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9830\n",
      "Epoch 00036: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0698 - acc: 0.9830 - val_loss: 6.2506 - val_acc: 0.3864\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9808\n",
      "Epoch 00037: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0817 - acc: 0.9808 - val_loss: 7.2591 - val_acc: 0.3436\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9838\n",
      "Epoch 00038: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0689 - acc: 0.9838 - val_loss: 6.4335 - val_acc: 0.3857\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9815\n",
      "Epoch 00039: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0808 - acc: 0.9815 - val_loss: 7.6794 - val_acc: 0.3149\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9824\n",
      "Epoch 00040: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0769 - acc: 0.9824 - val_loss: 6.8996 - val_acc: 0.3708\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9851\n",
      "Epoch 00041: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0616 - acc: 0.9851 - val_loss: 6.7431 - val_acc: 0.3566\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9846\n",
      "Epoch 00042: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0665 - acc: 0.9846 - val_loss: 6.7327 - val_acc: 0.3592\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9868\n",
      "Epoch 00043: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0541 - acc: 0.9868 - val_loss: 6.8072 - val_acc: 0.3604\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9866\n",
      "Epoch 00044: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0569 - acc: 0.9866 - val_loss: 6.3900 - val_acc: 0.3974\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9830\n",
      "Epoch 00045: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0734 - acc: 0.9830 - val_loss: 6.7927 - val_acc: 0.3811\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9859\n",
      "Epoch 00046: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0608 - acc: 0.9859 - val_loss: 6.7561 - val_acc: 0.3823\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9867\n",
      "Epoch 00047: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0589 - acc: 0.9867 - val_loss: 7.3168 - val_acc: 0.3438\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9862\n",
      "Epoch 00048: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0610 - acc: 0.9862 - val_loss: 7.6616 - val_acc: 0.3329\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0666 - acc: 0.9855\n",
      "Epoch 00049: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0666 - acc: 0.9855 - val_loss: 7.0178 - val_acc: 0.3711\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9865\n",
      "Epoch 00050: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0600 - acc: 0.9866 - val_loss: 7.0138 - val_acc: 0.3732\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9841\n",
      "Epoch 00051: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0727 - acc: 0.9841 - val_loss: 6.8819 - val_acc: 0.3757\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9856\n",
      "Epoch 00052: val_loss did not improve from 2.72158\n",
      "36805/36805 [==============================] - 71s 2ms/sample - loss: 0.0668 - acc: 0.9856 - val_loss: 6.9058 - val_acc: 0.3792\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 731us/sample - loss: 2.8316 - acc: 0.3246\n",
      "Loss: 2.8315895648017477 Accuracy: 0.3246106\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1080 - acc: 0.3761\n",
      "Epoch 00001: val_loss improved from inf to 1.79469, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_3_conv_checkpoint/001-1.7947.hdf5\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 2.1081 - acc: 0.3761 - val_loss: 1.7947 - val_acc: 0.4477\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2548 - acc: 0.6199\n",
      "Epoch 00002: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 1.2549 - acc: 0.6199 - val_loss: 3.5024 - val_acc: 0.2863\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8874 - acc: 0.7292\n",
      "Epoch 00003: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.8875 - acc: 0.7292 - val_loss: 2.0531 - val_acc: 0.4603\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6491 - acc: 0.8095\n",
      "Epoch 00004: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.6491 - acc: 0.8095 - val_loss: 3.2396 - val_acc: 0.3650\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4812 - acc: 0.8655\n",
      "Epoch 00005: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.4812 - acc: 0.8655 - val_loss: 2.2591 - val_acc: 0.4722\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3566 - acc: 0.9103\n",
      "Epoch 00006: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.3566 - acc: 0.9103 - val_loss: 1.9196 - val_acc: 0.5001\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2682 - acc: 0.9381\n",
      "Epoch 00007: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2682 - acc: 0.9381 - val_loss: 2.9977 - val_acc: 0.3597\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2184 - acc: 0.9535\n",
      "Epoch 00008: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.2184 - acc: 0.9535 - val_loss: 2.2803 - val_acc: 0.4594\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1809 - acc: 0.9640\n",
      "Epoch 00009: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1809 - acc: 0.9640 - val_loss: 2.4620 - val_acc: 0.4621\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1562 - acc: 0.9692\n",
      "Epoch 00010: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1562 - acc: 0.9692 - val_loss: 2.6023 - val_acc: 0.4421\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1350 - acc: 0.9752\n",
      "Epoch 00011: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1350 - acc: 0.9752 - val_loss: 2.1335 - val_acc: 0.5465\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9800\n",
      "Epoch 00012: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1128 - acc: 0.9799 - val_loss: 1.9722 - val_acc: 0.5723\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9783\n",
      "Epoch 00013: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1111 - acc: 0.9783 - val_loss: 2.0320 - val_acc: 0.5472\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9815\n",
      "Epoch 00014: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0933 - acc: 0.9816 - val_loss: 2.4925 - val_acc: 0.4987\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9830\n",
      "Epoch 00015: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0914 - acc: 0.9830 - val_loss: 2.3811 - val_acc: 0.5476\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9870\n",
      "Epoch 00016: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0747 - acc: 0.9870 - val_loss: 2.1035 - val_acc: 0.5656\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9871\n",
      "Epoch 00017: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0700 - acc: 0.9871 - val_loss: 2.0644 - val_acc: 0.5821\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9793\n",
      "Epoch 00018: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1014 - acc: 0.9792 - val_loss: 3.2357 - val_acc: 0.4673\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9657\n",
      "Epoch 00019: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.1424 - acc: 0.9657 - val_loss: 2.2292 - val_acc: 0.5730\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9932\n",
      "Epoch 00020: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0454 - acc: 0.9932 - val_loss: 3.1785 - val_acc: 0.4712\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9904\n",
      "Epoch 00021: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0569 - acc: 0.9904 - val_loss: 2.4520 - val_acc: 0.5367\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9901\n",
      "Epoch 00022: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0522 - acc: 0.9901 - val_loss: 2.4071 - val_acc: 0.5611\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9925\n",
      "Epoch 00023: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0441 - acc: 0.9925 - val_loss: 2.5684 - val_acc: 0.5399\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9877\n",
      "Epoch 00024: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0592 - acc: 0.9877 - val_loss: 2.6840 - val_acc: 0.5318\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0439 - acc: 0.9915\n",
      "Epoch 00025: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0439 - acc: 0.9916 - val_loss: 2.4666 - val_acc: 0.5775\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9914\n",
      "Epoch 00026: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0445 - acc: 0.9914 - val_loss: 2.5546 - val_acc: 0.5642\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9889\n",
      "Epoch 00027: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0530 - acc: 0.9889 - val_loss: 2.4904 - val_acc: 0.5509\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9914\n",
      "Epoch 00028: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0402 - acc: 0.9914 - val_loss: 2.5695 - val_acc: 0.5444\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9891\n",
      "Epoch 00029: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0526 - acc: 0.9891 - val_loss: 2.9579 - val_acc: 0.5290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9940\n",
      "Epoch 00030: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0309 - acc: 0.9940 - val_loss: 3.1503 - val_acc: 0.5073\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9942\n",
      "Epoch 00031: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0320 - acc: 0.9942 - val_loss: 2.9321 - val_acc: 0.5246\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9865\n",
      "Epoch 00032: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0573 - acc: 0.9865 - val_loss: 3.0355 - val_acc: 0.5348\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9916\n",
      "Epoch 00033: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0407 - acc: 0.9916 - val_loss: 2.7926 - val_acc: 0.5597\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9895\n",
      "Epoch 00034: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0474 - acc: 0.9895 - val_loss: 3.0397 - val_acc: 0.5253\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9926\n",
      "Epoch 00035: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0387 - acc: 0.9926 - val_loss: 2.6892 - val_acc: 0.5579\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9894\n",
      "Epoch 00036: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0516 - acc: 0.9894 - val_loss: 2.4621 - val_acc: 0.5868\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9947\n",
      "Epoch 00037: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0288 - acc: 0.9947 - val_loss: 2.5529 - val_acc: 0.5828\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9935\n",
      "Epoch 00038: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0324 - acc: 0.9935 - val_loss: 2.9072 - val_acc: 0.5674\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9938\n",
      "Epoch 00039: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0287 - acc: 0.9938 - val_loss: 2.9201 - val_acc: 0.5455\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9889\n",
      "Epoch 00040: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0455 - acc: 0.9889 - val_loss: 2.7121 - val_acc: 0.5809\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9929\n",
      "Epoch 00041: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0321 - acc: 0.9929 - val_loss: 2.6550 - val_acc: 0.5830\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9937\n",
      "Epoch 00042: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0293 - acc: 0.9937 - val_loss: 3.3216 - val_acc: 0.5285\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9943\n",
      "Epoch 00043: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0278 - acc: 0.9943 - val_loss: 2.7684 - val_acc: 0.5665\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9930\n",
      "Epoch 00044: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0321 - acc: 0.9930 - val_loss: 3.1615 - val_acc: 0.5395\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9927\n",
      "Epoch 00045: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0340 - acc: 0.9927 - val_loss: 3.3570 - val_acc: 0.5351\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9913\n",
      "Epoch 00046: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0358 - acc: 0.9913 - val_loss: 2.9854 - val_acc: 0.5586\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9929\n",
      "Epoch 00047: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0309 - acc: 0.9929 - val_loss: 2.7352 - val_acc: 0.5807\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0214 - acc: 0.9953\n",
      "Epoch 00048: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0214 - acc: 0.9953 - val_loss: 4.0062 - val_acc: 0.4726\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9920\n",
      "Epoch 00049: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0406 - acc: 0.9920 - val_loss: 3.9478 - val_acc: 0.4738\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9931\n",
      "Epoch 00050: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0325 - acc: 0.9931 - val_loss: 2.9212 - val_acc: 0.5646\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9940\n",
      "Epoch 00051: val_loss did not improve from 1.79469\n",
      "36805/36805 [==============================] - 81s 2ms/sample - loss: 0.0264 - acc: 0.9940 - val_loss: 3.3135 - val_acc: 0.5386\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 844us/sample - loss: 1.8795 - acc: 0.4295\n",
      "Loss: 1.879499415222358 Accuracy: 0.42949116\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8377 - acc: 0.4319\n",
      "Epoch 00001: val_loss improved from inf to 1.69651, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_4_conv_checkpoint/001-1.6965.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.8377 - acc: 0.4319 - val_loss: 1.6965 - val_acc: 0.4722\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2276 - acc: 0.6290\n",
      "Epoch 00002: val_loss did not improve from 1.69651\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 1.2275 - acc: 0.6290 - val_loss: 2.3154 - val_acc: 0.4263\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9965 - acc: 0.6983\n",
      "Epoch 00003: val_loss did not improve from 1.69651\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.9966 - acc: 0.6984 - val_loss: 3.0509 - val_acc: 0.3517\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8381 - acc: 0.7484\n",
      "Epoch 00004: val_loss did not improve from 1.69651\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.8381 - acc: 0.7484 - val_loss: 1.7505 - val_acc: 0.4969\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7175 - acc: 0.7875\n",
      "Epoch 00005: val_loss did not improve from 1.69651\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.7175 - acc: 0.7875 - val_loss: 1.7829 - val_acc: 0.5390\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6193 - acc: 0.8186\n",
      "Epoch 00006: val_loss did not improve from 1.69651\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.6193 - acc: 0.8186 - val_loss: 2.4671 - val_acc: 0.4477\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5414 - acc: 0.8456\n",
      "Epoch 00007: val_loss did not improve from 1.69651\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.5414 - acc: 0.8456 - val_loss: 2.7594 - val_acc: 0.4151\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4688 - acc: 0.8689\n",
      "Epoch 00008: val_loss did not improve from 1.69651\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4687 - acc: 0.8689 - val_loss: 2.7147 - val_acc: 0.4507\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4097 - acc: 0.8890\n",
      "Epoch 00009: val_loss improved from 1.69651 to 1.67904, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_4_conv_checkpoint/009-1.6790.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.4097 - acc: 0.8890 - val_loss: 1.6790 - val_acc: 0.5667\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3541 - acc: 0.9073\n",
      "Epoch 00010: val_loss improved from 1.67904 to 1.32598, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_4_conv_checkpoint/010-1.3260.hdf5\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.3541 - acc: 0.9073 - val_loss: 1.3260 - val_acc: 0.6296\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3155 - acc: 0.9186\n",
      "Epoch 00011: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 84s 2ms/sample - loss: 0.3155 - acc: 0.9186 - val_loss: 4.1639 - val_acc: 0.3098\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2765 - acc: 0.9323\n",
      "Epoch 00012: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2767 - acc: 0.9322 - val_loss: 2.2544 - val_acc: 0.5234\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2500 - acc: 0.9398\n",
      "Epoch 00013: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2500 - acc: 0.9397 - val_loss: 1.5388 - val_acc: 0.6000\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2191 - acc: 0.9500\n",
      "Epoch 00014: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2191 - acc: 0.9500 - val_loss: 2.1793 - val_acc: 0.5227\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2001 - acc: 0.9543\n",
      "Epoch 00015: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.2001 - acc: 0.9544 - val_loss: 2.7982 - val_acc: 0.4575\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1777 - acc: 0.9607\n",
      "Epoch 00016: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1777 - acc: 0.9607 - val_loss: 1.9939 - val_acc: 0.5150\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1641 - acc: 0.9643\n",
      "Epoch 00017: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1641 - acc: 0.9643 - val_loss: 3.6876 - val_acc: 0.4065\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1485 - acc: 0.9679\n",
      "Epoch 00018: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1485 - acc: 0.9679 - val_loss: 2.6998 - val_acc: 0.4759\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9742\n",
      "Epoch 00019: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1314 - acc: 0.9742 - val_loss: 1.5927 - val_acc: 0.6373\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1297 - acc: 0.9738\n",
      "Epoch 00020: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1297 - acc: 0.9738 - val_loss: 3.1498 - val_acc: 0.4498\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9765\n",
      "Epoch 00021: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1144 - acc: 0.9765 - val_loss: 2.6250 - val_acc: 0.5164\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9801\n",
      "Epoch 00022: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1038 - acc: 0.9800 - val_loss: 4.0407 - val_acc: 0.4004\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9787\n",
      "Epoch 00023: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.1051 - acc: 0.9787 - val_loss: 2.4115 - val_acc: 0.5229\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9812\n",
      "Epoch 00024: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0965 - acc: 0.9811 - val_loss: 1.5636 - val_acc: 0.6518\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9824\n",
      "Epoch 00025: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0900 - acc: 0.9824 - val_loss: 2.8581 - val_acc: 0.5167\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9839\n",
      "Epoch 00026: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0831 - acc: 0.9839 - val_loss: 3.4892 - val_acc: 0.4635\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9844\n",
      "Epoch 00027: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0815 - acc: 0.9844 - val_loss: 3.4169 - val_acc: 0.4531\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9847\n",
      "Epoch 00028: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0783 - acc: 0.9847 - val_loss: 1.9930 - val_acc: 0.5858\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9854\n",
      "Epoch 00029: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0762 - acc: 0.9854 - val_loss: 2.3747 - val_acc: 0.5432\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9876\n",
      "Epoch 00030: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0694 - acc: 0.9876 - val_loss: 1.9970 - val_acc: 0.6014\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9871\n",
      "Epoch 00031: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0692 - acc: 0.9871 - val_loss: 2.0837 - val_acc: 0.5812\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9877\n",
      "Epoch 00032: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0640 - acc: 0.9877 - val_loss: 2.4744 - val_acc: 0.5679\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9901\n",
      "Epoch 00033: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0541 - acc: 0.9901 - val_loss: 3.3523 - val_acc: 0.4705\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9877\n",
      "Epoch 00034: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0639 - acc: 0.9877 - val_loss: 2.4036 - val_acc: 0.5658\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9889\n",
      "Epoch 00035: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0568 - acc: 0.9888 - val_loss: 2.2404 - val_acc: 0.5842\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9907\n",
      "Epoch 00036: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0489 - acc: 0.9907 - val_loss: 1.4371 - val_acc: 0.6862\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9897\n",
      "Epoch 00037: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0555 - acc: 0.9897 - val_loss: 2.0764 - val_acc: 0.6066\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9885\n",
      "Epoch 00038: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0560 - acc: 0.9885 - val_loss: 2.0424 - val_acc: 0.6196\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9912\n",
      "Epoch 00039: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0466 - acc: 0.9912 - val_loss: 2.2447 - val_acc: 0.5917\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9876\n",
      "Epoch 00040: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0566 - acc: 0.9876 - val_loss: 2.0960 - val_acc: 0.6266\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9924\n",
      "Epoch 00041: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0456 - acc: 0.9924 - val_loss: 1.8688 - val_acc: 0.6373\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9919\n",
      "Epoch 00042: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0446 - acc: 0.9919 - val_loss: 3.0741 - val_acc: 0.5346\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9927\n",
      "Epoch 00043: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0413 - acc: 0.9927 - val_loss: 2.1170 - val_acc: 0.6105\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9921\n",
      "Epoch 00044: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0411 - acc: 0.9921 - val_loss: 2.1656 - val_acc: 0.5996\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9918\n",
      "Epoch 00045: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0429 - acc: 0.9918 - val_loss: 2.2241 - val_acc: 0.5959\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9925\n",
      "Epoch 00046: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0399 - acc: 0.9925 - val_loss: 2.0015 - val_acc: 0.6203\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0367 - acc: 0.9933\n",
      "Epoch 00047: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0367 - acc: 0.9933 - val_loss: 1.9806 - val_acc: 0.6310\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9905\n",
      "Epoch 00048: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0458 - acc: 0.9905 - val_loss: 2.9402 - val_acc: 0.5465\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9903\n",
      "Epoch 00049: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0428 - acc: 0.9903 - val_loss: 1.6293 - val_acc: 0.6762\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9924\n",
      "Epoch 00050: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0409 - acc: 0.9924 - val_loss: 2.3945 - val_acc: 0.5784\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9941\n",
      "Epoch 00051: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0321 - acc: 0.9941 - val_loss: 1.5645 - val_acc: 0.6900\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9944\n",
      "Epoch 00052: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0311 - acc: 0.9944 - val_loss: 1.8807 - val_acc: 0.6464\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9914\n",
      "Epoch 00053: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0398 - acc: 0.9914 - val_loss: 1.6510 - val_acc: 0.6876\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0333 - acc: 0.9938\n",
      "Epoch 00054: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0333 - acc: 0.9938 - val_loss: 1.7309 - val_acc: 0.6704\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9941\n",
      "Epoch 00055: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0306 - acc: 0.9941 - val_loss: 2.0478 - val_acc: 0.6231\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9914\n",
      "Epoch 00056: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0417 - acc: 0.9914 - val_loss: 3.9037 - val_acc: 0.4731\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9942\n",
      "Epoch 00057: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0327 - acc: 0.9942 - val_loss: 1.7356 - val_acc: 0.6771\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9923\n",
      "Epoch 00058: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0382 - acc: 0.9923 - val_loss: 1.6773 - val_acc: 0.6851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0286 - acc: 0.9945\n",
      "Epoch 00059: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0286 - acc: 0.9945 - val_loss: 2.2440 - val_acc: 0.6061\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9939\n",
      "Epoch 00060: val_loss did not improve from 1.32598\n",
      "36805/36805 [==============================] - 85s 2ms/sample - loss: 0.0314 - acc: 0.9939 - val_loss: 1.6700 - val_acc: 0.6746\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 873us/sample - loss: 1.3915 - acc: 0.6079\n",
      "Loss: 1.3915153474698805 Accuracy: 0.607892\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7787 - acc: 0.4496\n",
      "Epoch 00001: val_loss improved from inf to 1.29033, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_5_conv_checkpoint/001-1.2903.hdf5\n",
      "36805/36805 [==============================] - 94s 3ms/sample - loss: 1.7787 - acc: 0.4496 - val_loss: 1.2903 - val_acc: 0.6042\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1938 - acc: 0.6370\n",
      "Epoch 00002: val_loss did not improve from 1.29033\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 1.1942 - acc: 0.6370 - val_loss: 1.7057 - val_acc: 0.5218\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9991 - acc: 0.7002\n",
      "Epoch 00003: val_loss did not improve from 1.29033\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.9992 - acc: 0.7002 - val_loss: 2.1497 - val_acc: 0.4358\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8611 - acc: 0.7413\n",
      "Epoch 00004: val_loss improved from 1.29033 to 1.24389, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_5_conv_checkpoint/004-1.2439.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.8611 - acc: 0.7413 - val_loss: 1.2439 - val_acc: 0.6448\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7519 - acc: 0.7761\n",
      "Epoch 00005: val_loss did not improve from 1.24389\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.7519 - acc: 0.7761 - val_loss: 1.4970 - val_acc: 0.5847\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6662 - acc: 0.8019\n",
      "Epoch 00006: val_loss improved from 1.24389 to 0.92839, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_5_conv_checkpoint/006-0.9284.hdf5\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.6661 - acc: 0.8019 - val_loss: 0.9284 - val_acc: 0.7347\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5944 - acc: 0.8274\n",
      "Epoch 00007: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5944 - acc: 0.8274 - val_loss: 1.7836 - val_acc: 0.5707\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5353 - acc: 0.8430\n",
      "Epoch 00008: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.5352 - acc: 0.8431 - val_loss: 1.2622 - val_acc: 0.6431\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4801 - acc: 0.8608\n",
      "Epoch 00009: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4801 - acc: 0.8608 - val_loss: 1.1682 - val_acc: 0.6676\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4348 - acc: 0.8751\n",
      "Epoch 00010: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.4348 - acc: 0.8750 - val_loss: 2.2342 - val_acc: 0.4778\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3881 - acc: 0.8880\n",
      "Epoch 00011: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3884 - acc: 0.8880 - val_loss: 2.0724 - val_acc: 0.5057\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3529 - acc: 0.9000\n",
      "Epoch 00012: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3529 - acc: 0.9000 - val_loss: 1.3637 - val_acc: 0.6259\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3250 - acc: 0.9096\n",
      "Epoch 00013: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.3250 - acc: 0.9096 - val_loss: 1.4978 - val_acc: 0.6296\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2881 - acc: 0.9206\n",
      "Epoch 00014: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2881 - acc: 0.9206 - val_loss: 1.1150 - val_acc: 0.6851\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2699 - acc: 0.9272\n",
      "Epoch 00015: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2700 - acc: 0.9272 - val_loss: 2.5425 - val_acc: 0.5113\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2450 - acc: 0.9338\n",
      "Epoch 00016: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2450 - acc: 0.9338 - val_loss: 1.8425 - val_acc: 0.5660\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2184 - acc: 0.9442\n",
      "Epoch 00017: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2184 - acc: 0.9442 - val_loss: 2.4983 - val_acc: 0.4745\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2101 - acc: 0.9455\n",
      "Epoch 00018: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.2101 - acc: 0.9454 - val_loss: 1.2215 - val_acc: 0.6848\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1895 - acc: 0.9515\n",
      "Epoch 00019: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1895 - acc: 0.9515 - val_loss: 2.4591 - val_acc: 0.5034\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1740 - acc: 0.9565\n",
      "Epoch 00020: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1741 - acc: 0.9565 - val_loss: 1.4644 - val_acc: 0.6448\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1668 - acc: 0.9584\n",
      "Epoch 00021: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1668 - acc: 0.9584 - val_loss: 3.5197 - val_acc: 0.3983\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1460 - acc: 0.9649\n",
      "Epoch 00022: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1460 - acc: 0.9649 - val_loss: 1.1756 - val_acc: 0.7072\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1413 - acc: 0.9658\n",
      "Epoch 00023: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1414 - acc: 0.9657 - val_loss: 1.2879 - val_acc: 0.6972\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1361 - acc: 0.9681\n",
      "Epoch 00024: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1362 - acc: 0.9680 - val_loss: 1.1397 - val_acc: 0.7181\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9686\n",
      "Epoch 00025: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1303 - acc: 0.9686 - val_loss: 1.5953 - val_acc: 0.6152\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9745\n",
      "Epoch 00026: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1147 - acc: 0.9745 - val_loss: 1.8904 - val_acc: 0.6110\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9745\n",
      "Epoch 00027: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1085 - acc: 0.9745 - val_loss: 1.5086 - val_acc: 0.6443\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9767\n",
      "Epoch 00028: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1028 - acc: 0.9766 - val_loss: 1.4434 - val_acc: 0.6699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1065 - acc: 0.9741\n",
      "Epoch 00029: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1065 - acc: 0.9741 - val_loss: 1.8267 - val_acc: 0.6268\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9788\n",
      "Epoch 00030: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0931 - acc: 0.9788 - val_loss: 1.6927 - val_acc: 0.6189\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9792\n",
      "Epoch 00031: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0906 - acc: 0.9792 - val_loss: 1.1087 - val_acc: 0.7391\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9799\n",
      "Epoch 00032: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0888 - acc: 0.9799 - val_loss: 2.2401 - val_acc: 0.5674\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9820\n",
      "Epoch 00033: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0815 - acc: 0.9820 - val_loss: 2.6174 - val_acc: 0.5372\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9835\n",
      "Epoch 00034: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0761 - acc: 0.9835 - val_loss: 1.2164 - val_acc: 0.7244\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9804\n",
      "Epoch 00035: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0806 - acc: 0.9804 - val_loss: 1.0478 - val_acc: 0.7498\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9835\n",
      "Epoch 00036: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0732 - acc: 0.9835 - val_loss: 1.0966 - val_acc: 0.7531\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9853\n",
      "Epoch 00037: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0661 - acc: 0.9853 - val_loss: 1.7559 - val_acc: 0.6674\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9826\n",
      "Epoch 00038: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0756 - acc: 0.9826 - val_loss: 2.1126 - val_acc: 0.5935\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9763\n",
      "Epoch 00039: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.1013 - acc: 0.9763 - val_loss: 1.0726 - val_acc: 0.7570\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9879\n",
      "Epoch 00040: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0574 - acc: 0.9879 - val_loss: 1.3597 - val_acc: 0.7188\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9851\n",
      "Epoch 00041: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0673 - acc: 0.9851 - val_loss: 1.8085 - val_acc: 0.6571\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9894\n",
      "Epoch 00042: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0538 - acc: 0.9894 - val_loss: 1.4563 - val_acc: 0.7018\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9870\n",
      "Epoch 00043: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0585 - acc: 0.9870 - val_loss: 1.4171 - val_acc: 0.7030\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9864\n",
      "Epoch 00044: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0604 - acc: 0.9864 - val_loss: 1.2408 - val_acc: 0.7396\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9870\n",
      "Epoch 00045: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0590 - acc: 0.9870 - val_loss: 1.2422 - val_acc: 0.7372\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9883\n",
      "Epoch 00046: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0539 - acc: 0.9883 - val_loss: 2.1700 - val_acc: 0.5968\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9877\n",
      "Epoch 00047: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0552 - acc: 0.9877 - val_loss: 1.5520 - val_acc: 0.6946\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9883\n",
      "Epoch 00048: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0520 - acc: 0.9883 - val_loss: 1.5997 - val_acc: 0.6932\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9879\n",
      "Epoch 00049: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0534 - acc: 0.9879 - val_loss: 1.6317 - val_acc: 0.6890\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9904\n",
      "Epoch 00050: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0469 - acc: 0.9904 - val_loss: 1.8351 - val_acc: 0.6771\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9888\n",
      "Epoch 00051: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0497 - acc: 0.9888 - val_loss: 1.2944 - val_acc: 0.7468\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9884\n",
      "Epoch 00052: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0495 - acc: 0.9884 - val_loss: 1.4481 - val_acc: 0.7179\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9885\n",
      "Epoch 00053: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0501 - acc: 0.9885 - val_loss: 1.8216 - val_acc: 0.6571\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9893\n",
      "Epoch 00054: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0483 - acc: 0.9893 - val_loss: 1.2315 - val_acc: 0.7454\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0452 - acc: 0.9901\n",
      "Epoch 00055: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0452 - acc: 0.9901 - val_loss: 1.4901 - val_acc: 0.7202\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9883\n",
      "Epoch 00056: val_loss did not improve from 0.92839\n",
      "36805/36805 [==============================] - 87s 2ms/sample - loss: 0.0502 - acc: 0.9883 - val_loss: 1.4060 - val_acc: 0.7372\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 4s 923us/sample - loss: 1.0521 - acc: 0.6947\n",
      "Loss: 1.0520976801156254 Accuracy: 0.69470406\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8395 - acc: 0.4285\n",
      "Epoch 00001: val_loss improved from inf to 1.48074, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_6_conv_checkpoint/001-1.4807.hdf5\n",
      "36805/36805 [==============================] - 98s 3ms/sample - loss: 1.8393 - acc: 0.4286 - val_loss: 1.4807 - val_acc: 0.5395\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2432 - acc: 0.6212\n",
      "Epoch 00002: val_loss did not improve from 1.48074\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.2431 - acc: 0.6212 - val_loss: 1.5299 - val_acc: 0.5206\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0457 - acc: 0.6857\n",
      "Epoch 00003: val_loss did not improve from 1.48074\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 1.0457 - acc: 0.6857 - val_loss: 1.5014 - val_acc: 0.5395\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9232 - acc: 0.7256\n",
      "Epoch 00004: val_loss improved from 1.48074 to 1.31473, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_6_conv_checkpoint/004-1.3147.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.9233 - acc: 0.7256 - val_loss: 1.3147 - val_acc: 0.6077\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8389 - acc: 0.7514\n",
      "Epoch 00005: val_loss did not improve from 1.31473\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.8392 - acc: 0.7514 - val_loss: 1.5246 - val_acc: 0.5544\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7726 - acc: 0.7691\n",
      "Epoch 00006: val_loss did not improve from 1.31473\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7726 - acc: 0.7691 - val_loss: 1.3934 - val_acc: 0.6014\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7138 - acc: 0.7880\n",
      "Epoch 00007: val_loss did not improve from 1.31473\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.7138 - acc: 0.7880 - val_loss: 1.3842 - val_acc: 0.6026\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6662 - acc: 0.8046\n",
      "Epoch 00008: val_loss improved from 1.31473 to 1.04492, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_6_conv_checkpoint/008-1.0449.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6662 - acc: 0.8046 - val_loss: 1.0449 - val_acc: 0.6916\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6239 - acc: 0.8180\n",
      "Epoch 00009: val_loss did not improve from 1.04492\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.6239 - acc: 0.8180 - val_loss: 1.0805 - val_acc: 0.6737\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5858 - acc: 0.8280\n",
      "Epoch 00010: val_loss did not improve from 1.04492\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5859 - acc: 0.8279 - val_loss: 1.3390 - val_acc: 0.6252\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5561 - acc: 0.8371\n",
      "Epoch 00011: val_loss did not improve from 1.04492\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5560 - acc: 0.8371 - val_loss: 1.0803 - val_acc: 0.6867\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5196 - acc: 0.8479\n",
      "Epoch 00012: val_loss did not improve from 1.04492\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.5197 - acc: 0.8479 - val_loss: 1.3714 - val_acc: 0.6301\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4951 - acc: 0.8546\n",
      "Epoch 00013: val_loss did not improve from 1.04492\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4952 - acc: 0.8546 - val_loss: 1.3849 - val_acc: 0.6126\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4706 - acc: 0.8642\n",
      "Epoch 00014: val_loss did not improve from 1.04492\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4706 - acc: 0.8642 - val_loss: 1.2183 - val_acc: 0.6765\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4384 - acc: 0.8730\n",
      "Epoch 00015: val_loss did not improve from 1.04492\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4385 - acc: 0.8730 - val_loss: 1.1340 - val_acc: 0.6935\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4199 - acc: 0.8779\n",
      "Epoch 00016: val_loss improved from 1.04492 to 0.90231, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_6_conv_checkpoint/016-0.9023.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.4199 - acc: 0.8778 - val_loss: 0.9023 - val_acc: 0.7358\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3974 - acc: 0.8846\n",
      "Epoch 00017: val_loss did not improve from 0.90231\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3974 - acc: 0.8847 - val_loss: 1.2211 - val_acc: 0.6909\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3786 - acc: 0.8915\n",
      "Epoch 00018: val_loss improved from 0.90231 to 0.88948, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_6_conv_checkpoint/018-0.8895.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3786 - acc: 0.8915 - val_loss: 0.8895 - val_acc: 0.7468\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3558 - acc: 0.8986\n",
      "Epoch 00019: val_loss did not improve from 0.88948\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3558 - acc: 0.8986 - val_loss: 1.0261 - val_acc: 0.7060\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3411 - acc: 0.9007\n",
      "Epoch 00020: val_loss did not improve from 0.88948\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3411 - acc: 0.9007 - val_loss: 0.9238 - val_acc: 0.7531\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3217 - acc: 0.9085\n",
      "Epoch 00021: val_loss did not improve from 0.88948\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3218 - acc: 0.9085 - val_loss: 0.9228 - val_acc: 0.7438\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3071 - acc: 0.9127\n",
      "Epoch 00022: val_loss improved from 0.88948 to 0.86941, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_6_conv_checkpoint/022-0.8694.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.3071 - acc: 0.9127 - val_loss: 0.8694 - val_acc: 0.7554\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2896 - acc: 0.9167\n",
      "Epoch 00023: val_loss did not improve from 0.86941\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2896 - acc: 0.9166 - val_loss: 1.5102 - val_acc: 0.6273\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2820 - acc: 0.9183\n",
      "Epoch 00024: val_loss did not improve from 0.86941\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2821 - acc: 0.9182 - val_loss: 1.2720 - val_acc: 0.6755\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2668 - acc: 0.9245\n",
      "Epoch 00025: val_loss did not improve from 0.86941\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2667 - acc: 0.9245 - val_loss: 1.0953 - val_acc: 0.7072\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2531 - acc: 0.9272\n",
      "Epoch 00026: val_loss did not improve from 0.86941\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2532 - acc: 0.9272 - val_loss: 1.3461 - val_acc: 0.6860\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2455 - acc: 0.9315\n",
      "Epoch 00027: val_loss did not improve from 0.86941\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2455 - acc: 0.9315 - val_loss: 0.9133 - val_acc: 0.7522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2286 - acc: 0.9366\n",
      "Epoch 00028: val_loss improved from 0.86941 to 0.79614, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_6_conv_checkpoint/028-0.7961.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2286 - acc: 0.9366 - val_loss: 0.7961 - val_acc: 0.7857\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2186 - acc: 0.9388\n",
      "Epoch 00029: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2186 - acc: 0.9388 - val_loss: 1.4004 - val_acc: 0.6669\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9426\n",
      "Epoch 00030: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2076 - acc: 0.9426 - val_loss: 1.2657 - val_acc: 0.7174\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2165 - acc: 0.9399\n",
      "Epoch 00031: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.2165 - acc: 0.9399 - val_loss: 0.8573 - val_acc: 0.7738\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1870 - acc: 0.9500\n",
      "Epoch 00032: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1870 - acc: 0.9500 - val_loss: 1.0224 - val_acc: 0.7293\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1820 - acc: 0.9505\n",
      "Epoch 00033: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1819 - acc: 0.9505 - val_loss: 0.9544 - val_acc: 0.7515\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1748 - acc: 0.9519\n",
      "Epoch 00034: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1748 - acc: 0.9519 - val_loss: 1.0922 - val_acc: 0.7338\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9542\n",
      "Epoch 00035: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1664 - acc: 0.9542 - val_loss: 1.0250 - val_acc: 0.7324\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1611 - acc: 0.9564\n",
      "Epoch 00036: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1611 - acc: 0.9564 - val_loss: 1.2095 - val_acc: 0.7051\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1553 - acc: 0.9574\n",
      "Epoch 00037: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1553 - acc: 0.9575 - val_loss: 1.0614 - val_acc: 0.7305\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9586\n",
      "Epoch 00038: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1502 - acc: 0.9586 - val_loss: 1.8094 - val_acc: 0.6201\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1407 - acc: 0.9622\n",
      "Epoch 00039: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1407 - acc: 0.9622 - val_loss: 1.0919 - val_acc: 0.7379\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9637\n",
      "Epoch 00040: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1360 - acc: 0.9637 - val_loss: 1.0800 - val_acc: 0.7410\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9656\n",
      "Epoch 00041: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1323 - acc: 0.9655 - val_loss: 1.0285 - val_acc: 0.7536\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9621\n",
      "Epoch 00042: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.1390 - acc: 0.9621 - val_loss: 1.1109 - val_acc: 0.7421\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9679\n",
      "Epoch 00043: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1222 - acc: 0.9679 - val_loss: 0.9567 - val_acc: 0.7543\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9703\n",
      "Epoch 00044: val_loss did not improve from 0.79614\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1148 - acc: 0.9703 - val_loss: 1.0417 - val_acc: 0.7303\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9695\n",
      "Epoch 00045: val_loss improved from 0.79614 to 0.78462, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_6_conv_checkpoint/045-0.7846.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1161 - acc: 0.9695 - val_loss: 0.7846 - val_acc: 0.8064\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9690\n",
      "Epoch 00046: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1150 - acc: 0.9689 - val_loss: 1.1600 - val_acc: 0.7335\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9712\n",
      "Epoch 00047: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1107 - acc: 0.9713 - val_loss: 0.8210 - val_acc: 0.8036\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9743\n",
      "Epoch 00048: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1004 - acc: 0.9743 - val_loss: 1.4861 - val_acc: 0.6674\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1077 - acc: 0.9721\n",
      "Epoch 00049: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1077 - acc: 0.9722 - val_loss: 1.4954 - val_acc: 0.6648\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9772\n",
      "Epoch 00050: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0925 - acc: 0.9772 - val_loss: 1.0999 - val_acc: 0.7414\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9772\n",
      "Epoch 00051: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0904 - acc: 0.9772 - val_loss: 1.3152 - val_acc: 0.7002\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9728\n",
      "Epoch 00052: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0964 - acc: 0.9727 - val_loss: 0.9794 - val_acc: 0.7657\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1115 - acc: 0.9695\n",
      "Epoch 00053: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1116 - acc: 0.9695 - val_loss: 0.9484 - val_acc: 0.7738\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9752\n",
      "Epoch 00054: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0958 - acc: 0.9752 - val_loss: 0.8124 - val_acc: 0.7999\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9807\n",
      "Epoch 00055: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0791 - acc: 0.9806 - val_loss: 0.9880 - val_acc: 0.7710\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0965 - acc: 0.9754\n",
      "Epoch 00056: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0965 - acc: 0.9754 - val_loss: 1.3599 - val_acc: 0.6967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9806\n",
      "Epoch 00057: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0784 - acc: 0.9806 - val_loss: 1.9339 - val_acc: 0.6138\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9799\n",
      "Epoch 00058: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0809 - acc: 0.9799 - val_loss: 0.8546 - val_acc: 0.7969\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9811\n",
      "Epoch 00059: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0756 - acc: 0.9811 - val_loss: 0.8312 - val_acc: 0.8027\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9801\n",
      "Epoch 00060: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0793 - acc: 0.9801 - val_loss: 1.0241 - val_acc: 0.7675\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9825\n",
      "Epoch 00061: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0712 - acc: 0.9825 - val_loss: 0.9021 - val_acc: 0.7964\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9795\n",
      "Epoch 00062: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0785 - acc: 0.9795 - val_loss: 0.9979 - val_acc: 0.7678\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9828\n",
      "Epoch 00063: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0687 - acc: 0.9828 - val_loss: 1.0687 - val_acc: 0.7536\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0684 - acc: 0.9827\n",
      "Epoch 00064: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0684 - acc: 0.9827 - val_loss: 1.1642 - val_acc: 0.7501\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9837\n",
      "Epoch 00065: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0663 - acc: 0.9837 - val_loss: 0.7884 - val_acc: 0.8132\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9816\n",
      "Epoch 00066: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0732 - acc: 0.9816 - val_loss: 1.2040 - val_acc: 0.7524\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9834\n",
      "Epoch 00067: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0665 - acc: 0.9834 - val_loss: 0.8686 - val_acc: 0.7939\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9814\n",
      "Epoch 00068: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0706 - acc: 0.9814 - val_loss: 0.9330 - val_acc: 0.7817\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9846\n",
      "Epoch 00069: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0607 - acc: 0.9846 - val_loss: 0.9246 - val_acc: 0.7880\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9832\n",
      "Epoch 00070: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0651 - acc: 0.9832 - val_loss: 0.8524 - val_acc: 0.8053\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9837\n",
      "Epoch 00071: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0641 - acc: 0.9837 - val_loss: 1.5380 - val_acc: 0.6862\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9845\n",
      "Epoch 00072: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0617 - acc: 0.9845 - val_loss: 0.9683 - val_acc: 0.7803\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9848\n",
      "Epoch 00073: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0619 - acc: 0.9848 - val_loss: 0.9464 - val_acc: 0.7904\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0566 - acc: 0.9867\n",
      "Epoch 00074: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0566 - acc: 0.9866 - val_loss: 1.0362 - val_acc: 0.7738\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9846\n",
      "Epoch 00075: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0600 - acc: 0.9846 - val_loss: 1.0625 - val_acc: 0.7794\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0569 - acc: 0.9866\n",
      "Epoch 00076: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0569 - acc: 0.9866 - val_loss: 0.9644 - val_acc: 0.7957\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9850\n",
      "Epoch 00077: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0571 - acc: 0.9849 - val_loss: 1.2334 - val_acc: 0.7433\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9814\n",
      "Epoch 00078: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0731 - acc: 0.9814 - val_loss: 0.9019 - val_acc: 0.8041\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9875\n",
      "Epoch 00079: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0511 - acc: 0.9875 - val_loss: 0.8139 - val_acc: 0.8195\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9872\n",
      "Epoch 00080: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0520 - acc: 0.9872 - val_loss: 1.0427 - val_acc: 0.7841\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9864\n",
      "Epoch 00081: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0526 - acc: 0.9864 - val_loss: 1.1112 - val_acc: 0.7750\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0549 - acc: 0.9858\n",
      "Epoch 00082: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0550 - acc: 0.9858 - val_loss: 1.5887 - val_acc: 0.7109\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9863\n",
      "Epoch 00083: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0554 - acc: 0.9863 - val_loss: 1.1464 - val_acc: 0.7568\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9887\n",
      "Epoch 00084: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0477 - acc: 0.9888 - val_loss: 0.9939 - val_acc: 0.7855\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9884\n",
      "Epoch 00085: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0477 - acc: 0.9884 - val_loss: 1.1993 - val_acc: 0.7610\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9873\n",
      "Epoch 00086: val_loss did not improve from 0.78462\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0514 - acc: 0.9873 - val_loss: 0.9664 - val_acc: 0.8043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0506 - acc: 0.9873\n",
      "Epoch 00087: val_loss improved from 0.78462 to 0.75632, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_6_conv_checkpoint/087-0.7563.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0506 - acc: 0.9873 - val_loss: 0.7563 - val_acc: 0.8395\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9890\n",
      "Epoch 00088: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0460 - acc: 0.9890 - val_loss: 0.9761 - val_acc: 0.7948\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9868\n",
      "Epoch 00089: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0504 - acc: 0.9868 - val_loss: 0.7848 - val_acc: 0.8390\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9874\n",
      "Epoch 00090: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0501 - acc: 0.9874 - val_loss: 1.6407 - val_acc: 0.7065\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9886\n",
      "Epoch 00091: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0457 - acc: 0.9886 - val_loss: 1.0569 - val_acc: 0.7741\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9907\n",
      "Epoch 00092: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0404 - acc: 0.9906 - val_loss: 1.2559 - val_acc: 0.7475\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9849\n",
      "Epoch 00093: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0560 - acc: 0.9849 - val_loss: 1.1498 - val_acc: 0.7724\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9880\n",
      "Epoch 00094: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0467 - acc: 0.9880 - val_loss: 1.1467 - val_acc: 0.7708\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9891\n",
      "Epoch 00095: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0443 - acc: 0.9891 - val_loss: 1.0342 - val_acc: 0.7848\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9901\n",
      "Epoch 00096: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0413 - acc: 0.9901 - val_loss: 1.1428 - val_acc: 0.7808\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9883\n",
      "Epoch 00097: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0461 - acc: 0.9883 - val_loss: 0.8807 - val_acc: 0.8169\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9904\n",
      "Epoch 00098: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0406 - acc: 0.9904 - val_loss: 1.2542 - val_acc: 0.7543\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9906\n",
      "Epoch 00099: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0399 - acc: 0.9906 - val_loss: 1.1890 - val_acc: 0.7657\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9868\n",
      "Epoch 00100: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0500 - acc: 0.9868 - val_loss: 1.9118 - val_acc: 0.6632\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9899\n",
      "Epoch 00101: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0412 - acc: 0.9899 - val_loss: 0.9585 - val_acc: 0.8008\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0453 - acc: 0.9886\n",
      "Epoch 00102: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0453 - acc: 0.9886 - val_loss: 1.7624 - val_acc: 0.6697\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9896\n",
      "Epoch 00103: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0431 - acc: 0.9895 - val_loss: 0.9716 - val_acc: 0.8057\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9782\n",
      "Epoch 00104: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0825 - acc: 0.9782 - val_loss: 0.8361 - val_acc: 0.8239\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9905\n",
      "Epoch 00105: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0419 - acc: 0.9905 - val_loss: 0.9128 - val_acc: 0.8150\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9917\n",
      "Epoch 00106: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0372 - acc: 0.9917 - val_loss: 1.1288 - val_acc: 0.7836\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9925\n",
      "Epoch 00107: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0338 - acc: 0.9925 - val_loss: 0.9425 - val_acc: 0.8041\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9908\n",
      "Epoch 00108: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0383 - acc: 0.9908 - val_loss: 1.2164 - val_acc: 0.7566\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9898\n",
      "Epoch 00109: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0405 - acc: 0.9898 - val_loss: 1.0674 - val_acc: 0.7822\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9912\n",
      "Epoch 00110: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0376 - acc: 0.9912 - val_loss: 0.8628 - val_acc: 0.8262\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9909\n",
      "Epoch 00111: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0378 - acc: 0.9909 - val_loss: 0.9342 - val_acc: 0.8127\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9877\n",
      "Epoch 00112: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0469 - acc: 0.9877 - val_loss: 1.1045 - val_acc: 0.7766\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9902\n",
      "Epoch 00113: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0404 - acc: 0.9902 - val_loss: 0.9823 - val_acc: 0.8055\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9921\n",
      "Epoch 00114: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0326 - acc: 0.9921 - val_loss: 0.8669 - val_acc: 0.8241\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9912\n",
      "Epoch 00115: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0350 - acc: 0.9912 - val_loss: 0.9379 - val_acc: 0.8099\n",
      "Epoch 116/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9880\n",
      "Epoch 00116: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0431 - acc: 0.9880 - val_loss: 1.6485 - val_acc: 0.7202\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9892\n",
      "Epoch 00117: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0436 - acc: 0.9892 - val_loss: 1.0949 - val_acc: 0.7906\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9918\n",
      "Epoch 00118: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0351 - acc: 0.9918 - val_loss: 0.8785 - val_acc: 0.8218\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9882\n",
      "Epoch 00119: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 88s 2ms/sample - loss: 0.0464 - acc: 0.9882 - val_loss: 1.0249 - val_acc: 0.7945\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9921\n",
      "Epoch 00120: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0335 - acc: 0.9921 - val_loss: 1.1371 - val_acc: 0.7771\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9918\n",
      "Epoch 00121: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0347 - acc: 0.9918 - val_loss: 1.4510 - val_acc: 0.7363\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9904\n",
      "Epoch 00122: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0368 - acc: 0.9904 - val_loss: 1.2523 - val_acc: 0.7580\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9921\n",
      "Epoch 00123: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0334 - acc: 0.9921 - val_loss: 1.0349 - val_acc: 0.7904\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9915\n",
      "Epoch 00124: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0338 - acc: 0.9915 - val_loss: 1.3899 - val_acc: 0.7447\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9896\n",
      "Epoch 00125: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0393 - acc: 0.9896 - val_loss: 1.2299 - val_acc: 0.7752\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9908\n",
      "Epoch 00126: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0362 - acc: 0.9908 - val_loss: 1.0844 - val_acc: 0.7878\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9904\n",
      "Epoch 00127: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0391 - acc: 0.9904 - val_loss: 1.0106 - val_acc: 0.7976\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9918\n",
      "Epoch 00128: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0334 - acc: 0.9918 - val_loss: 1.2094 - val_acc: 0.7668\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0368 - acc: 0.9904\n",
      "Epoch 00129: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0368 - acc: 0.9904 - val_loss: 1.2869 - val_acc: 0.7640\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9927\n",
      "Epoch 00130: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0291 - acc: 0.9927 - val_loss: 0.9190 - val_acc: 0.8130\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9907\n",
      "Epoch 00131: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0358 - acc: 0.9907 - val_loss: 0.9068 - val_acc: 0.8176\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9920\n",
      "Epoch 00132: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0350 - acc: 0.9920 - val_loss: 1.0209 - val_acc: 0.8008\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0350 - acc: 0.9911\n",
      "Epoch 00133: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0350 - acc: 0.9911 - val_loss: 0.8399 - val_acc: 0.8300\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9919\n",
      "Epoch 00134: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0322 - acc: 0.9919 - val_loss: 1.0702 - val_acc: 0.8013\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9927\n",
      "Epoch 00135: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0312 - acc: 0.9927 - val_loss: 1.1612 - val_acc: 0.7734\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9912\n",
      "Epoch 00136: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0354 - acc: 0.9913 - val_loss: 0.9413 - val_acc: 0.8141\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9936\n",
      "Epoch 00137: val_loss did not improve from 0.75632\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0276 - acc: 0.9936 - val_loss: 0.9503 - val_acc: 0.8076\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 944us/sample - loss: 0.8392 - acc: 0.8150\n",
      "Loss: 0.8392356582148425 Accuracy: 0.81495327\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9117 - acc: 0.4002\n",
      "Epoch 00001: val_loss improved from inf to 1.47832, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_7_conv_checkpoint/001-1.4783.hdf5\n",
      "36805/36805 [==============================] - 102s 3ms/sample - loss: 1.9117 - acc: 0.4002 - val_loss: 1.4783 - val_acc: 0.5409\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2842 - acc: 0.6077\n",
      "Epoch 00002: val_loss did not improve from 1.47832\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.2841 - acc: 0.6078 - val_loss: 1.7665 - val_acc: 0.4987\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0577 - acc: 0.6834\n",
      "Epoch 00003: val_loss improved from 1.47832 to 1.12850, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_7_conv_checkpoint/003-1.1285.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.0577 - acc: 0.6834 - val_loss: 1.1285 - val_acc: 0.6429\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9192 - acc: 0.7278\n",
      "Epoch 00004: val_loss improved from 1.12850 to 1.10423, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_7_conv_checkpoint/004-1.1042.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.9191 - acc: 0.7278 - val_loss: 1.1042 - val_acc: 0.6716\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8248 - acc: 0.7574\n",
      "Epoch 00005: val_loss improved from 1.10423 to 0.81611, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_7_conv_checkpoint/005-0.8161.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.8247 - acc: 0.7574 - val_loss: 0.8161 - val_acc: 0.7543\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7498 - acc: 0.7799\n",
      "Epoch 00006: val_loss did not improve from 0.81611\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.7499 - acc: 0.7798 - val_loss: 1.4905 - val_acc: 0.5856\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6810 - acc: 0.8014\n",
      "Epoch 00007: val_loss did not improve from 0.81611\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.6810 - acc: 0.8014 - val_loss: 1.5818 - val_acc: 0.6003\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6324 - acc: 0.8159\n",
      "Epoch 00008: val_loss did not improve from 0.81611\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.6324 - acc: 0.8159 - val_loss: 0.8177 - val_acc: 0.7524\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5924 - acc: 0.8262\n",
      "Epoch 00009: val_loss did not improve from 0.81611\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5924 - acc: 0.8262 - val_loss: 0.9272 - val_acc: 0.7074\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5518 - acc: 0.8402\n",
      "Epoch 00010: val_loss did not improve from 0.81611\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5519 - acc: 0.8401 - val_loss: 1.1562 - val_acc: 0.6830\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5174 - acc: 0.8524\n",
      "Epoch 00011: val_loss improved from 0.81611 to 0.73212, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_7_conv_checkpoint/011-0.7321.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.5173 - acc: 0.8524 - val_loss: 0.7321 - val_acc: 0.7810\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4898 - acc: 0.8599\n",
      "Epoch 00012: val_loss did not improve from 0.73212\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4899 - acc: 0.8599 - val_loss: 0.7758 - val_acc: 0.7727\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4590 - acc: 0.8673\n",
      "Epoch 00013: val_loss did not improve from 0.73212\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4590 - acc: 0.8673 - val_loss: 1.4899 - val_acc: 0.6145\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4319 - acc: 0.8751\n",
      "Epoch 00014: val_loss did not improve from 0.73212\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4319 - acc: 0.8752 - val_loss: 1.1013 - val_acc: 0.6802\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4107 - acc: 0.8814\n",
      "Epoch 00015: val_loss did not improve from 0.73212\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4107 - acc: 0.8814 - val_loss: 1.0149 - val_acc: 0.7158\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3899 - acc: 0.8874\n",
      "Epoch 00016: val_loss did not improve from 0.73212\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3899 - acc: 0.8874 - val_loss: 0.9378 - val_acc: 0.7447\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3712 - acc: 0.8939\n",
      "Epoch 00017: val_loss did not improve from 0.73212\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3713 - acc: 0.8938 - val_loss: 1.0585 - val_acc: 0.7114\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3576 - acc: 0.8967\n",
      "Epoch 00018: val_loss did not improve from 0.73212\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3576 - acc: 0.8967 - val_loss: 1.0366 - val_acc: 0.7221\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3432 - acc: 0.9020\n",
      "Epoch 00019: val_loss did not improve from 0.73212\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3432 - acc: 0.9020 - val_loss: 0.7375 - val_acc: 0.7952\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3306 - acc: 0.9046\n",
      "Epoch 00020: val_loss did not improve from 0.73212\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3306 - acc: 0.9046 - val_loss: 2.1132 - val_acc: 0.5560\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3109 - acc: 0.9099\n",
      "Epoch 00021: val_loss did not improve from 0.73212\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3110 - acc: 0.9098 - val_loss: 0.8010 - val_acc: 0.7650\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3045 - acc: 0.9136\n",
      "Epoch 00022: val_loss did not improve from 0.73212\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3046 - acc: 0.9136 - val_loss: 0.9986 - val_acc: 0.7335\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2856 - acc: 0.9189\n",
      "Epoch 00023: val_loss did not improve from 0.73212\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2857 - acc: 0.9189 - val_loss: 1.0657 - val_acc: 0.6986\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2764 - acc: 0.9210\n",
      "Epoch 00024: val_loss improved from 0.73212 to 0.68117, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_7_conv_checkpoint/024-0.6812.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2764 - acc: 0.9210 - val_loss: 0.6812 - val_acc: 0.8197\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2596 - acc: 0.9252\n",
      "Epoch 00025: val_loss did not improve from 0.68117\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2597 - acc: 0.9252 - val_loss: 0.7345 - val_acc: 0.7973\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2517 - acc: 0.9276\n",
      "Epoch 00026: val_loss did not improve from 0.68117\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2517 - acc: 0.9276 - val_loss: 0.8463 - val_acc: 0.7715\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2421 - acc: 0.9290\n",
      "Epoch 00027: val_loss did not improve from 0.68117\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2421 - acc: 0.9290 - val_loss: 1.1074 - val_acc: 0.7144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2352 - acc: 0.9326\n",
      "Epoch 00028: val_loss improved from 0.68117 to 0.56293, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_7_conv_checkpoint/028-0.5629.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2352 - acc: 0.9325 - val_loss: 0.5629 - val_acc: 0.8381\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2216 - acc: 0.9352\n",
      "Epoch 00029: val_loss improved from 0.56293 to 0.53260, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_7_conv_checkpoint/029-0.5326.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2216 - acc: 0.9352 - val_loss: 0.5326 - val_acc: 0.8523\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2102 - acc: 0.9391\n",
      "Epoch 00030: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2102 - acc: 0.9391 - val_loss: 1.4304 - val_acc: 0.6804\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2052 - acc: 0.9399\n",
      "Epoch 00031: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2052 - acc: 0.9399 - val_loss: 0.6389 - val_acc: 0.8311\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9432\n",
      "Epoch 00032: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1965 - acc: 0.9432 - val_loss: 0.6204 - val_acc: 0.8251\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1887 - acc: 0.9440\n",
      "Epoch 00033: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1888 - acc: 0.9439 - val_loss: 0.7149 - val_acc: 0.8071\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1832 - acc: 0.9468\n",
      "Epoch 00034: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1832 - acc: 0.9468 - val_loss: 0.9358 - val_acc: 0.7617\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1709 - acc: 0.9514\n",
      "Epoch 00035: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1709 - acc: 0.9514 - val_loss: 0.5892 - val_acc: 0.8353\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1647 - acc: 0.9526\n",
      "Epoch 00036: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1647 - acc: 0.9526 - val_loss: 1.0207 - val_acc: 0.7526\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1587 - acc: 0.9540\n",
      "Epoch 00037: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1589 - acc: 0.9540 - val_loss: 0.5449 - val_acc: 0.8479\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9561\n",
      "Epoch 00038: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1550 - acc: 0.9561 - val_loss: 0.7057 - val_acc: 0.8095\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9582\n",
      "Epoch 00039: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1489 - acc: 0.9582 - val_loss: 0.6237 - val_acc: 0.8409\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9607\n",
      "Epoch 00040: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1393 - acc: 0.9607 - val_loss: 0.8678 - val_acc: 0.7827\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9589\n",
      "Epoch 00041: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1416 - acc: 0.9589 - val_loss: 0.5352 - val_acc: 0.8479\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9598\n",
      "Epoch 00042: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1395 - acc: 0.9598 - val_loss: 1.0586 - val_acc: 0.7484\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9623\n",
      "Epoch 00043: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1336 - acc: 0.9623 - val_loss: 0.5796 - val_acc: 0.8505\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1307 - acc: 0.9614\n",
      "Epoch 00044: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1307 - acc: 0.9614 - val_loss: 0.6383 - val_acc: 0.8269\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1180 - acc: 0.9673\n",
      "Epoch 00045: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1181 - acc: 0.9672 - val_loss: 0.5510 - val_acc: 0.8563\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9623\n",
      "Epoch 00046: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1269 - acc: 0.9623 - val_loss: 1.1723 - val_acc: 0.7282\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1095 - acc: 0.9684\n",
      "Epoch 00047: val_loss did not improve from 0.53260\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1095 - acc: 0.9684 - val_loss: 0.5909 - val_acc: 0.8570\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9708\n",
      "Epoch 00048: val_loss improved from 0.53260 to 0.44250, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_7_conv_checkpoint/048-0.4425.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1054 - acc: 0.9708 - val_loss: 0.4425 - val_acc: 0.8817\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1084 - acc: 0.9693\n",
      "Epoch 00049: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.1084 - acc: 0.9692 - val_loss: 0.6576 - val_acc: 0.8269\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9689\n",
      "Epoch 00050: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1106 - acc: 0.9689 - val_loss: 0.6138 - val_acc: 0.8523\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9738\n",
      "Epoch 00051: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0978 - acc: 0.9738 - val_loss: 0.5541 - val_acc: 0.8530\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9719\n",
      "Epoch 00052: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0992 - acc: 0.9719 - val_loss: 0.4934 - val_acc: 0.8663\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0970 - acc: 0.9733\n",
      "Epoch 00053: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0970 - acc: 0.9733 - val_loss: 0.6911 - val_acc: 0.8248\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9763\n",
      "Epoch 00054: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0866 - acc: 0.9763 - val_loss: 0.4971 - val_acc: 0.8663\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9752\n",
      "Epoch 00055: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0887 - acc: 0.9752 - val_loss: 0.5994 - val_acc: 0.8444\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9718\n",
      "Epoch 00056: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0960 - acc: 0.9718 - val_loss: 0.7399 - val_acc: 0.8174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9762\n",
      "Epoch 00057: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0846 - acc: 0.9762 - val_loss: 0.5320 - val_acc: 0.8698\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9732\n",
      "Epoch 00058: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0913 - acc: 0.9732 - val_loss: 0.4654 - val_acc: 0.8735\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9785\n",
      "Epoch 00059: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0779 - acc: 0.9785 - val_loss: 1.1232 - val_acc: 0.7624\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0870 - acc: 0.9755\n",
      "Epoch 00060: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0871 - acc: 0.9755 - val_loss: 0.5465 - val_acc: 0.8605\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9783\n",
      "Epoch 00061: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0775 - acc: 0.9783 - val_loss: 0.6468 - val_acc: 0.8386\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9794\n",
      "Epoch 00062: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0751 - acc: 0.9794 - val_loss: 0.6079 - val_acc: 0.8472\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9771\n",
      "Epoch 00063: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0826 - acc: 0.9771 - val_loss: 0.7762 - val_acc: 0.8202\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9800\n",
      "Epoch 00064: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0700 - acc: 0.9800 - val_loss: 0.5884 - val_acc: 0.8570\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9806\n",
      "Epoch 00065: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0697 - acc: 0.9806 - val_loss: 0.7490 - val_acc: 0.8244\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9817\n",
      "Epoch 00066: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0679 - acc: 0.9816 - val_loss: 0.5558 - val_acc: 0.8600\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9804\n",
      "Epoch 00067: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0694 - acc: 0.9804 - val_loss: 0.6445 - val_acc: 0.8516\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9820\n",
      "Epoch 00068: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0658 - acc: 0.9819 - val_loss: 0.6088 - val_acc: 0.8505\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9790\n",
      "Epoch 00069: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0731 - acc: 0.9791 - val_loss: 0.9365 - val_acc: 0.7894\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9809\n",
      "Epoch 00070: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0654 - acc: 0.9808 - val_loss: 0.6125 - val_acc: 0.8551\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9805\n",
      "Epoch 00071: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0702 - acc: 0.9805 - val_loss: 0.6660 - val_acc: 0.8474\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9840\n",
      "Epoch 00072: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0572 - acc: 0.9841 - val_loss: 0.4788 - val_acc: 0.8826\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0617 - acc: 0.9827\n",
      "Epoch 00073: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0617 - acc: 0.9827 - val_loss: 0.6207 - val_acc: 0.8546\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0720 - acc: 0.9800\n",
      "Epoch 00074: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0720 - acc: 0.9800 - val_loss: 0.7335 - val_acc: 0.8283\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9849\n",
      "Epoch 00075: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0548 - acc: 0.9849 - val_loss: 0.7745 - val_acc: 0.8262\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9842\n",
      "Epoch 00076: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0580 - acc: 0.9842 - val_loss: 0.5989 - val_acc: 0.8519\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9837\n",
      "Epoch 00077: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0580 - acc: 0.9837 - val_loss: 0.7476 - val_acc: 0.8362\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9853\n",
      "Epoch 00078: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0530 - acc: 0.9853 - val_loss: 0.6914 - val_acc: 0.8484\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9864\n",
      "Epoch 00079: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0497 - acc: 0.9864 - val_loss: 0.7801 - val_acc: 0.8293\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9848\n",
      "Epoch 00080: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0545 - acc: 0.9848 - val_loss: 0.8704 - val_acc: 0.8102\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9852\n",
      "Epoch 00081: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0534 - acc: 0.9851 - val_loss: 0.5768 - val_acc: 0.8721\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9858\n",
      "Epoch 00082: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0513 - acc: 0.9858 - val_loss: 0.5270 - val_acc: 0.8758\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9838\n",
      "Epoch 00083: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0553 - acc: 0.9838 - val_loss: 0.4528 - val_acc: 0.8956\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9858\n",
      "Epoch 00084: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0496 - acc: 0.9858 - val_loss: 0.6438 - val_acc: 0.8537\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9882\n",
      "Epoch 00085: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0450 - acc: 0.9882 - val_loss: 0.5153 - val_acc: 0.8765\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0500 - acc: 0.9857\n",
      "Epoch 00086: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0500 - acc: 0.9857 - val_loss: 0.7973 - val_acc: 0.8169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9861\n",
      "Epoch 00087: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0487 - acc: 0.9861 - val_loss: 0.6473 - val_acc: 0.8505\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9851\n",
      "Epoch 00088: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0519 - acc: 0.9851 - val_loss: 0.6594 - val_acc: 0.8507\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9859\n",
      "Epoch 00089: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0497 - acc: 0.9859 - val_loss: 0.7636 - val_acc: 0.8372\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9882\n",
      "Epoch 00090: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0428 - acc: 0.9882 - val_loss: 0.5315 - val_acc: 0.8861\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9853\n",
      "Epoch 00091: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0482 - acc: 0.9853 - val_loss: 0.5048 - val_acc: 0.8877\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0441 - acc: 0.9881\n",
      "Epoch 00092: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0442 - acc: 0.9881 - val_loss: 0.6580 - val_acc: 0.8539\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9860\n",
      "Epoch 00093: val_loss did not improve from 0.44250\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0518 - acc: 0.9860 - val_loss: 0.5831 - val_acc: 0.8672\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9867\n",
      "Epoch 00094: val_loss improved from 0.44250 to 0.40282, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_7_conv_checkpoint/094-0.4028.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0485 - acc: 0.9867 - val_loss: 0.4028 - val_acc: 0.9031\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9906\n",
      "Epoch 00095: val_loss did not improve from 0.40282\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0363 - acc: 0.9906 - val_loss: 0.4349 - val_acc: 0.9012\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9875\n",
      "Epoch 00096: val_loss did not improve from 0.40282\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0457 - acc: 0.9875 - val_loss: 0.6476 - val_acc: 0.8570\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9920\n",
      "Epoch 00097: val_loss did not improve from 0.40282\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0325 - acc: 0.9920 - val_loss: 0.4098 - val_acc: 0.9022\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9863\n",
      "Epoch 00098: val_loss did not improve from 0.40282\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0478 - acc: 0.9863 - val_loss: 0.6428 - val_acc: 0.8563\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9876\n",
      "Epoch 00099: val_loss did not improve from 0.40282\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0438 - acc: 0.9876 - val_loss: 0.6026 - val_acc: 0.8672\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9887\n",
      "Epoch 00100: val_loss did not improve from 0.40282\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0405 - acc: 0.9888 - val_loss: 0.6065 - val_acc: 0.8546\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9899\n",
      "Epoch 00101: val_loss did not improve from 0.40282\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0358 - acc: 0.9899 - val_loss: 0.6910 - val_acc: 0.8446\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9886\n",
      "Epoch 00102: val_loss did not improve from 0.40282\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0430 - acc: 0.9886 - val_loss: 0.4539 - val_acc: 0.8991\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9887\n",
      "Epoch 00103: val_loss did not improve from 0.40282\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0386 - acc: 0.9888 - val_loss: 0.4590 - val_acc: 0.8924\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9905\n",
      "Epoch 00104: val_loss did not improve from 0.40282\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0357 - acc: 0.9905 - val_loss: 0.5245 - val_acc: 0.8831\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9874\n",
      "Epoch 00105: val_loss did not improve from 0.40282\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0435 - acc: 0.9874 - val_loss: 0.6049 - val_acc: 0.8623\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9912\n",
      "Epoch 00106: val_loss did not improve from 0.40282\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0341 - acc: 0.9913 - val_loss: 1.2246 - val_acc: 0.7768\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9904\n",
      "Epoch 00107: val_loss improved from 0.40282 to 0.40170, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_7_conv_checkpoint/107-0.4017.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0344 - acc: 0.9904 - val_loss: 0.4017 - val_acc: 0.9092\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9901\n",
      "Epoch 00108: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0354 - acc: 0.9901 - val_loss: 0.7759 - val_acc: 0.8337\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9896\n",
      "Epoch 00109: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0377 - acc: 0.9896 - val_loss: 0.8106 - val_acc: 0.8295\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9871\n",
      "Epoch 00110: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0461 - acc: 0.9871 - val_loss: 0.5527 - val_acc: 0.8838\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9908\n",
      "Epoch 00111: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0347 - acc: 0.9907 - val_loss: 0.4618 - val_acc: 0.8952\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9831\n",
      "Epoch 00112: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0628 - acc: 0.9831 - val_loss: 0.4425 - val_acc: 0.8996\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9931\n",
      "Epoch 00113: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0265 - acc: 0.9930 - val_loss: 0.8853 - val_acc: 0.8232\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9888\n",
      "Epoch 00114: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0420 - acc: 0.9888 - val_loss: 0.4636 - val_acc: 0.8984\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9933\n",
      "Epoch 00115: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0265 - acc: 0.9933 - val_loss: 0.6193 - val_acc: 0.8654\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9915\n",
      "Epoch 00116: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0322 - acc: 0.9915 - val_loss: 0.5542 - val_acc: 0.8824\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0360 - acc: 0.9903\n",
      "Epoch 00117: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0360 - acc: 0.9903 - val_loss: 0.4750 - val_acc: 0.8903\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9877\n",
      "Epoch 00118: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0410 - acc: 0.9876 - val_loss: 0.6274 - val_acc: 0.8593\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9896\n",
      "Epoch 00119: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0352 - acc: 0.9896 - val_loss: 0.4832 - val_acc: 0.8940\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9913\n",
      "Epoch 00120: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0307 - acc: 0.9913 - val_loss: 0.6242 - val_acc: 0.8647\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9905\n",
      "Epoch 00121: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0336 - acc: 0.9905 - val_loss: 0.4760 - val_acc: 0.8894\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9911\n",
      "Epoch 00122: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0313 - acc: 0.9911 - val_loss: 0.4715 - val_acc: 0.9015\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9945\n",
      "Epoch 00123: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0237 - acc: 0.9945 - val_loss: 0.5700 - val_acc: 0.8824\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9869\n",
      "Epoch 00124: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0470 - acc: 0.9869 - val_loss: 0.5078 - val_acc: 0.8870\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9945\n",
      "Epoch 00125: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0235 - acc: 0.9945 - val_loss: 0.4202 - val_acc: 0.9108\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9885\n",
      "Epoch 00126: val_loss did not improve from 0.40170\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0383 - acc: 0.9885 - val_loss: 0.6409 - val_acc: 0.8612\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9882\n",
      "Epoch 00127: val_loss improved from 0.40170 to 0.39387, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_7_conv_checkpoint/127-0.3939.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0409 - acc: 0.9882 - val_loss: 0.3939 - val_acc: 0.9122\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9926\n",
      "Epoch 00128: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0283 - acc: 0.9925 - val_loss: 0.4982 - val_acc: 0.8870\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9902\n",
      "Epoch 00129: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0385 - acc: 0.9902 - val_loss: 0.6510 - val_acc: 0.8623\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9934\n",
      "Epoch 00130: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0241 - acc: 0.9934 - val_loss: 0.5889 - val_acc: 0.8724\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9936\n",
      "Epoch 00131: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0242 - acc: 0.9936 - val_loss: 0.7913 - val_acc: 0.8428\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9852\n",
      "Epoch 00132: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0484 - acc: 0.9852 - val_loss: 0.5144 - val_acc: 0.8921\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9955\n",
      "Epoch 00133: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0207 - acc: 0.9955 - val_loss: 0.4765 - val_acc: 0.8942\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9925\n",
      "Epoch 00134: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0289 - acc: 0.9925 - val_loss: 0.7875 - val_acc: 0.8409\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9904\n",
      "Epoch 00135: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0325 - acc: 0.9904 - val_loss: 0.5667 - val_acc: 0.8779\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9901\n",
      "Epoch 00136: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0341 - acc: 0.9901 - val_loss: 0.4717 - val_acc: 0.9012\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9940\n",
      "Epoch 00137: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0232 - acc: 0.9940 - val_loss: 0.5103 - val_acc: 0.8915\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9939\n",
      "Epoch 00138: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0242 - acc: 0.9939 - val_loss: 0.7033 - val_acc: 0.8560\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9939\n",
      "Epoch 00139: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0236 - acc: 0.9939 - val_loss: 0.5046 - val_acc: 0.8877\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9926\n",
      "Epoch 00140: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0287 - acc: 0.9926 - val_loss: 0.6384 - val_acc: 0.8700\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9907\n",
      "Epoch 00141: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0321 - acc: 0.9907 - val_loss: 0.6078 - val_acc: 0.8728\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9910\n",
      "Epoch 00142: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0307 - acc: 0.9910 - val_loss: 0.6407 - val_acc: 0.8663\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9928\n",
      "Epoch 00143: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0270 - acc: 0.9928 - val_loss: 0.4433 - val_acc: 0.9064\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9935\n",
      "Epoch 00144: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0249 - acc: 0.9935 - val_loss: 0.6682 - val_acc: 0.8644\n",
      "Epoch 145/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9923\n",
      "Epoch 00145: val_loss did not improve from 0.39387\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0275 - acc: 0.9923 - val_loss: 0.6583 - val_acc: 0.8651\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9899\n",
      "Epoch 00146: val_loss improved from 0.39387 to 0.37927, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_7_conv_checkpoint/146-0.3793.hdf5\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0374 - acc: 0.9899 - val_loss: 0.3793 - val_acc: 0.9173\n",
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9944\n",
      "Epoch 00147: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0209 - acc: 0.9944 - val_loss: 0.8529 - val_acc: 0.8446\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9920\n",
      "Epoch 00148: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0284 - acc: 0.9920 - val_loss: 0.5446 - val_acc: 0.8854\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0330 - acc: 0.9910\n",
      "Epoch 00149: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0330 - acc: 0.9910 - val_loss: 0.5575 - val_acc: 0.8770\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9907\n",
      "Epoch 00150: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0338 - acc: 0.9907 - val_loss: 0.4177 - val_acc: 0.9110\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9936\n",
      "Epoch 00151: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0227 - acc: 0.9936 - val_loss: 0.6374 - val_acc: 0.8658\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9938\n",
      "Epoch 00152: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0230 - acc: 0.9938 - val_loss: 0.7041 - val_acc: 0.8574\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9935\n",
      "Epoch 00153: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0251 - acc: 0.9935 - val_loss: 0.5482 - val_acc: 0.8866\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9946\n",
      "Epoch 00154: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0205 - acc: 0.9946 - val_loss: 0.6121 - val_acc: 0.8784\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0253 - acc: 0.9931\n",
      "Epoch 00155: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0253 - acc: 0.9931 - val_loss: 0.5998 - val_acc: 0.8852\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9925\n",
      "Epoch 00156: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0260 - acc: 0.9924 - val_loss: 0.6337 - val_acc: 0.8789\n",
      "Epoch 157/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9905\n",
      "Epoch 00157: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0325 - acc: 0.9905 - val_loss: 0.4999 - val_acc: 0.8926\n",
      "Epoch 158/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9934\n",
      "Epoch 00158: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0240 - acc: 0.9934 - val_loss: 0.7978 - val_acc: 0.8470\n",
      "Epoch 159/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9925\n",
      "Epoch 00159: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0267 - acc: 0.9925 - val_loss: 0.7139 - val_acc: 0.8567\n",
      "Epoch 160/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9907\n",
      "Epoch 00160: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0322 - acc: 0.9906 - val_loss: 0.5062 - val_acc: 0.8919\n",
      "Epoch 161/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9916\n",
      "Epoch 00161: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0300 - acc: 0.9916 - val_loss: 0.5013 - val_acc: 0.8956\n",
      "Epoch 162/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9949\n",
      "Epoch 00162: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0191 - acc: 0.9949 - val_loss: 0.5656 - val_acc: 0.8854\n",
      "Epoch 163/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9949\n",
      "Epoch 00163: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0187 - acc: 0.9949 - val_loss: 0.7884 - val_acc: 0.8362\n",
      "Epoch 164/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0298 - acc: 0.9916\n",
      "Epoch 00164: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0298 - acc: 0.9916 - val_loss: 0.4188 - val_acc: 0.9117\n",
      "Epoch 165/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9947\n",
      "Epoch 00165: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0207 - acc: 0.9947 - val_loss: 0.4194 - val_acc: 0.9113\n",
      "Epoch 166/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0215 - acc: 0.9945\n",
      "Epoch 00166: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0216 - acc: 0.9945 - val_loss: 0.6472 - val_acc: 0.8642\n",
      "Epoch 167/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9919\n",
      "Epoch 00167: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0301 - acc: 0.9919 - val_loss: 0.6543 - val_acc: 0.8698\n",
      "Epoch 168/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9911\n",
      "Epoch 00168: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0319 - acc: 0.9911 - val_loss: 0.7779 - val_acc: 0.8502\n",
      "Epoch 169/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9967\n",
      "Epoch 00169: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0137 - acc: 0.9967 - val_loss: 0.5329 - val_acc: 0.8870\n",
      "Epoch 170/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9898\n",
      "Epoch 00170: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0342 - acc: 0.9898 - val_loss: 0.6257 - val_acc: 0.8721\n",
      "Epoch 171/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9913\n",
      "Epoch 00171: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0309 - acc: 0.9913 - val_loss: 0.4396 - val_acc: 0.9094\n",
      "Epoch 172/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9961\n",
      "Epoch 00172: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0166 - acc: 0.9961 - val_loss: 0.5286 - val_acc: 0.8891\n",
      "Epoch 173/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9968\n",
      "Epoch 00173: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0131 - acc: 0.9968 - val_loss: 0.5346 - val_acc: 0.8903\n",
      "Epoch 174/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9906\n",
      "Epoch 00174: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0301 - acc: 0.9906 - val_loss: 0.6987 - val_acc: 0.8651\n",
      "Epoch 175/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9954\n",
      "Epoch 00175: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0168 - acc: 0.9954 - val_loss: 0.7632 - val_acc: 0.8472\n",
      "Epoch 176/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9927\n",
      "Epoch 00176: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0248 - acc: 0.9927 - val_loss: 0.4823 - val_acc: 0.9033\n",
      "Epoch 177/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9902\n",
      "Epoch 00177: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0331 - acc: 0.9902 - val_loss: 0.5575 - val_acc: 0.8887\n",
      "Epoch 178/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9960\n",
      "Epoch 00178: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0169 - acc: 0.9960 - val_loss: 0.5715 - val_acc: 0.8849\n",
      "Epoch 179/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9935\n",
      "Epoch 00179: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0259 - acc: 0.9935 - val_loss: 0.5982 - val_acc: 0.8798\n",
      "Epoch 180/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0218 - acc: 0.9939\n",
      "Epoch 00180: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0218 - acc: 0.9939 - val_loss: 0.6586 - val_acc: 0.8661\n",
      "Epoch 181/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9964\n",
      "Epoch 00181: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0165 - acc: 0.9964 - val_loss: 1.6134 - val_acc: 0.7461\n",
      "Epoch 182/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9948\n",
      "Epoch 00182: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0204 - acc: 0.9948 - val_loss: 0.5124 - val_acc: 0.8942\n",
      "Epoch 183/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9950\n",
      "Epoch 00183: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0187 - acc: 0.9950 - val_loss: 0.5147 - val_acc: 0.8966\n",
      "Epoch 184/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9915\n",
      "Epoch 00184: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0322 - acc: 0.9916 - val_loss: 0.4788 - val_acc: 0.8989\n",
      "Epoch 185/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9961\n",
      "Epoch 00185: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0156 - acc: 0.9961 - val_loss: 0.5198 - val_acc: 0.8905\n",
      "Epoch 186/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9945\n",
      "Epoch 00186: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0198 - acc: 0.9945 - val_loss: 0.8382 - val_acc: 0.8402\n",
      "Epoch 187/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9923\n",
      "Epoch 00187: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.0293 - acc: 0.9922 - val_loss: 0.6724 - val_acc: 0.8642\n",
      "Epoch 188/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9907\n",
      "Epoch 00188: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0304 - acc: 0.9907 - val_loss: 0.4745 - val_acc: 0.9085\n",
      "Epoch 189/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0159 - acc: 0.9958\n",
      "Epoch 00189: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0159 - acc: 0.9958 - val_loss: 0.6435 - val_acc: 0.8726\n",
      "Epoch 190/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9960\n",
      "Epoch 00190: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0170 - acc: 0.9960 - val_loss: 0.6268 - val_acc: 0.8847\n",
      "Epoch 191/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9933\n",
      "Epoch 00191: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0237 - acc: 0.9933 - val_loss: 0.9529 - val_acc: 0.8211\n",
      "Epoch 192/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9950\n",
      "Epoch 00192: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0193 - acc: 0.9950 - val_loss: 0.5293 - val_acc: 0.8924\n",
      "Epoch 193/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0210 - acc: 0.9946\n",
      "Epoch 00193: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0211 - acc: 0.9945 - val_loss: 0.5913 - val_acc: 0.8845\n",
      "Epoch 194/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9912\n",
      "Epoch 00194: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0310 - acc: 0.9912 - val_loss: 0.5363 - val_acc: 0.8910\n",
      "Epoch 195/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9924\n",
      "Epoch 00195: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0270 - acc: 0.9924 - val_loss: 0.4620 - val_acc: 0.9071\n",
      "Epoch 196/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9964\n",
      "Epoch 00196: val_loss did not improve from 0.37927\n",
      "36805/36805 [==============================] - 89s 2ms/sample - loss: 0.0142 - acc: 0.9964 - val_loss: 0.5280 - val_acc: 0.8940\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.4731 - acc: 0.8922\n",
      "Loss: 0.47306517379925134 Accuracy: 0.89221185\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9186 - acc: 0.3985\n",
      "Epoch 00001: val_loss improved from inf to 1.42298, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/001-1.4230.hdf5\n",
      "36805/36805 [==============================] - 106s 3ms/sample - loss: 1.9186 - acc: 0.3985 - val_loss: 1.4230 - val_acc: 0.5539\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2579 - acc: 0.6180\n",
      "Epoch 00002: val_loss improved from 1.42298 to 1.27944, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/002-1.2794.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 1.2580 - acc: 0.6180 - val_loss: 1.2794 - val_acc: 0.6173\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9827 - acc: 0.7102\n",
      "Epoch 00003: val_loss improved from 1.27944 to 1.08766, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/003-1.0877.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.9828 - acc: 0.7101 - val_loss: 1.0877 - val_acc: 0.6662\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8143 - acc: 0.7637\n",
      "Epoch 00004: val_loss improved from 1.08766 to 0.73727, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/004-0.7373.hdf5\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.8144 - acc: 0.7637 - val_loss: 0.7373 - val_acc: 0.7841\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6902 - acc: 0.8014\n",
      "Epoch 00005: val_loss improved from 0.73727 to 0.66757, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/005-0.6676.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.6903 - acc: 0.8013 - val_loss: 0.6676 - val_acc: 0.7971\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5921 - acc: 0.8317\n",
      "Epoch 00006: val_loss did not improve from 0.66757\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.5924 - acc: 0.8317 - val_loss: 0.8096 - val_acc: 0.7594\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5243 - acc: 0.8514\n",
      "Epoch 00007: val_loss improved from 0.66757 to 0.64572, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/007-0.6457.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.5242 - acc: 0.8514 - val_loss: 0.6457 - val_acc: 0.8116\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4655 - acc: 0.8684\n",
      "Epoch 00008: val_loss did not improve from 0.64572\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.4654 - acc: 0.8684 - val_loss: 0.7188 - val_acc: 0.7915\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4195 - acc: 0.8820\n",
      "Epoch 00009: val_loss improved from 0.64572 to 0.47904, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/009-0.4790.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.4196 - acc: 0.8820 - val_loss: 0.4790 - val_acc: 0.8668\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3881 - acc: 0.8908\n",
      "Epoch 00010: val_loss improved from 0.47904 to 0.47184, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/010-0.4718.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.3882 - acc: 0.8908 - val_loss: 0.4718 - val_acc: 0.8616\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3535 - acc: 0.9001\n",
      "Epoch 00011: val_loss did not improve from 0.47184\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3535 - acc: 0.9000 - val_loss: 0.5950 - val_acc: 0.8237\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3263 - acc: 0.9080\n",
      "Epoch 00012: val_loss did not improve from 0.47184\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.3262 - acc: 0.9080 - val_loss: 0.5086 - val_acc: 0.8581\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2984 - acc: 0.9152\n",
      "Epoch 00013: val_loss improved from 0.47184 to 0.44560, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/013-0.4456.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2986 - acc: 0.9152 - val_loss: 0.4456 - val_acc: 0.8772\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2827 - acc: 0.9200\n",
      "Epoch 00014: val_loss did not improve from 0.44560\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.2828 - acc: 0.9200 - val_loss: 0.5891 - val_acc: 0.8251\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2677 - acc: 0.9221\n",
      "Epoch 00015: val_loss improved from 0.44560 to 0.35238, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/015-0.3524.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2677 - acc: 0.9221 - val_loss: 0.3524 - val_acc: 0.8987\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2464 - acc: 0.9308\n",
      "Epoch 00016: val_loss did not improve from 0.35238\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2464 - acc: 0.9308 - val_loss: 0.6050 - val_acc: 0.8381\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2339 - acc: 0.9329\n",
      "Epoch 00017: val_loss improved from 0.35238 to 0.30499, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/017-0.3050.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2339 - acc: 0.9329 - val_loss: 0.3050 - val_acc: 0.9164\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2148 - acc: 0.9387\n",
      "Epoch 00018: val_loss did not improve from 0.30499\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2149 - acc: 0.9386 - val_loss: 0.4849 - val_acc: 0.8614\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9396\n",
      "Epoch 00019: val_loss did not improve from 0.30499\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.2116 - acc: 0.9396 - val_loss: 0.5376 - val_acc: 0.8376\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1978 - acc: 0.9430\n",
      "Epoch 00020: val_loss did not improve from 0.30499\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1978 - acc: 0.9429 - val_loss: 0.3293 - val_acc: 0.9064\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1832 - acc: 0.9485\n",
      "Epoch 00021: val_loss did not improve from 0.30499\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1832 - acc: 0.9485 - val_loss: 0.4151 - val_acc: 0.8887\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1734 - acc: 0.9513\n",
      "Epoch 00022: val_loss did not improve from 0.30499\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1734 - acc: 0.9513 - val_loss: 0.5495 - val_acc: 0.8577\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9518\n",
      "Epoch 00023: val_loss did not improve from 0.30499\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1678 - acc: 0.9518 - val_loss: 0.3103 - val_acc: 0.9168\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9564\n",
      "Epoch 00024: val_loss improved from 0.30499 to 0.29329, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/024-0.2933.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1514 - acc: 0.9564 - val_loss: 0.2933 - val_acc: 0.9157\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9565\n",
      "Epoch 00025: val_loss improved from 0.29329 to 0.26093, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/025-0.2609.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1499 - acc: 0.9565 - val_loss: 0.2609 - val_acc: 0.9264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9612\n",
      "Epoch 00026: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1342 - acc: 0.9612 - val_loss: 0.3961 - val_acc: 0.8968\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1299 - acc: 0.9635\n",
      "Epoch 00027: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 90s 2ms/sample - loss: 0.1299 - acc: 0.9635 - val_loss: 0.3303 - val_acc: 0.9096\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1300 - acc: 0.9624\n",
      "Epoch 00028: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1300 - acc: 0.9624 - val_loss: 0.2747 - val_acc: 0.9255\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1182 - acc: 0.9664\n",
      "Epoch 00029: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1182 - acc: 0.9664 - val_loss: 0.3757 - val_acc: 0.9099\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9693\n",
      "Epoch 00030: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1100 - acc: 0.9693 - val_loss: 0.3949 - val_acc: 0.8845\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1091 - acc: 0.9695\n",
      "Epoch 00031: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.1091 - acc: 0.9695 - val_loss: 0.2819 - val_acc: 0.9217\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9721\n",
      "Epoch 00032: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0981 - acc: 0.9721 - val_loss: 0.3641 - val_acc: 0.9024\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0914 - acc: 0.9736\n",
      "Epoch 00033: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0915 - acc: 0.9736 - val_loss: 0.3705 - val_acc: 0.8980\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0946 - acc: 0.9737\n",
      "Epoch 00034: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0946 - acc: 0.9736 - val_loss: 0.3854 - val_acc: 0.8980\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9751\n",
      "Epoch 00035: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0880 - acc: 0.9751 - val_loss: 0.3207 - val_acc: 0.9129\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9756\n",
      "Epoch 00036: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0834 - acc: 0.9756 - val_loss: 0.3756 - val_acc: 0.9038\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9782\n",
      "Epoch 00037: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0792 - acc: 0.9782 - val_loss: 0.3671 - val_acc: 0.8984\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9759\n",
      "Epoch 00038: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0852 - acc: 0.9759 - val_loss: 0.4285 - val_acc: 0.8884\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9817\n",
      "Epoch 00039: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0666 - acc: 0.9817 - val_loss: 0.5379 - val_acc: 0.8616\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9808\n",
      "Epoch 00040: val_loss did not improve from 0.26093\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0695 - acc: 0.9808 - val_loss: 0.2695 - val_acc: 0.9252\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9828\n",
      "Epoch 00041: val_loss improved from 0.26093 to 0.23016, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_8_conv_checkpoint/041-0.2302.hdf5\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0642 - acc: 0.9828 - val_loss: 0.2302 - val_acc: 0.9352\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9825\n",
      "Epoch 00042: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0619 - acc: 0.9825 - val_loss: 0.2869 - val_acc: 0.9227\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9832\n",
      "Epoch 00043: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0609 - acc: 0.9832 - val_loss: 0.3940 - val_acc: 0.9029\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9845\n",
      "Epoch 00044: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0560 - acc: 0.9845 - val_loss: 0.3199 - val_acc: 0.9234\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9848\n",
      "Epoch 00045: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0571 - acc: 0.9848 - val_loss: 0.3472 - val_acc: 0.9113\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9845\n",
      "Epoch 00046: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0563 - acc: 0.9844 - val_loss: 0.3558 - val_acc: 0.9033\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9823\n",
      "Epoch 00047: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0622 - acc: 0.9823 - val_loss: 0.4517 - val_acc: 0.8840\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9880\n",
      "Epoch 00048: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0458 - acc: 0.9880 - val_loss: 0.3574 - val_acc: 0.9043\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9839\n",
      "Epoch 00049: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0612 - acc: 0.9839 - val_loss: 0.3085 - val_acc: 0.9278\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9872\n",
      "Epoch 00050: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0469 - acc: 0.9872 - val_loss: 0.3369 - val_acc: 0.9192\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9886\n",
      "Epoch 00051: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0418 - acc: 0.9885 - val_loss: 0.3328 - val_acc: 0.9133\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9817\n",
      "Epoch 00052: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0654 - acc: 0.9817 - val_loss: 0.3676 - val_acc: 0.9040\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9888\n",
      "Epoch 00053: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0424 - acc: 0.9888 - val_loss: 0.3640 - val_acc: 0.9145\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9891\n",
      "Epoch 00054: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0412 - acc: 0.9891 - val_loss: 0.2462 - val_acc: 0.9350\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9887\n",
      "Epoch 00055: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0404 - acc: 0.9887 - val_loss: 0.3014 - val_acc: 0.9220\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9915\n",
      "Epoch 00056: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0339 - acc: 0.9915 - val_loss: 0.3162 - val_acc: 0.9199\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9879\n",
      "Epoch 00057: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0449 - acc: 0.9879 - val_loss: 0.3520 - val_acc: 0.9157\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9920\n",
      "Epoch 00058: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0319 - acc: 0.9920 - val_loss: 0.2568 - val_acc: 0.9383\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9908\n",
      "Epoch 00059: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0354 - acc: 0.9908 - val_loss: 0.3998 - val_acc: 0.8998\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9903\n",
      "Epoch 00060: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0357 - acc: 0.9903 - val_loss: 0.3299 - val_acc: 0.9187\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9905\n",
      "Epoch 00061: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0334 - acc: 0.9905 - val_loss: 0.4622 - val_acc: 0.8931\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9917\n",
      "Epoch 00062: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0320 - acc: 0.9917 - val_loss: 0.3392 - val_acc: 0.9164\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9907\n",
      "Epoch 00063: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0356 - acc: 0.9907 - val_loss: 0.3861 - val_acc: 0.9113\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9859\n",
      "Epoch 00064: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0482 - acc: 0.9859 - val_loss: 0.2996 - val_acc: 0.9283\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0204 - acc: 0.9949\n",
      "Epoch 00065: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0205 - acc: 0.9949 - val_loss: 0.2980 - val_acc: 0.9231\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9910\n",
      "Epoch 00066: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0348 - acc: 0.9909 - val_loss: 0.3188 - val_acc: 0.9213\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9882\n",
      "Epoch 00067: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0415 - acc: 0.9882 - val_loss: 0.3651 - val_acc: 0.9110\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9905\n",
      "Epoch 00068: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0358 - acc: 0.9905 - val_loss: 0.2355 - val_acc: 0.9474\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9957\n",
      "Epoch 00069: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0188 - acc: 0.9957 - val_loss: 0.2380 - val_acc: 0.9441\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9912\n",
      "Epoch 00070: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0313 - acc: 0.9912 - val_loss: 0.3392 - val_acc: 0.9178\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9907\n",
      "Epoch 00071: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0332 - acc: 0.9907 - val_loss: 0.2757 - val_acc: 0.9331\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9928\n",
      "Epoch 00072: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0270 - acc: 0.9928 - val_loss: 0.2804 - val_acc: 0.9348\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9934\n",
      "Epoch 00073: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0247 - acc: 0.9934 - val_loss: 0.3572 - val_acc: 0.9227\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9923\n",
      "Epoch 00074: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0274 - acc: 0.9923 - val_loss: 0.2528 - val_acc: 0.9352\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0231 - acc: 0.9939\n",
      "Epoch 00075: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0231 - acc: 0.9939 - val_loss: 0.3557 - val_acc: 0.9166\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9914\n",
      "Epoch 00076: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0322 - acc: 0.9914 - val_loss: 0.3005 - val_acc: 0.9324\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9959\n",
      "Epoch 00077: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0178 - acc: 0.9959 - val_loss: 0.2629 - val_acc: 0.9380\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9941\n",
      "Epoch 00078: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0236 - acc: 0.9941 - val_loss: 0.2815 - val_acc: 0.9329\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0278 - acc: 0.9925\n",
      "Epoch 00079: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0278 - acc: 0.9925 - val_loss: 0.2379 - val_acc: 0.9446\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9940\n",
      "Epoch 00080: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0228 - acc: 0.9940 - val_loss: 0.4321 - val_acc: 0.9040\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9911\n",
      "Epoch 00081: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0307 - acc: 0.9911 - val_loss: 0.2653 - val_acc: 0.9432\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9960\n",
      "Epoch 00082: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0160 - acc: 0.9960 - val_loss: 0.3918 - val_acc: 0.9185\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9924\n",
      "Epoch 00083: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0263 - acc: 0.9924 - val_loss: 0.3022 - val_acc: 0.9317\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9954\n",
      "Epoch 00084: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0177 - acc: 0.9954 - val_loss: 0.3354 - val_acc: 0.9273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9915\n",
      "Epoch 00085: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0314 - acc: 0.9915 - val_loss: 0.2442 - val_acc: 0.9427\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9937\n",
      "Epoch 00086: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0229 - acc: 0.9937 - val_loss: 0.2673 - val_acc: 0.9408\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9934\n",
      "Epoch 00087: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0229 - acc: 0.9934 - val_loss: 0.2378 - val_acc: 0.9474\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9955\n",
      "Epoch 00088: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0174 - acc: 0.9955 - val_loss: 0.4024 - val_acc: 0.9110\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9940\n",
      "Epoch 00089: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0224 - acc: 0.9940 - val_loss: 0.2642 - val_acc: 0.9387\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0205 - acc: 0.9947\n",
      "Epoch 00090: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0205 - acc: 0.9947 - val_loss: 0.3534 - val_acc: 0.9222\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0199 - acc: 0.9949\n",
      "Epoch 00091: val_loss did not improve from 0.23016\n",
      "36805/36805 [==============================] - 91s 2ms/sample - loss: 0.0199 - acc: 0.9949 - val_loss: 0.3652 - val_acc: 0.9227\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2912 - acc: 0.9169\n",
      "Loss: 0.2912467776614929 Accuracy: 0.91692626\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6693 - acc: 0.4859\n",
      "Epoch 00001: val_loss improved from inf to 1.10973, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/001-1.1097.hdf5\n",
      "36805/36805 [==============================] - 112s 3ms/sample - loss: 1.6692 - acc: 0.4859 - val_loss: 1.1097 - val_acc: 0.6662\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9181 - acc: 0.7257\n",
      "Epoch 00002: val_loss improved from 1.10973 to 0.76647, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/002-0.7665.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.9180 - acc: 0.7257 - val_loss: 0.7665 - val_acc: 0.7619\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6445 - acc: 0.8126\n",
      "Epoch 00003: val_loss improved from 0.76647 to 0.55339, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/003-0.5534.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.6445 - acc: 0.8126 - val_loss: 0.5534 - val_acc: 0.8456\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4963 - acc: 0.8554\n",
      "Epoch 00004: val_loss improved from 0.55339 to 0.43690, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/004-0.4369.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.4964 - acc: 0.8553 - val_loss: 0.4369 - val_acc: 0.8721\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4107 - acc: 0.8795\n",
      "Epoch 00005: val_loss did not improve from 0.43690\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.4108 - acc: 0.8795 - val_loss: 0.4840 - val_acc: 0.8619\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3447 - acc: 0.8983\n",
      "Epoch 00006: val_loss improved from 0.43690 to 0.32125, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/006-0.3213.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.3447 - acc: 0.8984 - val_loss: 0.3213 - val_acc: 0.9054\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2980 - acc: 0.9124\n",
      "Epoch 00007: val_loss did not improve from 0.32125\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.2981 - acc: 0.9123 - val_loss: 0.3365 - val_acc: 0.9066\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2617 - acc: 0.9237\n",
      "Epoch 00008: val_loss did not improve from 0.32125\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.2617 - acc: 0.9237 - val_loss: 0.4596 - val_acc: 0.8621\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2351 - acc: 0.9302\n",
      "Epoch 00009: val_loss improved from 0.32125 to 0.25591, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/009-0.2559.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.2353 - acc: 0.9301 - val_loss: 0.2559 - val_acc: 0.9250\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2053 - acc: 0.9402\n",
      "Epoch 00010: val_loss did not improve from 0.25591\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.2053 - acc: 0.9402 - val_loss: 0.2901 - val_acc: 0.9131\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1921 - acc: 0.9443\n",
      "Epoch 00011: val_loss did not improve from 0.25591\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1922 - acc: 0.9442 - val_loss: 0.3191 - val_acc: 0.9057\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1763 - acc: 0.9476\n",
      "Epoch 00012: val_loss improved from 0.25591 to 0.25298, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/012-0.2530.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1763 - acc: 0.9476 - val_loss: 0.2530 - val_acc: 0.9269\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1526 - acc: 0.9546\n",
      "Epoch 00013: val_loss did not improve from 0.25298\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1526 - acc: 0.9546 - val_loss: 0.2969 - val_acc: 0.9119\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1362 - acc: 0.9606\n",
      "Epoch 00014: val_loss improved from 0.25298 to 0.24651, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/014-0.2465.hdf5\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.1362 - acc: 0.9605 - val_loss: 0.2465 - val_acc: 0.9241\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9627\n",
      "Epoch 00015: val_loss did not improve from 0.24651\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1301 - acc: 0.9627 - val_loss: 0.2925 - val_acc: 0.9113\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1149 - acc: 0.9660\n",
      "Epoch 00016: val_loss did not improve from 0.24651\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1149 - acc: 0.9660 - val_loss: 0.2680 - val_acc: 0.9171\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1078 - acc: 0.9689\n",
      "Epoch 00017: val_loss did not improve from 0.24651\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1079 - acc: 0.9688 - val_loss: 0.2515 - val_acc: 0.9222\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9696\n",
      "Epoch 00018: val_loss improved from 0.24651 to 0.24315, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/018-0.2432.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.1052 - acc: 0.9696 - val_loss: 0.2432 - val_acc: 0.9266\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0858 - acc: 0.9760\n",
      "Epoch 00019: val_loss improved from 0.24315 to 0.21593, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/019-0.2159.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0858 - acc: 0.9760 - val_loss: 0.2159 - val_acc: 0.9376\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9774\n",
      "Epoch 00020: val_loss did not improve from 0.21593\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0802 - acc: 0.9774 - val_loss: 0.2556 - val_acc: 0.9255\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9787\n",
      "Epoch 00021: val_loss did not improve from 0.21593\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0752 - acc: 0.9788 - val_loss: 0.2501 - val_acc: 0.9308\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9817\n",
      "Epoch 00022: val_loss did not improve from 0.21593\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0673 - acc: 0.9816 - val_loss: 0.2777 - val_acc: 0.9227\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9812\n",
      "Epoch 00023: val_loss did not improve from 0.21593\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0680 - acc: 0.9812 - val_loss: 0.2313 - val_acc: 0.9331\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9842\n",
      "Epoch 00024: val_loss did not improve from 0.21593\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0595 - acc: 0.9842 - val_loss: 0.2526 - val_acc: 0.9231\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9860\n",
      "Epoch 00025: val_loss improved from 0.21593 to 0.20133, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/025-0.2013.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0524 - acc: 0.9860 - val_loss: 0.2013 - val_acc: 0.9406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9864\n",
      "Epoch 00026: val_loss did not improve from 0.20133\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0499 - acc: 0.9864 - val_loss: 0.2658 - val_acc: 0.9238\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9889\n",
      "Epoch 00027: val_loss did not improve from 0.20133\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0429 - acc: 0.9889 - val_loss: 0.2768 - val_acc: 0.9194\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0543 - acc: 0.9852\n",
      "Epoch 00028: val_loss did not improve from 0.20133\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0543 - acc: 0.9852 - val_loss: 0.2955 - val_acc: 0.9117\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9899\n",
      "Epoch 00029: val_loss did not improve from 0.20133\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0403 - acc: 0.9899 - val_loss: 0.2437 - val_acc: 0.9306\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9887\n",
      "Epoch 00030: val_loss did not improve from 0.20133\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0406 - acc: 0.9887 - val_loss: 0.2200 - val_acc: 0.9401\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9923\n",
      "Epoch 00031: val_loss did not improve from 0.20133\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0324 - acc: 0.9923 - val_loss: 0.2293 - val_acc: 0.9411\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9897\n",
      "Epoch 00032: val_loss improved from 0.20133 to 0.19895, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/032-0.1989.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0384 - acc: 0.9897 - val_loss: 0.1989 - val_acc: 0.9453\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9922\n",
      "Epoch 00033: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0302 - acc: 0.9922 - val_loss: 0.2010 - val_acc: 0.9462\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9941\n",
      "Epoch 00034: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0249 - acc: 0.9941 - val_loss: 0.2312 - val_acc: 0.9359\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0323 - acc: 0.9912\n",
      "Epoch 00035: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0324 - acc: 0.9912 - val_loss: 0.2680 - val_acc: 0.9276\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9901\n",
      "Epoch 00036: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0377 - acc: 0.9901 - val_loss: 0.2226 - val_acc: 0.9411\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9945\n",
      "Epoch 00037: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0225 - acc: 0.9945 - val_loss: 0.2087 - val_acc: 0.9439\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9943\n",
      "Epoch 00038: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0223 - acc: 0.9943 - val_loss: 0.2187 - val_acc: 0.9467\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9937\n",
      "Epoch 00039: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0256 - acc: 0.9937 - val_loss: 0.2216 - val_acc: 0.9394\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9938\n",
      "Epoch 00040: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0244 - acc: 0.9938 - val_loss: 0.2388 - val_acc: 0.9385\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9941\n",
      "Epoch 00041: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0213 - acc: 0.9941 - val_loss: 0.2862 - val_acc: 0.9308\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9932\n",
      "Epoch 00042: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0259 - acc: 0.9932 - val_loss: 0.2168 - val_acc: 0.9425\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9954\n",
      "Epoch 00043: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0192 - acc: 0.9954 - val_loss: 0.2087 - val_acc: 0.9483\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0164 - acc: 0.9956\n",
      "Epoch 00044: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0164 - acc: 0.9956 - val_loss: 0.2432 - val_acc: 0.9385\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9924\n",
      "Epoch 00045: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0248 - acc: 0.9924 - val_loss: 0.2493 - val_acc: 0.9364\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0195 - acc: 0.9951\n",
      "Epoch 00046: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0195 - acc: 0.9951 - val_loss: 0.2600 - val_acc: 0.9369\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9951\n",
      "Epoch 00047: val_loss did not improve from 0.19895\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0178 - acc: 0.9951 - val_loss: 0.2155 - val_acc: 0.9441\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9922\n",
      "Epoch 00048: val_loss improved from 0.19895 to 0.19297, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/048-0.1930.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0289 - acc: 0.9921 - val_loss: 0.1930 - val_acc: 0.9511\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0206 - acc: 0.9946\n",
      "Epoch 00049: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0207 - acc: 0.9946 - val_loss: 0.2494 - val_acc: 0.9394\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9939\n",
      "Epoch 00050: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0221 - acc: 0.9939 - val_loss: 0.2145 - val_acc: 0.9418\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9974\n",
      "Epoch 00051: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0114 - acc: 0.9974 - val_loss: 0.2153 - val_acc: 0.9453\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9971\n",
      "Epoch 00052: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0128 - acc: 0.9971 - val_loss: 0.1985 - val_acc: 0.9532\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9958\n",
      "Epoch 00053: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0162 - acc: 0.9958 - val_loss: 0.2263 - val_acc: 0.9453\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9941\n",
      "Epoch 00054: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0213 - acc: 0.9941 - val_loss: 0.1995 - val_acc: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9977\n",
      "Epoch 00055: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0096 - acc: 0.9977 - val_loss: 0.2190 - val_acc: 0.9462\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9955\n",
      "Epoch 00056: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0177 - acc: 0.9955 - val_loss: 0.2345 - val_acc: 0.9448\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9944\n",
      "Epoch 00057: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0202 - acc: 0.9944 - val_loss: 0.1999 - val_acc: 0.9532\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9969\n",
      "Epoch 00058: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 93s 3ms/sample - loss: 0.0116 - acc: 0.9969 - val_loss: 0.2083 - val_acc: 0.9474\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9969\n",
      "Epoch 00059: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0121 - acc: 0.9969 - val_loss: 0.2462 - val_acc: 0.9408\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9967\n",
      "Epoch 00060: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0132 - acc: 0.9967 - val_loss: 0.2015 - val_acc: 0.9541\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9949\n",
      "Epoch 00061: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0189 - acc: 0.9949 - val_loss: 0.2073 - val_acc: 0.9511\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9976\n",
      "Epoch 00062: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0100 - acc: 0.9976 - val_loss: 0.2056 - val_acc: 0.9504\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9953\n",
      "Epoch 00063: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0174 - acc: 0.9953 - val_loss: 0.4408 - val_acc: 0.8849\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9971\n",
      "Epoch 00064: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0114 - acc: 0.9971 - val_loss: 0.2933 - val_acc: 0.9292\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9935\n",
      "Epoch 00065: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0229 - acc: 0.9935 - val_loss: 0.2276 - val_acc: 0.9488\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9985\n",
      "Epoch 00066: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0069 - acc: 0.9985 - val_loss: 0.1974 - val_acc: 0.9520\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9968\n",
      "Epoch 00067: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0113 - acc: 0.9968 - val_loss: 0.2144 - val_acc: 0.9471\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9931\n",
      "Epoch 00068: val_loss did not improve from 0.19297\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0248 - acc: 0.9930 - val_loss: 0.1984 - val_acc: 0.9515\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9955\n",
      "Epoch 00069: val_loss improved from 0.19297 to 0.17436, saving model to model/checkpoint/1D_CNN_custom_tanh_DO_025_DO_BN_9_conv_checkpoint/069-0.1744.hdf5\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0170 - acc: 0.9955 - val_loss: 0.1744 - val_acc: 0.9550\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9978\n",
      "Epoch 00070: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0090 - acc: 0.9978 - val_loss: 0.1884 - val_acc: 0.9553\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9998\n",
      "Epoch 00071: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0024 - acc: 0.9998 - val_loss: 0.1813 - val_acc: 0.9560\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9939\n",
      "Epoch 00072: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0207 - acc: 0.9939 - val_loss: 0.2672 - val_acc: 0.9334\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9987\n",
      "Epoch 00073: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0072 - acc: 0.9988 - val_loss: 0.1897 - val_acc: 0.9543\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9962\n",
      "Epoch 00074: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0135 - acc: 0.9963 - val_loss: 0.2254 - val_acc: 0.9485\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9964\n",
      "Epoch 00075: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0137 - acc: 0.9964 - val_loss: 0.2276 - val_acc: 0.9488\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9982\n",
      "Epoch 00076: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0080 - acc: 0.9982 - val_loss: 0.1946 - val_acc: 0.9543\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0044 - acc: 0.9992\n",
      "Epoch 00077: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0044 - acc: 0.9992 - val_loss: 0.2083 - val_acc: 0.9527\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9954\n",
      "Epoch 00078: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0158 - acc: 0.9954 - val_loss: 0.2496 - val_acc: 0.9413\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9951\n",
      "Epoch 00079: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0180 - acc: 0.9951 - val_loss: 0.2122 - val_acc: 0.9534\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9986\n",
      "Epoch 00080: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0067 - acc: 0.9986 - val_loss: 0.1955 - val_acc: 0.9553\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9970\n",
      "Epoch 00081: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0111 - acc: 0.9970 - val_loss: 0.2040 - val_acc: 0.9553\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9971\n",
      "Epoch 00082: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0103 - acc: 0.9971 - val_loss: 0.2801 - val_acc: 0.9378\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9974\n",
      "Epoch 00083: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0103 - acc: 0.9974 - val_loss: 0.2536 - val_acc: 0.9411\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0085 - acc: 0.9979\n",
      "Epoch 00084: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0085 - acc: 0.9978 - val_loss: 0.2280 - val_acc: 0.9453\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9959\n",
      "Epoch 00085: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0151 - acc: 0.9958 - val_loss: 0.2132 - val_acc: 0.9541\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9956\n",
      "Epoch 00086: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0154 - acc: 0.9956 - val_loss: 0.1945 - val_acc: 0.9562\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0022 - acc: 0.9998\n",
      "Epoch 00087: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0022 - acc: 0.9998 - val_loss: 0.2013 - val_acc: 0.9541\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9982\n",
      "Epoch 00088: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0069 - acc: 0.9982 - val_loss: 0.2544 - val_acc: 0.9420\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9956\n",
      "Epoch 00089: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0149 - acc: 0.9956 - val_loss: 0.2431 - val_acc: 0.9478\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9977\n",
      "Epoch 00090: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0084 - acc: 0.9977 - val_loss: 0.2291 - val_acc: 0.9497\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9976\n",
      "Epoch 00091: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0091 - acc: 0.9976 - val_loss: 0.2590 - val_acc: 0.9450\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9945\n",
      "Epoch 00092: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0196 - acc: 0.9945 - val_loss: 0.2133 - val_acc: 0.9509\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9973\n",
      "Epoch 00093: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0102 - acc: 0.9973 - val_loss: 0.1924 - val_acc: 0.9569\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9994\n",
      "Epoch 00094: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0033 - acc: 0.9994 - val_loss: 0.2191 - val_acc: 0.9504\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9990\n",
      "Epoch 00095: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0045 - acc: 0.9990 - val_loss: 0.2154 - val_acc: 0.9532\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9959\n",
      "Epoch 00096: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0137 - acc: 0.9959 - val_loss: 0.2164 - val_acc: 0.9525\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0040 - acc: 0.9991\n",
      "Epoch 00097: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0041 - acc: 0.9991 - val_loss: 0.2238 - val_acc: 0.9522\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0161 - acc: 0.9955\n",
      "Epoch 00098: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0161 - acc: 0.9955 - val_loss: 0.2125 - val_acc: 0.9529\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0037 - acc: 0.9992\n",
      "Epoch 00099: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0036 - acc: 0.9992 - val_loss: 0.2187 - val_acc: 0.9548\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9985\n",
      "Epoch 00100: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0068 - acc: 0.9985 - val_loss: 0.2088 - val_acc: 0.9536\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9970\n",
      "Epoch 00101: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0102 - acc: 0.9970 - val_loss: 0.2064 - val_acc: 0.9511\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9978\n",
      "Epoch 00102: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0083 - acc: 0.9978 - val_loss: 0.1925 - val_acc: 0.9564\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9994\n",
      "Epoch 00103: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0029 - acc: 0.9994 - val_loss: 0.3133 - val_acc: 0.9315\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9939\n",
      "Epoch 00104: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0222 - acc: 0.9939 - val_loss: 0.1864 - val_acc: 0.9602\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0039 - acc: 0.9991\n",
      "Epoch 00105: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0039 - acc: 0.9991 - val_loss: 0.1760 - val_acc: 0.9616\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0035 - acc: 0.9992\n",
      "Epoch 00106: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0035 - acc: 0.9992 - val_loss: 0.1832 - val_acc: 0.9599\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9980\n",
      "Epoch 00107: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0070 - acc: 0.9980 - val_loss: 0.2179 - val_acc: 0.9509\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9974\n",
      "Epoch 00108: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0099 - acc: 0.9974 - val_loss: 0.2211 - val_acc: 0.9469\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0045 - acc: 0.9990\n",
      "Epoch 00109: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0045 - acc: 0.9990 - val_loss: 0.2049 - val_acc: 0.9571\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9968\n",
      "Epoch 00110: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0097 - acc: 0.9968 - val_loss: 0.2763 - val_acc: 0.9362\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9966\n",
      "Epoch 00111: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0127 - acc: 0.9966 - val_loss: 0.1958 - val_acc: 0.9581\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0028 - acc: 0.9995\n",
      "Epoch 00112: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0028 - acc: 0.9995 - val_loss: 0.1809 - val_acc: 0.9602\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9970\n",
      "Epoch 00113: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0100 - acc: 0.9969 - val_loss: 0.2124 - val_acc: 0.9534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9948\n",
      "Epoch 00114: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0179 - acc: 0.9948 - val_loss: 0.1848 - val_acc: 0.9599\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0033 - acc: 0.9995\n",
      "Epoch 00115: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0033 - acc: 0.9995 - val_loss: 0.1862 - val_acc: 0.9590\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0026 - acc: 0.9996\n",
      "Epoch 00116: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0026 - acc: 0.9996 - val_loss: 0.2080 - val_acc: 0.9534\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0034 - acc: 0.9992\n",
      "Epoch 00117: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0034 - acc: 0.9992 - val_loss: 0.2349 - val_acc: 0.9520\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0111 - acc: 0.9969\n",
      "Epoch 00118: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 3ms/sample - loss: 0.0112 - acc: 0.9968 - val_loss: 0.2073 - val_acc: 0.9536\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9945\n",
      "Epoch 00119: val_loss did not improve from 0.17436\n",
      "36805/36805 [==============================] - 92s 2ms/sample - loss: 0.0188 - acc: 0.9945 - val_loss: 0.2203 - val_acc: 0.9529\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 0.2331 - acc: 0.9439\n",
      "Loss: 0.23307212622312062 Accuracy: 0.94392526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_tanh_DO_025_DO_BN'\n",
    "\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 3s 600us/sample - loss: 3.0644 - acc: 0.1020\n",
      "Loss: 3.0644077859068464 Accuracy: 0.101973005\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 919us/sample - loss: 2.8316 - acc: 0.3246\n",
      "Loss: 2.8315895648017477 Accuracy: 0.3246106\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 987us/sample - loss: 1.8795 - acc: 0.4295\n",
      "Loss: 1.879499415222358 Accuracy: 0.42949116\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.3915 - acc: 0.6079\n",
      "Loss: 1.3915153474698805 Accuracy: 0.607892\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 1.0521 - acc: 0.6947\n",
      "Loss: 1.0520976801156254 Accuracy: 0.69470406\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.8392 - acc: 0.8150\n",
      "Loss: 0.8392356582148425 Accuracy: 0.81495327\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4731 - acc: 0.8922\n",
      "Loss: 0.47306517379925134 Accuracy: 0.89221185\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2912 - acc: 0.9169\n",
      "Loss: 0.2912467776614929 Accuracy: 0.91692626\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2331 - acc: 0.9439\n",
      "Loss: 0.23307212622312062 Accuracy: 0.94392526\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_tanh_DO_025_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,384,656\n",
      "Trainable params: 16,384,528\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 774us/sample - loss: 11.6530 - acc: 0.1055\n",
      "Loss: 11.65299606501499 Accuracy: 0.10550363\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_46 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,482,448\n",
      "Trainable params: 5,482,192\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 5s 1ms/sample - loss: 7.1687 - acc: 0.3699\n",
      "Loss: 7.168680361770519 Accuracy: 0.36988577\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_48 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,861,904\n",
      "Trainable params: 1,861,520\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 3.8171 - acc: 0.4843\n",
      "Loss: 3.817127781567915 Accuracy: 0.48431984\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_51 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 669,264\n",
      "Trainable params: 668,752\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.8324 - acc: 0.6465\n",
      "Loss: 1.832364528399514 Accuracy: 0.6465213\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_55 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 508,112\n",
      "Trainable params: 507,344\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.5914 - acc: 0.6955\n",
      "Loss: 1.591362614572234 Accuracy: 0.69553477\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_60 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 320,336\n",
      "Trainable params: 319,312\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 1.1083 - acc: 0.7753\n",
      "Loss: 1.108331382212733 Accuracy: 0.77528554\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_66 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_72 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 312,784\n",
      "Trainable params: 311,504\n",
      "Non-trainable params: 1,280\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.6750 - acc: 0.8685\n",
      "Loss: 0.6750180344220139 Accuracy: 0.8685358\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 366,672\n",
      "Trainable params: 365,136\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.4434 - acc: 0.8980\n",
      "Loss: 0.4434253625285465 Accuracy: 0.898027\n",
      "\n",
      "1D_CNN_custom_tanh_DO_025_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_81 (Conv1D)           (None, 16000, 64)         384       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 16000, 64)         20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 5333, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 1777, 64)          20544     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 592, 128)          41088     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 197, 128)          82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 65, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 21, 128)           82048     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            164096    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 525,648\n",
      "Trainable params: 523,600\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 0.2417 - acc: 0.9441\n",
      "Loss: 0.24172403020677877 Accuracy: 0.9441329\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
