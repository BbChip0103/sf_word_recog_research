{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_ch_128_DO(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=5, filters=128, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(Activation('relu'))\n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=5, filters=128*(2**int((i+1)/4)), \n",
    "                          strides=1, padding='same'))\n",
    "        model.add(Activation('relu'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 227456)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                3639312   \n",
      "=================================================================\n",
      "Total params: 3,804,176\n",
      "Trainable params: 3,804,176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 75776)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                1212432   \n",
      "=================================================================\n",
      "Total params: 1,459,344\n",
      "Trainable params: 1,459,344\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 50432)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                806928    \n",
      "=================================================================\n",
      "Total params: 1,217,936\n",
      "Trainable params: 1,217,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16640)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                266256    \n",
      "=================================================================\n",
      "Total params: 1,005,200\n",
      "Trainable params: 1,005,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_18 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_20 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 5376)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                86032     \n",
      "=================================================================\n",
      "Total params: 1,152,912\n",
      "Trainable params: 1,152,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_25 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_30 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1792)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                28688     \n",
      "=================================================================\n",
      "Total params: 1,423,504\n",
      "Trainable params: 1,423,504\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_33 (Conv1D)           (None, 16000, 128)        768       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 16000, 128)        82048     \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 16000, 128)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 5333, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 128)         82048     \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 1777, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 592, 256)          164096    \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 592, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 197, 256)          327936    \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 197, 256)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 65, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 65, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 21, 256)           327936    \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 21, 256)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 7, 512)            655872    \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 7, 512)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 2, 512)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                16400     \n",
      "=================================================================\n",
      "Total params: 2,067,088\n",
      "Trainable params: 2,067,088\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    model = build_1d_cnn_custom_ch_128_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0150 - acc: 0.3691\n",
      "Epoch 00001: val_loss improved from inf to 1.56676, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_3_conv_checkpoint/001-1.5668.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 2.0150 - acc: 0.3691 - val_loss: 1.5668 - val_acc: 0.5181\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3959 - acc: 0.5708\n",
      "Epoch 00002: val_loss improved from 1.56676 to 1.40682, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_3_conv_checkpoint/002-1.4068.hdf5\n",
      "36805/36805 [==============================] - 34s 926us/sample - loss: 1.3959 - acc: 0.5708 - val_loss: 1.4068 - val_acc: 0.5663\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1416 - acc: 0.6516\n",
      "Epoch 00003: val_loss improved from 1.40682 to 1.35032, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_3_conv_checkpoint/003-1.3503.hdf5\n",
      "36805/36805 [==============================] - 34s 931us/sample - loss: 1.1416 - acc: 0.6516 - val_loss: 1.3503 - val_acc: 0.5826\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9529 - acc: 0.7090\n",
      "Epoch 00004: val_loss improved from 1.35032 to 1.30582, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_3_conv_checkpoint/004-1.3058.hdf5\n",
      "36805/36805 [==============================] - 34s 930us/sample - loss: 0.9529 - acc: 0.7091 - val_loss: 1.3058 - val_acc: 0.6063\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7886 - acc: 0.7607\n",
      "Epoch 00005: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 925us/sample - loss: 0.7885 - acc: 0.7607 - val_loss: 1.3811 - val_acc: 0.5935\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6329 - acc: 0.8110\n",
      "Epoch 00006: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 925us/sample - loss: 0.6329 - acc: 0.8110 - val_loss: 1.4857 - val_acc: 0.5840\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5042 - acc: 0.8510\n",
      "Epoch 00007: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 930us/sample - loss: 0.5042 - acc: 0.8509 - val_loss: 1.4924 - val_acc: 0.5945\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4042 - acc: 0.8796\n",
      "Epoch 00008: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 33s 909us/sample - loss: 0.4041 - acc: 0.8796 - val_loss: 1.6370 - val_acc: 0.5966\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3254 - acc: 0.9043\n",
      "Epoch 00009: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 934us/sample - loss: 0.3254 - acc: 0.9043 - val_loss: 1.7472 - val_acc: 0.5847\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2692 - acc: 0.9218\n",
      "Epoch 00010: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 931us/sample - loss: 0.2691 - acc: 0.9218 - val_loss: 1.8358 - val_acc: 0.5837\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2246 - acc: 0.9350\n",
      "Epoch 00011: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 929us/sample - loss: 0.2250 - acc: 0.9350 - val_loss: 1.9245 - val_acc: 0.5893\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9457\n",
      "Epoch 00012: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 921us/sample - loss: 0.1927 - acc: 0.9457 - val_loss: 2.0226 - val_acc: 0.5896\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1650 - acc: 0.9543\n",
      "Epoch 00013: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 925us/sample - loss: 0.1650 - acc: 0.9543 - val_loss: 2.1100 - val_acc: 0.5847\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9607\n",
      "Epoch 00014: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 928us/sample - loss: 0.1417 - acc: 0.9607 - val_loss: 2.1621 - val_acc: 0.5998\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9631\n",
      "Epoch 00015: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 926us/sample - loss: 0.1328 - acc: 0.9631 - val_loss: 2.2908 - val_acc: 0.5884\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1229 - acc: 0.9663\n",
      "Epoch 00016: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 920us/sample - loss: 0.1229 - acc: 0.9663 - val_loss: 2.3209 - val_acc: 0.5893\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9698\n",
      "Epoch 00017: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 917us/sample - loss: 0.1097 - acc: 0.9698 - val_loss: 2.3134 - val_acc: 0.5980\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9725\n",
      "Epoch 00018: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 922us/sample - loss: 0.1020 - acc: 0.9724 - val_loss: 2.4681 - val_acc: 0.5793\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1085 - acc: 0.9713\n",
      "Epoch 00019: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 928us/sample - loss: 0.1084 - acc: 0.9713 - val_loss: 2.3499 - val_acc: 0.6017\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9762\n",
      "Epoch 00020: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 931us/sample - loss: 0.0926 - acc: 0.9762 - val_loss: 2.3755 - val_acc: 0.5980\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0835 - acc: 0.9783\n",
      "Epoch 00021: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 932us/sample - loss: 0.0835 - acc: 0.9783 - val_loss: 2.4986 - val_acc: 0.5984\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9792\n",
      "Epoch 00022: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 923us/sample - loss: 0.0817 - acc: 0.9792 - val_loss: 2.4953 - val_acc: 0.5942\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0787 - acc: 0.9807\n",
      "Epoch 00023: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 937us/sample - loss: 0.0787 - acc: 0.9807 - val_loss: 2.4559 - val_acc: 0.6035\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9810\n",
      "Epoch 00024: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 930us/sample - loss: 0.0770 - acc: 0.9810 - val_loss: 2.5159 - val_acc: 0.6014\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9821\n",
      "Epoch 00025: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 916us/sample - loss: 0.0732 - acc: 0.9821 - val_loss: 2.5071 - val_acc: 0.5980\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9825\n",
      "Epoch 00026: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 34s 914us/sample - loss: 0.0707 - acc: 0.9825 - val_loss: 2.5222 - val_acc: 0.6021\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9824\n",
      "Epoch 00027: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 938us/sample - loss: 0.0697 - acc: 0.9824 - val_loss: 2.5557 - val_acc: 0.6063\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9826\n",
      "Epoch 00028: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 945us/sample - loss: 0.0690 - acc: 0.9826 - val_loss: 2.5582 - val_acc: 0.6031\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9848\n",
      "Epoch 00029: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 958us/sample - loss: 0.0616 - acc: 0.9848 - val_loss: 2.6144 - val_acc: 0.5975\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0631 - acc: 0.9851\n",
      "Epoch 00030: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 959us/sample - loss: 0.0631 - acc: 0.9851 - val_loss: 2.6090 - val_acc: 0.6031\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9855\n",
      "Epoch 00031: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 36s 968us/sample - loss: 0.0620 - acc: 0.9855 - val_loss: 2.6284 - val_acc: 0.6031\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0565 - acc: 0.9866\n",
      "Epoch 00032: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 961us/sample - loss: 0.0565 - acc: 0.9866 - val_loss: 2.6889 - val_acc: 0.6014\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9880\n",
      "Epoch 00033: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 36s 966us/sample - loss: 0.0542 - acc: 0.9880 - val_loss: 2.6309 - val_acc: 0.6063\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9869\n",
      "Epoch 00034: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 963us/sample - loss: 0.0553 - acc: 0.9869 - val_loss: 2.5686 - val_acc: 0.6131\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9892\n",
      "Epoch 00035: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 36s 965us/sample - loss: 0.0483 - acc: 0.9892 - val_loss: 2.6900 - val_acc: 0.6042\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9862\n",
      "Epoch 00036: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 961us/sample - loss: 0.0573 - acc: 0.9862 - val_loss: 2.7864 - val_acc: 0.5959\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9873\n",
      "Epoch 00037: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 36s 965us/sample - loss: 0.0545 - acc: 0.9873 - val_loss: 2.6330 - val_acc: 0.6194\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0524 - acc: 0.9885\n",
      "Epoch 00038: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 962us/sample - loss: 0.0524 - acc: 0.9885 - val_loss: 2.6362 - val_acc: 0.6138\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9889\n",
      "Epoch 00039: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 960us/sample - loss: 0.0481 - acc: 0.9889 - val_loss: 2.7766 - val_acc: 0.6049\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9877\n",
      "Epoch 00040: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 961us/sample - loss: 0.0512 - acc: 0.9877 - val_loss: 2.7009 - val_acc: 0.6017\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9894\n",
      "Epoch 00041: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 36s 965us/sample - loss: 0.0467 - acc: 0.9894 - val_loss: 2.7219 - val_acc: 0.6077\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9904\n",
      "Epoch 00042: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 960us/sample - loss: 0.0447 - acc: 0.9904 - val_loss: 2.6697 - val_acc: 0.6177\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9880\n",
      "Epoch 00043: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 964us/sample - loss: 0.0504 - acc: 0.9880 - val_loss: 2.7116 - val_acc: 0.6161\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9908\n",
      "Epoch 00044: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 957us/sample - loss: 0.0431 - acc: 0.9908 - val_loss: 2.6761 - val_acc: 0.6108\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9908\n",
      "Epoch 00045: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 963us/sample - loss: 0.0424 - acc: 0.9908 - val_loss: 2.6746 - val_acc: 0.6198\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9915\n",
      "Epoch 00046: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 36s 965us/sample - loss: 0.0411 - acc: 0.9915 - val_loss: 2.7663 - val_acc: 0.6171\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9905\n",
      "Epoch 00047: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 36s 966us/sample - loss: 0.0435 - acc: 0.9905 - val_loss: 2.6655 - val_acc: 0.6177\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9904\n",
      "Epoch 00048: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 960us/sample - loss: 0.0463 - acc: 0.9904 - val_loss: 2.7362 - val_acc: 0.6143\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9919\n",
      "Epoch 00049: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 965us/sample - loss: 0.0402 - acc: 0.9919 - val_loss: 2.6869 - val_acc: 0.6271\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9914\n",
      "Epoch 00050: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 961us/sample - loss: 0.0411 - acc: 0.9914 - val_loss: 2.7072 - val_acc: 0.6196\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9926\n",
      "Epoch 00051: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 36s 969us/sample - loss: 0.0394 - acc: 0.9926 - val_loss: 2.8283 - val_acc: 0.6124\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9918\n",
      "Epoch 00052: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 959us/sample - loss: 0.0406 - acc: 0.9918 - val_loss: 2.7871 - val_acc: 0.6140\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9906\n",
      "Epoch 00053: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 36s 967us/sample - loss: 0.0435 - acc: 0.9906 - val_loss: 2.8114 - val_acc: 0.6164\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9917\n",
      "Epoch 00054: val_loss did not improve from 1.30582\n",
      "36805/36805 [==============================] - 35s 961us/sample - loss: 0.0407 - acc: 0.9917 - val_loss: 2.7870 - val_acc: 0.6094\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd8VFXawPHfmZKZ9IQUwIQQFJROqOKi4uqKCi4rKqJrwQbuq6vr2sCyiu7rrm13XdaKFVdX115ZWQtFfVEpAiKgdEho6b1MOe8fZzKZQBKGkMkkmef7+dzPnXLn3udOMve599xTlNYaIYQQAsAS7gCEEEJ0HJIUhBBC+ElSEEII4SdJQQghhJ8kBSGEEH6SFIQQQvhJUhBCCOEnSUEIIYSfJAUhhBB+tnAHcLhSU1N1dnZ2uMMQQohOZeXKlQVa67RDLdfpkkJ2djYrVqwIdxhCCNGpKKV2BLOcFB8JIYTwk6QghBDCT5KCEEIIv053T6EpLpeL3Nxcampqwh1Kp+V0OsnMzMRut4c7FCFEGHWJpJCbm0t8fDzZ2dkopcIdTqejtaawsJDc3Fz69OkT7nCEEGHUJYqPampqSElJkYTQSkopUlJS5EpLCNE1kgIgCeEIyfcnhIAulBSEEKJDqq2FJ56AzZvDHUlQJCm0gZKSEp544olWfXbixImUlJQEvfycOXN45JFHWrUtIUQY3HsvXHcd9O8PV18N27c3v6zWsHYtfPcdeL3tFmIgSQptoKWk4Ha7W/zsggULSEpKCkVYQohwW74cHnwQLrzQJIaXX4Z+/eA3v4Fdu8wyNTXwn//AtddC794wbBiMGAGZmTBzJnzwAVRVtVvIkhTawOzZs9myZQs5OTnceuutLF68mJNOOonJkyczcOBAAM455xxGjhzJoEGDmDdvnv+z2dnZFBQUsH37dgYMGMCMGTMYNGgQEyZMoLq6usXtrl69mrFjxzJ06FCmTJlCcXExAHPnzmXgwIEMHTqUCy+8EIAlS5aQk5NDTk4Ow4cPp7y8PETfhui08vPh6afB5Qp3JF1DTQ1Mnw5HHQVPPgl//7spQpo5E55/Hvr2hVNPhZQUmDgR5s+HkSPh2WfN43Hj4LXXYPJks8wvf2kSRIh1iSqpgTZtupGKitVtus64uBz69Xu02fcfeOAB1q1bx+rVZruLFy9m1apVrFu3zl/F8/nnn6dbt25UV1czevRozjvvPFJSUg6IfROvvvoqzzzzDBdccAFvvfUWl1xySbPbveyyy/jHP/7B+PHjufvuu7n33nt59NFHeeCBB9i2bRsOh8NfNPXII4/w+OOPM27cOCoqKnA6nUf6tYiupLraHHS++QbcbnNW2xpFRXDppXDllXDeeW0bY1uprYWoKAh15Yo5c2DDBvj4Y6gvDcjMhMcfh1mz4P774csv4fLL4eyz4ec/h8Df5WWXQV0dLFliksEHH8D69ebvFEJypRAiY8aMaVTnf+7cuQwbNoyxY8eya9cuNm3adNBn+vTpQ05ODgAjR45kewtlj6WlpZSUlDB+/HgApk+fztKlSwEYOnQoF198MS+//DI2m8n748aN46abbmLu3LmUlJT4XxcCreGqq0xC6NMH/vhHqKxs3brmzIEFC+CCC+C559o0zDaxZYvZx/PPD22Z/TffwMMPm+/1jDMOfj8ry1yV/fCDSRJnndU4IdSLioLTT4e5c2HrVrjpptDF7NPljgwtndG3p9jYWP/jxYsX8+mnn7Js2TJiYmI45ZRTmmwT4HA4/I+tVushi4+a89FHH7F06VI++OAD7r//fr7//ntmz57NpEmTWLBgAePGjWPhwoX079+/VesXXcwf/wivvgp//jOcdBKceKI5CN1+++GtZ/16U8vmiitgzx5zU7WkBG6+OTRxH66CAnPwLSqCt9+G++4zSayt1dSYs/+MDPjLX9puvUpBO/Q4IFcKbSA+Pr7FMvrS0lKSk5OJiYlh48aNfP3110e8zcTERJKTk/niiy8A+Oc//8n48ePxer3s2rWLn//85zz44IOUlpZSUVHBli1bGDJkCLNmzWL06NFs3LjxiGMQXcDrr8M995iiilmzTDn2pEnw0EPgu0cVFK3hxhshPt589r33zNXCLbfAXXeZ98OpqsoUu+zaBZ99Zsr6773XxNkcrU3SyMoy5fzBXlncfTds3Gg+k5jYJuG3J0kKbSAlJYVx48YxePBgbr311oPeP/PMM3G73QwYMIDZs2czduzYNtnu/PnzufXWWxk6dCirV6/m7rvvxuPxcMkllzBkyBCGDx/ODTfcQFJSEo8++iiDBw9m6NCh2O12zjrrrDaJQXRi335rDo4nngjz5jWUsd9/vznDf+ih4Nf14YfwySfmIJqaaoo9/vUvc7Vw//1w/fUNB9WSEnj3XbjhBhg82Nxc/fLLQ29Da/jpJ1POfjg8Hrj4YlOk88orJvE99RSMHg2XXGKucA5UV9eQOCwWmDHDfG71Ie5XLltmrg5mzoQJEw4vzo5Ca92pppEjR+oDrV+//qDXxOGT7zGC7NypdY8eWvfpo/X+/Qe/f9FFWkdHa71796HXVVOjdd++Wvfvr3VdXeP3vF6tb71Va9D61FO1HjVKa4vFPI+J0XrCBK179zbPr71W69LSprexeLHWJ55oluvZU+v//V+t8/MPHZvXq/V115nPzZ3b+L1du7ROT9e6Xz+ti4sbXi8u1vrnPzef+eMftfZ4tH7pJbOsxaL1DTdoXVLSsPyOHVq/+KLWl1+udWqq1llZze9HGAErdBDH2LAf5A93kqQQOvI9dgLr12t9883moN5a1dVaDx+udUKC1uvWNb3Mpk1a22zmQH0oDz9sDiUff9z0+16v1n/+s9ZJSVqfdJLW99yj9dKlWtfWmvfLy7X+3e+0VkrrzEytP/yw4bPffKP16aeb9R91lNb336/1GWeY506n1jNmNL8PWmv90ENm2Vtuafr9pUvNfp51ltZut9bbt2s9cKDWdrvW//xn42WLisz3oZRJqJdeapKquYbROiVF63PP1XrVqkN/Z2EgSUEcNvkeO7j5883ZNZgD7BtvtG49t91m1hF48G3Kb35jDphbtjS/zN69WsfHa3322a2LJdCyZVoPGmRiu/BCrSdPNo9TU7X+y1+0rqpqWPaHH7SeOdMkBtD6hBNMDFOmaD11qta//rXW06aZ96ZNM2f7zXniCbPc9OnmYJ+YqPXnnze//PLlZnspKWZ7f/+71mvXtryNDkCSgjhs8j12UBUVpmgCtB4/XusvvtB6zBjz/MorzZl2sJYtM0UgM2Ycetm8PFOEdMklzS9z1VXmrPrHH4OPoSW1tVrfe69ZZ2KiKSYqK2t++fx8rf/0J3OQHjFC6yFDTDFW376mWGrqVFO81RKvV+urrzbfZ1ZWy1cenZgkBXHY5HvsgNatM8UZSmn9hz9o7XKZ1+vqtL7zTvN6v37m7PVQqqvNAfNwyrxvu81sY+3ag99budK8d/PNwe9PsPLz27dcvqZG68ceC+4eSicVbFJQZtnOY9SoUXrFihWNXtuwYQMDBgwIU0Rdh3yPHUh+PrzxhqnSmZBg+sz5xS8OXm7JElODZu9eU8vnlltMbZmm3HabaVD13/+aBlHBKCqCo4+G9HTT6KuqqmHas8fUMtq0qVNWvYw0SqmVWutRh1quyzVeE6LD2r/fVL1MSIDk5IYpIQFyc+GLLxqmDRvMZ0491VSj7NGj6XWOH2961Zw507Qz+OILeOkls95AX3/dUFUy2IQA0K0bPPKIacxWWgoxMdCzp5kff7xpsSsJoUuRK4UwiYuLo6KiIujX20Nn/B47jbfegmuugcLClpdLTDT14U86yUwnnND8mX8grU13CTfdZFrSvvmmqf8Ppl+j4cPN/PvvTRISEUeuFIToCEpLTcOtf/7THKTfess0EisuNlNJiZmnpZkkMHgwWK2Hvx2l4Le/hVGjTEvin/0M/vEP0+jq7rvhxx9N4zJJCOJQgrnx0JGmjnijedasWfqxxx7zP7/nnnv0ww8/rMvLy/Wpp56qhw8frgcPHqzfffdd/zKxsbFNrqv+da/Xq2+55RY9aNAgPXjwYP3aa69prbXevXu3Pumkk/SwYcP0oEGD9NKlS7Xb7dbTp0/3L/vXv/61VfsR7u+xy/n8c3NT12rV+u67D27YFSr5+aZRGGg9aZKpbXTNNe2zbdFhEeSN5q53pXDjjYduin64cnLg0eY72ps2bRo33ngj1/m6G3799ddZuHAhTqeTd955h4SEBAoKChg7diyTJ08Oajzkt99+m9WrV7NmzRoKCgoYPXo0J598Mv/6178444wzuPPOO/F4PFRVVbF69Wry8vJYt24dwGGN5CaO0I4d5iZvTU3j6auvzJl6v37m8fHHt19Mqammp9I//tF0+paVZW4wCxGErpcUwmD48OHs37+f3bt3k5+fT3JyMr169cLlcnHHHXewdOlSLBYLeXl57Nu3jx7N3TQM8OWXX3LRRRdhtVrp3r0748ePZ/ny5YwePZorr7wSl8vFOeecQ05ODkcffTRbt27l+uuvZ9KkSUzorH2udBYul+lI7YknYNGi5pe79lrTf1BAj7ntxmo1/RCdfba5WRwf3/4xiE4pZElBKdULeAnoDmhgntb67wcscwrwHrDN99LbWuv7jmjDLZzRh9LUqVN588032bt3L9OmTQPglVdeIT8/n5UrV2K328nOzm6yy+zDcfLJJ7N06VI++ugjLr/8cm666SYuu+wy1qxZw8KFC3nqqad4/fXXef7559tit0SgvDx45hnTedyePWboxD/9yQyf6HQ2npKTTS2dcBt1yPuKQjQSyisFN3Cz1nqVUioeWKmU+kRrfWCXhF9orc8OYRztYtq0acyYMYOCggKWLFkCmC6z09PTsdvtLFq0iB07dgS9vpNOOomnn36a6dOnU1RUxNKlS3n44YfZsWMHmZmZzJgxg9raWlatWsXEiROJiorivPPO47jjjmtxtDbhU1dnxsWNjTWjYWVmQlxcw/sul+n+eM0aUxy5ahUsXWp6+jzzTJMYzjqrdTeFhejAQpYUtNZ7gD2+x+VKqQ1ABtBEP7Wd36BBgygvLycjI4OevjPEiy++mF/+8pcMGTKEUaNGHdagNlOmTGHZsmUMGzYMpRQPPfQQPXr0YP78+Tz88MPY7Xbi4uJ46aWXyMvL44orrsDr65r4z3/+c0j2sUPJywObzdSXj4k5vIPzli1mIPUDqjaTmGiSg91uulOu76LZ4YAhQ8xgMddcYxpzCdFFtUs7BaVUNrAUGKy1Lgt4/RTgLSAX2A3corX+oaV1dZV2Ch1Rp/keZ8+GBx9s/JrDYc76hw0zI4b94hdNj8H7+uummqbFYur1Z2SYhmOBU02NSQI5OWZ9xx1nEpAQnViHaaeglIrDHPhvDEwIPquA3lrrCqXUROBdoF8T65gJzATIysoKccSiQ/u//zM3b88/37T2raw0XS5UVkJ5Obz/vhnc5PjjzYhfkyaZ5FBdDb//vRkXd+xYM/xkdna490aIDiekVwpKKTvwIbBQa/3XIJbfDozSWhc0t4xcKYROu3yPN9xgin5ef/3wy+NraszZe02NaZnbVI2a2lp48UV44AHYvt0sf911ppuG7783/f/87/+2y1i3QnQkwV4phGw4TmUq4z8HbGguISileviWQyk1xhfPIfoBEJ3WqlWm7v7bb7eulticOaZl7jPPNF/F0uEw5f4//WSSQ1WVKS7as8fU3X/wQUkIQrQglMVH44BLge+VUvWtye4AsgC01k8B5wP/o5RyA9XAhbo9bnKI8LjrLlNV8/jj4Y47TC2eQYOC++zy5aYB1lVXBdehm91uxti95BLTK2hOTseoIipEBxfK2kdfAi023dVaPwY8FqoYRAfyxRemCuiDD8Lll5s+fi691PTeGRXV8mdra+HKK81B/S9/ObztWq2m6qgQIighKz4Swk9rc2XQo4fptC093dzw/e47U75/KH/6E6xbZz4j3TQLEVKSFNpASUkJTzzxRKs+O3HixK7fV9HChWYcgT/8wbQpAJgyBS67zBzwv/22+c+uXm2WufRSU5NICBFSkhTaQEtJwe12t/jZBQsWkJSUFIqwOgav11wl9OkDV1/d+L2//x2OOsokh+rqgz+7bZspNkpJCVv3JUJEGkkKbWD27Nls2bKFnJwcbr31VhYvXsxJJ53E5MmTGThwIADnnHMOI0eOZNCgQcybN8//2ezsbAoKCti+fTsDBgxgxowZDBo0iAkTJlDdxIHygw8+4Pjjj2f48OH84he/YN++fQBUVFRwxRVXMGTIEIYOHcpbb70FwMcff8yIESMYNmwYp512Wjt8Gwd4+21TTHTvvQffO0hKghdeMDWKbr/dFDOtWWNqGQ0bZloOr1ljio26dWv/2IWIQF1u5LUw9JzN9u3bOfvss/1dVy9evJhJkyaxbt06+vTpA0BRURHdunWjurqa0aNHs2TJElJSUsjOzmbFihVUVFTQt29fVqxYQU5ODhdccAGTJ08+qB+j4uJikpKSUErx7LPPsmHDBv7yl78wa9YsamtredQXaHFxMW63mxEjRrB06VL69Onjj6E5bd5Owe02LYMtFjNkZHPtEm64wVRVzc42bQuUMqOPTZliJt93KIRovQ7TojlSjRkzxp8QAObOncs777wDwK5du9i0aRMpKSmNPtOnTx9ycnIAGDlyJNu3bz9ovbm5uUybNo09e/ZQV1fn38ann37Ka6+95l8uOTmZDz74gJNPPtm/TEsJISReftl0Kvf22y03VHvgAfjhB9PG4I47YPJk6N69/eIUQvh1uaTQUYqeYwP60F+8eDGffvopy5YtIyYmhlNOOaXJLrQdDof/sdVqbbL46Prrr+emm25i8uTJLF68mDlz5oQk/qBoDStXwocfmhvI3bubGkbdu5v7AHPmmK6bzzmn5fXExMBnn7VLyEKIlnW5pBAO8fHxlJeXN/t+aWkpycnJxMTEsHHjRr7++utWb6u0tJSMjAwA5s+f73/99NNP5/HHH29UfDR27FiuvfZatm3bFlTxUdB27zZXAfPnm95EW/LMM013TCeE6JDkRnMbSElJYdy4cQwePJhbb731oPfPPPNM3G43AwYMYPbs2YwdO7bV25ozZw5Tp05l5MiRpKam+l+/6667KC4uZvDgwQwbNoxFixaRlpbGvHnzOPfccxk2bJh/8J9W+/hj0wq5Vy+YNcvcKH76aTPwfHk5bN5sqp6++abpgfSFF0xvpUKITqPL3WgWrdfi97hqFYwebbqanj7dVCPtd1CHtkKIDkpuNIu243bDzJmQlmaqiCYnhzsiIUSISFIQh/bYY+aG8quvSkIQoouTewqiZTt3mt5NzzoLjvSehBCiw5OkIJqntenATmt44gmpRSREBJDiI9G8t9+GDz4w4xjI0JVCRAS5UhBNKy2F6683fXzceGO4oxFCtBO5UgiTuLg4Kioqwh1G8+64A/btg/feA5v8mwgRKeRKQRxs2TJ48klzP2H06HBHI4RoR5IU2sDs2bN5/PHH/c/nzJnDI488QkVFBaeddhojRoxgyJAhvPfee4dcV3NdbDfVBXZz3WW3mtam+umECZCZGdyoaEKILqXLtWi+8eMbWb23bfvOzumRw6NnNt/T3nfffceNN97IkiVLABg4cCALFy6kZ8+eVFVVkZCQQEFBAWPHjmXTpk0opZotPmqqi22v19tkF9hNdZed3Np2BNXVbPj6awaceqpJCk8/LTeXhehCpEVzOxo+fDj79+9n9+7d5Ofnk5ycTK9evXC5XNxxxx0sXboUi8VCXl4e+/bto0ePHs2uq6kutvPz85vsArup7rIPm9cLe/fCnj3gcsFLL8Ell0j1UyEiVJdLCi2d0YfS1KlTefPNN9m7d6+/47lXXnmF/Px8Vq5cid1uJzs7u8kus+sF28V2m6muhq1bzbxbNzOewYQJodueEKLDk3sKbWTatGm89tprvPnmm0ydOhUw3Vynp6djt9tZtGgRO3bsaHEdzXWxPXbsWJYuXcq2bdsAU8QEDd1l1ysuLg4+4Npa+Oknc3XQt68Z+rKlgXCEEBFBkkIbGTRoEOXl5WRkZNCzZ08ALr74YlasWMGQIUN46aWX6N+/f4vraK6L7ea6wG6qu+yguFwmIXi9cOyxpgtsIYSgC95oFofgdpuEUFNjEkJcnP8t+R6F6LqCvdEsVwqRxOMxA+FUV8MxxzRKCEIIASFMCkqpXkqpRUqp9UqpH5RSv2tiGaWUmquU2qyUWquUGhGqeCKe12tuKldUQJ8+kJgY7oiEEB1QKGsfuYGbtdarlFLxwEql1Cda68BBfc8C+vmm44EnffPDprVGSTXKpmkN27eb/ox69zY1jQ5apHMVIwohQiNkVwpa6z1a61W+x+XABiDjgMV+Bbykja+BJKVUz8PdltPppLCwsMUDm8tVQkXFWrze2sNdfee3ezcUFZmhNNPSDnpba01hYSFOpzMMwQkhOpJ2aaeglMoGhgPfHPBWBrAr4Hmu77U9h7P+zMxMcnNzyc/Pb3YZr7eGurp9REV5sFgi6OBXWQkFBeb+QUmJmZrgdDrJzMxs5+CEEB1NyJOCUioOeAu4UWtd1sp1zARmAmRlZR30vt1u97f2bU519Ta++WYExx33LD17XtWaMDqfFSvgpJNg1Cj49FPTOE0IIVoQ0tpHSik7JiG8orV+u4lF8oBeAc8zfa81orWep7UepbUeldZE8UcwHI5egJXq6m2t+nyns2cPnHMOpKfDW29JQhBCBCWUtY8U8BywQWv912YWex+4zFcLaSxQqrU+rKKjYFksNpzOLGpqtoZi9R1LdbVJCCUl8P77JjEIIUQQQll8NA64FPheKVXfbekdQBaA1vopYAEwEdgMVAFXhDAenM4+1NR08SsFrWHGDPj2WzOc5rBh4Y5ICNGJhCwpaK2/BFqsI6pNdaHrQhXDgaKjj6ag4P322lx4PPggvPKKGQthypRwRyOE6GQiqkWz09kHl2s/Hk9luEMJjZdfhttvhwsvNMNpCiHEYYqwpHA0QNe82bxgAVxxBZx6Krz4ooyHIIRolYhKCtHRptpql7uvsGwZnH8+DB0K77wjNY2EEK0WUUmh/kqhS9VA+uEHmDTJtFb+z38gISHcEQkhOrGISgp2eyoWS2zXKT7auRPOOAOcTvjvf6XqqRDiiHW54ThbopQiOvrornGlUFBghs6srISlS03Pp0IIcYQiKilAfVuFTp4UKipg4kTYsQM++QSGDAl3REKILiKiio/AtFWort7aebuKrq2Fc8+FVavg9dfhxBPDHZEQoguJuKTgdPbB663C5Wq+R9UOy+OB6dPN1cFzz8EvfxnuiIQQXUwEJoX6tgqdrAhJa/jd7+Df/4aHHzbJQQgh2ljEJYVO21bhj3+Exx+HW2+FW24JdzRCiC4q4pKC01mfFDrRlcKTT8I998Dll5u+jYQQIkQiLilYrTHY7d07T1uFDz6A666Ds8+GZ56R7iuEECEVcUkB6DxtFXbtMvcOhg839xJsEVeDWAjRziIyKXSKcRXcbvj1r8Hlgtdeg5iYcEckhIgAEZkUzJXCTrxeV7hDad5998GXX8JTT0G/fuGORggRISIyKZibzV5qa3eFO5SmLVpkBsm5/HK4+OJwRyOEiCARmhQ6cFuF/HyTCI49Fv7xj3BHI4SIMBF557LDtlXwes2N5aIiM2hOXFy4IxJCRJiITAoORyZK2TpeDaS//c2MifDYY5CTE+5ohBARKCKLj5Sy4nRmd6y2Chs2wOzZMGUKXHttuKMRQkSoiEwK0AG70L71VlPt9OmnpYGaECJsIjgpHN1x7il8+il89BHcdRekpYU7GiFEBIvYpBAd3QeXqwC3uzy8gXg8cPPNkJ0N118f3liEEBEvspLCjz/6H9ZXSw371cL8+bB2renozukMbyxCiIgXOUlh/nzo3x9WrwYaeksNa1uFigq480444QSYOjV8cQghhE/kJIVf/QoSE+HeewHT1QWE+Urh4Ydh717461/l5rIQokMIWVJQSj2vlNqvlFrXzPunKKVKlVKrfdPdoYoFgKQkuOkmePddWLkSmy0ZqzUhfEkhN9ckhWnTYOzY8MQghBAHCCopKKV+p5RKUMZzSqlVSqkJh/jYi8CZh1jmC611jm+6L5hYjsjvfgfJyTBnDkopoqOPDl/x0Z13mhbMDzwQnu0LIUQTgr1SuFJrXQZMAJKBS4EWj2Za66VA0ZGF18YSE01Nnw8/hOXLw9eF9sqV8NJLJkllZ7f/9oUQohnBdnNRX+A9Efin1voHpdqkEPwEpdQaYDdwi9b6hyY3rtRMYCZAVlbWkW3xhhtMGf499+CcO5Cioo/RWtM2u3OA/ftNH0b795spP99Ma9ZAairccUfbb1MIIY5AsElhpVLqv0Af4HalVDzgPcJtrwJ6a60rlFITgXeBJgcO0FrPA+YBjBo1Sh/RVuPj4bbbYPZsEtcPIDehmrq6fTgcPY5otQcpK4OTT26oBhsdbRqmpafDsGHw+9+bKxchhOhAgi0+ugqYDYzWWlcBduCKI9mw1rpMa13he7wAsCulUo9knUG77jpISyPx0cUAbd/dhdZw1VWwebMpqqqogKoq2LEDli83Vw+nn9622xRCiDYQbFI4AfhRa12ilLoEuAsoPZINK6V61BdBKaXG+GIpPJJ1Bi0uDm67jahFq0j8PgTVUv/2N3jzTfjzn2HSJIiNbdv1CyFEiASbFJ4EqpRSw4CbgS3ASy19QCn1KrAMOE4plauUukop9Rul1G98i5wPrPPdU5gLXKi1PrKiocNx7bXo7t3JfqGNG7B98YUpnpoyBW65pe3WK4QQ7SDYewpurbVWSv0KeExr/ZxS6qqWPqC1vugQ7z8GPBbk9tteTAxq9mySf/97ypYug+w2WOfevXDBBXD00fDCC9IgTQjR6QR7pVCulLodUxX1I6WUBXNfoXO75hpcqVGkPvilqRV0JFwu0xCttBTeektuIgshOqVgk8I0oBbTXmEvkAk8HLKo2kt0NPvuGEv0pnL0kCGm++rWuuMOWLoUnnkGhgxpuxiDnqzvAAAgAElEQVSFEKIdBZUUfIngFSBRKXU2UKO1bvGeQmdhmXYxK58Cb2oCnH02/M//QGXl4a3kmWfgkUfMiGkXXxyaQIUQoh0E283FBcC3wFTgAuAbpdT5oQysvaSm/orKoxU737zA3Bh++mkYPhy++Sa4FTz8MMycCWeeaRrFCSFEJxZs8dGdmDYK07XWlwFjgD+ELqz2ExXVncTEEyko/8Ac4D//HGprYdw4mDXL3CNoitZw++2mptG0afDee+BwtG/wQgjRxoJNChat9f6A54WH8dkOLzV1CpWVa6mu3gKnnGIGvZk+3SSJY46BuXOhrq7hAx4P/OY3pjO7a66BV16BqKiwxS+EEG0l2AP7x0qphUqpy5VSlwMfAQtCF1b7Sk2dAkB+/jvmhcREeO4503FdTo7puG7gQHjjDXMV8etfw7x55krhySfBag1j9EII0XZUsO3FlFLnAeN8T7/QWr8TsqhaMGrUKL1ixYo2X++KFSOwWJyMGPF/jd/QGhYuhFtvhXXrICUFCgvNVYQ0ThNCdBJKqZVa61GHWi7oIiCt9Vta65t8U1gSQiilpp5LWdkyamv3NH5DKXMTefVqeP55yMgwVxGSEIQQXVCLSUEpVa6UKmtiKldKlbVXkO0hLc0UIRUUvNv0AlYrXHGF6fb6yivbMTIhhGg/LSYFrXW81jqhiSlea53QXkG2h5iYgURHH0tBQZe7CBJCiKB1mRpER0opRWrqFEpKFuFydawB44QQor1IUgiQlnYuWrspLPww3KEIIURYSFIIEB8/CocjU4qQhBARS5JCAKUspKaeQ1HRx3g8h9n/kRBCdAGSFA6QmnouXm8NRUULwx2KEEK0O0kKB0hMPAmbLYX8/LfDHYoQQrQ7SQoHsFhspKZOprDwQ7zeukN/QAghuhBJCk1ITZ2Cx1NKScmicIcihBDtSpJCE5KTT8diiWX//jfCHYoQQrQrSQpNsFqdpKdfyP79r+JyFYc7HCGEaDeSFJqRmXk9Xm8Ve/c+H+5QhBCi3UhSaEZc3DASE8eTl/cYWnvCHY4QQrQLSQotyMy8gZqa7dLthRAiYkhSaEFKymQcjl7k5s4NdyhCCNEuJCm0wGKxkZFxHSUln1NRsS7c4QghRMiFLCkopZ5XSu1XSjV5NFXGXKXUZqXUWqXUiFDFciR69rwai8VJXt4/wh2KEEKEXCivFF4Ezmzh/bOAfr5pJvBkCGNpNbs9he7dL2Hfvn/KOAtCiC4vZElBa70UaOko+ivgJW18DSQppXqGKp4jkZFxPV5vNXv2PBfuUIQQIqRsYdx2BrAr4Hmu77U94QmneXFxQ0lKOoW8vMfIzPw9Fks4vzYhDK8XXC5wu83c6wWbzUxWq5lbLOb12loz1dSYeV0d2O0QEwPR0WZua+LfWmvweMw23O6DH3s8ZpkDp/rt18/rY3G5zLYD5y5Xw7oCJ5sNHA5wOhvmUVHmc9XVDVP9PjVFa7P/Ho+Z1z9WqiG+wFiVavhs/WOtG77j+sntNuuyWMxygXOvt+E7CvyuLJaGyWptmNd/P4GTUk1/58cdB0OHtv3/UqBOcXRTSs3EFDGRlZUVlhgyMm7ghx/OpbDwA9LSpoQlhkjg9UJFBZSWQkkJlJWZH31dXcOBrba28YEk8Ed/4I+3/gfc3MGrfh2BB7n6ddUvU/+4JfXv18+93sYx1z92uQ6OIXBbgc/r9ytwqo+zfj1tyWYzB97AbXm9bbsNcWRmzeraSSEP6BXwPNP32kG01vOAeQCjRo1q459CcFJSfonDkUVe3twunRTcbigsbDgY15+F1c+rqg6eKisbTxUVDY/r11F/RldT03AWGHiWZLWadZWVtd2BSClzNhx4FnjgFHiWGHh2feAZYP10IK0bXg+cK2XOah0OiI2F5GTz2G5vOo6mzjjr4zvwbNZqNeup37f6ucVy8Jm8y2WWDzzbdjhMbC6X+btUVTXMa2oO/rsc+LcKjCPwe62PGRqfLQcmM7vdbDsqquFx4Prqz56tVrN8/f9d/f9gXZ35THR0w1S/T039faDxeuv/toFXQIFJMPDvGijwuw78vg9M4l5v89/VgVctByb7wMnrNds58G+RlnZkv4lghDMpvA/8Vin1GnA8UKq17nBFR/Xqq6du3TqLioq1xMWFOF23sZISyM2FvLyGeV4e7NkDBQWQn2/mJSWHv2673Rz44uLMvP5xamrDjzZwfuDBq/6HGR0NiYmQlNQwT0ho+NEHTvU/mKYOJvU/XKu17b9HIbq6kCUFpdSrwClAqlIqF7gHsANorZ8CFgATgc1AFXBFqGJpKz17Xs327fexc+eDDBz4SrjDaURr2L0b1q+HLVtg61Yzbdtm5k0d7NPToWdPM8/ONgfx+ikhofFZWP08JqbxFB3ddFm0EKJzCtnPWWt90SHe18B1odp+KNjt3cjIuI5dux4hO/tuYmKOC0scJSWwfDmsXm2SwIYNZl5e3rCMw2EO9EcfDSecAH36QK9ekJFhpp49zTJCCBFIzvEOU69eN5OX9w927PgTAwbMD/n2vF74/nv4+mszffONSQL1evSAAQPgsstg4EDz+NhjzUHfIu3VhRCHSZLCYYqKSueoo/6H3Ny/07v3H4iJ6dvm26iqgs8+g/ffhw8+gH37zOupqTB2LPz613D88TByJHTr1uabF0JEMEkKrdCr1y3s3v0EO3f+if7922a8heJieOcdeO89+OQTUxskIQHOOgsmTYJx40wRUHM1LIQQoi1IUmgFh6MnPXvOJC/vcXr3/gPR0X1atZ7qavjwQ/jXv2DBAlPdrndvuPpqmDwZTj7ZVL8TQoj2IkmhlbKyZrF799Ps3PlnjjtuXtCf0xqWLoUXXoC33zY3h3v2hN/+1hQLjRghVwNCiPCRpNBKDsdR9Ox5NXv2PE3v3nfidPZucXmtTbHQfffBV1+ZoqGpU+Hii2H8eKlTL4ToGKR+yhHIypoFKHbufKDZZbQ2RUMnnABnnAE7dsDjj8PevfDcc3DqqZIQhBAdhySFI+B09qJHjyvZs+c5amp2HfT+p5/CmDHmRvHevfD007B5M1x7rWn0JYQQHY0khSOUlTUb0Oza9ZD/tb17zf2B0083/Qg9+yz89BPMnCkNxoQQHZskhSMUHZ1Njx6Xs3v3M1RX5/HUU9C/P7z1Ftxzj2lpfNVVUotICNE5SFJoA1lZd7BlyyB+9rNa/ud/TA2itWthzhzTZ5AQQnQWUvvoCFVVwX339eGRR74lLq6IZ5/dz5VXpku1UiFEpyRJ4Qh89hlcc43plXT69BrOOy+Hvn1PQ6mXwh2aEEK0ihQftUJhIVx+OfziF6ah2eefw4svxjJw4K/Zt+9lKivXhztEIYRoFUkKh0FrePVV0xPpK6/AHXeYewc//7l5v1evWVitcWzbdnd4AxVCiFaSpBCk4mKYNs1UNe3TB1auhPvvb9zeICoqlczMmygoeIvy8pXhC1YIIVpJkkIQFi0yg2W/8w786U/wf//X/ODZvXrdhM3WjW3b7mrfIIUQog1IUmhBXR3MmgWnnWaGnly2DG6/veVuKWy2BLKyZlFU9DElJV+2X7BCCNEGJCk0Y+NG01/RQw/BjBmwahWMGhXcZzMyfktUVA+2bbsTM+qoEEJ0DpIUmrBihRnhbMcOU2T09NMQGxv8563WGHr3vovS0qUUF38SukCFEKKNSTuFAyxfbvos6tbN3Evo3XKP2M3q2XMGO3c+zNatt5OcfBpKSVeoQnRmWmv2Ve5jY8FGNhZspKKugu6x3ekR14PucWaeEp2C1dK5f+uSFAIEJoTFiyEr6+BltNaoIJorWyxRHH30A2zYcBF5eU+QmXl92wcsws6rvShUUP8ToaS1pqKugvyqfPIr88mvymd/5X7yK/OJskaRmZDpn3rG98Rmafmn79VeVu5eyYJNC1iweQFbi7eS5EyiW3Q3ukV3I9mZTLfobnSP7d5o3ZkJmcQ74oOK2eP1UFJTwp6KPWwv2c6Okh1mXmrmNe4aoqxR2K127BY7dqudKGsUCY4Ekp3JZoo2c4fNwe7y3eSW5bKrbBe7SneRW5ZLeV05TpuTaFs00fZo/9yiLHi1F4/Xg1d78WovGo3T5iTWHktsVKx/7tVefir8iY0FGympKWlxn6zKSmpMKt3jutM9trt/nhqTitYal9eFy+Pyz+s8ddR6as3krqXGXUOtpxa7xU56bDrdY7uTHpvun45NOZZeib2C/r9oDdXZyrxHjRqlV6xY0ebr/fZbmDCh6YSwtXgrH/30ER9t+oglO5bQLbobA1IH0D+1v39+XOpxHBV/FBbVUCKntWbt2rMoK/uK0aPX43T2wuVxsatsFyU1JdS6axv+Kdy1uL1uMhMyOTblWBKdiW2+j4eyr2Ifq/euZvXe1VS5qujbra9/So1JPeSBr8Zdw+7y3eSV5ZFXnkeNu4bRR41mQNqARt/Lgdv875b/8vn2z6l2VRNrjyUuKs4/xdhjUEqZH63W/h+vRVmIi4ojwZFAfFQ88Y54EhwJVLuq2VW2i52lO9lVuoudZTvJLcvF4/XgsDmIskbhsJq50+Ykxh5z0EHAZrFRXltOeV15wzzgcVltmf9xlasKi7L41xNjjzGPo2L9B876ebfobjhsDoqriymqLqKopsj/uNZT2+T3Y1XWRgdFu8WORVkoryunpKaE0ppSM68txe11B/V3tigLPeJ6kBGfQUZCBkfFHcVR8UeRkZCB3WLnk62f8J/N/2F/5X4UiuMzj2dY92GU1pZSVN0Qc2F1YZMHyfioeBKdiQ3fhe97sVvt5nNVhRRWF1JcXYym8fHHYXXQO6k3vRN7E2OPOeggWuuppbSmlOKaYoqri/FoT6PPJzmT6JXQi16JvciMzyTBkUCNu4Zqd7V/Xu2q9v8PWZQFq7L6/z9r3DVUuiqpqKugsq6SSlclWmuOTTm20e+9f2p/EhwJ7Kvcx76Kfeyt2Mu+St+8Yp953ffevsp91LhrGsUZZY3y/02dNicOq8PMbQ4cVge1nlryK01iD9zH2352Gw+e/mBQf+cDKaVWaq0PeWdUkgINCSElxRQZxaUVsWL3Cj7Z8gkfbvqQjQUbAejXrR8TjplARV0FGwo2sLFgI2W1Zf712C12MhMyyUrM8k8WXcWKzXMpcCezzxVDblkuXu09ZEzpsen069aPY1OOpXdib6KsUVgtVqzKitVi/oldHpf5kdYUN5rXeerQWvt/cPV/43hHPImORBKdiSQ5kkh0JqK15vv937Nm3xr2Vuz1b1+hGv1gExwJ9O3Wl1h7LB7tweP1+Od1njr2VuylsLqwyX1JciZxQuYJjOs1jnFZ4/BqLws3L2ThloWs2bcGgNSYVFKiU6ioq/BPB/7gD1d8VDxZiVlkJmRit9pNAnabs7I6Tx017hqqXFX+H3+Vq6rR52PsMf6EEzgPTERxUXF4vB7/5+uniroK/4Gr/m8T+HePtceSHN2QNKLtBw+wobXGoz2NDoourwuv9hIfFU+S0/wNEx2JJDmTSHYmkxabRlpMGumx6f7HtZ5acstyySvLI7cs1382vbt8N3nleewu301RdZF/u8nOZM7seyYT+03kjGPOIC02rdnvuP5EoH699ScE5bXljb6TSlclLo+L5OhkUqJTSIlOMX/zmBS6x3and1JvspOySY9Nb/YEoqnvp9JVSXF1MTXuGnrG9yQuKi6oz7YnrTXV7moUCrvVjlVZg76y9GovJTUl7K/cz/7K/fSI68GxKce2Kg5JCkFatryG06/6Ekf2Ssaet4INJSvZVrINMAf58dnjmdRvEpP6TaJfSr9Gn9Vas6diDxsLNvJT4U/sLN3JjtId7Czdyc7SneSV5eHRHtKj40mzl9O/+8kM7DmePkl9/GeN9WeuDpsDi7Kws3Qnmwo38VPhT/xU9BObCjexp2JPs/FblKXR2WhydDJOm+maNbBYo754of6ssv4M06u9DEofRE6PHHK65zCsxzCGdR9GbFQs20u2s6lwE5uLNpupeDM17hp/Yqqf2yw2esT2ICMhw3/2mRGfgc1i4+vcr/lq11d8tesr1uc3dP9ht9gZlzWOM445gwnHTCCnR85BV1m1nlr/gVqh/Gd2Sik8Xg8VdRXmrN13Fl9WW4bD5iArMYteCb0O+2rLq71Uu6pxeV3ERcUdsojlcNddVltGrbuWJGcSDlvHGlij2lXN7vLdVNRVMCh9UJvuu+gYJCkcgtaadze+y0Xzf09t9A4Ajk4+mpE9RzLqqFGM7DmSMRljgi4fbYrb68btdRNlsbJy5WhcrgLGjFmPzZZwWOtxeVwHnZ17tAe7xU68Iz7oM6umBHuPpC0UVRexbNcyAMZnj++QZ3VCdFXBJoWIPB34seBHbvj4Bv675b9QNphL49/j0ZtOpFt0tzbdjs1i859xHXfcPFatGsu2bXfSr98/Dms9dqsdO/Y2ja1ee94g7RbdjUnHTmq37QkhDl9I2ykopc5USv2olNqslJrdxPuXK6XylVKrfdPVoYynoq6C2Z/OZsiTQ/g692tOqf471me/4+GrJ7d5QjhQQsIYMjJ+S17e45SVfRPSbQkhRGuFLCkoUzH/ceAsYCBwkVJqYBOL/ltrneObng1VPJ9v+5z+j/Xnwa8e5OKhF7N2xk+sfeYGzj3HRvfuodpqY336/C9RUUfx448z8Xpd7bNRIYQ4DKG8UhgDbNZab9Va1wGvAb8K4fZalB6bzlHxR/HVlV/xwq9e4Iv/dKeoCGbObL8YbLYE+vV7jMrKtezc2bpqZUIIEUqhTAoZwK6A57m+1w50nlJqrVLqTaVUk60ylFIzlVIrlFIr8vPzWxXM4PTBfHP1N/ys188AmDcPjjkGTj21VatrtbS0c0hPv4jt2++hqGhh+25cCCEOIdx9H30AZGuthwKfAPObWkhrPU9rPUprPSotrfk604dSf1N1/Xr44gtzlWAJwzdw3HHPEBs7hPXrL6SqanP7ByCEEM0I5SExDwg888/0veantS7UWtc35XwWGBnCePzmzQO73QypGQ5WayyDB78LWFm3bjJud9khPyOEEO0hlElhOdBPKdVHKRUFXAi8H7iAUqpnwNPJwIYQxgNAdTXMnw/nngvp6aHeWvOio7MZNOhNqqp+YsOGS9FBtHIWQohQC1lS0Fq7gd8CCzEH+9e11j8ope5TSk32LXaDUuoHpdQa4Abg8lDFU++NN6CkBK65JtRbOrTk5FPo2/dvFBa+z/bt94Y7HCGEiLwWzePGQX4+/PgjhLljS8C0KP7xx6vYu/cFBg16i7S0c8MdkhCiCwq2RXO4bzS3q3XrzPjKM2d2jIQA5ub3scc+SULCWDZsuIzy8lXhDkkIEcEiKinMmwdRUeG7wdwci8XBoEFvY7ensGbNaZSVfRvukIQQESpikkJVFbz0Epx3HqSmhjuagzkcPRk+fCk2WzfWrPkFpaVfhTskIUQEipik8MYbUFraMW4wN8fp7E1OzhKionqyZs0ZFBcvDndIQogIEzFJ4bzz4JVX4OSTwx1Jy5zOTHJyluB09ub77ydSVPRJuEMSQkSQiEkKcXHw6193nBvMLXE4epCTs5jo6GP5/vtfUlj4UbhDEkJEiIhJCp1NVFQaOTmfExs7mHXrzmHHjvvxBjkGrxBCtJYkhQ7Mbu9GTs5npKWdz7Ztd7F69clUV28Jd1hCiC5MkkIHZ7MlMnDgqwwY8C+qqjawfPkwdu9+hs7W6FAI0TlIUugkune/iFGj1pKQMJaffprJunWTqa3dG+6whBBdjCSFTsTp7MWwYf+lb99HKSr6hG+/7c/OnQ/h8VSHOzQhRBchSaGTUcpCZubvGDXqOxITT2Tr1ll8++2x7NnzIlp7wh2eEKKTk6TQScXGDmDo0A8ZNmwRUVE9+fHHK1ixYjiFhf+R+w1CiFaTpNDJJSefwogR3zBw4L/xeKr4/vuJrFo1ht27n8Xtrgh3eEKITkaSQheglCI9/QLGjFlPv35P4PFU8dNPM1i2rCc//vgbysu/C3eIQohOIuLGU4gEWmvKypaxe/fT5Oe/jtdbQ3z8KLp3v4S0tKk4HEeFO0QhRDsLdjwFSQpdnMtVzL59L7Nnz3NUVq4BFImJJ5OefiFpaecRFZUW7hCFEO1AkoI4SGXlBvbv/zf5+f+mqmojYCU5+eekpJxNt24TiYnpF+4QhRAhIklBNEtrTWXlWl+CeJvq6h8BcDqPISVlIt26nUVi4onYbPFhjlQI0VYkKYigVVdvpajoPxQWLqCkZBFer2kMZ7Ml4XBkHjBl4XT2xunsjcPRC4slKszRCyGCEWxSsLVHMKJji44+moyM68jIuA6Pp5qSkiVUVq6htjaX2tpcamp2UV7+HS7XvgM+qYiKOgqnM5uYmOOIjR1ITMxAYmMH4nD0Qimp3CZEZyNJQTRitUaTknImKSlnHvSe11vrSxI7/FNt7Q6qq7dRWPgRe/c+71/WYoklJqYfUVFHERXVg6ionr55D5Sy4XIV4HLlB8wLcTiOIi5uBPHxI4mNHYLVGt2euy6EQJKCOAwWi4Po6GOIjj6myfddrkIqKzdQVbWeysr1VFdvoq5uLxUVq6mr2wcc3A2HxRKL3Z6K3Z5MWdnX7NnzrO8dK7GxA4mLG47T2QeHIxOns5evCKsXNltC6HZUiAgmSUG0Gbs9haSkE0lKOvGg97T24HIVUle3B6092O1p2O2pja4GtNbU1u6kvHwVFRWrKC9fSXHxp9TV7QEa3/uyWJwo5cBiiUKpKN/cjsXixGKJxmqNCZjH+N83y9Q/jsJqjcVqjcNqjffN47BaY33raTyZz1hQygpYUcqK6gxD+QlxGCQpiHahlJWoqHSiotJbWEb5b2KnpU3xv+711lFXt4eaml3U1u6itjYXl2s/Xm8dWtfh9bp881rfVI3XW0VdXRlebxUeTxVa16G1y7dsw9QGe+ZLEpaAuQWl7NjtaURFdfcVm5m5zZaI1m5fHO5GcZgkY6Mh4diw2RKw2ZKx2bpht5u5zZaExRKNxdK2P1+v14XLVYjFEuVbv1OSXgSSpCA6PIslyp8s2pLWXrzeajyeCtzucjyeCv+kdS1eb41/8niqfQdwD+BFa4/vsQetvQGvewEPXm8dLlc+dXX7/MVnHk9pm8YPFiwWh+9KxoFSNl9c7kZzqzUGu90kZDPvjt2egstV5KtMYJJtXd1emroia7hScvi25/BdnTl8V1oJ2GzxvnkCVmscXq/Ln5Drk7TXW4fVGu9bJsE/N1dmDes0V3IOvN5q3O4iXK6igHkJNluibx+6+5Jtd+z2VF9CtQRczVn8ydVMjSs+mL9/4N+5/oSi2ve82tctvRebLRm7PQW7PRWbrVubJ2QTS+A2te9KNxqLJbpdK22ENCkopc4E/g5YgWe11g8c8L4DeAkYCRQC07TW20MZkxD1lLL4DmqxREV1D/n2PJ4aPJ4y3wHK7pts/mKo+uQSeFD3eMr8B0W3u9h/YKw/iDUkr1q0dgesr+GKw+OpxOXaT13dfioqVlFXtx+PpxSLJdZ3n6YXsbGDcTgyiYrqjtYuPJ7qgw6QXm+dbzsNV2UeTwW1tbvxeMpwu8vweMoBr+/7tWGxxPiL8JSy4fFU4vGU4vEcfmeNSjmw2RJxu0vQuq4VfwHlTxD1V2mtZbUmYrXGHHByYCbz/UdhsZgiSlNkaff9fd0HTC7/d9xi5MpcvfXqdRPZ2Xe3Ou5ghCwpKJOqHwdOB3KB5Uqp97XW6wMWuwoo1lr3VUpdCDwITAtVTEKEk9XqxGp1Nvu+OcO1AHb/a3Z7Ek5nVpvH4vW6fAfIti0e0lrj9Vb7D4TNL+fxXaGV+a7M6g5KOhZLNHZ7N1/RWTffGbNCa43bXYrLtY+6OjO5XIXUX8E1XLF5aXzV1HAgNvE5DroSMmfmTl/xWX0RmgWXqwiXqxC3uxCXy0xebxUNRX1W/70mc6XoCiiyrPNts+GqxXzOhsVi92+r/j6YxRINqICkXO1P0nFxOW3692pKKK8UxgCbtdZbAZRSrwG/AgKTwq+AOb7HbwKPKaWU7mwt6oToZFo6YB8JpRRWa0wQy1mx2RKx2RJbtQ27PQm7PYmYmONaE6ZoQSgLqjKAXQHPc32vNbmM1toNlAIpIYxJCCFECzpFk1Ol1Eyl1Aql1Ir8/PxwhyOEEF1WKJNCHtAr4Hmm77Uml1GmoC0Rc8O5Ea31PK31KK31qLQ06epZCCFCJZRJYTnQTynVRykVBVwIvH/AMu8D032Pzwc+l/sJQggRPiG70ay1diulfgssxNySf15r/YNS6j5ghdb6feA54J9Kqc1AESZxCCGECJOQtlPQWi8AFhzw2t0Bj2uAqaGMQQghRPA6xY1mIYQQ7UOSghBCCL9ON/KaUiof2NHKj6cCBW0YTkcVCfsZCfsIkbGfkbCPEP797K21PmT1zU6XFI6EUmpFMMPRdXaRsJ+RsI8QGfsZCfsInWc/pfhICCGEnyQFIYQQfpGWFOaFO4B2Egn7GQn7CJGxn5Gwj9BJ9jOi7ikIIYRoWaRdKQghhGhBxCQFpdSZSqkflVKblVKzwx1PW1FKPa+U2q+UWhfwWjel1CdKqU2+eXI4YzxSSqleSqlFSqn1SqkflFK/873eZfZTKeVUSn2rlFrj28d7fa/3UUp94/u//bevH7FOTSllVUp9p5T60Pe8K+7jdqXU90qp1UqpFb7XOsX/a0QkhYBR4M4CBgIXKaUGhjeqNvMicOYBr80GPtNa9wM+8z3vzNzAzVrrgcBY4Drf368r7WctcKrWehiQA5yplBqLGY3wb1rrvkAxZrTCzu53wIaA511xHwF+rrXOCaiG2in+XyMiKRAwCpw2g7vWjwLX6Wmtl2I6Ewz0K2C+7/F84Jx2DaqNaa33aK1X+R6XYw4oGXSh/dRG/cDFdt+kgVMxoxJCJ99HAEFFVHQAAAPOSURBVKVUJjAJeNb3XNHF9rEFneL/NVKSQjCjwHUl3bXWe3yP9wKhH5W+nSilsoHhwDd0sf30FausBvYDnwBbgBLfqITQNf5vHwVuA7y+5yl0vX0Ek9D/q5RaqZSa6XutU/y/hrSXVBF+WmutlOoSVcyUUnHAW8CNWuuywEHnu8J+ajPqfI5SKgl4B+gf5pDalFLqbGC/1nqlUuqUcMcTYidqrfOUUunAJ0qpjYFvduT/10i5UghmFLiuZJ9SqieAb74/zPEcMaWUHZMQXtFav+17ucvtJ4DWugRYBJwAJPlGJYTO/387DpislNqOKcI9Ffg7XWsfAdBa5/nm+zEJfgyd5P81UpJCMKPAdSWBI9pNB94LYyxHzFfu/BywQWv914C3usx+KqXSfFcIKKWigdMx904WYUYlhE6+j1rr27XWmVrrbMxv8HOt9cV0oX0EUErFKqXi6x8DE4B1dJL/14hpvKaUmogpz6wfBe7+MIfUJpRSrwKnYHpg3AfcA7wLvA5kYXqUvUBrfeDN6E5DKXUi8AXwPQ1l0Xdg7it0if1USg3F3Hy0Yk7WXtda36eUOhpzVt0N+A64RGtdG75I24av+OgWrfXZXW0fffvzju+pDfiX1vp+pVQKneD/NWKSghBCiEOLlOIjIYQQQZCkIIQQwk+SghBCCD9JCkIIIfwkKQghhPCTpCBEO1JKnVLfO6gQHZEkBSGEEH6SFIRoglLqEt/4BquVUk/7OqurUEr9zTfewWdKqTTfsjlKqa+VUmuVUu/U95OvlOqrlPrUN0bCKqXUMb7Vxyml3lRKbVRKvaICO3ESIswkKQhxAKXUAGAaME5rnQN4gIuBWGCF1noQsATTehzgJWCW1nooptV1/euvAI/7xkj4GVDfQ+Zw4EbM2B5HY/oEEqJDkF5ShTjYacBIYLnvJD4a03mZF/i3b5mXgbeVUolAktZ6ie/1+cAbvr5vMrTW7wBorWsAfOv7Vmud63u+GsgGvgz9bglxaJIUhDiYAuZrrW9v9KJSfzhgudb2ERPYr48H+R2KDkSKj4Q42GfA+b6+8OvH1u2N+b3U9+b5a+BLrXUpUKyUOsn3+qXAEt8IcblKqXN863AopWLadS+EaAU5QxHiAFrr9UqpuzAjZ1kAF3AdUAmM8b23H3PfAUw3yE/5DvpbgSt8r18KPK2Uus+3jqntuBtCtIr0kipEkJRSFVrruHDHIUQoSfGREEIIP7lSEEII4SdXCkIIIfwkKQghhPCTpCCEEMJPkoIQQgg/SQpCCCH8JCmI/98oGAWjYBTAAQBbFn/xzsCYMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 1.3925 - acc: 0.5718\n",
      "Loss: 1.3925352943772962 Accuracy: 0.57175493\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9255 - acc: 0.3836\n",
      "Epoch 00001: val_loss improved from inf to 1.44310, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_4_conv_checkpoint/001-1.4431.hdf5\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 1.9255 - acc: 0.3836 - val_loss: 1.4431 - val_acc: 0.5567\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3137 - acc: 0.5943\n",
      "Epoch 00002: val_loss improved from 1.44310 to 1.22143, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_4_conv_checkpoint/002-1.2214.hdf5\n",
      "36805/36805 [==============================] - 37s 993us/sample - loss: 1.3137 - acc: 0.5943 - val_loss: 1.2214 - val_acc: 0.6224\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0694 - acc: 0.6724\n",
      "Epoch 00003: val_loss improved from 1.22143 to 1.06965, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_4_conv_checkpoint/003-1.0696.hdf5\n",
      "36805/36805 [==============================] - 36s 987us/sample - loss: 1.0694 - acc: 0.6724 - val_loss: 1.0696 - val_acc: 0.6685\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8940 - acc: 0.7314\n",
      "Epoch 00004: val_loss improved from 1.06965 to 1.01159, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_4_conv_checkpoint/004-1.0116.hdf5\n",
      "36805/36805 [==============================] - 37s 999us/sample - loss: 0.8940 - acc: 0.7314 - val_loss: 1.0116 - val_acc: 0.6930\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7438 - acc: 0.7767\n",
      "Epoch 00005: val_loss improved from 1.01159 to 0.95332, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_4_conv_checkpoint/005-0.9533.hdf5\n",
      "36805/36805 [==============================] - 37s 998us/sample - loss: 0.7439 - acc: 0.7767 - val_loss: 0.9533 - val_acc: 0.7060\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6054 - acc: 0.8173\n",
      "Epoch 00006: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 994us/sample - loss: 0.6054 - acc: 0.8173 - val_loss: 0.9954 - val_acc: 0.6974\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4972 - acc: 0.8486\n",
      "Epoch 00007: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 993us/sample - loss: 0.4971 - acc: 0.8486 - val_loss: 0.9919 - val_acc: 0.7142\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4004 - acc: 0.8784\n",
      "Epoch 00008: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 998us/sample - loss: 0.4003 - acc: 0.8784 - val_loss: 1.0047 - val_acc: 0.7198\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3233 - acc: 0.9015\n",
      "Epoch 00009: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 999us/sample - loss: 0.3233 - acc: 0.9015 - val_loss: 1.1419 - val_acc: 0.7067\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2662 - acc: 0.9178\n",
      "Epoch 00010: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 993us/sample - loss: 0.2662 - acc: 0.9178 - val_loss: 1.1205 - val_acc: 0.7156\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9280\n",
      "Epoch 00011: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 993us/sample - loss: 0.2264 - acc: 0.9280 - val_loss: 1.1577 - val_acc: 0.7205\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1985 - acc: 0.9391\n",
      "Epoch 00012: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 995us/sample - loss: 0.1985 - acc: 0.9391 - val_loss: 1.1985 - val_acc: 0.7140\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1706 - acc: 0.9477\n",
      "Epoch 00013: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 995us/sample - loss: 0.1706 - acc: 0.9477 - val_loss: 1.2635 - val_acc: 0.7079\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1489 - acc: 0.9543\n",
      "Epoch 00014: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 996us/sample - loss: 0.1489 - acc: 0.9543 - val_loss: 1.2892 - val_acc: 0.7195\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1406 - acc: 0.9560\n",
      "Epoch 00015: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 996us/sample - loss: 0.1406 - acc: 0.9560 - val_loss: 1.3234 - val_acc: 0.7140\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1250 - acc: 0.9611\n",
      "Epoch 00016: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 997us/sample - loss: 0.1250 - acc: 0.9611 - val_loss: 1.3311 - val_acc: 0.7235\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9651\n",
      "Epoch 00017: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 993us/sample - loss: 0.1141 - acc: 0.9651 - val_loss: 1.2871 - val_acc: 0.7279\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9680\n",
      "Epoch 00018: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 992us/sample - loss: 0.1058 - acc: 0.9680 - val_loss: 1.3828 - val_acc: 0.7219\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9696\n",
      "Epoch 00019: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 993us/sample - loss: 0.1006 - acc: 0.9696 - val_loss: 1.4845 - val_acc: 0.7123\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9682\n",
      "Epoch 00020: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 995us/sample - loss: 0.1012 - acc: 0.9682 - val_loss: 1.4037 - val_acc: 0.7368\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9727\n",
      "Epoch 00021: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 993us/sample - loss: 0.0927 - acc: 0.9727 - val_loss: 1.3430 - val_acc: 0.7270\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9754\n",
      "Epoch 00022: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 993us/sample - loss: 0.0830 - acc: 0.9754 - val_loss: 1.4735 - val_acc: 0.7254\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9765\n",
      "Epoch 00023: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 992us/sample - loss: 0.0780 - acc: 0.9765 - val_loss: 1.3864 - val_acc: 0.7403\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9762\n",
      "Epoch 00024: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 995us/sample - loss: 0.0764 - acc: 0.9763 - val_loss: 1.5420 - val_acc: 0.7240\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9780\n",
      "Epoch 00025: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 992us/sample - loss: 0.0735 - acc: 0.9780 - val_loss: 1.4350 - val_acc: 0.7356\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9787\n",
      "Epoch 00026: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 994us/sample - loss: 0.0745 - acc: 0.9787 - val_loss: 1.4871 - val_acc: 0.7333\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0740 - acc: 0.9782\n",
      "Epoch 00027: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 991us/sample - loss: 0.0740 - acc: 0.9782 - val_loss: 1.4357 - val_acc: 0.7410\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9789\n",
      "Epoch 00028: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 997us/sample - loss: 0.0705 - acc: 0.9789 - val_loss: 1.5112 - val_acc: 0.7417\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9809\n",
      "Epoch 00029: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 993us/sample - loss: 0.0644 - acc: 0.9809 - val_loss: 1.5497 - val_acc: 0.7377\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9815\n",
      "Epoch 00030: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 989us/sample - loss: 0.0629 - acc: 0.9815 - val_loss: 1.4980 - val_acc: 0.7419\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9818\n",
      "Epoch 00031: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 987us/sample - loss: 0.0618 - acc: 0.9818 - val_loss: 1.5109 - val_acc: 0.7365\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9820\n",
      "Epoch 00032: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 985us/sample - loss: 0.0598 - acc: 0.9820 - val_loss: 1.4855 - val_acc: 0.7454\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9830\n",
      "Epoch 00033: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 985us/sample - loss: 0.0577 - acc: 0.9830 - val_loss: 1.4818 - val_acc: 0.7405\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9849\n",
      "Epoch 00034: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 980us/sample - loss: 0.0546 - acc: 0.9849 - val_loss: 1.5636 - val_acc: 0.7466\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0558 - acc: 0.9840\n",
      "Epoch 00035: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 977us/sample - loss: 0.0558 - acc: 0.9841 - val_loss: 1.5043 - val_acc: 0.7424\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9850\n",
      "Epoch 00036: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 985us/sample - loss: 0.0533 - acc: 0.9850 - val_loss: 1.5255 - val_acc: 0.7442\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9837\n",
      "Epoch 00037: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 986us/sample - loss: 0.0552 - acc: 0.9837 - val_loss: 1.5446 - val_acc: 0.7396\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9849\n",
      "Epoch 00038: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 976us/sample - loss: 0.0531 - acc: 0.9849 - val_loss: 1.4837 - val_acc: 0.7491\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9865\n",
      "Epoch 00039: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 981us/sample - loss: 0.0486 - acc: 0.9865 - val_loss: 1.4937 - val_acc: 0.7540\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9875\n",
      "Epoch 00040: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 990us/sample - loss: 0.0472 - acc: 0.9875 - val_loss: 1.5333 - val_acc: 0.7498\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9861\n",
      "Epoch 00041: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 991us/sample - loss: 0.0507 - acc: 0.9861 - val_loss: 1.5984 - val_acc: 0.7454\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9874\n",
      "Epoch 00042: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 991us/sample - loss: 0.0466 - acc: 0.9874 - val_loss: 1.6748 - val_acc: 0.7372\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9849\n",
      "Epoch 00043: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 985us/sample - loss: 0.0530 - acc: 0.9849 - val_loss: 1.5655 - val_acc: 0.7503\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9878\n",
      "Epoch 00044: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 992us/sample - loss: 0.0450 - acc: 0.9878 - val_loss: 1.6410 - val_acc: 0.7349\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9887\n",
      "Epoch 00045: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 37s 992us/sample - loss: 0.0431 - acc: 0.9887 - val_loss: 1.6112 - val_acc: 0.7435\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9876\n",
      "Epoch 00046: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 982us/sample - loss: 0.0455 - acc: 0.9876 - val_loss: 1.5662 - val_acc: 0.7494\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9884\n",
      "Epoch 00047: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 982us/sample - loss: 0.0432 - acc: 0.9884 - val_loss: 1.5969 - val_acc: 0.7587\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9867\n",
      "Epoch 00048: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 981us/sample - loss: 0.0454 - acc: 0.9867 - val_loss: 1.5872 - val_acc: 0.7473\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9888\n",
      "Epoch 00049: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 982us/sample - loss: 0.0425 - acc: 0.9888 - val_loss: 1.5516 - val_acc: 0.7496\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9881\n",
      "Epoch 00050: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 974us/sample - loss: 0.0434 - acc: 0.9881 - val_loss: 1.5228 - val_acc: 0.7508\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9875\n",
      "Epoch 00051: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 976us/sample - loss: 0.0456 - acc: 0.9875 - val_loss: 1.5444 - val_acc: 0.7543\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9900\n",
      "Epoch 00052: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 985us/sample - loss: 0.0392 - acc: 0.9900 - val_loss: 1.6545 - val_acc: 0.7421\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9907\n",
      "Epoch 00053: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 986us/sample - loss: 0.0364 - acc: 0.9907 - val_loss: 1.6451 - val_acc: 0.7459\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9900\n",
      "Epoch 00054: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 979us/sample - loss: 0.0388 - acc: 0.9900 - val_loss: 1.5712 - val_acc: 0.7489\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0384 - acc: 0.9902\n",
      "Epoch 00055: val_loss did not improve from 0.95332\n",
      "36805/36805 [==============================] - 36s 980us/sample - loss: 0.0384 - acc: 0.9902 - val_loss: 1.6853 - val_acc: 0.7407\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 1.0524 - acc: 0.6766\n",
      "Loss: 1.0524171884928908 Accuracy: 0.6766355\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9222 - acc: 0.3773\n",
      "Epoch 00001: val_loss improved from inf to 1.40916, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_5_conv_checkpoint/001-1.4092.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 1.9222 - acc: 0.3772 - val_loss: 1.4092 - val_acc: 0.5521\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2887 - acc: 0.6010\n",
      "Epoch 00002: val_loss improved from 1.40916 to 1.08047, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_5_conv_checkpoint/002-1.0805.hdf5\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 1.2886 - acc: 0.6010 - val_loss: 1.0805 - val_acc: 0.6823\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0465 - acc: 0.6799\n",
      "Epoch 00003: val_loss improved from 1.08047 to 1.06883, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_5_conv_checkpoint/003-1.0688.hdf5\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 1.0464 - acc: 0.6800 - val_loss: 1.0688 - val_acc: 0.6739\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8932 - acc: 0.7298\n",
      "Epoch 00004: val_loss improved from 1.06883 to 0.83485, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_5_conv_checkpoint/004-0.8349.hdf5\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.8931 - acc: 0.7298 - val_loss: 0.8349 - val_acc: 0.7484\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7795 - acc: 0.7641\n",
      "Epoch 00005: val_loss did not improve from 0.83485\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.7795 - acc: 0.7641 - val_loss: 0.9072 - val_acc: 0.7226\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6893 - acc: 0.7898\n",
      "Epoch 00006: val_loss improved from 0.83485 to 0.72964, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_5_conv_checkpoint/006-0.7296.hdf5\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.6892 - acc: 0.7898 - val_loss: 0.7296 - val_acc: 0.7831\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6076 - acc: 0.8191\n",
      "Epoch 00007: val_loss did not improve from 0.72964\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.6077 - acc: 0.8191 - val_loss: 0.7488 - val_acc: 0.7766\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5284 - acc: 0.8426\n",
      "Epoch 00008: val_loss improved from 0.72964 to 0.70416, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_5_conv_checkpoint/008-0.7042.hdf5\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.5284 - acc: 0.8425 - val_loss: 0.7042 - val_acc: 0.7929\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4588 - acc: 0.8610\n",
      "Epoch 00009: val_loss did not improve from 0.70416\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.4587 - acc: 0.8610 - val_loss: 0.7072 - val_acc: 0.7964\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3935 - acc: 0.8810\n",
      "Epoch 00010: val_loss improved from 0.70416 to 0.68283, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_5_conv_checkpoint/010-0.6828.hdf5\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.3935 - acc: 0.8810 - val_loss: 0.6828 - val_acc: 0.8071\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3353 - acc: 0.8986\n",
      "Epoch 00011: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.3353 - acc: 0.8986 - val_loss: 0.6921 - val_acc: 0.8078\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2844 - acc: 0.9117\n",
      "Epoch 00012: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.2843 - acc: 0.9117 - val_loss: 0.7481 - val_acc: 0.8076\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2495 - acc: 0.9231\n",
      "Epoch 00013: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.2495 - acc: 0.9231 - val_loss: 0.7003 - val_acc: 0.8118\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2170 - acc: 0.9333\n",
      "Epoch 00014: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 37s 1ms/sample - loss: 0.2169 - acc: 0.9333 - val_loss: 0.7552 - val_acc: 0.8055\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1858 - acc: 0.9440\n",
      "Epoch 00015: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1858 - acc: 0.9440 - val_loss: 0.7805 - val_acc: 0.8102\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1700 - acc: 0.9471\n",
      "Epoch 00016: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1701 - acc: 0.9471 - val_loss: 0.8180 - val_acc: 0.8067\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9521\n",
      "Epoch 00017: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1535 - acc: 0.9522 - val_loss: 0.8052 - val_acc: 0.8106\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1360 - acc: 0.9579\n",
      "Epoch 00018: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1361 - acc: 0.9579 - val_loss: 0.8406 - val_acc: 0.8127\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1288 - acc: 0.9602\n",
      "Epoch 00019: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1288 - acc: 0.9602 - val_loss: 0.8805 - val_acc: 0.8157\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9641\n",
      "Epoch 00020: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1159 - acc: 0.9641 - val_loss: 0.8813 - val_acc: 0.8141\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9683\n",
      "Epoch 00021: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1053 - acc: 0.9683 - val_loss: 0.8309 - val_acc: 0.8239\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9688\n",
      "Epoch 00022: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1000 - acc: 0.9688 - val_loss: 0.9123 - val_acc: 0.8090\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9695\n",
      "Epoch 00023: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1022 - acc: 0.9695 - val_loss: 0.8824 - val_acc: 0.8167\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9726\n",
      "Epoch 00024: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0916 - acc: 0.9726 - val_loss: 0.8932 - val_acc: 0.8302\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9758\n",
      "Epoch 00025: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0818 - acc: 0.9758 - val_loss: 0.9498 - val_acc: 0.8085\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9757\n",
      "Epoch 00026: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0806 - acc: 0.9757 - val_loss: 0.8775 - val_acc: 0.8251\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9765\n",
      "Epoch 00027: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0816 - acc: 0.9764 - val_loss: 0.9018 - val_acc: 0.8241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9760\n",
      "Epoch 00028: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0788 - acc: 0.9760 - val_loss: 0.9500 - val_acc: 0.8160\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9779\n",
      "Epoch 00029: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0721 - acc: 0.9779 - val_loss: 0.8424 - val_acc: 0.8276\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9788\n",
      "Epoch 00030: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0690 - acc: 0.9788 - val_loss: 0.9109 - val_acc: 0.8132\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9787\n",
      "Epoch 00031: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0703 - acc: 0.9788 - val_loss: 0.9452 - val_acc: 0.8234\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9804\n",
      "Epoch 00032: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0667 - acc: 0.9804 - val_loss: 0.9240 - val_acc: 0.8258\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9825\n",
      "Epoch 00033: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0589 - acc: 0.9825 - val_loss: 0.9578 - val_acc: 0.8258\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9803\n",
      "Epoch 00034: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0656 - acc: 0.9803 - val_loss: 0.9808 - val_acc: 0.8239\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9826\n",
      "Epoch 00035: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0599 - acc: 0.9826 - val_loss: 0.9646 - val_acc: 0.8220\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9837\n",
      "Epoch 00036: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0574 - acc: 0.9837 - val_loss: 0.9336 - val_acc: 0.8265\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9846\n",
      "Epoch 00037: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0551 - acc: 0.9846 - val_loss: 0.9386 - val_acc: 0.8318\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9833\n",
      "Epoch 00038: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0574 - acc: 0.9833 - val_loss: 1.0396 - val_acc: 0.8206\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9845\n",
      "Epoch 00039: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0554 - acc: 0.9845 - val_loss: 0.9581 - val_acc: 0.8316\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9836\n",
      "Epoch 00040: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0547 - acc: 0.9836 - val_loss: 1.0457 - val_acc: 0.8213\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9864\n",
      "Epoch 00041: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 37s 1ms/sample - loss: 0.0493 - acc: 0.9864 - val_loss: 0.9824 - val_acc: 0.8295\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9853\n",
      "Epoch 00042: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0529 - acc: 0.9853 - val_loss: 0.9731 - val_acc: 0.8379\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0532 - acc: 0.9848\n",
      "Epoch 00043: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0532 - acc: 0.9848 - val_loss: 0.9732 - val_acc: 0.8376\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9865\n",
      "Epoch 00044: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0475 - acc: 0.9865 - val_loss: 0.9516 - val_acc: 0.8404\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9837\n",
      "Epoch 00045: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0574 - acc: 0.9837 - val_loss: 1.0074 - val_acc: 0.8255\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9891\n",
      "Epoch 00046: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0432 - acc: 0.9891 - val_loss: 0.9514 - val_acc: 0.8369\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9871\n",
      "Epoch 00047: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0493 - acc: 0.9871 - val_loss: 0.9295 - val_acc: 0.8318\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9893\n",
      "Epoch 00048: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0408 - acc: 0.9893 - val_loss: 0.9779 - val_acc: 0.8348\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9861\n",
      "Epoch 00049: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0503 - acc: 0.9861 - val_loss: 0.9472 - val_acc: 0.8365\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9881\n",
      "Epoch 00050: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0430 - acc: 0.9881 - val_loss: 0.9914 - val_acc: 0.8442\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0467 - acc: 0.9874\n",
      "Epoch 00051: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0467 - acc: 0.9874 - val_loss: 0.9443 - val_acc: 0.8386\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9873\n",
      "Epoch 00052: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0474 - acc: 0.9873 - val_loss: 0.9601 - val_acc: 0.8362\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9890\n",
      "Epoch 00053: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0410 - acc: 0.9890 - val_loss: 0.9519 - val_acc: 0.8444\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0388 - acc: 0.9900\n",
      "Epoch 00054: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0388 - acc: 0.9900 - val_loss: 1.0418 - val_acc: 0.8316\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0406 - acc: 0.9893\n",
      "Epoch 00055: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0406 - acc: 0.9893 - val_loss: 0.9562 - val_acc: 0.8411\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9901\n",
      "Epoch 00056: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0391 - acc: 0.9901 - val_loss: 0.9615 - val_acc: 0.8369\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0401 - acc: 0.9889\n",
      "Epoch 00057: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0401 - acc: 0.9889 - val_loss: 1.0301 - val_acc: 0.8318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9905\n",
      "Epoch 00058: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0391 - acc: 0.9905 - val_loss: 0.9971 - val_acc: 0.8328\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9906\n",
      "Epoch 00059: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0378 - acc: 0.9906 - val_loss: 1.0208 - val_acc: 0.8451\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9887\n",
      "Epoch 00060: val_loss did not improve from 0.68283\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0405 - acc: 0.9888 - val_loss: 1.0046 - val_acc: 0.8421\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xd8VfX9+PHX597c7D3BBCQoCIQRIAxFxYm4cCJSRx3Vb1tHrdVKXbVaW63WWiv+FC11UdG6qQNFQbSALNl7CgEyIJOsO96/Pz43IYEkBMjNDeH9fDzO4+ae+bk3yXmfzzjvY0QEpZRS6mAcwS6AUkqpo4MGDKWUUi2iAUMppVSLaMBQSinVIhowlFJKtYgGDKWUUi2iAUMppVSLBCxgGGO6GGNmGmNWGWNWGmN+1cg6xhjznDFmgzFmmTFmUL1lPzXGrPdPPw1UOZVSSrWMCdSNe8aYzkBnEVlsjIkBFgGXisiqeutcANwBXAAMA/4uIsOMMYnAQiAHEP+2g0WkKCCFVUopdVAhgdqxiOwEdvp/LjPGrAbSgVX1VrsEeF1s1JpnjIn3B5ozgC9FZA+AMeZLYDTwVnPHTE5Olm7durX2R1FKqQ5r0aJFhSKS0pJ1AxYw6jPGdAMGAt/vtygd2Fbv/Xb/vKbmN6tbt24sXLjwSIqqlFLHFGPM1pauG/BOb2NMNPAecJeIlAZg/7caYxYaYxYWFBS09u6VUkr5BTRgGGNc2GAxRUTeb2SVXKBLvfcZ/nlNzT+AiEwSkRwRyUlJaVGtSiml1GEI5CgpA/wTWC0izzSx2sfA9f7RUsOBEn/fx3RglDEmwRiTAIzyz1NKKRUkgezDGAFcByw3xizxz7sf6AogIi8Cn2JHSG0AKoAb/cv2GGMeAxb4t3u0tgP8ULndbrZv305VVdVhf5BjWXh4OBkZGbhcrmAXRSkVZAEbVhsMOTk5sn+n9+bNm4mJiSEpKQlb6VEtJSLs3r2bsrIyMjMzg10cpVQAGGMWiUhOS9bt8Hd6V1VVabA4TMYYkpKStHamlAKOgYABaLA4AvrdKaVqHRMBozkiQnX1DjyekmAXRSml2rVjPmAYY6ipyQtYwCguLuaFF144rG0vuOACiouLW7z+I488wtNPP31Yx1JKqYM55gMGgDEhiHgCsu/mAobH0/wxP/30U+Lj4wNRLKWUOmQaMAhswJgwYQIbN24kOzube++9l1mzZnHaaacxZswY+vTpA8Cll17K4MGDycrKYtKkSXXbduvWjcLCQrZs2ULv3r255ZZbyMrKYtSoUVRWVjZ73CVLljB8+HD69+/PZZddRlGRzdv43HPP0adPH/r378/VV18NwDfffEN2djbZ2dkMHDiQsrKygHwXSqmjW5vkkmov1q+/i/LyJQfM9/kqAcHhiDzkfUZHZ9Ojx7NNLn/iiSdYsWIFS5bY486aNYvFixezYsWKuqGqkydPJjExkcrKSoYMGcIVV1xBUlLSfmVfz1tvvcXLL7/MVVddxXvvvce1117b5HGvv/56/vGPfzBy5Egefvhh/vCHP/Dss8/yxBNPsHnzZsLCwuqau55++mkmTpzIiBEjKC8vJzw8/JC/B6VUx6c1DAAMbXk/ytChQxvc1/Dcc88xYMAAhg8fzrZt21i/fv0B22RmZpKdnQ3A4MGD2bJlS5P7Lykpobi4mJEjRwLw05/+lNmzZwPQv39/rrnmGt58801CQuz1wogRI7j77rt57rnnKC4urpuvlFL1HVNnhqZqAlVV23C7C4iJGdTo8tYWFRVV9/OsWbOYMWMGc+fOJTIykjPOOKPR+x7CwsLqfnY6nQdtkmrKJ598wuzZs5k2bRqPP/44y5cvZ8KECVx44YV8+umnjBgxgunTp9OrV6/D2r9SquPSGga2DwN8iPhafd8xMTHN9gmUlJSQkJBAZGQka9asYd68eUd8zLi4OBISEvj2228BeOONNxg5ciQ+n49t27Zx5pln8uSTT1JSUkJ5eTkbN26kX79+3HfffQwZMoQ1a9YccRmUUh3PMVXDaIoNGCDiwZjQVt13UlISI0aMoG/fvpx//vlceOGFDZaPHj2aF198kd69e3PSSScxfPjwVjnua6+9xs9//nMqKiro3r07//rXv/B6vVx77bWUlJQgItx5553Ex8fz0EMPMXPmTBwOB1lZWZx//vmtUgalVMfS4XNJrV69mt69eze7ndtdRFXVRiIj++B0HnrHd0fXku9QKXV00lxSh6h+DUMppVTjNGCgAUMppVpCAwYaMJRSqiU0YKABQymlWkIDBrUpvJ0aMJRSqhkaMPwCmU9KKaU6goAFDGPMZGNMvjFmRRPL7zXGLPFPK4wxXmNMon/ZFmPMcv+yhY1t3/rlbT8BIzo6+pDmK6VUWwhkDeNVYHRTC0XkKRHJFpFs4HfANyKyp94qZ/qXt2h88JFqTwFDKaXao4AFDBGZDew56IrWeOCtQJWlJQIVMCZMmMDEiRPr3tc+5Ki8vJyzzz6bQYMG0a9fPz766KMW71NEuPfee+nbty/9+vXj7bffBmDnzp2cfvrpZGdn07dvX7799lu8Xi833HBD3bp/+9vfWv0zKqWODUFPDWKMicTWRG6vN1uAL4wxArwkIpMa3dhufytwK0DXrl2bP9hdd8GSA9ObA4T5qvGJG5yH2OyTnQ3PNp3efNy4cdx1113cdtttALzzzjtMnz6d8PBwPvjgA2JjYyksLGT48OGMGTOmRc/Qfv/991myZAlLly6lsLCQIUOGcPrpp/Pvf/+b8847jwceeACv10tFRQVLliwhNzeXFStsy+ChPMFPKaXqC3rAAC4G/rdfc9SpIpJrjEkFvjTGrPHXWA7gDyaTwKYGOfxiGEAQBMPBT9otNXDgQPLz89mxYwcFBQUkJCTQpUsX3G43999/P7Nnz8bhcJCbm0teXh6dOnU66D6/++47xo8fj9PpJC0tjZEjR7JgwQKGDBnCTTfdhNvt5tJLLyU7O5vu3buzadMm7rjjDi688EJGjRrVap9NKXVsaQ8B42r2a44SkVz/a74x5gNgKNBowDgkzdQEPDUFVFdvJSqqH8YR1uR6h2Ps2LG8++677Nq1i3HjxgEwZcoUCgoKWLRoES6Xi27dujWa1vxQnH766cyePZtPPvmEG264gbvvvpvrr7+epUuXMn36dF588UXeeecdJk+e3BofSyl1jAnqsFpjTBwwEvio3rwoY0xM7c/AKKDRkVatW5bA3bw3btw4pk6dyrvvvsvYsWMBm9Y8NTUVl8vFzJkz2bp1a4v3d9ppp/H222/j9XopKChg9uzZDB06lK1bt5KWlsYtt9zCz372MxYvXkxhYSE+n48rrriCP/7xjyxevLjVP59S6tgQsBqGMeYt4Awg2RizHfg94AIQkRf9q10GfCEie+ttmgZ84G/LDwH+LSKfB6qc+8obuICRlZVFWVkZ6enpdO7cGYBrrrmGiy++mH79+pGTk3NIDyy67LLLmDt3LgMGDMAYw1/+8hc6derEa6+9xlNPPYXL5SI6OprXX3+d3NxcbrzxRnw++6yPP//5z63++ZRSxwZNb+7n9VZSUbGS8PBMXK6kg65/LNH05kp1XJre/DBoPimllGqeBgw/DRhKKdU8DRh+ts9E7/ZWSqmmaMCoR9ODKKVU0zRg1KMBQymlmqYBox4NGEop1TQNGPUEImAUFxfzwgsvHNa2F1xwgeZ+Ukq1Gxow6qkNGK15b0pzAcPjaT44ffrpp8THx7daWZRS6khowKjHDq0VwNdq+5wwYQIbN24kOzube++9l1mzZnHaaacxZswY+vTpA8Cll17K4MGDycrKYtKkfYl5u3XrRmFhIVu2bKF3797ccsstZGVlMWrUKCorKw841rRp0xg2bBgDBw7knHPOIS8vD4Dy8nJuvPFG+vXrR//+/XnvvfcA+Pzzzxk0aBADBgzg7LPPbrXPrJTqmNpD8sE200x2cwBEkvD5onA6W56t9iDZzXniiSdYsWIFS/wHnjVrFosXL2bFihVkZmYCMHnyZBITE6msrGTIkCFcccUVJCU1vNt8/fr1vPXWW7z88stcddVVvPfee1x77bUN1jn11FOZN28exhheeeUV/vKXv/DXv/6Vxx57jLi4OJYvXw5AUVERBQUF3HLLLcyePZvMzEz27Gnpo0uUUseqYypgHJwNFCJCCx5LcdiGDh1aFywAnnvuOT744AMAtm3bxvr16w8IGJmZmWRnZwMwePBgtmzZcsB+t2/fzrhx49i5cyc1NTV1x5gxYwZTp06tWy8hIYFp06Zx+umn162TmJjYqp9RKdXxHFMBo7maAIDHU0Vl5VoiInoQEhIXsHJERUXV/Txr1ixmzJjB3LlziYyM5Iwzzmg0zXlY2L6U606ns9EmqTvuuIO7776bMWPGMGvWLB555JGAlF8pdWzSPox6ApEeJCYmhrKysiaXl5SUkJCQQGRkJGvWrGHevHmHfaySkhLS09MBeO211+rmn3vuuQ0eE1tUVMTw4cOZPXs2mzdvBtAmKaXUQWnAqCcQASMpKYkRI0bQt29f7r333gOWjx49Go/HQ+/evZkwYQLDhw8/7GM98sgjjB07lsGDB5OcnFw3/8EHH6SoqIi+ffsyYMAAZs6cSUpKCpMmTeLyyy9nwIABdQ92Ukqppmh683pEhPLyRYSGdiYsLD0QRTwqaXpzpTouTW9+mIwxere3Uko1QQPGfjRgKKVU4wIWMIwxk40x+caYRp/HbYw5wxhTYoxZ4p8errdstDFmrTFmgzFmQqDK2Hi5NGAopVRjAlnDeBUYfZB1vhWRbP/0KIAxxglMBM4H+gDjjTF9AljOBjRgKKVU4wIWMERkNnA4YzWHAhtEZJOI1ABTgUtatXDN0IChlFKNC3YfxsnGmKXGmM+MMVn+eenAtnrrbPfPaxOBSEColFIdQTADxmLgeBEZAPwD+PBwdmKMudUYs9AYs7CgoOCICxWIBISHKjo6OmjHVkqppgQtYIhIqYiU+3/+FHAZY5KBXKBLvVUz/POa2s8kEckRkZyUlJQjLlcgbt5TSqmOIGgBwxjTyRib4s8YM9Rflt3AAqCHMSbTGBMKXA183Hblat2AMWHChAZpOR555BGefvppysvLOfvssxk0aBD9+vXjo48+Oui+mkqD3lia8qZSmiul1OEKWPJBY8xbwBlAsjFmO/B7wAUgIi8CVwK/MMZ4gErgarEdBx5jzO3AdMAJTBaRla1Rprs+v4slu5rJbw6IePH5KnA4IuqCR3OyO2Xz7OimsxqOGzeOu+66i9tuuw2Ad955h+nTpxMeHs4HH3xAbGwshYWFDB8+nDFjxmCaSZPbWBp0n8/XaJryxlKaK6XUkQhYwBCR8QdZ/jzwfBPLPgU+DUS5Dq72hN06nd4DBw4kPz+fHTt2UFBQQEJCAl26dMHtdnP//fcze/ZsHA4Hubm55OXl0alTpyb31Vga9IKCgkbTlDeW0lwppY7EsZXevJmaQC2fz8PevUsIC8sgNLTpk/ehGDt2LO+++y67du2qS/I3ZcoUCgoKWLRoES6Xi27dujWa1rxWS9OgK6VUoAR7WG27Y+8bbN1O73HjxjF16lTeffddxo4dC9hU5KmpqbhcLmbOnMnWrVub3UdTadCbSlPeWEpzpZQ6Ehow9mMTELoQ8bbaPrOysigrKyM9PZ3OnTsDcM0117Bw4UL69evH66+/Tq9evZrdR1Np0JtKU95YSnOllDoSmt5cBDZtgrg48D9DYu/elTgcYUREnBjI4h41NL25Uh2Xpjc/FMZAebmd6mZpehCllNqfBgyA8HCo14GsAUMppQ50TASMgza7hYVpwGhCR2qyVEodmQ4fMMLDw9m9e3fzJ77wcPB47IQmIKwlIuzevZvw8PBgF0Up1Q50+PswMjIy2L59O80mJqyogMJCWLECwsLweErxeIoIC1uFMR0+pjYrPDycjIyMYBdDKdUOdPiA4XK56u6CbtLatZCTA6+/Dtddx65db7BmzfUMHbqeyEgdKaWUUnAMNEm1SGYmOJ02cAAulx1e63YXBrNUSinVrmjAAAgNtUFj3TpAA4ZSSjVGA0atk07SgKGUUs3QgFGrZ08bMHw+XK4kQAOGUkrVpwGjVs+eUFkJubk4nTEY49KAoZRS9WjAqHXSSfZ13TqMMbhcyRowlFKqHg0YtXr2tK91/RgpuN35QSyQUkq1LwELGMaYycaYfGPMiiaWX2OMWWaMWW6MmWOMGVBv2Rb//CXGmIWNbd/qjjsOoqLqhtZGRfWhvHxZmxxaKaWOBoGsYbwKjG5m+WZgpIj0Ax4DJu23/EwRyW5p2t0jZsy+jm8gJiaH6uqt1NQ0c4e4UkodQwIWMERkNrCnmeVzRKT2MXDzgODnn9gvYACUlS0KZomUUqrdaC99GDcDn9V7L8AXxphFxphb26wUPXvC5s1QXU109EAAysrapkVMKaXau6DnkjLGnIkNGKfWm32qiOQaY1KBL40xa/w1lsa2vxW4FaBr165HVpiePcHng02bCOndm4iIkzRgKKWUX1BrGMaY/sArwCUisrt2vojk+l/zgQ+AoU3tQ0QmiUiOiOSkpKQcWYHqDa0F2yylAUMppaygBQxjTFfgfeA6EVlXb36UMSam9mdgFNDoSKtW16OHfa0XMGpqcqmu3tkmh1dKqfYsYE1Sxpi3gDOAZGPMduD3gAtARF4EHgaSgBeMMQAe/4ioNOAD/7wQ4N8i8nmgytlAfDykptYNra3f8R0WdlGbFEEppdqrgAUMERl/kOU/A37WyPxNwIADt2gj9ZIQRkdnAw7KyhaSnKwBQyl1bGsvo6Taj3pDa0NCoomM7K39GEophQaMA/XsCXl5UFIC7Ov4Ptaf762UUhow9tfISCm3O4/q6twgFkoppYJPA8b+9ktCuK/jW5ullFLHNg0Y++veHRyOeh3fAwCnBgyl1DFPA8b+wsKgW7e6obVOZwRRUX01YCiljnkaMBpTb2gtaMe3UkqBBozG1Q6t9QeImJgcPJ7dVFVtDXLBlFIqeDRgNKZnT9i7F3balCDa8a2UUhowGlc7tNbfjxEd3Q9jXBowlFLHNA0YjdlvaK3DEUZUVH8NGEqpY5oGjMakp0NEBKxaVTdLO76VUsc6DRiNcTggKwuee87el3H99aR9XEHY5hIqKzYEu3RKKRUUQX/iXrv1zjvw4Yfw7bfw+efEv1HAUKB68hUwa1mwS6eUUm1OaxhNycyEX/8a3n8f8vLwrVpO3jkOQr9dAeXlwS6dUkq1OQ0YLWEMjt59Kb3oRIxPYPHiYJdIqbb1xRfw1VfBLkX7JWKH4ndwLQoYxphfGWNijfVPY8xiY8yoQBeuvQkZfhYA3u+/C3JJlGoFRUVw2mnw3/82v96OHXDZZXDBBbBgQduU7Wjzq1/Z/s6CgmCXJKBaWsO4SURKsc/XTgCuA5442EbGmMnGmHxjTKPP5PYHoOeMMRuMMcuMMYPqLfupMWa9f/ppC8sZUAkn/YSqNHB/Ny3YRVHqyP397/Ddd3DrrVBa2vR6Dz4IHo99fPGVV0JhYduV8WiwahVMnAj5+fDww4e+/c6dMHgwTJgAVVWtX77WJCIHnYBl/te/A5f5f/6hBdudDgwCVjSx/ALgM8AAw4Hv/fMTgU3+1wT/zwkHO97gwYMlkHw+jxScGSbV6VEBPY5SAVdSIhIfL5KdLWKMyN13N77eDz/Y5ffcIzJ/vkhoqMioUSIeT9uWtz27+GKR2FiRa68VcThEli5t+bZer8i554qEhIiASJ8+9ntubL333xcZPlykXz+R3/9eZMWKVik+sFBaEAfElrBFAeNfwBfAeiASiAEWtXDbbs0EjJeA8fXerwU6A+OBl5par6kp0AFDRCTv3uEiIJ4dWwJ+LKUC5k9/sv/+CxeK3HqriNMpsnx5w3V8PpGzzhJJShIpKrLzXnrJbvfQQ61fJp9P5OWXRVaubP19B8qsWfb7+POfRXbvFklMtN+Zz9ey7Z9+2m7/4osin30mkp5ufxcPPCBSVSXidotMmSKSlWXXO+EEkdNOs0EcRHr3Fnn4YZFly1p+zP0EImA4/DWFeNlXA+jfwm2bCxj/BU6t9/4rIAe4B3iw3vyHgHsOdqy2CBgl0+wvuHhKAP5hlGoL5eUiyckiF1xg3xcW2hPd6ac3POl8/LE9RTz//L55Pp/IjTfa+f/9b+uW69FH7X5TU0U2bWrdfQeCzycyZIhIRoZIRYWd949/2M/wwQcH337xYhGXS+TSS/d970VFIjfcYPeRlSVy4on7ah5TptgAIiKyY4fIxIkiZ5xhazUJCSI1NYf1MQ4lYBi7fvOMMSOAJSKy1xhzrT94/F1EDpq+1RjTDfiviPRtZNl/gSdE5Dv/+6+A+4AzgHAR+aN//kNApYg83cg+bgVuBejatevgrVsDm1HWV7oHk5BE4c8HkDJxSUCPpdShEAG3G2pq7Kvbbbseal+9XnC5IPTVSYQ9ej9hX36C69RheL1Q8/JrVP/6Pmr+9gI1F10ObjehF56Ly+HF9e3XuCJd1NTYR92X5FVRcsOvKNmxl5o//xVXRhqhodRNLpe999Xp3PdqDFRXQ2WlbaavrLTvIyMhLg5iZ31M7CO/Jmb0qZTMWcn2uCy2TZjI9uJotm+3nyEysuHkcNiBSfUnr9fuLz7eTgkJEBVlj1lRYae9a7ZR+cnXOE49BWevHoSEQEjIvvLWMsa+ut0Ny11VZctes2Er7v/NpyZ7GO7OXfF6IcTpI+TbWTjFTcjoc3CEOPF69/0O6n4PDg+hc2YR5qkg9OLzCI0Jw+2ud4ztBVSu3oo3JBTSM5CEBGzLvS1rRIT9DiIiINJUkkI+T751/GH93RhjFolITovWbWHAWAYMAPoDrwKvAFeJyMgWbNuNpgPGS8AsEXnL/34tNlicAZwhIv/X2HpNycnJkYULA5/vqapnAhVJ5cT/rwKHwxXw46kjV1VlBwUVF9uTns9n59eeFIyx/8i1/9S1E9iTSP3J69138qmosP/glZUNT85ut11vfyL7Tpy1U+3JrPakV/uz02lPdtHREOWsIqpwC8bjoTy2M+WuBMr3Oigrs+vXBoiOKDERwsP3fd81NQ2Xu1z2e4oK9+D0VFPijqSkxDS7TyceBIMPZ4vLERpqT9Dh4RAWJoTu2IrL6SW0V3dcLoPT6f8bKirFs3Er3tTOeOOT6wKSy2VfHQ7wbNhMdUEpNV1PpNoZRU2NXV67/9rXkHq3Vu8fwGr/9ioqbHBcvrzFH6WBQwkYLb3T2yMiYoy5BHheRP5pjLn58IrXwMfA7caYqcAwoEREdhpjpgN/MsYk+NcbBfyuFY7XKmTIYGL++xXFRbNITDo32MXpMETsCT0/304FBfa19srR52v4Wnu1Vntyr6622xcX7wsOtT9XV7fd53A49l2xmkbOW2Fh9oRQ/+QQGQkpKfZhj5GR9gTo9cLe7XsoX7qRvbkllJtocDiJ2bmITs4qorvEEzM4nYiTuhIW7bK1B/8Vfv2p9mTlcIDn8xlUv/kO1XfeS03XHtTU2OWhoRC6aythTzyK69RhsOQH3F1OwH3nb3B7DDU1dp3YWHsFHxcHcVuWEv7O67hXradm605qcFFDKDWhMfgcIfjE4BUHPhz4QsMJP/Nkwq8aQ8SJ6YSH2/1VLllLyc13U9qpJ6UT/kSpO4K4OMhYP5Muj91C+uXDifjP6w0u/T0ee5L0+ez35HIBGzbAmWfCru0weDDeF16irOdgiorsfbYRERA1bSqR9/ySyAE9cE19A266CZkzF+/k1/BcfS0eT90jcBq8ulz291S/9sFz/7BDaad9BqNP2O83HAsX/Q5mz4Zl6yEtreHi99+HK66A++6DJw462LRdaWkN4xvgc+Am4DQgH1gqIv0Ost1b2NpCMpAH/B5wAYjIi8YYAzwPjAYqgBtFZKF/25uA+/27elxE/nWwcrZVDcP3//6B45d3snnGNWSe/WbAj3c0qqmB3Fz48Uf7Wlpq/3Frp7Iy2LPHBoXCQjvt3r3vqr4lnE4aNCeEhtomiNrmiPrNEvVfY2PtNvVPCiJ2H7Un2PonfJ+v4eRwHNg8Eh7e8AryiM2ZA489Bp9/DjEx8ItfwF13QXIyfPMN/Oc/9sRTWGjnPfMMXHtt4xGqVk0NnHCCjUqzZze+7m23wQsv2GU//AADBrSsvOXlsGyZ3WbTJjuvfvVt+3Z47z37C77oIptFoXt3OPlk+6XNnWuTftb39NNw771wzz3w1FNNH3vtWjjrLPv57r8f/vIXe6Vx553w6KO2ivbnP8MDD8A559jvLSbGXomMGQMzZ8KLL9rhxbVE7CX7Rx/ZX3pWlp1OPNFGqxNOgOxs+PLLxr/HtWuhb18YOxbGj7efv3b6+GO7/Zw59o82yA6lhtHSTu9OwN3Aaf73XYHrW9pR0lZTW3R6i4jtrAJZ84c48fm8bXPMdsDrtaMxt2wRWbJEZMYMkddfF3niCZE77hC54go76u+44/YN4mhsiooSSUuzAzxOO03ksstEbrlFZMIEkWeeEXnzTZEvvrDHyM21xywvF6mstP16Hs9hDwixO5g8ed+on0M1d64tXKBUVIj86lf7On//9Kemy+p221/CySfb9c8+W2T9+qb3PWmSXW/69KbX2bNHpEsXkV/+8sg+R2N27LCjq5KTbTnCwkTi4poeHurzidx2m133nntE8vMPXGfVKpFOnURSUvaN8ioqEvnFL+wfYUaGyNVX232MHy9SXd1w+4oK2/kP9o9v3jyRe++1o5HA7qP+H7PLJdK5s/150aLmP+/ddzf8w3c6Rbp2taOomvs9tTFae5SU3SdpwEX+KbWl27Xl1GYBo6ZGfOEu+XEsUlz8Xdscsw35fCJr14q89pr9vxs40A7CcDiaDgJxcTYAnH22HUTz+9+L/POfIl9+af+nd+wQKS21QSeoH+ymm2yBL7vs0KPOxx/b+xAiI+3IokPh9dohlCkp9tgzZx54/PnzRXr1suW7/XYbJVu67//3/+y9AOHhNsjUjpiprLQjjr77TiQz047qOdjnrqw8gojcApWV9o/j3HNFvvmm+XU9HpHrr7ffSXhD6tgEAAAgAElEQVS4HQK8apVdtmKFDappaY0PxZ0zR6RvX7vtr3/d9B9fdbW92qkfFEaPtgF21y6RvXttcHjjDXtVc/HFIo88cvDPWVUl8skn9ve6Y0e7vXel1QMGcBWwFXgNeB3YDFzZ0oO01dRmAUNEfCcPk+J+Rtavb+KGp6PIzp32XPjQQ/b/JCFh3/9OTIzIOefY89dDD4n89a/2f/299+wQ9HXrWn5eC7o//tF+qCFD7Osbb7R82/fftzdX1Y6Hf/TRlm+7ZYsd/gi2SpWUZH/u18/ed1BSYsfSO532ivjLLw/9s4nY6tiVV9p9p6XZobL1o7oxIp9+enj7DraVK201NCzMfpbzz7fBt3NnkdWrm96upsZWVQ/G7bbDVN944/Brn0epQASMpfVrFUAKtg8j6EGi/tSWAUN+9Svxhjtk7rfHiy+QV2OtrLra1rr/+leRyy+356fa84nDYc9hN98s8sor9gKunV4UHbo337Qf8tpr7clhxAhbLdq27eDbvvOOPZmffLJIcfG+k1VlZfPb+Xz2BBQbKxIdbZvCfD7bDPLKKyL9+0tdUwXYK+nWOFl9/LHIuHG2evjYYzbCf/ZZu2oGOWz5+TZYp6bam9zWrg12iY56gQgYy/d779h/XnuY2jRgTJkiAjL/ZaS0dPGBy9tJEKmsFPn6a3vj6MiRIhER+wJEZqZt1n3mGZFvvz2Kagpz54q88MKB7dFNmTXLNjOccca+bdavt01L553X/O/q3/+2J/RTT7VtaiL2CwV713NTSktFxo61640Y0fiNaD6fLdsvftGyG73UPtXVtqlIHbFABIyngOnADf7pM+DJlh6kraY2DRjr14uArPmNkU2bHmy47P33bbvO5s1tVx4/n882tz75pG0iDg/fdxGbk2P7U//zH9ukelQqLd3X6dirl8hXXzW//qpVNmdS7962Q7e+iROlLi3D/jweG5QcDhtpy8r2LfP5RAYPFunZs/F2cZ/PXuE7nbY/ocNU01RHFKhO7yuAZ/zTZS3dri2nNg0YPp9IQoIUXtZZvv++975mqZ0797VRP/dcmxVn9WqRBx+0tYbaGkRWlg0Q06bZZvIO4e67bVv800+LdO8udaNf6kdAr9cGismTRbp1s80XjQVvr9d20ERFiWzcaOe53bYZ6aST7L7POafxqtfUqdJkCohXX7XLHn+8VT6yUoEUkIBxNExtGjBERM47T6r7ZMjMmUhx8VwbRMaMsR1zaWkiF14Y0MPn54v87W/2Yre2D+Lcc0X+9a+joAaxerVtjvnyS9u+Pm2ayEcfNd+Gv3y5vWq/5Rb7vqLCDscKC7O987fdZjOpxsXti5qpqY1n/6z144+2j+G00+wXV5u7p39/WxVramSN222D0SmnNJy/fr0NQCNHas1CHRVaLWAAZUBpI1MZUNrSg7TV1OYB46GHxOd0ynfTY2Xlyqv3XVk+84xtl46MtEPrWpHPZ0cijh9vm+VBZNAge8h2HyRE7An4/vv3ndD3n3r3FsnLO3A7n88mx0tMPHBI6/r1dniXw2FP9LfeamsXq1a1bBxv7e8N7BjiDz5o2XbPPWe3+d//7PuaGjsCKyHBBiKljgJaw2gr/mye294aJ3PfcYovNsae1LxekQ8/tF/vwdrYW2jPHpG//92eT2vve7jzzlZLid82iotFLrrIfoCbb7adx7Nn207sBQvsWN2ICDtUq6Cg4bZvvGG3mzSp6f0f7hW9z2ezjE6bdmiDFcrLbQC79FL7/ne/s2X8z38OrxxKBYEGjLayc6cISM2f75fdgxFvpGtfW3hJiR23f999h717j8e21owbt2/4+dCh9uL5qBsgsmaN7RcICbGdzU2dmGfMsD312dn2+QIitpkqLU1k2LAg3/nXiAcftH0qL75oX3/2s2CXSKlDcigBo0W5pI4WbZVLqoHjj7c5aXbvZsM9UWQ+UYDTGWGXjRxpkyj98MMh7XLdOpg8Gd54wz5OOTERfvITuPFGGDTo4Nu3O59+avPphIbCu+/a76U5n38Ol1wC/fvDjBnw0EPw/POwcGH7+wLy8uzfQHU19OwJixfbjHjqoDw+DyGOluY/PXIiQm5ZLmsK17C5aDOJEYl0ietCl9gupEWn4TDNJwErrylnTeEaVhWswuVwcUa3M+gc07nJ9X3iY3fFbuLD43E5jyyrtYiwqmAVs7bMYnflbuLC4ogPj6+bEiIS6J/W/7D2HYhstaopQ4fCu+/iPjOH7RcsJCr/LTp3vskuO+88m/AsL+/AjJWNWLzY5kh77z2bwO788+G552yutrCwAH+OQHC74Q9/gD/9ySax+/BDe3I9mNGjbWC5/HI4/XRYscIm32tvwQLs7/Xmm+Hll+Hf/263waLaU82eyj10iu6EaS5BIfbEGOYMa9FJzic+thZvZUX+ClYWrGRF/gp+LPkRQXAYBwaDMQYRoaymjJKqEkqqSyitLqXGW8OgzoMY03MMY04aQ3an7LqyiQg/lvzIdz9+x5xtc6jyVJEem056TDrHxRxHemw6ka5IiquKKakqobiqmOKqYkqrS6nyVFHpqbSv7kpKqktYt3sdawrXsNe9t9HP4XK4SI9NJzEikejQ6LopyhVF3t48VhWsYkvxlgO2653cm7Mzz+bs7mfTLb4bS3ctZfHOxfyw6wd+2PUD5TXlACRGJJIalVo3dY7u3OCzdI7ujNPhxOPz4Pa6cfvcVHuqWbJrCbO2zuKbLd9QUFHQ5O8hNSqVvHvyDvr7OlJawzhSkyfDAw8g8+ezcNdF/nIssX/4ixZBTg68/jpcd12Tu/j2W3tO/fxzm0n19tvhjjugU6e2+hABsGmTrRZ9/72tGj3/vE3reggq3n2LZb+5lpiIOPrM2YBJTDzoNiLC8vzlfLHxC77Y+AWrClZxRe8ruHPYnZyQuH8aaquosojPN3xOSXUJIY4QXA4XLqcLl8NFp+hO9EnpQ1Jk0gHb7ancw/9+/B/fbvmGwt3bOKffJYw+cTSJEY2Xs7S6lOV5yymqKqK8przB5BPfAeu7HC4iXZFEuiKJcEXs+zlk38+Rrkh84iNvbx555Xl1r7vKd7G9bDu5pblsL91ed7JJikjilC6n1E2DOw9ma8lW5m6by9ztdlpdsJqwkDAGdR7EkOOGMOS4IQxNH4rL6WJVwSpW5q9kVaH/tWBVg5Nwl9gudE/ojsM4EASf+GxThjHEhMYQFx5HbGgssWGxhDhCmLV1FnO3zUUQMmIzuODECyipLuG7H78jtywXgJjQGKJDo8nbm9fo99SYEEcIESERhIeEEx0aTY+kHvRK6kWvZDtlJmRSXFXMtpJtbCvdxraSbWwv205xVXGD30tZdRmJEYlkpWaRlZJFn5Q+ZKVkUV5Tztebv+brLV8ze+tsKtwVdceOdEWS3SmbQZ0GcWLiiRRXFVNQUUD+3nzy9+aTtzePHWU7KK0ubdFn6RLbhTMzz+SM48/gzMwzyYjNoLS6tC5IFlcV4/a6Oe/E81q0v/21+gOUjhZBCRhQl/N6585/snbtzxgwYCYJCWfY+Z06wahR8OaBadAXL7ZZnmfPts9CuPtueyEdF9c2xfb6vDgdLX+ATANvv23TQo8YYVNL109NPWUKvl/8nMpQB3v//hR7LziXkuqSBn/gpdWlOI2TCJf9p44IiSDUGcqmok0s2rmIRTsXsbpgNV6xTyHKjM/k4p4XM+akMZx+/Om4nC584iO31DYxrClcw8KdC/li4xfsKt8FQFZKFicknsCn6z/F6/NySa9L+PXwX3Na19MorS7lo7Uf8c7Kd/hi4xe4fc0/fSgtKq3uZOHxefj2x29ZWbASsCf26NBoiqqKcBgHJ2eczEU9L2Jo+lBWFaxiwY4FzM+dz9rCtQht8/+WHJlMekw6GbEZdVNsWCxLdi1hzrY5rN299oBtEsITGJ4xnGHpwyipLmHBjgUs3rm4wcmwVufozmSlZtEnuQ99U/vSN7UvfVL6EBd+6H+8+Xvz+XT9p3y89mO+2PgFiRGJnNr1VEZ0GcGIriPol9qv7uo7r9yebHPLcql0VxIfHk9c+L7mmZjQGCJcEW3a1FXjrWF+7nxyS3MZ0GkAPRJ7tOj/qrym3H6W0lx2lu9EROouVFxOFyGOEHok9qB7QveD1gqPhAaMIPF6K5k7twvx8afTt+/7duY119ic+bt21T0oYc8eePBBm4I/Odk20d98c8svwL0+LysLVjJv+zzW716Px+fB4/PgFS8en6fuKmz/JoHdlbvrrnLy9+ZTVFVEfHg8mfGZZCZk0i2uG5kJmXh9XnaV72LX3l3sLNvJrvJdeMVLYkQiiaFxJC5ZS+KSdbiMk8IwLwWRUJgUQUFiGHuoZK+vmoojSPOfFpXG4OMGM6jTIAZ1HkRBRQHT1k1jxqYZVHmqiAuLIzMhk/W71ze4uk2OTOac7ucwqvsoRp0wivRYG8R2lO1g4vyJvLjoRfZU7qFHYg+2lmylxltD17iuXNXnKsZmjaVrXNe65gC3102Nt4btpdvtVXWBvZpeVbAKgFO6nMJpXU/j1K6nMjR9KKHOUBbsWMAn6z7hk/Wf8MOuHxp8nqHpQxly3BAGdR5EalRqg2aP6NDoA04wIoLb56bCXUGlu5IKd0XdVOnZ977SXWmPEZ1GWlQaadFppESmHLQ5qbCikHnb57FoxyK6xnXl5C4n0zOp5wHt+B6fxwa93AX4xEdWaha9k3uTEJHQxJ6PTG1tRLUdDRhBtGnT/fz445MMG7aRiIhutjnqpz+FRYvwZQ9i8mT43e9s0Lj9dtvEHx/fcB8en4fCikL2VO5pMK0tXMu83HksyF1Qd6IMc4YR6gwlxBFCiCMEp8NZ908v4m8SQDAYkiKT9rWjRqaSGJFIYUUhm4s3s7l4M1uKt1DlqQKoa46pnZwOJ0V7drBn/TL2mCr2xIRQ4xCSQ+NJcbtIKaoheWcJieVeonNOJurUs4kKjyHKFUVUaJS9EqzXURcbFotXvFS6Kxu0OXeJ7cJxMcc1etLYW7OXrzZ/xcdrP2ZH2Q5OSjqpronhpOSTSItKa/ZkU+Gu4I2lb/D2yrfJ7pTNuKxxDE0fekgnKBGpa59vzo6yHSzLW0ZWShYZsRl6ElTtlgaMIKqq2s68ed3IyLiLE0982tYsOnfmm5+9wb3LrmHBfMOpp8LEiXYQUK0abw1fbvyS/6z6Dx+t/YjiquID9h3iCGFgp4F1zQbDM4a3anVVRMjbm4fL4SIhIqHhSfGDD+CGG+xj6F5/HS666MCrwZoa++S1FvQ1KKXaBx0lFUTh4RmkpFzJzp2v0K3b7/lhWyceiJ7Dl5+D45pUYi924OnUnSc3dOeE3SeQHpPOnO1z+GjNR5RUlxAXFsclvS5hWPowkiKSbDOQf+oc05nwkPCAld0YQ6fo/Xrad+yw1aBJk2DIEHjnHfuIT//6DYSGarBQqgMLaMAwxowG/g44gVdE5In9lv8NONP/NhL7zI14/zIvsNy/7EcRGRPIsramLl1+w/z5y3n88e1Mn96b+NQkYq4eSHJaKmefcA6bijcxZ9scpq6Yik98xIfHc1nvyxjbZyzndD+HUGfwn/NLQQE8+aStCnk89nnSTzxxlI7vVUq1hoAFDGOME5gInAtsBxYYYz4WkVW164jIr+utfwcwsN4uKkUkO1DlC5Tqanj88SE89dRyIiLKuf/hQj6PvoR1RRVMO+43ZI25vW5dt9dNblkux8Uc1z6CBEBREfz1r/Dss1BZaYcDP/wwdO8e7JIppYKs+Z67IzMU2CAim0SkBpgKXNLM+uOBtwJYnoAoripm+obpeH1eli+39/H95S9w442lTJlyAiu7j2BxxRre/CSUrG/XNNjWVVlNty/mE5pXGNhC+nz2Zg9380NH+fFH27Hy+OP2bsGVK+HVVzVYKKWAwAaMdGBbvffb/fMOYIw5HsgEvq43O9wYs9AYM88Yc2lTBzHG3Opfb2FBQdN3QgaCiHD1u1czespoMh7PZtD4j9mVJ/z3v/DPf8Yz33ESH21Zx0Mj7uSSjHNg+nSbE3X+fLj1VujcGcaNg2HDYNWqgx/wcN13n71jeuxYWwVqzJ499g7rsjKYNw+mToVevQJXJqXUUSeQAeNQXA28K+K/S8s63t9z/xPgWWNMo7fpisgkEckRkZyUlJS2KGudV5e8yvSN0+m082Z2FVTjGXsJXR45hcg+M/ly45c8uWQuI1OcXJm23aYJ2bABsrJsgJgyBa68Et56y/YRnHoqzJ3b+oV8/nl4+mm7/48+gssus01N9VVWwsUXw8aNNn3HsGGtXw6l1FEvkAEjF+hS732Gf15jrma/5igRyfW/bgJm0bB/I+hyS3O56/NfE553OqVvTuKlASuZdNHL5FVu56zXz+LCf19IVkoWE8+9jz2736d0ZAaEh0N0NLz0EuzcCf/6F1x9Nfzvf5CUBGefDZ980nqF/PBDuPNOm8hv1iw70unzz2HMGJswEWywGj/eBqs334Qzzmi94yulOpaWprU91Anbob4J29QUCiwFshpZrxewBf89If55CUCY/+dkYD3Q52DHbKv05j6fT86ZfJGYByMkqst6mTt337JKd6U8M+cZOeu1s2Tjno3idpfJd9+lyeLFp4qvurrpnebl2UfnOZ32gT77q64+tNTec+faNOHDhjXMhf7aa/ZBQ6efbp+P/X//J239OFmlVPtBe3keBnABsA7YCDzgn/coMKbeOo8AT+y33SnYIbVL/a83t+R4bRUw/vHNG8IjSOjIZ+oettac3NwXZeZMpKDgo+ZXLC0VOfts+2sZMsQ+LalzZ/tQIRA57jiRZ5+1jyZtzvr1IsnJIiecYJ/jur+pU21gOu44u98JEw7+IZRSHdKhBAy90/sQLd+8i+yX+0BhL76+7ltGnnbwJGM+n4cFC/pijCEnZzmO5hKjVVfbTupVq2zOkLi4fa8zZsA339iEhr/9Lfzf/+1LQCUCW7bAkiV2WVGRbWbq0aPx43zwge1w/8lPbNOYpq5Q6pikqUFawfzc+azbvY6slCx6JfciwhVBXp7Q48ErKOv0Ka+dvITrL2j5KKKCgg9ZufIyevSYSHr6Lw+/YN98A48+Cl9/bZ/FMGYMrF0LS5dCSYldJybGjsg6+eTm91VUZIORBguljlkaMI6Q2+sm428Z5O/NB2zW1xMTT6RgQ1eKEmZwS+YTTLr+vkPap4iwdOk5lJcvZujQtYSGph5ZIb/7zgaO77+3I6+ys/dN/fpBRMSR7V8pdUzQXFJH6LMNn5G/N5+JF0wkJTKFFfkr+HThCtZ5V9An9DxeuPY3h7xPYww9ekxk4cL+bNo0gV69Jh9ZIU89Fb744sj2oZRSh0ADRiNeXfIqqVGp3DLoFlxOF2d1GssLV8HJPeC7v9c91uKQRUX1IiPjbrZte5LOnW8mLm5E6xZcKaUCqL3cuNduFOy1D+u5rv91dQ+h+e1vobjY3j5xuMGi1vHHP0hYWAbr1t2Gz+dphRIrpVTb0ICxnynLp+Dxebgh+wbAPj518mT4zW9s18CRCgmJ5sQTn2Xv3qXs2PH/jnyHSinVRjRg7OfVJa+Sc1wOfVP7UlMDP/+5ffzDww+33jGSky8nIWEUmzc/SHX1rtbbsVJKBZAGjHp+2PkDS/OWcmP2jQA89RSsXg0vvNDy5223hO0A/wc+XxWbNv229XaslFIBpAGjnleXvEqoM5TxfcezYQM89phN8Hr++a1/rMjInnTpci95eW9QXDy79Q+glFKtTAOGX423hinLp3Bpr0tJiEjg3nvtw+WefTZwxzz++PsJCzuedet+js9XE7gDKaVUK9CA4Tdt7TR2V+7mxuwb8Xjgyy/h+uvhuOMCd0ynM5KePSdSUbGabdueDtyBlFKqFWjA8Ht16ascF3Mc53Y/l5Urbfbvg2XWaA1JSReSnHw5W7c+RmXlxsAfUCmlDpMGDGBX+S4+W/8Z1/e/HqfDWfcco+HD2+b4J574d4wJYd262+hIqVqUUh2LBgzgjaVv4BUvNw60o6PmzYPUVMjMbJvjh4dnkJn5R4qKplNQ8E7bHFQppQ7RMR8wRIRXl77KKV1OoWdST8AGjOHD2zaJa3r67URHD2LDhrtwu4vb7sBKKdVCx3zA2OveS7/Uftw66FYA9uyx2cLbqjmqljFOevZ8iZqafDZvfqBtD66UUi1wzCcfjA6NZuqVU+vef/+9fW2LDu/9xcbmkJ5+G7m5z9Op00+JjR3a9oVQSqkmBLSGYYwZbYxZa4zZYIyZ0MjyG4wxBcaYJf7pZ/WW/dQYs94//TSQ5axv3jybYDCnRdnhW19m5mOEhnZmzZob8Xorg1MIpZRqRMAChjHGCUwEzgf6AOONMX0aWfVtEcn2T6/4t00Efg8MA4YCvzfGJASqrPXNm2eTDEZHt8XRDhQSEsdJJ/2TiopVbNp0QIxVSqmgCWQNYyiwQUQ2iUgNMBW4pIXbngd8KSJ7RKQI+BIYHaBy1vH5bJNUW/df7C8paTTp6XeQm/sce/ZMD25hlFLKL5ABIx3YVu/9dv+8/V1hjFlmjHnXGNPlELfFGHOrMWahMWZhQUHBERV4zRr7WOxg9F/sr3v3J4mM7MOaNTdQU1MY7OIopVTQR0lNA7qJSH9sLeK1Q92BiEwSkRwRyUlJSTmiwsybZ1+DXcMAcDoj6N17Cm73btatu0Vv6FNKBV0gA0Yu0KXe+wz/vDoisltEqv1vXwEGt3TbQJg3DxISoEePQB+pZWJissnM/BOFhR+ya9cRPgNcKaWOUCADxgKghzEm0xgTClwNfFx/BWNM53pvxwCr/T9PB0YZYxL8nd2j/PMCau5cGDbsyB/D2pq6dLmb+PizWL/+V1RUbAh2cZRSx7CAnRpFxAPcjj3RrwbeEZGVxphHjTFj/KvdaYxZaYxZCtwJ3ODfdg/wGDboLAAe9c8LmNJSWLmyffRf1GeMg169XsPhcLF69U80DbpSKmhMR2obz8nJkYULFx7Wtl99BeecA9Onw6hRrVywVlBQ8D4rV15BRsZdnHji34JdHKVUB2GMWSQiLbrzrB01vgRXbYf30HZ6c3VKyuWkp9/J9u3PUlDwfrCLo5Q6BmnA8Js7F3r3hvj4YJekaSec8BQxMUNYs+YmKis3Bbs4SqljjAYMQMTWMNpb/8X+HI5Q+vR5B2MMK1dehc9XffCNlFKqlWjAADZuhN2728f9FwcTEdGNXr1epbx8ERs2/CbYxVFKHUM0YECbP2HvSCUnX0JGxt3s2DGR/Hx94JJSqm1owMA2R8XEQJ/GUiO2U927P0Fs7HDWrr2Z8vLlwS6OUuoYoAEDGzCGDgWnM9glaTmHw0WfPv/B6Yxh+fKLqanJC3aRlFId3DEfMKqrYfXqo6c5qr7w8Az69ZuG253PihWX4vVWBbtISqkO7JgPGGFhtsP7nnuCXZLDExMzmN6936S0dB5r196kSQqVUgFzzAcMgIiI9n3/xcGkpFxOZuafyc9/i61bHw12cZRSHdQx/0zvjqJr1/uoqFjDli2PEBHRk7S08cEuklKqg9GA0UEYYzjppJeoqtrEmjU3EhqaRkLCWcEullKqA9EmqQ7E4Qijb98PiIzswfLlF1Nc/F2wi6SU6kA0YHQwLlcSAwbMICwsg+XLL6C0dH6wi6SU6iA0YHRAoaFpZGd/jcuVwrJl51FWtiTYRVJKdQAaMDqosLB0srO/xumMYdmyc9m7d2Wwi6SUOsppwOjAwsOPZ8CArzHGxZIlZ1NauiDYRVJKHcUCGjCMMaONMWuNMRuMMRMaWX63MWaVMWaZMeYrY8zx9ZZ5jTFL/NPH+2+rWiYy8kQGDPgKhyOUH344ha1bH0fEG+xiKaWOQgELGMYYJzAROB/oA4w3xuyf3u8HIEdE+gPvAn+pt6xSRLL90xjUYYuK6k1OzlKSk69g8+YHWbLkTKqqtga7WEqpo0wgaxhDgQ0isklEaoCpwCX1VxCRmSJS4X87D8gIYHmOaS5XAn36vEWvXq9TXr6EBQv6k5f372AXSyl1FAlkwEgHttV7v90/ryk3A5/Vex9ujFlojJlnjLk0EAU81hhj6NTpOnJylhIV1ZfVq69h5cqrqKnJD3bRlFJHgXbR6W2MuRbIAZ6qN/t4EckBfgI8a4w5oYltb/UHloUFBQVtUNqjX0REJtnZ35CZ+TiFhR+xYEEW+flva+JCpVSzAhkwcoEu9d5n+Oc1YIw5B3gAGCMidQ+pFpFc/+smYBYwsLGDiMgkEckRkZyUlJTWK30H53CEcPzx95OTs5jw8ExWrbqalSuv1OdqKKWaFMiAsQDoYYzJNMaEAlcDDUY7GWMGAi9hg0V+vfkJxpgw/8/JwAhgVQDLesyKispi4MA5dO/+JLt3f8L8+X3YtesNrW0opQ4QsIAhIh7gdmA6sBp4R0RWGmMeNcbUjnp6CogG/rPf8NnewEJjzFJgJvCEiGjACBCHI4SuXX9LTs4SIiNPYs2a61m27DwqKzcFu2hKqXbEdKQryZycHFm4cGGwi3FUE/GxY8eLbNo0AREP3bo9QkbGr3E4XMEumlIqAIwxi/z9xQfVLjq9VfthjIP09F8ydOhqEhPPY9Om+1i0aAh79szQG/6UOsZpwFCNCgtLp2/fD8jKeh+3u4Bly85lzpzOrF17C7t3f4bPV33wnSilOhR9gJJqVkrKZSQmjmL37s8oLHyf/Py32bnzFZzOWJKSLiY19SoSE8/D4QgLdlGVUgGmAUMdlNMZRWrqlaSmXonPV01R0VcUFLxPYeGH5OdPwemMJTn5ElJTx5GQcC4OR2iwi6yUCgDt9FaHzedzU1z8Nfn571BY+D4eTzEhIfGkpFxJauo1xMefjjHa6qlUe3Yond4aMFSr8PlqKCqaQX7+WxQWfojXW05oaDppaeNJTb2aqKh+WvNQqh3SgKGCyuutoLDwY/Lz/yUWogAAAA0rSURBVM2ePZ9hb8lxEh7ejcjIHkRE9CQysiexsacQHT1AayFKBdGhBAztw1CtzumMJC3tatLSrsbt3s2ePZ9TUbGGiop1VFaup7j4W3y+vQCEhCSRkHAWCQnnkJBwDhER3YNceqVUUzRgqIByuZJIS7umwTwRobp6G8XF31BUNMPfif4fAEJDjyM2digxMcP8r0MICYkJRtGVUvvRgKHanDGG8PCudOp0HZ06XYeIUFGxluLirygpmUtZ2XwKCz+sXZvw8OMJDU0nLCzDP6UTEhKL17sXr7fc/7oXY5zExAwmNnYY4eHdMcYE9XMq1dFowFBBZ4whKqoXUVG9SE+/DQC3ew+lpfMpK/ueior11NTkUl6+iN27P8Lnq9pvDw6czmhEauqWuVzJxMQMJTZ2GDExQ4iJGUxoaGobfzKlOhYNGKpdcrkSSUoaTVLS6AbzRQSPZw9ebzlOZzQORxQORxjGGHw+D3v3rqCs7HtKS+20Z89ngB3YERaWQXT0YGJiBhISkoAxoTgcLowJxRgXIIi4EXHj89lXhyMUpzOOkJBYQkLicDpjCQ1NxeVK1RqMOuboKCnVoXk8pZSX/0BZ2aK6qbJyHbVB5HA5HFFERHQnPLw7EREnEB5+PCEhCYSExPunBH+tx+2v+VTj89Ug4vEHn0RcriSczojW+aBKHSYdJaWUX0hILPHxI4mPH1k3z+utxOer9J/Aa/w1ihqMcWCMC2NC/K8uRGrweErw/v/27i3GrqqO4/j3d/a5z4yFXqwFSju9cFOhXIKAlyBEg40RHzCgaIwh4QUjJiZK4y36pC8qD0Qh3kCJICjaEBWlEBIeBAoUKGClV1ps7dDrdHous8/5+7DXTE9HWnanM5zZM/9PsnPOXmefPet/Zs/8z1p777VaB4njA8TxQZrNndRqm6jXN1Orvca+fY+8RTdZOrlchUJhDuXyEqrVc8JyLtXq2Zg1qdU2h5+1iVptE2YtyuUzKZUWUiqdSbl8JsXiAqKoj3y+j1yu6i0fN2k8YbgZJ4oqJ/TNvlQ67bivm7UZHt5LHO8Pyz7ieD+t1iBSgVyuFLrNikj5kHj2Mjy8JyxvUqttZGDgQeJ471v+jFyuSqWyBKnA4ODTDA+/eYzaJOdzoqgvPPaSz/eF7rsK7XaNOB4MFwsM0moNkcsVyeWqRFEPUVQN3XzFkDiPLPn8rI4LD86gVFpIFPV0xLGHON5DHB8E2pi1SVpyBkSUSqdRKi0MSe49SBFxfIDBwedC628tQ0MvUCotYs6clcyevZJqddkxP3MwpOi4v5t2e5hmcxfF4gJyOf93d7L8E3TuJEk5isW5FItzT3pfzeZAuGflX+RyRcrlpVQqS8M/2CMth1brMI3Gdur112k2d3UkgMGQEAbD1WNJcmg03qDVOkwUVYmiPorF+UTRMqKoitkwrdZhWq0h2u3DNJs7Q1daHJYWZsPE8T5arUMnHSOAlKdQmEuzuWu0rFRaRG/vBRw+vIGNG28FbqVSWc7s2SspFObSaGyjXt9Kvb6Nen0bANXqufT0vG90KRRO5dChF0I35PMMDa3HrIGUD92Hy6lWz6Jc7qfdro0m7CTZ7aXdrod4j8ReKJxKudwf3t9PudwfWnU9YekNXwaEmYXuxyOt2OQLQzksJaQcZjb6uSat3BjIhURdCMvxW4ojP6vVOki7XadcPnNCfjfH4+cwnHOpmBmt1kEajR3U69tpNHbQbg+Rz8+hUDiyRNGscPd+LvzTE2YxjcYbo0mu0dhOs7mTSmUpfX2X0Nt78VEJt1bbxJ49f2Xv3r+wf//jtNt1CoX5lMuLKZcXUS4vBoyhoZcZGlpPo/H6UXXN52fT13cRvb0XUi4vodHYTq3279GbR9vtGgBSkUJhblhmk8tVQqslCi2rHMPDb1Kvb6Fe3w4ca06YiFyukLJrMjrOfsbusxiSTGm0pWoWE8cHabUOYjYMQLG4gCuu+E+Kff6/KTM0iKRrgNtJPqGfm9kPxrxeAu4BLgb2ANeb2dbw2irgJpJP9itm9sjb/TxPGM5NP61WHbDjdiPG8QGGhl4hjvfS0/N+SqWFx/yGnnQhDpDLJS2EtOd82u04JLwtNJu7abc77wM6FK6qq4wuUVRBKo5e7n1kaSJFobtypEWRx6zdcZHEyGMTs0ZotTQwawIR+Xxy5V4UvStcRDGH+fNvGMenO0VOeitJ03cAHwN2AM9IWj1mbu6bgH1mtkzSDcAPgeslnQfcALwXOA14VNJZ5lO+OTfjRFH5bbfJ52cxa9blqfaXdCHOP+F65HJ5KpV+KpX+E37vdDGZo75dCmw0s82WpMX7gGvHbHMtcHd4/iBwtZJ0fy1wn5k1zGwLsDHszznnXJdMZsI4Hdjesb4jlL3lNpac9TkAzEn5Xuecc++gzI8rLelmSWslrR0YGOh2dZxzbtqazITxBrCwY/2MUPaW20jKA7NITn6neS8AZnaXmV1iZpfMmzdvgqrunHNurMlMGM8AyyX1SyqSnMRePWab1cAXw/PrgMcsuWxrNXCDpJKkfmA58PQk1tU559zbmLSrpMwslvRl4BGSy2p/aWYvS/o+sNbMVgO/AH4jaSOwlySpELb7PfAKEAO3+BVSzjnXXX7jnnPOzWAnch9G5k96O+ece2dMqxaGpAFg2zjfPhc41ohuWTOdYgGPZyqbTrHA9IonbSyLzCzVFUPTKmGcDElr0zbLprrpFAt4PFPZdIoFplc8kxGLd0k555xLxROGc865VDxhHHFXtyswgaZTLODxTGXTKRaYXvFMeCx+DsM551wq3sJwzjmXyoxPGJKukbRB0kZJt3W7PidK0i8l7Za0vqNstqR/SHotPJ7azTqmJWmhpMclvSLpZUm3hvKsxlOW9LSkF0I83wvl/ZKeCsfc/WHonEyQFEl6XtLDYT3LsWyV9JKkdZLWhrJMHmsAkk6R9KCkf0l6VdLlEx3PjE4YHZM8fQI4D/hsmLwpS34NXDOm7DZgjZktB9aE9SyIga+Z2XnAZcAt4feR1XgawFVmdgGwArhG0mUkE4X92MyWAftIJhLLiluBVzvWsxwLwEfNbEXH5adZPdYgmd30b2Z2DnABye9pYuNJJiOfmQtwOfBIx/oqYFW36zWOOBYD6zvWNwALwvMFwIZu13Gccf2ZZMbGzMcDVIHngA+Q3EyVD+VHHYNTeSEZNXoNcBXwMKCsxhLquxWYO6Ysk8cayUjfWwjnpScrnhndwmD6TtQ038x2hue7gBOfj7LLJC0GLgSeIsPxhC6cdcBu4B/AJmC/JROGQbaOuZ8AXwfaYX0O2Y0FwIC/S3pW0s2hLKvHWj8wAPwqdBn+XFIPExzPTE8Y054lXy0ydSmcpF7gD8BXzexg52tZi8fMWma2guTb+aXAOV2u0rhI+iSw28ye7XZdJtCHzOwiki7pWyR9pPPFjB1reeAi4KdmdiEwxJjup4mIZ6YnjNQTNWXMfyUtAAiPu7tcn9QkFUiSxb1m9sdQnNl4RpjZfuBxkm6bU8KEYZCdY+6DwKckbQXuI+mWup1sxgKAmb0RHncDD5Ek9KweazuAHWb2VFh/kCSBTGg8Mz1hpJnkKYs6J6b6Ism5gClPkkjmSHnVzH7U8VJW45kn6ZTwvEJyPuZVksRxXdgsE/GY2SozO8PMFpP8nTxmZjeSwVgAJPVI6ht5DnwcWE9GjzUz2wVsl3R2KLqaZD6hiY2n2ydrur0AK4F/k/Qtf7Pb9RlH/X8H7ASGSb5l3ETSt7wGeA14FJjd7XqmjOVDJE3mF4F1YVmZ4XjOB54P8awHvhPKl5DMILkReAAodbuuJxjXlcDDWY4l1PuFsLw88ref1WMt1H0FsDYcb38CTp3oePxOb+ecc6nM9C4p55xzKXnCcM45l4onDOecc6l4wnDOOZeKJwznnHOpeMJwbgqQdOXICLDOTVWeMJxzzqXiCcO5EyDp82GOi3WS7gyDCx6S9OMw58UaSfPCtisk/VPSi5IeGpmLQNIySY+GeTKek7Q07L63Yz6De8Od785NGZ4wnEtJ0rnA9cAHLRlQsAXcCPQAa83svcATwHfDW+4BvmFm5wMvdZTfC9xhyTwZV5DcqQ/J6LxfJZmbZQnJ+E3OTRn5t9/EORdcDVwMPBO+/FdIBnNrA/eHbX4L/FHSLOAUM3silN8NPBDGLzrdzB4CMLM6QNjf02a2I6yvI5nn5MnJD8u5dDxhOJeegLvNbNVRhdK3x2w33vF2Gh3PW/jfp5tivEvKufTWANdJejeMzv+8iOTvaGTE1s8BT5rZAWCfpA+H8i8AT5jZILBD0qfDPkqSqu9oFM6Nk3+DcS4lM3tF0rdIZmnLkYwQfAvJZDWXhtd2k5zngGQ46Z+FhLAZ+FIo/wJwp6Tvh3185h0Mw7lx89FqnTtJkg6ZWW+36+HcZPMuKeecc6l4C8M551wq3sJwzjmXiicM55xzqXjCcM45l4onDOecc6l4wnDOOZeKJwznnHOp/A/VeDqRpWULcAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.7859 - acc: 0.7701\n",
      "Loss: 0.7858693222390528 Accuracy: 0.77009344\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9821 - acc: 0.3528\n",
      "Epoch 00001: val_loss improved from inf to 1.36695, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_6_conv_checkpoint/001-1.3669.hdf5\n",
      "36805/36805 [==============================] - 43s 1ms/sample - loss: 1.9820 - acc: 0.3528 - val_loss: 1.3669 - val_acc: 0.5805\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3300 - acc: 0.5779\n",
      "Epoch 00002: val_loss improved from 1.36695 to 1.12111, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_6_conv_checkpoint/002-1.1211.hdf5\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 1.3300 - acc: 0.5778 - val_loss: 1.1211 - val_acc: 0.6664\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0737 - acc: 0.6666\n",
      "Epoch 00003: val_loss improved from 1.12111 to 0.91774, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_6_conv_checkpoint/003-0.9177.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 1.0737 - acc: 0.6665 - val_loss: 0.9177 - val_acc: 0.7126\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8667 - acc: 0.7358\n",
      "Epoch 00004: val_loss improved from 0.91774 to 0.75915, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_6_conv_checkpoint/004-0.7591.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.8668 - acc: 0.7357 - val_loss: 0.7591 - val_acc: 0.7738\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7229 - acc: 0.7818\n",
      "Epoch 00005: val_loss improved from 0.75915 to 0.66556, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_6_conv_checkpoint/005-0.6656.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.7228 - acc: 0.7819 - val_loss: 0.6656 - val_acc: 0.8081\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6292 - acc: 0.8108\n",
      "Epoch 00006: val_loss improved from 0.66556 to 0.61569, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_6_conv_checkpoint/006-0.6157.hdf5\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.6296 - acc: 0.8108 - val_loss: 0.6157 - val_acc: 0.8265\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5664 - acc: 0.8290\n",
      "Epoch 00007: val_loss improved from 0.61569 to 0.54796, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_6_conv_checkpoint/007-0.5480.hdf5\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.5665 - acc: 0.8290 - val_loss: 0.5480 - val_acc: 0.8418\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4975 - acc: 0.8487\n",
      "Epoch 00008: val_loss improved from 0.54796 to 0.45728, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_6_conv_checkpoint/008-0.4573.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.4975 - acc: 0.8487 - val_loss: 0.4573 - val_acc: 0.8742\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4506 - acc: 0.8637\n",
      "Epoch 00009: val_loss improved from 0.45728 to 0.43094, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_6_conv_checkpoint/009-0.4309.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.4506 - acc: 0.8637 - val_loss: 0.4309 - val_acc: 0.8782\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4079 - acc: 0.8790\n",
      "Epoch 00010: val_loss did not improve from 0.43094\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.4079 - acc: 0.8790 - val_loss: 0.4451 - val_acc: 0.8772\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3786 - acc: 0.8858\n",
      "Epoch 00011: val_loss improved from 0.43094 to 0.41245, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_6_conv_checkpoint/011-0.4124.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.3786 - acc: 0.8858 - val_loss: 0.4124 - val_acc: 0.8849\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3460 - acc: 0.8946\n",
      "Epoch 00012: val_loss did not improve from 0.41245\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.3459 - acc: 0.8946 - val_loss: 0.4296 - val_acc: 0.8831\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3153 - acc: 0.9048\n",
      "Epoch 00013: val_loss improved from 0.41245 to 0.38361, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_6_conv_checkpoint/013-0.3836.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.3153 - acc: 0.9048 - val_loss: 0.3836 - val_acc: 0.8959\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2869 - acc: 0.9104\n",
      "Epoch 00014: val_loss did not improve from 0.38361\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.2871 - acc: 0.9104 - val_loss: 0.5440 - val_acc: 0.8502\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3008 - acc: 0.9069\n",
      "Epoch 00015: val_loss did not improve from 0.38361\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.3008 - acc: 0.9069 - val_loss: 0.4089 - val_acc: 0.8896\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2516 - acc: 0.9210\n",
      "Epoch 00016: val_loss improved from 0.38361 to 0.36971, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_6_conv_checkpoint/016-0.3697.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.2516 - acc: 0.9210 - val_loss: 0.3697 - val_acc: 0.9066\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2277 - acc: 0.9291\n",
      "Epoch 00017: val_loss did not improve from 0.36971\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.2277 - acc: 0.9291 - val_loss: 0.3738 - val_acc: 0.9052\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2165 - acc: 0.9321\n",
      "Epoch 00018: val_loss improved from 0.36971 to 0.33986, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_6_conv_checkpoint/018-0.3399.hdf5\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.2165 - acc: 0.9321 - val_loss: 0.3399 - val_acc: 0.9117\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1954 - acc: 0.9378\n",
      "Epoch 00019: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1954 - acc: 0.9378 - val_loss: 0.3572 - val_acc: 0.9082\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1800 - acc: 0.9427\n",
      "Epoch 00020: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.1800 - acc: 0.9428 - val_loss: 0.3839 - val_acc: 0.9043\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1686 - acc: 0.9465\n",
      "Epoch 00021: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1688 - acc: 0.9464 - val_loss: 0.3679 - val_acc: 0.9113\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1615 - acc: 0.9485\n",
      "Epoch 00022: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.1615 - acc: 0.9485 - val_loss: 0.3693 - val_acc: 0.9096\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1482 - acc: 0.9536\n",
      "Epoch 00023: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1482 - acc: 0.9536 - val_loss: 0.3550 - val_acc: 0.9124\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9536\n",
      "Epoch 00024: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.1399 - acc: 0.9536 - val_loss: 0.3924 - val_acc: 0.8989\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9586\n",
      "Epoch 00025: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1279 - acc: 0.9586 - val_loss: 0.3886 - val_acc: 0.9138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9602\n",
      "Epoch 00026: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.1201 - acc: 0.9602 - val_loss: 0.3835 - val_acc: 0.9150\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9624\n",
      "Epoch 00027: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.1159 - acc: 0.9625 - val_loss: 0.3789 - val_acc: 0.9117\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9651\n",
      "Epoch 00028: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.1079 - acc: 0.9651 - val_loss: 0.3905 - val_acc: 0.9110\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9668\n",
      "Epoch 00029: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1041 - acc: 0.9667 - val_loss: 0.3968 - val_acc: 0.9217\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0992 - acc: 0.9678\n",
      "Epoch 00030: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0991 - acc: 0.9678 - val_loss: 0.4178 - val_acc: 0.9110\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9700\n",
      "Epoch 00031: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0909 - acc: 0.9699 - val_loss: 0.3968 - val_acc: 0.9154\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0906 - acc: 0.9705\n",
      "Epoch 00032: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0906 - acc: 0.9705 - val_loss: 0.4142 - val_acc: 0.9164\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9725\n",
      "Epoch 00033: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0842 - acc: 0.9725 - val_loss: 0.4308 - val_acc: 0.9045\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9744\n",
      "Epoch 00034: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0791 - acc: 0.9744 - val_loss: 0.4535 - val_acc: 0.9113\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0752 - acc: 0.9760\n",
      "Epoch 00035: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0752 - acc: 0.9760 - val_loss: 0.4541 - val_acc: 0.9101\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0750 - acc: 0.9754\n",
      "Epoch 00036: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0750 - acc: 0.9754 - val_loss: 0.3903 - val_acc: 0.9220\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0675 - acc: 0.9782\n",
      "Epoch 00037: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0675 - acc: 0.9782 - val_loss: 0.5245 - val_acc: 0.9026\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9775\n",
      "Epoch 00038: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0703 - acc: 0.9775 - val_loss: 0.4118 - val_acc: 0.9180\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9793\n",
      "Epoch 00039: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0647 - acc: 0.9793 - val_loss: 0.4395 - val_acc: 0.9154\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9810\n",
      "Epoch 00040: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0599 - acc: 0.9810 - val_loss: 0.4280 - val_acc: 0.9152\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9784\n",
      "Epoch 00041: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0656 - acc: 0.9784 - val_loss: 0.4172 - val_acc: 0.9189\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0647 - acc: 0.9795\n",
      "Epoch 00042: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0648 - acc: 0.9794 - val_loss: 0.4237 - val_acc: 0.9106\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9812\n",
      "Epoch 00043: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0588 - acc: 0.9812 - val_loss: 0.4268 - val_acc: 0.9178\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0550 - acc: 0.9824\n",
      "Epoch 00044: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0551 - acc: 0.9824 - val_loss: 0.4389 - val_acc: 0.9150\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9818\n",
      "Epoch 00045: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0552 - acc: 0.9819 - val_loss: 0.4493 - val_acc: 0.9196\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9839\n",
      "Epoch 00046: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0522 - acc: 0.9839 - val_loss: 0.4504 - val_acc: 0.9187\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9850\n",
      "Epoch 00047: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0477 - acc: 0.9850 - val_loss: 0.4347 - val_acc: 0.9206\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0533 - acc: 0.9835\n",
      "Epoch 00048: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0533 - acc: 0.9835 - val_loss: 0.4246 - val_acc: 0.9154\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9857\n",
      "Epoch 00049: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0464 - acc: 0.9857 - val_loss: 0.4306 - val_acc: 0.9178\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9823\n",
      "Epoch 00050: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0568 - acc: 0.9823 - val_loss: 0.4655 - val_acc: 0.9147\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9859\n",
      "Epoch 00051: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0445 - acc: 0.9859 - val_loss: 0.4558 - val_acc: 0.9199\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9851\n",
      "Epoch 00052: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0480 - acc: 0.9851 - val_loss: 0.4610 - val_acc: 0.9192\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9875\n",
      "Epoch 00053: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0411 - acc: 0.9875 - val_loss: 0.4543 - val_acc: 0.9182\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9859\n",
      "Epoch 00054: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0450 - acc: 0.9859 - val_loss: 0.4387 - val_acc: 0.9213\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9876\n",
      "Epoch 00055: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0420 - acc: 0.9876 - val_loss: 0.4310 - val_acc: 0.9259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9871\n",
      "Epoch 00056: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0425 - acc: 0.9871 - val_loss: 0.4356 - val_acc: 0.9252\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9878\n",
      "Epoch 00057: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0400 - acc: 0.9878 - val_loss: 0.4822 - val_acc: 0.9159\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0450 - acc: 0.9866\n",
      "Epoch 00058: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0450 - acc: 0.9866 - val_loss: 0.4559 - val_acc: 0.9236\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9882\n",
      "Epoch 00059: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0381 - acc: 0.9882 - val_loss: 0.4557 - val_acc: 0.9255\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9873\n",
      "Epoch 00060: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0395 - acc: 0.9873 - val_loss: 0.4352 - val_acc: 0.9194\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9877\n",
      "Epoch 00061: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0407 - acc: 0.9877 - val_loss: 0.4552 - val_acc: 0.9206\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0340 - acc: 0.9895\n",
      "Epoch 00062: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0340 - acc: 0.9895 - val_loss: 0.4621 - val_acc: 0.9248\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9895\n",
      "Epoch 00063: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0345 - acc: 0.9895 - val_loss: 0.4558 - val_acc: 0.9185\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0342 - acc: 0.9891\n",
      "Epoch 00064: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0342 - acc: 0.9891 - val_loss: 0.4952 - val_acc: 0.9194\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9876\n",
      "Epoch 00065: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0392 - acc: 0.9876 - val_loss: 0.4859 - val_acc: 0.9227\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9901\n",
      "Epoch 00066: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0326 - acc: 0.9901 - val_loss: 0.4727 - val_acc: 0.9208\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9889\n",
      "Epoch 00067: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0358 - acc: 0.9889 - val_loss: 0.4816 - val_acc: 0.9187\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9873\n",
      "Epoch 00068: val_loss did not improve from 0.33986\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0421 - acc: 0.9873 - val_loss: 0.4433 - val_acc: 0.9224\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.4116 - acc: 0.8802\n",
      "Loss: 0.41161584854125977 Accuracy: 0.8801662\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0531 - acc: 0.3255\n",
      "Epoch 00001: val_loss improved from inf to 1.30697, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/001-1.3070.hdf5\n",
      "36805/36805 [==============================] - 44s 1ms/sample - loss: 2.0530 - acc: 0.3255 - val_loss: 1.3070 - val_acc: 0.5980\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2685 - acc: 0.5896\n",
      "Epoch 00002: val_loss improved from 1.30697 to 1.00844, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/002-1.0084.hdf5\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 1.2685 - acc: 0.5896 - val_loss: 1.0084 - val_acc: 0.6879\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9365 - acc: 0.7050\n",
      "Epoch 00003: val_loss improved from 1.00844 to 0.65119, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/003-0.6512.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.9364 - acc: 0.7050 - val_loss: 0.6512 - val_acc: 0.8141\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7146 - acc: 0.7789\n",
      "Epoch 00004: val_loss improved from 0.65119 to 0.56025, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/004-0.5603.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.7145 - acc: 0.7790 - val_loss: 0.5603 - val_acc: 0.8365\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5720 - acc: 0.8236\n",
      "Epoch 00005: val_loss improved from 0.56025 to 0.43760, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/005-0.4376.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.5720 - acc: 0.8236 - val_loss: 0.4376 - val_acc: 0.8619\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4766 - acc: 0.8532\n",
      "Epoch 00006: val_loss improved from 0.43760 to 0.33226, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/006-0.3323.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.4766 - acc: 0.8532 - val_loss: 0.3323 - val_acc: 0.9064\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4098 - acc: 0.8713\n",
      "Epoch 00007: val_loss did not improve from 0.33226\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.4097 - acc: 0.8713 - val_loss: 0.3532 - val_acc: 0.9026\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3543 - acc: 0.8889\n",
      "Epoch 00008: val_loss improved from 0.33226 to 0.26534, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/008-0.2653.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.3542 - acc: 0.8889 - val_loss: 0.2653 - val_acc: 0.9229\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3269 - acc: 0.8980\n",
      "Epoch 00009: val_loss did not improve from 0.26534\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.3269 - acc: 0.8980 - val_loss: 0.2768 - val_acc: 0.9203\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3054 - acc: 0.9039\n",
      "Epoch 00010: val_loss improved from 0.26534 to 0.24757, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/010-0.2476.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.3054 - acc: 0.9039 - val_loss: 0.2476 - val_acc: 0.9329\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2749 - acc: 0.9126\n",
      "Epoch 00011: val_loss improved from 0.24757 to 0.24573, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/011-0.2457.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.2749 - acc: 0.9126 - val_loss: 0.2457 - val_acc: 0.9292\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2566 - acc: 0.9180\n",
      "Epoch 00012: val_loss improved from 0.24573 to 0.21392, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/012-0.2139.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2566 - acc: 0.9180 - val_loss: 0.2139 - val_acc: 0.9359\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2339 - acc: 0.9251\n",
      "Epoch 00013: val_loss did not improve from 0.21392\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.2339 - acc: 0.9251 - val_loss: 0.2363 - val_acc: 0.9334\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2163 - acc: 0.9319\n",
      "Epoch 00014: val_loss improved from 0.21392 to 0.20906, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/014-0.2091.hdf5\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.2162 - acc: 0.9319 - val_loss: 0.2091 - val_acc: 0.9436\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2035 - acc: 0.9360\n",
      "Epoch 00015: val_loss improved from 0.20906 to 0.19282, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/015-0.1928.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.2035 - acc: 0.9360 - val_loss: 0.1928 - val_acc: 0.9432\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1900 - acc: 0.9398\n",
      "Epoch 00016: val_loss did not improve from 0.19282\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1900 - acc: 0.9398 - val_loss: 0.2121 - val_acc: 0.9436\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1795 - acc: 0.9418- ETA: 0s - loss: 0.1797 - ac\n",
      "Epoch 00017: val_loss improved from 0.19282 to 0.18901, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/017-0.1890.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1795 - acc: 0.9418 - val_loss: 0.1890 - val_acc: 0.9443\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1700 - acc: 0.9446\n",
      "Epoch 00018: val_loss improved from 0.18901 to 0.18506, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/018-0.1851.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1701 - acc: 0.9446 - val_loss: 0.1851 - val_acc: 0.9490\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9479\n",
      "Epoch 00019: val_loss did not improve from 0.18506\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1621 - acc: 0.9479 - val_loss: 0.1869 - val_acc: 0.9509\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1479 - acc: 0.9507\n",
      "Epoch 00020: val_loss did not improve from 0.18506\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1479 - acc: 0.9507 - val_loss: 0.1906 - val_acc: 0.9478\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9542\n",
      "Epoch 00021: val_loss did not improve from 0.18506\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1370 - acc: 0.9542 - val_loss: 0.1908 - val_acc: 0.9490\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9552\n",
      "Epoch 00022: val_loss did not improve from 0.18506\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1332 - acc: 0.9553 - val_loss: 0.2031 - val_acc: 0.9462\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9582\n",
      "Epoch 00023: val_loss improved from 0.18506 to 0.17599, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/023-0.1760.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1241 - acc: 0.9582 - val_loss: 0.1760 - val_acc: 0.9539\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9599- ETA: 1s - loss: 0.121 - ETA: 0s - loss: 0.1206 - a\n",
      "Epoch 00024: val_loss did not improve from 0.17599\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1202 - acc: 0.9600 - val_loss: 0.1934 - val_acc: 0.9543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9627\n",
      "Epoch 00025: val_loss did not improve from 0.17599\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1101 - acc: 0.9627 - val_loss: 0.1933 - val_acc: 0.9492\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9650\n",
      "Epoch 00026: val_loss did not improve from 0.17599\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.1061 - acc: 0.9650 - val_loss: 0.1943 - val_acc: 0.9476\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9644\n",
      "Epoch 00027: val_loss improved from 0.17599 to 0.17357, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_7_conv_checkpoint/027-0.1736.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.1042 - acc: 0.9644 - val_loss: 0.1736 - val_acc: 0.9520\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9691\n",
      "Epoch 00028: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0931 - acc: 0.9691 - val_loss: 0.1908 - val_acc: 0.9509\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9701\n",
      "Epoch 00029: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0909 - acc: 0.9701 - val_loss: 0.1825 - val_acc: 0.9564\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0891 - acc: 0.9698\n",
      "Epoch 00030: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0891 - acc: 0.9698 - val_loss: 0.1893 - val_acc: 0.9550\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9738\n",
      "Epoch 00031: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0807 - acc: 0.9738 - val_loss: 0.1870 - val_acc: 0.9527\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9715\n",
      "Epoch 00032: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0855 - acc: 0.9715 - val_loss: 0.1757 - val_acc: 0.9583\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9739\n",
      "Epoch 00033: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0751 - acc: 0.9739 - val_loss: 0.1788 - val_acc: 0.9555\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9753\n",
      "Epoch 00034: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0735 - acc: 0.9753 - val_loss: 0.1888 - val_acc: 0.9553\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9766\n",
      "Epoch 00035: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0682 - acc: 0.9766 - val_loss: 0.2047 - val_acc: 0.9509\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0662 - acc: 0.9774\n",
      "Epoch 00036: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0663 - acc: 0.9774 - val_loss: 0.2128 - val_acc: 0.9518\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9746\n",
      "Epoch 00037: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0781 - acc: 0.9746 - val_loss: 0.1896 - val_acc: 0.9555\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9799\n",
      "Epoch 00038: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0590 - acc: 0.9799 - val_loss: 0.1915 - val_acc: 0.9555\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9796\n",
      "Epoch 00039: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0594 - acc: 0.9796 - val_loss: 0.1930 - val_acc: 0.9567\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0604 - acc: 0.9797\n",
      "Epoch 00040: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0604 - acc: 0.9797 - val_loss: 0.1873 - val_acc: 0.9569\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9804\n",
      "Epoch 00041: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0567 - acc: 0.9804 - val_loss: 0.1919 - val_acc: 0.9625\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9817\n",
      "Epoch 00042: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0562 - acc: 0.9817 - val_loss: 0.1850 - val_acc: 0.9576\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0501 - acc: 0.9829\n",
      "Epoch 00043: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0501 - acc: 0.9829 - val_loss: 0.2147 - val_acc: 0.9548\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9838\n",
      "Epoch 00044: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0494 - acc: 0.9838 - val_loss: 0.2020 - val_acc: 0.9564\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0492 - acc: 0.9832\n",
      "Epoch 00045: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0492 - acc: 0.9832 - val_loss: 0.2193 - val_acc: 0.9581\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9840\n",
      "Epoch 00046: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0480 - acc: 0.9840 - val_loss: 0.2118 - val_acc: 0.9550\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9844\n",
      "Epoch 00047: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0463 - acc: 0.9844 - val_loss: 0.2238 - val_acc: 0.9532\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0464 - acc: 0.9837\n",
      "Epoch 00048: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0464 - acc: 0.9837 - val_loss: 0.1868 - val_acc: 0.9576\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9863\n",
      "Epoch 00049: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0422 - acc: 0.9863 - val_loss: 0.1937 - val_acc: 0.9578\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9852\n",
      "Epoch 00050: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0424 - acc: 0.9852 - val_loss: 0.2129 - val_acc: 0.9548\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9871\n",
      "Epoch 00051: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 38s 1ms/sample - loss: 0.0387 - acc: 0.9871 - val_loss: 0.2146 - val_acc: 0.9590\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9863\n",
      "Epoch 00052: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0413 - acc: 0.9863 - val_loss: 0.1934 - val_acc: 0.9599\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9862\n",
      "Epoch 00053: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0382 - acc: 0.9863 - val_loss: 0.2042 - val_acc: 0.9574\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9863\n",
      "Epoch 00054: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0397 - acc: 0.9863 - val_loss: 0.2114 - val_acc: 0.9546\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0361 - acc: 0.9879\n",
      "Epoch 00055: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0361 - acc: 0.9879 - val_loss: 0.2268 - val_acc: 0.9576\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9895\n",
      "Epoch 00056: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0309 - acc: 0.9895 - val_loss: 0.2156 - val_acc: 0.9595\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0365 - acc: 0.9879\n",
      "Epoch 00057: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0365 - acc: 0.9879 - val_loss: 0.2012 - val_acc: 0.9609\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9886\n",
      "Epoch 00058: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0341 - acc: 0.9886 - val_loss: 0.2111 - val_acc: 0.9562\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0313 - acc: 0.9889\n",
      "Epoch 00059: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0313 - acc: 0.9889 - val_loss: 0.1871 - val_acc: 0.9597\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9895\n",
      "Epoch 00060: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0324 - acc: 0.9895 - val_loss: 0.2356 - val_acc: 0.9564\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9892\n",
      "Epoch 00061: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0328 - acc: 0.9892 - val_loss: 0.2253 - val_acc: 0.9539\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0363 - acc: 0.9875\n",
      "Epoch 00062: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0363 - acc: 0.9875 - val_loss: 0.2111 - val_acc: 0.9585\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9892\n",
      "Epoch 00063: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0300 - acc: 0.9892 - val_loss: 0.2228 - val_acc: 0.9611\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9899\n",
      "Epoch 00064: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0294 - acc: 0.9899 - val_loss: 0.2082 - val_acc: 0.9602\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9904\n",
      "Epoch 00065: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0281 - acc: 0.9904 - val_loss: 0.2082 - val_acc: 0.9583\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0273 - acc: 0.9910\n",
      "Epoch 00066: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0273 - acc: 0.9910 - val_loss: 0.2295 - val_acc: 0.9585\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9904\n",
      "Epoch 00067: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0287 - acc: 0.9904 - val_loss: 0.2136 - val_acc: 0.9590\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9900\n",
      "Epoch 00068: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0302 - acc: 0.9900 - val_loss: 0.2226 - val_acc: 0.9555\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9917\n",
      "Epoch 00069: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0258 - acc: 0.9917 - val_loss: 0.2368 - val_acc: 0.9578\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9907\n",
      "Epoch 00070: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0294 - acc: 0.9907 - val_loss: 0.2161 - val_acc: 0.9597\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9922\n",
      "Epoch 00071: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0236 - acc: 0.9922 - val_loss: 0.2107 - val_acc: 0.9592\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9910\n",
      "Epoch 00072: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0259 - acc: 0.9910 - val_loss: 0.2313 - val_acc: 0.9604\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9923\n",
      "Epoch 00073: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0239 - acc: 0.9923 - val_loss: 0.2078 - val_acc: 0.9623\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9921\n",
      "Epoch 00074: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 39s 1ms/sample - loss: 0.0236 - acc: 0.9921 - val_loss: 0.2162 - val_acc: 0.9592\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9924\n",
      "Epoch 00075: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0227 - acc: 0.9924 - val_loss: 0.2134 - val_acc: 0.9590\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9918\n",
      "Epoch 00076: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0244 - acc: 0.9918 - val_loss: 0.2357 - val_acc: 0.9569\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9917\n",
      "Epoch 00077: val_loss did not improve from 0.17357\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0252 - acc: 0.9917 - val_loss: 0.2388 - val_acc: 0.9576\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 0.2154 - acc: 0.9387\n",
      "Loss: 0.21535514052783217 Accuracy: 0.9387331\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.9251 - acc: 0.3698\n",
      "Epoch 00001: val_loss improved from inf to 1.01605, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/001-1.0160.hdf5\n",
      "36805/36805 [==============================] - 46s 1ms/sample - loss: 1.9249 - acc: 0.3699 - val_loss: 1.0160 - val_acc: 0.6867\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9931 - acc: 0.6819\n",
      "Epoch 00002: val_loss improved from 1.01605 to 0.63776, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/002-0.6378.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.9930 - acc: 0.6819 - val_loss: 0.6378 - val_acc: 0.7997\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6934 - acc: 0.7774\n",
      "Epoch 00003: val_loss improved from 0.63776 to 0.42839, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/003-0.4284.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.6934 - acc: 0.7774 - val_loss: 0.4284 - val_acc: 0.8698\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5361 - acc: 0.8305\n",
      "Epoch 00004: val_loss improved from 0.42839 to 0.31825, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/004-0.3182.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.5360 - acc: 0.8305 - val_loss: 0.3182 - val_acc: 0.9119\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4295 - acc: 0.8630\n",
      "Epoch 00005: val_loss improved from 0.31825 to 0.26540, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/005-0.2654.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.4295 - acc: 0.8630 - val_loss: 0.2654 - val_acc: 0.9208\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3684 - acc: 0.8845\n",
      "Epoch 00006: val_loss improved from 0.26540 to 0.22446, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/006-0.2245.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.3686 - acc: 0.8844 - val_loss: 0.2245 - val_acc: 0.9359\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3187 - acc: 0.8983\n",
      "Epoch 00007: val_loss improved from 0.22446 to 0.19694, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/007-0.1969.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.3187 - acc: 0.8982 - val_loss: 0.1969 - val_acc: 0.9406\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2795 - acc: 0.9113\n",
      "Epoch 00008: val_loss did not improve from 0.19694\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2795 - acc: 0.9113 - val_loss: 0.2143 - val_acc: 0.9324\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2502 - acc: 0.9210\n",
      "Epoch 00009: val_loss improved from 0.19694 to 0.16942, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/009-0.1694.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2502 - acc: 0.9209 - val_loss: 0.1694 - val_acc: 0.9476\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2305 - acc: 0.9274\n",
      "Epoch 00010: val_loss did not improve from 0.16942\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2304 - acc: 0.9274 - val_loss: 0.1897 - val_acc: 0.9376\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2101 - acc: 0.9329\n",
      "Epoch 00011: val_loss improved from 0.16942 to 0.16268, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/011-0.1627.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.2101 - acc: 0.9328 - val_loss: 0.1627 - val_acc: 0.9474\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1893 - acc: 0.9388\n",
      "Epoch 00012: val_loss improved from 0.16268 to 0.16044, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/012-0.1604.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1893 - acc: 0.9388 - val_loss: 0.1604 - val_acc: 0.9502\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1813 - acc: 0.9425\n",
      "Epoch 00013: val_loss improved from 0.16044 to 0.13265, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/013-0.1327.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1813 - acc: 0.9425 - val_loss: 0.1327 - val_acc: 0.9599\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1636 - acc: 0.9462\n",
      "Epoch 00014: val_loss improved from 0.13265 to 0.12438, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/014-0.1244.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1636 - acc: 0.9462 - val_loss: 0.1244 - val_acc: 0.9637\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9483\n",
      "Epoch 00015: val_loss did not improve from 0.12438\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1602 - acc: 0.9483 - val_loss: 0.1255 - val_acc: 0.9623\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9527\n",
      "Epoch 00016: val_loss did not improve from 0.12438\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1425 - acc: 0.9527 - val_loss: 0.1288 - val_acc: 0.9620\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1353 - acc: 0.9562\n",
      "Epoch 00017: val_loss did not improve from 0.12438\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1353 - acc: 0.9562 - val_loss: 0.1321 - val_acc: 0.9599\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9584\n",
      "Epoch 00018: val_loss did not improve from 0.12438\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1277 - acc: 0.9584 - val_loss: 0.1280 - val_acc: 0.9618\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1177 - acc: 0.9599\n",
      "Epoch 00019: val_loss did not improve from 0.12438\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1177 - acc: 0.9599 - val_loss: 0.1578 - val_acc: 0.9525\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9620\n",
      "Epoch 00020: val_loss did not improve from 0.12438\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1106 - acc: 0.9620 - val_loss: 0.1375 - val_acc: 0.9592\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9661\n",
      "Epoch 00021: val_loss improved from 0.12438 to 0.12240, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/021-0.1224.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.1031 - acc: 0.9661 - val_loss: 0.1224 - val_acc: 0.9630\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0990 - acc: 0.9681\n",
      "Epoch 00022: val_loss did not improve from 0.12240\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0990 - acc: 0.9681 - val_loss: 0.1392 - val_acc: 0.9646\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0942 - acc: 0.9681\n",
      "Epoch 00023: val_loss did not improve from 0.12240\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0942 - acc: 0.9681 - val_loss: 0.1341 - val_acc: 0.9623\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9701\n",
      "Epoch 00024: val_loss improved from 0.12240 to 0.12018, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/024-0.1202.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0885 - acc: 0.9701 - val_loss: 0.1202 - val_acc: 0.9683\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9711\n",
      "Epoch 00025: val_loss did not improve from 0.12018\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0847 - acc: 0.9711 - val_loss: 0.1338 - val_acc: 0.9613\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9734\n",
      "Epoch 00026: val_loss improved from 0.12018 to 0.11179, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_8_conv_checkpoint/026-0.1118.hdf5\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0788 - acc: 0.9734 - val_loss: 0.1118 - val_acc: 0.9697\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9734\n",
      "Epoch 00027: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0780 - acc: 0.9734 - val_loss: 0.1222 - val_acc: 0.9690\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9769\n",
      "Epoch 00028: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0699 - acc: 0.9769 - val_loss: 0.1296 - val_acc: 0.9639\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9768\n",
      "Epoch 00029: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0691 - acc: 0.9768 - val_loss: 0.1216 - val_acc: 0.9674\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9767\n",
      "Epoch 00030: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0671 - acc: 0.9767 - val_loss: 0.1275 - val_acc: 0.9674\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9777\n",
      "Epoch 00031: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0646 - acc: 0.9777 - val_loss: 0.1131 - val_acc: 0.9734\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9804\n",
      "Epoch 00032: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0582 - acc: 0.9804 - val_loss: 0.1231 - val_acc: 0.9693\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9809\n",
      "Epoch 00033: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0564 - acc: 0.9809 - val_loss: 0.1255 - val_acc: 0.9681\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9810\n",
      "Epoch 00034: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0560 - acc: 0.9810 - val_loss: 0.1347 - val_acc: 0.9665\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0507 - acc: 0.9834\n",
      "Epoch 00035: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0507 - acc: 0.9834 - val_loss: 0.1335 - val_acc: 0.9681\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9830\n",
      "Epoch 00036: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0516 - acc: 0.9830 - val_loss: 0.1258 - val_acc: 0.9683\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9838\n",
      "Epoch 00037: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0482 - acc: 0.9838 - val_loss: 0.1406 - val_acc: 0.9653\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9843\n",
      "Epoch 00038: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0458 - acc: 0.9843 - val_loss: 0.1341 - val_acc: 0.9653\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9852\n",
      "Epoch 00039: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0436 - acc: 0.9852 - val_loss: 0.1426 - val_acc: 0.9674\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9860\n",
      "Epoch 00040: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0416 - acc: 0.9860 - val_loss: 0.1236 - val_acc: 0.9669\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9863\n",
      "Epoch 00041: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0419 - acc: 0.9863 - val_loss: 0.1321 - val_acc: 0.9686\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9853\n",
      "Epoch 00042: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0433 - acc: 0.9853 - val_loss: 0.1322 - val_acc: 0.9676\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9877\n",
      "Epoch 00043: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0371 - acc: 0.9877 - val_loss: 0.1309 - val_acc: 0.9713\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0343 - acc: 0.9887\n",
      "Epoch 00044: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0343 - acc: 0.9888 - val_loss: 0.1375 - val_acc: 0.9690\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9865\n",
      "Epoch 00045: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0386 - acc: 0.9866 - val_loss: 0.1346 - val_acc: 0.9690\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9875\n",
      "Epoch 00046: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0364 - acc: 0.9875 - val_loss: 0.1363 - val_acc: 0.9674\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9882\n",
      "Epoch 00047: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0347 - acc: 0.9882 - val_loss: 0.1382 - val_acc: 0.9709\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9891\n",
      "Epoch 00048: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0335 - acc: 0.9891 - val_loss: 0.1222 - val_acc: 0.9720\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0314 - acc: 0.9896\n",
      "Epoch 00049: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0314 - acc: 0.9896 - val_loss: 0.1720 - val_acc: 0.9627\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9895\n",
      "Epoch 00050: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0337 - acc: 0.9895 - val_loss: 0.1300 - val_acc: 0.9704\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9893\n",
      "Epoch 00051: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0311 - acc: 0.9893 - val_loss: 0.1284 - val_acc: 0.9718\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0274 - acc: 0.9910\n",
      "Epoch 00052: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0274 - acc: 0.9910 - val_loss: 0.1443 - val_acc: 0.9700\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0301 - acc: 0.9900\n",
      "Epoch 00053: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0301 - acc: 0.9900 - val_loss: 0.1429 - val_acc: 0.9695\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9909\n",
      "Epoch 00054: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0271 - acc: 0.9909 - val_loss: 0.1477 - val_acc: 0.9693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9925\n",
      "Epoch 00055: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0237 - acc: 0.9925 - val_loss: 0.1411 - val_acc: 0.9681\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9906\n",
      "Epoch 00056: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0280 - acc: 0.9906 - val_loss: 0.1316 - val_acc: 0.9676\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9913\n",
      "Epoch 00057: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0260 - acc: 0.9913 - val_loss: 0.1454 - val_acc: 0.9693\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9911\n",
      "Epoch 00058: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0260 - acc: 0.9911 - val_loss: 0.1491 - val_acc: 0.9681\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0270 - acc: 0.9918\n",
      "Epoch 00059: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0270 - acc: 0.9918 - val_loss: 0.1407 - val_acc: 0.9690\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0209 - acc: 0.9930\n",
      "Epoch 00060: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0209 - acc: 0.9930 - val_loss: 0.1530 - val_acc: 0.9718\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0245 - acc: 0.9919\n",
      "Epoch 00061: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0245 - acc: 0.9919 - val_loss: 0.1330 - val_acc: 0.9725\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9920\n",
      "Epoch 00062: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0252 - acc: 0.9920 - val_loss: 0.1385 - val_acc: 0.9706\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9926\n",
      "Epoch 00063: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0225 - acc: 0.9926 - val_loss: 0.1505 - val_acc: 0.9711\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9924\n",
      "Epoch 00064: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0230 - acc: 0.9924 - val_loss: 0.1552 - val_acc: 0.9713\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9915\n",
      "Epoch 00065: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0242 - acc: 0.9915 - val_loss: 0.1464 - val_acc: 0.9665\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9932\n",
      "Epoch 00066: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0220 - acc: 0.9932 - val_loss: 0.1548 - val_acc: 0.9686\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9939\n",
      "Epoch 00067: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0185 - acc: 0.9939 - val_loss: 0.1294 - val_acc: 0.9711\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9939\n",
      "Epoch 00068: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0178 - acc: 0.9939 - val_loss: 0.1787 - val_acc: 0.9672\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9937\n",
      "Epoch 00069: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0186 - acc: 0.9938 - val_loss: 0.1576 - val_acc: 0.9688\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9936\n",
      "Epoch 00070: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0192 - acc: 0.9936 - val_loss: 0.1453 - val_acc: 0.9709\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9931\n",
      "Epoch 00071: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0208 - acc: 0.9931 - val_loss: 0.1643 - val_acc: 0.9686\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9950\n",
      "Epoch 00072: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0154 - acc: 0.9950 - val_loss: 0.1760 - val_acc: 0.9667\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9930\n",
      "Epoch 00073: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0223 - acc: 0.9930 - val_loss: 0.1640 - val_acc: 0.9695\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9944\n",
      "Epoch 00074: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0162 - acc: 0.9944 - val_loss: 0.1727 - val_acc: 0.9688\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0183 - acc: 0.9943\n",
      "Epoch 00075: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0183 - acc: 0.9943 - val_loss: 0.1582 - val_acc: 0.9713\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9944\n",
      "Epoch 00076: val_loss did not improve from 0.11179\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0157 - acc: 0.9944 - val_loss: 0.1634 - val_acc: 0.9711\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.1628 - acc: 0.9543\n",
      "Loss: 0.16284374764280032 Accuracy: 0.95430946\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6425 - acc: 0.4671\n",
      "Epoch 00001: val_loss improved from inf to 0.81307, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_9_conv_checkpoint/001-0.8131.hdf5\n",
      "36805/36805 [==============================] - 47s 1ms/sample - loss: 1.6425 - acc: 0.4671 - val_loss: 0.8131 - val_acc: 0.7321\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7607 - acc: 0.7514\n",
      "Epoch 00002: val_loss improved from 0.81307 to 0.51611, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_9_conv_checkpoint/002-0.5161.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.7607 - acc: 0.7514 - val_loss: 0.5161 - val_acc: 0.8293\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5146 - acc: 0.8352\n",
      "Epoch 00003: val_loss improved from 0.51611 to 0.34357, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_9_conv_checkpoint/003-0.3436.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.5146 - acc: 0.8352 - val_loss: 0.3436 - val_acc: 0.8917\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3835 - acc: 0.8758\n",
      "Epoch 00004: val_loss improved from 0.34357 to 0.25581, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_9_conv_checkpoint/004-0.2558.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3835 - acc: 0.8758 - val_loss: 0.2558 - val_acc: 0.9159\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3060 - acc: 0.9016\n",
      "Epoch 00005: val_loss improved from 0.25581 to 0.20710, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_9_conv_checkpoint/005-0.2071.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.3061 - acc: 0.9016 - val_loss: 0.2071 - val_acc: 0.9383\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2611 - acc: 0.9151\n",
      "Epoch 00006: val_loss improved from 0.20710 to 0.19491, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_9_conv_checkpoint/006-0.1949.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2611 - acc: 0.9151 - val_loss: 0.1949 - val_acc: 0.9345\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2213 - acc: 0.9290\n",
      "Epoch 00007: val_loss improved from 0.19491 to 0.18998, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_9_conv_checkpoint/007-0.1900.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.2213 - acc: 0.9290 - val_loss: 0.1900 - val_acc: 0.9394\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1962 - acc: 0.9363\n",
      "Epoch 00008: val_loss improved from 0.18998 to 0.15852, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_9_conv_checkpoint/008-0.1585.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1962 - acc: 0.9363 - val_loss: 0.1585 - val_acc: 0.9515\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1794 - acc: 0.9421\n",
      "Epoch 00009: val_loss improved from 0.15852 to 0.15102, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_9_conv_checkpoint/009-0.1510.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1794 - acc: 0.9421 - val_loss: 0.1510 - val_acc: 0.9534\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9473\n",
      "Epoch 00010: val_loss did not improve from 0.15102\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1604 - acc: 0.9473 - val_loss: 0.1583 - val_acc: 0.9497\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9547\n",
      "Epoch 00011: val_loss improved from 0.15102 to 0.12534, saving model to model/checkpoint/1D_CNN_custom_ch_128_DO_9_conv_checkpoint/011-0.1253.hdf5\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1375 - acc: 0.9547 - val_loss: 0.1253 - val_acc: 0.9623\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1200 - acc: 0.9593\n",
      "Epoch 00012: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1200 - acc: 0.9593 - val_loss: 0.1366 - val_acc: 0.9588\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1136 - acc: 0.9635\n",
      "Epoch 00013: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1136 - acc: 0.9635 - val_loss: 0.1319 - val_acc: 0.9569\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9670\n",
      "Epoch 00014: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.1006 - acc: 0.9670 - val_loss: 0.1327 - val_acc: 0.9625\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9669\n",
      "Epoch 00015: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0984 - acc: 0.9669 - val_loss: 0.1480 - val_acc: 0.9576\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9712\n",
      "Epoch 00016: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0833 - acc: 0.9712 - val_loss: 0.1530 - val_acc: 0.9564\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0814 - acc: 0.9724\n",
      "Epoch 00017: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0814 - acc: 0.9724 - val_loss: 0.1524 - val_acc: 0.9581\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9768\n",
      "Epoch 00018: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0708 - acc: 0.9769 - val_loss: 0.1436 - val_acc: 0.9590\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0663 - acc: 0.9780\n",
      "Epoch 00019: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0663 - acc: 0.9780 - val_loss: 0.1334 - val_acc: 0.9606\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9775\n",
      "Epoch 00020: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0671 - acc: 0.9775 - val_loss: 0.1265 - val_acc: 0.9646\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9793\n",
      "Epoch 00021: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0609 - acc: 0.9794 - val_loss: 0.1288 - val_acc: 0.9620\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9832\n",
      "Epoch 00022: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0504 - acc: 0.9831 - val_loss: 0.1463 - val_acc: 0.9644\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9820\n",
      "Epoch 00023: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0556 - acc: 0.9819 - val_loss: 0.1270 - val_acc: 0.9625\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0514 - acc: 0.9828\n",
      "Epoch 00024: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0513 - acc: 0.9828 - val_loss: 0.1396 - val_acc: 0.9681\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9859\n",
      "Epoch 00025: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0429 - acc: 0.9859 - val_loss: 0.1454 - val_acc: 0.9683\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9859\n",
      "Epoch 00026: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0432 - acc: 0.9859 - val_loss: 0.1349 - val_acc: 0.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9858\n",
      "Epoch 00027: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0420 - acc: 0.9858 - val_loss: 0.1442 - val_acc: 0.9632\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9867\n",
      "Epoch 00028: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0389 - acc: 0.9867 - val_loss: 0.1789 - val_acc: 0.9597\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9871\n",
      "Epoch 00029: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0376 - acc: 0.9871 - val_loss: 0.1621 - val_acc: 0.9646\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9889\n",
      "Epoch 00030: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0339 - acc: 0.9889 - val_loss: 0.1528 - val_acc: 0.9662\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0370 - acc: 0.9879\n",
      "Epoch 00031: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0370 - acc: 0.9879 - val_loss: 0.1575 - val_acc: 0.9658\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9895\n",
      "Epoch 00032: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0327 - acc: 0.9895 - val_loss: 0.1754 - val_acc: 0.9604\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9889\n",
      "Epoch 00033: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0318 - acc: 0.9889 - val_loss: 0.1390 - val_acc: 0.9681\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0292 - acc: 0.9901\n",
      "Epoch 00034: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0292 - acc: 0.9901 - val_loss: 0.1559 - val_acc: 0.9641\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9904\n",
      "Epoch 00035: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0304 - acc: 0.9904 - val_loss: 0.1722 - val_acc: 0.9616\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9908\n",
      "Epoch 00036: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0289 - acc: 0.9908 - val_loss: 0.1722 - val_acc: 0.9634\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0265 - acc: 0.9921\n",
      "Epoch 00037: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0265 - acc: 0.9921 - val_loss: 0.1783 - val_acc: 0.9646\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0277 - acc: 0.9913\n",
      "Epoch 00038: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0277 - acc: 0.9913 - val_loss: 0.1710 - val_acc: 0.9665\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9920\n",
      "Epoch 00039: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0241 - acc: 0.9920 - val_loss: 0.1663 - val_acc: 0.9653\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9917\n",
      "Epoch 00040: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0250 - acc: 0.9917 - val_loss: 0.1547 - val_acc: 0.9634\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9918\n",
      "Epoch 00041: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0259 - acc: 0.9918 - val_loss: 0.1638 - val_acc: 0.9695\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9931\n",
      "Epoch 00042: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0207 - acc: 0.9931 - val_loss: 0.1733 - val_acc: 0.9646\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9930\n",
      "Epoch 00043: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0216 - acc: 0.9930 - val_loss: 0.2107 - val_acc: 0.9590\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0241 - acc: 0.9924\n",
      "Epoch 00044: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0241 - acc: 0.9924 - val_loss: 0.1832 - val_acc: 0.9592\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9938\n",
      "Epoch 00045: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0190 - acc: 0.9938 - val_loss: 0.1816 - val_acc: 0.9620\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9934\n",
      "Epoch 00046: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0211 - acc: 0.9934 - val_loss: 0.1735 - val_acc: 0.9627\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9941\n",
      "Epoch 00047: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0196 - acc: 0.9941 - val_loss: 0.1774 - val_acc: 0.9658\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9949\n",
      "Epoch 00048: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0163 - acc: 0.9949 - val_loss: 0.1876 - val_acc: 0.9609\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9937\n",
      "Epoch 00049: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0192 - acc: 0.9937 - val_loss: 0.1585 - val_acc: 0.9667\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0192 - acc: 0.9935\n",
      "Epoch 00050: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0192 - acc: 0.9935 - val_loss: 0.1553 - val_acc: 0.9693\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0194 - acc: 0.9936\n",
      "Epoch 00051: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0194 - acc: 0.9936 - val_loss: 0.1885 - val_acc: 0.9641\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9951\n",
      "Epoch 00052: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0155 - acc: 0.9951 - val_loss: 0.1658 - val_acc: 0.9669\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9945\n",
      "Epoch 00053: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0177 - acc: 0.9945 - val_loss: 0.1631 - val_acc: 0.9700\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0171 - acc: 0.9943\n",
      "Epoch 00054: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0171 - acc: 0.9943 - val_loss: 0.1795 - val_acc: 0.9641\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9954\n",
      "Epoch 00055: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 0.0150 - acc: 0.9954 - val_loss: 0.1943 - val_acc: 0.9646\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0185 - acc: 0.9942\n",
      "Epoch 00056: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0185 - acc: 0.9942 - val_loss: 0.1901 - val_acc: 0.9630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9954\n",
      "Epoch 00057: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0148 - acc: 0.9954 - val_loss: 0.1945 - val_acc: 0.9602\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9955\n",
      "Epoch 00058: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0136 - acc: 0.9955 - val_loss: 0.2080 - val_acc: 0.9655\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0146 - acc: 0.9957\n",
      "Epoch 00059: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0146 - acc: 0.9957 - val_loss: 0.1959 - val_acc: 0.9665\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0149 - acc: 0.9955\n",
      "Epoch 00060: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 41s 1ms/sample - loss: 0.0149 - acc: 0.9955 - val_loss: 0.1589 - val_acc: 0.9655\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9954\n",
      "Epoch 00061: val_loss did not improve from 0.12534\n",
      "36805/36805 [==============================] - 42s 1ms/sample - loss: 0.0155 - acc: 0.9954 - val_loss: 0.1946 - val_acc: 0.9611\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3XmYHFXV+PHv6WX2fTLZt8lG9j0hvEAAEYwgCLIEBFFUeFVE+eGLBnBB5ZVFQUVBQEBBkUUQAeEVBROimAAhBghLMtkz2Wbft17O74/b3bNkZjJJpmcy6fN5nvt0d3V11amennvq1q26JaqKMcYYA+Dp7wCMMcYcOSwpGGOMibGkYIwxJsaSgjHGmBhLCsYYY2IsKRhjjImxpGCMMSbGkoIxxpgYSwrGGGNifP0dwMEaNGiQjh07tr/DMMaYAeWtt94qU9WCA8034JLC2LFjWbNmTX+HYYwxA4qIbO/JfHb4yBhjTIwlBWOMMTGWFIwxxsQMuD6FzgQCAYqLi2lqaurvUAaslJQURo4cid/v7+9QjDH96KhICsXFxWRmZjJ27FhEpL/DGXBUlfLycoqLiyksLOzvcIwx/eioOHzU1NREfn6+JYRDJCLk5+dbS8sYc3QkBcASwmGy788YA0dRUjiQUKiR5uZdhMOB/g7FGGOOWAmTFMLhJlpa9qDa+0mhqqqKe+6555A+e8YZZ1BVVdXj+W+66SZ+8pOfHNK6jDHmQBImKYi4TVUN9/qyu0sKwWCw28+++OKL5OTk9HpMxhhzKOKWFETkIREpEZH13cxzsoisE5H3ROTVeMXieCOPoV5f8rJly9i8eTOzZ8/muuuuY8WKFZx44omcffbZTJ06FYBzzjmHefPmMW3aNO6///7YZ8eOHUtZWRnbtm1jypQpXHHFFUybNo3TTz+dxsbGbte7bt06Fi1axMyZMzn33HOprKwE4K677mLq1KnMnDmTiy66CIBXX32V2bNnM3v2bObMmUNtbW2vfw/GmIEvnqek/hb4JfBIZ2+KSA5wD7BEVXeIyODeWGlR0TXU1a3r5J0woVA9Hk8qIge32RkZs5k48Wddvn/rrbeyfv161q1z612xYgVr165l/fr1sVM8H3roIfLy8mhsbGTBggWcd9555Ofnd4i9iMcee4xf//rXXHjhhTz99NNceumlXa73sssu4xe/+AUnnXQS3/3ud/n+97/Pz372M2699Va2bt1KcnJy7NDUT37yE+6++26OP/546urqSElJOajvwBiTGOLWUlDVlUBFN7N8GviTqu6IzF8Sr1ja0z5Zy8KFC9ud83/XXXcxa9YsFi1axM6dOykqKtrvM4WFhcyePRuAefPmsW3bti6XX11dTVVVFSeddBIAn/3sZ1m5ciUAM2fO5JJLLuH3v/89Pp9LgMcffzzXXnstd911F1VVVbHpxhjTVn/WDJMAv4isADKBn6tqV62KK4ErAUaPHt3tQrvaow+HA9TXv01y8miSknqlUdKt9PT02PMVK1bw8ssvs2rVKtLS0jj55JM7vSYgOTk59tzr9R7w8FFXXnjhBVauXMnzzz/P//7v//Luu++ybNkyzjzzTF588UWOP/54XnrpJSZPnnxIyzfGHL36s6PZB8wDzgQ+BnxHRCZ1NqOq3q+q81V1fkHBAYcD71RrR3Pv9ylkZmZ2e4y+urqa3Nxc0tLS+PDDD1m9evVhrzM7O5vc3Fz++c9/AvC73/2Ok046iXA4zM6dOznllFO47bbbqK6upq6ujs2bNzNjxgy+9a1vsWDBAj788MPDjsEYc/Tpz5ZCMVCuqvVAvYisBGYBG+Ozumj+6/2zj/Lz8zn++OOZPn06H//4xznzzDPbvb9kyRLuvfdepkyZwjHHHMOiRYt6Zb0PP/wwX/rSl2hoaGDcuHH85je/IRQKcemll1JdXY2q8rWvfY2cnBy+853vsHz5cjweD9OmTePjH/94r8RgjDm6iGr8jrGLyFjgL6o6vZP3puA6oj8GJAFvABepapdnKwHMnz9fO95k54MPPmDKlCkHjKe2di1+fwEpKaN6ugkJpaffozFm4BGRt1R1/oHmi1tLQUQeA04GBolIMfA9wA+gqveq6gci8lfgHdzu+wMHSgiHH5OXeJySaowxR4u4JQVVvbgH8/wY+HG8YtifNy59CsYYc7RImCuawXU2x+OKZmOMOVokXFKIR0ezMcYcLRIqKdjhI2OM6V5CJQU7fGSMMd1LqKTgBsU7MloKGRkZBzXdGGP6QkIlBWspGGNM9xIsKbiWQm9fsLds2TLuvvvu2OvojXDq6uo49dRTmTt3LjNmzODZZ5/t8TJVleuuu47p06czY8YMnnjiCQD27NnD4sWLmT17NtOnT+ef//wnoVCIz33uc7F5f/rTn/bq9hljEsfRN1TmNdfAus6GzgZ/uAWvNoM38+CWOXs2/KzrobOXLl3KNddcw1VXXQXAk08+yUsvvURKSgrPPPMMWVlZlJWVsWjRIs4+++we3Q/5T3/6E+vWrePtt9+mrKyMBQsWsHjxYv7whz/wsY99jBtvvJFQKERDQwPr1q1j165drF/vrv07mDu5GWNMW0dfUuiOSGTkbAV670b1c+bMoaSkhN27d1NaWkpubi6jRo0iEAhwww03sHLlSjweD7t27WLfvn0MHTr0gMv817/+xcUXX4zX62XIkCGcdNJJvPnmmyxYsIDPf/7zBAIBzjnnHGbPns24cePYsmULV199NWeeeSann356r22bMSaxHH1JoZs9+mBLGc3N20hPn4F4kruc71BccMEFPPXUU+zdu5elS5cC8Oijj1JaWspbb72F3+9n7NixnQ6ZfTAWL17MypUreeGFF/jc5z7Htddey2WXXcbbb7/NSy+9xL333suTTz7JQw891BubZYxJMAnWpxC/4bOXLl3K448/zlNPPcUFF1wAuCGzBw8ejN/vZ/ny5Wzfvr3HyzvxxBN54oknCIVClJaWsnLlShYuXMj27dsZMmQIV1xxBV/84hdZu3YtZWVlhMNhzjvvPG6++WbWrl3b69tnjEkMR19LoRuuo5m4nIE0bdo0amtrGTFiBMOGDQPgkksu4ayzzmLGjBnMnz//oG5qc+6557Jq1SpmzZqFiHD77bczdOhQHn74YX784x/j9/vJyMjgkUceYdeuXVx++eWEw267brnlll7fPmNMYojr0NnxcDhDZweDtTQ2biA1dRI+X1a8QhywbOhsY45ePR06O8EOH0VbCkfGBWzGGHOkSbCkEN1cSwrGGNOZuCUFEXlIREpEpNsb54jIAhEJisj58YqlVfz6FIwx5mgQz5bCb4El3c0g7njObcDf4hhHm/VFzz6ypGCMMZ2JW1JQ1ZVAxQFmuxp4GiiJVxzt2eEjY4zpTr/1KYjICOBc4Fd9uE7ABsUzxpiu9GdH88+Ab2kPamgRuVJE1ojImtLS0sNaaXRQvN5UVVXFPffcc0ifPeOMM2ysImPMEaM/k8J84HER2QacD9wjIud0NqOq3q+q81V1fkFBwWGutvdbCt0lhWAw2O1nX3zxRXJycno1HmOMOVT9lhRUtVBVx6rqWOAp4Cuq+ud4r1ek92/JuWzZMjZv3szs2bO57rrrWLFiBSeeeCJnn302U6dOBeCcc85h3rx5TJs2jfvvvz/22bFjx1JWVsa2bduYMmUKV1xxBdOmTeP000+nsbFxv3U9//zzHHvsscyZM4ePfvSj7Nu3D4C6ujouv/xyZsyYwcyZM3n66acB+Otf/8rcuXOZNWsWp556aq9utzHm6BO3YS5E5DHgZGCQiBQD3wP8AKp6b7zW283I2QCEw2MB8BxEOjzAyNnceuutrF+/nnWRFa9YsYK1a9eyfv16CgsLAXjooYfIy8ujsbGRBQsWcN5555Gfn99uOUVFRTz22GP8+te/5sILL+Tpp5/m0ksvbTfPCSecwOrVqxERHnjgAW6//XbuuOMOfvjDH5Kdnc27774LQGVlJaWlpVxxxRWsXLmSwsJCKioO1O9vjEl0cUsKqnrxQcz7uXjF0cX64r6OhQsXxhICwF133cUzzzwDwM6dOykqKtovKRQWFjJ79mwA5s2bx7Zt2/ZbbnFxMUuXLmXPnj20tLTE1vHyyy/z+OOPx+bLzc3l+eefZ/HixbF58vLyenUbjTFHn6NuQLzu9ugBGhv3EA43kp4+Pa5xpKenx56vWLGCl19+mVWrVpGWlsbJJ5/c6RDaycmtw3l7vd5ODx9dffXVXHvttZx99tmsWLGCm266KS7xG2MSU0INc+F4e72jOTMzk9ra2i7fr66uJjc3l7S0ND788ENWr159yOuqrq5mxIgRADz88MOx6aeddlq7W4JWVlayaNEiVq5cydatWwHs8JEx5oASLimIeHq9ozk/P5/jjz+e6dOnc9111+33/pIlSwgGg0yZMoVly5axaNGiQ17XTTfdxAUXXMC8efMYNGhQbPq3v/1tKisrmT59OrNmzWL58uUUFBRw//3386lPfYpZs2bFbv5jjDFdSaihswGam4tpadlHRsbcHt0rOZHY0NnGHL1s6OwueXH3aB5YydAYY/pCwiWFeN6S0xhjBrqESwrR4bPBxj8yxpiOEi4p2PDZxhjTtQRMCnZLTmOM6UrCJYXWTbaWgjHGdJRwSeFIaSlkZGT06/qNMaYzCZcUrKVgjDFdS7ikEI+WwrJly9oNMXHTTTfxk5/8hLq6Ok499VTmzp3LjBkzePbZZw+4rK6G2O5sCOyuhss2xphDddQNiHfNX69h3d5uxs5GCYXqEEnG40nq0TJnD53Nz5Z0PdLe0qVLueaaa7jqqqsAePLJJ3nppZdISUnhmWeeISsri7KyMhYtWsTZZ5/d7ZXUnQ2xHQ6HOx0Cu7Phso0x5nAcdUnhwKIVcu9d0TxnzhxKSkrYvXs3paWl5ObmMmrUKAKBADfccAMrV67E4/Gwa9cu9u3bx9ChQ7tcVmdDbJeWlnY6BHZnw2UbY8zhiOdNdh4CPgGUqOp+41SLyCXAt3C1dC3wZVV9+3DX290efVRt7Vr8/gJSUkYd7upiLrjgAp566in27t0bG3ju0UcfpbS0lLfeegu/38/YsWM7HTI7qqdDbBtjTLzEs0/ht8CSbt7fCpykqjOAHwL3dzNvr3L9Cr3b0bx06VIef/xxnnrqKS644ALADXM9ePBg/H4/y5cvZ/v27d0uo6shtrsaAruz4bKNMeZwxC0pqOpKoMsB/FX136oarcVWAyPjFcv+en/47GnTplFbW8uIESMYNmwYAJdccglr1qxhxowZPPLII0yePLnbZXQ1xHZXQ2B3Nly2McYcjrgOnS0iY4G/dHb4qMN8/wNMVtUvHmiZhzt0NkB9/XuIJJOWNqHHn0kENnS2MUevng6d3e8dzSJyCvAF4IRu5rkSuBJg9OjRvbBOL2DDXBhjTEf9ep2CiMwEHgA+qarlXc2nqver6nxVnV9QUNALa/bYgHjGGNOJfksKIjIa+BPwGVXdeLjLO5jDYNZS2N9AuwOfMSY+4nlK6mPAycAgESkGvgf4AVT1XuC7QD5wT+RirmBPjnd1JiUlhfLycvLz83t4i01rKbSlqpSXl5OSktLfoRhj+lnckoKqXnyA978IHLBjuSdGjhxJcXExpaWlPZo/EKggFKonJcXfG6s/KqSkpDByZB+eAGaMOSL1e0dzb/D7/bGrfXtiy5br2bnzDubMaYljVMYYM/Ak3IB4AF5vBqoBwmFLCsYY01aCJoVMAEKhun6OxBhjjiwJmhTcDW4sKRhjTHsJnhRq+zkSY4w5siR4UrCWgjHGtGVJwRhjTIwlBWOMMTGWFIwxxsQkaFKwU1KNMaYzCZoUrKVgjDGdSdCkkAZAMGinpBpjTFsJmRREvHg8adZSMMaYDhIyKYA7hGRJwRhj2rOkYIwxJsaSgjHGmJi4JQUReUhESkRkfRfvi4jcJSKbROQdEZkbr1g64/VmWlIwxpgO4tlS+C2wpJv3Pw5MjJQrgV/FMZb9WEvBGGP2F7ekoKorgYpuZvkk8Ig6q4EcERkWr3g6sqRgjOkPqhAOQygEwWBrCYXcdNX+ja8/b8c5AtjZ5nVxZNqejjOKyJW41gSjR4/ulZW7pGDXKZieaWmB+vrW0tgIPh8kJbUWvx+am917DQ2uNDaCiJs3WrxeCATcvE1NrjQ3u4pBtX0JhdqXYNB9NvqZ6OfD4dYYokWkdf7oYzgMHk/7ItK6Pmhdb9vlR9cXJdJavF5Xotvn8bjvK/q5xsbWz3q97v3oY8eKMRDovHi9kJLiSnKye/T52sch0hp/2+0JBFwM0dLU5KZF/xbR2KPfRcflNTe77Yk+BoMuhmgcycnu+47OE/2umpvd9902poPRNobo8+uugx/96OB/vwdjQNyjWVXvB+4HmD9/fq/kUWspHBmCQSgrg3372peWlvYVQHJya2UTLYEA1NVBeXn7Ul/fuvzoP1X0edt/MlW3jI7LjO6xRR+jFdaRKPr9eDyt2xIItK+AfD5XaUUrvuieatvSsSL0eCA1tbUiTklxSadjAol+vuMebzSu6DIyM9vPH00G0cq+bdJsm9iipbMk1VkSjW5D2wo+LQ2GDm2NJzXVradtom27l94xqSQnu22PPnq9rUkvGlMg0D5RRL+vaBywf8JpWzqut22Loe30xYvj/5vqz6SwCxjV5vXIyLQ+YUnhwKJ7utG9nuhe8N69UFzsyq5dsHu3q4jbztcSuf11dE8sWpqb3bx1de6xpRduk52ZCfn5rWXkyNZ/tKiOe8JRHff0/f7WWKN7tF4vpKe3L6mpriKJJpPm5taKIS2ttaSkuPW0rTSDQbeejkkvuufbtkLr+P15va2fjVbSnQmF3HZ6vV3PY0xn+jMpPAd8VUQeB44FqlV1v0NH8eL1ZqDaQjjcgseT1Fer7VNNTa4CLy2FkpLWUlXVfq8KXEW1d6+r5KMVfe0Bjq6JwJAhMHy4q5izs1v3qJKT3TyhELSEm2iQfTR49pHs95KVnE1uag65adlkpfvJy4P8wS1k5NeQmlNNUlYNSX5IIgNvOB1vOB1PMJ36lnr2tWxhV+MWihs2U1y3hepAOUgYVSWsYRTF402iIK2AwemDKUgroCC9gPzUfNKT0knzp8VKRlIGmUmZSBe1ZnOwmeKaYnbX7qaupY7GYCMNgQbqAg2UBhoREbzixevx4hUvGV4/wzOHMzZnLGOyx5DsS44tq7S+lLf3vc27e9fxXul7JIWSGCpDGZY8jKHpQxmaMZT81HxyUnLITskmydv+N6mqNAWbqGupozrYSEldM82hZpqD7rEx0EhdSx31gXr32FJPMBwk2ZdMsjc59pjqTyXdn056UjoZSRmk+9MJaYhNFZsoKi+iqMKV0vpShmcOZ3T26HZlXO44hmYMxSOH1x2pqoQ0RHVTNeWN5ZQ3lFPRWEFlUyXZydmx9eWk5MT+Po2BRrZUbmFz5WY2VWyipL6EqqaqdiXVn8qY7DGMyR7j/g45Y0j3p1PZVOmW31gZe17RWEF5o1tveUM5YQ0zLnccE/ImMD53PBPyJjAia0Qs1lA4REhDAO1+R2n+NNL96aT4Ujr9Lakqe+v2srVqKzurd9IYbKQl1EIgFHCP4QBe8ZLkTSLJm4Tf6ycp8hsekTWCkVkjyU7O7vJ32tvilhRE5DHgZGCQiBQD3wP8AKp6L/AicAawCWgALo9XLJ1pHRSvfkAkBVVl7Z61PL/xeZ7f+DxbKraS7SsgjQL8gQI8DYMJ1ubTWJ1OXWUGteXpNFRlgIQhZxvkbmkt6SVQOxypGQ3Vo6FmNJ66EWSnp5KflULBmGQm5yUzKM+PL7mZsK8B9TYQjpSUjBbSMlpITgsQ0hZaQi2xCrM+UE99oIGSlnrKGsrYU7eHqqaqLrcrzZtGqDJEc1lzl/N0JT81n8Hpg/GIB494EBEEoTnUTGl9KRWNFSjdH22M/vMVpLskku5PZ3ftbrZXb2dv3d6DjilKEIZnDmdk1kh2VO9gT13r/s7QjKGENUxpfWmX8aX6UslJyUFR6lvqqQ/UE9bwIcfTU9nJ2UzMn8iwzGHsrt3N6uLVlDeWt5snxZdCYU4h4/PGMzprNF6P1yVkVRQlGA5S3Vwdq4ArGyupbq6mOdhMMBwkGA4SCAd6FE9GUgajskZR01zDrtr2BxKSvEnkpOS4RJqcTXZKNo2BRl7Z+gq7anZ1+7dP96eTn5ZPXmoe+an5zBo6C1VlS+UWVhevprq5+qC/uyRvErkpueSm5pKbkkt6UjrFNcVsq9pGU7DpoJfXVpo/jRGZI/jKgq9wzaJrDmtZBxK3pKCqFx/gfQWuitf6D8Tnax0+2+/P7bP1NgWbWLl9Jf9X9H9srdrabs+uPlCP3+NnSMYQBqcPZnD6ELJkCO/vKubVPX+hOrwbVPDuWURo11KqUisgvRTSNkH6vyG7AnKDMHb/9eYnD2Vs1jgmFpzI8KzB7K7bzY7qHeyofoXdtbsJaZgK3OliRdEPBSKlC9G9G7/XT6ovtd2eU6o/lakFU/lI4UcYljGMoRlDY5Vhx707n8dHVnIWWclZZKdkx/beo99LXUsddS11pPnTGJ83nnG54yjMKSQ7Jbvb7zoYDlLeUE5pg0sQDYGGdqWmuYayhjJK6ksobSiltL6U4ppiRmSO4MyJZ8b2VkdkjiAzObPd9qX4Uvbbg2wJtVBcU8zWyq1srXKluKaY08afxqwhs1wZOotBaYPc1xsKUNpQyt66veyp3UNlU2XsO6luqqayqRKPeEj3R/bqk9JJ97vWTmctgOief3Ren8cXa0m0bVG0/c3VtdQhIozPHc+k/EkMShu03x5pfUs9O2t2sq1qG1sqt8TK5srNvLbjNRRFkFhy9oiH7JRsclNyGZQ2iIl5E8lJySHFl4LP44sVv8dPdkp2rGLOT8snNyWXqqaqyG8zUmp2kJGUwYTcCW4vPm8843PHk5+W3+XfPvq3iFbIbSvr3NTc/VpibakqFY0VbKrYxJ66PXjE065FCMR2gqKlrqWOqqYqKhsrqWhyLZK6ljqmFkzlzIlnUphT2K7lEm0VJHmT8Hl8hDQUazm0hFpoCjZRUl/Crtpd7KrZ5R5rd5Gf2vU29xbR/j7/6SDNnz9f16xZc9jLKSl5gvffv4gFC94nPX3KIS0jGA7iFW+3zbrGQCPbq7fz6rZXeaHoBV7Z+goNgQZSfClMzJtImi8DCaYTbkon0JBOTV0LlS0l1LGPlqR9kFIFzRmw+XRSd57FzNQzmDd5MJMnw+jR7vj5yJFQUBDpiA21xP7Zo3uXY7LHkJ6U3mWMgVCAkvoSGoON7SqRQDhAii+lfWXvSyXZl4zf48fr8R7S92aM6Xsi8paqzj/QfAPi7KN4aD18dPCnpdY013DHv+/gztV30hRsYnD6YIakD4nt4dc018T2csoaymKfG5YyloX+y8mqOJOqdSez+cNU3u3QtZ6dDYWFMHasexw5tIUJ44U5X/bHOlC7k+RNIik1idzUnrd+/F4/I7JGHMQ3YIw5WllSOIgzkJqDzdy75l5u/ufNlDWU8akpn2JS3iT21e9zpW4f75W8R1ZyluuUS15A2ebRbHhzFHvWzGdP2WT2IKSnw7RpcOqpMHEijB8PEya4x7y8jms98vs7jDFHD0sKPUgKYQ3zh3f/wHeWf4dtVdv4SOFHuPXUW1kwYkG7+VTh7bfhj3+EP/4MiorcIZ1TToGrroEZM1wZM8ZNN8aYI40lhQMkhdXFq/n6X7/OG7veYO6wudz/ifv56LiPxvoRwmF44w3405/g6adhyxZ3bvgpp8D//A+ce6473m+MMQOBJYUuksLu2t0se3kZv3vndwzLGMYj5zzCJTMviZ2fXVHhLjd//HF3Xr/f7w4HXX89fPKTlgiMMQNTAieF1lNS2wprmNtfu52bV95MIBzghhNu4PoTrycjySURVfjd7+Ab34DKSvjEJ+CWW+CssyAnp883wxhjelUCJwV3imbHpHDX63dx/SvX88ljPsmdH7uTcbnjYu9t2ABf/jIsXw6LFsG998KsWX0atjHGxFWPujtF5OsikhW5Mc6DIrJWRE6Pd3DxJOLF40ltlxSKyou44ZUbOHPimTyz9JlYQgiF4KabYOZM+M9/4L774LXXLCEYY44+PT0H5vOqWgOcDuQCnwFujVtUfaTt8NmhcIjLn72cZF8y9591f6wjORiEyy6D738fzj8fPvwQrrzSzh4yxhydenr4KHrJ1BnA71T1Pemr0ZniqO1IqT9//ee8tvM1HjnnEYZnDgfc6Jef/rQ7q+iWW2DZsv6M1hhj4q+nSeEtEfkbUAhcLyKZQPxH54qzaFLYULaBG/9xI2dNOotLZ14KuKGQL7gAnn8efvpTuCa+Y1AZY8wRoadJ4QvAbGCLqjaISB59PKppPHi9GbQEa7ny2ctJ9aVy3yfuQ0RobHTXF7z0Etxzj+tcNsaYRNDTpHAcsE5V60XkUmAu8PP4hdU3vN5MfrPxQ1YV7+D35/6eYZnDaG52p5kuXw4PPgif/3x/R2mMMX2np92lvwIaRGQW8A1gM/BI3KLqI7sb4Vcf7uScyefw6RmfBuDXv4Z//AN+8xtLCMaYxNPTpBCM3P/gk8AvVfVuIPNAHxKRJSKyQUQ2ich+3bQiMlpElovIf0TkHRE54+DCPzy/37ydsCp3n3E3IkJTk+tQXrzYnXFkjDGJpqdJoVZErsedivqCiHiI3EWtKyLiBe4GPg5MBS4WkakdZvs28KSqzgEuAu45mOAPyl/+4saj3rEDgOqmav68bQunDkmKnW30wAPuNpTf+57d19YYk5h6mhSWAs246xX2AiOBHx/gMwuBTaq6RVVbgMdxLY22FMiKPM8GdvcwnoOXlgbbt8OmTQD8dt1vaQgGOHe4u8lQUxPceiuceKIbzM4YYxJRj5JCJBE8CmSLyCeAJlU9UJ/CCGBnm9fFkWlt3QRcGrmH84vA1Z0tSESuFJE1IrKmtLS0JyHvb8IE97hpE2EN84s3fsHcglEckxkgHA7w4INuYLubbrJWgjEmcfV0mIsLgTeAC4ALgddF5PxeWP/FwG9VdSSRC+Mih6baUdX7VXW+qs4XvZN/AAAgAElEQVQvONThR0eOhORk2LSJ/yv6PzZXbubz004GoKGhnltugRNOsFaCMSax9fSU1BuBBapaAiAiBcDLwFPdfGYXMKrN65GRaW19AVgCoKqrRCQFGASU9DCunvN4YNw42LSJu954m+GZw/nE+P9i66bf8eCDyq5d8PDD1kowxiS2nvYpeKIJIaK8B599E5goIoUikoTrSH6uwzw7gFMBRGQKkAIc4vGhHpgwgQ/2redvm//GV+Z/hRR/Di0tSdx+ewYnnAAf+Ujc1myMMQNCT1sKfxWRl4DHIq+X4voAuqSqQRH5KvAS4AUeioyZ9ANgjao+h7vm4dci8v9wnc6fi5z6Gh8TJvBLeZFkbzJXzrsSaXydF1/8Art3+62VYIwx9DApqOp1InIecHxk0v2q+kwPPvciHZKHqn63zfP32ywz7qrGDefh1BAXjz+PgvQCSurz+cMfrmfhwgpOPTWvr8IwxpgjVo9vsqOqTwNPxzGWuPtNxibqk+DqrNMAeOON6ZSWZnLbbU/jcp4xxiS2bpOCiNTiDuvs9xagqprVyXtHpFA4xC/KX+SE7TB3lOsO2bzZXZQ9adI/AEsKxhjTbVJQ1QMOZTFQvFD0AlvrdnLbGi8MdRewbdwImZm1JCWt7ufojDHmyJAw9w+bPng6y45fxrkt42JXNRcVQWFhJY2N76Ma6ucIjTGm/yVMUhiXO45bPnoLvvETY0lh40aYMKGFcLiJxsat/RyhMcb0v4RJCjETJsCmTTQ1Kjt2wOTJKQDU16/v58CMMab/JWZSqK1l85sVqMKUKfkANDS818+BGWNM/0vMpABsfM1dOD1lSirJyWOspWCMMSRyUlhXD8DEiZCePp36emspGGNM4iWFMWPA66VoIwwZAllZkJ4+jYaGDwmHA/0dnTHG9KvESwpJSTBmDBt3pTFpkpuUnj4d1QCNjZv6NzZjjOlniZcUACZMoKiqgIkT3cv09GmAnYFkjDEJmRRqRk9nb2BQrKWQljYFEOtXMMYkvIRMCkWZcwGYNKwWAK83ldTU8dZSMMYkvMRMCt7JAEz0b4tNS0+fbtcqGGMSXlyTgogsEZENIrJJRJZ1Mc+FIvK+iLwnIn+IZzxRG5tGI4QZ3/x+bFpa2jQaGooIh5v7IgRjjDki9fh+CgdLRLzA3cBpQDHwpog8F7mxTnSeicD1wPGqWikig+MVT1sby/IYxU5Sd2yITUtPnw6EaGjYQEbGzL4IwxhjjjjxbCksBDap6hZVbQEeBz7ZYZ4rgLtVtRKgw32g46Zoi5dJKTtiA+NB2zOQ7BCSMSZxxTMpjAB2tnldHJnW1iRgkoi8JiKrRWRJHOMBQNWNjjopv8KNnR2RlnYMIj7rbDbGJLS4HT46iPVPBE4GRgIrRWSGqla1nUlErgSuBBg9evRhrbCsDKqqYOKUZihqbSl4PEmkpk60loIxJqHFs6WwCxjV5vXIyLS2ioHnVDWgqluBjbgk0Y6q3q+q81V1fkFBwWEFFW0cTJrsac0QEW4MJGspGGMSVzyTwpvARBEpFJEk4CLguQ7z/BnXSkBEBuEOJ22JY0xs3OgeJy3Idk82b469l54+jaamLYRCDfEMwRhjjlhxSwqqGgS+CrwEfAA8qarvicgPROTsyGwvAeUi8j6wHLhOVcvjFRO4pODzwdjjhrkJ7TqbpwNKQ8MH8QzBGGOOWHHtU1DVF4EXO0z7bpvnClwbKX2iqAjGjQPfpHFuQpukkJbWegZSZua8vgrJGGOOGAl3RfPGjbgxj9LSYMSIdkkhNXUCIknWr2CMSVgJlRTCYddSiI6OGr1fc5TH4yMtbbKdgWSMSVgJlRR274bGRmKjo3ZMCmBnIBljEltCJYXomUftWgp790JdXWye9PRpNDfvIBis6fsAjTGmnyVkUmjXUoBOzkCC+vr3McaYRJNQSaGoCFJTXf8yALNmucc334zNk5k5H4CqquV9HJ0xxvS/hEoKGze6xoEnutUTJsDQobByZWye5OThZGYupKzsmf4J0hhj+lFCJYWiojaHjgBEYPHidkkBYNCgc6mtfZOmpp0YY0wiSZikEAy6ES3aJQVwSWHHDti+PTapoOBTAJSV/bkPIzTGmP6XMElh2zaXGCZ2HG5v8WL32Ka1kJY2ibS0qZSV/anP4jPGmCNBwiSF2OioHVsK06ZBbu5+h5AKCj5FVdVKWlrK+iZAY4w5AiRMUsjNhYsugmOO6fCGxwMnnthJv8KngDDl5R0HdjXGmKNXwiSFRYvgscdg0KBO3ly82J2atHdvbFJGxmySk8dQWmqHkIwxiSNhkkK3ov0K//xnbJKIUFDwKSor/04wWNtPgRljTN+ypAAwZw6kp3d6CEm1hYqKF7v4oDHGHF3imhREZImIbBCRTSKyrJv5zhMRFZH58YynSz4fHH/8fkkhO/s4/P7BlJbahWzGmMQQt6QgIl7gbuDjwFTgYhGZ2sl8mcDXgdfjFUuPLF4M774LFRWxSSJeBg06h4qKFwiFmvoxOGOM6RvxbCksBDap6hZVbQEeBz7ZyXw/BG4D+rfWXbwYVOFf/2o3edCgcwmF6qiqeqWfAjPGmL4Tz6QwAmg7TkRxZFqMiMwFRqnqC3GMo2cWLIDk5P0OIeXmfgSvN8vOQjLGJIR+62gWEQ9wJ/CNHsx7pYisEZE1paWl8QkoJQWOPXa/pODxJJGffxbl5c8RDgfjs25jjDlCxDMp7AJGtXk9MjItKhOYDqwQkW3AIuC5zjqbVfV+VZ2vqvMLCgriF/HixbB2LdS2PwW1oOBcAoEyqqtXdvFBY4w5OsQzKbwJTBSRQhFJAi4CYpcHq2q1qg5S1bGqOhZYDZytqmviGFP3Fi+GUAhWrWo3OS/v4/j9BWzf/r+oaj8FZ4wx8Re3pKCqQeCrwEvAB8CTqvqeiPxARM6O13oPy3HHgde73yEkrzeNMWO+Q1XVP6is/Fs/BWeMMfEnA23Pd/78+bpmTRwbE8ce22mHczjcwhtvTMbrzWL+/LW4LhFjjBkYROQtVT3gtWBWs3W0eDG8/jo0tT9D1uNJorDwf6mvf5uSksf6KThjjIkvSwodLV4MLS3w2mv7vTV48FIyMuaydeu3CYeb+yE4Y4yJL0sKHX3kI5CXB7/4xX5viXgYN+42mpq2sWvXr/ohOGOMiS9LCh2lp8PXvgbPPgvr1+/3dl7eR8nNPY3t228mGKzuhwCNMSZ+LCl05uqrXXK49dZO3x437laCwXJ27Li9jwMzxpj4sqTQmbw8+PKX3V15tmzZ7+3MzLkMHvxpiot/SnPz7n4I0Bhj4sOSQleuvdYNqX17562BwsIfohri/feXEgo19HFwxhgTH5YUujJsGHz+8/Cb38Du/VsDqanjmDLld1RXv8Z7751PONzSD0EaY0zvsqTQneuuc8Ne3Hlnp28PHnwhkybdR0XF//HBB5ehGurjAI0xpndZUujOuHFw8cVw771QXt7pLMOHX8G4cbdRWvoERUVftbGRjDEDmiWFA1m2DOrrO71uIWr06G8yatS32L37XrZu/XYfBmeMMb3LksKBTJsG55wDd92135DabY0bdwvDhl3Jjh0/Yvv2H/VhgMYY03ssKfTEDTdAZaU7I6mLw0MiwqRJ9zB48CVs3XojW7bcaIeSjDEDjiWFnliwwCWGBx6An/yky9lEvEyZ8jDDhl3Bjh0/YtOmaywxGGMGFF9/BzBg/PCHsHkzfPObUFgI55/f6WwiXiZNug+vN53i4p8RCtVzzDH3IeLt44CNMebgWVLoKY8Hfvtb2LEDPvMZGDXK3XuhEyLC+PF34vVmsn37DwmH65k8+RE8Hn/fxmyMMQcproePRGSJiGwQkU0isqyT968VkfdF5B0ReUVExsQznsOWkuIGyhs+HM4+G7Zt63JWEaGw8AeMG3crJSWPs27dYmpr1/VdrMYYcwjilhTEHS+5G/g4MBW4WESmdpjtP8B8VZ0JPAUc+SPMFRTACy+4ey6ceWa3iQFg9OhvMWXKozQ2buatt+ZRVHQ1gUBV38RqTDz95z9wwQXwr3/1dyQDw7Zt8Mgj8PbbXZ6wciSIZ0thIbBJVbeoagvwOPDJtjOo6nJVjQ4ctBoYGcd4es/kyfDMM1BU5PoXZsxw1zOsXAnB4H6zDxnyaRYu3MCIEV9h1657eOONSezZ81tUw/0QvDG94O9/dzekeuop9/i1r7nreUx7GzbAj34E8+a5uuKzn4XZs93h5yuvhD//udtT3dsJ9c2ICXG7R7OInA8sUdUvRl5/BjhWVb/axfy/BPaq6s2dvHclcCXA6NGj523fvj0uMR+0zZvdH/WFF+Cf/3QJIScHZs6E0aPblxNOgMxMamvXUVT0FWpqVpGePp3hw7/EkCGX4vNl9/fWGNMzjz4Kn/scTJkCf/wj/PKXrhQWwoMPwimn9HeErVRd8fTC/u+GDW7bV6+GQYPcYeRhw9xjbi7s2we7drWWDz90nwHX/3jeeXDqqa6l8OKL8Le/QU0NJCXBbbfBNdd0ve6yMjj3XDce2+WXH1L4Pb1HM6oalwKcDzzQ5vVngF92Me+luJZC8oGWO2/ePD0iVVerPvWU6he/qHriiapjxqh6vdGfpHv9+uuqqhoOh3TPnkf0zTfn6vLl6KuvpukHH3xeq6tf13A43K+bYUyXwmHVH//Y/Z5POkm1srL1vVdfVZ0wwb33xS+q/uY3qk88ofr886qvvKK6enX7+Q+0ng8/VL3vPtVLLlEdP171sstUKyoOLt4dO1SPPVZ11CgXTzB4cJ9XVd21S/WOO1TnznXb5vGozpnjYkpNbf3/bltyc1WnT1c94wzVn//cxdGZlhbVFStUzz7bfe6aa1RDof3n++ADt77kZPedHiJgjfak7u7JTIdSgOOAl9q8vh64vpP5Pgp8AAzuyXKP2KTQmWBQdedO1RdecEnB71f96U/djz6iuvpN/fDDL+qrr6br8uXomjXzde/exzQUCvRf3InqwQddJfLd73b9j3wwystVH3hAdffuQ/t8U5NqaWn7UlKiun696jPPqN5+u6uATzrJlauuUv3Vr1T/9S/VqqrDj7+tujpXaYHqBReoNjbuP099veo3vuEqzs4qS1AtLFT91KdUb75Z9bnnVP/0J9V77lH93vdU//u/Vc86S3XIkNb5hw51lavPpzpihOrf/96zeJcvVy0oUM3MdJU4qM6Y4f4XD7Tj1dzsdvCWLFEVcZ+dP1/1zjvb/y3DYfc9v/++6muvqRYVue/gYAWDql//ulvP+ee3/25feUU1J8dty6pVB7/sNo6EpOADtgCFQBLwNjCtwzxzgM3AxJ4ud0AlhbYqKlr3CM49d7+9pkCgWouL79bVqyfp8uXov/89Rnfs+KkGAjX9FHACCQRU/9//a620RFzF9olPuD3dg93DfPttV1lH9yRHjlR9552efTYcVl2zxlWQmZldV67RUlCg+l//pXrccfvPP3So6sKFqued5yr0O+90lWJt7YFj2L5d9bHHVK++WnXevNZW79VXd74321ZVlerWrarvvaf65puuFfHcc6o/+pFLKNEWRdsi4rZl+nTVSy9V/fWvVTdsaK3A16xRnTzZzfv1r6s2NHQd+513ungnT3Z72eGw28MeP15jrZxnnnGV7AcfqO7d6xLBBx+o/s//uDiif7dvf9u1WvrCHXe49Z5wgtuhePBBlwynTlXdsuWwF9/vScHFwBnAxkjFf2Nk2g+AsyPPXwb2Aesi5bkDLXPAJgVV9+O84w73hy4sdP90Gza0q3TC4ZCWlj6ra9ecoKv+gK6/JU13PvcFDQR6ec/POFVVbo8QVL/2NZcgtmxRveEGV6mC20O95BLVX/5S9a233DxR4bBL+OvWqT76qKtwwCWEK65we8IjRrgK+29/6zqOykq3/NmzWz9/2WWqd92l+otftC+PPuoq246HY8Jh1W3bVP/yF9Vbb1X9/OdVTzvNVY5paa0VsN+vevLJrpJ+6y3Vmhq3Z33rrarnnKM6bFjrvGlpqqeconrjjW4vvbcOb1ZXq/7736pr17q970APWsb19S4pgeqUKa4V9txzbjkbN7rlXHxx645XdXX7zzc3u+84Wul3Vnw+99kXXji0w02H6/HHVZOSWltLp53Wa62+niaFuHU0x8v8+fN1zZo1/R3G4Vm1Ci66yF0IB5Ca6gbemzkTRGD9enjvPairA0A9sP2KNHw33sLwEV/C40nq3XhUYeNGd8rcjh2wfbt73LPHve/zueL1QnKyi3XhQjf8R35+78bSlzZtgrPOco933+3OBmkrEIDnn3edi//+N+zd66anpbkzzqqrYefO9mfdjB0LV13lOgTz8ty04mJ3+vL778N997n3wH3vq1e7aU8+CY2NMGcOXHGFG7I9J6f3tlXVjd/1n/+4Ds6XXnIdnh1NmOA6RRctgv/6L/eb9B1h17j+7W+us7WTm18hAjff7M4G7Kpzub4e3nkHqqrcdxJ9TE93/5dDh8Y3/gN59VW48ELXMf3zn4O/dy567WlHsyWF/tLc7Cr+d95pX1RdhTN9unucMoXAT3+A/09/p/RE2H7TOEZPv42CgvMQkcOLYds2+P3v3bnTRUWt071eGDHCnVXh8bizqqKlocGddRX93Ywb5xLECSe4UxOnTTv0Mz3q610F/MAD7h/0G9+AM87oennNza6i3by5fQmF4MQT3Vkwxx3nkm5UWZmriFetgl/9ylUiTz8NJ5/cfWyqLlGuWuXKu++6Sn/UKFdGj4YxY2DuXPf9dVRT44ZG+fvf3Thaw4e7ZPDuu5CRAZdc4pLBvHmH9t0dir17XTzbtrn1LlzozqoZCFpa3Bk+ZWWtpbwc5s93v8WBTtX9NnuRJYWjiSp6553wrW/SNMrPu99vxjN1HiNHfo0C32l4V65y/9xbt7rKZtQoGDnSlYICV0kGAq4Eg64SePRRt0cCrkK86CJXoY8e7ZbR3d5hTQ2sXQtvvOHK6tXuHxRcRXniiXDSSa6CnDrVxdCdTZvgnnvgoYfc3vfMmW7PbedOF9M3v+niS0qC0lJ3CvDzz7u93bZ76YMGwfjxbnvXroVw2H3m2GPdd/Lmm63Jz+eD44936xw37lD/MgcnEIAvfcmtE9z389//7VoFmZl9E4NJWJYUjkYrVqAXXog21lJyRgpp71SRuREkDJqRjhwz2R3y2bPnwFdMTpoEl10Gl17q9nAPh6pLNCtXuvLqq26PPSo/3yWHKVNcJV1b6xJLTQ1UVLhDGj6f25P+6lfdYYtgEJ54Am6/3e1NjxzpEtaqVW59I0a4Qz+nnAITJ7pkkJXVus6aGnel7YoVruza5Q53HXecK/Pnu8NAfU3VtUzGjnUxGNNHLCkcrYqL4YIL0DffJDRvMhXzQuyasoGaKUr2oFNIT59Jmn8C6bUFpJWn4q8B8ftdpRt9zMlxe+C93DxtZ88e1zfy/vut5YMP3N57VlZrycx0lfQVV7gLgTpShb/+Fe64w7UiPvEJlwzmzIlv/MYcZSwpHM1U3fH0lBQAmpp2snv3fVRUvEhDw0bC4dZDKj5fPvn5ZzJo0Dnk5Z2O15veX1EbY/qRJYUEpao0N++ioeFDGhs3UFOzmvLyFwgGK/F4UsjNPY28vI/h9w/G58vC683E683C7x9EcnI/n3VhjImbniaFI+xcM3O4RISUlJGkpIwEPsqIEVcRDgeorv4XZWV/pqzsWcrLn+/0s5mZCxky5FIGD76IpKQDdA4bY45K1lJIMK4lUUwwWE0oVEsoVEMwWENT0xb27XuM+vq3AS95eUsYPHgpycmj8HrT8XozIo9Z+P29eP68MaZPWEvBdMq1JEYBo/Z7b/Tob1FX9y779j1KScmjfPjhC50uIzV1Ajk5HyEn5xRyc08hKWlInKM2xvQVaymYTqmGqat7h2CwklCojlConlCojmCwnOrq16iqepVQqAaAtLQppKUdQ1LSCJKTR5CcPJLk5OGI+FENEA4HUA2gGiQpaQipqRPx+wcd/sV3xpges5aCOSwiHjIzZ3f5fjgcpK7uP1RVLae6+p80Nm6iqmoFwWDP7irn8+WQmjqJ1NSJZGbOIyfnFDIyZiIS1zvEGmMOwJKCOSQej4+srAVkZS0AvhmbHgrV09y8m+bmXUAYET8ivsijl5aWPTQ0bKSxsYjGxo1UV79KScmjAPh8ueTknEROzsn4fDk0NW1rV1xLYzjJycMjrZLhpKSMIzNzPqmp463lYUwvsMNHpt81Ne2kqupVqqqWU1W1gqamLbH3kpKGk5IylpSUwlhSaW7eTUvLboLByth8Pl8OGRnzyMycR2rqhMjUcGS0XnfbU48nGZFkPJ4UPJ5kvN40fL48/P48fL58vN50SyzmqGXXKZgBq6lpJ+FwIykpY/B4krucLxRqpKFhA7W1a2Klvv4dVAOHtF6RJHy+XLzeVDye1EjySMXrTcPvL8DvH0xS0hCSkobg8+URCtUQCJQTCJQRCJQTDFbh9+dFWjMjIi2a4Xi9aYgkIeLH4/EjkhRJQHaozPQd61MwA5Y7O+rAvN5UMjNnR/o+vghAONxMS0tJpML1ABJ5roTDzYTDTZHHZsLhegKBCoLBikjlXkEwWEk43BiZzz2GQnU0Nm4lENhHKFTXWSSR1kZ2bHkHJni9Wfh8ObECoNrcJr5mRDyRBJUaSVZpeL0ZkQsPs/D5svF6s/B4/G0+57bR4/FHEtng2KPXm9mh878l8ryFcLglNg08pKSMJiVlbI/vH66qsZMS/P5BeDxWvQxEcf2ricgS4OeAF3e/5ls7vJ8MPALMA8qBpaq6LZ4xmaObx5Pc46RyKEKhBlpaSggGKyLXbOTj82W32+sPhZpoadlDS8tumpt3Ew43Ririlshjc+RMrqp2BcDrzYycmZWMx5OMaiiSnFxpadlHKLSZUKiaYLCGcLih0zjdmV8hoofODofPl0NKyliSkoahGo4kjuj2NBMM1rTZhuj6vCQnj4gc+htDcvIoVIORa2NqCQZrCYfrEfFFkl5aLOn5fDmRltmgWFENRpJ3RexRtRmA1qMdnT96PCkkJQ1tVzyetEgcNbHrdVwS9gJeRLyR2JIi1+hkxorHkxRpHZbS0lJCIFBKMFiD35/XpjU5GJ8v97Bag+67DkX+jiFUg5FWZuoBP3s44pYUxH27dwOnAcXAmyLynKq+32a2LwCVqjpBRC4CbgOWxismYw6X15tGaupYYGw386SQmlpIamph3OMJhwOEQrWoBvB4UiLJJAkRD6ohAoFKAoGSSOVVQihUG+n090fma/s8KfaoGqS5eUe7jv7m5j2RytLN7/Ol4vEkkZaW3abFk43Xm0ZLy97I57ZTVbWC5uZdiPjwejPx+aIVbEYk6TUQCjUQDjdGTn2u6eHWt61wXV9Qa59Q66Nr+fSHaCuvtR9LJAkIEQ63EA43x1porv8r3O6xNbm1GjXqW4wff+t+03tTPFsKC4FNqroFQEQeBz4JtE0KnwRuijx/CviliIgOtI4OY/qJx+PH48nr9D0RL0lJg0hKGkR6+tRDWPqCwwuuDdVwj/eaw+Foq6AsVkT8kUN00RMDcnt8B8JwuCWSFPfR0rKXlpa9hEKNkeSUFUlUWXg8KZE982Bs7zzaqou2bkKhWsLhZvz+QSQluX4mv78Any+LQKAiso6SSCIujbTwmiOHBZsIh1tiLZC2SdjtQ3tihz1FBBEfra0W13LJzOy9v0lX4pkURgA727wuBo7tah5VDYpINZAPlMUxLmNMHzuYwygej4+kJNcH0hs8nqQ244HFT3LycGB6XNfRFwbE6Q8icqWIrBGRNaWlpf0djjHGHLXimRR20X6AnZGRaZ3OI66tlI3rcG5HVe9X1fmqOr/gQLd2NMYYc8jimRTeBCaKSKG43pWLgOc6zPMc8NnI8/OBf1h/gjHG9J+49SlE+gi+CryEOyX1IVV9T0R+AKxR1eeAB4HficgmoAKXOIwxxvSTuF6noKovAi92mPbdNs+bgAviGYMxxpieGxAdzcYYY/qGJQVjjDExlhSMMcbEDLhRUkWkFNh+iB8fxNFzYZxty5HpaNmWo2U7wLYlaoyqHvCc/gGXFA6HiKzpydCxA4Fty5HpaNmWo2U7wLblYNnhI2OMMTGWFIwxxsQkWlK4v78D6EW2LUemo2VbjpbtANuWg5JQfQrGGGO6l2gtBWOMMd1ImKQgIktEZIOIbBKRZf0dz8EQkYdEpERE1reZlicifxeRoshjbn/G2BMiMkpElovI+yLynoh8PTJ9IG5Lioi8ISJvR7bl+5HphSLyeuR39kRkMMgBQUS8IvIfEflL5PWA3BYR2SYi74rIOhFZE5k2EH9jOSLylIh8KCIfiMhxfbEdCZEU2twa9OPAVOBiETmUW1H1l98CSzpMWwa8oqoTgVcir490QeAbqjoVWARcFfk7DMRtaQY+oqqzgNnAEhFZhLul7E9VdQJQibvl7EDxdeCDNq8H8racoqqz25y+ORB/Yz8H/qqqk4FZuL9N/LdDVY/6AhwHvNTm9fXA9f0d10Fuw1hgfZvXG4BhkefDgA39HeMhbNOzuHt4D+htAdKAtbg7C5YBvsj0dr+7I7ng7nfyCvAR4C+4mxwP1G3ZBgzqMG1A/cZw95bZSqTfty+3IyFaCnR+a9AR/RRLbxmiqnsiz/cCQ/ozmIMlImOBOcDrDNBtiRxuWQeUAH8HNgNVqhqMzDKQfmc/A76Ju2M8uNviDtRtUeBvIvKWiFwZmTbQfmOFQCnwm8ghvQdEJJ0+2I5ESQpHNXW7DQPmNDIRyQCeBq5R1Zq27w2kbVHVkKrOxu1lLwQm93NIh0REPgGUqOpb/R1LLzlBVefiDhdfJSKL2745QH5jPmAu8CtVnQPU0+FQUby2I1GSQk9uDTrQ7BORYQCRx5J+jqdHRMSPSwiPquqfIpMH5LZEqUF6nYQAAAMgSURBVGoVsBx3iCUncmtZGDi/s+OBs0VkG/A47hDSzxmY24Kq7oo8lgDP4BL2QPuNFQPFqvp65PVTuCQR9+1IlKTQk1uDDjRtb2X6Wdzx+SOaiAjubnsfqOqdbd4aiNtSICI5keepuL6RD3DJ4fzIbANiW1T1elUdqapjcf8b/1DVSxiA2yIi6SKSGX0OnA6sZ4D9xlR1L7BTRI6JTDoVeJ++2I7+7lDpw46bM4CNuOO+N/Z3PAcZ+2PAHiCA24P4Au6Y7ytAEfAykNffcfZgO07ANXffAdZFyhkDdFtmAv+JbMt64LuR6eOAN4BNwB+B5P6O9SC362TgLwN1WyIxvx0p70X/1wfob2w2sCbyG/szkNsX22FXNBtjjIlJlMNHxhhjesCSgjHGmBhLCsYYY2IsKRhjjImxpGCMMSbGkoIxfUhETo6OQmrMkciSgjHGmBhLCsZ0QkQujdwvYZ2I3BcZ/K5ORH4auX/CKyJSEJl3toisFpF3ROSZ6Bj3IjJBRF6O3HNhrYiM///t3T9rVEEUhvHniCCagFY2FoKdBGwEC8XKL2ChCEqK1DZ2IiiC30HQMmIKEfQTWCykUgtBsLRKZSOihRbxtZhxWDdFZCFxwedX7c7eHXaKu+f+4b6nT788lZO/0Z/0lhaCRUGaUVWngWvAhbTAu23gBrAEvE2yAkyA+/0rT4DbSc4A76fGN4CHaT0XztOeSoeWDnuL1tvjFC17SFoIB3ffRPrvXALOAm/6QfxhWvDYT+BZ3+Yp8KKqjgLHkkz6+DrwvOfvnEjyEiDJd4A+3+skW/39O1qvjM29X5a0O4uCtFMB60nu/DFYdW9mu3kzYn5Mvd7G/VALxMtH0k6vgCtVdRxGf9+TtP3ld2rodWAzyRfgc1Vd7OOrwCTJV2Crqi73OQ5V1ZF9XYU0B49QpBlJPlTVXVr3rgO0dNqbtEYn5/pnn2j3HaBFGD/qf/ofgbU+vgo8rqoHfY6r+7gMaS6mpEp/qaq+JVn+179D2ktePpIkDZ4pSJIGzxQkSYNFQZI0WBQkSYNFQZI0WBQkSYNFQZI0/AIHNjQ3hWvOlgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2026 - acc: 0.9396\n",
      "Loss: 0.20258532717499034 Accuracy: 0.9395639\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3, 10):\n",
    "    base = '1D_CNN_custom_ch_128_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_ch_128_DO(conv_num=i)\n",
    "        \n",
    "    model = multi_gpu_model(model, gpus=4)\n",
    "    \n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_128_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_42_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, 16)           3804176     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Concatenate)           (None, 16)           0           sequential_7[1][0]               \n",
      "                                                                 sequential_7[2][0]               \n",
      "                                                                 sequential_7[3][0]               \n",
      "                                                                 sequential_7[4][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,804,176\n",
      "Trainable params: 3,804,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 1.3925 - acc: 0.5718\n",
      "Loss: 1.3925352943772962 Accuracy: 0.57175493\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_45_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 16)           1459344     lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Concatenate)           (None, 16)           0           sequential_8[1][0]               \n",
      "                                                                 sequential_8[2][0]               \n",
      "                                                                 sequential_8[3][0]               \n",
      "                                                                 sequential_8[4][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,459,344\n",
      "Trainable params: 1,459,344\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 1.0524 - acc: 0.6766\n",
      "Loss: 1.0524171884928908 Accuracy: 0.6766355\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_49_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 16)           1217936     lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Concatenate)           (None, 16)           0           sequential_9[1][0]               \n",
      "                                                                 sequential_9[2][0]               \n",
      "                                                                 sequential_9[3][0]               \n",
      "                                                                 sequential_9[4][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,217,936\n",
      "Trainable params: 1,217,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.7859 - acc: 0.7701\n",
      "Loss: 0.7858693222390528 Accuracy: 0.77009344\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_54_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 16)           1005200     lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Concatenate)          (None, 16)           0           sequential_10[1][0]              \n",
      "                                                                 sequential_10[2][0]              \n",
      "                                                                 sequential_10[3][0]              \n",
      "                                                                 sequential_10[4][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,005,200\n",
      "Trainable params: 1,005,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.4116 - acc: 0.8802\n",
      "Loss: 0.41161584854125977 Accuracy: 0.8801662\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_60_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 16)           1152912     lambda_16[0][0]                  \n",
      "                                                                 lambda_17[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "                                                                 lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Concatenate)          (None, 16)           0           sequential_11[1][0]              \n",
      "                                                                 sequential_11[2][0]              \n",
      "                                                                 sequential_11[3][0]              \n",
      "                                                                 sequential_11[4][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,152,912\n",
      "Trainable params: 1,152,912\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2154 - acc: 0.9387\n",
      "Loss: 0.21535514052783217 Accuracy: 0.9387331\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_67_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 16)           1423504     lambda_20[0][0]                  \n",
      "                                                                 lambda_21[0][0]                  \n",
      "                                                                 lambda_22[0][0]                  \n",
      "                                                                 lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Concatenate)          (None, 16)           0           sequential_12[1][0]              \n",
      "                                                                 sequential_12[2][0]              \n",
      "                                                                 sequential_12[3][0]              \n",
      "                                                                 sequential_12[4][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,423,504\n",
      "Trainable params: 1,423,504\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.1628 - acc: 0.9543\n",
      "Loss: 0.16284374764280032 Accuracy: 0.95430946\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_9_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_75_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 16)           2067088     lambda_24[0][0]                  \n",
      "                                                                 lambda_25[0][0]                  \n",
      "                                                                 lambda_26[0][0]                  \n",
      "                                                                 lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Concatenate)          (None, 16)           0           sequential_13[1][0]              \n",
      "                                                                 sequential_13[2][0]              \n",
      "                                                                 sequential_13[3][0]              \n",
      "                                                                 sequential_13[4][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,067,088\n",
      "Trainable params: 2,067,088\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2026 - acc: 0.9396\n",
      "Loss: 0.20258532717499034 Accuracy: 0.9395639\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_ch_128_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(3, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_ch_128_DO_3_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_42_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 16000, 1)     0           conv1d_42_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_7 (Sequential)       (None, 16)           3804176     lambda[0][0]                     \n",
      "                                                                 lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Concatenate)           (None, 16)           0           sequential_7[1][0]               \n",
      "                                                                 sequential_7[2][0]               \n",
      "                                                                 sequential_7[3][0]               \n",
      "                                                                 sequential_7[4][0]               \n",
      "==================================================================================================\n",
      "Total params: 3,804,176\n",
      "Trainable params: 3,804,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 3.0270 - acc: 0.5759\n",
      "Loss: 3.02699627613848 Accuracy: 0.5759086\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_4_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_45_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 16000, 1)     0           conv1d_45_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       (None, 16)           1459344     lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Concatenate)           (None, 16)           0           sequential_8[1][0]               \n",
      "                                                                 sequential_8[2][0]               \n",
      "                                                                 sequential_8[3][0]               \n",
      "                                                                 sequential_8[4][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,459,344\n",
      "Trainable params: 1,459,344\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 1.9071 - acc: 0.7144\n",
      "Loss: 1.907051080830496 Accuracy: 0.7144341\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_5_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_49_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 16000, 1)     0           conv1d_49_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       (None, 16)           1217936     lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Concatenate)           (None, 16)           0           sequential_9[1][0]               \n",
      "                                                                 sequential_9[2][0]               \n",
      "                                                                 sequential_9[3][0]               \n",
      "                                                                 sequential_9[4][0]               \n",
      "==================================================================================================\n",
      "Total params: 1,217,936\n",
      "Trainable params: 1,217,936\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 1.2637 - acc: 0.8012\n",
      "Loss: 1.2636504463441398 Accuracy: 0.8012461\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_6_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_54_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 16000, 1)     0           conv1d_54_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_10 (Sequential)      (None, 16)           1005200     lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Concatenate)          (None, 16)           0           sequential_10[1][0]              \n",
      "                                                                 sequential_10[2][0]              \n",
      "                                                                 sequential_10[3][0]              \n",
      "                                                                 sequential_10[4][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,005,200\n",
      "Trainable params: 1,005,200\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.4876 - acc: 0.9076\n",
      "Loss: 0.4875690118731739 Accuracy: 0.9075805\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_7_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_60_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 16000, 1)     0           conv1d_60_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 16)           1152912     lambda_16[0][0]                  \n",
      "                                                                 lambda_17[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "                                                                 lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Concatenate)          (None, 16)           0           sequential_11[1][0]              \n",
      "                                                                 sequential_11[2][0]              \n",
      "                                                                 sequential_11[3][0]              \n",
      "                                                                 sequential_11[4][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,152,912\n",
      "Trainable params: 1,152,912\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2418 - acc: 0.9493\n",
      "Loss: 0.24175022204898816 Accuracy: 0.949325\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_8_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_67_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 16000, 1)     0           conv1d_67_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_12 (Sequential)      (None, 16)           1423504     lambda_20[0][0]                  \n",
      "                                                                 lambda_21[0][0]                  \n",
      "                                                                 lambda_22[0][0]                  \n",
      "                                                                 lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Concatenate)          (None, 16)           0           sequential_12[1][0]              \n",
      "                                                                 sequential_12[2][0]              \n",
      "                                                                 sequential_12[3][0]              \n",
      "                                                                 sequential_12[4][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,423,504\n",
      "Trainable params: 1,423,504\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2168 - acc: 0.9562\n",
      "Loss: 0.21679355497926528 Accuracy: 0.9561786\n",
      "\n",
      "1D_CNN_custom_ch_128_DO_9_conv Model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "conv1d_75_input (InputLayer)    (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 16000, 1)     0           conv1d_75_input[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_13 (Sequential)      (None, 16)           2067088     lambda_24[0][0]                  \n",
      "                                                                 lambda_25[0][0]                  \n",
      "                                                                 lambda_26[0][0]                  \n",
      "                                                                 lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Concatenate)          (None, 16)           0           sequential_13[1][0]              \n",
      "                                                                 sequential_13[2][0]              \n",
      "                                                                 sequential_13[3][0]              \n",
      "                                                                 sequential_13[4][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,067,088\n",
      "Trainable params: 2,067,088\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2817 - acc: 0.9481\n",
      "Loss: 0.2816557916207009 Accuracy: 0.94807893\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_ch_128_DO'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(3, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
