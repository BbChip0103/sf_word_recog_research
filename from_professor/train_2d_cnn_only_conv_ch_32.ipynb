{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_data = np.load(os.path.join(data_dir, 'train_data.npz'))\n",
    "val_data = np.load(os.path.join(data_dir, 'validation_data.npz'))\n",
    "test_data = np.load(os.path.join(data_dir, 'test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 25443),\n",
       " (36805,),\n",
       " (4293, 25443),\n",
       " (4293,),\n",
       " (4815, 25443),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x_data):\n",
    "    x_data = np.reshape(x_data, [x_data.shape[0], 99, 257, 1])\n",
    "    x_data = np.rot90(x_data, 1, (1, 2))\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_2d = preprocess(x_train)\n",
    "mean_vals = np.mean(x_train_2d, axis=0)\n",
    "std_val = np.std(x_train_2d)\n",
    "x_train_2d_norm = (x_train_2d-mean_vals) / std_val\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_2d = preprocess(x_val)\n",
    "x_val_2d_norm = (x_val_2d-mean_vals) / std_val\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_2d = preprocess(x_test)\n",
    "x_test_2d_norm = (x_test_2d-mean_vals) / std_val\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test_2d_norm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_only_conv_ch_32_DO(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=32*(2**int((i)/2)), strides=(1,1), padding='valid')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                3121168   \n",
      "=================================================================\n",
      "Total params: 3,122,000\n",
      "Trainable params: 3,122,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                698384    \n",
      "=================================================================\n",
      "Total params: 724,848\n",
      "Trainable params: 724,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                267280    \n",
      "=================================================================\n",
      "Total params: 345,008\n",
      "Trainable params: 345,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 25, 5, 64)         102464    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 25, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 3, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                39952     \n",
      "=================================================================\n",
      "Total params: 220,144\n",
      "Trainable params: 220,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model = build_2d_cnn_only_conv_ch_32_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5382 - acc: 0.5377\n",
      "Epoch 00001: val_loss improved from inf to 1.32974, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_1_conv_checkpoint/001-1.3297.hdf5\n",
      "36805/36805 [==============================] - 19s 509us/sample - loss: 1.5381 - acc: 0.5377 - val_loss: 1.3297 - val_acc: 0.6024\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1425 - acc: 0.6593\n",
      "Epoch 00002: val_loss improved from 1.32974 to 1.19325, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_1_conv_checkpoint/002-1.1932.hdf5\n",
      "36805/36805 [==============================] - 17s 456us/sample - loss: 1.1428 - acc: 0.6592 - val_loss: 1.1932 - val_acc: 0.6625\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9536 - acc: 0.7148\n",
      "Epoch 00003: val_loss improved from 1.19325 to 1.09154, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_1_conv_checkpoint/003-1.0915.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.9535 - acc: 0.7148 - val_loss: 1.0915 - val_acc: 0.7028\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8136 - acc: 0.7527\n",
      "Epoch 00004: val_loss improved from 1.09154 to 1.06769, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_1_conv_checkpoint/004-1.0677.hdf5\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.8135 - acc: 0.7527 - val_loss: 1.0677 - val_acc: 0.7126\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7171 - acc: 0.7854\n",
      "Epoch 00005: val_loss improved from 1.06769 to 1.03109, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_1_conv_checkpoint/005-1.0311.hdf5\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.7171 - acc: 0.7855 - val_loss: 1.0311 - val_acc: 0.7214\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6308 - acc: 0.8115\n",
      "Epoch 00006: val_loss did not improve from 1.03109\n",
      "36805/36805 [==============================] - 16s 424us/sample - loss: 0.6308 - acc: 0.8115 - val_loss: 1.0375 - val_acc: 0.7303\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5715 - acc: 0.8268\n",
      "Epoch 00007: val_loss did not improve from 1.03109\n",
      "36805/36805 [==============================] - 16s 429us/sample - loss: 0.5715 - acc: 0.8268 - val_loss: 1.0691 - val_acc: 0.7279\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5201 - acc: 0.8451\n",
      "Epoch 00008: val_loss did not improve from 1.03109\n",
      "36805/36805 [==============================] - 16s 424us/sample - loss: 0.5201 - acc: 0.8451 - val_loss: 1.0585 - val_acc: 0.7321\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4795 - acc: 0.8549\n",
      "Epoch 00009: val_loss improved from 1.03109 to 1.02654, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_1_conv_checkpoint/009-1.0265.hdf5\n",
      "36805/36805 [==============================] - 15s 417us/sample - loss: 0.4796 - acc: 0.8549 - val_loss: 1.0265 - val_acc: 0.7475\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4430 - acc: 0.8679\n",
      "Epoch 00010: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.4430 - acc: 0.8679 - val_loss: 1.0342 - val_acc: 0.7445\n",
      "Epoch 11/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4060 - acc: 0.8780\n",
      "Epoch 00011: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.4064 - acc: 0.8780 - val_loss: 1.0529 - val_acc: 0.7403\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3862 - acc: 0.8840\n",
      "Epoch 00012: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 430us/sample - loss: 0.3862 - acc: 0.8840 - val_loss: 1.0428 - val_acc: 0.7505\n",
      "Epoch 13/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3691 - acc: 0.8887\n",
      "Epoch 00013: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 427us/sample - loss: 0.3693 - acc: 0.8887 - val_loss: 1.0985 - val_acc: 0.7477\n",
      "Epoch 14/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3402 - acc: 0.8988\n",
      "Epoch 00014: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 422us/sample - loss: 0.3402 - acc: 0.8988 - val_loss: 1.0779 - val_acc: 0.7524\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3231 - acc: 0.9027\n",
      "Epoch 00015: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 15s 421us/sample - loss: 0.3231 - acc: 0.9027 - val_loss: 1.1185 - val_acc: 0.7419\n",
      "Epoch 16/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3038 - acc: 0.9093\n",
      "Epoch 00016: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 424us/sample - loss: 0.3038 - acc: 0.9092 - val_loss: 1.0900 - val_acc: 0.7612\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2930 - acc: 0.9112\n",
      "Epoch 00017: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 426us/sample - loss: 0.2930 - acc: 0.9112 - val_loss: 1.1286 - val_acc: 0.7549\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2790 - acc: 0.9154\n",
      "Epoch 00018: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 15s 415us/sample - loss: 0.2791 - acc: 0.9154 - val_loss: 1.1385 - val_acc: 0.7589\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2638 - acc: 0.9221\n",
      "Epoch 00019: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 15s 414us/sample - loss: 0.2638 - acc: 0.9221 - val_loss: 1.1323 - val_acc: 0.7631\n",
      "Epoch 20/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2561 - acc: 0.9233- ETA: 1s - l\n",
      "Epoch 00020: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 15s 416us/sample - loss: 0.2560 - acc: 0.9233 - val_loss: 1.1937 - val_acc: 0.7473\n",
      "Epoch 21/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2445 - acc: 0.9265\n",
      "Epoch 00021: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.2449 - acc: 0.9262 - val_loss: 1.1749 - val_acc: 0.7617\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2315 - acc: 0.9314\n",
      "Epoch 00022: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 427us/sample - loss: 0.2315 - acc: 0.9314 - val_loss: 1.2027 - val_acc: 0.7554\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2274 - acc: 0.9329\n",
      "Epoch 00023: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 429us/sample - loss: 0.2275 - acc: 0.9329 - val_loss: 1.2034 - val_acc: 0.7584\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2202 - acc: 0.9335\n",
      "Epoch 00024: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 429us/sample - loss: 0.2204 - acc: 0.9335 - val_loss: 1.1845 - val_acc: 0.7624\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2111 - acc: 0.9372\n",
      "Epoch 00025: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 431us/sample - loss: 0.2110 - acc: 0.9372 - val_loss: 1.2161 - val_acc: 0.7594\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9421\n",
      "Epoch 00026: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.1985 - acc: 0.9420 - val_loss: 1.2656 - val_acc: 0.7475\n",
      "Epoch 27/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9398\n",
      "Epoch 00027: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.1994 - acc: 0.9398 - val_loss: 1.2576 - val_acc: 0.7601\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1914 - acc: 0.9429\n",
      "Epoch 00028: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.1914 - acc: 0.9429 - val_loss: 1.2570 - val_acc: 0.7575\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1872 - acc: 0.9438\n",
      "Epoch 00029: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.1875 - acc: 0.9438 - val_loss: 1.2822 - val_acc: 0.7510\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1781 - acc: 0.9469\n",
      "Epoch 00030: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.1780 - acc: 0.9469 - val_loss: 1.3051 - val_acc: 0.7515\n",
      "Epoch 31/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9478\n",
      "Epoch 00031: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.1753 - acc: 0.9478 - val_loss: 1.2885 - val_acc: 0.7561\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1700 - acc: 0.9494\n",
      "Epoch 00032: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.1700 - acc: 0.9494 - val_loss: 1.2770 - val_acc: 0.7580\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1678 - acc: 0.9503\n",
      "Epoch 00033: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 444us/sample - loss: 0.1678 - acc: 0.9503 - val_loss: 1.3181 - val_acc: 0.7556\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1616 - acc: 0.9526\n",
      "Epoch 00034: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.1616 - acc: 0.9526 - val_loss: 1.3163 - val_acc: 0.7561\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1544 - acc: 0.9549\n",
      "Epoch 00035: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.1544 - acc: 0.9549 - val_loss: 1.3162 - val_acc: 0.7563\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9540\n",
      "Epoch 00036: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.1551 - acc: 0.9540 - val_loss: 1.3379 - val_acc: 0.7563\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9555\n",
      "Epoch 00037: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 441us/sample - loss: 0.1490 - acc: 0.9555 - val_loss: 1.3206 - val_acc: 0.7601\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9555\n",
      "Epoch 00038: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.1497 - acc: 0.9554 - val_loss: 1.3164 - val_acc: 0.7647\n",
      "Epoch 39/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9539\n",
      "Epoch 00039: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.1519 - acc: 0.9539 - val_loss: 1.3723 - val_acc: 0.7580\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1434 - acc: 0.9582\n",
      "Epoch 00040: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 442us/sample - loss: 0.1433 - acc: 0.9582 - val_loss: 1.3761 - val_acc: 0.7543\n",
      "Epoch 41/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9593\n",
      "Epoch 00041: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.1372 - acc: 0.9593 - val_loss: 1.3876 - val_acc: 0.7612\n",
      "Epoch 42/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9599\n",
      "Epoch 00042: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 443us/sample - loss: 0.1379 - acc: 0.9600 - val_loss: 1.3757 - val_acc: 0.7661\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9605\n",
      "Epoch 00043: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.1336 - acc: 0.9605 - val_loss: 1.3881 - val_acc: 0.7594\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9618\n",
      "Epoch 00044: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.1323 - acc: 0.9618 - val_loss: 1.4379 - val_acc: 0.7505\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9623\n",
      "Epoch 00045: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.1301 - acc: 0.9623 - val_loss: 1.4341 - val_acc: 0.7524\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1256 - acc: 0.9639\n",
      "Epoch 00046: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.1257 - acc: 0.9639 - val_loss: 1.4092 - val_acc: 0.7647\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9644\n",
      "Epoch 00047: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 446us/sample - loss: 0.1246 - acc: 0.9644 - val_loss: 1.4281 - val_acc: 0.7589\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9641\n",
      "Epoch 00048: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.1208 - acc: 0.9641 - val_loss: 1.4355 - val_acc: 0.7629\n",
      "Epoch 49/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9646\n",
      "Epoch 00049: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 17s 452us/sample - loss: 0.1212 - acc: 0.9647 - val_loss: 1.4758 - val_acc: 0.7487\n",
      "Epoch 50/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1215 - acc: 0.9651\n",
      "Epoch 00050: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 17s 454us/sample - loss: 0.1216 - acc: 0.9651 - val_loss: 1.4382 - val_acc: 0.7573\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9665\n",
      "Epoch 00051: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.1142 - acc: 0.9665 - val_loss: 1.4631 - val_acc: 0.7605\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9663\n",
      "Epoch 00052: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.1155 - acc: 0.9663 - val_loss: 1.4408 - val_acc: 0.7608\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9679\n",
      "Epoch 00053: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 447us/sample - loss: 0.1114 - acc: 0.9679 - val_loss: 1.4522 - val_acc: 0.7545\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1070 - acc: 0.9696\n",
      "Epoch 00054: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.1070 - acc: 0.9697 - val_loss: 1.4661 - val_acc: 0.7645\n",
      "Epoch 55/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9686\n",
      "Epoch 00055: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.1104 - acc: 0.9686 - val_loss: 1.4776 - val_acc: 0.7580\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9704\n",
      "Epoch 00056: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.1044 - acc: 0.9704 - val_loss: 1.4749 - val_acc: 0.7596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9688\n",
      "Epoch 00057: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 17s 449us/sample - loss: 0.1079 - acc: 0.9688 - val_loss: 1.4878 - val_acc: 0.7596\n",
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9701\n",
      "Epoch 00058: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.1043 - acc: 0.9702 - val_loss: 1.5199 - val_acc: 0.7536\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9700\n",
      "Epoch 00059: val_loss did not improve from 1.02654\n",
      "36805/36805 [==============================] - 17s 451us/sample - loss: 0.1037 - acc: 0.9700 - val_loss: 1.5504 - val_acc: 0.7508\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 234us/sample - loss: 1.1429 - acc: 0.7099\n",
      "Loss: 1.1429275806571588 Accuracy: 0.70986503\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5182 - acc: 0.5391\n",
      "Epoch 00001: val_loss improved from inf to 1.10332, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_2_conv_checkpoint/001-1.1033.hdf5\n",
      "36805/36805 [==============================] - 20s 530us/sample - loss: 1.5184 - acc: 0.5391 - val_loss: 1.1033 - val_acc: 0.6939\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9629 - acc: 0.7124\n",
      "Epoch 00002: val_loss improved from 1.10332 to 0.81644, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_2_conv_checkpoint/002-0.8164.hdf5\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.9630 - acc: 0.7124 - val_loss: 0.8164 - val_acc: 0.7817\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7314 - acc: 0.7808\n",
      "Epoch 00003: val_loss improved from 0.81644 to 0.67519, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_2_conv_checkpoint/003-0.6752.hdf5\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.7314 - acc: 0.7807 - val_loss: 0.6752 - val_acc: 0.8309\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6065 - acc: 0.8188\n",
      "Epoch 00004: val_loss improved from 0.67519 to 0.60055, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_2_conv_checkpoint/004-0.6006.hdf5\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.6066 - acc: 0.8188 - val_loss: 0.6006 - val_acc: 0.8442\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5118 - acc: 0.8451\n",
      "Epoch 00005: val_loss improved from 0.60055 to 0.55310, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_2_conv_checkpoint/005-0.5531.hdf5\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.5117 - acc: 0.8451 - val_loss: 0.5531 - val_acc: 0.8607\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4481 - acc: 0.8630\n",
      "Epoch 00006: val_loss improved from 0.55310 to 0.52611, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_2_conv_checkpoint/006-0.5261.hdf5\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.4483 - acc: 0.8630 - val_loss: 0.5261 - val_acc: 0.8668\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3926 - acc: 0.8788\n",
      "Epoch 00007: val_loss improved from 0.52611 to 0.49507, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_2_conv_checkpoint/007-0.4951.hdf5\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.3927 - acc: 0.8788 - val_loss: 0.4951 - val_acc: 0.8786\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3578 - acc: 0.8901\n",
      "Epoch 00008: val_loss improved from 0.49507 to 0.48300, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_2_conv_checkpoint/008-0.4830.hdf5\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.3577 - acc: 0.8901 - val_loss: 0.4830 - val_acc: 0.8835\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3208 - acc: 0.9019\n",
      "Epoch 00009: val_loss improved from 0.48300 to 0.47373, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_2_conv_checkpoint/009-0.4737.hdf5\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.3208 - acc: 0.9019 - val_loss: 0.4737 - val_acc: 0.8863\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2887 - acc: 0.9116\n",
      "Epoch 00010: val_loss improved from 0.47373 to 0.46172, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_2_conv_checkpoint/010-0.4617.hdf5\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.2887 - acc: 0.9116 - val_loss: 0.4617 - val_acc: 0.8891\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2657 - acc: 0.9168\n",
      "Epoch 00011: val_loss did not improve from 0.46172\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.2657 - acc: 0.9168 - val_loss: 0.4696 - val_acc: 0.8882\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2448 - acc: 0.9252\n",
      "Epoch 00012: val_loss did not improve from 0.46172\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.2448 - acc: 0.9252 - val_loss: 0.4672 - val_acc: 0.8924\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2280 - acc: 0.9287\n",
      "Epoch 00013: val_loss did not improve from 0.46172\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.2280 - acc: 0.9287 - val_loss: 0.4739 - val_acc: 0.8963\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2119 - acc: 0.9348\n",
      "Epoch 00014: val_loss improved from 0.46172 to 0.46087, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_2_conv_checkpoint/014-0.4609.hdf5\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.2119 - acc: 0.9348 - val_loss: 0.4609 - val_acc: 0.8963\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9379\n",
      "Epoch 00015: val_loss did not improve from 0.46087\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.1981 - acc: 0.9378 - val_loss: 0.4725 - val_acc: 0.8952\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1857 - acc: 0.9417\n",
      "Epoch 00016: val_loss improved from 0.46087 to 0.45867, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_2_conv_checkpoint/016-0.4587.hdf5\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.1857 - acc: 0.9417 - val_loss: 0.4587 - val_acc: 0.9008\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1736 - acc: 0.9468\n",
      "Epoch 00017: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.1736 - acc: 0.9467 - val_loss: 0.4770 - val_acc: 0.8973\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1662 - acc: 0.9474\n",
      "Epoch 00018: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.1662 - acc: 0.9474 - val_loss: 0.4638 - val_acc: 0.9005\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1513 - acc: 0.9524\n",
      "Epoch 00019: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.1513 - acc: 0.9525 - val_loss: 0.4771 - val_acc: 0.9012\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1495 - acc: 0.9530\n",
      "Epoch 00020: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.1496 - acc: 0.9530 - val_loss: 0.4754 - val_acc: 0.9001\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9554\n",
      "Epoch 00021: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.1424 - acc: 0.9554 - val_loss: 0.4730 - val_acc: 0.9005\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1328 - acc: 0.9586\n",
      "Epoch 00022: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.1328 - acc: 0.9586 - val_loss: 0.4613 - val_acc: 0.9033\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9630\n",
      "Epoch 00023: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.1219 - acc: 0.9629 - val_loss: 0.4829 - val_acc: 0.9031\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9611\n",
      "Epoch 00024: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.1240 - acc: 0.9611 - val_loss: 0.4732 - val_acc: 0.9019\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9641\n",
      "Epoch 00025: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 19s 503us/sample - loss: 0.1148 - acc: 0.9641 - val_loss: 0.5085 - val_acc: 0.8968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9663\n",
      "Epoch 00026: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.1097 - acc: 0.9663 - val_loss: 0.4949 - val_acc: 0.9057\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1062 - acc: 0.9671\n",
      "Epoch 00027: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.1062 - acc: 0.9671 - val_loss: 0.5047 - val_acc: 0.9012\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0986 - acc: 0.9696\n",
      "Epoch 00028: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0986 - acc: 0.9697 - val_loss: 0.5152 - val_acc: 0.9022\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0991 - acc: 0.9697\n",
      "Epoch 00029: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0991 - acc: 0.9697 - val_loss: 0.5311 - val_acc: 0.9015\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0922 - acc: 0.9717\n",
      "Epoch 00030: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0922 - acc: 0.9717 - val_loss: 0.5221 - val_acc: 0.9054\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9720\n",
      "Epoch 00031: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0919 - acc: 0.9719 - val_loss: 0.4942 - val_acc: 0.9066\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9728\n",
      "Epoch 00032: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0860 - acc: 0.9728 - val_loss: 0.5040 - val_acc: 0.9047\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9726\n",
      "Epoch 00033: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0877 - acc: 0.9726 - val_loss: 0.5104 - val_acc: 0.9096\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9762\n",
      "Epoch 00034: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0795 - acc: 0.9762 - val_loss: 0.5219 - val_acc: 0.9059\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9765\n",
      "Epoch 00035: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0788 - acc: 0.9765 - val_loss: 0.5193 - val_acc: 0.9064\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9770\n",
      "Epoch 00036: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0766 - acc: 0.9770 - val_loss: 0.5303 - val_acc: 0.9050\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9772\n",
      "Epoch 00037: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0762 - acc: 0.9772 - val_loss: 0.5235 - val_acc: 0.9026\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9798\n",
      "Epoch 00038: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 492us/sample - loss: 0.0690 - acc: 0.9797 - val_loss: 0.5396 - val_acc: 0.9036\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9778\n",
      "Epoch 00039: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0716 - acc: 0.9778 - val_loss: 0.5338 - val_acc: 0.9050\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9802\n",
      "Epoch 00040: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0685 - acc: 0.9802 - val_loss: 0.5580 - val_acc: 0.9005\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9789\n",
      "Epoch 00041: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0672 - acc: 0.9789 - val_loss: 0.5502 - val_acc: 0.9045\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9795\n",
      "Epoch 00042: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0674 - acc: 0.9795 - val_loss: 0.5606 - val_acc: 0.9040\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9818\n",
      "Epoch 00043: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0621 - acc: 0.9818 - val_loss: 0.5651 - val_acc: 0.9054\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9824\n",
      "Epoch 00044: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0603 - acc: 0.9824 - val_loss: 0.5694 - val_acc: 0.9047\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9831\n",
      "Epoch 00045: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0593 - acc: 0.9830 - val_loss: 0.5616 - val_acc: 0.9045\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9824\n",
      "Epoch 00046: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0608 - acc: 0.9824 - val_loss: 0.5568 - val_acc: 0.9082\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9830\n",
      "Epoch 00047: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0575 - acc: 0.9830 - val_loss: 0.5711 - val_acc: 0.9017\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9845\n",
      "Epoch 00048: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0559 - acc: 0.9845 - val_loss: 0.5576 - val_acc: 0.9050\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9843\n",
      "Epoch 00049: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0537 - acc: 0.9843 - val_loss: 0.5610 - val_acc: 0.9045\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9841\n",
      "Epoch 00050: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0523 - acc: 0.9841 - val_loss: 0.5391 - val_acc: 0.9073\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9847\n",
      "Epoch 00051: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.0521 - acc: 0.9847 - val_loss: 0.5666 - val_acc: 0.9040\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9850\n",
      "Epoch 00052: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0537 - acc: 0.9850 - val_loss: 0.5718 - val_acc: 0.9017\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9853\n",
      "Epoch 00053: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0499 - acc: 0.9853 - val_loss: 0.5768 - val_acc: 0.9064\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9858\n",
      "Epoch 00054: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0493 - acc: 0.9858 - val_loss: 0.5771 - val_acc: 0.9057\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9854\n",
      "Epoch 00055: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 19s 503us/sample - loss: 0.0496 - acc: 0.9854 - val_loss: 0.5668 - val_acc: 0.9008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9856\n",
      "Epoch 00056: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0478 - acc: 0.9856 - val_loss: 0.5780 - val_acc: 0.9036\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9865\n",
      "Epoch 00057: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0454 - acc: 0.9865 - val_loss: 0.5720 - val_acc: 0.9024\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9862\n",
      "Epoch 00058: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 494us/sample - loss: 0.0502 - acc: 0.9862 - val_loss: 0.5885 - val_acc: 0.9052\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9875\n",
      "Epoch 00059: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0448 - acc: 0.9875 - val_loss: 0.5836 - val_acc: 0.9054\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9879\n",
      "Epoch 00060: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0435 - acc: 0.9879 - val_loss: 0.5724 - val_acc: 0.9052\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0437 - acc: 0.9876\n",
      "Epoch 00061: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0437 - acc: 0.9876 - val_loss: 0.5623 - val_acc: 0.9061\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9878\n",
      "Epoch 00062: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0409 - acc: 0.9878 - val_loss: 0.5716 - val_acc: 0.9073\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0428 - acc: 0.9881\n",
      "Epoch 00063: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.0428 - acc: 0.9881 - val_loss: 0.5723 - val_acc: 0.9054\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9882\n",
      "Epoch 00064: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0424 - acc: 0.9882 - val_loss: 0.5666 - val_acc: 0.9101\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9892\n",
      "Epoch 00065: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0396 - acc: 0.9892 - val_loss: 0.5698 - val_acc: 0.9075\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9887\n",
      "Epoch 00066: val_loss did not improve from 0.45867\n",
      "36805/36805 [==============================] - 18s 491us/sample - loss: 0.0390 - acc: 0.9887 - val_loss: 0.5698 - val_acc: 0.9064\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 265us/sample - loss: 0.5499 - acc: 0.8648\n",
      "Loss: 0.5498564678436747 Accuracy: 0.86479753\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5729 - acc: 0.5135\n",
      "Epoch 00001: val_loss improved from inf to 0.94064, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/001-0.9406.hdf5\n",
      "36805/36805 [==============================] - 21s 570us/sample - loss: 1.5728 - acc: 0.5135 - val_loss: 0.9406 - val_acc: 0.7459\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8544 - acc: 0.7435\n",
      "Epoch 00002: val_loss improved from 0.94064 to 0.59847, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/002-0.5985.hdf5\n",
      "36805/36805 [==============================] - 20s 534us/sample - loss: 0.8544 - acc: 0.7435 - val_loss: 0.5985 - val_acc: 0.8449\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6125 - acc: 0.8143\n",
      "Epoch 00003: val_loss improved from 0.59847 to 0.47716, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/003-0.4772.hdf5\n",
      "36805/36805 [==============================] - 20s 537us/sample - loss: 0.6126 - acc: 0.8143 - val_loss: 0.4772 - val_acc: 0.8724\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4907 - acc: 0.8511\n",
      "Epoch 00004: val_loss improved from 0.47716 to 0.41569, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/004-0.4157.hdf5\n",
      "36805/36805 [==============================] - 20s 544us/sample - loss: 0.4907 - acc: 0.8511 - val_loss: 0.4157 - val_acc: 0.8880\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4184 - acc: 0.8726\n",
      "Epoch 00005: val_loss improved from 0.41569 to 0.39693, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/005-0.3969.hdf5\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.4184 - acc: 0.8726 - val_loss: 0.3969 - val_acc: 0.8882\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3641 - acc: 0.8877\n",
      "Epoch 00006: val_loss improved from 0.39693 to 0.33957, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/006-0.3396.hdf5\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.3641 - acc: 0.8878 - val_loss: 0.3396 - val_acc: 0.9108\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3256 - acc: 0.8995\n",
      "Epoch 00007: val_loss improved from 0.33957 to 0.32068, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/007-0.3207.hdf5\n",
      "36805/36805 [==============================] - 20s 534us/sample - loss: 0.3255 - acc: 0.8995 - val_loss: 0.3207 - val_acc: 0.9175\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2890 - acc: 0.9107\n",
      "Epoch 00008: val_loss improved from 0.32068 to 0.30387, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/008-0.3039.hdf5\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.2890 - acc: 0.9107 - val_loss: 0.3039 - val_acc: 0.9168\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2651 - acc: 0.9189\n",
      "Epoch 00009: val_loss improved from 0.30387 to 0.29356, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/009-0.2936.hdf5\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.2651 - acc: 0.9188 - val_loss: 0.2936 - val_acc: 0.9189\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2429 - acc: 0.9239\n",
      "Epoch 00010: val_loss improved from 0.29356 to 0.27456, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/010-0.2746.hdf5\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.2430 - acc: 0.9239 - val_loss: 0.2746 - val_acc: 0.9287\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2213 - acc: 0.9315\n",
      "Epoch 00011: val_loss did not improve from 0.27456\n",
      "36805/36805 [==============================] - 20s 537us/sample - loss: 0.2213 - acc: 0.9315 - val_loss: 0.2784 - val_acc: 0.9229\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2073 - acc: 0.9343\n",
      "Epoch 00012: val_loss improved from 0.27456 to 0.26785, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/012-0.2679.hdf5\n",
      "36805/36805 [==============================] - 20s 543us/sample - loss: 0.2073 - acc: 0.9343 - val_loss: 0.2679 - val_acc: 0.9297\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1913 - acc: 0.9400\n",
      "Epoch 00013: val_loss improved from 0.26785 to 0.26216, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/013-0.2622.hdf5\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.1913 - acc: 0.9400 - val_loss: 0.2622 - val_acc: 0.9283\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1827 - acc: 0.9426\n",
      "Epoch 00014: val_loss improved from 0.26216 to 0.25238, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/014-0.2524.hdf5\n",
      "36805/36805 [==============================] - 20s 543us/sample - loss: 0.1827 - acc: 0.9426 - val_loss: 0.2524 - val_acc: 0.9334\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1675 - acc: 0.9470\n",
      "Epoch 00015: val_loss improved from 0.25238 to 0.24288, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/015-0.2429.hdf5\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.1674 - acc: 0.9470 - val_loss: 0.2429 - val_acc: 0.9392\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1593 - acc: 0.9489\n",
      "Epoch 00016: val_loss did not improve from 0.24288\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.1593 - acc: 0.9489 - val_loss: 0.2560 - val_acc: 0.9355\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9523\n",
      "Epoch 00017: val_loss did not improve from 0.24288\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.1483 - acc: 0.9523 - val_loss: 0.2638 - val_acc: 0.9348\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1396 - acc: 0.9548\n",
      "Epoch 00018: val_loss did not improve from 0.24288\n",
      "36805/36805 [==============================] - 20s 533us/sample - loss: 0.1396 - acc: 0.9548 - val_loss: 0.2464 - val_acc: 0.9397\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1337 - acc: 0.9578\n",
      "Epoch 00019: val_loss improved from 0.24288 to 0.24087, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/019-0.2409.hdf5\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.1337 - acc: 0.9578 - val_loss: 0.2409 - val_acc: 0.9380\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9588\n",
      "Epoch 00020: val_loss did not improve from 0.24087\n",
      "36805/36805 [==============================] - 20s 535us/sample - loss: 0.1274 - acc: 0.9588 - val_loss: 0.2412 - val_acc: 0.9380\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9605\n",
      "Epoch 00021: val_loss improved from 0.24087 to 0.23454, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_3_conv_checkpoint/021-0.2345.hdf5\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.1202 - acc: 0.9605 - val_loss: 0.2345 - val_acc: 0.9411\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1167 - acc: 0.9622\n",
      "Epoch 00022: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.1167 - acc: 0.9622 - val_loss: 0.2581 - val_acc: 0.9378\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1111 - acc: 0.9643\n",
      "Epoch 00023: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.1110 - acc: 0.9643 - val_loss: 0.2513 - val_acc: 0.9397\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1061 - acc: 0.9654\n",
      "Epoch 00024: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.1062 - acc: 0.9654 - val_loss: 0.2481 - val_acc: 0.9411\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9678\n",
      "Epoch 00025: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 535us/sample - loss: 0.1015 - acc: 0.9678 - val_loss: 0.2472 - val_acc: 0.9443\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9684\n",
      "Epoch 00026: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.0959 - acc: 0.9684 - val_loss: 0.2562 - val_acc: 0.9441\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9696\n",
      "Epoch 00027: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.0938 - acc: 0.9696 - val_loss: 0.2479 - val_acc: 0.9397\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9698\n",
      "Epoch 00028: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 534us/sample - loss: 0.0900 - acc: 0.9698 - val_loss: 0.2584 - val_acc: 0.9464\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9712\n",
      "Epoch 00029: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.0896 - acc: 0.9712 - val_loss: 0.2475 - val_acc: 0.9450\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9731\n",
      "Epoch 00030: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 535us/sample - loss: 0.0838 - acc: 0.9731 - val_loss: 0.2425 - val_acc: 0.9455\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9733\n",
      "Epoch 00031: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0800 - acc: 0.9733 - val_loss: 0.2561 - val_acc: 0.9469\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9744\n",
      "Epoch 00032: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 537us/sample - loss: 0.0784 - acc: 0.9744 - val_loss: 0.2552 - val_acc: 0.9453\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9754\n",
      "Epoch 00033: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 544us/sample - loss: 0.0769 - acc: 0.9754 - val_loss: 0.2474 - val_acc: 0.9478\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0745 - acc: 0.9760\n",
      "Epoch 00034: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0745 - acc: 0.9760 - val_loss: 0.2615 - val_acc: 0.9406\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9768\n",
      "Epoch 00035: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0711 - acc: 0.9769 - val_loss: 0.2558 - val_acc: 0.9429\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9768\n",
      "Epoch 00036: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0706 - acc: 0.9768 - val_loss: 0.2531 - val_acc: 0.9457\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9776\n",
      "Epoch 00037: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 536us/sample - loss: 0.0703 - acc: 0.9776 - val_loss: 0.2769 - val_acc: 0.9429\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9775\n",
      "Epoch 00038: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 532us/sample - loss: 0.0696 - acc: 0.9775 - val_loss: 0.2720 - val_acc: 0.9415\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9790- ETA: 1s - l\n",
      "Epoch 00039: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 543us/sample - loss: 0.0650 - acc: 0.9790 - val_loss: 0.2533 - val_acc: 0.9453\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9790\n",
      "Epoch 00040: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 535us/sample - loss: 0.0651 - acc: 0.9790 - val_loss: 0.2556 - val_acc: 0.9448\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9797\n",
      "Epoch 00041: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0619 - acc: 0.9797 - val_loss: 0.2617 - val_acc: 0.9443\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9797\n",
      "Epoch 00042: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.0629 - acc: 0.9797 - val_loss: 0.2799 - val_acc: 0.9441\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9804\n",
      "Epoch 00043: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.0607 - acc: 0.9804 - val_loss: 0.2568 - val_acc: 0.9441\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9802\n",
      "Epoch 00044: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0600 - acc: 0.9802 - val_loss: 0.2854 - val_acc: 0.9453\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9817\n",
      "Epoch 00045: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 542us/sample - loss: 0.0585 - acc: 0.9817 - val_loss: 0.2752 - val_acc: 0.9443\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9816\n",
      "Epoch 00046: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0560 - acc: 0.9816 - val_loss: 0.2740 - val_acc: 0.9453\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9829\n",
      "Epoch 00047: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.0539 - acc: 0.9829 - val_loss: 0.2863 - val_acc: 0.9436\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9824\n",
      "Epoch 00048: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.0539 - acc: 0.9824 - val_loss: 0.2917 - val_acc: 0.9471\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9814\n",
      "Epoch 00049: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0553 - acc: 0.9814 - val_loss: 0.2966 - val_acc: 0.9450\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0521 - acc: 0.9828\n",
      "Epoch 00050: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 544us/sample - loss: 0.0521 - acc: 0.9828 - val_loss: 0.2626 - val_acc: 0.9469\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9845\n",
      "Epoch 00051: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 542us/sample - loss: 0.0494 - acc: 0.9844 - val_loss: 0.2989 - val_acc: 0.9441\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9830\n",
      "Epoch 00052: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0519 - acc: 0.9830 - val_loss: 0.2714 - val_acc: 0.9474\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9851\n",
      "Epoch 00053: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 537us/sample - loss: 0.0484 - acc: 0.9851 - val_loss: 0.2964 - val_acc: 0.9476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0498 - acc: 0.9839\n",
      "Epoch 00054: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 537us/sample - loss: 0.0498 - acc: 0.9839 - val_loss: 0.2666 - val_acc: 0.9495\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0531 - acc: 0.9826\n",
      "Epoch 00055: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.0531 - acc: 0.9826 - val_loss: 0.2922 - val_acc: 0.9481\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9851\n",
      "Epoch 00056: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0475 - acc: 0.9851 - val_loss: 0.2710 - val_acc: 0.9492\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9849\n",
      "Epoch 00057: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 540us/sample - loss: 0.0486 - acc: 0.9849 - val_loss: 0.2705 - val_acc: 0.9497\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9863\n",
      "Epoch 00058: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 539us/sample - loss: 0.0443 - acc: 0.9863 - val_loss: 0.2735 - val_acc: 0.9478\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9858\n",
      "Epoch 00059: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0434 - acc: 0.9858 - val_loss: 0.2859 - val_acc: 0.9481\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9859\n",
      "Epoch 00060: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 543us/sample - loss: 0.0451 - acc: 0.9859 - val_loss: 0.2968 - val_acc: 0.9495\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9857\n",
      "Epoch 00061: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0446 - acc: 0.9857 - val_loss: 0.2833 - val_acc: 0.9476\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9863\n",
      "Epoch 00062: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0444 - acc: 0.9863 - val_loss: 0.2869 - val_acc: 0.9492\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9869\n",
      "Epoch 00063: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 543us/sample - loss: 0.0415 - acc: 0.9869 - val_loss: 0.2850 - val_acc: 0.9485\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0418 - acc: 0.9867\n",
      "Epoch 00064: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 544us/sample - loss: 0.0418 - acc: 0.9867 - val_loss: 0.3124 - val_acc: 0.9476\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9879\n",
      "Epoch 00065: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 541us/sample - loss: 0.0397 - acc: 0.9879 - val_loss: 0.2715 - val_acc: 0.9497\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9879\n",
      "Epoch 00066: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 543us/sample - loss: 0.0382 - acc: 0.9879 - val_loss: 0.2971 - val_acc: 0.9513\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9871\n",
      "Epoch 00067: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 538us/sample - loss: 0.0400 - acc: 0.9871 - val_loss: 0.2982 - val_acc: 0.9476\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0423 - acc: 0.9868\n",
      "Epoch 00068: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 543us/sample - loss: 0.0423 - acc: 0.9868 - val_loss: 0.3037 - val_acc: 0.9497\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9886\n",
      "Epoch 00069: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 545us/sample - loss: 0.0372 - acc: 0.9886 - val_loss: 0.3010 - val_acc: 0.9515\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9869\n",
      "Epoch 00070: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 535us/sample - loss: 0.0411 - acc: 0.9869 - val_loss: 0.2908 - val_acc: 0.9495\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0390 - acc: 0.9875\n",
      "Epoch 00071: val_loss did not improve from 0.23454\n",
      "36805/36805 [==============================] - 20s 544us/sample - loss: 0.0390 - acc: 0.9875 - val_loss: 0.2831 - val_acc: 0.9471\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 301us/sample - loss: 0.3244 - acc: 0.9126\n",
      "Loss: 0.32435973173980276 Accuracy: 0.9125649\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8496 - acc: 0.4108\n",
      "Epoch 00001: val_loss improved from inf to 1.02945, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/001-1.0295.hdf5\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 1.8496 - acc: 0.4108 - val_loss: 1.0295 - val_acc: 0.7032\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0410 - acc: 0.6723\n",
      "Epoch 00002: val_loss improved from 1.02945 to 0.64948, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/002-0.6495.hdf5\n",
      "36805/36805 [==============================] - 21s 559us/sample - loss: 1.0410 - acc: 0.6723 - val_loss: 0.6495 - val_acc: 0.8157\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7524 - acc: 0.7617\n",
      "Epoch 00003: val_loss improved from 0.64948 to 0.49869, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/003-0.4987.hdf5\n",
      "36805/36805 [==============================] - 21s 562us/sample - loss: 0.7526 - acc: 0.7616 - val_loss: 0.4987 - val_acc: 0.8609\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6185 - acc: 0.8047\n",
      "Epoch 00004: val_loss improved from 0.49869 to 0.41641, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/004-0.4164.hdf5\n",
      "36805/36805 [==============================] - 21s 558us/sample - loss: 0.6184 - acc: 0.8047 - val_loss: 0.4164 - val_acc: 0.8798\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5246 - acc: 0.8350\n",
      "Epoch 00005: val_loss improved from 0.41641 to 0.38132, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/005-0.3813.hdf5\n",
      "36805/36805 [==============================] - 21s 563us/sample - loss: 0.5247 - acc: 0.8349 - val_loss: 0.3813 - val_acc: 0.8980\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4682 - acc: 0.8536\n",
      "Epoch 00006: val_loss improved from 0.38132 to 0.33502, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/006-0.3350.hdf5\n",
      "36805/36805 [==============================] - 21s 560us/sample - loss: 0.4682 - acc: 0.8536 - val_loss: 0.3350 - val_acc: 0.9040\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4171 - acc: 0.8665\n",
      "Epoch 00007: val_loss improved from 0.33502 to 0.30647, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/007-0.3065.hdf5\n",
      "36805/36805 [==============================] - 21s 560us/sample - loss: 0.4170 - acc: 0.8665 - val_loss: 0.3065 - val_acc: 0.9136\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3829 - acc: 0.8801\n",
      "Epoch 00008: val_loss improved from 0.30647 to 0.28225, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/008-0.2823.hdf5\n",
      "36805/36805 [==============================] - 21s 557us/sample - loss: 0.3829 - acc: 0.8801 - val_loss: 0.2823 - val_acc: 0.9243\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3493 - acc: 0.8872\n",
      "Epoch 00009: val_loss improved from 0.28225 to 0.26349, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/009-0.2635.hdf5\n",
      "36805/36805 [==============================] - 20s 552us/sample - loss: 0.3492 - acc: 0.8872 - val_loss: 0.2635 - val_acc: 0.9273\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3266 - acc: 0.8954\n",
      "Epoch 00010: val_loss improved from 0.26349 to 0.25319, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/010-0.2532.hdf5\n",
      "36805/36805 [==============================] - 20s 555us/sample - loss: 0.3266 - acc: 0.8954 - val_loss: 0.2532 - val_acc: 0.9292\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3019 - acc: 0.9047\n",
      "Epoch 00011: val_loss improved from 0.25319 to 0.23468, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/011-0.2347.hdf5\n",
      "36805/36805 [==============================] - 21s 557us/sample - loss: 0.3018 - acc: 0.9047 - val_loss: 0.2347 - val_acc: 0.9364\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2840 - acc: 0.9098\n",
      "Epoch 00012: val_loss improved from 0.23468 to 0.23430, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/012-0.2343.hdf5\n",
      "36805/36805 [==============================] - 21s 559us/sample - loss: 0.2840 - acc: 0.9098 - val_loss: 0.2343 - val_acc: 0.9357\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2660 - acc: 0.9154\n",
      "Epoch 00013: val_loss improved from 0.23430 to 0.22666, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/013-0.2267.hdf5\n",
      "36805/36805 [==============================] - 20s 556us/sample - loss: 0.2660 - acc: 0.9154 - val_loss: 0.2267 - val_acc: 0.9373\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2497 - acc: 0.9202\n",
      "Epoch 00014: val_loss improved from 0.22666 to 0.21684, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/014-0.2168.hdf5\n",
      "36805/36805 [==============================] - 21s 557us/sample - loss: 0.2498 - acc: 0.9202 - val_loss: 0.2168 - val_acc: 0.9413\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2382 - acc: 0.9238\n",
      "Epoch 00015: val_loss improved from 0.21684 to 0.20943, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/015-0.2094.hdf5\n",
      "36805/36805 [==============================] - 21s 558us/sample - loss: 0.2381 - acc: 0.9238 - val_loss: 0.2094 - val_acc: 0.9420\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2226 - acc: 0.9295\n",
      "Epoch 00016: val_loss improved from 0.20943 to 0.20881, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/016-0.2088.hdf5\n",
      "36805/36805 [==============================] - 20s 556us/sample - loss: 0.2226 - acc: 0.9295 - val_loss: 0.2088 - val_acc: 0.9441\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9338\n",
      "Epoch 00017: val_loss improved from 0.20881 to 0.19848, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/017-0.1985.hdf5\n",
      "36805/36805 [==============================] - 20s 554us/sample - loss: 0.2115 - acc: 0.9338 - val_loss: 0.1985 - val_acc: 0.9476\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2009 - acc: 0.9360- ETA: 0s - loss: 0.2015 - ac\n",
      "Epoch 00018: val_loss improved from 0.19848 to 0.19789, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/018-0.1979.hdf5\n",
      "36805/36805 [==============================] - 21s 563us/sample - loss: 0.2009 - acc: 0.9360 - val_loss: 0.1979 - val_acc: 0.9471\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9370\n",
      "Epoch 00019: val_loss improved from 0.19789 to 0.18479, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/019-0.1848.hdf5\n",
      "36805/36805 [==============================] - 21s 558us/sample - loss: 0.1959 - acc: 0.9370 - val_loss: 0.1848 - val_acc: 0.9518\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1848 - acc: 0.9408\n",
      "Epoch 00020: val_loss did not improve from 0.18479\n",
      "36805/36805 [==============================] - 20s 553us/sample - loss: 0.1848 - acc: 0.9407 - val_loss: 0.1863 - val_acc: 0.9520\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1768 - acc: 0.9418\n",
      "Epoch 00021: val_loss did not improve from 0.18479\n",
      "36805/36805 [==============================] - 20s 553us/sample - loss: 0.1768 - acc: 0.9419 - val_loss: 0.1983 - val_acc: 0.9462\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1697 - acc: 0.9460\n",
      "Epoch 00022: val_loss did not improve from 0.18479\n",
      "36805/36805 [==============================] - 21s 558us/sample - loss: 0.1698 - acc: 0.9460 - val_loss: 0.1907 - val_acc: 0.9515\n",
      "Epoch 23/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9476\n",
      "Epoch 00023: val_loss did not improve from 0.18479\n",
      "36805/36805 [==============================] - 21s 559us/sample - loss: 0.1621 - acc: 0.9476 - val_loss: 0.1909 - val_acc: 0.9513\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9483\n",
      "Epoch 00024: val_loss improved from 0.18479 to 0.18453, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/024-0.1845.hdf5\n",
      "36805/36805 [==============================] - 21s 563us/sample - loss: 0.1581 - acc: 0.9482 - val_loss: 0.1845 - val_acc: 0.9522\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9499\n",
      "Epoch 00025: val_loss improved from 0.18453 to 0.17925, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/025-0.1793.hdf5\n",
      "36805/36805 [==============================] - 21s 558us/sample - loss: 0.1535 - acc: 0.9499 - val_loss: 0.1793 - val_acc: 0.9546\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9520\n",
      "Epoch 00026: val_loss improved from 0.17925 to 0.17688, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/026-0.1769.hdf5\n",
      "36805/36805 [==============================] - 21s 560us/sample - loss: 0.1476 - acc: 0.9519 - val_loss: 0.1769 - val_acc: 0.9571\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1414 - acc: 0.9536\n",
      "Epoch 00027: val_loss did not improve from 0.17688\n",
      "36805/36805 [==============================] - 21s 557us/sample - loss: 0.1414 - acc: 0.9536 - val_loss: 0.1779 - val_acc: 0.9536\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9543\n",
      "Epoch 00028: val_loss did not improve from 0.17688\n",
      "36805/36805 [==============================] - 20s 556us/sample - loss: 0.1367 - acc: 0.9543 - val_loss: 0.1815 - val_acc: 0.9527\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1312 - acc: 0.9567\n",
      "Epoch 00029: val_loss improved from 0.17688 to 0.17630, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/029-0.1763.hdf5\n",
      "36805/36805 [==============================] - 20s 551us/sample - loss: 0.1312 - acc: 0.9567 - val_loss: 0.1763 - val_acc: 0.9553\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1273 - acc: 0.9580\n",
      "Epoch 00030: val_loss improved from 0.17630 to 0.17445, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/030-0.1744.hdf5\n",
      "36805/36805 [==============================] - 21s 557us/sample - loss: 0.1273 - acc: 0.9580 - val_loss: 0.1744 - val_acc: 0.9581\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1216 - acc: 0.9605\n",
      "Epoch 00031: val_loss did not improve from 0.17445\n",
      "36805/36805 [==============================] - 21s 560us/sample - loss: 0.1216 - acc: 0.9605 - val_loss: 0.1781 - val_acc: 0.9546\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1202 - acc: 0.9608\n",
      "Epoch 00032: val_loss did not improve from 0.17445\n",
      "36805/36805 [==============================] - 21s 563us/sample - loss: 0.1203 - acc: 0.9608 - val_loss: 0.1754 - val_acc: 0.9583\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9608\n",
      "Epoch 00033: val_loss did not improve from 0.17445\n",
      "36805/36805 [==============================] - 21s 558us/sample - loss: 0.1165 - acc: 0.9608 - val_loss: 0.1910 - val_acc: 0.9553\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9621\n",
      "Epoch 00034: val_loss did not improve from 0.17445\n",
      "36805/36805 [==============================] - 20s 553us/sample - loss: 0.1141 - acc: 0.9621 - val_loss: 0.1794 - val_acc: 0.9576\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9638\n",
      "Epoch 00035: val_loss did not improve from 0.17445\n",
      "36805/36805 [==============================] - 21s 561us/sample - loss: 0.1087 - acc: 0.9638 - val_loss: 0.1808 - val_acc: 0.9576\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9651\n",
      "Epoch 00036: val_loss did not improve from 0.17445\n",
      "36805/36805 [==============================] - 20s 555us/sample - loss: 0.1065 - acc: 0.9651 - val_loss: 0.2073 - val_acc: 0.9564\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9649\n",
      "Epoch 00037: val_loss did not improve from 0.17445\n",
      "36805/36805 [==============================] - 20s 557us/sample - loss: 0.1048 - acc: 0.9650 - val_loss: 0.1820 - val_acc: 0.9553\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1031 - acc: 0.9655\n",
      "Epoch 00038: val_loss improved from 0.17445 to 0.16504, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/038-0.1650.hdf5\n",
      "36805/36805 [==============================] - 21s 559us/sample - loss: 0.1031 - acc: 0.9655 - val_loss: 0.1650 - val_acc: 0.9562\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9673\n",
      "Epoch 00039: val_loss improved from 0.16504 to 0.16262, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_4_conv_checkpoint/039-0.1626.hdf5\n",
      "36805/36805 [==============================] - 21s 560us/sample - loss: 0.0997 - acc: 0.9673 - val_loss: 0.1626 - val_acc: 0.9609\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9670\n",
      "Epoch 00040: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 560us/sample - loss: 0.0981 - acc: 0.9670 - val_loss: 0.1780 - val_acc: 0.9597\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9683\n",
      "Epoch 00041: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 555us/sample - loss: 0.0963 - acc: 0.9683 - val_loss: 0.1774 - val_acc: 0.9571\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9694\n",
      "Epoch 00042: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 560us/sample - loss: 0.0921 - acc: 0.9694 - val_loss: 0.1725 - val_acc: 0.9590\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9699\n",
      "Epoch 00043: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 561us/sample - loss: 0.0892 - acc: 0.9699 - val_loss: 0.1950 - val_acc: 0.9576\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9718\n",
      "Epoch 00044: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 553us/sample - loss: 0.0889 - acc: 0.9718 - val_loss: 0.1822 - val_acc: 0.9576\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9715\n",
      "Epoch 00045: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 559us/sample - loss: 0.0852 - acc: 0.9715 - val_loss: 0.1747 - val_acc: 0.9590\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9730\n",
      "Epoch 00046: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 556us/sample - loss: 0.0811 - acc: 0.9730 - val_loss: 0.1683 - val_acc: 0.9602\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0856 - acc: 0.9718\n",
      "Epoch 00047: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 556us/sample - loss: 0.0856 - acc: 0.9718 - val_loss: 0.1838 - val_acc: 0.9581\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0796 - acc: 0.9736\n",
      "Epoch 00048: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 552us/sample - loss: 0.0798 - acc: 0.9736 - val_loss: 0.1945 - val_acc: 0.9571\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.972 - ETA: 0s - loss: 0.0842 - acc: 0.9721\n",
      "Epoch 00049: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 552us/sample - loss: 0.0842 - acc: 0.9721 - val_loss: 0.1861 - val_acc: 0.9578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9743\n",
      "Epoch 00050: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 554us/sample - loss: 0.0764 - acc: 0.9744 - val_loss: 0.1762 - val_acc: 0.9585\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9751\n",
      "Epoch 00051: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 555us/sample - loss: 0.0733 - acc: 0.9751 - val_loss: 0.1777 - val_acc: 0.9567\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9746\n",
      "Epoch 00052: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 555us/sample - loss: 0.0742 - acc: 0.9747 - val_loss: 0.1922 - val_acc: 0.9590\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0721 - acc: 0.9760\n",
      "Epoch 00053: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 558us/sample - loss: 0.0721 - acc: 0.9760 - val_loss: 0.1849 - val_acc: 0.9595\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0694 - acc: 0.9773\n",
      "Epoch 00054: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 557us/sample - loss: 0.0694 - acc: 0.9773 - val_loss: 0.1997 - val_acc: 0.9590\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9758\n",
      "Epoch 00055: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 559us/sample - loss: 0.0711 - acc: 0.9758 - val_loss: 0.1880 - val_acc: 0.9604\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9768\n",
      "Epoch 00056: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 559us/sample - loss: 0.0707 - acc: 0.9768 - val_loss: 0.1877 - val_acc: 0.9571\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9788\n",
      "Epoch 00057: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 554us/sample - loss: 0.0657 - acc: 0.9788 - val_loss: 0.1936 - val_acc: 0.9588\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0646 - acc: 0.9783\n",
      "Epoch 00058: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 557us/sample - loss: 0.0646 - acc: 0.9783 - val_loss: 0.2005 - val_acc: 0.9604\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0671 - acc: 0.9775\n",
      "Epoch 00059: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 556us/sample - loss: 0.0671 - acc: 0.9775 - val_loss: 0.1911 - val_acc: 0.9620\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9771\n",
      "Epoch 00060: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 555us/sample - loss: 0.0658 - acc: 0.9771 - val_loss: 0.2087 - val_acc: 0.9592\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9779- ETA\n",
      "Epoch 00061: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 556us/sample - loss: 0.0651 - acc: 0.9778 - val_loss: 0.2184 - val_acc: 0.9583\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9791\n",
      "Epoch 00062: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 553us/sample - loss: 0.0651 - acc: 0.9791 - val_loss: 0.1979 - val_acc: 0.9581\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0620 - acc: 0.9797\n",
      "Epoch 00063: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 561us/sample - loss: 0.0621 - acc: 0.9797 - val_loss: 0.1850 - val_acc: 0.9585\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9799\n",
      "Epoch 00064: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 557us/sample - loss: 0.0628 - acc: 0.9799 - val_loss: 0.2011 - val_acc: 0.9562\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0580 - acc: 0.9806\n",
      "Epoch 00065: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 559us/sample - loss: 0.0580 - acc: 0.9806 - val_loss: 0.1850 - val_acc: 0.9592\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9807\n",
      "Epoch 00066: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 554us/sample - loss: 0.0583 - acc: 0.9807 - val_loss: 0.1881 - val_acc: 0.9597\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9813\n",
      "Epoch 00067: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 558us/sample - loss: 0.0597 - acc: 0.9813 - val_loss: 0.2035 - val_acc: 0.9616\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0576 - acc: 0.9817\n",
      "Epoch 00068: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 553us/sample - loss: 0.0576 - acc: 0.9817 - val_loss: 0.2038 - val_acc: 0.9604\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9812\n",
      "Epoch 00069: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 557us/sample - loss: 0.0567 - acc: 0.9812 - val_loss: 0.1829 - val_acc: 0.9599\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9804\n",
      "Epoch 00070: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 560us/sample - loss: 0.0609 - acc: 0.9804 - val_loss: 0.2175 - val_acc: 0.9571\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0525 - acc: 0.9822\n",
      "Epoch 00071: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 555us/sample - loss: 0.0526 - acc: 0.9822 - val_loss: 0.1962 - val_acc: 0.9595\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9827- ETA: 1s - loss: \n",
      "Epoch 00072: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 557us/sample - loss: 0.0541 - acc: 0.9827 - val_loss: 0.2103 - val_acc: 0.9599\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0551 - acc: 0.9821\n",
      "Epoch 00073: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 554us/sample - loss: 0.0551 - acc: 0.9821 - val_loss: 0.1927 - val_acc: 0.9606\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9826\n",
      "Epoch 00074: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 561us/sample - loss: 0.0536 - acc: 0.9826 - val_loss: 0.2018 - val_acc: 0.9590\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9835\n",
      "Epoch 00075: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 558us/sample - loss: 0.0509 - acc: 0.9835 - val_loss: 0.2071 - val_acc: 0.9581\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9832\n",
      "Epoch 00076: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 554us/sample - loss: 0.0503 - acc: 0.9832 - val_loss: 0.2080 - val_acc: 0.9602\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0527 - acc: 0.9823\n",
      "Epoch 00077: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 557us/sample - loss: 0.0527 - acc: 0.9823 - val_loss: 0.2128 - val_acc: 0.9590\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9843\n",
      "Epoch 00078: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 564us/sample - loss: 0.0490 - acc: 0.9843 - val_loss: 0.2120 - val_acc: 0.9599\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9840\n",
      "Epoch 00079: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 555us/sample - loss: 0.0495 - acc: 0.9840 - val_loss: 0.2073 - val_acc: 0.9616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9844\n",
      "Epoch 00080: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 550us/sample - loss: 0.0480 - acc: 0.9844 - val_loss: 0.2051 - val_acc: 0.9583\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9846\n",
      "Epoch 00081: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 554us/sample - loss: 0.0473 - acc: 0.9846 - val_loss: 0.2173 - val_acc: 0.9590\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9837\n",
      "Epoch 00082: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 559us/sample - loss: 0.0515 - acc: 0.9837 - val_loss: 0.2123 - val_acc: 0.9590\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9837\n",
      "Epoch 00083: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 557us/sample - loss: 0.0476 - acc: 0.9837 - val_loss: 0.2239 - val_acc: 0.9604\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9844\n",
      "Epoch 00084: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 560us/sample - loss: 0.0479 - acc: 0.9844 - val_loss: 0.2217 - val_acc: 0.9564\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9860\n",
      "Epoch 00085: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 21s 560us/sample - loss: 0.0440 - acc: 0.9860 - val_loss: 0.2262 - val_acc: 0.9597\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9846\n",
      "Epoch 00086: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 554us/sample - loss: 0.0463 - acc: 0.9846 - val_loss: 0.2062 - val_acc: 0.9613\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0463 - acc: 0.9855\n",
      "Epoch 00087: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 554us/sample - loss: 0.0463 - acc: 0.9855 - val_loss: 0.2329 - val_acc: 0.9627\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9846\n",
      "Epoch 00088: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 553us/sample - loss: 0.0460 - acc: 0.9846 - val_loss: 0.2100 - val_acc: 0.9581\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9846\n",
      "Epoch 00089: val_loss did not improve from 0.16262\n",
      "36805/36805 [==============================] - 20s 555us/sample - loss: 0.0449 - acc: 0.9846 - val_loss: 0.2131 - val_acc: 0.9590\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 322us/sample - loss: 0.2328 - acc: 0.9360\n",
      "Loss: 0.23281810850616805 Accuracy: 0.93603325\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    base = '2D_CNN_only_conv_ch_32_DO'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_2d_cnn_only_conv_ch_32_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_2d_norm, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_2d_norm, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "    \n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2D_CNN_only_conv_ch_32_DO_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                3121168   \n",
      "=================================================================\n",
      "Total params: 3,122,000\n",
      "Trainable params: 3,122,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 1s 257us/sample - loss: 1.1429 - acc: 0.7099\n",
      "Loss: 1.1429275806571588 Accuracy: 0.70986503\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                698384    \n",
      "=================================================================\n",
      "Total params: 724,848\n",
      "Trainable params: 724,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 1s 284us/sample - loss: 0.5499 - acc: 0.8648\n",
      "Loss: 0.5498564678436747 Accuracy: 0.86479753\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                267280    \n",
      "=================================================================\n",
      "Total params: 345,008\n",
      "Trainable params: 345,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 316us/sample - loss: 0.3244 - acc: 0.9126\n",
      "Loss: 0.32435973173980276 Accuracy: 0.9125649\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 25, 5, 64)         102464    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 25, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 13, 3, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                39952     \n",
      "=================================================================\n",
      "Total params: 220,144\n",
      "Trainable params: 220,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 315us/sample - loss: 0.2328 - acc: 0.9360\n",
      "Loss: 0.23281810850616805 Accuracy: 0.93603325\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '2D_CNN_only_conv_ch_32_DO'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 5):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_only_conv_ch_32_BN(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    \n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=32*(2**int((i)/2)), strides=(1,1), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 195072)            780288    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                3121168   \n",
      "=================================================================\n",
      "Total params: 3,902,416\n",
      "Trainable params: 3,512,208\n",
      "Non-trainable params: 390,208\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 43648)             174592    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                698384    \n",
      "=================================================================\n",
      "Total params: 899,696\n",
      "Trainable params: 812,272\n",
      "Non-trainable params: 87,424\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16704)             66816     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                267280    \n",
      "=================================================================\n",
      "Total params: 412,336\n",
      "Trainable params: 378,672\n",
      "Non-trainable params: 33,664\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 25, 5, 64)         102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 25, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 25, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 13, 3, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 2496)              9984      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                39952     \n",
      "=================================================================\n",
      "Total params: 230,896\n",
      "Trainable params: 225,520\n",
      "Non-trainable params: 5,376\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model = build_2d_cnn_only_conv_ch_32_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1498 - acc: 0.5460\n",
      "Epoch 00001: val_loss improved from inf to 1.65534, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_1_conv_checkpoint/001-1.6553.hdf5\n",
      "36805/36805 [==============================] - 26s 694us/sample - loss: 2.1499 - acc: 0.5459 - val_loss: 1.6553 - val_acc: 0.6164\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9707 - acc: 0.7618\n",
      "Epoch 00002: val_loss did not improve from 1.65534\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.9711 - acc: 0.7618 - val_loss: 1.7016 - val_acc: 0.6587\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5626 - acc: 0.8481\n",
      "Epoch 00003: val_loss improved from 1.65534 to 1.65040, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_1_conv_checkpoint/003-1.6504.hdf5\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.5625 - acc: 0.8481 - val_loss: 1.6504 - val_acc: 0.6646\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3371 - acc: 0.9103\n",
      "Epoch 00004: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.3371 - acc: 0.9103 - val_loss: 1.7231 - val_acc: 0.6643\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2593 - acc: 0.9297\n",
      "Epoch 00005: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.2596 - acc: 0.9297 - val_loss: 1.7329 - val_acc: 0.6727\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2108 - acc: 0.9438\n",
      "Epoch 00006: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.2110 - acc: 0.9438 - val_loss: 1.8140 - val_acc: 0.6723\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1972 - acc: 0.9480\n",
      "Epoch 00007: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 0.1972 - acc: 0.9481 - val_loss: 1.9047 - val_acc: 0.6790\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1905 - acc: 0.9495\n",
      "Epoch 00008: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.1906 - acc: 0.9494 - val_loss: 1.9656 - val_acc: 0.6695\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1660 - acc: 0.9571\n",
      "Epoch 00009: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.1663 - acc: 0.9570 - val_loss: 2.2110 - val_acc: 0.6562\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9509\n",
      "Epoch 00010: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.1912 - acc: 0.9508 - val_loss: 2.0959 - val_acc: 0.6767\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1511 - acc: 0.9614\n",
      "Epoch 00011: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.1514 - acc: 0.9613 - val_loss: 2.1103 - val_acc: 0.6818\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1421 - acc: 0.9645\n",
      "Epoch 00012: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 611us/sample - loss: 0.1421 - acc: 0.9645 - val_loss: 2.2063 - val_acc: 0.6790\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9739\n",
      "Epoch 00013: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.1151 - acc: 0.9738 - val_loss: 2.2405 - val_acc: 0.6799\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1221 - acc: 0.9712\n",
      "Epoch 00014: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.1228 - acc: 0.9711 - val_loss: 2.2450 - val_acc: 0.6774\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9673\n",
      "Epoch 00015: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.1334 - acc: 0.9673 - val_loss: 2.3195 - val_acc: 0.6765\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1119 - acc: 0.9747\n",
      "Epoch 00016: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.1119 - acc: 0.9747 - val_loss: 2.3932 - val_acc: 0.6748\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9735\n",
      "Epoch 00017: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.1117 - acc: 0.9734 - val_loss: 2.4558 - val_acc: 0.6688\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9768\n",
      "Epoch 00018: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.1019 - acc: 0.9768 - val_loss: 2.4195 - val_acc: 0.6855\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9804\n",
      "Epoch 00019: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.0887 - acc: 0.9804 - val_loss: 2.3886 - val_acc: 0.6872\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9747\n",
      "Epoch 00020: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.1132 - acc: 0.9747 - val_loss: 2.5939 - val_acc: 0.6741\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0900 - acc: 0.9809\n",
      "Epoch 00021: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.0900 - acc: 0.9809 - val_loss: 2.5386 - val_acc: 0.6797\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9828\n",
      "Epoch 00022: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.0827 - acc: 0.9828 - val_loss: 2.6392 - val_acc: 0.6660\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9837\n",
      "Epoch 00023: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.0785 - acc: 0.9837 - val_loss: 2.5099 - val_acc: 0.6867\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9793\n",
      "Epoch 00024: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.0931 - acc: 0.9792 - val_loss: 2.6388 - val_acc: 0.6767\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9781\n",
      "Epoch 00025: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.1096 - acc: 0.9781 - val_loss: 2.6005 - val_acc: 0.6792\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9828\n",
      "Epoch 00026: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.0851 - acc: 0.9828 - val_loss: 2.5721 - val_acc: 0.6858\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9833\n",
      "Epoch 00027: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.0798 - acc: 0.9833 - val_loss: 2.5457 - val_acc: 0.6925\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9842\n",
      "Epoch 00028: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.0772 - acc: 0.9842 - val_loss: 2.6999 - val_acc: 0.6839\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9865\n",
      "Epoch 00029: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.0710 - acc: 0.9864 - val_loss: 2.8252 - val_acc: 0.6662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9816\n",
      "Epoch 00030: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.0903 - acc: 0.9816 - val_loss: 2.6985 - val_acc: 0.6832\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0779 - acc: 0.9849\n",
      "Epoch 00031: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.0779 - acc: 0.9849 - val_loss: 2.8285 - val_acc: 0.6748\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0735 - acc: 0.9849\n",
      "Epoch 00032: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.0735 - acc: 0.9849 - val_loss: 2.7798 - val_acc: 0.6774\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9864\n",
      "Epoch 00033: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.0722 - acc: 0.9864 - val_loss: 2.7172 - val_acc: 0.6895\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9846\n",
      "Epoch 00034: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.0814 - acc: 0.9845 - val_loss: 2.9637 - val_acc: 0.6653\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0714 - acc: 0.9863\n",
      "Epoch 00035: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.0714 - acc: 0.9863 - val_loss: 2.8575 - val_acc: 0.6753\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9865\n",
      "Epoch 00036: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.0778 - acc: 0.9865 - val_loss: 2.9147 - val_acc: 0.6711\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9850\n",
      "Epoch 00037: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.0798 - acc: 0.9850 - val_loss: 2.9466 - val_acc: 0.6695\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0685 - acc: 0.9877\n",
      "Epoch 00038: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.0686 - acc: 0.9877 - val_loss: 2.9295 - val_acc: 0.6718\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9875\n",
      "Epoch 00039: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.0710 - acc: 0.9874 - val_loss: 2.9033 - val_acc: 0.6748\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0702 - acc: 0.9878\n",
      "Epoch 00040: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.0701 - acc: 0.9878 - val_loss: 2.9538 - val_acc: 0.6660\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9895\n",
      "Epoch 00041: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.0598 - acc: 0.9894 - val_loss: 2.8865 - val_acc: 0.6862\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9871\n",
      "Epoch 00042: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.0709 - acc: 0.9871 - val_loss: 2.8534 - val_acc: 0.6897\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9867\n",
      "Epoch 00043: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.0732 - acc: 0.9866 - val_loss: 3.0968 - val_acc: 0.6695\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0806 - acc: 0.9860\n",
      "Epoch 00044: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.0807 - acc: 0.9860 - val_loss: 2.9480 - val_acc: 0.6851\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9888\n",
      "Epoch 00045: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.0648 - acc: 0.9888 - val_loss: 3.1135 - val_acc: 0.6725\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9878\n",
      "Epoch 00046: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.0653 - acc: 0.9877 - val_loss: 2.9781 - val_acc: 0.6767\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9893\n",
      "Epoch 00047: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.0633 - acc: 0.9893 - val_loss: 3.0859 - val_acc: 0.6783\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9899\n",
      "Epoch 00048: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.0610 - acc: 0.9899 - val_loss: 3.0392 - val_acc: 0.6785\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0581 - acc: 0.9909\n",
      "Epoch 00049: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 609us/sample - loss: 0.0581 - acc: 0.9909 - val_loss: 2.9705 - val_acc: 0.6751\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0596 - acc: 0.9902\n",
      "Epoch 00050: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.0598 - acc: 0.9901 - val_loss: 2.9015 - val_acc: 0.6895\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9888\n",
      "Epoch 00051: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 610us/sample - loss: 0.0664 - acc: 0.9888 - val_loss: 3.0173 - val_acc: 0.6825\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0729 - acc: 0.9882\n",
      "Epoch 00052: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.0734 - acc: 0.9882 - val_loss: 3.1725 - val_acc: 0.6711\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9889\n",
      "Epoch 00053: val_loss did not improve from 1.65040\n",
      "36805/36805 [==============================] - 22s 608us/sample - loss: 0.0663 - acc: 0.9888 - val_loss: 3.0882 - val_acc: 0.6781\n",
      "\n",
      "2D_CNN_only_conv_ch_32_BN_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 316us/sample - loss: 1.8948 - acc: 0.6428\n",
      "Loss: 1.8947815366746976 Accuracy: 0.642783\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4444 - acc: 0.5920\n",
      "Epoch 00001: val_loss improved from inf to 1.10262, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_2_conv_checkpoint/001-1.1026.hdf5\n",
      "36805/36805 [==============================] - 29s 795us/sample - loss: 1.4444 - acc: 0.5920 - val_loss: 1.1026 - val_acc: 0.6879\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7399 - acc: 0.7828\n",
      "Epoch 00002: val_loss improved from 1.10262 to 0.92340, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_2_conv_checkpoint/002-0.9234.hdf5\n",
      "36805/36805 [==============================] - 26s 694us/sample - loss: 0.7395 - acc: 0.7829 - val_loss: 0.9234 - val_acc: 0.7468\n",
      "Epoch 3/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4532 - acc: 0.8681\n",
      "Epoch 00003: val_loss improved from 0.92340 to 0.78041, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_2_conv_checkpoint/003-0.7804.hdf5\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 0.4532 - acc: 0.8680 - val_loss: 0.7804 - val_acc: 0.7952\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3155 - acc: 0.9101\n",
      "Epoch 00004: val_loss improved from 0.78041 to 0.71149, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_2_conv_checkpoint/004-0.7115.hdf5\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.3155 - acc: 0.9101 - val_loss: 0.7115 - val_acc: 0.8246\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2241 - acc: 0.9417\n",
      "Epoch 00005: val_loss improved from 0.71149 to 0.66796, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_2_conv_checkpoint/005-0.6680.hdf5\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.2241 - acc: 0.9417 - val_loss: 0.6680 - val_acc: 0.8418\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1826 - acc: 0.9525\n",
      "Epoch 00006: val_loss did not improve from 0.66796\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1826 - acc: 0.9525 - val_loss: 0.6695 - val_acc: 0.8414\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9682\n",
      "Epoch 00007: val_loss did not improve from 0.66796\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1370 - acc: 0.9682 - val_loss: 0.6975 - val_acc: 0.8286\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9700\n",
      "Epoch 00008: val_loss improved from 0.66796 to 0.62518, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_2_conv_checkpoint/008-0.6252.hdf5\n",
      "36805/36805 [==============================] - 26s 694us/sample - loss: 0.1250 - acc: 0.9700 - val_loss: 0.6252 - val_acc: 0.8479\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9734\n",
      "Epoch 00009: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1075 - acc: 0.9734 - val_loss: 0.6762 - val_acc: 0.8446\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0760 - acc: 0.9843\n",
      "Epoch 00010: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 691us/sample - loss: 0.0760 - acc: 0.9843 - val_loss: 0.6915 - val_acc: 0.8439\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0705 - acc: 0.9848\n",
      "Epoch 00011: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 693us/sample - loss: 0.0707 - acc: 0.9847 - val_loss: 0.7027 - val_acc: 0.8416\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9848\n",
      "Epoch 00012: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 691us/sample - loss: 0.0681 - acc: 0.9848 - val_loss: 0.6828 - val_acc: 0.8456\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9908\n",
      "Epoch 00013: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.0482 - acc: 0.9908 - val_loss: 0.7506 - val_acc: 0.8332\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9898\n",
      "Epoch 00014: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.0480 - acc: 0.9898 - val_loss: 0.6912 - val_acc: 0.8560\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9924\n",
      "Epoch 00015: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.0406 - acc: 0.9923 - val_loss: 0.8004 - val_acc: 0.8344\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9895\n",
      "Epoch 00016: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0456 - acc: 0.9895 - val_loss: 0.7485 - val_acc: 0.8446\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9919\n",
      "Epoch 00017: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.0398 - acc: 0.9919 - val_loss: 0.7549 - val_acc: 0.8514\n",
      "Epoch 18/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9936\n",
      "Epoch 00018: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.0320 - acc: 0.9936 - val_loss: 0.7348 - val_acc: 0.8514\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9922\n",
      "Epoch 00019: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.0357 - acc: 0.9922 - val_loss: 0.7713 - val_acc: 0.8502\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9933\n",
      "Epoch 00020: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.0311 - acc: 0.9933 - val_loss: 0.7707 - val_acc: 0.8565\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9962\n",
      "Epoch 00021: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.0217 - acc: 0.9962 - val_loss: 0.7725 - val_acc: 0.8532\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9973\n",
      "Epoch 00022: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.0167 - acc: 0.9973 - val_loss: 0.7661 - val_acc: 0.8544\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9932\n",
      "Epoch 00023: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0309 - acc: 0.9932 - val_loss: 1.0255 - val_acc: 0.8050\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0261 - acc: 0.9938\n",
      "Epoch 00024: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0261 - acc: 0.9938 - val_loss: 0.7764 - val_acc: 0.8567\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0158 - acc: 0.9971\n",
      "Epoch 00025: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.0160 - acc: 0.9970 - val_loss: 0.8614 - val_acc: 0.8323\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9924\n",
      "Epoch 00026: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.0306 - acc: 0.9924 - val_loss: 0.7748 - val_acc: 0.8612\n",
      "Epoch 27/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9964\n",
      "Epoch 00027: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.0174 - acc: 0.9964 - val_loss: 0.9049 - val_acc: 0.8262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0226 - acc: 0.9949\n",
      "Epoch 00028: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0228 - acc: 0.9948 - val_loss: 1.2986 - val_acc: 0.7685\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9935\n",
      "Epoch 00029: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.0271 - acc: 0.9935 - val_loss: 0.9416 - val_acc: 0.8223\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9976\n",
      "Epoch 00030: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0126 - acc: 0.9976 - val_loss: 0.8331 - val_acc: 0.8565\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9965\n",
      "Epoch 00031: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0152 - acc: 0.9965 - val_loss: 0.8714 - val_acc: 0.8458\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9948\n",
      "Epoch 00032: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.0217 - acc: 0.9948 - val_loss: 0.8854 - val_acc: 0.8530\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0208 - acc: 0.9952\n",
      "Epoch 00033: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0208 - acc: 0.9952 - val_loss: 0.8731 - val_acc: 0.8556\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9980\n",
      "Epoch 00034: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.0120 - acc: 0.9979 - val_loss: 0.8918 - val_acc: 0.8479\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0203 - acc: 0.9949\n",
      "Epoch 00035: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0206 - acc: 0.9948 - val_loss: 0.9195 - val_acc: 0.8435\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9939\n",
      "Epoch 00036: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.0240 - acc: 0.9939 - val_loss: 0.8660 - val_acc: 0.8535\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9979\n",
      "Epoch 00037: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0120 - acc: 0.9979 - val_loss: 0.8646 - val_acc: 0.8579\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9964\n",
      "Epoch 00038: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.0148 - acc: 0.9964 - val_loss: 0.8694 - val_acc: 0.8502\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9971\n",
      "Epoch 00039: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0139 - acc: 0.9971 - val_loss: 0.8978 - val_acc: 0.8449\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9974\n",
      "Epoch 00040: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0110 - acc: 0.9974 - val_loss: 1.0167 - val_acc: 0.8209\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9974\n",
      "Epoch 00041: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0113 - acc: 0.9974 - val_loss: 0.8855 - val_acc: 0.8544\n",
      "Epoch 42/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9976\n",
      "Epoch 00042: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0116 - acc: 0.9976 - val_loss: 0.9026 - val_acc: 0.8458\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9968\n",
      "Epoch 00043: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0130 - acc: 0.9968 - val_loss: 0.8606 - val_acc: 0.8491\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9962\n",
      "Epoch 00044: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0151 - acc: 0.9962 - val_loss: 1.0846 - val_acc: 0.8227\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9987\n",
      "Epoch 00045: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.0075 - acc: 0.9987 - val_loss: 0.9241 - val_acc: 0.8512\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9954\n",
      "Epoch 00046: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0162 - acc: 0.9954 - val_loss: 1.0682 - val_acc: 0.8297\n",
      "Epoch 47/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9972\n",
      "Epoch 00047: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0118 - acc: 0.9972 - val_loss: 0.9196 - val_acc: 0.8523\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9985\n",
      "Epoch 00048: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0083 - acc: 0.9985 - val_loss: 0.9118 - val_acc: 0.8591\n",
      "Epoch 49/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9971\n",
      "Epoch 00049: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.0110 - acc: 0.9971 - val_loss: 0.8734 - val_acc: 0.8630\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9984\n",
      "Epoch 00050: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0078 - acc: 0.9984 - val_loss: 1.0506 - val_acc: 0.8367\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9970\n",
      "Epoch 00051: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0114 - acc: 0.9970 - val_loss: 1.0058 - val_acc: 0.8414\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9985\n",
      "Epoch 00052: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0075 - acc: 0.9985 - val_loss: 1.0020 - val_acc: 0.8407\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9939\n",
      "Epoch 00053: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0239 - acc: 0.9939 - val_loss: 0.9509 - val_acc: 0.8507\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9980\n",
      "Epoch 00054: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0091 - acc: 0.9979 - val_loss: 1.0642 - val_acc: 0.8325\n",
      "Epoch 55/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9959\n",
      "Epoch 00055: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.0162 - acc: 0.9959 - val_loss: 0.9588 - val_acc: 0.8467\n",
      "Epoch 56/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9978\n",
      "Epoch 00056: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.0097 - acc: 0.9978 - val_loss: 0.9421 - val_acc: 0.8532\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9983\n",
      "Epoch 00057: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.0077 - acc: 0.9983 - val_loss: 0.9869 - val_acc: 0.8460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9979\n",
      "Epoch 00058: val_loss did not improve from 0.62518\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.0087 - acc: 0.9979 - val_loss: 0.9501 - val_acc: 0.8498\n",
      "\n",
      "2D_CNN_only_conv_ch_32_BN_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 360us/sample - loss: 0.7362 - acc: 0.8123\n",
      "Loss: 0.7361935867079817 Accuracy: 0.81225336\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.3980 - acc: 0.5837\n",
      "Epoch 00001: val_loss improved from inf to 0.96685, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_3_conv_checkpoint/001-0.9669.hdf5\n",
      "36805/36805 [==============================] - 33s 884us/sample - loss: 1.3974 - acc: 0.5838 - val_loss: 0.9669 - val_acc: 0.7279\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7123 - acc: 0.7930\n",
      "Epoch 00002: val_loss improved from 0.96685 to 0.63911, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_3_conv_checkpoint/002-0.6391.hdf5\n",
      "36805/36805 [==============================] - 27s 739us/sample - loss: 0.7120 - acc: 0.7931 - val_loss: 0.6391 - val_acc: 0.8120\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4796 - acc: 0.8589\n",
      "Epoch 00003: val_loss improved from 0.63911 to 0.57609, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_3_conv_checkpoint/003-0.5761.hdf5\n",
      "36805/36805 [==============================] - 28s 749us/sample - loss: 0.4796 - acc: 0.8589 - val_loss: 0.5761 - val_acc: 0.8430\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3612 - acc: 0.8954\n",
      "Epoch 00004: val_loss improved from 0.57609 to 0.44123, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_3_conv_checkpoint/004-0.4412.hdf5\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.3612 - acc: 0.8954 - val_loss: 0.4412 - val_acc: 0.8819\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2806 - acc: 0.9189\n",
      "Epoch 00005: val_loss improved from 0.44123 to 0.43964, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_3_conv_checkpoint/005-0.4396.hdf5\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.2807 - acc: 0.9188 - val_loss: 0.4396 - val_acc: 0.8824\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2365 - acc: 0.9318\n",
      "Epoch 00006: val_loss improved from 0.43964 to 0.39016, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_3_conv_checkpoint/006-0.3902.hdf5\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.2366 - acc: 0.9317 - val_loss: 0.3902 - val_acc: 0.8915\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9431\n",
      "Epoch 00007: val_loss improved from 0.39016 to 0.37013, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_3_conv_checkpoint/007-0.3701.hdf5\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.2005 - acc: 0.9431 - val_loss: 0.3701 - val_acc: 0.8987\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1665 - acc: 0.9536\n",
      "Epoch 00008: val_loss improved from 0.37013 to 0.34688, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_3_conv_checkpoint/008-0.3469.hdf5\n",
      "36805/36805 [==============================] - 28s 747us/sample - loss: 0.1665 - acc: 0.9535 - val_loss: 0.3469 - val_acc: 0.9092\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9609\n",
      "Epoch 00009: val_loss did not improve from 0.34688\n",
      "36805/36805 [==============================] - 27s 738us/sample - loss: 0.1453 - acc: 0.9609 - val_loss: 0.3595 - val_acc: 0.9059\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9652\n",
      "Epoch 00010: val_loss did not improve from 0.34688\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.1281 - acc: 0.9652 - val_loss: 0.3532 - val_acc: 0.9080\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9740\n",
      "Epoch 00011: val_loss did not improve from 0.34688\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.1027 - acc: 0.9739 - val_loss: 0.3722 - val_acc: 0.9078\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1019 - acc: 0.9739\n",
      "Epoch 00012: val_loss did not improve from 0.34688\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.1019 - acc: 0.9739 - val_loss: 0.4278 - val_acc: 0.8991\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0826 - acc: 0.9796\n",
      "Epoch 00013: val_loss improved from 0.34688 to 0.31979, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_3_conv_checkpoint/013-0.3198.hdf5\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0826 - acc: 0.9796 - val_loss: 0.3198 - val_acc: 0.9236\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9823\n",
      "Epoch 00014: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 739us/sample - loss: 0.0754 - acc: 0.9822 - val_loss: 0.4472 - val_acc: 0.8873\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9823\n",
      "Epoch 00015: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.0733 - acc: 0.9822 - val_loss: 0.3425 - val_acc: 0.9150\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0687 - acc: 0.9825\n",
      "Epoch 00016: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0688 - acc: 0.9825 - val_loss: 0.3812 - val_acc: 0.9019\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9867\n",
      "Epoch 00017: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0567 - acc: 0.9867 - val_loss: 0.3334 - val_acc: 0.9227\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9894\n",
      "Epoch 00018: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0477 - acc: 0.9894 - val_loss: 0.3386 - val_acc: 0.9203\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9904\n",
      "Epoch 00019: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 738us/sample - loss: 0.0438 - acc: 0.9904 - val_loss: 0.3421 - val_acc: 0.9145\n",
      "Epoch 20/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0420 - acc: 0.9912\n",
      "Epoch 00020: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0422 - acc: 0.9912 - val_loss: 0.3866 - val_acc: 0.9061\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9889\n",
      "Epoch 00021: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0462 - acc: 0.9889 - val_loss: 0.4009 - val_acc: 0.9061\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0331 - acc: 0.9930\n",
      "Epoch 00022: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0331 - acc: 0.9930 - val_loss: 0.3277 - val_acc: 0.9213\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9931\n",
      "Epoch 00023: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0321 - acc: 0.9931 - val_loss: 0.3375 - val_acc: 0.9243\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0375 - acc: 0.9913\n",
      "Epoch 00024: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0375 - acc: 0.9913 - val_loss: 0.3973 - val_acc: 0.9129\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9949\n",
      "Epoch 00025: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0256 - acc: 0.9949 - val_loss: 0.3806 - val_acc: 0.9178\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9945\n",
      "Epoch 00026: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0262 - acc: 0.9945 - val_loss: 0.4261 - val_acc: 0.9036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9925\n",
      "Epoch 00027: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0316 - acc: 0.9925 - val_loss: 0.3804 - val_acc: 0.9136\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9945\n",
      "Epoch 00028: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0262 - acc: 0.9945 - val_loss: 0.3612 - val_acc: 0.9194\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9945\n",
      "Epoch 00029: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0252 - acc: 0.9944 - val_loss: 0.3775 - val_acc: 0.9152\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9944\n",
      "Epoch 00030: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0253 - acc: 0.9943 - val_loss: 0.4392 - val_acc: 0.9061\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9951\n",
      "Epoch 00031: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 739us/sample - loss: 0.0228 - acc: 0.9950 - val_loss: 0.3685 - val_acc: 0.9196\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9938\n",
      "Epoch 00032: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0265 - acc: 0.9938 - val_loss: 0.3818 - val_acc: 0.9213\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9950\n",
      "Epoch 00033: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0225 - acc: 0.9950 - val_loss: 0.3574 - val_acc: 0.9250\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9973\n",
      "Epoch 00034: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.0145 - acc: 0.9973 - val_loss: 0.3854 - val_acc: 0.9099\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9942\n",
      "Epoch 00035: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 746us/sample - loss: 0.0249 - acc: 0.9942 - val_loss: 0.3944 - val_acc: 0.9122\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9956\n",
      "Epoch 00036: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0186 - acc: 0.9956 - val_loss: 0.3420 - val_acc: 0.9227\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0139 - acc: 0.9975\n",
      "Epoch 00037: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0140 - acc: 0.9975 - val_loss: 0.3785 - val_acc: 0.9180\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9940\n",
      "Epoch 00038: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0240 - acc: 0.9940 - val_loss: 0.3937 - val_acc: 0.9150\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9977\n",
      "Epoch 00039: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0122 - acc: 0.9976 - val_loss: 0.3729 - val_acc: 0.9133\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0346 - acc: 0.9908\n",
      "Epoch 00040: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.0346 - acc: 0.9908 - val_loss: 0.4005 - val_acc: 0.9159\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0147 - acc: 0.9970\n",
      "Epoch 00041: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 739us/sample - loss: 0.0147 - acc: 0.9970 - val_loss: 0.4027 - val_acc: 0.9199\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9968\n",
      "Epoch 00042: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0150 - acc: 0.9968 - val_loss: 0.3785 - val_acc: 0.9227\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9967\n",
      "Epoch 00043: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0163 - acc: 0.9967 - val_loss: 0.3827 - val_acc: 0.9213\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9972\n",
      "Epoch 00044: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0137 - acc: 0.9972 - val_loss: 0.3686 - val_acc: 0.9234\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0186 - acc: 0.9954\n",
      "Epoch 00045: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0187 - acc: 0.9954 - val_loss: 0.3832 - val_acc: 0.9269\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9967\n",
      "Epoch 00046: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0151 - acc: 0.9967 - val_loss: 0.3740 - val_acc: 0.9264\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0094 - acc: 0.9982\n",
      "Epoch 00047: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0094 - acc: 0.9982 - val_loss: 0.3869 - val_acc: 0.9248\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0096 - acc: 0.9982\n",
      "Epoch 00048: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0098 - acc: 0.9982 - val_loss: 0.4027 - val_acc: 0.9168\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9942\n",
      "Epoch 00049: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0230 - acc: 0.9942 - val_loss: 0.4032 - val_acc: 0.9224\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9977\n",
      "Epoch 00050: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0105 - acc: 0.9977 - val_loss: 0.4124 - val_acc: 0.9201\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0154 - acc: 0.9962\n",
      "Epoch 00051: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0156 - acc: 0.9962 - val_loss: 0.3813 - val_acc: 0.9250\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9961\n",
      "Epoch 00052: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0153 - acc: 0.9961 - val_loss: 0.3762 - val_acc: 0.9273\n",
      "Epoch 53/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0080 - acc: 0.9985\n",
      "Epoch 00053: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 746us/sample - loss: 0.0080 - acc: 0.9985 - val_loss: 0.3764 - val_acc: 0.9259\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9964\n",
      "Epoch 00054: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0145 - acc: 0.9964 - val_loss: 0.3870 - val_acc: 0.9234\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9976\n",
      "Epoch 00055: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0116 - acc: 0.9976 - val_loss: 0.3692 - val_acc: 0.9278\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9987\n",
      "Epoch 00056: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 747us/sample - loss: 0.0075 - acc: 0.9987 - val_loss: 0.3870 - val_acc: 0.9264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9949\n",
      "Epoch 00057: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0186 - acc: 0.9949 - val_loss: 0.3692 - val_acc: 0.9259\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0084 - acc: 0.9985\n",
      "Epoch 00058: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 28s 748us/sample - loss: 0.0085 - acc: 0.9984 - val_loss: 0.4077 - val_acc: 0.9182\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0202 - acc: 0.9956\n",
      "Epoch 00059: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0202 - acc: 0.9956 - val_loss: 0.3585 - val_acc: 0.9299\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9986\n",
      "Epoch 00060: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0078 - acc: 0.9986 - val_loss: 0.3708 - val_acc: 0.9292\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9981\n",
      "Epoch 00061: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 737us/sample - loss: 0.0083 - acc: 0.9981 - val_loss: 0.3925 - val_acc: 0.9273\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9964\n",
      "Epoch 00062: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 737us/sample - loss: 0.0142 - acc: 0.9964 - val_loss: 0.3865 - val_acc: 0.9292\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0068 - acc: 0.9986\n",
      "Epoch 00063: val_loss did not improve from 0.31979\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0068 - acc: 0.9986 - val_loss: 0.4091 - val_acc: 0.9194\n",
      "\n",
      "2D_CNN_only_conv_ch_32_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 380us/sample - loss: 0.4196 - acc: 0.8872\n",
      "Loss: 0.4196391498807311 Accuracy: 0.8872274\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.6120 - acc: 0.5107\n",
      "Epoch 00001: val_loss improved from inf to 1.07953, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/001-1.0795.hdf5\n",
      "36805/36805 [==============================] - 35s 954us/sample - loss: 1.6115 - acc: 0.5108 - val_loss: 1.0795 - val_acc: 0.6550\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7930 - acc: 0.7640\n",
      "Epoch 00002: val_loss improved from 1.07953 to 0.59565, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/002-0.5957.hdf5\n",
      "36805/36805 [==============================] - 29s 778us/sample - loss: 0.7925 - acc: 0.7641 - val_loss: 0.5957 - val_acc: 0.8286\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5286 - acc: 0.8462\n",
      "Epoch 00003: val_loss improved from 0.59565 to 0.46977, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/003-0.4698.hdf5\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.5288 - acc: 0.8462 - val_loss: 0.4698 - val_acc: 0.8677\n",
      "Epoch 4/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4126 - acc: 0.8797\n",
      "Epoch 00004: val_loss improved from 0.46977 to 0.38915, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/004-0.3892.hdf5\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.4126 - acc: 0.8796 - val_loss: 0.3892 - val_acc: 0.8877\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3310 - acc: 0.9050\n",
      "Epoch 00005: val_loss improved from 0.38915 to 0.33059, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/005-0.3306.hdf5\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.3309 - acc: 0.9050 - val_loss: 0.3306 - val_acc: 0.9073\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2767 - acc: 0.9217\n",
      "Epoch 00006: val_loss did not improve from 0.33059\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.2766 - acc: 0.9217 - val_loss: 0.4109 - val_acc: 0.8803\n",
      "Epoch 7/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2408 - acc: 0.9303\n",
      "Epoch 00007: val_loss improved from 0.33059 to 0.30273, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/007-0.3027.hdf5\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.2409 - acc: 0.9303 - val_loss: 0.3027 - val_acc: 0.9124\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2113 - acc: 0.9395\n",
      "Epoch 00008: val_loss improved from 0.30273 to 0.28287, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/008-0.2829.hdf5\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.2112 - acc: 0.9395 - val_loss: 0.2829 - val_acc: 0.9238\n",
      "Epoch 9/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9489\n",
      "Epoch 00009: val_loss improved from 0.28287 to 0.26324, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/009-0.2632.hdf5\n",
      "36805/36805 [==============================] - 29s 778us/sample - loss: 0.1810 - acc: 0.9489 - val_loss: 0.2632 - val_acc: 0.9227\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1615 - acc: 0.9570\n",
      "Epoch 00010: val_loss improved from 0.26324 to 0.25561, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/010-0.2556.hdf5\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.1615 - acc: 0.9570 - val_loss: 0.2556 - val_acc: 0.9259\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9591\n",
      "Epoch 00011: val_loss improved from 0.25561 to 0.25039, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/011-0.2504.hdf5\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.1463 - acc: 0.9591 - val_loss: 0.2504 - val_acc: 0.9294\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1348 - acc: 0.9627\n",
      "Epoch 00012: val_loss improved from 0.25039 to 0.23613, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/012-0.2361.hdf5\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.1349 - acc: 0.9627 - val_loss: 0.2361 - val_acc: 0.9336\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1231 - acc: 0.9664\n",
      "Epoch 00013: val_loss did not improve from 0.23613\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.1231 - acc: 0.9664 - val_loss: 0.2598 - val_acc: 0.9229\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1034 - acc: 0.9724\n",
      "Epoch 00014: val_loss improved from 0.23613 to 0.21878, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/014-0.2188.hdf5\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.1034 - acc: 0.9724 - val_loss: 0.2188 - val_acc: 0.9401\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9753\n",
      "Epoch 00015: val_loss did not improve from 0.21878\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.0987 - acc: 0.9753 - val_loss: 0.2749 - val_acc: 0.9238\n",
      "Epoch 16/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9773\n",
      "Epoch 00016: val_loss did not improve from 0.21878\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0913 - acc: 0.9773 - val_loss: 0.2243 - val_acc: 0.9352\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9806\n",
      "Epoch 00017: val_loss improved from 0.21878 to 0.21871, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/017-0.2187.hdf5\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.0782 - acc: 0.9806 - val_loss: 0.2187 - val_acc: 0.9376\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9814\n",
      "Epoch 00018: val_loss did not improve from 0.21871\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0749 - acc: 0.9814 - val_loss: 0.2233 - val_acc: 0.9373\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0768 - acc: 0.9806\n",
      "Epoch 00019: val_loss did not improve from 0.21871\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.0768 - acc: 0.9807 - val_loss: 0.2195 - val_acc: 0.9392\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9852\n",
      "Epoch 00020: val_loss improved from 0.21871 to 0.20833, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/020-0.2083.hdf5\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0635 - acc: 0.9852 - val_loss: 0.2083 - val_acc: 0.9446\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0600 - acc: 0.9852\n",
      "Epoch 00021: val_loss did not improve from 0.20833\n",
      "36805/36805 [==============================] - 29s 776us/sample - loss: 0.0600 - acc: 0.9852 - val_loss: 0.2118 - val_acc: 0.9413\n",
      "Epoch 22/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9875\n",
      "Epoch 00022: val_loss did not improve from 0.20833\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.0539 - acc: 0.9874 - val_loss: 0.2513 - val_acc: 0.9338\n",
      "Epoch 23/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9841\n",
      "Epoch 00023: val_loss improved from 0.20833 to 0.20678, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/023-0.2068.hdf5\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0633 - acc: 0.9841 - val_loss: 0.2068 - val_acc: 0.9394\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9892\n",
      "Epoch 00024: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.0454 - acc: 0.9892 - val_loss: 0.2199 - val_acc: 0.9401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9903\n",
      "Epoch 00025: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.0431 - acc: 0.9903 - val_loss: 0.2831 - val_acc: 0.9215\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0422 - acc: 0.9908\n",
      "Epoch 00026: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 779us/sample - loss: 0.0424 - acc: 0.9908 - val_loss: 0.2469 - val_acc: 0.9331\n",
      "Epoch 27/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9878\n",
      "Epoch 00027: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0493 - acc: 0.9878 - val_loss: 0.2276 - val_acc: 0.9387\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0392 - acc: 0.9908\n",
      "Epoch 00028: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.0392 - acc: 0.9908 - val_loss: 0.2901 - val_acc: 0.9234\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9908\n",
      "Epoch 00029: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.0399 - acc: 0.9908 - val_loss: 0.2214 - val_acc: 0.9418\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0344 - acc: 0.9923\n",
      "Epoch 00030: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.0345 - acc: 0.9923 - val_loss: 0.2375 - val_acc: 0.9373\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9898\n",
      "Epoch 00031: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.0413 - acc: 0.9898 - val_loss: 0.2187 - val_acc: 0.9441\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9944\n",
      "Epoch 00032: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0271 - acc: 0.9944 - val_loss: 0.2240 - val_acc: 0.9436\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9933\n",
      "Epoch 00033: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.0307 - acc: 0.9933 - val_loss: 0.2541 - val_acc: 0.9315\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0262 - acc: 0.9948\n",
      "Epoch 00034: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0262 - acc: 0.9948 - val_loss: 0.2467 - val_acc: 0.9338\n",
      "Epoch 35/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9908\n",
      "Epoch 00035: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.0353 - acc: 0.9908 - val_loss: 0.2206 - val_acc: 0.9408\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9948\n",
      "Epoch 00036: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0255 - acc: 0.9947 - val_loss: 0.2112 - val_acc: 0.9404\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9916\n",
      "Epoch 00037: val_loss did not improve from 0.20678\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0335 - acc: 0.9916 - val_loss: 0.2522 - val_acc: 0.9399\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9930\n",
      "Epoch 00038: val_loss improved from 0.20678 to 0.19635, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_BN_4_conv_checkpoint/038-0.1963.hdf5\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.0299 - acc: 0.9930 - val_loss: 0.1963 - val_acc: 0.9469\n",
      "Epoch 39/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0182 - acc: 0.9964\n",
      "Epoch 00039: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 779us/sample - loss: 0.0182 - acc: 0.9964 - val_loss: 0.2257 - val_acc: 0.9420\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9966\n",
      "Epoch 00040: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0173 - acc: 0.9966 - val_loss: 0.2352 - val_acc: 0.9432\n",
      "Epoch 41/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9962\n",
      "Epoch 00041: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0190 - acc: 0.9962 - val_loss: 0.2500 - val_acc: 0.9394\n",
      "Epoch 42/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9964\n",
      "Epoch 00042: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.0179 - acc: 0.9964 - val_loss: 0.2258 - val_acc: 0.9394\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9955\n",
      "Epoch 00043: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0222 - acc: 0.9954 - val_loss: 0.3003 - val_acc: 0.9266\n",
      "Epoch 44/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0308 - acc: 0.9921\n",
      "Epoch 00044: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.0308 - acc: 0.9921 - val_loss: 0.2937 - val_acc: 0.9311\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9936\n",
      "Epoch 00045: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0254 - acc: 0.9936 - val_loss: 0.2176 - val_acc: 0.9453\n",
      "Epoch 46/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9935\n",
      "Epoch 00046: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.0259 - acc: 0.9935 - val_loss: 0.2293 - val_acc: 0.9404\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9973\n",
      "Epoch 00047: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.0137 - acc: 0.9973 - val_loss: 0.2275 - val_acc: 0.9455\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9966\n",
      "Epoch 00048: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0175 - acc: 0.9966 - val_loss: 0.2276 - val_acc: 0.9432\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9969\n",
      "Epoch 00049: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0143 - acc: 0.9969 - val_loss: 0.2763 - val_acc: 0.9371\n",
      "Epoch 50/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9968\n",
      "Epoch 00050: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.0139 - acc: 0.9967 - val_loss: 0.2366 - val_acc: 0.9383\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9967\n",
      "Epoch 00051: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.0157 - acc: 0.9967 - val_loss: 0.2534 - val_acc: 0.9331\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0127 - acc: 0.9977\n",
      "Epoch 00052: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.0127 - acc: 0.9977 - val_loss: 0.2351 - val_acc: 0.9434\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9966\n",
      "Epoch 00053: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0153 - acc: 0.9966 - val_loss: 0.3065 - val_acc: 0.9294\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9970\n",
      "Epoch 00054: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0137 - acc: 0.9970 - val_loss: 0.2300 - val_acc: 0.9446\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9972\n",
      "Epoch 00055: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.0133 - acc: 0.9972 - val_loss: 0.2597 - val_acc: 0.9401\n",
      "Epoch 56/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9972\n",
      "Epoch 00056: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.0132 - acc: 0.9972 - val_loss: 0.2382 - val_acc: 0.9443\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9971\n",
      "Epoch 00057: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.0130 - acc: 0.9971 - val_loss: 0.2775 - val_acc: 0.9324\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9971\n",
      "Epoch 00058: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.0136 - acc: 0.9971 - val_loss: 0.2425 - val_acc: 0.9434\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9979\n",
      "Epoch 00059: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0100 - acc: 0.9979 - val_loss: 0.2364 - val_acc: 0.9413\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9974\n",
      "Epoch 00060: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.0121 - acc: 0.9974 - val_loss: 0.2689 - val_acc: 0.9366\n",
      "Epoch 61/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0124 - acc: 0.9971\n",
      "Epoch 00061: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0124 - acc: 0.9971 - val_loss: 0.2626 - val_acc: 0.9404\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9977\n",
      "Epoch 00062: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 778us/sample - loss: 0.0114 - acc: 0.9976 - val_loss: 0.3235 - val_acc: 0.9245\n",
      "Epoch 63/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9913\n",
      "Epoch 00063: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0312 - acc: 0.9913 - val_loss: 0.2473 - val_acc: 0.9432\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9966\n",
      "Epoch 00064: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 779us/sample - loss: 0.0137 - acc: 0.9966 - val_loss: 0.2247 - val_acc: 0.9483\n",
      "Epoch 65/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0100 - acc: 0.9981\n",
      "Epoch 00065: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.0100 - acc: 0.9982 - val_loss: 0.2294 - val_acc: 0.9446\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0070 - acc: 0.9989\n",
      "Epoch 00066: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.0070 - acc: 0.9989 - val_loss: 0.2323 - val_acc: 0.9462\n",
      "Epoch 67/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9967\n",
      "Epoch 00067: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.0136 - acc: 0.9967 - val_loss: 0.2315 - val_acc: 0.9485\n",
      "Epoch 68/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9987\n",
      "Epoch 00068: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 777us/sample - loss: 0.0072 - acc: 0.9987 - val_loss: 0.2063 - val_acc: 0.9518\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9986\n",
      "Epoch 00069: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 778us/sample - loss: 0.0073 - acc: 0.9986 - val_loss: 0.2594 - val_acc: 0.9415\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9986\n",
      "Epoch 00070: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 779us/sample - loss: 0.0071 - acc: 0.9986 - val_loss: 0.2976 - val_acc: 0.9329\n",
      "Epoch 71/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9986\n",
      "Epoch 00071: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 778us/sample - loss: 0.0072 - acc: 0.9986 - val_loss: 0.2806 - val_acc: 0.9401\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9961\n",
      "Epoch 00072: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0155 - acc: 0.9961 - val_loss: 0.2411 - val_acc: 0.9471\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0076 - acc: 0.9987\n",
      "Epoch 00073: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 776us/sample - loss: 0.0076 - acc: 0.9987 - val_loss: 0.3000 - val_acc: 0.9331\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9985\n",
      "Epoch 00074: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 779us/sample - loss: 0.0077 - acc: 0.9985 - val_loss: 0.2351 - val_acc: 0.9441\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9943\n",
      "Epoch 00075: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0199 - acc: 0.9943 - val_loss: 0.2324 - val_acc: 0.9469\n",
      "Epoch 76/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9987\n",
      "Epoch 00076: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.0067 - acc: 0.9987 - val_loss: 0.2540 - val_acc: 0.9441\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9971\n",
      "Epoch 00077: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0116 - acc: 0.9971 - val_loss: 0.2361 - val_acc: 0.9469\n",
      "Epoch 78/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9988\n",
      "Epoch 00078: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 779us/sample - loss: 0.0063 - acc: 0.9988 - val_loss: 0.2783 - val_acc: 0.9380\n",
      "Epoch 79/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9950\n",
      "Epoch 00079: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.0173 - acc: 0.9950 - val_loss: 0.2335 - val_acc: 0.9474\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9990\n",
      "Epoch 00080: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0056 - acc: 0.9990 - val_loss: 0.2513 - val_acc: 0.9427\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9969\n",
      "Epoch 00081: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 779us/sample - loss: 0.0134 - acc: 0.9969 - val_loss: 0.2184 - val_acc: 0.9509\n",
      "Epoch 82/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9989\n",
      "Epoch 00082: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.0059 - acc: 0.9989 - val_loss: 0.2324 - val_acc: 0.9502\n",
      "Epoch 83/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9981\n",
      "Epoch 00083: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0087 - acc: 0.9981 - val_loss: 0.2570 - val_acc: 0.9460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9989\n",
      "Epoch 00084: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.0065 - acc: 0.9989 - val_loss: 0.2349 - val_acc: 0.9483\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9961\n",
      "Epoch 00085: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0144 - acc: 0.9961 - val_loss: 0.2208 - val_acc: 0.9515\n",
      "Epoch 86/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9989\n",
      "Epoch 00086: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.0058 - acc: 0.9988 - val_loss: 0.2338 - val_acc: 0.9485\n",
      "Epoch 87/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0081 - acc: 0.9983\n",
      "Epoch 00087: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.0082 - acc: 0.9983 - val_loss: 0.2338 - val_acc: 0.9476\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9975\n",
      "Epoch 00088: val_loss did not improve from 0.19635\n",
      "36805/36805 [==============================] - 29s 779us/sample - loss: 0.0109 - acc: 0.9975 - val_loss: 0.2551 - val_acc: 0.9476\n",
      "\n",
      "2D_CNN_only_conv_ch_32_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 406us/sample - loss: 0.2697 - acc: 0.9225\n",
      "Loss: 0.2697078215029876 Accuracy: 0.92253375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    base = '2D_CNN_only_conv_ch_32_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_2d_cnn_only_conv_ch_32_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_2d_norm, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_2d_norm, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "    \n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2D_CNN_only_conv_ch_32_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 195072)            780288    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                3121168   \n",
      "=================================================================\n",
      "Total params: 3,902,416\n",
      "Trainable params: 3,512,208\n",
      "Non-trainable params: 390,208\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 390us/sample - loss: 1.8948 - acc: 0.6428\n",
      "Loss: 1.8947815366746976 Accuracy: 0.642783\n",
      "\n",
      "2D_CNN_only_conv_ch_32_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 43648)             174592    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                698384    \n",
      "=================================================================\n",
      "Total params: 899,696\n",
      "Trainable params: 812,272\n",
      "Non-trainable params: 87,424\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 401us/sample - loss: 0.7362 - acc: 0.8123\n",
      "Loss: 0.7361935867079817 Accuracy: 0.81225336\n",
      "\n",
      "2D_CNN_only_conv_ch_32_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16704)             66816     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                267280    \n",
      "=================================================================\n",
      "Total params: 412,336\n",
      "Trainable params: 378,672\n",
      "Non-trainable params: 33,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 435us/sample - loss: 0.4196 - acc: 0.8872\n",
      "Loss: 0.4196391498807311 Accuracy: 0.8872274\n",
      "\n",
      "2D_CNN_only_conv_ch_32_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 25, 5, 64)         102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 25, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 25, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 13, 3, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 2496)              9984      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                39952     \n",
      "=================================================================\n",
      "Total params: 230,896\n",
      "Trainable params: 225,520\n",
      "Non-trainable params: 5,376\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 434us/sample - loss: 0.2697 - acc: 0.9225\n",
      "Loss: 0.2697078215029876 Accuracy: 0.92253375\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '2D_CNN_only_conv_ch_32_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 5):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_only_conv_ch_32_DO_BN(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    \n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=32*(2**int((i)/2)), strides=(1,1), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                3121168   \n",
      "=================================================================\n",
      "Total params: 3,122,128\n",
      "Trainable params: 3,122,064\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                698384    \n",
      "=================================================================\n",
      "Total params: 725,104\n",
      "Trainable params: 724,976\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                267280    \n",
      "=================================================================\n",
      "Total params: 345,520\n",
      "Trainable params: 345,264\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 25, 5, 64)         102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 25, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 25, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 13, 3, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                39952     \n",
      "=================================================================\n",
      "Total params: 220,912\n",
      "Trainable params: 220,528\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model = build_2d_cnn_only_conv_ch_32_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1503 - acc: 0.4820\n",
      "Epoch 00001: val_loss improved from inf to 1.76284, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_1_conv_checkpoint/001-1.7628.hdf5\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 2.1502 - acc: 0.4820 - val_loss: 1.7628 - val_acc: 0.5535\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5610 - acc: 0.6013\n",
      "Epoch 00002: val_loss improved from 1.76284 to 1.61247, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_1_conv_checkpoint/002-1.6125.hdf5\n",
      "36805/36805 [==============================] - 21s 579us/sample - loss: 1.5611 - acc: 0.6013 - val_loss: 1.6125 - val_acc: 0.6177\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2343 - acc: 0.6724\n",
      "Epoch 00003: val_loss improved from 1.61247 to 1.55405, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_1_conv_checkpoint/003-1.5540.hdf5\n",
      "36805/36805 [==============================] - 21s 583us/sample - loss: 1.2344 - acc: 0.6724 - val_loss: 1.5540 - val_acc: 0.6469\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0324 - acc: 0.7186\n",
      "Epoch 00004: val_loss improved from 1.55405 to 1.49744, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_1_conv_checkpoint/004-1.4974.hdf5\n",
      "36805/36805 [==============================] - 22s 585us/sample - loss: 1.0323 - acc: 0.7186 - val_loss: 1.4974 - val_acc: 0.6513\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8954 - acc: 0.7504\n",
      "Epoch 00005: val_loss improved from 1.49744 to 1.45484, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_1_conv_checkpoint/005-1.4548.hdf5\n",
      "36805/36805 [==============================] - 22s 588us/sample - loss: 0.8954 - acc: 0.7504 - val_loss: 1.4548 - val_acc: 0.6774\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7809 - acc: 0.7766\n",
      "Epoch 00006: val_loss improved from 1.45484 to 1.45149, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_1_conv_checkpoint/006-1.4515.hdf5\n",
      "36805/36805 [==============================] - 21s 578us/sample - loss: 0.7809 - acc: 0.7766 - val_loss: 1.4515 - val_acc: 0.6820\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6961 - acc: 0.7994\n",
      "Epoch 00007: val_loss improved from 1.45149 to 1.39428, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_1_conv_checkpoint/007-1.3943.hdf5\n",
      "36805/36805 [==============================] - 22s 584us/sample - loss: 0.6962 - acc: 0.7994 - val_loss: 1.3943 - val_acc: 0.6942\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6495 - acc: 0.8126\n",
      "Epoch 00008: val_loss did not improve from 1.39428\n",
      "36805/36805 [==============================] - 21s 583us/sample - loss: 0.6494 - acc: 0.8126 - val_loss: 1.4078 - val_acc: 0.7025\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5763 - acc: 0.8304\n",
      "Epoch 00009: val_loss improved from 1.39428 to 1.39332, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_1_conv_checkpoint/009-1.3933.hdf5\n",
      "36805/36805 [==============================] - 21s 578us/sample - loss: 0.5763 - acc: 0.8304 - val_loss: 1.3933 - val_acc: 0.7084\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5297 - acc: 0.8465\n",
      "Epoch 00010: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 582us/sample - loss: 0.5297 - acc: 0.8465 - val_loss: 1.5155 - val_acc: 0.6900\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5136 - acc: 0.8498\n",
      "Epoch 00011: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 582us/sample - loss: 0.5135 - acc: 0.8499 - val_loss: 1.4826 - val_acc: 0.7070\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4811 - acc: 0.8588\n",
      "Epoch 00012: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 582us/sample - loss: 0.4814 - acc: 0.8588 - val_loss: 1.4773 - val_acc: 0.7112\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4571 - acc: 0.8655\n",
      "Epoch 00013: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 582us/sample - loss: 0.4570 - acc: 0.8655 - val_loss: 1.5571 - val_acc: 0.7151\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4177 - acc: 0.8781\n",
      "Epoch 00014: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 577us/sample - loss: 0.4177 - acc: 0.8781 - val_loss: 1.4638 - val_acc: 0.7186\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4153 - acc: 0.8771\n",
      "Epoch 00015: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 581us/sample - loss: 0.4152 - acc: 0.8771 - val_loss: 1.5276 - val_acc: 0.7193\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3831 - acc: 0.8885\n",
      "Epoch 00016: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 582us/sample - loss: 0.3833 - acc: 0.8884 - val_loss: 1.5289 - val_acc: 0.7144\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3684 - acc: 0.8923\n",
      "Epoch 00017: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 582us/sample - loss: 0.3683 - acc: 0.8923 - val_loss: 1.5304 - val_acc: 0.7198\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3479 - acc: 0.8997\n",
      "Epoch 00018: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 581us/sample - loss: 0.3480 - acc: 0.8997 - val_loss: 1.5204 - val_acc: 0.7251\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3479 - acc: 0.9002\n",
      "Epoch 00019: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 582us/sample - loss: 0.3479 - acc: 0.9002 - val_loss: 1.5791 - val_acc: 0.7228\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3304 - acc: 0.9052\n",
      "Epoch 00020: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 583us/sample - loss: 0.3304 - acc: 0.9052 - val_loss: 1.5937 - val_acc: 0.7247\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3214 - acc: 0.9080\n",
      "Epoch 00021: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 580us/sample - loss: 0.3214 - acc: 0.9080 - val_loss: 1.6469 - val_acc: 0.7258\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3173 - acc: 0.9103\n",
      "Epoch 00022: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 577us/sample - loss: 0.3173 - acc: 0.9103 - val_loss: 1.6201 - val_acc: 0.7303\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2961 - acc: 0.9147\n",
      "Epoch 00023: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 582us/sample - loss: 0.2962 - acc: 0.9146 - val_loss: 1.7204 - val_acc: 0.7144\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2986 - acc: 0.9156\n",
      "Epoch 00024: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 581us/sample - loss: 0.2985 - acc: 0.9156 - val_loss: 1.6896 - val_acc: 0.7093\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2963 - acc: 0.9145\n",
      "Epoch 00025: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 580us/sample - loss: 0.2963 - acc: 0.9145 - val_loss: 1.6845 - val_acc: 0.7251\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2878 - acc: 0.9163\n",
      "Epoch 00026: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 581us/sample - loss: 0.2880 - acc: 0.9162 - val_loss: 1.6288 - val_acc: 0.7335\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2766 - acc: 0.9217\n",
      "Epoch 00027: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 580us/sample - loss: 0.2766 - acc: 0.9217 - val_loss: 1.7063 - val_acc: 0.7254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2668 - acc: 0.9252\n",
      "Epoch 00028: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 579us/sample - loss: 0.2667 - acc: 0.9252 - val_loss: 1.7310 - val_acc: 0.7363\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2687 - acc: 0.9235\n",
      "Epoch 00029: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 580us/sample - loss: 0.2687 - acc: 0.9235 - val_loss: 1.7095 - val_acc: 0.7277\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2497 - acc: 0.9304\n",
      "Epoch 00030: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 580us/sample - loss: 0.2497 - acc: 0.9304 - val_loss: 1.6956 - val_acc: 0.7372\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2475 - acc: 0.9311\n",
      "Epoch 00031: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 580us/sample - loss: 0.2475 - acc: 0.9312 - val_loss: 1.6651 - val_acc: 0.7377\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2514 - acc: 0.9302\n",
      "Epoch 00032: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 580us/sample - loss: 0.2515 - acc: 0.9301 - val_loss: 1.7487 - val_acc: 0.7254\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2459 - acc: 0.9327\n",
      "Epoch 00033: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 577us/sample - loss: 0.2459 - acc: 0.9327 - val_loss: 1.7523 - val_acc: 0.7221\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2328 - acc: 0.9361\n",
      "Epoch 00034: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 581us/sample - loss: 0.2328 - acc: 0.9361 - val_loss: 1.7030 - val_acc: 0.7398\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2334 - acc: 0.9365\n",
      "Epoch 00035: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 580us/sample - loss: 0.2334 - acc: 0.9365 - val_loss: 1.7013 - val_acc: 0.7361\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2323 - acc: 0.9367\n",
      "Epoch 00036: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 584us/sample - loss: 0.2323 - acc: 0.9367 - val_loss: 1.7170 - val_acc: 0.7372\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2249 - acc: 0.9398\n",
      "Epoch 00037: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 580us/sample - loss: 0.2248 - acc: 0.9398 - val_loss: 1.7492 - val_acc: 0.7361\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2293 - acc: 0.9371\n",
      "Epoch 00038: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 580us/sample - loss: 0.2293 - acc: 0.9371 - val_loss: 1.7503 - val_acc: 0.7328\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2191 - acc: 0.9423\n",
      "Epoch 00039: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 584us/sample - loss: 0.2191 - acc: 0.9422 - val_loss: 1.8300 - val_acc: 0.7291\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9402\n",
      "Epoch 00040: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 582us/sample - loss: 0.2194 - acc: 0.9401 - val_loss: 1.7650 - val_acc: 0.7349\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2167 - acc: 0.9407\n",
      "Epoch 00041: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 581us/sample - loss: 0.2167 - acc: 0.9407 - val_loss: 1.7767 - val_acc: 0.7363\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2010 - acc: 0.9463\n",
      "Epoch 00042: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 580us/sample - loss: 0.2014 - acc: 0.9463 - val_loss: 1.7638 - val_acc: 0.7328\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2073 - acc: 0.9448\n",
      "Epoch 00043: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 582us/sample - loss: 0.2074 - acc: 0.9447 - val_loss: 1.8042 - val_acc: 0.7275\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2092 - acc: 0.9451\n",
      "Epoch 00044: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 579us/sample - loss: 0.2092 - acc: 0.9451 - val_loss: 1.7909 - val_acc: 0.7419\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9439\n",
      "Epoch 00045: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 577us/sample - loss: 0.2075 - acc: 0.9439 - val_loss: 1.8241 - val_acc: 0.7265\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2065 - acc: 0.9463\n",
      "Epoch 00046: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 579us/sample - loss: 0.2065 - acc: 0.9463 - val_loss: 1.7692 - val_acc: 0.7412\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2016 - acc: 0.9482\n",
      "Epoch 00047: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 575us/sample - loss: 0.2016 - acc: 0.9481 - val_loss: 1.8052 - val_acc: 0.7393\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1945 - acc: 0.9494\n",
      "Epoch 00048: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 572us/sample - loss: 0.1949 - acc: 0.9494 - val_loss: 1.8305 - val_acc: 0.7349\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2115 - acc: 0.9449\n",
      "Epoch 00049: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 576us/sample - loss: 0.2115 - acc: 0.9449 - val_loss: 1.8345 - val_acc: 0.7375\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1853 - acc: 0.9510\n",
      "Epoch 00050: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 577us/sample - loss: 0.1853 - acc: 0.9510 - val_loss: 1.8404 - val_acc: 0.7379\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1875 - acc: 0.9507\n",
      "Epoch 00051: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 575us/sample - loss: 0.1875 - acc: 0.9507 - val_loss: 1.8829 - val_acc: 0.7296\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1937 - acc: 0.9491\n",
      "Epoch 00052: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 573us/sample - loss: 0.1937 - acc: 0.9491 - val_loss: 1.8156 - val_acc: 0.7414\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1791 - acc: 0.9543\n",
      "Epoch 00053: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 577us/sample - loss: 0.1791 - acc: 0.9544 - val_loss: 1.8345 - val_acc: 0.7365\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1906 - acc: 0.9505\n",
      "Epoch 00054: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 575us/sample - loss: 0.1906 - acc: 0.9505 - val_loss: 2.0003 - val_acc: 0.7198\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1847 - acc: 0.9525\n",
      "Epoch 00055: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 573us/sample - loss: 0.1847 - acc: 0.9525 - val_loss: 1.8962 - val_acc: 0.7312\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9554\n",
      "Epoch 00056: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 574us/sample - loss: 0.1759 - acc: 0.9554 - val_loss: 1.9269 - val_acc: 0.7289\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1766 - acc: 0.9547\n",
      "Epoch 00057: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 575us/sample - loss: 0.1766 - acc: 0.9547 - val_loss: 1.8980 - val_acc: 0.7384\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9563\n",
      "Epoch 00058: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 577us/sample - loss: 0.1735 - acc: 0.9563 - val_loss: 1.9068 - val_acc: 0.7428\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1756 - acc: 0.9551\n",
      "Epoch 00059: val_loss did not improve from 1.39332\n",
      "36805/36805 [==============================] - 21s 574us/sample - loss: 0.1756 - acc: 0.9551 - val_loss: 1.8798 - val_acc: 0.7421\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_BN_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 386us/sample - loss: 1.6229 - acc: 0.6721\n",
      "Loss: 1.622935887264438 Accuracy: 0.67206645\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7870 - acc: 0.4595\n",
      "Epoch 00001: val_loss improved from inf to 1.18114, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/001-1.1811.hdf5\n",
      "36805/36805 [==============================] - 33s 891us/sample - loss: 1.7868 - acc: 0.4596 - val_loss: 1.1811 - val_acc: 0.6618\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0913 - acc: 0.6658\n",
      "Epoch 00002: val_loss improved from 1.18114 to 0.86344, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/002-0.8634.hdf5\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 1.0912 - acc: 0.6658 - val_loss: 0.8634 - val_acc: 0.7619\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8368 - acc: 0.7431\n",
      "Epoch 00003: val_loss improved from 0.86344 to 0.73496, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/003-0.7350.hdf5\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.8369 - acc: 0.7431 - val_loss: 0.7350 - val_acc: 0.8097\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6771 - acc: 0.7922\n",
      "Epoch 00004: val_loss improved from 0.73496 to 0.69475, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/004-0.6947.hdf5\n",
      "36805/36805 [==============================] - 25s 691us/sample - loss: 0.6770 - acc: 0.7922 - val_loss: 0.6947 - val_acc: 0.8230\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5790 - acc: 0.8218\n",
      "Epoch 00005: val_loss improved from 0.69475 to 0.60243, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/005-0.6024.hdf5\n",
      "36805/36805 [==============================] - 25s 691us/sample - loss: 0.5790 - acc: 0.8218 - val_loss: 0.6024 - val_acc: 0.8400\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5072 - acc: 0.8434\n",
      "Epoch 00006: val_loss improved from 0.60243 to 0.57622, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/006-0.5762.hdf5\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 0.5072 - acc: 0.8434 - val_loss: 0.5762 - val_acc: 0.8516\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4551 - acc: 0.8574\n",
      "Epoch 00007: val_loss improved from 0.57622 to 0.54205, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/007-0.5421.hdf5\n",
      "36805/36805 [==============================] - 25s 691us/sample - loss: 0.4550 - acc: 0.8574 - val_loss: 0.5421 - val_acc: 0.8586\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4147 - acc: 0.8709\n",
      "Epoch 00008: val_loss improved from 0.54205 to 0.54030, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/008-0.5403.hdf5\n",
      "36805/36805 [==============================] - 25s 692us/sample - loss: 0.4146 - acc: 0.8709 - val_loss: 0.5403 - val_acc: 0.8605\n",
      "Epoch 9/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3845 - acc: 0.8812\n",
      "Epoch 00009: val_loss did not improve from 0.54030\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.3846 - acc: 0.8812 - val_loss: 0.5435 - val_acc: 0.8539\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3540 - acc: 0.8889\n",
      "Epoch 00010: val_loss improved from 0.54030 to 0.51963, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/010-0.5196.hdf5\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.3540 - acc: 0.8889 - val_loss: 0.5196 - val_acc: 0.8696\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3218 - acc: 0.8999\n",
      "Epoch 00011: val_loss improved from 0.51963 to 0.50114, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/011-0.5011.hdf5\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.3218 - acc: 0.8999 - val_loss: 0.5011 - val_acc: 0.8819\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3011 - acc: 0.9048\n",
      "Epoch 00012: val_loss did not improve from 0.50114\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.3012 - acc: 0.9048 - val_loss: 0.5167 - val_acc: 0.8803\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2830 - acc: 0.9098\n",
      "Epoch 00013: val_loss did not improve from 0.50114\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.2829 - acc: 0.9098 - val_loss: 0.5487 - val_acc: 0.8607\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2651 - acc: 0.9165\n",
      "Epoch 00014: val_loss improved from 0.50114 to 0.49066, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/014-0.4907.hdf5\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.2652 - acc: 0.9165 - val_loss: 0.4907 - val_acc: 0.8838\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2491 - acc: 0.9220\n",
      "Epoch 00015: val_loss improved from 0.49066 to 0.47877, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/015-0.4788.hdf5\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.2491 - acc: 0.9220 - val_loss: 0.4788 - val_acc: 0.8884\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2382 - acc: 0.9242\n",
      "Epoch 00016: val_loss improved from 0.47877 to 0.47805, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/016-0.4781.hdf5\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.2383 - acc: 0.9241 - val_loss: 0.4781 - val_acc: 0.8898\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2267 - acc: 0.9283\n",
      "Epoch 00017: val_loss improved from 0.47805 to 0.46125, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_2_conv_checkpoint/017-0.4613.hdf5\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.2267 - acc: 0.9283 - val_loss: 0.4613 - val_acc: 0.8889\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2120 - acc: 0.9327\n",
      "Epoch 00018: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.2121 - acc: 0.9327 - val_loss: 0.4912 - val_acc: 0.8873\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9321\n",
      "Epoch 00019: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.2107 - acc: 0.9321 - val_loss: 0.5583 - val_acc: 0.8684\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1954 - acc: 0.9388\n",
      "Epoch 00020: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1954 - acc: 0.9388 - val_loss: 0.4838 - val_acc: 0.8875\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1901 - acc: 0.9403\n",
      "Epoch 00021: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.1901 - acc: 0.9403 - val_loss: 0.4765 - val_acc: 0.8908\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1869 - acc: 0.9405\n",
      "Epoch 00022: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 690us/sample - loss: 0.1869 - acc: 0.9405 - val_loss: 0.4784 - val_acc: 0.8887\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9468\n",
      "Epoch 00023: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.1690 - acc: 0.9468 - val_loss: 0.4854 - val_acc: 0.8894\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9476\n",
      "Epoch 00024: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.1654 - acc: 0.9476 - val_loss: 0.5430 - val_acc: 0.8719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1601 - acc: 0.9500\n",
      "Epoch 00025: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1601 - acc: 0.9500 - val_loss: 0.4976 - val_acc: 0.8866\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1525 - acc: 0.9515\n",
      "Epoch 00026: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.1525 - acc: 0.9514 - val_loss: 0.4941 - val_acc: 0.8903\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9535\n",
      "Epoch 00027: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.1502 - acc: 0.9535 - val_loss: 0.5167 - val_acc: 0.8784\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9548\n",
      "Epoch 00028: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1444 - acc: 0.9548 - val_loss: 0.5202 - val_acc: 0.8884\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1370 - acc: 0.9570\n",
      "Epoch 00029: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.1371 - acc: 0.9569 - val_loss: 0.5598 - val_acc: 0.8747\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1356 - acc: 0.9566\n",
      "Epoch 00030: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1355 - acc: 0.9566 - val_loss: 0.5161 - val_acc: 0.8908\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9611\n",
      "Epoch 00031: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.1277 - acc: 0.9611 - val_loss: 0.4849 - val_acc: 0.8933\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9595\n",
      "Epoch 00032: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.1305 - acc: 0.9595 - val_loss: 0.5760 - val_acc: 0.8675\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1230 - acc: 0.9615\n",
      "Epoch 00033: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.1230 - acc: 0.9615 - val_loss: 0.5375 - val_acc: 0.8859\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1274 - acc: 0.9602\n",
      "Epoch 00034: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.1273 - acc: 0.9602 - val_loss: 0.4948 - val_acc: 0.8917\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9640\n",
      "Epoch 00035: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.1174 - acc: 0.9640 - val_loss: 0.4946 - val_acc: 0.8949\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1137 - acc: 0.9638\n",
      "Epoch 00036: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.1137 - acc: 0.9638 - val_loss: 0.5120 - val_acc: 0.8915\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9639\n",
      "Epoch 00037: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.1122 - acc: 0.9639 - val_loss: 0.5144 - val_acc: 0.8889\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9671\n",
      "Epoch 00038: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.1056 - acc: 0.9671 - val_loss: 0.4914 - val_acc: 0.8961\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1049 - acc: 0.9671\n",
      "Epoch 00039: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.1049 - acc: 0.9671 - val_loss: 0.4855 - val_acc: 0.8973\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1038 - acc: 0.9683\n",
      "Epoch 00040: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.1039 - acc: 0.9683 - val_loss: 0.5110 - val_acc: 0.8928\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9695\n",
      "Epoch 00041: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.0987 - acc: 0.9695 - val_loss: 0.5381 - val_acc: 0.8921\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9695\n",
      "Epoch 00042: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0978 - acc: 0.9695 - val_loss: 0.5004 - val_acc: 0.8980\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9721\n",
      "Epoch 00043: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.0928 - acc: 0.9721 - val_loss: 0.4941 - val_acc: 0.8968\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9724\n",
      "Epoch 00044: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 689us/sample - loss: 0.0902 - acc: 0.9724 - val_loss: 0.5770 - val_acc: 0.8847\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9731\n",
      "Epoch 00045: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0893 - acc: 0.9731 - val_loss: 0.5120 - val_acc: 0.8938\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9738\n",
      "Epoch 00046: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0876 - acc: 0.9738 - val_loss: 0.5025 - val_acc: 0.8977\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9731\n",
      "Epoch 00047: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.0907 - acc: 0.9731 - val_loss: 0.5399 - val_acc: 0.8912\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9739\n",
      "Epoch 00048: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.0872 - acc: 0.9739 - val_loss: 0.4950 - val_acc: 0.8984\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9763\n",
      "Epoch 00049: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.0790 - acc: 0.9763 - val_loss: 0.5290 - val_acc: 0.8966\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9745\n",
      "Epoch 00050: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.0790 - acc: 0.9745 - val_loss: 0.5488 - val_acc: 0.8866\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9765\n",
      "Epoch 00051: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0788 - acc: 0.9765 - val_loss: 0.5134 - val_acc: 0.8938\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9757\n",
      "Epoch 00052: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0776 - acc: 0.9757 - val_loss: 0.4969 - val_acc: 0.8975\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9769\n",
      "Epoch 00053: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.0773 - acc: 0.9769 - val_loss: 0.5158 - val_acc: 0.8921\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9771\n",
      "Epoch 00054: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0778 - acc: 0.9771 - val_loss: 0.5319 - val_acc: 0.8994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9757\n",
      "Epoch 00055: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0772 - acc: 0.9757 - val_loss: 0.5330 - val_acc: 0.8942\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9787\n",
      "Epoch 00056: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0710 - acc: 0.9787 - val_loss: 0.5149 - val_acc: 0.8989\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0688 - acc: 0.9799\n",
      "Epoch 00057: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 0.0688 - acc: 0.9799 - val_loss: 0.5306 - val_acc: 0.8966\n",
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0699 - acc: 0.9791\n",
      "Epoch 00058: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0698 - acc: 0.9791 - val_loss: 0.5329 - val_acc: 0.8994\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0676 - acc: 0.9795\n",
      "Epoch 00059: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0676 - acc: 0.9795 - val_loss: 0.5221 - val_acc: 0.8952\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9791\n",
      "Epoch 00060: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.0707 - acc: 0.9791 - val_loss: 0.5238 - val_acc: 0.8975\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0640 - acc: 0.9817\n",
      "Epoch 00061: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0640 - acc: 0.9817 - val_loss: 0.5335 - val_acc: 0.8880\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0634 - acc: 0.9812\n",
      "Epoch 00062: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0634 - acc: 0.9812 - val_loss: 0.5589 - val_acc: 0.8882\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9805\n",
      "Epoch 00063: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0674 - acc: 0.9805 - val_loss: 0.5126 - val_acc: 0.9022\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9806\n",
      "Epoch 00064: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0644 - acc: 0.9806 - val_loss: 0.5024 - val_acc: 0.8973\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0587 - acc: 0.9827\n",
      "Epoch 00065: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0587 - acc: 0.9827 - val_loss: 0.5323 - val_acc: 0.8959\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0635 - acc: 0.9811\n",
      "Epoch 00066: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.0635 - acc: 0.9811 - val_loss: 0.5322 - val_acc: 0.8963\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0599 - acc: 0.9828\n",
      "Epoch 00067: val_loss did not improve from 0.46125\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0599 - acc: 0.9828 - val_loss: 0.5477 - val_acc: 0.8945\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_BN_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 446us/sample - loss: 0.5361 - acc: 0.8623\n",
      "Loss: 0.536075967593604 Accuracy: 0.8623053\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7832 - acc: 0.4523\n",
      "Epoch 00001: val_loss improved from inf to 1.01719, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/001-1.0172.hdf5\n",
      "36805/36805 [==============================] - 37s 1ms/sample - loss: 1.7831 - acc: 0.4524 - val_loss: 1.0172 - val_acc: 0.7037\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9439 - acc: 0.7083\n",
      "Epoch 00002: val_loss improved from 1.01719 to 0.63158, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/002-0.6316.hdf5\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.9439 - acc: 0.7083 - val_loss: 0.6316 - val_acc: 0.8225\n",
      "Epoch 3/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6814 - acc: 0.7906\n",
      "Epoch 00003: val_loss improved from 0.63158 to 0.59585, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/003-0.5959.hdf5\n",
      "36805/36805 [==============================] - 27s 747us/sample - loss: 0.6811 - acc: 0.7907 - val_loss: 0.5959 - val_acc: 0.8421\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5574 - acc: 0.8303\n",
      "Epoch 00004: val_loss improved from 0.59585 to 0.46630, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/004-0.4663.hdf5\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.5574 - acc: 0.8303 - val_loss: 0.4663 - val_acc: 0.8744\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4839 - acc: 0.8514\n",
      "Epoch 00005: val_loss improved from 0.46630 to 0.41553, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/005-0.4155.hdf5\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.4839 - acc: 0.8514 - val_loss: 0.4155 - val_acc: 0.8921\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4215 - acc: 0.8712\n",
      "Epoch 00006: val_loss improved from 0.41553 to 0.38271, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/006-0.3827.hdf5\n",
      "36805/36805 [==============================] - 27s 745us/sample - loss: 0.4215 - acc: 0.8712 - val_loss: 0.3827 - val_acc: 0.9001\n",
      "Epoch 7/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3827 - acc: 0.8815\n",
      "Epoch 00007: val_loss improved from 0.38271 to 0.36491, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/007-0.3649.hdf5\n",
      "36805/36805 [==============================] - 27s 745us/sample - loss: 0.3827 - acc: 0.8815 - val_loss: 0.3649 - val_acc: 0.9047\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3437 - acc: 0.8946\n",
      "Epoch 00008: val_loss improved from 0.36491 to 0.35095, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/008-0.3510.hdf5\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.3443 - acc: 0.8943 - val_loss: 0.3510 - val_acc: 0.9089\n",
      "Epoch 9/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3216 - acc: 0.9003\n",
      "Epoch 00009: val_loss improved from 0.35095 to 0.34140, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/009-0.3414.hdf5\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.3220 - acc: 0.9003 - val_loss: 0.3414 - val_acc: 0.9038\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2978 - acc: 0.9086\n",
      "Epoch 00010: val_loss did not improve from 0.34140\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.2976 - acc: 0.9087 - val_loss: 0.3426 - val_acc: 0.9166\n",
      "Epoch 11/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2716 - acc: 0.9156\n",
      "Epoch 00011: val_loss improved from 0.34140 to 0.31512, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/011-0.3151.hdf5\n",
      "36805/36805 [==============================] - 27s 746us/sample - loss: 0.2716 - acc: 0.9156 - val_loss: 0.3151 - val_acc: 0.9180\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2604 - acc: 0.9193\n",
      "Epoch 00012: val_loss improved from 0.31512 to 0.30196, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/012-0.3020.hdf5\n",
      "36805/36805 [==============================] - 27s 746us/sample - loss: 0.2604 - acc: 0.9193 - val_loss: 0.3020 - val_acc: 0.9238\n",
      "Epoch 13/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.9248\n",
      "Epoch 00013: val_loss did not improve from 0.30196\n",
      "36805/36805 [==============================] - 27s 738us/sample - loss: 0.2402 - acc: 0.9248 - val_loss: 0.3963 - val_acc: 0.9010\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2301 - acc: 0.9277\n",
      "Epoch 00014: val_loss improved from 0.30196 to 0.29709, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/014-0.2971.hdf5\n",
      "36805/36805 [==============================] - 28s 748us/sample - loss: 0.2301 - acc: 0.9278 - val_loss: 0.2971 - val_acc: 0.9276\n",
      "Epoch 15/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2096 - acc: 0.9349\n",
      "Epoch 00015: val_loss improved from 0.29709 to 0.27017, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/015-0.2702.hdf5\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.2095 - acc: 0.9349 - val_loss: 0.2702 - val_acc: 0.9331\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2068 - acc: 0.9364\n",
      "Epoch 00016: val_loss did not improve from 0.27017\n",
      "36805/36805 [==============================] - 27s 739us/sample - loss: 0.2067 - acc: 0.9364 - val_loss: 0.3464 - val_acc: 0.9257\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9379\n",
      "Epoch 00017: val_loss did not improve from 0.27017\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.1967 - acc: 0.9379 - val_loss: 0.2779 - val_acc: 0.9336\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1891 - acc: 0.9395\n",
      "Epoch 00018: val_loss did not improve from 0.27017\n",
      "36805/36805 [==============================] - 27s 746us/sample - loss: 0.1892 - acc: 0.9395 - val_loss: 0.3150 - val_acc: 0.9217\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1847 - acc: 0.9423\n",
      "Epoch 00019: val_loss did not improve from 0.27017\n",
      "36805/36805 [==============================] - 27s 745us/sample - loss: 0.1847 - acc: 0.9423 - val_loss: 0.3111 - val_acc: 0.9252\n",
      "Epoch 20/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1665 - acc: 0.9465\n",
      "Epoch 00020: val_loss did not improve from 0.27017\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.1664 - acc: 0.9465 - val_loss: 0.2804 - val_acc: 0.9364\n",
      "Epoch 21/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1665 - acc: 0.9467\n",
      "Epoch 00021: val_loss did not improve from 0.27017\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.1665 - acc: 0.9467 - val_loss: 0.2879 - val_acc: 0.9369\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9506\n",
      "Epoch 00022: val_loss improved from 0.27017 to 0.26370, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/022-0.2637.hdf5\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.1547 - acc: 0.9506 - val_loss: 0.2637 - val_acc: 0.9376\n",
      "Epoch 23/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1519 - acc: 0.9516\n",
      "Epoch 00023: val_loss did not improve from 0.26370\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.1519 - acc: 0.9516 - val_loss: 0.2747 - val_acc: 0.9352\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9528\n",
      "Epoch 00024: val_loss improved from 0.26370 to 0.25966, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/024-0.2597.hdf5\n",
      "36805/36805 [==============================] - 27s 745us/sample - loss: 0.1480 - acc: 0.9528 - val_loss: 0.2597 - val_acc: 0.9420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1400 - acc: 0.9564\n",
      "Epoch 00025: val_loss did not improve from 0.25966\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.1400 - acc: 0.9563 - val_loss: 0.2877 - val_acc: 0.9329\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1342 - acc: 0.9576\n",
      "Epoch 00026: val_loss improved from 0.25966 to 0.24861, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/026-0.2486.hdf5\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.1343 - acc: 0.9575 - val_loss: 0.2486 - val_acc: 0.9429\n",
      "Epoch 27/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9565\n",
      "Epoch 00027: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.1377 - acc: 0.9564 - val_loss: 0.2867 - val_acc: 0.9327\n",
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9588\n",
      "Epoch 00028: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.1296 - acc: 0.9587 - val_loss: 0.3003 - val_acc: 0.9327\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1258 - acc: 0.9610\n",
      "Epoch 00029: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.1258 - acc: 0.9610 - val_loss: 0.3134 - val_acc: 0.9245\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1209 - acc: 0.9606\n",
      "Epoch 00030: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.1210 - acc: 0.9605 - val_loss: 0.2678 - val_acc: 0.9390\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9623\n",
      "Epoch 00031: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.1179 - acc: 0.9623 - val_loss: 0.2788 - val_acc: 0.9373\n",
      "Epoch 32/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1129 - acc: 0.9638\n",
      "Epoch 00032: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.1129 - acc: 0.9638 - val_loss: 0.2550 - val_acc: 0.9432\n",
      "Epoch 33/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9649\n",
      "Epoch 00033: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.1099 - acc: 0.9649 - val_loss: 0.3234 - val_acc: 0.9317\n",
      "Epoch 34/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9657\n",
      "Epoch 00034: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.1082 - acc: 0.9657 - val_loss: 0.2820 - val_acc: 0.9364\n",
      "Epoch 35/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9655\n",
      "Epoch 00035: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.1061 - acc: 0.9655 - val_loss: 0.2627 - val_acc: 0.9434\n",
      "Epoch 36/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9686\n",
      "Epoch 00036: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 738us/sample - loss: 0.0966 - acc: 0.9686 - val_loss: 0.3010 - val_acc: 0.9334\n",
      "Epoch 37/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9679\n",
      "Epoch 00037: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.1006 - acc: 0.9679 - val_loss: 0.2744 - val_acc: 0.9385\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9696\n",
      "Epoch 00038: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0959 - acc: 0.9696 - val_loss: 0.2768 - val_acc: 0.9292\n",
      "Epoch 39/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0975 - acc: 0.9697\n",
      "Epoch 00039: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0975 - acc: 0.9697 - val_loss: 0.2690 - val_acc: 0.9385\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9700\n",
      "Epoch 00040: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0931 - acc: 0.9700 - val_loss: 0.2627 - val_acc: 0.9418\n",
      "Epoch 41/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9725\n",
      "Epoch 00041: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0881 - acc: 0.9725 - val_loss: 0.2574 - val_acc: 0.9420\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9719\n",
      "Epoch 00042: val_loss did not improve from 0.24861\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0894 - acc: 0.9719 - val_loss: 0.2612 - val_acc: 0.9439\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9723\n",
      "Epoch 00043: val_loss improved from 0.24861 to 0.24752, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_3_conv_checkpoint/043-0.2475.hdf5\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.0889 - acc: 0.9723 - val_loss: 0.2475 - val_acc: 0.9450\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9726\n",
      "Epoch 00044: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 745us/sample - loss: 0.0860 - acc: 0.9726 - val_loss: 0.3266 - val_acc: 0.9299\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0816 - acc: 0.9743\n",
      "Epoch 00045: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0816 - acc: 0.9743 - val_loss: 0.2692 - val_acc: 0.9415\n",
      "Epoch 46/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9736\n",
      "Epoch 00046: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 747us/sample - loss: 0.0823 - acc: 0.9736 - val_loss: 0.2715 - val_acc: 0.9383\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9743\n",
      "Epoch 00047: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.0809 - acc: 0.9742 - val_loss: 0.2559 - val_acc: 0.9471\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9751\n",
      "Epoch 00048: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 746us/sample - loss: 0.0776 - acc: 0.9751 - val_loss: 0.2666 - val_acc: 0.9434\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9757\n",
      "Epoch 00049: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 746us/sample - loss: 0.0770 - acc: 0.9757 - val_loss: 0.3322 - val_acc: 0.9280\n",
      "Epoch 50/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9767\n",
      "Epoch 00050: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0739 - acc: 0.9767 - val_loss: 0.2640 - val_acc: 0.9464\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9761\n",
      "Epoch 00051: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.0736 - acc: 0.9761 - val_loss: 0.2856 - val_acc: 0.9399\n",
      "Epoch 52/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0712 - acc: 0.9774\n",
      "Epoch 00052: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0712 - acc: 0.9774 - val_loss: 0.2892 - val_acc: 0.9371\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9771\n",
      "Epoch 00053: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.0717 - acc: 0.9771 - val_loss: 0.2711 - val_acc: 0.9457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9785\n",
      "Epoch 00054: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 745us/sample - loss: 0.0682 - acc: 0.9785 - val_loss: 0.2986 - val_acc: 0.9355\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9786\n",
      "Epoch 00055: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 745us/sample - loss: 0.0682 - acc: 0.9786 - val_loss: 0.3023 - val_acc: 0.9343\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9783\n",
      "Epoch 00056: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0679 - acc: 0.9783 - val_loss: 0.4265 - val_acc: 0.9110\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9787\n",
      "Epoch 00057: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0668 - acc: 0.9788 - val_loss: 0.3783 - val_acc: 0.9161\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9805\n",
      "Epoch 00058: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0658 - acc: 0.9805 - val_loss: 0.2545 - val_acc: 0.9476\n",
      "Epoch 59/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9797\n",
      "Epoch 00059: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 746us/sample - loss: 0.0656 - acc: 0.9796 - val_loss: 0.2695 - val_acc: 0.9422\n",
      "Epoch 60/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9797\n",
      "Epoch 00060: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0641 - acc: 0.9797 - val_loss: 0.3365 - val_acc: 0.9252\n",
      "Epoch 61/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9803\n",
      "Epoch 00061: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 737us/sample - loss: 0.0627 - acc: 0.9803 - val_loss: 0.3654 - val_acc: 0.9192\n",
      "Epoch 62/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0602 - acc: 0.9809\n",
      "Epoch 00062: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 737us/sample - loss: 0.0601 - acc: 0.9809 - val_loss: 0.2747 - val_acc: 0.9460\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9813\n",
      "Epoch 00063: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0574 - acc: 0.9813 - val_loss: 0.3084 - val_acc: 0.9387\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9793\n",
      "Epoch 00064: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 739us/sample - loss: 0.0651 - acc: 0.9793 - val_loss: 0.2823 - val_acc: 0.9427\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0561 - acc: 0.9816\n",
      "Epoch 00065: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 738us/sample - loss: 0.0561 - acc: 0.9816 - val_loss: 0.3064 - val_acc: 0.9362\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0573 - acc: 0.9818\n",
      "Epoch 00066: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0573 - acc: 0.9818 - val_loss: 0.2954 - val_acc: 0.9380\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9825\n",
      "Epoch 00067: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 739us/sample - loss: 0.0564 - acc: 0.9825 - val_loss: 0.2591 - val_acc: 0.9420\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9823\n",
      "Epoch 00068: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0577 - acc: 0.9823 - val_loss: 0.2731 - val_acc: 0.9457\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0539 - acc: 0.9832\n",
      "Epoch 00069: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 735us/sample - loss: 0.0539 - acc: 0.9832 - val_loss: 0.2885 - val_acc: 0.9432\n",
      "Epoch 70/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0610 - acc: 0.9814\n",
      "Epoch 00070: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0610 - acc: 0.9813 - val_loss: 0.2583 - val_acc: 0.9455\n",
      "Epoch 71/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9839\n",
      "Epoch 00071: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0508 - acc: 0.9839 - val_loss: 0.3094 - val_acc: 0.9385\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9832\n",
      "Epoch 00072: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0526 - acc: 0.9832 - val_loss: 0.2757 - val_acc: 0.9455\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9833\n",
      "Epoch 00073: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 739us/sample - loss: 0.0531 - acc: 0.9833 - val_loss: 0.2593 - val_acc: 0.9460\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9848\n",
      "Epoch 00074: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 746us/sample - loss: 0.0509 - acc: 0.9848 - val_loss: 0.2776 - val_acc: 0.9474\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9833\n",
      "Epoch 00075: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0522 - acc: 0.9833 - val_loss: 0.2568 - val_acc: 0.9488\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0470 - acc: 0.9855\n",
      "Epoch 00076: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 739us/sample - loss: 0.0471 - acc: 0.9855 - val_loss: 0.2646 - val_acc: 0.9474\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9854\n",
      "Epoch 00077: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0508 - acc: 0.9854 - val_loss: 0.3037 - val_acc: 0.9441\n",
      "Epoch 78/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0512 - acc: 0.9845\n",
      "Epoch 00078: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0512 - acc: 0.9845 - val_loss: 0.2572 - val_acc: 0.9488\n",
      "Epoch 79/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9855\n",
      "Epoch 00079: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0472 - acc: 0.9855 - val_loss: 0.2849 - val_acc: 0.9434\n",
      "Epoch 80/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0446 - acc: 0.9862\n",
      "Epoch 00080: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0446 - acc: 0.9862 - val_loss: 0.2682 - val_acc: 0.9488\n",
      "Epoch 81/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9862\n",
      "Epoch 00081: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0447 - acc: 0.9862 - val_loss: 0.2747 - val_acc: 0.9436\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9850\n",
      "Epoch 00082: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0488 - acc: 0.9850 - val_loss: 0.2979 - val_acc: 0.9418\n",
      "Epoch 83/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9860\n",
      "Epoch 00083: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0450 - acc: 0.9861 - val_loss: 0.3114 - val_acc: 0.9357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9858\n",
      "Epoch 00084: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0443 - acc: 0.9858 - val_loss: 0.2688 - val_acc: 0.9448\n",
      "Epoch 85/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0447 - acc: 0.9867\n",
      "Epoch 00085: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0447 - acc: 0.9867 - val_loss: 0.2927 - val_acc: 0.9464\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9864\n",
      "Epoch 00086: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0438 - acc: 0.9864 - val_loss: 0.3047 - val_acc: 0.9383\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0416 - acc: 0.9877\n",
      "Epoch 00087: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0416 - acc: 0.9877 - val_loss: 0.2607 - val_acc: 0.9495\n",
      "Epoch 88/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9870\n",
      "Epoch 00088: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0426 - acc: 0.9870 - val_loss: 0.2656 - val_acc: 0.9497\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9877\n",
      "Epoch 00089: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0411 - acc: 0.9877 - val_loss: 0.2811 - val_acc: 0.9460\n",
      "Epoch 90/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9864\n",
      "Epoch 00090: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0434 - acc: 0.9864 - val_loss: 0.2733 - val_acc: 0.9492\n",
      "Epoch 91/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9872\n",
      "Epoch 00091: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0427 - acc: 0.9872 - val_loss: 0.2826 - val_acc: 0.9455\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9865\n",
      "Epoch 00092: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 736us/sample - loss: 0.0448 - acc: 0.9865 - val_loss: 0.2667 - val_acc: 0.9488\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0407 - acc: 0.9868\n",
      "Epoch 00093: val_loss did not improve from 0.24752\n",
      "36805/36805 [==============================] - 27s 737us/sample - loss: 0.0407 - acc: 0.9868 - val_loss: 0.2714 - val_acc: 0.9499\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 474us/sample - loss: 0.3144 - acc: 0.9229\n",
      "Loss: 0.3143982418724805 Accuracy: 0.92294914\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 2.0992 - acc: 0.3517\n",
      "Epoch 00001: val_loss improved from inf to 1.23297, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/001-1.2330.hdf5\n",
      "36805/36805 [==============================] - 40s 1ms/sample - loss: 2.0981 - acc: 0.3520 - val_loss: 1.2330 - val_acc: 0.6366\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1547 - acc: 0.6344\n",
      "Epoch 00002: val_loss improved from 1.23297 to 0.68360, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/002-0.6836.hdf5\n",
      "36805/36805 [==============================] - 28s 755us/sample - loss: 1.1542 - acc: 0.6346 - val_loss: 0.6836 - val_acc: 0.8076\n",
      "Epoch 3/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7993 - acc: 0.7489\n",
      "Epoch 00003: val_loss improved from 0.68360 to 0.50373, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/003-0.5037.hdf5\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.7990 - acc: 0.7491 - val_loss: 0.5037 - val_acc: 0.8672\n",
      "Epoch 4/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6361 - acc: 0.8013\n",
      "Epoch 00004: val_loss improved from 0.50373 to 0.42869, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/004-0.4287.hdf5\n",
      "36805/36805 [==============================] - 28s 760us/sample - loss: 0.6361 - acc: 0.8013 - val_loss: 0.4287 - val_acc: 0.8756\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5287 - acc: 0.8334\n",
      "Epoch 00005: val_loss improved from 0.42869 to 0.36104, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/005-0.3610.hdf5\n",
      "36805/36805 [==============================] - 28s 758us/sample - loss: 0.5287 - acc: 0.8334 - val_loss: 0.3610 - val_acc: 0.9022\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4606 - acc: 0.8556\n",
      "Epoch 00006: val_loss improved from 0.36104 to 0.34130, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/006-0.3413.hdf5\n",
      "36805/36805 [==============================] - 28s 761us/sample - loss: 0.4604 - acc: 0.8557 - val_loss: 0.3413 - val_acc: 0.9001\n",
      "Epoch 7/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4113 - acc: 0.8717\n",
      "Epoch 00007: val_loss did not improve from 0.34130\n",
      "36805/36805 [==============================] - 28s 753us/sample - loss: 0.4110 - acc: 0.8718 - val_loss: 0.3720 - val_acc: 0.8842\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3684 - acc: 0.8858\n",
      "Epoch 00008: val_loss improved from 0.34130 to 0.27163, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/008-0.2716.hdf5\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.3687 - acc: 0.8857 - val_loss: 0.2716 - val_acc: 0.9238\n",
      "Epoch 9/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3337 - acc: 0.8958\n",
      "Epoch 00009: val_loss improved from 0.27163 to 0.25487, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/009-0.2549.hdf5\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.3337 - acc: 0.8957 - val_loss: 0.2549 - val_acc: 0.9306\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3101 - acc: 0.9025\n",
      "Epoch 00010: val_loss improved from 0.25487 to 0.23767, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/010-0.2377.hdf5\n",
      "36805/36805 [==============================] - 28s 754us/sample - loss: 0.3101 - acc: 0.9026 - val_loss: 0.2377 - val_acc: 0.9329\n",
      "Epoch 11/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2836 - acc: 0.9102\n",
      "Epoch 00011: val_loss did not improve from 0.23767\n",
      "36805/36805 [==============================] - 28s 754us/sample - loss: 0.2840 - acc: 0.9101 - val_loss: 0.2699 - val_acc: 0.9252\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2676 - acc: 0.9169\n",
      "Epoch 00012: val_loss improved from 0.23767 to 0.22427, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/012-0.2243.hdf5\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.2677 - acc: 0.9169 - val_loss: 0.2243 - val_acc: 0.9366\n",
      "Epoch 13/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2492 - acc: 0.9221\n",
      "Epoch 00013: val_loss improved from 0.22427 to 0.22387, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/013-0.2239.hdf5\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.2492 - acc: 0.9222 - val_loss: 0.2239 - val_acc: 0.9311\n",
      "Epoch 14/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2326 - acc: 0.9269\n",
      "Epoch 00014: val_loss improved from 0.22387 to 0.19927, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/014-0.1993.hdf5\n",
      "36805/36805 [==============================] - 28s 758us/sample - loss: 0.2329 - acc: 0.9268 - val_loss: 0.1993 - val_acc: 0.9413\n",
      "Epoch 15/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2247 - acc: 0.9307\n",
      "Epoch 00015: val_loss did not improve from 0.19927\n",
      "36805/36805 [==============================] - 28s 755us/sample - loss: 0.2247 - acc: 0.9307 - val_loss: 0.2476 - val_acc: 0.9280\n",
      "Epoch 16/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9338\n",
      "Epoch 00016: val_loss improved from 0.19927 to 0.18228, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/016-0.1823.hdf5\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 0.2106 - acc: 0.9338 - val_loss: 0.1823 - val_acc: 0.9504\n",
      "Epoch 17/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2003 - acc: 0.9382\n",
      "Epoch 00017: val_loss did not improve from 0.18228\n",
      "36805/36805 [==============================] - 28s 760us/sample - loss: 0.2001 - acc: 0.9383 - val_loss: 0.2189 - val_acc: 0.9338\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1864 - acc: 0.9426\n",
      "Epoch 00018: val_loss improved from 0.18228 to 0.17396, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/018-0.1740.hdf5\n",
      "36805/36805 [==============================] - 28s 754us/sample - loss: 0.1864 - acc: 0.9426 - val_loss: 0.1740 - val_acc: 0.9527\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1772 - acc: 0.9440\n",
      "Epoch 00019: val_loss did not improve from 0.17396\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.1772 - acc: 0.9439 - val_loss: 0.2108 - val_acc: 0.9380\n",
      "Epoch 20/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1731 - acc: 0.9463\n",
      "Epoch 00020: val_loss did not improve from 0.17396\n",
      "36805/36805 [==============================] - 28s 753us/sample - loss: 0.1731 - acc: 0.9463 - val_loss: 0.1872 - val_acc: 0.9446\n",
      "Epoch 21/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1632 - acc: 0.9489\n",
      "Epoch 00021: val_loss did not improve from 0.17396\n",
      "36805/36805 [==============================] - 28s 760us/sample - loss: 0.1633 - acc: 0.9488 - val_loss: 0.1828 - val_acc: 0.9471\n",
      "Epoch 22/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1604 - acc: 0.9498\n",
      "Epoch 00022: val_loss improved from 0.17396 to 0.17049, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/022-0.1705.hdf5\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.1604 - acc: 0.9498 - val_loss: 0.1705 - val_acc: 0.9532\n",
      "Epoch 23/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9506\n",
      "Epoch 00023: val_loss improved from 0.17049 to 0.16171, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/023-0.1617.hdf5\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 0.1530 - acc: 0.9507 - val_loss: 0.1617 - val_acc: 0.9527\n",
      "Epoch 24/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1433 - acc: 0.9553\n",
      "Epoch 00024: val_loss did not improve from 0.16171\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.1432 - acc: 0.9553 - val_loss: 0.1739 - val_acc: 0.9502\n",
      "Epoch 25/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9558\n",
      "Epoch 00025: val_loss did not improve from 0.16171\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 0.1401 - acc: 0.9558 - val_loss: 0.1794 - val_acc: 0.9476\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1397 - acc: 0.9559\n",
      "Epoch 00026: val_loss did not improve from 0.16171\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 0.1398 - acc: 0.9558 - val_loss: 0.1763 - val_acc: 0.9513\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9601\n",
      "Epoch 00027: val_loss did not improve from 0.16171\n",
      "36805/36805 [==============================] - 28s 753us/sample - loss: 0.1281 - acc: 0.9601 - val_loss: 0.1707 - val_acc: 0.9504\n",
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9595\n",
      "Epoch 00028: val_loss improved from 0.16171 to 0.15850, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/028-0.1585.hdf5\n",
      "36805/36805 [==============================] - 28s 755us/sample - loss: 0.1280 - acc: 0.9594 - val_loss: 0.1585 - val_acc: 0.9546\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9613\n",
      "Epoch 00029: val_loss did not improve from 0.15850\n",
      "36805/36805 [==============================] - 28s 758us/sample - loss: 0.1223 - acc: 0.9613 - val_loss: 0.1978 - val_acc: 0.9467\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9625\n",
      "Epoch 00030: val_loss did not improve from 0.15850\n",
      "36805/36805 [==============================] - 28s 754us/sample - loss: 0.1166 - acc: 0.9624 - val_loss: 0.1675 - val_acc: 0.9532\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1141 - acc: 0.9639\n",
      "Epoch 00031: val_loss did not improve from 0.15850\n",
      "36805/36805 [==============================] - 28s 755us/sample - loss: 0.1141 - acc: 0.9639 - val_loss: 0.1770 - val_acc: 0.9522\n",
      "Epoch 32/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1104 - acc: 0.9649\n",
      "Epoch 00032: val_loss did not improve from 0.15850\n",
      "36805/36805 [==============================] - 28s 751us/sample - loss: 0.1104 - acc: 0.9649 - val_loss: 0.1593 - val_acc: 0.9574\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1053 - acc: 0.9661\n",
      "Epoch 00033: val_loss did not improve from 0.15850\n",
      "36805/36805 [==============================] - 28s 754us/sample - loss: 0.1053 - acc: 0.9661 - val_loss: 0.1959 - val_acc: 0.9436\n",
      "Epoch 34/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9676\n",
      "Epoch 00034: val_loss did not improve from 0.15850\n",
      "36805/36805 [==============================] - 28s 755us/sample - loss: 0.1013 - acc: 0.9676 - val_loss: 0.1965 - val_acc: 0.9481\n",
      "Epoch 35/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1006 - acc: 0.9677\n",
      "Epoch 00035: val_loss did not improve from 0.15850\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 0.1005 - acc: 0.9677 - val_loss: 0.1617 - val_acc: 0.9527\n",
      "Epoch 36/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9704\n",
      "Epoch 00036: val_loss improved from 0.15850 to 0.14616, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/036-0.1462.hdf5\n",
      "36805/36805 [==============================] - 28s 752us/sample - loss: 0.0947 - acc: 0.9704 - val_loss: 0.1462 - val_acc: 0.9567\n",
      "Epoch 37/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9692\n",
      "Epoch 00037: val_loss did not improve from 0.14616\n",
      "36805/36805 [==============================] - 28s 754us/sample - loss: 0.0951 - acc: 0.9692 - val_loss: 0.1806 - val_acc: 0.9525\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9712\n",
      "Epoch 00038: val_loss did not improve from 0.14616\n",
      "36805/36805 [==============================] - 28s 754us/sample - loss: 0.0892 - acc: 0.9712 - val_loss: 0.1826 - val_acc: 0.9457\n",
      "Epoch 39/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0851 - acc: 0.9726\n",
      "Epoch 00039: val_loss did not improve from 0.14616\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 0.0851 - acc: 0.9726 - val_loss: 0.1494 - val_acc: 0.9609\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9736\n",
      "Epoch 00040: val_loss did not improve from 0.14616\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0821 - acc: 0.9736 - val_loss: 0.1750 - val_acc: 0.9483\n",
      "Epoch 41/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9726\n",
      "Epoch 00041: val_loss did not improve from 0.14616\n",
      "36805/36805 [==============================] - 28s 752us/sample - loss: 0.0851 - acc: 0.9726 - val_loss: 0.1673 - val_acc: 0.9543\n",
      "Epoch 42/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9738\n",
      "Epoch 00042: val_loss did not improve from 0.14616\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 0.0818 - acc: 0.9738 - val_loss: 0.1661 - val_acc: 0.9576\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9754\n",
      "Epoch 00043: val_loss did not improve from 0.14616\n",
      "36805/36805 [==============================] - 28s 755us/sample - loss: 0.0776 - acc: 0.9755 - val_loss: 0.1486 - val_acc: 0.9606\n",
      "Epoch 44/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9752\n",
      "Epoch 00044: val_loss did not improve from 0.14616\n",
      "36805/36805 [==============================] - 28s 754us/sample - loss: 0.0779 - acc: 0.9752 - val_loss: 0.1473 - val_acc: 0.9592\n",
      "Epoch 45/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0727 - acc: 0.9774\n",
      "Epoch 00045: val_loss did not improve from 0.14616\n",
      "36805/36805 [==============================] - 28s 752us/sample - loss: 0.0729 - acc: 0.9773 - val_loss: 0.1696 - val_acc: 0.9541\n",
      "Epoch 46/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9743\n",
      "Epoch 00046: val_loss did not improve from 0.14616\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 0.0807 - acc: 0.9743 - val_loss: 0.1881 - val_acc: 0.9471\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9767\n",
      "Epoch 00047: val_loss improved from 0.14616 to 0.14207, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_DO_BN_4_conv_checkpoint/047-0.1421.hdf5\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0725 - acc: 0.9767 - val_loss: 0.1421 - val_acc: 0.9646\n",
      "Epoch 48/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0710 - acc: 0.9772\n",
      "Epoch 00048: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 755us/sample - loss: 0.0709 - acc: 0.9772 - val_loss: 0.1485 - val_acc: 0.9606\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9795\n",
      "Epoch 00049: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 0.0654 - acc: 0.9795 - val_loss: 0.1504 - val_acc: 0.9576\n",
      "Epoch 50/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0672 - acc: 0.9791\n",
      "Epoch 00050: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 758us/sample - loss: 0.0672 - acc: 0.9791 - val_loss: 0.2133 - val_acc: 0.9485\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9779\n",
      "Epoch 00051: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.0693 - acc: 0.9779 - val_loss: 0.1782 - val_acc: 0.9546\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9805\n",
      "Epoch 00052: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 761us/sample - loss: 0.0626 - acc: 0.9805 - val_loss: 0.1629 - val_acc: 0.9583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0593 - acc: 0.9810\n",
      "Epoch 00053: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.0593 - acc: 0.9810 - val_loss: 0.1644 - val_acc: 0.9616\n",
      "Epoch 54/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0657 - acc: 0.9790\n",
      "Epoch 00054: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 0.0656 - acc: 0.9790 - val_loss: 0.1548 - val_acc: 0.9618\n",
      "Epoch 55/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0619 - acc: 0.9805\n",
      "Epoch 00055: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0619 - acc: 0.9805 - val_loss: 0.1699 - val_acc: 0.9590\n",
      "Epoch 56/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9819\n",
      "Epoch 00056: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.0586 - acc: 0.9819 - val_loss: 0.1911 - val_acc: 0.9553\n",
      "Epoch 57/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9808\n",
      "Epoch 00057: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 754us/sample - loss: 0.0603 - acc: 0.9807 - val_loss: 0.1950 - val_acc: 0.9432\n",
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9814\n",
      "Epoch 00058: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 761us/sample - loss: 0.0586 - acc: 0.9813 - val_loss: 0.1661 - val_acc: 0.9553\n",
      "Epoch 59/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0595 - acc: 0.9810\n",
      "Epoch 00059: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.0595 - acc: 0.9810 - val_loss: 0.1548 - val_acc: 0.9585\n",
      "Epoch 60/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9824\n",
      "Epoch 00060: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 754us/sample - loss: 0.0557 - acc: 0.9824 - val_loss: 0.1868 - val_acc: 0.9520\n",
      "Epoch 61/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9827\n",
      "Epoch 00061: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0551 - acc: 0.9827 - val_loss: 0.1825 - val_acc: 0.9555\n",
      "Epoch 62/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0515 - acc: 0.9838\n",
      "Epoch 00062: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.0515 - acc: 0.9838 - val_loss: 0.1568 - val_acc: 0.9632\n",
      "Epoch 63/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0530 - acc: 0.9833\n",
      "Epoch 00063: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 760us/sample - loss: 0.0530 - acc: 0.9833 - val_loss: 0.1696 - val_acc: 0.9602\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9850\n",
      "Epoch 00064: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 758us/sample - loss: 0.0487 - acc: 0.9850 - val_loss: 0.1866 - val_acc: 0.9557\n",
      "Epoch 65/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0494 - acc: 0.9844\n",
      "Epoch 00065: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.0494 - acc: 0.9844 - val_loss: 0.1814 - val_acc: 0.9592\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9841\n",
      "Epoch 00066: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 755us/sample - loss: 0.0528 - acc: 0.9841 - val_loss: 0.1600 - val_acc: 0.9613\n",
      "Epoch 67/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9852\n",
      "Epoch 00067: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 755us/sample - loss: 0.0472 - acc: 0.9852 - val_loss: 0.1755 - val_acc: 0.9555\n",
      "Epoch 68/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0486 - acc: 0.9844\n",
      "Epoch 00068: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.0486 - acc: 0.9844 - val_loss: 0.1766 - val_acc: 0.9611\n",
      "Epoch 69/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9855\n",
      "Epoch 00069: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.0476 - acc: 0.9855 - val_loss: 0.1678 - val_acc: 0.9630\n",
      "Epoch 70/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9852\n",
      "Epoch 00070: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.0475 - acc: 0.9852 - val_loss: 0.2005 - val_acc: 0.9571\n",
      "Epoch 71/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9855\n",
      "Epoch 00071: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0462 - acc: 0.9855 - val_loss: 0.1774 - val_acc: 0.9562\n",
      "Epoch 72/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9872\n",
      "Epoch 00072: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.0423 - acc: 0.9872 - val_loss: 0.2111 - val_acc: 0.9534\n",
      "Epoch 73/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9864\n",
      "Epoch 00073: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 0.0434 - acc: 0.9865 - val_loss: 0.1675 - val_acc: 0.9616\n",
      "Epoch 74/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9852\n",
      "Epoch 00074: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 762us/sample - loss: 0.0475 - acc: 0.9852 - val_loss: 0.1797 - val_acc: 0.9567\n",
      "Epoch 75/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0402 - acc: 0.9880\n",
      "Epoch 00075: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 758us/sample - loss: 0.0402 - acc: 0.9880 - val_loss: 0.1814 - val_acc: 0.9511\n",
      "Epoch 76/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0403 - acc: 0.9876\n",
      "Epoch 00076: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 755us/sample - loss: 0.0403 - acc: 0.9876 - val_loss: 0.1628 - val_acc: 0.9606\n",
      "Epoch 77/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9870\n",
      "Epoch 00077: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 758us/sample - loss: 0.0426 - acc: 0.9871 - val_loss: 0.1857 - val_acc: 0.9595\n",
      "Epoch 78/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9857\n",
      "Epoch 00078: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 0.0457 - acc: 0.9857 - val_loss: 0.1567 - val_acc: 0.9599\n",
      "Epoch 79/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9876\n",
      "Epoch 00079: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 755us/sample - loss: 0.0409 - acc: 0.9876 - val_loss: 0.1786 - val_acc: 0.9581\n",
      "Epoch 80/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9878\n",
      "Epoch 00080: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 760us/sample - loss: 0.0394 - acc: 0.9878 - val_loss: 0.1592 - val_acc: 0.9651\n",
      "Epoch 81/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9879\n",
      "Epoch 00081: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 752us/sample - loss: 0.0394 - acc: 0.9879 - val_loss: 0.1757 - val_acc: 0.9632\n",
      "Epoch 82/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9874\n",
      "Epoch 00082: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0397 - acc: 0.9874 - val_loss: 0.1740 - val_acc: 0.9609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0376 - acc: 0.9886\n",
      "Epoch 00083: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 760us/sample - loss: 0.0377 - acc: 0.9886 - val_loss: 0.1875 - val_acc: 0.9609\n",
      "Epoch 84/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9888\n",
      "Epoch 00084: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 760us/sample - loss: 0.0383 - acc: 0.9888 - val_loss: 0.1635 - val_acc: 0.9639\n",
      "Epoch 85/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9882\n",
      "Epoch 00085: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 758us/sample - loss: 0.0391 - acc: 0.9882 - val_loss: 0.1757 - val_acc: 0.9567\n",
      "Epoch 86/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0383 - acc: 0.9886\n",
      "Epoch 00086: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 758us/sample - loss: 0.0384 - acc: 0.9886 - val_loss: 0.2023 - val_acc: 0.9546\n",
      "Epoch 87/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9884\n",
      "Epoch 00087: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 756us/sample - loss: 0.0378 - acc: 0.9884 - val_loss: 0.1970 - val_acc: 0.9564\n",
      "Epoch 88/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9895\n",
      "Epoch 00088: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.0352 - acc: 0.9895 - val_loss: 0.2131 - val_acc: 0.9520\n",
      "Epoch 89/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9899\n",
      "Epoch 00089: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 766us/sample - loss: 0.0348 - acc: 0.9899 - val_loss: 0.2168 - val_acc: 0.9562\n",
      "Epoch 90/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0338 - acc: 0.9895\n",
      "Epoch 00090: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 760us/sample - loss: 0.0338 - acc: 0.9895 - val_loss: 0.2212 - val_acc: 0.9518\n",
      "Epoch 91/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0374 - acc: 0.9886\n",
      "Epoch 00091: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 758us/sample - loss: 0.0374 - acc: 0.9886 - val_loss: 0.1720 - val_acc: 0.9623\n",
      "Epoch 92/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0359 - acc: 0.9886\n",
      "Epoch 00092: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0358 - acc: 0.9887 - val_loss: 0.1724 - val_acc: 0.9595\n",
      "Epoch 93/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0352 - acc: 0.9889\n",
      "Epoch 00093: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 761us/sample - loss: 0.0352 - acc: 0.9890 - val_loss: 0.1669 - val_acc: 0.9667\n",
      "Epoch 94/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9901\n",
      "Epoch 00094: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0334 - acc: 0.9901 - val_loss: 0.1957 - val_acc: 0.9620\n",
      "Epoch 95/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0320 - acc: 0.9906\n",
      "Epoch 00095: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 761us/sample - loss: 0.0321 - acc: 0.9906 - val_loss: 0.1800 - val_acc: 0.9623\n",
      "Epoch 96/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0335 - acc: 0.9894\n",
      "Epoch 00096: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0336 - acc: 0.9894 - val_loss: 0.1759 - val_acc: 0.9637\n",
      "Epoch 97/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9914\n",
      "Epoch 00097: val_loss did not improve from 0.14207\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0296 - acc: 0.9914 - val_loss: 0.1910 - val_acc: 0.9583\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 502us/sample - loss: 0.2300 - acc: 0.9375\n",
      "Loss: 0.2299849759566821 Accuracy: 0.937487\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    base = '2D_CNN_only_conv_ch_32_DO_BN'\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_2d_cnn_only_conv_ch_32_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_2d_norm, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_2d_norm, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "    \n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2D_CNN_only_conv_ch_32_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_21 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_50 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 16)                3121168   \n",
      "=================================================================\n",
      "Total params: 3,122,128\n",
      "Trainable params: 3,122,064\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 456us/sample - loss: 1.6229 - acc: 0.6721\n",
      "Loss: 1.622935887264438 Accuracy: 0.67206645\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_22 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 16)                698384    \n",
      "=================================================================\n",
      "Total params: 725,104\n",
      "Trainable params: 724,976\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 478us/sample - loss: 0.5361 - acc: 0.8623\n",
      "Loss: 0.536075967593604 Accuracy: 0.8623053\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_23 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_54 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_55 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 16)                267280    \n",
      "=================================================================\n",
      "Total params: 345,520\n",
      "Trainable params: 345,264\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 512us/sample - loss: 0.3144 - acc: 0.9229\n",
      "Loss: 0.3143982418724805 Accuracy: 0.92294914\n",
      "\n",
      "2D_CNN_only_conv_ch_32_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_24 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_56 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_56 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_57 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_57 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_58 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 25, 5, 64)         102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 25, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 25, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_59 (MaxPooling (None, 13, 3, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 16)                39952     \n",
      "=================================================================\n",
      "Total params: 220,912\n",
      "Trainable params: 220,528\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 517us/sample - loss: 0.2300 - acc: 0.9375\n",
      "Loss: 0.2299849759566821 Accuracy: 0.937487\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '2D_CNN_only_conv_ch_32_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 5):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
