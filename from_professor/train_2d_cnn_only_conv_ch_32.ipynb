{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_data = np.load(os.path.join(data_dir, 'train_data.npz'))\n",
    "val_data = np.load(os.path.join(data_dir, 'validation_data.npz'))\n",
    "test_data = np.load(os.path.join(data_dir, 'test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 25443),\n",
       " (36805,),\n",
       " (4293, 25443),\n",
       " (4293,),\n",
       " (4815, 25443),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x_data):\n",
    "    x_data = np.reshape(x_data, [x_data.shape[0], 99, 257, 1])\n",
    "    x_data = np.rot90(x_data, 1, (1, 2))\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_2d = preprocess(x_train)\n",
    "mean_vals = np.mean(x_train_2d, axis=0)\n",
    "std_val = np.std(x_train_2d)\n",
    "x_train_2d_norm = (x_train_2d-mean_vals) / std_val\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_2d = preprocess(x_val)\n",
    "x_val_2d_norm = (x_val_2d-mean_vals) / std_val\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_2d = preprocess(x_test)\n",
    "x_test_2d_norm = (x_test_2d-mean_vals) / std_val\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test_2d_norm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_only_conv_ch_32_DO(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=32*(2**int((i)/2)), strides=(1,1), padding='valid')(input_layer)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                3121168   \n",
      "=================================================================\n",
      "Total params: 3,122,000\n",
      "Trainable params: 3,122,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                3121168   \n",
      "=================================================================\n",
      "Total params: 3,122,000\n",
      "Trainable params: 3,122,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 253, 95, 64)       1664      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 253, 95, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 127, 48, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 390144)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 390144)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                6242320   \n",
      "=================================================================\n",
      "Total params: 6,243,984\n",
      "Trainable params: 6,243,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 253, 95, 64)       1664      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 253, 95, 64)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 127, 48, 64)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 390144)            0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 390144)            0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                6242320   \n",
      "=================================================================\n",
      "Total params: 6,243,984\n",
      "Trainable params: 6,243,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model = build_2d_cnn_only_conv_ch_32_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5558 - acc: 0.5348\n",
      "Epoch 00001: val_loss improved from inf to 1.32778, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_checkpoint/001-1.3278.hdf5\n",
      "36805/36805 [==============================] - 17s 455us/sample - loss: 1.5557 - acc: 0.5348 - val_loss: 1.3278 - val_acc: 0.6145\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1648 - acc: 0.6545\n",
      "Epoch 00002: val_loss improved from 1.32778 to 1.21581, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_checkpoint/002-1.2158.hdf5\n",
      "36805/36805 [==============================] - 16s 434us/sample - loss: 1.1647 - acc: 0.6545 - val_loss: 1.2158 - val_acc: 0.6601\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9719 - acc: 0.7100\n",
      "Epoch 00003: val_loss improved from 1.21581 to 1.13777, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_checkpoint/003-1.1378.hdf5\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 0.9719 - acc: 0.7100 - val_loss: 1.1378 - val_acc: 0.6914\n",
      "Epoch 4/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8298 - acc: 0.7537\n",
      "Epoch 00004: val_loss improved from 1.13777 to 1.09057, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_checkpoint/004-1.0906.hdf5\n",
      "36805/36805 [==============================] - 16s 433us/sample - loss: 0.8296 - acc: 0.7538 - val_loss: 1.0906 - val_acc: 0.7074\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.7292 - acc: 0.7804\n",
      "Epoch 00005: val_loss improved from 1.09057 to 1.08719, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_checkpoint/005-1.0872.hdf5\n",
      "36805/36805 [==============================] - 16s 438us/sample - loss: 0.7295 - acc: 0.7803 - val_loss: 1.0872 - val_acc: 0.7037\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6461 - acc: 0.8072\n",
      "Epoch 00006: val_loss did not improve from 1.08719\n",
      "36805/36805 [==============================] - 16s 435us/sample - loss: 0.6461 - acc: 0.8072 - val_loss: 1.0888 - val_acc: 0.7086\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5783 - acc: 0.8286\n",
      "Epoch 00007: val_loss improved from 1.08719 to 1.05181, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_checkpoint/007-1.0518.hdf5\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 0.5782 - acc: 0.8286 - val_loss: 1.0518 - val_acc: 0.7358\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5227 - acc: 0.8457\n",
      "Epoch 00008: val_loss did not improve from 1.05181\n",
      "36805/36805 [==============================] - 16s 428us/sample - loss: 0.5224 - acc: 0.8458 - val_loss: 1.0715 - val_acc: 0.7347\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4861 - acc: 0.8563\n",
      "Epoch 00009: val_loss did not improve from 1.05181\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 0.4861 - acc: 0.8563 - val_loss: 1.0617 - val_acc: 0.7396\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4433 - acc: 0.8685\n",
      "Epoch 00010: val_loss did not improve from 1.05181\n",
      "36805/36805 [==============================] - 16s 429us/sample - loss: 0.4435 - acc: 0.8684 - val_loss: 1.0519 - val_acc: 0.7487\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4121 - acc: 0.8785\n",
      "Epoch 00011: val_loss did not improve from 1.05181\n",
      "36805/36805 [==============================] - 16s 429us/sample - loss: 0.4121 - acc: 0.8785 - val_loss: 1.0619 - val_acc: 0.7449\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3841 - acc: 0.8860\n",
      "Epoch 00012: val_loss did not improve from 1.05181\n",
      "36805/36805 [==============================] - 16s 432us/sample - loss: 0.3841 - acc: 0.8859 - val_loss: 1.0812 - val_acc: 0.7433\n",
      "Epoch 13/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3582 - acc: 0.8948\n",
      "Epoch 00013: val_loss did not improve from 1.05181\n",
      "36805/36805 [==============================] - 16s 425us/sample - loss: 0.3581 - acc: 0.8948 - val_loss: 1.1084 - val_acc: 0.7501\n",
      "Epoch 14/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3417 - acc: 0.8979\n",
      "Epoch 00014: val_loss did not improve from 1.05181\n",
      "36805/36805 [==============================] - 16s 431us/sample - loss: 0.3414 - acc: 0.8979 - val_loss: 1.1221 - val_acc: 0.7370\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3146 - acc: 0.9082\n",
      "Epoch 00015: val_loss did not improve from 1.05181\n",
      "36805/36805 [==============================] - 16s 437us/sample - loss: 0.3146 - acc: 0.9082 - val_loss: 1.1167 - val_acc: 0.7501\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2997 - acc: 0.9121\n",
      "Epoch 00016: val_loss did not improve from 1.05181\n",
      "36805/36805 [==============================] - 16s 428us/sample - loss: 0.2997 - acc: 0.9121 - val_loss: 1.1316 - val_acc: 0.7512\n",
      "Epoch 17/500\n",
      " 7424/36805 [=====>........................] - ETA: 11s - loss: 0.2662 - acc: 0.9275"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_only_conv_ch_32_{}_conv_DO'.format(i)\n",
    "    model = build_2d_cnn_only_conv_ch_32_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_2d_norm, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_2d_norm, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "    \n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_only_conv_ch_32_{}_conv_DO'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_only_conv_ch_32_BN(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=32*(2**int((i)/2)), strides=(1,1), padding='valid')(input_layer)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    model = build_2d_cnn_only_conv_ch_32_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_only_conv_ch_32_{}_conv_BN'.format(i)\n",
    "    model = build_2d_cnn_only_conv_ch_32_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_2d_norm, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_2d_norm, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "    \n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_only_conv_ch_32_{}_conv_BN'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_only_conv_ch_32_DO_BN(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=32*(2**int((i)/2)), strides=(1,1), padding='valid')(input_layer)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    model = build_2d_cnn_only_conv_ch_32_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_only_conv_ch_32_{}_conv_DO_BN'.format(i)\n",
    "    model = build_2d_cnn_only_conv_ch_32_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_2d_norm, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_2d_norm, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "    \n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_only_conv_ch_32_{}_conv_BN'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
