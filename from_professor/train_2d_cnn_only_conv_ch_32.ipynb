{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input, InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_data = np.load(os.path.join(data_dir, 'train_data.npz'))\n",
    "val_data = np.load(os.path.join(data_dir, 'validation_data.npz'))\n",
    "test_data = np.load(os.path.join(data_dir, 'test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 25443),\n",
       " (36805,),\n",
       " (4293, 25443),\n",
       " (4293,),\n",
       " (4815, 25443),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x_data):\n",
    "    x_data = np.reshape(x_data, [x_data.shape[0], 99, 257, 1])\n",
    "    x_data = np.rot90(x_data, 1, (1, 2))\n",
    "    return x_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_2d = preprocess(x_train)\n",
    "mean_vals = np.mean(x_train_2d, axis=0)\n",
    "std_val = np.std(x_train_2d)\n",
    "x_train_2d_norm = (x_train_2d-mean_vals) / std_val\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_2d = preprocess(x_val)\n",
    "x_val_2d_norm = (x_val_2d-mean_vals) / std_val\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_2d = preprocess(x_test)\n",
    "x_test_2d_norm = (x_test_2d-mean_vals) / std_val\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test_2d_norm[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_only_conv_ch_32_DO(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "\n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=32*(2**int((i)/2)), strides=(1,1), padding='valid')(x)\n",
    "#         x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                3121168   \n",
      "=================================================================\n",
      "Total params: 3,122,000\n",
      "Trainable params: 3,122,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                698384    \n",
      "=================================================================\n",
      "Total params: 724,848\n",
      "Trainable params: 724,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                267280    \n",
      "=================================================================\n",
      "Total params: 345,008\n",
      "Trainable params: 345,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 25, 5, 64)         102464    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 25, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 3, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                39952     \n",
      "=================================================================\n",
      "Total params: 220,144\n",
      "Trainable params: 220,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model = build_2d_cnn_only_conv_ch_32_DO(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.5280 - acc: 0.5413\n",
      "Epoch 00001: val_loss improved from inf to 1.28709, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_checkpoint/001-1.2871.hdf5\n",
      "36805/36805 [==============================] - 18s 479us/sample - loss: 1.5275 - acc: 0.5414 - val_loss: 1.2871 - val_acc: 0.6364\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 1.1168 - acc: 0.6653\n",
      "Epoch 00002: val_loss improved from 1.28709 to 1.16840, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_checkpoint/002-1.1684.hdf5\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 1.1170 - acc: 0.6653 - val_loss: 1.1684 - val_acc: 0.6862\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9318 - acc: 0.7155\n",
      "Epoch 00003: val_loss improved from 1.16840 to 1.09322, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_checkpoint/003-1.0932.hdf5\n",
      "36805/36805 [==============================] - 16s 448us/sample - loss: 0.9319 - acc: 0.7154 - val_loss: 1.0932 - val_acc: 0.6930\n",
      "Epoch 4/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8017 - acc: 0.7583\n",
      "Epoch 00004: val_loss improved from 1.09322 to 1.07895, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_checkpoint/004-1.0790.hdf5\n",
      "36805/36805 [==============================] - 16s 440us/sample - loss: 0.8009 - acc: 0.7586 - val_loss: 1.0790 - val_acc: 0.6993\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7017 - acc: 0.7885\n",
      "Epoch 00005: val_loss improved from 1.07895 to 1.07891, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_checkpoint/005-1.0789.hdf5\n",
      "36805/36805 [==============================] - 16s 439us/sample - loss: 0.7018 - acc: 0.7885 - val_loss: 1.0789 - val_acc: 0.7149\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6270 - acc: 0.8096\n",
      "Epoch 00006: val_loss improved from 1.07891 to 1.04848, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_checkpoint/006-1.0485.hdf5\n",
      "36805/36805 [==============================] - 16s 430us/sample - loss: 0.6276 - acc: 0.8096 - val_loss: 1.0485 - val_acc: 0.7237\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5710 - acc: 0.8280\n",
      "Epoch 00007: val_loss improved from 1.04848 to 1.03689, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_checkpoint/007-1.0369.hdf5\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.5711 - acc: 0.8279 - val_loss: 1.0369 - val_acc: 0.7368\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5180 - acc: 0.8452\n",
      "Epoch 00008: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 410us/sample - loss: 0.5181 - acc: 0.8451 - val_loss: 1.0448 - val_acc: 0.7342\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4740 - acc: 0.8580\n",
      "Epoch 00009: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 419us/sample - loss: 0.4740 - acc: 0.8580 - val_loss: 1.0545 - val_acc: 0.7391\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4409 - acc: 0.8678\n",
      "Epoch 00010: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 16s 423us/sample - loss: 0.4409 - acc: 0.8678 - val_loss: 1.0896 - val_acc: 0.7335\n",
      "Epoch 11/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.4083 - acc: 0.8774\n",
      "Epoch 00011: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 411us/sample - loss: 0.4093 - acc: 0.8772 - val_loss: 1.0739 - val_acc: 0.7480\n",
      "Epoch 12/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3801 - acc: 0.8856\n",
      "Epoch 00012: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 406us/sample - loss: 0.3799 - acc: 0.8856 - val_loss: 1.1025 - val_acc: 0.7298\n",
      "Epoch 13/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.3619 - acc: 0.8898\n",
      "Epoch 00013: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 415us/sample - loss: 0.3617 - acc: 0.8898 - val_loss: 1.1163 - val_acc: 0.7428\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3398 - acc: 0.8973\n",
      "Epoch 00014: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 16s 426us/sample - loss: 0.3398 - acc: 0.8973 - val_loss: 1.1196 - val_acc: 0.7501\n",
      "Epoch 15/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3210 - acc: 0.9023\n",
      "Epoch 00015: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 405us/sample - loss: 0.3211 - acc: 0.9023 - val_loss: 1.1573 - val_acc: 0.7405\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3104 - acc: 0.9052\n",
      "Epoch 00016: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 411us/sample - loss: 0.3104 - acc: 0.9052 - val_loss: 1.1596 - val_acc: 0.7473\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2885 - acc: 0.9128\n",
      "Epoch 00017: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 418us/sample - loss: 0.2885 - acc: 0.9128 - val_loss: 1.1484 - val_acc: 0.7573\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2746 - acc: 0.9180\n",
      "Epoch 00018: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 420us/sample - loss: 0.2746 - acc: 0.9181 - val_loss: 1.1765 - val_acc: 0.7396\n",
      "Epoch 19/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2668 - acc: 0.9194\n",
      "Epoch 00019: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 397us/sample - loss: 0.2670 - acc: 0.9193 - val_loss: 1.2049 - val_acc: 0.7508\n",
      "Epoch 20/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2543 - acc: 0.9225\n",
      "Epoch 00020: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 397us/sample - loss: 0.2543 - acc: 0.9225 - val_loss: 1.1685 - val_acc: 0.7591\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2426 - acc: 0.9260\n",
      "Epoch 00021: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 396us/sample - loss: 0.2427 - acc: 0.9259 - val_loss: 1.2263 - val_acc: 0.7431\n",
      "Epoch 22/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2317 - acc: 0.9305\n",
      "Epoch 00022: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 402us/sample - loss: 0.2315 - acc: 0.9306 - val_loss: 1.2320 - val_acc: 0.7517\n",
      "Epoch 23/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2269 - acc: 0.9311\n",
      "Epoch 00023: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 398us/sample - loss: 0.2267 - acc: 0.9312 - val_loss: 1.2150 - val_acc: 0.7566\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2156 - acc: 0.9350\n",
      "Epoch 00024: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 400us/sample - loss: 0.2155 - acc: 0.9350 - val_loss: 1.2821 - val_acc: 0.7419\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2129 - acc: 0.9351\n",
      "Epoch 00025: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 410us/sample - loss: 0.2130 - acc: 0.9350 - val_loss: 1.2657 - val_acc: 0.7522\n",
      "Epoch 26/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.2054 - acc: 0.9385\n",
      "Epoch 00026: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 407us/sample - loss: 0.2055 - acc: 0.9384 - val_loss: 1.2839 - val_acc: 0.7494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1946 - acc: 0.9423\n",
      "Epoch 00027: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 398us/sample - loss: 0.1947 - acc: 0.9423 - val_loss: 1.2765 - val_acc: 0.7524\n",
      "Epoch 28/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1897 - acc: 0.9446\n",
      "Epoch 00028: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 397us/sample - loss: 0.1895 - acc: 0.9446 - val_loss: 1.2789 - val_acc: 0.7533\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1900 - acc: 0.9434\n",
      "Epoch 00029: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 410us/sample - loss: 0.1900 - acc: 0.9434 - val_loss: 1.3021 - val_acc: 0.7503\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9457\n",
      "Epoch 00030: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 413us/sample - loss: 0.1810 - acc: 0.9457 - val_loss: 1.3743 - val_acc: 0.7424\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1787 - acc: 0.9462\n",
      "Epoch 00031: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 401us/sample - loss: 0.1787 - acc: 0.9462 - val_loss: 1.3350 - val_acc: 0.7435\n",
      "Epoch 32/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9484\n",
      "Epoch 00032: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 408us/sample - loss: 0.1704 - acc: 0.9485 - val_loss: 1.3692 - val_acc: 0.7515\n",
      "Epoch 33/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1669 - acc: 0.9507\n",
      "Epoch 00033: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 410us/sample - loss: 0.1667 - acc: 0.9508 - val_loss: 1.3850 - val_acc: 0.7442\n",
      "Epoch 34/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1636 - acc: 0.9515\n",
      "Epoch 00034: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 411us/sample - loss: 0.1635 - acc: 0.9515 - val_loss: 1.3960 - val_acc: 0.7428\n",
      "Epoch 35/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9539\n",
      "Epoch 00035: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 397us/sample - loss: 0.1570 - acc: 0.9538 - val_loss: 1.3776 - val_acc: 0.7461\n",
      "Epoch 36/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1568 - acc: 0.9525\n",
      "Epoch 00036: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 411us/sample - loss: 0.1568 - acc: 0.9525 - val_loss: 1.4274 - val_acc: 0.7433\n",
      "Epoch 37/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1538 - acc: 0.9542\n",
      "Epoch 00037: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 411us/sample - loss: 0.1538 - acc: 0.9541 - val_loss: 1.4024 - val_acc: 0.7573\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9571\n",
      "Epoch 00038: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 412us/sample - loss: 0.1465 - acc: 0.9571 - val_loss: 1.4412 - val_acc: 0.7512\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1497 - acc: 0.9543\n",
      "Epoch 00039: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 397us/sample - loss: 0.1497 - acc: 0.9543 - val_loss: 1.4176 - val_acc: 0.7487\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1399 - acc: 0.9588\n",
      "Epoch 00040: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 398us/sample - loss: 0.1399 - acc: 0.9588 - val_loss: 1.4294 - val_acc: 0.7512\n",
      "Epoch 41/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1413 - acc: 0.9583\n",
      "Epoch 00041: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 14s 392us/sample - loss: 0.1413 - acc: 0.9583 - val_loss: 1.4467 - val_acc: 0.7461\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9567\n",
      "Epoch 00042: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 398us/sample - loss: 0.1417 - acc: 0.9567 - val_loss: 1.4375 - val_acc: 0.7480\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9614\n",
      "Epoch 00043: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 395us/sample - loss: 0.1351 - acc: 0.9614 - val_loss: 1.4050 - val_acc: 0.7549\n",
      "Epoch 44/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1304 - acc: 0.9614\n",
      "Epoch 00044: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 396us/sample - loss: 0.1304 - acc: 0.9614 - val_loss: 1.4230 - val_acc: 0.7533\n",
      "Epoch 45/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1277 - acc: 0.9632\n",
      "Epoch 00045: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 400us/sample - loss: 0.1278 - acc: 0.9632 - val_loss: 1.4264 - val_acc: 0.7587\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1251 - acc: 0.9636\n",
      "Epoch 00046: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 410us/sample - loss: 0.1251 - acc: 0.9636 - val_loss: 1.4473 - val_acc: 0.7515\n",
      "Epoch 47/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9602\n",
      "Epoch 00047: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 409us/sample - loss: 0.1300 - acc: 0.9602 - val_loss: 1.4394 - val_acc: 0.7584\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9633\n",
      "Epoch 00048: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 400us/sample - loss: 0.1236 - acc: 0.9633 - val_loss: 1.4848 - val_acc: 0.7517\n",
      "Epoch 49/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9649\n",
      "Epoch 00049: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 403us/sample - loss: 0.1208 - acc: 0.9649 - val_loss: 1.4920 - val_acc: 0.7536\n",
      "Epoch 50/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9645\n",
      "Epoch 00050: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 409us/sample - loss: 0.1203 - acc: 0.9646 - val_loss: 1.4869 - val_acc: 0.7491\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1153 - acc: 0.9664\n",
      "Epoch 00051: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 409us/sample - loss: 0.1153 - acc: 0.9664 - val_loss: 1.4907 - val_acc: 0.7512\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1203 - acc: 0.9647\n",
      "Epoch 00052: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 396us/sample - loss: 0.1203 - acc: 0.9647 - val_loss: 1.4744 - val_acc: 0.7533\n",
      "Epoch 53/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9663\n",
      "Epoch 00053: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 395us/sample - loss: 0.1160 - acc: 0.9663 - val_loss: 1.4963 - val_acc: 0.7552\n",
      "Epoch 54/500\n",
      "36672/36805 [============================>.] - ETA: 0s - loss: 0.1122 - acc: 0.9669\n",
      "Epoch 00054: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 408us/sample - loss: 0.1124 - acc: 0.9668 - val_loss: 1.4954 - val_acc: 0.7547\n",
      "Epoch 55/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1090 - acc: 0.9691\n",
      "Epoch 00055: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 411us/sample - loss: 0.1091 - acc: 0.9691 - val_loss: 1.5216 - val_acc: 0.7477\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9682\n",
      "Epoch 00056: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 397us/sample - loss: 0.1099 - acc: 0.9682 - val_loss: 1.5300 - val_acc: 0.7552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9701\n",
      "Epoch 00057: val_loss did not improve from 1.03689\n",
      "36805/36805 [==============================] - 15s 398us/sample - loss: 0.1043 - acc: 0.9701 - val_loss: 1.5797 - val_acc: 0.7461\n",
      "\n",
      "2D_CNN_only_conv_ch_32_1_conv_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 263us/sample - loss: 1.1518 - acc: 0.6984\n",
      "Loss: 1.1517724619228644 Accuracy: 0.69844234\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5411 - acc: 0.5315\n",
      "Epoch 00001: val_loss improved from inf to 1.10267, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_DO_checkpoint/001-1.1027.hdf5\n",
      "36805/36805 [==============================] - 18s 482us/sample - loss: 1.5410 - acc: 0.5316 - val_loss: 1.1027 - val_acc: 0.6983\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9679 - acc: 0.7134\n",
      "Epoch 00002: val_loss improved from 1.10267 to 0.80992, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_DO_checkpoint/002-0.8099.hdf5\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.9678 - acc: 0.7134 - val_loss: 0.8099 - val_acc: 0.7850\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7349 - acc: 0.7787\n",
      "Epoch 00003: val_loss improved from 0.80992 to 0.68605, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_DO_checkpoint/003-0.6861.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.7349 - acc: 0.7787 - val_loss: 0.6861 - val_acc: 0.8286\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6051 - acc: 0.8177\n",
      "Epoch 00004: val_loss improved from 0.68605 to 0.59797, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_DO_checkpoint/004-0.5980.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.6050 - acc: 0.8177 - val_loss: 0.5980 - val_acc: 0.8488\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5136 - acc: 0.8440\n",
      "Epoch 00005: val_loss improved from 0.59797 to 0.54995, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_DO_checkpoint/005-0.5500.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.5135 - acc: 0.8441 - val_loss: 0.5500 - val_acc: 0.8630\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4471 - acc: 0.8645\n",
      "Epoch 00006: val_loss improved from 0.54995 to 0.52062, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_DO_checkpoint/006-0.5206.hdf5\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.4471 - acc: 0.8644 - val_loss: 0.5206 - val_acc: 0.8703\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3962 - acc: 0.8783\n",
      "Epoch 00007: val_loss improved from 0.52062 to 0.49480, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_DO_checkpoint/007-0.4948.hdf5\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.3961 - acc: 0.8783 - val_loss: 0.4948 - val_acc: 0.8852\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3557 - acc: 0.8908\n",
      "Epoch 00008: val_loss improved from 0.49480 to 0.49102, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_DO_checkpoint/008-0.4910.hdf5\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.3556 - acc: 0.8909 - val_loss: 0.4910 - val_acc: 0.8828\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3268 - acc: 0.8995\n",
      "Epoch 00009: val_loss improved from 0.49102 to 0.48245, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_DO_checkpoint/009-0.4825.hdf5\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.3268 - acc: 0.8995 - val_loss: 0.4825 - val_acc: 0.8891\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2914 - acc: 0.9105\n",
      "Epoch 00010: val_loss did not improve from 0.48245\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2913 - acc: 0.9105 - val_loss: 0.4856 - val_acc: 0.8835\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2694 - acc: 0.9165\n",
      "Epoch 00011: val_loss did not improve from 0.48245\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.2694 - acc: 0.9165 - val_loss: 0.4872 - val_acc: 0.8845\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2490 - acc: 0.9218\n",
      "Epoch 00012: val_loss did not improve from 0.48245\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2491 - acc: 0.9218 - val_loss: 0.4895 - val_acc: 0.8863\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2288 - acc: 0.9291\n",
      "Epoch 00013: val_loss did not improve from 0.48245\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.2289 - acc: 0.9291 - val_loss: 0.4898 - val_acc: 0.8868\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2093 - acc: 0.9353\n",
      "Epoch 00014: val_loss did not improve from 0.48245\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.2093 - acc: 0.9353 - val_loss: 0.4837 - val_acc: 0.8917\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1957 - acc: 0.9389\n",
      "Epoch 00015: val_loss improved from 0.48245 to 0.46346, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_DO_checkpoint/015-0.4635.hdf5\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.1956 - acc: 0.9389 - val_loss: 0.4635 - val_acc: 0.8968\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1842 - acc: 0.9428\n",
      "Epoch 00016: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.1841 - acc: 0.9428 - val_loss: 0.4863 - val_acc: 0.8942\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1726 - acc: 0.9470\n",
      "Epoch 00017: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.1727 - acc: 0.9470 - val_loss: 0.4907 - val_acc: 0.8984\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1639 - acc: 0.9484\n",
      "Epoch 00018: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.1638 - acc: 0.9484 - val_loss: 0.4878 - val_acc: 0.8940\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9527\n",
      "Epoch 00019: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.1530 - acc: 0.9527 - val_loss: 0.4775 - val_acc: 0.9003\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9546\n",
      "Epoch 00020: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.1465 - acc: 0.9546 - val_loss: 0.4672 - val_acc: 0.9017\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9579\n",
      "Epoch 00021: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.1381 - acc: 0.9579 - val_loss: 0.4869 - val_acc: 0.8977\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9601\n",
      "Epoch 00022: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.1315 - acc: 0.9601 - val_loss: 0.4821 - val_acc: 0.9005\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1260 - acc: 0.9603\n",
      "Epoch 00023: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.1260 - acc: 0.9603 - val_loss: 0.5067 - val_acc: 0.8980\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9640\n",
      "Epoch 00024: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.1179 - acc: 0.9640 - val_loss: 0.4917 - val_acc: 0.8998\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9638\n",
      "Epoch 00025: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.1159 - acc: 0.9638 - val_loss: 0.5239 - val_acc: 0.8975\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9658\n",
      "Epoch 00026: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.1106 - acc: 0.9658 - val_loss: 0.5036 - val_acc: 0.8998\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9669\n",
      "Epoch 00027: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.1040 - acc: 0.9669 - val_loss: 0.4900 - val_acc: 0.9012\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9700\n",
      "Epoch 00028: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.0982 - acc: 0.9700 - val_loss: 0.5032 - val_acc: 0.9024\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9687\n",
      "Epoch 00029: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.0966 - acc: 0.9687 - val_loss: 0.5191 - val_acc: 0.9012\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9725\n",
      "Epoch 00030: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0905 - acc: 0.9725 - val_loss: 0.5107 - val_acc: 0.9047\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9736\n",
      "Epoch 00031: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.0883 - acc: 0.9736 - val_loss: 0.5182 - val_acc: 0.9005\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9742\n",
      "Epoch 00032: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0854 - acc: 0.9742 - val_loss: 0.5261 - val_acc: 0.9008\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9750\n",
      "Epoch 00033: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0840 - acc: 0.9750 - val_loss: 0.5238 - val_acc: 0.9008\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9755\n",
      "Epoch 00034: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.0795 - acc: 0.9755 - val_loss: 0.5330 - val_acc: 0.9059\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9759\n",
      "Epoch 00035: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0795 - acc: 0.9759 - val_loss: 0.5417 - val_acc: 0.9038\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0753 - acc: 0.9772\n",
      "Epoch 00036: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0753 - acc: 0.9772 - val_loss: 0.5481 - val_acc: 0.9008\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9763\n",
      "Epoch 00037: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.0756 - acc: 0.9763 - val_loss: 0.5108 - val_acc: 0.9059\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0706 - acc: 0.9788\n",
      "Epoch 00038: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.0706 - acc: 0.9788 - val_loss: 0.5176 - val_acc: 0.9029\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0667 - acc: 0.9805\n",
      "Epoch 00039: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0667 - acc: 0.9805 - val_loss: 0.5228 - val_acc: 0.9050\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9804\n",
      "Epoch 00040: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0668 - acc: 0.9804 - val_loss: 0.5133 - val_acc: 0.9033\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0637 - acc: 0.9806\n",
      "Epoch 00041: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.0637 - acc: 0.9806 - val_loss: 0.5240 - val_acc: 0.9045\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9808\n",
      "Epoch 00042: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0629 - acc: 0.9808 - val_loss: 0.5362 - val_acc: 0.9075\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9820\n",
      "Epoch 00043: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0612 - acc: 0.9819 - val_loss: 0.5418 - val_acc: 0.9045\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0609 - acc: 0.9821\n",
      "Epoch 00044: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.0609 - acc: 0.9821 - val_loss: 0.5444 - val_acc: 0.9057\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9830\n",
      "Epoch 00045: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 465us/sample - loss: 0.0571 - acc: 0.9830 - val_loss: 0.5349 - val_acc: 0.9092\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9831\n",
      "Epoch 00046: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.0571 - acc: 0.9831 - val_loss: 0.5441 - val_acc: 0.9071\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9832\n",
      "Epoch 00047: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.0571 - acc: 0.9832 - val_loss: 0.5514 - val_acc: 0.9078\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9841\n",
      "Epoch 00048: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 458us/sample - loss: 0.0552 - acc: 0.9841 - val_loss: 0.5284 - val_acc: 0.9099\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0503 - acc: 0.9851\n",
      "Epoch 00049: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.0503 - acc: 0.9851 - val_loss: 0.5495 - val_acc: 0.9071\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9850\n",
      "Epoch 00050: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0526 - acc: 0.9850 - val_loss: 0.5526 - val_acc: 0.9064\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9848\n",
      "Epoch 00051: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0508 - acc: 0.9848 - val_loss: 0.5478 - val_acc: 0.9131\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9842\n",
      "Epoch 00052: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 457us/sample - loss: 0.0510 - acc: 0.9842 - val_loss: 0.5582 - val_acc: 0.9096\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9862\n",
      "Epoch 00053: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0472 - acc: 0.9862 - val_loss: 0.5891 - val_acc: 0.9071\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0472 - acc: 0.9865\n",
      "Epoch 00054: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.0472 - acc: 0.9865 - val_loss: 0.5563 - val_acc: 0.9101\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9854\n",
      "Epoch 00055: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 463us/sample - loss: 0.0485 - acc: 0.9854 - val_loss: 0.5462 - val_acc: 0.9096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0460 - acc: 0.9868\n",
      "Epoch 00056: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0460 - acc: 0.9868 - val_loss: 0.5600 - val_acc: 0.9096\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9853\n",
      "Epoch 00057: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.0481 - acc: 0.9853 - val_loss: 0.5442 - val_acc: 0.9110\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0454 - acc: 0.9873\n",
      "Epoch 00058: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 461us/sample - loss: 0.0454 - acc: 0.9873 - val_loss: 0.5680 - val_acc: 0.9050\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9866\n",
      "Epoch 00059: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 459us/sample - loss: 0.0459 - acc: 0.9866 - val_loss: 0.5577 - val_acc: 0.9103\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9878\n",
      "Epoch 00060: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0436 - acc: 0.9878 - val_loss: 0.5540 - val_acc: 0.9106\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0436 - acc: 0.9875\n",
      "Epoch 00061: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0435 - acc: 0.9875 - val_loss: 0.5619 - val_acc: 0.9094\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9887\n",
      "Epoch 00062: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 464us/sample - loss: 0.0410 - acc: 0.9887 - val_loss: 0.5844 - val_acc: 0.9073\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0432 - acc: 0.9877\n",
      "Epoch 00063: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0434 - acc: 0.9877 - val_loss: 0.5659 - val_acc: 0.9117\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0412 - acc: 0.9882\n",
      "Epoch 00064: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 460us/sample - loss: 0.0412 - acc: 0.9882 - val_loss: 0.5664 - val_acc: 0.9094\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0394 - acc: 0.9888\n",
      "Epoch 00065: val_loss did not improve from 0.46346\n",
      "36805/36805 [==============================] - 17s 462us/sample - loss: 0.0394 - acc: 0.9888 - val_loss: 0.5664 - val_acc: 0.9089\n",
      "\n",
      "2D_CNN_only_conv_ch_32_2_conv_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 281us/sample - loss: 0.5462 - acc: 0.8652\n",
      "Loss: 0.5462203813985624 Accuracy: 0.86521286\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6234 - acc: 0.4967\n",
      "Epoch 00001: val_loss improved from inf to 1.07348, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/001-1.0735.hdf5\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 1.6234 - acc: 0.4967 - val_loss: 1.0735 - val_acc: 0.6969\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9384 - acc: 0.7175\n",
      "Epoch 00002: val_loss improved from 1.07348 to 0.66269, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/002-0.6627.hdf5\n",
      "36805/36805 [==============================] - 19s 504us/sample - loss: 0.9384 - acc: 0.7175 - val_loss: 0.6627 - val_acc: 0.8227\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6512 - acc: 0.8065\n",
      "Epoch 00003: val_loss improved from 0.66269 to 0.49234, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/003-0.4923.hdf5\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.6512 - acc: 0.8065 - val_loss: 0.4923 - val_acc: 0.8726\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5121 - acc: 0.8458\n",
      "Epoch 00004: val_loss improved from 0.49234 to 0.43377, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/004-0.4338.hdf5\n",
      "36805/36805 [==============================] - 18s 502us/sample - loss: 0.5120 - acc: 0.8459 - val_loss: 0.4338 - val_acc: 0.8812\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4318 - acc: 0.8681\n",
      "Epoch 00005: val_loss improved from 0.43377 to 0.37864, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/005-0.3786.hdf5\n",
      "36805/36805 [==============================] - 18s 502us/sample - loss: 0.4319 - acc: 0.8681 - val_loss: 0.3786 - val_acc: 0.9033\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3782 - acc: 0.8850\n",
      "Epoch 00006: val_loss improved from 0.37864 to 0.34696, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/006-0.3470.hdf5\n",
      "36805/36805 [==============================] - 19s 504us/sample - loss: 0.3781 - acc: 0.8850 - val_loss: 0.3470 - val_acc: 0.9047\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3305 - acc: 0.8996\n",
      "Epoch 00007: val_loss improved from 0.34696 to 0.32623, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/007-0.3262.hdf5\n",
      "36805/36805 [==============================] - 19s 505us/sample - loss: 0.3306 - acc: 0.8996 - val_loss: 0.3262 - val_acc: 0.9168\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2971 - acc: 0.9099\n",
      "Epoch 00008: val_loss improved from 0.32623 to 0.30906, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/008-0.3091.hdf5\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.2971 - acc: 0.9099 - val_loss: 0.3091 - val_acc: 0.9185\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2707 - acc: 0.9166\n",
      "Epoch 00009: val_loss improved from 0.30906 to 0.28821, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/009-0.2882.hdf5\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.2707 - acc: 0.9166 - val_loss: 0.2882 - val_acc: 0.9224\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2479 - acc: 0.9230\n",
      "Epoch 00010: val_loss did not improve from 0.28821\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.2479 - acc: 0.9230 - val_loss: 0.2883 - val_acc: 0.9257\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9296\n",
      "Epoch 00011: val_loss improved from 0.28821 to 0.26940, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/011-0.2694.hdf5\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.2264 - acc: 0.9296 - val_loss: 0.2694 - val_acc: 0.9334\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2081 - acc: 0.9364\n",
      "Epoch 00012: val_loss improved from 0.26940 to 0.26072, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/012-0.2607.hdf5\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.2081 - acc: 0.9364 - val_loss: 0.2607 - val_acc: 0.9338\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1916 - acc: 0.9393\n",
      "Epoch 00013: val_loss did not improve from 0.26072\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.1917 - acc: 0.9393 - val_loss: 0.2662 - val_acc: 0.9348\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1788 - acc: 0.9436\n",
      "Epoch 00014: val_loss did not improve from 0.26072\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.1788 - acc: 0.9436 - val_loss: 0.2694 - val_acc: 0.9345\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1669 - acc: 0.9469\n",
      "Epoch 00015: val_loss improved from 0.26072 to 0.24866, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/015-0.2487.hdf5\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.1669 - acc: 0.9469 - val_loss: 0.2487 - val_acc: 0.9355\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1573 - acc: 0.9512\n",
      "Epoch 00016: val_loss improved from 0.24866 to 0.24579, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/016-0.2458.hdf5\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.1573 - acc: 0.9512 - val_loss: 0.2458 - val_acc: 0.9390\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9544\n",
      "Epoch 00017: val_loss did not improve from 0.24579\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.1464 - acc: 0.9544 - val_loss: 0.2478 - val_acc: 0.9406\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1381 - acc: 0.9560\n",
      "Epoch 00018: val_loss improved from 0.24579 to 0.24449, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/018-0.2445.hdf5\n",
      "36805/36805 [==============================] - 18s 502us/sample - loss: 0.1381 - acc: 0.9560 - val_loss: 0.2445 - val_acc: 0.9394\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1289 - acc: 0.9596\n",
      "Epoch 00019: val_loss did not improve from 0.24449\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.1289 - acc: 0.9596 - val_loss: 0.2449 - val_acc: 0.9446\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1238 - acc: 0.9608\n",
      "Epoch 00020: val_loss did not improve from 0.24449\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.1238 - acc: 0.9608 - val_loss: 0.2459 - val_acc: 0.9453\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1193 - acc: 0.9617\n",
      "Epoch 00021: val_loss did not improve from 0.24449\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.1193 - acc: 0.9617 - val_loss: 0.2621 - val_acc: 0.9408\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9648\n",
      "Epoch 00022: val_loss did not improve from 0.24449\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.1102 - acc: 0.9648 - val_loss: 0.2597 - val_acc: 0.9436\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9668\n",
      "Epoch 00023: val_loss improved from 0.24449 to 0.24074, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_DO_checkpoint/023-0.2407.hdf5\n",
      "36805/36805 [==============================] - 18s 502us/sample - loss: 0.1059 - acc: 0.9668 - val_loss: 0.2407 - val_acc: 0.9478\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9663\n",
      "Epoch 00024: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.1028 - acc: 0.9663 - val_loss: 0.2414 - val_acc: 0.9478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9691\n",
      "Epoch 00025: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 493us/sample - loss: 0.0964 - acc: 0.9691 - val_loss: 0.2493 - val_acc: 0.9446\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0961 - acc: 0.9696\n",
      "Epoch 00026: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.0960 - acc: 0.9696 - val_loss: 0.2431 - val_acc: 0.9464\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9724\n",
      "Epoch 00027: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.0862 - acc: 0.9724 - val_loss: 0.2455 - val_acc: 0.9499\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9732\n",
      "Epoch 00028: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.0831 - acc: 0.9732 - val_loss: 0.2434 - val_acc: 0.9455\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9728\n",
      "Epoch 00029: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0851 - acc: 0.9728 - val_loss: 0.2546 - val_acc: 0.9492\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9736\n",
      "Epoch 00030: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 510us/sample - loss: 0.0807 - acc: 0.9736 - val_loss: 0.2423 - val_acc: 0.9467\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9754\n",
      "Epoch 00031: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.0764 - acc: 0.9754 - val_loss: 0.2710 - val_acc: 0.9469\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9764\n",
      "Epoch 00032: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.0742 - acc: 0.9764 - val_loss: 0.2528 - val_acc: 0.9481\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9778\n",
      "Epoch 00033: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.0690 - acc: 0.9778 - val_loss: 0.2713 - val_acc: 0.9455\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9777\n",
      "Epoch 00034: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.0692 - acc: 0.9777 - val_loss: 0.2573 - val_acc: 0.9474\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0679 - acc: 0.9770\n",
      "Epoch 00035: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.0679 - acc: 0.9770 - val_loss: 0.2565 - val_acc: 0.9467\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0642 - acc: 0.9793\n",
      "Epoch 00036: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0643 - acc: 0.9793 - val_loss: 0.2488 - val_acc: 0.9504\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0652 - acc: 0.9793\n",
      "Epoch 00037: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.0652 - acc: 0.9793 - val_loss: 0.2620 - val_acc: 0.9467\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0613 - acc: 0.9816\n",
      "Epoch 00038: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0613 - acc: 0.9816 - val_loss: 0.2668 - val_acc: 0.9504\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0621 - acc: 0.9802\n",
      "Epoch 00039: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 503us/sample - loss: 0.0622 - acc: 0.9802 - val_loss: 0.2483 - val_acc: 0.9499\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9811\n",
      "Epoch 00040: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.0591 - acc: 0.9811 - val_loss: 0.2471 - val_acc: 0.9492\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0572 - acc: 0.9816\n",
      "Epoch 00041: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0572 - acc: 0.9816 - val_loss: 0.2691 - val_acc: 0.9518\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0555 - acc: 0.9825\n",
      "Epoch 00042: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 518us/sample - loss: 0.0555 - acc: 0.9825 - val_loss: 0.2521 - val_acc: 0.9518\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9818\n",
      "Epoch 00043: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 510us/sample - loss: 0.0560 - acc: 0.9818 - val_loss: 0.2579 - val_acc: 0.9520\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0545 - acc: 0.9830\n",
      "Epoch 00044: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0545 - acc: 0.9829 - val_loss: 0.2692 - val_acc: 0.9467\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0536 - acc: 0.9831\n",
      "Epoch 00045: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0536 - acc: 0.9831 - val_loss: 0.2608 - val_acc: 0.9502\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9838\n",
      "Epoch 00046: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.0516 - acc: 0.9838 - val_loss: 0.2715 - val_acc: 0.9504\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9834\n",
      "Epoch 00047: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.0526 - acc: 0.9834 - val_loss: 0.2628 - val_acc: 0.9525\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0517 - acc: 0.9832\n",
      "Epoch 00048: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 503us/sample - loss: 0.0517 - acc: 0.9832 - val_loss: 0.2692 - val_acc: 0.9483\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9852\n",
      "Epoch 00049: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.0466 - acc: 0.9852 - val_loss: 0.2683 - val_acc: 0.9492\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0434 - acc: 0.9862\n",
      "Epoch 00050: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.0434 - acc: 0.9862 - val_loss: 0.2813 - val_acc: 0.9483\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0457 - acc: 0.9853\n",
      "Epoch 00051: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 514us/sample - loss: 0.0457 - acc: 0.9853 - val_loss: 0.2785 - val_acc: 0.9483\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0462 - acc: 0.9854\n",
      "Epoch 00052: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0461 - acc: 0.9854 - val_loss: 0.2729 - val_acc: 0.9490\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9862\n",
      "Epoch 00053: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 496us/sample - loss: 0.0430 - acc: 0.9862 - val_loss: 0.2658 - val_acc: 0.9499\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9864\n",
      "Epoch 00054: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.0425 - acc: 0.9864 - val_loss: 0.2745 - val_acc: 0.9502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0430 - acc: 0.9860\n",
      "Epoch 00055: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 513us/sample - loss: 0.0430 - acc: 0.9860 - val_loss: 0.2759 - val_acc: 0.9481\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9865\n",
      "Epoch 00056: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0440 - acc: 0.9866 - val_loss: 0.2801 - val_acc: 0.9497\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0426 - acc: 0.9871\n",
      "Epoch 00057: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.0426 - acc: 0.9871 - val_loss: 0.2710 - val_acc: 0.9509\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0399 - acc: 0.9871\n",
      "Epoch 00058: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 495us/sample - loss: 0.0400 - acc: 0.9871 - val_loss: 0.2905 - val_acc: 0.9476\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9871\n",
      "Epoch 00059: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 500us/sample - loss: 0.0419 - acc: 0.9871 - val_loss: 0.2695 - val_acc: 0.9520\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0398 - acc: 0.9878\n",
      "Epoch 00060: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 503us/sample - loss: 0.0398 - acc: 0.9878 - val_loss: 0.2814 - val_acc: 0.9513\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9875\n",
      "Epoch 00061: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0391 - acc: 0.9875 - val_loss: 0.2833 - val_acc: 0.9527\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9881\n",
      "Epoch 00062: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.0387 - acc: 0.9881 - val_loss: 0.2833 - val_acc: 0.9504\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9880\n",
      "Epoch 00063: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 515us/sample - loss: 0.0397 - acc: 0.9880 - val_loss: 0.3006 - val_acc: 0.9483\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0348 - acc: 0.9894\n",
      "Epoch 00064: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 508us/sample - loss: 0.0348 - acc: 0.9894 - val_loss: 0.2855 - val_acc: 0.9504\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0379 - acc: 0.9883\n",
      "Epoch 00065: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 501us/sample - loss: 0.0379 - acc: 0.9883 - val_loss: 0.2745 - val_acc: 0.9527\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0345 - acc: 0.9896\n",
      "Epoch 00066: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0345 - acc: 0.9896 - val_loss: 0.2720 - val_acc: 0.9539\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9883\n",
      "Epoch 00067: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 512us/sample - loss: 0.0378 - acc: 0.9883 - val_loss: 0.2773 - val_acc: 0.9492\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9887\n",
      "Epoch 00068: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 510us/sample - loss: 0.0369 - acc: 0.9887 - val_loss: 0.2801 - val_acc: 0.9515\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0334 - acc: 0.9892\n",
      "Epoch 00069: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 497us/sample - loss: 0.0334 - acc: 0.9892 - val_loss: 0.2822 - val_acc: 0.9511\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0353 - acc: 0.9888\n",
      "Epoch 00070: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 498us/sample - loss: 0.0353 - acc: 0.9888 - val_loss: 0.2930 - val_acc: 0.9504\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0321 - acc: 0.9903\n",
      "Epoch 00071: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 509us/sample - loss: 0.0321 - acc: 0.9903 - val_loss: 0.2941 - val_acc: 0.9534\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9882\n",
      "Epoch 00072: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 19s 511us/sample - loss: 0.0377 - acc: 0.9882 - val_loss: 0.2911 - val_acc: 0.9532\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9891\n",
      "Epoch 00073: val_loss did not improve from 0.24074\n",
      "36805/36805 [==============================] - 18s 499us/sample - loss: 0.0355 - acc: 0.9891 - val_loss: 0.3003 - val_acc: 0.9502\n",
      "\n",
      "2D_CNN_only_conv_ch_32_3_conv_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 284us/sample - loss: 0.3144 - acc: 0.9200\n",
      "Loss: 0.31443020229770385 Accuracy: 0.92004156\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.8521 - acc: 0.4076\n",
      "Epoch 00001: val_loss improved from inf to 1.07134, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/001-1.0713.hdf5\n",
      "36805/36805 [==============================] - 21s 567us/sample - loss: 1.8520 - acc: 0.4076 - val_loss: 1.0713 - val_acc: 0.6890\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0546 - acc: 0.6673\n",
      "Epoch 00002: val_loss improved from 1.07134 to 0.64835, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/002-0.6483.hdf5\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 1.0546 - acc: 0.6673 - val_loss: 0.6483 - val_acc: 0.8225\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7574 - acc: 0.7599\n",
      "Epoch 00003: val_loss improved from 0.64835 to 0.50782, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/003-0.5078.hdf5\n",
      "36805/36805 [==============================] - 19s 530us/sample - loss: 0.7575 - acc: 0.7599 - val_loss: 0.5078 - val_acc: 0.8537\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6198 - acc: 0.8063\n",
      "Epoch 00004: val_loss improved from 0.50782 to 0.41677, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/004-0.4168.hdf5\n",
      "36805/36805 [==============================] - 20s 531us/sample - loss: 0.6198 - acc: 0.8063 - val_loss: 0.4168 - val_acc: 0.8887\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5262 - acc: 0.8346\n",
      "Epoch 00005: val_loss improved from 0.41677 to 0.36263, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/005-0.3626.hdf5\n",
      "36805/36805 [==============================] - 20s 530us/sample - loss: 0.5263 - acc: 0.8346 - val_loss: 0.3626 - val_acc: 0.8998\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4708 - acc: 0.8515\n",
      "Epoch 00006: val_loss improved from 0.36263 to 0.33139, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/006-0.3314.hdf5\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.4708 - acc: 0.8515 - val_loss: 0.3314 - val_acc: 0.9082\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4196 - acc: 0.8684\n",
      "Epoch 00007: val_loss improved from 0.33139 to 0.30676, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/007-0.3068.hdf5\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.4196 - acc: 0.8684 - val_loss: 0.3068 - val_acc: 0.9103\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3791 - acc: 0.8807\n",
      "Epoch 00008: val_loss improved from 0.30676 to 0.28633, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/008-0.2863.hdf5\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.3790 - acc: 0.8807 - val_loss: 0.2863 - val_acc: 0.9203\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3497 - acc: 0.8893\n",
      "Epoch 00009: val_loss improved from 0.28633 to 0.26876, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/009-0.2688.hdf5\n",
      "36805/36805 [==============================] - 20s 531us/sample - loss: 0.3497 - acc: 0.8893 - val_loss: 0.2688 - val_acc: 0.9238\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3336 - acc: 0.8945\n",
      "Epoch 00010: val_loss improved from 0.26876 to 0.24785, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/010-0.2478.hdf5\n",
      "36805/36805 [==============================] - 20s 531us/sample - loss: 0.3336 - acc: 0.8944 - val_loss: 0.2478 - val_acc: 0.9322\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3000 - acc: 0.9054\n",
      "Epoch 00011: val_loss improved from 0.24785 to 0.23413, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/011-0.2341.hdf5\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.3000 - acc: 0.9054 - val_loss: 0.2341 - val_acc: 0.9345\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2882 - acc: 0.9109\n",
      "Epoch 00012: val_loss improved from 0.23413 to 0.22685, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/012-0.2269.hdf5\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.2883 - acc: 0.9109 - val_loss: 0.2269 - val_acc: 0.9371\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2697 - acc: 0.9139\n",
      "Epoch 00013: val_loss improved from 0.22685 to 0.21088, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/013-0.2109.hdf5\n",
      "36805/36805 [==============================] - 20s 533us/sample - loss: 0.2697 - acc: 0.9139 - val_loss: 0.2109 - val_acc: 0.9429\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2556 - acc: 0.9176\n",
      "Epoch 00014: val_loss did not improve from 0.21088\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 0.2557 - acc: 0.9176 - val_loss: 0.2179 - val_acc: 0.9413\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2418 - acc: 0.9229\n",
      "Epoch 00015: val_loss did not improve from 0.21088\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.2418 - acc: 0.9229 - val_loss: 0.2302 - val_acc: 0.9345\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2311 - acc: 0.9266\n",
      "Epoch 00016: val_loss improved from 0.21088 to 0.19673, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/016-0.1967.hdf5\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.2310 - acc: 0.9266 - val_loss: 0.1967 - val_acc: 0.9464\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2140 - acc: 0.9324\n",
      "Epoch 00017: val_loss improved from 0.19673 to 0.19139, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/017-0.1914.hdf5\n",
      "36805/36805 [==============================] - 20s 530us/sample - loss: 0.2140 - acc: 0.9324 - val_loss: 0.1914 - val_acc: 0.9497\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9363\n",
      "Epoch 00018: val_loss did not improve from 0.19139\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.2039 - acc: 0.9363 - val_loss: 0.1923 - val_acc: 0.9455\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1982 - acc: 0.9368\n",
      "Epoch 00019: val_loss did not improve from 0.19139\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.1982 - acc: 0.9368 - val_loss: 0.1916 - val_acc: 0.9490\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1871 - acc: 0.9403\n",
      "Epoch 00020: val_loss improved from 0.19139 to 0.17877, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/020-0.1788.hdf5\n",
      "36805/36805 [==============================] - 20s 530us/sample - loss: 0.1870 - acc: 0.9403 - val_loss: 0.1788 - val_acc: 0.9511\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1816 - acc: 0.9422\n",
      "Epoch 00021: val_loss improved from 0.17877 to 0.17735, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/021-0.1773.hdf5\n",
      "36805/36805 [==============================] - 19s 530us/sample - loss: 0.1816 - acc: 0.9422 - val_loss: 0.1773 - val_acc: 0.9527\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1698 - acc: 0.9446\n",
      "Epoch 00022: val_loss improved from 0.17735 to 0.17048, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/022-0.1705.hdf5\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.1698 - acc: 0.9446 - val_loss: 0.1705 - val_acc: 0.9525\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1638 - acc: 0.9475\n",
      "Epoch 00023: val_loss did not improve from 0.17048\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.1638 - acc: 0.9475 - val_loss: 0.1727 - val_acc: 0.9525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1590 - acc: 0.9473\n",
      "Epoch 00024: val_loss did not improve from 0.17048\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.1590 - acc: 0.9473 - val_loss: 0.1838 - val_acc: 0.9532\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9502\n",
      "Epoch 00025: val_loss improved from 0.17048 to 0.16872, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/025-0.1687.hdf5\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.1549 - acc: 0.9502 - val_loss: 0.1687 - val_acc: 0.9550\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1464 - acc: 0.9532\n",
      "Epoch 00026: val_loss improved from 0.16872 to 0.16525, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/026-0.1653.hdf5\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.1464 - acc: 0.9532 - val_loss: 0.1653 - val_acc: 0.9522\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1444 - acc: 0.9530\n",
      "Epoch 00027: val_loss did not improve from 0.16525\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.1444 - acc: 0.9530 - val_loss: 0.1741 - val_acc: 0.9550\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1378 - acc: 0.9551\n",
      "Epoch 00028: val_loss did not improve from 0.16525\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.1378 - acc: 0.9551 - val_loss: 0.1661 - val_acc: 0.9562\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9558\n",
      "Epoch 00029: val_loss did not improve from 0.16525\n",
      "36805/36805 [==============================] - 19s 524us/sample - loss: 0.1372 - acc: 0.9558 - val_loss: 0.1679 - val_acc: 0.9546\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9577\n",
      "Epoch 00030: val_loss improved from 0.16525 to 0.16480, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/030-0.1648.hdf5\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.1308 - acc: 0.9577 - val_loss: 0.1648 - val_acc: 0.9567\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1272 - acc: 0.9589\n",
      "Epoch 00031: val_loss did not improve from 0.16480\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.1271 - acc: 0.9589 - val_loss: 0.1663 - val_acc: 0.9585\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9607\n",
      "Epoch 00032: val_loss improved from 0.16480 to 0.16454, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/032-0.1645.hdf5\n",
      "36805/36805 [==============================] - 19s 530us/sample - loss: 0.1239 - acc: 0.9607 - val_loss: 0.1645 - val_acc: 0.9543\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9615\n",
      "Epoch 00033: val_loss improved from 0.16454 to 0.16419, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/033-0.1642.hdf5\n",
      "36805/36805 [==============================] - 20s 532us/sample - loss: 0.1150 - acc: 0.9615 - val_loss: 0.1642 - val_acc: 0.9574\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1181 - acc: 0.9615\n",
      "Epoch 00034: val_loss did not improve from 0.16419\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.1181 - acc: 0.9615 - val_loss: 0.1649 - val_acc: 0.9595\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1162 - acc: 0.9631\n",
      "Epoch 00035: val_loss did not improve from 0.16419\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.1162 - acc: 0.9631 - val_loss: 0.1646 - val_acc: 0.9562\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1063 - acc: 0.9649\n",
      "Epoch 00036: val_loss improved from 0.16419 to 0.16024, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/036-0.1602.hdf5\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.1063 - acc: 0.9649 - val_loss: 0.1602 - val_acc: 0.9595\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9651\n",
      "Epoch 00037: val_loss did not improve from 0.16024\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.1067 - acc: 0.9651 - val_loss: 0.1656 - val_acc: 0.9623\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9652\n",
      "Epoch 00038: val_loss improved from 0.16024 to 0.15373, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/038-0.1537.hdf5\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.1033 - acc: 0.9652 - val_loss: 0.1537 - val_acc: 0.9606\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9658\n",
      "Epoch 00039: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 19s 530us/sample - loss: 0.1029 - acc: 0.9658 - val_loss: 0.1656 - val_acc: 0.9599\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0973 - acc: 0.9678\n",
      "Epoch 00040: val_loss did not improve from 0.15373\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0973 - acc: 0.9678 - val_loss: 0.1589 - val_acc: 0.9592\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9685\n",
      "Epoch 00041: val_loss improved from 0.15373 to 0.15141, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_DO_checkpoint/041-0.1514.hdf5\n",
      "36805/36805 [==============================] - 20s 530us/sample - loss: 0.0972 - acc: 0.9685 - val_loss: 0.1514 - val_acc: 0.9616\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0977 - acc: 0.9681\n",
      "Epoch 00042: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0976 - acc: 0.9681 - val_loss: 0.1527 - val_acc: 0.9620\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0911 - acc: 0.9697\n",
      "Epoch 00043: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0911 - acc: 0.9697 - val_loss: 0.1652 - val_acc: 0.9592\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9694\n",
      "Epoch 00044: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 523us/sample - loss: 0.0932 - acc: 0.9694 - val_loss: 0.1620 - val_acc: 0.9620\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9722\n",
      "Epoch 00045: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 0.0864 - acc: 0.9722 - val_loss: 0.1759 - val_acc: 0.9604\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0867 - acc: 0.9710\n",
      "Epoch 00046: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0867 - acc: 0.9710 - val_loss: 0.1712 - val_acc: 0.9618\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9725\n",
      "Epoch 00047: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 0.0824 - acc: 0.9725 - val_loss: 0.1580 - val_acc: 0.9604\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9722\n",
      "Epoch 00048: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 20s 531us/sample - loss: 0.0821 - acc: 0.9722 - val_loss: 0.1737 - val_acc: 0.9620\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0921 - acc: 0.9699\n",
      "Epoch 00049: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 20s 534us/sample - loss: 0.0921 - acc: 0.9699 - val_loss: 0.1642 - val_acc: 0.9613\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9738\n",
      "Epoch 00050: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0783 - acc: 0.9738 - val_loss: 0.1868 - val_acc: 0.9592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9744\n",
      "Epoch 00051: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 20s 530us/sample - loss: 0.0759 - acc: 0.9744 - val_loss: 0.1655 - val_acc: 0.9634\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9753\n",
      "Epoch 00052: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 20s 531us/sample - loss: 0.0739 - acc: 0.9753 - val_loss: 0.1638 - val_acc: 0.9630\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9755\n",
      "Epoch 00053: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0774 - acc: 0.9755 - val_loss: 0.1736 - val_acc: 0.9623\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9756\n",
      "Epoch 00054: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 0.0736 - acc: 0.9756 - val_loss: 0.1595 - val_acc: 0.9644\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9762\n",
      "Epoch 00055: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 525us/sample - loss: 0.0742 - acc: 0.9762 - val_loss: 0.1567 - val_acc: 0.9616\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0715 - acc: 0.9769\n",
      "Epoch 00056: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 525us/sample - loss: 0.0715 - acc: 0.9769 - val_loss: 0.1669 - val_acc: 0.9632\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9755\n",
      "Epoch 00057: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0734 - acc: 0.9755 - val_loss: 0.1729 - val_acc: 0.9613\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9758\n",
      "Epoch 00058: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 20s 532us/sample - loss: 0.0722 - acc: 0.9758 - val_loss: 0.1700 - val_acc: 0.9634\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9778\n",
      "Epoch 00059: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 20s 530us/sample - loss: 0.0680 - acc: 0.9778 - val_loss: 0.1757 - val_acc: 0.9618\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9784\n",
      "Epoch 00060: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0658 - acc: 0.9784 - val_loss: 0.1905 - val_acc: 0.9585\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9774\n",
      "Epoch 00061: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0666 - acc: 0.9774 - val_loss: 0.1768 - val_acc: 0.9620\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0636 - acc: 0.9792\n",
      "Epoch 00062: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0636 - acc: 0.9792 - val_loss: 0.1597 - val_acc: 0.9625\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0641 - acc: 0.9786\n",
      "Epoch 00063: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0641 - acc: 0.9786 - val_loss: 0.1696 - val_acc: 0.9651\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9802\n",
      "Epoch 00064: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0597 - acc: 0.9802 - val_loss: 0.1835 - val_acc: 0.9611\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0653 - acc: 0.9786\n",
      "Epoch 00065: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 20s 532us/sample - loss: 0.0653 - acc: 0.9786 - val_loss: 0.1804 - val_acc: 0.9627\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9796\n",
      "Epoch 00066: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0614 - acc: 0.9796 - val_loss: 0.1768 - val_acc: 0.9630\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0633 - acc: 0.9794\n",
      "Epoch 00067: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0633 - acc: 0.9794 - val_loss: 0.1837 - val_acc: 0.9625\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0585 - acc: 0.9810\n",
      "Epoch 00068: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0585 - acc: 0.9810 - val_loss: 0.1821 - val_acc: 0.9623\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9806\n",
      "Epoch 00069: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0579 - acc: 0.9806 - val_loss: 0.1782 - val_acc: 0.9611\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0553 - acc: 0.9812\n",
      "Epoch 00070: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0553 - acc: 0.9812 - val_loss: 0.1718 - val_acc: 0.9641\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9826\n",
      "Epoch 00071: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0534 - acc: 0.9826 - val_loss: 0.1820 - val_acc: 0.9646\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0588 - acc: 0.9793\n",
      "Epoch 00072: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0588 - acc: 0.9794 - val_loss: 0.1929 - val_acc: 0.9662\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9812\n",
      "Epoch 00073: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0574 - acc: 0.9812 - val_loss: 0.1811 - val_acc: 0.9644\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9829\n",
      "Epoch 00074: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 526us/sample - loss: 0.0520 - acc: 0.9829 - val_loss: 0.1775 - val_acc: 0.9641\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0547 - acc: 0.9817\n",
      "Epoch 00075: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 525us/sample - loss: 0.0547 - acc: 0.9817 - val_loss: 0.1833 - val_acc: 0.9653\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0541 - acc: 0.9816\n",
      "Epoch 00076: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 525us/sample - loss: 0.0541 - acc: 0.9816 - val_loss: 0.1750 - val_acc: 0.9632\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0493 - acc: 0.9836\n",
      "Epoch 00077: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0493 - acc: 0.9836 - val_loss: 0.1922 - val_acc: 0.9648\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0529 - acc: 0.9822\n",
      "Epoch 00078: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0529 - acc: 0.9822 - val_loss: 0.1748 - val_acc: 0.9627\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9828\n",
      "Epoch 00079: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0520 - acc: 0.9828 - val_loss: 0.1789 - val_acc: 0.9639\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9834\n",
      "Epoch 00080: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0502 - acc: 0.9834 - val_loss: 0.1706 - val_acc: 0.9651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9836\n",
      "Epoch 00081: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0476 - acc: 0.9836 - val_loss: 0.1856 - val_acc: 0.9630\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0504 - acc: 0.9840\n",
      "Epoch 00082: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 20s 531us/sample - loss: 0.0504 - acc: 0.9840 - val_loss: 0.1758 - val_acc: 0.9611\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9841\n",
      "Epoch 00083: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0479 - acc: 0.9841 - val_loss: 0.1865 - val_acc: 0.9627\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9839\n",
      "Epoch 00084: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0487 - acc: 0.9839 - val_loss: 0.2026 - val_acc: 0.9599\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9856\n",
      "Epoch 00085: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 527us/sample - loss: 0.0456 - acc: 0.9856 - val_loss: 0.1867 - val_acc: 0.9644\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0475 - acc: 0.9848\n",
      "Epoch 00086: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 528us/sample - loss: 0.0475 - acc: 0.9848 - val_loss: 0.2074 - val_acc: 0.9606\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0455 - acc: 0.9847\n",
      "Epoch 00087: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 20s 531us/sample - loss: 0.0456 - acc: 0.9847 - val_loss: 0.1738 - val_acc: 0.9637\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9843\n",
      "Epoch 00088: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 524us/sample - loss: 0.0481 - acc: 0.9843 - val_loss: 0.2004 - val_acc: 0.9648\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0443 - acc: 0.9860\n",
      "Epoch 00089: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0443 - acc: 0.9860 - val_loss: 0.2034 - val_acc: 0.9625\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0479 - acc: 0.9844\n",
      "Epoch 00090: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 530us/sample - loss: 0.0479 - acc: 0.9844 - val_loss: 0.1917 - val_acc: 0.9653\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9845\n",
      "Epoch 00091: val_loss did not improve from 0.15141\n",
      "36805/36805 [==============================] - 19s 529us/sample - loss: 0.0477 - acc: 0.9845 - val_loss: 0.1835 - val_acc: 0.9653\n",
      "\n",
      "2D_CNN_only_conv_ch_32_4_conv_DO Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 1s 309us/sample - loss: 0.2294 - acc: 0.9371\n",
      "Loss: 0.22936627486351246 Accuracy: 0.9370716\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_only_conv_ch_32_{}_conv_DO'.format(i)\n",
    "    model = build_2d_cnn_only_conv_ch_32_DO(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_2d_norm, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_2d_norm, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "    \n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2D_CNN_only_conv_ch_32_1_conv_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_5 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                3121168   \n",
      "=================================================================\n",
      "Total params: 3,122,000\n",
      "Trainable params: 3,122,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 1s 243us/sample - loss: 1.1518 - acc: 0.6984\n",
      "Loss: 1.1517724619228644 Accuracy: 0.69844234\n",
      "\n",
      "2D_CNN_only_conv_ch_32_2_conv_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                698384    \n",
      "=================================================================\n",
      "Total params: 724,848\n",
      "Trainable params: 724,848\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 1s 302us/sample - loss: 0.5462 - acc: 0.8652\n",
      "Loss: 0.5462203813985624 Accuracy: 0.86521286\n",
      "\n",
      "2D_CNN_only_conv_ch_32_3_conv_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                267280    \n",
      "=================================================================\n",
      "Total params: 345,008\n",
      "Trainable params: 345,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 1s 307us/sample - loss: 0.3144 - acc: 0.9200\n",
      "Loss: 0.31443020229770385 Accuracy: 0.92004156\n",
      "\n",
      "2D_CNN_only_conv_ch_32_4_conv_DO Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_8 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 25, 5, 64)         102464    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 25, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 13, 3, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                39952     \n",
      "=================================================================\n",
      "Total params: 220,144\n",
      "Trainable params: 220,144\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 318us/sample - loss: 0.2294 - acc: 0.9371\n",
      "Loss: 0.22936627486351246 Accuracy: 0.9370716\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_only_conv_ch_32_{}_conv_DO'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_only_conv_ch_32_BN(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    \n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=32*(2**int((i)/2)), strides=(1,1), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 195072)            780288    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                3121168   \n",
      "=================================================================\n",
      "Total params: 3,902,416\n",
      "Trainable params: 3,512,208\n",
      "Non-trainable params: 390,208\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 43648)             174592    \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                698384    \n",
      "=================================================================\n",
      "Total params: 899,696\n",
      "Trainable params: 812,272\n",
      "Non-trainable params: 87,424\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_23 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_24 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_25 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16704)             66816     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                267280    \n",
      "=================================================================\n",
      "Total params: 412,336\n",
      "Trainable params: 378,672\n",
      "Non-trainable params: 33,664\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_26 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_28 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 25, 5, 64)         102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 25, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 25, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 13, 3, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 2496)              9984      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                39952     \n",
      "=================================================================\n",
      "Total params: 230,896\n",
      "Trainable params: 225,520\n",
      "Non-trainable params: 5,376\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model = build_2d_cnn_only_conv_ch_32_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1280 - acc: 0.5424\n",
      "Epoch 00001: val_loss improved from inf to 1.66380, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_BN_checkpoint/001-1.6638.hdf5\n",
      "36805/36805 [==============================] - 25s 688us/sample - loss: 2.1282 - acc: 0.5424 - val_loss: 1.6638 - val_acc: 0.6003\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8888 - acc: 0.7742\n",
      "Epoch 00002: val_loss improved from 1.66380 to 1.62216, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_BN_checkpoint/002-1.6222.hdf5\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.8888 - acc: 0.7742 - val_loss: 1.6222 - val_acc: 0.6541\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4998 - acc: 0.8662\n",
      "Epoch 00003: val_loss improved from 1.62216 to 1.58567, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_BN_checkpoint/003-1.5857.hdf5\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.4998 - acc: 0.8662 - val_loss: 1.5857 - val_acc: 0.6886\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3300 - acc: 0.9099\n",
      "Epoch 00004: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 620us/sample - loss: 0.3301 - acc: 0.9099 - val_loss: 1.6883 - val_acc: 0.6781\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2342 - acc: 0.9371\n",
      "Epoch 00005: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.2344 - acc: 0.9370 - val_loss: 1.6532 - val_acc: 0.6937\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1936 - acc: 0.9473\n",
      "Epoch 00006: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.1938 - acc: 0.9473 - val_loss: 1.7387 - val_acc: 0.6883\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9531\n",
      "Epoch 00007: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.1739 - acc: 0.9531 - val_loss: 1.8940 - val_acc: 0.6848\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1539 - acc: 0.9602\n",
      "Epoch 00008: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 0.1538 - acc: 0.9602 - val_loss: 1.9645 - val_acc: 0.6771\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9655\n",
      "Epoch 00009: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.1332 - acc: 0.9655 - val_loss: 1.9514 - val_acc: 0.6781\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9654\n",
      "Epoch 00010: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.1329 - acc: 0.9654 - val_loss: 2.1567 - val_acc: 0.6774\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1346 - acc: 0.9660\n",
      "Epoch 00011: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.1348 - acc: 0.9659 - val_loss: 2.0741 - val_acc: 0.6769\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1511 - acc: 0.9616\n",
      "Epoch 00012: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.1511 - acc: 0.9616 - val_loss: 2.2509 - val_acc: 0.6685\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1241 - acc: 0.9680\n",
      "Epoch 00013: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 0.1242 - acc: 0.9680 - val_loss: 2.1744 - val_acc: 0.6881\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1101 - acc: 0.9731\n",
      "Epoch 00014: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.1101 - acc: 0.9731 - val_loss: 2.1803 - val_acc: 0.6876\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9775\n",
      "Epoch 00015: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 22s 611us/sample - loss: 0.0925 - acc: 0.9775 - val_loss: 2.4323 - val_acc: 0.6662\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9747\n",
      "Epoch 00016: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 0.1067 - acc: 0.9746 - val_loss: 2.3317 - val_acc: 0.6737\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9695\n",
      "Epoch 00017: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.1342 - acc: 0.9694 - val_loss: 2.3215 - val_acc: 0.6760\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1082 - acc: 0.9756\n",
      "Epoch 00018: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.1082 - acc: 0.9756 - val_loss: 2.3559 - val_acc: 0.6895\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0809 - acc: 0.9812\n",
      "Epoch 00019: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.0810 - acc: 0.9812 - val_loss: 2.2908 - val_acc: 0.6937\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9822\n",
      "Epoch 00020: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.0764 - acc: 0.9822 - val_loss: 2.4684 - val_acc: 0.6837\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9824\n",
      "Epoch 00021: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.0751 - acc: 0.9824 - val_loss: 2.4793 - val_acc: 0.6771\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0818 - acc: 0.9824\n",
      "Epoch 00022: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.0819 - acc: 0.9823 - val_loss: 2.5438 - val_acc: 0.6813\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9805\n",
      "Epoch 00023: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 624us/sample - loss: 0.0823 - acc: 0.9805 - val_loss: 2.5801 - val_acc: 0.6788\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9833\n",
      "Epoch 00024: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.0736 - acc: 0.9833 - val_loss: 2.6311 - val_acc: 0.6709\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9835\n",
      "Epoch 00025: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 0.0757 - acc: 0.9834 - val_loss: 2.6626 - val_acc: 0.6783\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0848 - acc: 0.9812\n",
      "Epoch 00026: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 0.0848 - acc: 0.9812 - val_loss: 2.6956 - val_acc: 0.6765\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9830\n",
      "Epoch 00027: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.0771 - acc: 0.9830 - val_loss: 2.5912 - val_acc: 0.6872\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0692 - acc: 0.9851\n",
      "Epoch 00028: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.0697 - acc: 0.9851 - val_loss: 2.5655 - val_acc: 0.6869\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9838\n",
      "Epoch 00029: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.0774 - acc: 0.9838 - val_loss: 2.6637 - val_acc: 0.6739\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9838\n",
      "Epoch 00030: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.0760 - acc: 0.9838 - val_loss: 2.6516 - val_acc: 0.6816\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9839\n",
      "Epoch 00031: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.0761 - acc: 0.9839 - val_loss: 2.7145 - val_acc: 0.6746\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9894\n",
      "Epoch 00032: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.0548 - acc: 0.9893 - val_loss: 2.7187 - val_acc: 0.6860\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9863\n",
      "Epoch 00033: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.0658 - acc: 0.9863 - val_loss: 2.8002 - val_acc: 0.6762\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9889\n",
      "Epoch 00034: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.0554 - acc: 0.9888 - val_loss: 2.6722 - val_acc: 0.6883\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9875\n",
      "Epoch 00035: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 625us/sample - loss: 0.0625 - acc: 0.9875 - val_loss: 2.7470 - val_acc: 0.6935\n",
      "Epoch 36/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9852\n",
      "Epoch 00036: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 638us/sample - loss: 0.0742 - acc: 0.9852 - val_loss: 2.8898 - val_acc: 0.6769\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0716 - acc: 0.9857\n",
      "Epoch 00037: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 625us/sample - loss: 0.0719 - acc: 0.9857 - val_loss: 2.8594 - val_acc: 0.6748\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0680 - acc: 0.9871\n",
      "Epoch 00038: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 619us/sample - loss: 0.0681 - acc: 0.9870 - val_loss: 2.8152 - val_acc: 0.6830\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9867\n",
      "Epoch 00039: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.0689 - acc: 0.9867 - val_loss: 2.7167 - val_acc: 0.6965\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9896\n",
      "Epoch 00040: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 617us/sample - loss: 0.0579 - acc: 0.9896 - val_loss: 2.8772 - val_acc: 0.6916\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9873\n",
      "Epoch 00041: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.0629 - acc: 0.9873 - val_loss: 2.8862 - val_acc: 0.6802\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0592 - acc: 0.9895\n",
      "Epoch 00042: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.0594 - acc: 0.9894 - val_loss: 2.8558 - val_acc: 0.6823\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9883\n",
      "Epoch 00043: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 616us/sample - loss: 0.0632 - acc: 0.9882 - val_loss: 2.9526 - val_acc: 0.6792\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0603 - acc: 0.9890\n",
      "Epoch 00044: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 622us/sample - loss: 0.0604 - acc: 0.9890 - val_loss: 2.8641 - val_acc: 0.6848\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9903\n",
      "Epoch 00045: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 618us/sample - loss: 0.0519 - acc: 0.9903 - val_loss: 2.8017 - val_acc: 0.6881\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9871\n",
      "Epoch 00046: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.0703 - acc: 0.9871 - val_loss: 2.8705 - val_acc: 0.6886\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0645 - acc: 0.9881\n",
      "Epoch 00047: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.0645 - acc: 0.9881 - val_loss: 2.8913 - val_acc: 0.6883\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0499 - acc: 0.9914\n",
      "Epoch 00048: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 614us/sample - loss: 0.0500 - acc: 0.9914 - val_loss: 2.8430 - val_acc: 0.6986\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0605 - acc: 0.9895\n",
      "Epoch 00049: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.0605 - acc: 0.9895 - val_loss: 2.9053 - val_acc: 0.6904\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0577 - acc: 0.9900\n",
      "Epoch 00050: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 613us/sample - loss: 0.0578 - acc: 0.9899 - val_loss: 3.0811 - val_acc: 0.6851\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9887\n",
      "Epoch 00051: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 612us/sample - loss: 0.0629 - acc: 0.9887 - val_loss: 2.9596 - val_acc: 0.6897\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9914\n",
      "Epoch 00052: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.0508 - acc: 0.9914 - val_loss: 2.9898 - val_acc: 0.6862\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0554 - acc: 0.9905\n",
      "Epoch 00053: val_loss did not improve from 1.58567\n",
      "36805/36805 [==============================] - 23s 615us/sample - loss: 0.0554 - acc: 0.9905 - val_loss: 2.8871 - val_acc: 0.6911\n",
      "\n",
      "2D_CNN_only_conv_ch_32_1_conv_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 325us/sample - loss: 1.7279 - acc: 0.6534\n",
      "Loss: 1.7279256380235666 Accuracy: 0.65337485\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4233 - acc: 0.5970\n",
      "Epoch 00001: val_loss improved from inf to 1.05937, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_BN_checkpoint/001-1.0594.hdf5\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 1.4234 - acc: 0.5970 - val_loss: 1.0594 - val_acc: 0.7063\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6833 - acc: 0.8029\n",
      "Epoch 00002: val_loss improved from 1.05937 to 0.80164, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_BN_checkpoint/002-0.8016.hdf5\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.6835 - acc: 0.8028 - val_loss: 0.8016 - val_acc: 0.7794\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4176 - acc: 0.8798\n",
      "Epoch 00003: val_loss improved from 0.80164 to 0.71475, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_BN_checkpoint/003-0.7148.hdf5\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.4176 - acc: 0.8798 - val_loss: 0.7148 - val_acc: 0.8153\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2915 - acc: 0.9190\n",
      "Epoch 00004: val_loss improved from 0.71475 to 0.66642, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_BN_checkpoint/004-0.6664.hdf5\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.2915 - acc: 0.9191 - val_loss: 0.6664 - val_acc: 0.8353\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2103 - acc: 0.9446\n",
      "Epoch 00005: val_loss did not improve from 0.66642\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.2104 - acc: 0.9445 - val_loss: 0.7568 - val_acc: 0.7994\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1713 - acc: 0.9550\n",
      "Epoch 00006: val_loss improved from 0.66642 to 0.63902, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_BN_checkpoint/006-0.6390.hdf5\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.1714 - acc: 0.9550 - val_loss: 0.6390 - val_acc: 0.8470\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1344 - acc: 0.9656\n",
      "Epoch 00007: val_loss did not improve from 0.63902\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.1345 - acc: 0.9655 - val_loss: 0.8031 - val_acc: 0.7929\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9747\n",
      "Epoch 00008: val_loss did not improve from 0.63902\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.1081 - acc: 0.9747 - val_loss: 0.6603 - val_acc: 0.8463\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9810\n",
      "Epoch 00009: val_loss improved from 0.63902 to 0.63177, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_2_conv_BN_checkpoint/009-0.6318.hdf5\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.0877 - acc: 0.9810 - val_loss: 0.6318 - val_acc: 0.8584\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9835\n",
      "Epoch 00010: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0758 - acc: 0.9835 - val_loss: 0.6980 - val_acc: 0.8360\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9852\n",
      "Epoch 00011: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.0662 - acc: 0.9852 - val_loss: 0.8245 - val_acc: 0.8097\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9871\n",
      "Epoch 00012: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 685us/sample - loss: 0.0581 - acc: 0.9871 - val_loss: 0.6433 - val_acc: 0.8637\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0570 - acc: 0.9879\n",
      "Epoch 00013: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0570 - acc: 0.9879 - val_loss: 0.6904 - val_acc: 0.8514\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0488 - acc: 0.9895\n",
      "Epoch 00014: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0489 - acc: 0.9895 - val_loss: 0.7933 - val_acc: 0.8307\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9910\n",
      "Epoch 00015: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0417 - acc: 0.9910 - val_loss: 0.6948 - val_acc: 0.8491\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9943\n",
      "Epoch 00016: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.0305 - acc: 0.9942 - val_loss: 0.7760 - val_acc: 0.8379\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9917\n",
      "Epoch 00017: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 678us/sample - loss: 0.0378 - acc: 0.9917 - val_loss: 0.7571 - val_acc: 0.8532\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9951\n",
      "Epoch 00018: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0277 - acc: 0.9951 - val_loss: 1.0635 - val_acc: 0.8036\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0288 - acc: 0.9943\n",
      "Epoch 00019: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0288 - acc: 0.9943 - val_loss: 0.7867 - val_acc: 0.8418\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9954\n",
      "Epoch 00020: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0235 - acc: 0.9954 - val_loss: 0.7522 - val_acc: 0.8479\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0316 - acc: 0.9925\n",
      "Epoch 00021: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.0316 - acc: 0.9925 - val_loss: 0.7426 - val_acc: 0.8572\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0212 - acc: 0.9959\n",
      "Epoch 00022: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0213 - acc: 0.9959 - val_loss: 0.8242 - val_acc: 0.8397\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0315 - acc: 0.9924\n",
      "Epoch 00023: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 686us/sample - loss: 0.0316 - acc: 0.9924 - val_loss: 1.0229 - val_acc: 0.8130\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9952\n",
      "Epoch 00024: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0226 - acc: 0.9952 - val_loss: 0.8109 - val_acc: 0.8528\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9957\n",
      "Epoch 00025: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0222 - acc: 0.9956 - val_loss: 1.0524 - val_acc: 0.8046\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9951\n",
      "Epoch 00026: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0225 - acc: 0.9950 - val_loss: 0.9024 - val_acc: 0.8337\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0178 - acc: 0.9963\n",
      "Epoch 00027: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0178 - acc: 0.9963 - val_loss: 0.7810 - val_acc: 0.8577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9969\n",
      "Epoch 00028: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.0156 - acc: 0.9969 - val_loss: 0.8511 - val_acc: 0.8463\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0151 - acc: 0.9969\n",
      "Epoch 00029: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0153 - acc: 0.9968 - val_loss: 0.8373 - val_acc: 0.8428\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0341 - acc: 0.9908\n",
      "Epoch 00030: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.0341 - acc: 0.9908 - val_loss: 0.8552 - val_acc: 0.8465\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9971\n",
      "Epoch 00031: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0162 - acc: 0.9971 - val_loss: 0.8732 - val_acc: 0.8402\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9968\n",
      "Epoch 00032: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0157 - acc: 0.9968 - val_loss: 0.9418 - val_acc: 0.8316\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9981\n",
      "Epoch 00033: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0112 - acc: 0.9981 - val_loss: 0.8174 - val_acc: 0.8521\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0121 - acc: 0.9976\n",
      "Epoch 00034: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0121 - acc: 0.9976 - val_loss: 1.0132 - val_acc: 0.8134\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9968\n",
      "Epoch 00035: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0145 - acc: 0.9968 - val_loss: 0.8957 - val_acc: 0.8400\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9976\n",
      "Epoch 00036: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0117 - acc: 0.9976 - val_loss: 0.8811 - val_acc: 0.8581\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0108 - acc: 0.9979\n",
      "Epoch 00037: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.0109 - acc: 0.9979 - val_loss: 0.8729 - val_acc: 0.8539\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9952\n",
      "Epoch 00038: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0197 - acc: 0.9952 - val_loss: 0.9073 - val_acc: 0.8355\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9976\n",
      "Epoch 00039: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0120 - acc: 0.9975 - val_loss: 0.8839 - val_acc: 0.8623\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9947\n",
      "Epoch 00040: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0201 - acc: 0.9947 - val_loss: 1.0597 - val_acc: 0.8251\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0102 - acc: 0.9977\n",
      "Epoch 00041: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0105 - acc: 0.9976 - val_loss: 0.8495 - val_acc: 0.8586\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9952\n",
      "Epoch 00042: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.0207 - acc: 0.9952 - val_loss: 0.9044 - val_acc: 0.8498\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9982\n",
      "Epoch 00043: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0094 - acc: 0.9981 - val_loss: 0.9151 - val_acc: 0.8488\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9940\n",
      "Epoch 00044: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0221 - acc: 0.9940 - val_loss: 0.9965 - val_acc: 0.8332\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9972\n",
      "Epoch 00045: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0120 - acc: 0.9971 - val_loss: 0.8699 - val_acc: 0.8570\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9971\n",
      "Epoch 00046: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0109 - acc: 0.9971 - val_loss: 0.8550 - val_acc: 0.8602\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9987\n",
      "Epoch 00047: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0066 - acc: 0.9987 - val_loss: 0.8843 - val_acc: 0.8542\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0065 - acc: 0.9987\n",
      "Epoch 00048: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0065 - acc: 0.9988 - val_loss: 0.9681 - val_acc: 0.8470\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9958\n",
      "Epoch 00049: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 681us/sample - loss: 0.0162 - acc: 0.9957 - val_loss: 0.9422 - val_acc: 0.8388\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9965\n",
      "Epoch 00050: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 687us/sample - loss: 0.0135 - acc: 0.9965 - val_loss: 1.3652 - val_acc: 0.7834\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0153 - acc: 0.9958\n",
      "Epoch 00051: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0153 - acc: 0.9958 - val_loss: 0.8689 - val_acc: 0.8668\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0069 - acc: 0.9985\n",
      "Epoch 00052: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.0072 - acc: 0.9985 - val_loss: 0.9309 - val_acc: 0.8560\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9961\n",
      "Epoch 00053: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0169 - acc: 0.9960 - val_loss: 0.9896 - val_acc: 0.8365\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0125 - acc: 0.9969\n",
      "Epoch 00054: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0125 - acc: 0.9969 - val_loss: 0.8711 - val_acc: 0.8637\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0082 - acc: 0.9983\n",
      "Epoch 00055: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 684us/sample - loss: 0.0083 - acc: 0.9983 - val_loss: 1.0680 - val_acc: 0.8381\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0132 - acc: 0.9970\n",
      "Epoch 00056: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 683us/sample - loss: 0.0132 - acc: 0.9969 - val_loss: 1.0917 - val_acc: 0.8334\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9947\n",
      "Epoch 00057: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 682us/sample - loss: 0.0216 - acc: 0.9947 - val_loss: 0.9576 - val_acc: 0.8435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0060 - acc: 0.9990\n",
      "Epoch 00058: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 680us/sample - loss: 0.0061 - acc: 0.9990 - val_loss: 0.9613 - val_acc: 0.8486\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9978\n",
      "Epoch 00059: val_loss did not improve from 0.63177\n",
      "36805/36805 [==============================] - 25s 679us/sample - loss: 0.0109 - acc: 0.9978 - val_loss: 0.8730 - val_acc: 0.8602\n",
      "\n",
      "2D_CNN_only_conv_ch_32_2_conv_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 352us/sample - loss: 0.7404 - acc: 0.8237\n",
      "Loss: 0.7404076204988196 Accuracy: 0.823676\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3933 - acc: 0.5851\n",
      "Epoch 00001: val_loss improved from inf to 0.99236, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_BN_checkpoint/001-0.9924.hdf5\n",
      "36805/36805 [==============================] - 33s 889us/sample - loss: 1.3934 - acc: 0.5851 - val_loss: 0.9924 - val_acc: 0.7091\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.6985 - acc: 0.7942\n",
      "Epoch 00002: val_loss improved from 0.99236 to 0.62002, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_BN_checkpoint/002-0.6200.hdf5\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.6980 - acc: 0.7943 - val_loss: 0.6200 - val_acc: 0.8311\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4618 - acc: 0.8642\n",
      "Epoch 00003: val_loss improved from 0.62002 to 0.53101, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_BN_checkpoint/003-0.5310.hdf5\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.4618 - acc: 0.8643 - val_loss: 0.5310 - val_acc: 0.8544\n",
      "Epoch 4/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3373 - acc: 0.9016\n",
      "Epoch 00004: val_loss improved from 0.53101 to 0.44885, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_BN_checkpoint/004-0.4489.hdf5\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.3370 - acc: 0.9017 - val_loss: 0.4489 - val_acc: 0.8817\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2712 - acc: 0.9206\n",
      "Epoch 00005: val_loss improved from 0.44885 to 0.43522, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_BN_checkpoint/005-0.4352.hdf5\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.2711 - acc: 0.9207 - val_loss: 0.4352 - val_acc: 0.8805\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2202 - acc: 0.9364\n",
      "Epoch 00006: val_loss did not improve from 0.43522\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.2202 - acc: 0.9365 - val_loss: 0.4429 - val_acc: 0.8891\n",
      "Epoch 7/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1900 - acc: 0.9464\n",
      "Epoch 00007: val_loss improved from 0.43522 to 0.40992, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_BN_checkpoint/007-0.4099.hdf5\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.1899 - acc: 0.9464 - val_loss: 0.4099 - val_acc: 0.8956\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1575 - acc: 0.9568\n",
      "Epoch 00008: val_loss improved from 0.40992 to 0.37958, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_BN_checkpoint/008-0.3796.hdf5\n",
      "36805/36805 [==============================] - 28s 747us/sample - loss: 0.1577 - acc: 0.9568 - val_loss: 0.3796 - val_acc: 0.8940\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1334 - acc: 0.9663\n",
      "Epoch 00009: val_loss did not improve from 0.37958\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.1334 - acc: 0.9663 - val_loss: 0.4489 - val_acc: 0.8812\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1158 - acc: 0.9710\n",
      "Epoch 00010: val_loss did not improve from 0.37958\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.1158 - acc: 0.9711 - val_loss: 0.3802 - val_acc: 0.9001\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9745\n",
      "Epoch 00011: val_loss did not improve from 0.37958\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.1011 - acc: 0.9745 - val_loss: 0.3799 - val_acc: 0.9057\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9795\n",
      "Epoch 00012: val_loss improved from 0.37958 to 0.35200, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_BN_checkpoint/012-0.3520.hdf5\n",
      "36805/36805 [==============================] - 27s 744us/sample - loss: 0.0851 - acc: 0.9795 - val_loss: 0.3520 - val_acc: 0.9110\n",
      "Epoch 13/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0829 - acc: 0.9792\n",
      "Epoch 00013: val_loss did not improve from 0.35200\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0829 - acc: 0.9792 - val_loss: 0.3640 - val_acc: 0.9126\n",
      "Epoch 14/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9810\n",
      "Epoch 00014: val_loss did not improve from 0.35200\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0762 - acc: 0.9810 - val_loss: 0.3592 - val_acc: 0.9075\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9829\n",
      "Epoch 00015: val_loss did not improve from 0.35200\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0699 - acc: 0.9829 - val_loss: 0.4264 - val_acc: 0.8956\n",
      "Epoch 16/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9864\n",
      "Epoch 00016: val_loss did not improve from 0.35200\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0598 - acc: 0.9863 - val_loss: 0.3591 - val_acc: 0.9110\n",
      "Epoch 17/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9872\n",
      "Epoch 00017: val_loss did not improve from 0.35200\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0549 - acc: 0.9872 - val_loss: 0.3752 - val_acc: 0.9082\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9898\n",
      "Epoch 00018: val_loss improved from 0.35200 to 0.34265, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_BN_checkpoint/018-0.3426.hdf5\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0473 - acc: 0.9898 - val_loss: 0.3426 - val_acc: 0.9206\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9914\n",
      "Epoch 00019: val_loss did not improve from 0.34265\n",
      "36805/36805 [==============================] - 27s 739us/sample - loss: 0.0401 - acc: 0.9914 - val_loss: 0.4519 - val_acc: 0.9005\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9894\n",
      "Epoch 00020: val_loss did not improve from 0.34265\n",
      "36805/36805 [==============================] - 27s 739us/sample - loss: 0.0469 - acc: 0.9894 - val_loss: 0.3551 - val_acc: 0.9147\n",
      "Epoch 21/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0325 - acc: 0.9938\n",
      "Epoch 00021: val_loss did not improve from 0.34265\n",
      "36805/36805 [==============================] - 27s 745us/sample - loss: 0.0325 - acc: 0.9938 - val_loss: 0.4829 - val_acc: 0.8873\n",
      "Epoch 22/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0309 - acc: 0.9934\n",
      "Epoch 00022: val_loss did not improve from 0.34265\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0309 - acc: 0.9934 - val_loss: 0.4523 - val_acc: 0.8959\n",
      "Epoch 23/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0386 - acc: 0.9913\n",
      "Epoch 00023: val_loss did not improve from 0.34265\n",
      "36805/36805 [==============================] - 27s 740us/sample - loss: 0.0386 - acc: 0.9913 - val_loss: 0.4218 - val_acc: 0.9066\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9927\n",
      "Epoch 00024: val_loss did not improve from 0.34265\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0337 - acc: 0.9927 - val_loss: 0.4258 - val_acc: 0.9054\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0276 - acc: 0.9942\n",
      "Epoch 00025: val_loss improved from 0.34265 to 0.34137, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_3_conv_BN_checkpoint/025-0.3414.hdf5\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0276 - acc: 0.9942 - val_loss: 0.3414 - val_acc: 0.9215\n",
      "Epoch 26/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9956\n",
      "Epoch 00026: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 27s 738us/sample - loss: 0.0232 - acc: 0.9956 - val_loss: 0.3694 - val_acc: 0.9217\n",
      "Epoch 27/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0255 - acc: 0.9944\n",
      "Epoch 00027: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0255 - acc: 0.9943 - val_loss: 0.3708 - val_acc: 0.9178\n",
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0251 - acc: 0.9943\n",
      "Epoch 00028: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0251 - acc: 0.9943 - val_loss: 0.5992 - val_acc: 0.8668\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9964\n",
      "Epoch 00029: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0197 - acc: 0.9964 - val_loss: 0.4019 - val_acc: 0.9078\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9957\n",
      "Epoch 00030: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 753us/sample - loss: 0.0219 - acc: 0.9957 - val_loss: 0.3972 - val_acc: 0.9124\n",
      "Epoch 31/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9929\n",
      "Epoch 00031: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 27s 741us/sample - loss: 0.0319 - acc: 0.9929 - val_loss: 0.4197 - val_acc: 0.9059\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0244 - acc: 0.9945\n",
      "Epoch 00032: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 27s 742us/sample - loss: 0.0245 - acc: 0.9945 - val_loss: 0.6573 - val_acc: 0.8560\n",
      "Epoch 33/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0302 - acc: 0.9929\n",
      "Epoch 00033: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0302 - acc: 0.9929 - val_loss: 0.3780 - val_acc: 0.9201\n",
      "Epoch 34/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9941\n",
      "Epoch 00034: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 27s 743us/sample - loss: 0.0248 - acc: 0.9941 - val_loss: 0.3745 - val_acc: 0.9180\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9976\n",
      "Epoch 00035: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 27s 739us/sample - loss: 0.0135 - acc: 0.9976 - val_loss: 0.3680 - val_acc: 0.9234\n",
      "Epoch 36/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9944\n",
      "Epoch 00036: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 751us/sample - loss: 0.0242 - acc: 0.9944 - val_loss: 0.3927 - val_acc: 0.9187\n",
      "Epoch 37/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9976\n",
      "Epoch 00037: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 757us/sample - loss: 0.0138 - acc: 0.9976 - val_loss: 0.4212 - val_acc: 0.9166\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9945\n",
      "Epoch 00038: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 766us/sample - loss: 0.0235 - acc: 0.9945 - val_loss: 0.3836 - val_acc: 0.9210\n",
      "Epoch 39/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0126 - acc: 0.9978\n",
      "Epoch 00039: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 762us/sample - loss: 0.0126 - acc: 0.9978 - val_loss: 0.3648 - val_acc: 0.9250\n",
      "Epoch 40/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0138 - acc: 0.9972\n",
      "Epoch 00040: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 764us/sample - loss: 0.0138 - acc: 0.9972 - val_loss: 0.5929 - val_acc: 0.8749\n",
      "Epoch 41/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9975\n",
      "Epoch 00041: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 763us/sample - loss: 0.0136 - acc: 0.9975 - val_loss: 0.3761 - val_acc: 0.9241\n",
      "Epoch 42/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9938\n",
      "Epoch 00042: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 761us/sample - loss: 0.0247 - acc: 0.9938 - val_loss: 0.4246 - val_acc: 0.9164\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9972\n",
      "Epoch 00043: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 762us/sample - loss: 0.0130 - acc: 0.9972 - val_loss: 0.3880 - val_acc: 0.9217\n",
      "Epoch 44/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9964\n",
      "Epoch 00044: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 766us/sample - loss: 0.0165 - acc: 0.9964 - val_loss: 0.3696 - val_acc: 0.9262\n",
      "Epoch 45/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9982\n",
      "Epoch 00045: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 765us/sample - loss: 0.0095 - acc: 0.9982 - val_loss: 0.3910 - val_acc: 0.9199\n",
      "Epoch 46/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9984\n",
      "Epoch 00046: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 765us/sample - loss: 0.0091 - acc: 0.9983 - val_loss: 0.4224 - val_acc: 0.9115\n",
      "Epoch 47/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9950\n",
      "Epoch 00047: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 764us/sample - loss: 0.0198 - acc: 0.9950 - val_loss: 0.3937 - val_acc: 0.9192\n",
      "Epoch 48/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0099 - acc: 0.9982\n",
      "Epoch 00048: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 762us/sample - loss: 0.0099 - acc: 0.9982 - val_loss: 0.3813 - val_acc: 0.9164\n",
      "Epoch 49/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9978\n",
      "Epoch 00049: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 763us/sample - loss: 0.0107 - acc: 0.9978 - val_loss: 0.6230 - val_acc: 0.8768\n",
      "Epoch 50/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9950\n",
      "Epoch 00050: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 768us/sample - loss: 0.0188 - acc: 0.9950 - val_loss: 0.4047 - val_acc: 0.9166\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9978\n",
      "Epoch 00051: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 766us/sample - loss: 0.0110 - acc: 0.9978 - val_loss: 0.4115 - val_acc: 0.9238\n",
      "Epoch 52/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0133 - acc: 0.9973\n",
      "Epoch 00052: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 765us/sample - loss: 0.0133 - acc: 0.9973 - val_loss: 0.4102 - val_acc: 0.9196\n",
      "Epoch 53/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9988\n",
      "Epoch 00053: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 763us/sample - loss: 0.0075 - acc: 0.9988 - val_loss: 0.6236 - val_acc: 0.8868\n",
      "Epoch 54/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9946\n",
      "Epoch 00054: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 763us/sample - loss: 0.0203 - acc: 0.9946 - val_loss: 0.3962 - val_acc: 0.9206\n",
      "Epoch 55/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0180 - acc: 0.9956\n",
      "Epoch 00055: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 765us/sample - loss: 0.0180 - acc: 0.9956 - val_loss: 0.4231 - val_acc: 0.9203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9984\n",
      "Epoch 00056: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 765us/sample - loss: 0.0077 - acc: 0.9984 - val_loss: 0.3930 - val_acc: 0.9248\n",
      "Epoch 57/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9990\n",
      "Epoch 00057: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 763us/sample - loss: 0.0061 - acc: 0.9989 - val_loss: 0.3928 - val_acc: 0.9255\n",
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0211 - acc: 0.9942\n",
      "Epoch 00058: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 761us/sample - loss: 0.0211 - acc: 0.9942 - val_loss: 0.3970 - val_acc: 0.9250\n",
      "Epoch 59/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9986\n",
      "Epoch 00059: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 769us/sample - loss: 0.0075 - acc: 0.9986 - val_loss: 0.4084 - val_acc: 0.9252\n",
      "Epoch 60/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9965\n",
      "Epoch 00060: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 765us/sample - loss: 0.0146 - acc: 0.9965 - val_loss: 0.4539 - val_acc: 0.9122\n",
      "Epoch 61/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9984\n",
      "Epoch 00061: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 768us/sample - loss: 0.0077 - acc: 0.9985 - val_loss: 0.3994 - val_acc: 0.9199\n",
      "Epoch 62/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9983\n",
      "Epoch 00062: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 766us/sample - loss: 0.0083 - acc: 0.9983 - val_loss: 0.3993 - val_acc: 0.9208\n",
      "Epoch 63/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0057 - acc: 0.9992\n",
      "Epoch 00063: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 763us/sample - loss: 0.0057 - acc: 0.9992 - val_loss: 0.4330 - val_acc: 0.9138\n",
      "Epoch 64/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0064 - acc: 0.9988\n",
      "Epoch 00064: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 766us/sample - loss: 0.0064 - acc: 0.9988 - val_loss: 0.3980 - val_acc: 0.9259\n",
      "Epoch 65/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9976\n",
      "Epoch 00065: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 768us/sample - loss: 0.0093 - acc: 0.9976 - val_loss: 0.5637 - val_acc: 0.8938\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0117 - acc: 0.9973\n",
      "Epoch 00066: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 765us/sample - loss: 0.0117 - acc: 0.9973 - val_loss: 0.3973 - val_acc: 0.9206\n",
      "Epoch 67/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0075 - acc: 0.9984\n",
      "Epoch 00067: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0075 - acc: 0.9984 - val_loss: 0.4738 - val_acc: 0.9143\n",
      "Epoch 68/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0106 - acc: 0.9976\n",
      "Epoch 00068: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 761us/sample - loss: 0.0107 - acc: 0.9976 - val_loss: 0.4801 - val_acc: 0.9061\n",
      "Epoch 69/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9959\n",
      "Epoch 00069: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0153 - acc: 0.9958 - val_loss: 0.4281 - val_acc: 0.9154\n",
      "Epoch 70/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0144 - acc: 0.9961\n",
      "Epoch 00070: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0144 - acc: 0.9961 - val_loss: 0.4319 - val_acc: 0.9217\n",
      "Epoch 71/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0062 - acc: 0.9987\n",
      "Epoch 00071: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 760us/sample - loss: 0.0062 - acc: 0.9987 - val_loss: 0.4248 - val_acc: 0.9187\n",
      "Epoch 72/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0047 - acc: 0.9992\n",
      "Epoch 00072: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 761us/sample - loss: 0.0047 - acc: 0.9992 - val_loss: 0.3914 - val_acc: 0.9311\n",
      "Epoch 73/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0042 - acc: 0.9993\n",
      "Epoch 00073: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 761us/sample - loss: 0.0042 - acc: 0.9993 - val_loss: 0.4392 - val_acc: 0.9234\n",
      "Epoch 74/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9988\n",
      "Epoch 00074: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 760us/sample - loss: 0.0058 - acc: 0.9987 - val_loss: 0.4541 - val_acc: 0.9175\n",
      "Epoch 75/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9945\n",
      "Epoch 00075: val_loss did not improve from 0.34137\n",
      "36805/36805 [==============================] - 28s 759us/sample - loss: 0.0172 - acc: 0.9945 - val_loss: 0.4437 - val_acc: 0.9243\n",
      "\n",
      "2D_CNN_only_conv_ch_32_3_conv_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzsnXl4FEX6xz81OclJSAKBBEi4b8INIoKKiKKIIqLieqPuurqsu6547C7quuuBx3qgiywrnugPxPVAcUEOFZAbuSWBhCQcOclB7pn390cxOSfJ5BgmJPV5nn5mpru6662e7vrW+1Z1tRIRDAaDwWAAsLjbAIPBYDA0H4woGAwGg6EMIwoGg8FgKMOIgsFgMBjKMKJgMBgMhjKMKBgMBoOhDCMKBoPBYCjDiILBYDAYyjCiYDAYDIYyPN1tQH0JCwuT6Ohod5thMBgM5xXbt29PF5HwutKdd6IQHR3Ntm3b3G2GwWAwnFcopRKdSWfCRwaDwWAow4iCwWAwGMowomAwGAyGMs67PgVHlJSUkJycTGFhobtNOW/x9fUlKioKLy8vd5tiMBjciMtEQSm1GLgKSBWRAbWkGwFsAm4UkWUNySs5OZnAwECio6NRSjXM4FaMiJCRkUFycjIxMTHuNsdgMLgRV4aP3gEm15ZAKeUBPAd825iMCgsLCQ0NNYLQQJRShIaGGk/LYDC4ThREZAOQWUeyB4DlQGpj8zOC0DjM+TMYDODGjmalVCRwLfCmE2nvUUptU0ptS0tLa1B+VmsBRUUp2GwlDdrfYDAYWgPuHH30CvCIiNjqSigiC0VkuIgMDw+v84E8h9hshRQXn0Ck6UXh9OnTLFiwoEH7XnnllZw+fdrp9PPmzWP+/PkNystgMBjqwp2iMBxYqpRKAK4HFiilprkqM6V0UZ3QoHpTmyiUlpbWuu/KlStp27Ztk9tkMBgMDcFtoiAiMSISLSLRwDLgNyLymetytBe16UVh7ty5xMfHExsby8MPP8y6desYN24cU6dOpV+/fgBMmzaNYcOG0b9/fxYuXFi2b3R0NOnp6SQkJNC3b19mz55N//79mTRpEgUFBbXmu2vXLkaPHs2gQYO49tprycrKAuDVV1+lX79+DBo0iBtvvBGA9evXExsbS2xsLEOGDCE3N7fJz4PBYDj/ceWQ1I+ACUCYUioZ+CvgBSAib7kq38OH55CXt8vBFitWaz4WSxuUql+xAwJi6dnzlRq3P/vss+zdu5ddu3S+69atY8eOHezdu7dsiOfixYtp164dBQUFjBgxgunTpxMaGlrF9sN89NFHvP3229xwww0sX76cW265pcZ8b731Vl577TXGjx/PX/7yF5588kleeeUVnn32WY4ePYqPj09ZaGr+/Pm88cYbjB07lry8PHx9fet1DgwGQ+vAZaIgIjfVI+3trrKjnHM7umbkyJGVxvy/+uqrrFixAoCkpCQOHz5cTRRiYmKIjY0FYNiwYSQkJNR4/OzsbE6fPs348eMBuO2225gxYwYAgwYNYtasWUybNo1p03REbuzYsTz00EPMmjWL6667jqioqCYrq8FgaDm0iCeaK1JTi95mK+LMmT34+HTF27thndX1wd/fv+z7unXrWL16NZs2bcLPz48JEyY4fCbAx8en7LuHh0ed4aOa+Oqrr9iwYQNffPEFzzzzDHv27GHu3LlMmTKFlStXMnbsWFatWkWfPn0adHyDwdByaUVzH7muTyEwMLDWGH12djYhISH4+flx8OBBNm/e3Og8g4ODCQkJ4fvvvwfgvffeY/z48dhsNpKSkrj44ot57rnnyM7OJi8vj/j4eAYOHMgjjzzCiBEjOHjwYKNtMBgMLY8W5ynUhH542jWjj0JDQxk7diwDBgzgiiuuYMqUKZW2T548mbfeeou+ffvSu3dvRo8e3ST5LlmyhPvuu4/8/Hy6devGf/7zH6xWK7fccgvZ2dmICA8++CBt27blz3/+M2vXrsVisdC/f3+uuOKKJrHBYDC0LJSIuNuGejF8+HCp+pKdAwcO0Ldv31r3ExHy8rbj7d0RH59IV5p43uLMeTQYDOcnSqntIjK8rnStJnykp3GwuMRTMBgMhpZCqxEFsD/AZkTBYDAYaqJViQJ4IGJ1txEGg8HQbGlVomA8BYPBYKidViUKpk/BYDAYaqdViYLxFAwGg6F2WpUoNCdPISAgoF7rDQaD4VzQqkRBqeYjCgaDwdAcaVWioIvrmqmz33jjjbLf9hfh5OXlcemllzJ06FAGDhzIf//7X6ePKSI8/PDDDBgwgIEDB/Lxxx8DcOLECS666CJiY2MZMGAA33//PVarldtvv70s7csvv9zkZTQYDK2DljfNxZw5sMvR1NngYyvCJiXgUc8QTWwsvFLz1NkzZ85kzpw53H///QB88sknrFq1Cl9fX1asWEFQUBDp6emMHj2aqVOnOvU+5E8//ZRdu3axe/du0tPTGTFiBBdddBEffvghl19+OY8//jhWq5X8/Hx27dpFSkoKe/fuBajXm9wMBoOhIi1PFOqk6af1GDJkCKmpqRw/fpy0tDRCQkLo3LkzJSUlPPbYY2zYsAGLxUJKSgqnTp0iIiKizmP+8MMP3HTTTXh4eNChQwfGjx/P1q1bGTFiBHfeeSclJSVMmzaN2NhYunXrxpEjR3jggQeYMmUKkyZNavIyGgyG1kHLE4VaWvQlRccpLj5OQMAwp1rr9WHGjBksW7aMkydPMnPmTAA++OAD0tLS2L59O15eXkRHRzucMrs+XHTRRWzYsIGvvvqK22+/nYceeohbb72V3bt3s2rVKt566y0++eQTFi9e3BTFMhgMrYxW2KcAruhXmDlzJkuXLmXZsmVlL7vJzs6mffv2eHl5sXbtWhITE50+3rhx4/j444+xWq2kpaWxYcMGRo4cSWJiIh06dGD27Nncfffd7Nixg/T0dGw2G9OnT+dvf/sbO3bsaPLyGQyG1kHL8xRqQT+noKfPtk+l3VT079+f3NxcIiMj6dixIwCzZs3i6quvZuDAgQwfPrxeL7W59tpr2bRpE4MHD0YpxfPPP09ERARLlizhhRdewMvLi4CAAN59911SUlK44447sNm02P3jH/9o0rIZDIbWQ6uZOhugpCSdwsIE/P0HYLGYdxRXxUydbTC0XNw+dbZSarFSKlUptbeG7bOUUj8rpfYopTYqpQa7ypZyyj0Fg8FgMFTHlX0K7wCTa9l+FBgvIgOBp4GFLrQFcO3b1wwGg6El4LI+BRHZoJSKrmX7xgo/NwNRrrKlHNd1NBsMBkNLoLmMProL+NrVmVTsaDYYDAZDddw++kgpdTFaFC6sJc09wD0AXbp0aURuxlMwGAyG2nCrp6CUGgQsAq4RkYya0onIQhEZLiLDw8PDG5Gf3VMwb18zGAwGR7hNFJRSXYBPgV+JyC/nJlfXeAqnT59mwYIFDdr3yiuvNHMVGQyGZoMrh6R+BGwCeiulkpVSdyml7lNK3Xc2yV+AUGCBUmqXUmpbjQdrMptc06dQmyiUlpbWuu/KlStp27Ztk9pjMBgMDcVloiAiN4lIRxHxEpEoEfm3iLwlIm+d3X63iISISOzZpc6HKhqPazyFuXPnEh8fT2xsLA8//DDr1q1j3LhxTJ06lX79+gEwbdo0hg0bRv/+/Vm4sHz0bXR0NOnp6SQkJNC3b19mz55N//79mTRpEgUFBdXy+uKLLxg1ahRDhgxh4sSJnDp1CoC8vDzuuOMOBg4cyKBBg1i+fDkA33zzDUOHDmXw4MFceumlTVpug8HQ8nB7R3NTU8vM2YDCau2NUl5Y6iGHdcyczbPPPsvevXvZdTbjdevWsWPHDvbu3UtMTAwAixcvpl27dhQUFDBixAimT59OaGhopeMcPnyYjz76iLfffpsbbriB5cuXc8stt1RKc+GFF7J582aUUixatIjnn3+eF198kaeffprg4GD27NkDQFZWFmlpacyePZsNGzYQExNDZmam84U2GAytkhYnCnXTtLOj1sTIkSPLBAHg1VdfZcWKFQAkJSVx+PDhaqIQExNDbGwsAMOGDSMhIaHacZOTk5k5cyYnTpyguLi4LI/Vq1ezdOnSsnQhISF88cUXXHTRRWVp2rVr16RlNBgMLY8WJwq1tegB8vKO4OERSJs2MbUnbCT+/v5l39etW8fq1avZtGkTfn5+TJgwweEU2j4+PmXfPTw8HIaPHnjgAR566CGmTp3KunXrmDdvnkvsNxgMrZPm8vDaOUNPddG0Q1IDAwPJzc2tcXt2djYhISH4+flx8OBBNm/e3OC8srOziYyMBGDJkiVl6y+77LJKrwTNyspi9OjRbNiwgaNHjwKY8JHBYKiTVicKYGny0UehoaGMHTuWAQMG8PDDD1fbPnnyZEpLS+nbty9z585l9OjRDc5r3rx5zJgxg2HDhhEWFla2/oknniArK4sBAwYwePBg1q5dS3h4OAsXLuS6665j8ODBZS//MRgMhppoVVNnA+TnHwIEPz/n323QWjBTZxsMLRe3T53dfGl6T8FgMBhaCq1OFJQyomAwGAw10epEQRfZiILBYDA4otWJgvEUDAaDoWZanShA0w9JNRgMhpZCqxMFPSmecL6NujIYDIZzQasThebyop2AgAC35m8wGAyOaHWiYF7JaTAYDDXTakWhKT2FuXPnVppiYt68ecyfP5+8vDwuvfRShg4dysCBA/nvf/9b57FqmmLb0RTYNU2XbTAYDA2lxU2IN+ebOew6WePc2YiUYrMVYLH4VxCI2omNiOWVyTXPtDdz5kzmzJnD/fffD8Ann3zCqlWr8PX1ZcWKFQQFBZGens7o0aOZOnUqStU8U6ujKbZtNpvDKbAdTZdtMBgMjaHFiYLzNF1H85AhQ0hNTeX48eOkpaUREhJC586dKSkp4bHHHmPDhg1YLBZSUlI4deoUERERNR7L0RTbaWlpDqfAdjRdtsFgMDSGFicKtbXoAUpLcykoOESbNr3w9AxqsnxnzJjBsmXLOHnyZNnEcx988AFpaWls374dLy8voqOjHU6ZbcfZKbYNBoPBVbTaPoWm7mieOXMmS5cuZdmyZcyYMQPQ01y3b98eLy8v1q5dS2JiYq3HqGmK7ZqmwHY0XbbBYDA0hlYnCq4aktq/f39yc3OJjIykY8eOAMyaNYtt27YxcOBA3n33Xfr0qX1m1pqm2K5pCmxH02UbDAZDY3DZ1NlKqcXAVUCqiAxwsF0B/wSuBPKB20VkR13HbezU2TZbEWfO7MHHJxpv77C6d2hFmKmzDYaWS3OYOvsdYHIt268Aep5d7gHedKEtFbAX2Ux1YTAYDFVxWUeziGxQSkXXkuQa4F3RrspmpVRbpVRHETnhKpvAPLzWUrDZQCm9uOLYJ09CdjZ06gRBQZXzsdkgPR3S0iAsDMLDwWKpvD0tDVJSoLQUvLzKF6XAatVprFZo2xYiI8HDo7INInD6tLbBx0cvvr56W3Y2ZGXp7Tk5+lgierFYoGNH6NIF2rUrtzs/X9uTkgIlJeDpqfP08NA2dOwIISHl6W02yMiAEyfgzJly+729dT65uTrv3Fz9u1s36NEDAgMdn9OSEkhN1cc7dQoKC/W60lK9REZC3776s6INSUnwyy86fbt2egkN1XZnZZUv+fm67ErpTxEoKtL7FRbq7xZLeZk9PaFNG/D3Bz8/vVQ8Jx4eUFwMBQX62AUF+tj2/8LHBwICIDhYL35+1a/F0lJ9HZw8qcuckVG5zKWl2k77/w3aBk9Pfa59fCAqCnr2hIgI11zrjnDn6KNIIKnC7+Sz66qJglLqHrQ3QZcuXRweTERqHf9PYaG+i8peYWlEAcorp9JSoagIvvtO3wBBQbqSaNdO3ziJiXDoEBw8CHFx+oK2X8Cenjp9xZsWIC9PL7m5lSuRnBy92Lfn5embxc9P52W/USv+nVar/vsyM/VifyW2t7e+eby99V/bsaO+gTp21GXLztZ5ZWfrSiEoSC/Bwfr3mTPlS2YmHDsGycnaHjsBAfrmDAnRN3hKiq4w7Hh56fw6dNA3fnJy5e114empK/HoaH2spCRtR15eg/9WQJ/DTp3Kz1ld+Pjoc2e16kqs4jlwlogIXZaSkvIK1X5unYlUBwZqcSgogMOH9W17PmAXGZutfCkudq7MzhAQoEX33nvhvvua5pg1cV4MSRWRhcBC0H0KVbf7+vqSkZFBaGhozcJQUADJyaigIFrq29dE9A1dUqIvyOJi3UKyt0jsLUp7GntrBYTS0gy2bPHld7+rO5+oKN1qte9fUqIr3oKCmvexC0dQkL7xAwN1Jdu5s77gvbzKK5AzZ/T3ilgsuhU5cKAWnuBgXRZ7OQsLdavsxAnYulVX3h4e5QIQFKTTp6SUi4TNVlmEQkLgggt0pdali97nxAldyScn64rtggt0+aOitAilp5e3wE+d0jfu9dfrckVF6XLbz7W9krW3WJXSrdyjRyEhQX+WlEDv3nDZZdqGkJDy8hUVaZtDQnTrPiRE22hvIYPO5/jxcmE5flyfr6gobVOnTrry1w0BvWRl6XLaFw+PyuIaGKjtsi9K6XX2/1IE4uN1JX74sD5X3t76nLZpoz87dCg/ZocO5S1zLy9t/7FjsH8/HDiglw4dYNIk6NVLnw8/v3Jxy8zUdoeElC/+/pWvcdDXqH3x9i5vANnLXlG08vP1Ovt2q1Xv06ZN+QLl3kdRkd4vO7vcoyss1GWxL3aR7dBBf4aG6mNWbExV9Xbt92ZJic4jMbH8vP7yS3WP0hW4UxRSgM4VfkedXVdvoqKiSE5OJi0treZEhYX6Dj50iCKVjsWSj5dXI5tiLqJixe6otWa/+CtW8hVvhqrYL1L7BaiUvrjslZPFAqWlvvToEcW6dfoGyMmp3Crv0kXfnD176hvQEQUFuoLJyNC/AwN1hR8QoG+Qc+X+Gs49sbGN279bN5gwoUlMaVH07q3F8VziTlH4HPitUmopMArIbmh/gpeXV9nTvjWyfz9ccQUsXcqmLo/Qtu1F9O37bkOyazT2Fuu+fTokk5CgW0qJibq1aK9UQbeC/PzKWzk2m/7dtq1egoMrtxxDQqB9e+jaVVfkHTuem9YFlLeoOnU6N/kZDIamx2WioJT6CJgAhCmlkoG/Al4AIvIWsBI9HDUOPST1DlfZApT3JaSn4xHjj9V6xqXZVUQE9uyB5cvhf//TYpCTU769TRtdiXftCkOHQr9+MGCAXtq3Ny1sg8Fw7nDl6KOb6tguwP2uyr8aZ+cLIj0dDw9/bLb82tM3Abt3w8cfw7JlOiZoscCYMfCrX+mKv39/3akWHm4qfoPB0Dw4LzqamwRPTx1jSU/HYvFzmaeQnAwffgjvv6+9Aw8PuOQS+OMfYdo03fI3GAyG5krrEQUoGy7i4eFPcfHJJjtseroODS1dCuvX63DRmDGwYAHMmFFhFKzBYDA0c1qpKIQ0OnwkooVg0SJYvVp3AvfpA3/9K9xyC3Tv3kQ2GwwGwzmk9YlCSgoWS2Sjwkfr18PDD+vx8NHR8Kc/wY036jH0pm/A4EpsYsPi5MuhDM2T/JJ8PtzzId/Gf8uQiCFc1v0yhkQMwcNyjoYJ1kHrE4Xdu/HwaNjoo/374ZFH4Msv9cNA77yjvYJzNeTTFRSVFpF6JpXOwZ3rTtxExGfG82PSj1htVmxiwyY2fDx96BbSje4h3YkIiKj96fQmIL8knxO5Jwj1CyXIJwiLsmATGwmnE9h1che7T+4m9UwqvUJ70Te8L33D+tI5uLPDCrnUVkrC6QR+yfiFuMw44jLjiM+KJyk7iacvfppr+lzj0IbnfniOuMw4JnabyCUxlxDuHw7op/OP5x5n96nd7E3dy6H0QxzMOMih9EPkFucyJGIIo6NGMypyFBd0voCubbvWWE6rzYpFWep9PtPOpLE+cT3rEtZxuvA0Pdr1oFdoL3q260m/8H74ezt+WEVE2HVyF4WlhViUBYuyUGorJT4rnoPpBzmUcYi4zDjOFJ+hyFpEsbWYYmsxFmXB0+JZtgBl14ZNbAxoP4Dfj/49l3e/vFpZiq3FJJ5OpKC0gMLSQgpLC/GyeDGk4xB8PX0rpd2aspU3tr7Bl798yVtXvcX1/a53WI7jucexKAsRATW/EKsmcopy2JqylZTcFCICIogMjCQyKJLThadZsHUBi3YsIqswi4iACP5v///x2HePEeIbwsUxFzM6cjTDOw1naMehBPsGc6b4DFtStvDDsR/4MelHrut7HfcMu6feNtWH1icK6el4ePjVK3xUXAz/+Ac884wePvrss/Dgg+VPOZ4LRISC0gJyi3Jp16YdXh5ejTpeSk4Kb257k4XbF5KWn8Z9w+5j/qT51W72vOI8von7hit7Xomfl1+j8kzPT+ep9U/x5rY3KbWV1pjOz8uPkZEjWTFzBW192zp17IKSAnw9fZ2u/KZ+NJU1R9cAYFEW2rVpR1FpEbnFuWXrgnyCOF14umwfX09fQtuEEuoXSmibUNp4teFo1lHiMuMosZU/ZRjgHUD3kO5kFWZx/8r7mdhtYrXzuilpE3PXzMXL4sWinYsA/drX0Dah7D61m/T89LK0Hfw70DusN9P7TifAO4BtJ7axcPtC/vnTPwHoHdqbK3teyZSeUxgdNZqdJ3ey+shqVh9ZzU8pP+Ht4U3HgI50DOxIZGAkj174KIMjBjs8Lwu2LmDB1gXsS9sHgL+XP6F+oXy450Pk7NsKIwIi+OGOH+jernqM9Perfl9mV1U8lAcxITH0bNeTYN9gfDx88PbwxtvDGxGh1FZKqa2UElsJSiktKlgQhFXxq7jigyvoH96fP4z5A0M7DuW7o9+x+uhq1ies50xJ9Uaet4c3IyNHclGXi4gMiuSdXe+w9fhWArwDiAiIYNanswjzC2NC9IRK+3205yNu/exWSm2ldA3uWibA46PHExsRW61hkFOUw1e/fMWao2v4KeUn9qXuKztXjs7BtD7TeHDUg4zrMo7UM6m6HEdW813Cd3x64NOytF2Cu3A89ziltlIUigHtB6BwfSjCZVNnuwpHU2c7zXPPwdy5JOx7jITUvzN+fClK1d7M374d7rhDjyS6+WZ45RU9hNQViAhJOUnsPrlbt1ZP7WZP6h7S89PJKcopq0i9PbzpG9aXgR0GMqj9IC7rfhmxEdUfKY3LjGPeunlsP7GdiIAIXTEEdCQ5N5lPD3yK1Wbl6t5X0zmoMwu2LqB7u+68d+17jI4aTU5RDq9veZ2XNr1ERkEG47qM48ubvyTIp+631R3JOsKpvFP4efnh7+2Pr6cvH+35iGe+f4bc4lxmD53N70b9Dj8vv7LW5JmSMxzJOkJ8Zjy/ZPzCa1te46ExDzF/0vxqx7eJjY/2fMRPKT9xIP0AB9IOkJKbQnv/9oyJGsMFnS8oWxy17LembGXkopHcNeQu+of3J7Mgk4yCDCzKwuAOgxkcMZgB7Qfg5+VH2pm0sjzis+LJyM8goyCDzIJMcotz6RrclT5hfegd2pveYb3p0a4H4X7hKKXYmLSRsYvH8ueL/sxTFz9Vlr/VZmXUolGcyDvB/t/s51DGobJKPK84j0EdBhEbEcvgDtqOkDbVX7Naaitlb+pe1ies5+u4r1mXsI4ia1HZdoVieKfhjO86HqtYOZF3gpN5J9l9cjeBPoHsvm93NcH9+vDXXPnhlYyOGs203tOYED2BoR2H4uXhRWFpIUeyjrA/bT/3fnkvoW1C2XjXRsL8ykdRvL7ldR74+gHuG3Yf1/a9tqyVr1BEt42me7vueHt413n9OKLYWszSvUt5cdOL/Hzq57L1vUN7M7HbREZ0GkGAdwC+nr74evqSW5zLj8d+ZMOxDWw/vh2rWOkT1of7R9zPrYN1hX/h4gtJyU3h+zu+Z1CHQQC8ufVN7l95P+O6juOa3tewOXkzP6X8xLHsY4AW6Mt7XM7k7pMpKC3g0wOf8r8j/6PYWky7Nu0YFTmK0VGjGR01mpi2MZzMO0lKbgopOSmU2kq5eeDNtXrl6fnpbD++ne0ntrMndQ8xbWO4sMuFjIka4/A6qA/OTp3dukTh3/+Gu+8mZeOjHC76BxdemIunZ4DDpCIwb572Dtq3h7fegqlTG263I4pKi/jvof+y7fg2dp7cyY4TO8gsKJ+5rEe7HgzqMIgI/wiCfYMJ8gkiwDuApOwk9qTu4edTP5OSq2cGGR01mt8M/w0z+s8gqyCLpzc8zds73sbbw5uJ3SaSWZDJidwTnMg7gY+HD3cOuZPfjPgN3UK6AbA+YT23fXYbSTlJ3ND/Br6J+4bThaeZ0nMKE6In8OiaR4mNiOWbWd8Q6hdarSxZBVl8vO9j3t39LpuSNzks75SeU3j+sufpF96vznNz13/v4r2f32P//fvp0a5HpW0vbnyRP/7vjwR4B9AnrA/9wvvRPaQ7R7KOsDFpI4czDwNw77B7eeuqt6od+8ZlN/J13Nck/T7JKZFrDDcvv5kVB1dw4P4DRLeNBmDRjkXM/mI2H1z3ATcPvLlJ8jlTfIa1CWvZkrKF2IhYLo6+2GElsiVlC2MXj2Van2l8cv0nZZ7VybyTDHpzEBEBEfx090+08arZDd6YtJFL372U2IhY1ty6Bj8vP7765SumLp3K1b2uZvkNy10WHxcRvjv6HcdzjzMheoJTYc+84jyOZR+jb1jfSp7ksexjXPDvCxCEjXdu5L2f3+PPa//M1b2u5uPrP650Do7nHmf1kdV8E/cN38Z/S0aBnnYgum001/W5juv6XseYzmOadX+Ps6KAiJxXy7Bhw6TBrFghAnLq60dk7VqkqOhkjUlff11PRnzLLSJZWTUf0mazSUJWgnz484fy269+KzM+mSF3/fcu+f03v5d5a+fJkl1LJL84v9p+PyX/JP3f6C/MQ7yf9pZh/xomd//3bnljyxuy8dhGyS3KdapIqXmp8vKml6X3a72FeUjoc6Hi94yfeD7lKb/58jdyIvdENXttNpvDY2UXZsvtn90uzEOu+ega2ZayrWzbF4e+EJ+nfWTAggFlx0zNS5Ulu5bI9I+ni8/TPsI8pP8b/eX5H56Xrw9/Lcv3L5f3dr8nb219S9YnrHeqPHaO5xwX/2f8ZdrSaZXW7zqxS7xXwPwRAAAgAElEQVSf9pZpS6fVWI7UvFS594t7Rc1TsjVla6VtR7OOiseTHvLHVX+slz0N5djpY9Lmb21kxiczREQkMz9Twp4Pk3GLx9Vov6t57ofnhHnIv7b9S0RErDarXPbuZdLmb21kX+o+p46xfP9yUfOUTFs6TbYf3y4Bfw+QYf8aJnlFea40vcnZc2qPBP8jWNo+21aYh/zq019JcWlxrfuUWktlS/IW2Xlip9v+w4YAbBMn6li3V/L1XRolCt9/LwKS/uEfZO1aJD8/3mGyTZtEvLxErrpKxGqtvj0jP0M++PkDuWnZTdLpxU7CPIR5iN8zftL7td7S6cVO4v+Mf9n6sOfD5Ik1T8iJ3BNypviM/GHVH8TypEWiXoqSzw58JkWlRQ0v01lsNpusObJGblx2o9zx2R0SlxHX4GOVWEscrl9zZI34P+Mv3f7ZTcYsGiNqnhLmIR3nd5QHVz4o249vb9Kb5G/r/ybMQ7478p2IiOQX50v/N/pLxPwISTuTVuu+2YXZ0v6F9nLBvy+oZNOcr+eI51Oecuz0sSazsy6eXPekMA9Zn7BeHlj5gFietMjOEzvPWf5VsdqsMum9SeL7N1/Ze2qvvPDjC5VEwlle2fRKWaMm6qUoSclJcZHFrmV9wnoJ/HugzPl6jlhtDm74FoKzotC6wkcHD0LfvmQveJCdfV9l+PA9BARUflNoWpqef8jDN5/J8x8jozgFPy8//Dz98PX0ZcfJHfx47EesYiXcL5yJ3SYytvNYLuh8AQM7DCwbOQE6dvzDsR94efPLfH7oc7w8vAjzC+N47nHuG3Yfz132nMvDF03NpqRN3PzpzYT5hXFVz6u4qtdVDO041CWjhQpKCujzRh/atWnHttnbeGjVQ7y65VW+mfUNl/e4vM79F+9czF2f38X7177PrEGzOF14ms4vd+aa3tfw/nXvN7m9NZFfkk+f1/vg7eFNwukE7hl2DwumLDhn+TviZN5JBr81mEDvQBKzE5naeyrLZiyr9//4yP8e4d87/82aW9fU2Hl9PlBqK61077ZETPjIEWlpIiB5/7hX1q5FsrM3V9pcWioycaKId9BpGfLqOFHzlPR9va90fbmrhD8fLv7P+MugNwfJ42sel81Jm+vVqvgl/Rf57Ve/lQnvTJC1R9c2vAytjI/2fCTMQ25bcZswD3lw5YNO72u1WWXYv4ZJpxc7SW5RblnYZMfxHS602DFL9ywV5iHtnmsn6WfSz3n+jlgVt0qYh3R+qbNk5Gc0+Dg1eZaG5gUmfOSA0lIRpST/4Vtl7VokM3NNpc1PPCGCX5p0fWaYeD7lKUv3LG14XoYmwWazyZhFY8r6Kxz1z9TGj8d+FOYhf/r2TxL5YqRcsuQSF1laOzabTf646o/yxaEv3JJ/TXxx6As5mHbQ3WYYzgHOikLL9peq4uEB7drhkaWfUbBay59V2L8f/vbP47Sdcxmn5AifzfyMKb2muMtSw1mUUrx+5ev8+qtfs/CqhbWOinHEBZ0vYNbAWTy/8XkA3r76bVeYWSdKKV6Y9IJb8q6Nq3pd5W4TDM2M5jt+ylWEhWHJ1A8o2WzlD7w8s3A/3HkhJf7H+GbWN0YQmhFDOw7lp7t/anDM+tmJz+Ln5Ue/8H5M7jG5ia0zGFoWrctTAAgLQ50VBftUFx/t/IwP/X+Fr8Wftbd9x4jIEe600NDERAVF8e0t3xLSJsTl02cYDOc7rdJTUBl66oKS0jz+uvav3Pz5tZDaj6UXbzeC0EIZ22WsUw/NGQytndbnKYSGorZuodQGs1f/i2+P7Sck8Xaidr3J1IW+de9vMBgMLZhW6SmQnsGWTPj22H7u6/EPsv6zmPvv9TXTXhsMhlaPS0VBKTVZKXVIKRWnlJrrYHsXpdRapdROpdTPSqkrXWkPoMNHxcXszfTAy+JB9qo5BAYqZs1yec4Gg8HQ7HGZKCg9/egbwBVAP+AmpVTVoO4TwCciMgS4EXD9Y55n34259zT0CerA8o99ue02CHA8L57BYDC0KlzpKYwE4kTkiIgUA0uBqm8bEcA+z0MwcNyF9mjCwsj3ggMFVnxPDae4GH79a5fnajAYDOcFruxojgSSKvxOBkZVSTMP+FYp9QDgD0x0oT2asDC2REIpcGTtDCZMgH5mUIrBYDAA7u9ovgl4R0SigCuB95SqPiG5UuoepdQ2pdS2tLS0xuUYFsb3XUAJZOyawuzZjTucwWAwtCRcKQopQMU3YESdXVeRu4BPAERkE+ALhFVJg4gsFJHhIjI8vLGvPQsL44cuEJEfBoUhDK97zkCDwWBoNbhSFLYCPZVSMUopb3RH8udV0hwDLgVQSvVFi0IjXYHaKQ30Z2NnCE/tg8ViJTralbkZDAbD+YXLREFESoHfAquAA+hRRvuUUk8ppewvtvwDMFsptRv4CLj97Gx+LmN36h7yfMA3cSQdOpzAu2GvjDUYDIYWiUufaBaRlcDKKuv+UuH7fmCsK22oyg/HfgCg4JdJREYmoKNaBoPBYAD3dzSfc74/9j1dC3w4njqCyMg4d5tjMBgMzYpWJQoiwg/HfmDUmY5klLajY8df3G2SwWAwNCucEgWl1O+UUkFK82+l1A6l1CRXG9fUxGXGcerMKboXDAKgU6cDiNjcbJXBYDA0H5z1FO4UkRxgEhAC/Ap41mVWuYjvj30PQFjehQB06hhf6e1rBoPB0NpxVhTs84deCbwnIvsqrDtv+OHYD4S2CaUwVz9YHRV8pNLb1wwGg6G146wobFdKfYsWhVVKqUDgvIu7fH/se8Z2GUt8bkciOEFw8RnjKRgMBkMFnBWFu4C5wAgRyQe8gDtcZpULOJl3krjMOMZ1GUd8Vju6E49XdvkrOQ0Gg8HgvCiMAQ6JyGml1C3oKa+zXWdW02N/PmFcl3HEpwZoUcjBhI8MBoOhAs6KwptAvlJqMPop5HjgXZdZ5QJGR43mrSlv0aftEJJTfehB3FlPwYSPDAaDwY6zolB6dvqJa4DXReQNINB1ZjU9UUFR3Dv8XlKO6Xkt7OGjkpIMN1tmMBgMzQdnp7nIVUo9ih6KOu7s9NZerjPLdcSdfYi5m0ciXtlQVJToXoMMBoOhGeGspzATKEI/r3ASPWHQCy6zyoXEx+vPHqFZeOd6UVhoRMFgMBjsOCUKZ4XgAyBYKXUVUCgi51Wfgp34eAgOhtBwD3xz21BYmOBukwwGg6HZ4Ow0FzcAW4AZwA3AT0qp611pmKuIi4MePUCFheKd42k8BYPBYKiAs30Kj6OfUUgFUEqFA6uBZa4yzFXEx8PQoYA1DM9kMaLQWpg/H6Ki4MYb3W2JwdCscbZPwWIXhLNk1GPfZkNpKSQkQPfuQFgYntklWK3ZlJScdrdpBlfz4ovw73+72wqDodnjrKfwjVJqFfrtaKA7nlfWkr5ZcuyYFoYePYAjYViy8sGmRyB5ebV1t3kGV1FYCCdPQrt27rbEYGj2OCUKIvKwUmo65W9JWygiK1xnlmuwjzzq3h3ICUNZbXiegcLCRAICBrvVNoMLSUrSnykp7rXDYDgPcPp1nCKyHFjuQltcTiVRSAoDwCsb06/Q0kk8+/9mZ8OZM+Dv7157DIZmTK39AkqpXKVUjoMlVymVU9fBlVKTlVKHlFJxSqm5NaS5QSm1Xym1Tyn1YUML4gxxceDrC506AWFaFLxzvM2w1JZOYgXRP37cfXY0R26/Hd5txOjyr76C4cOhpKTJTDK4l1pFQUQCRSTIwRIoIkG17auU8gDeAK4A+gE3KaX6VUnTE3gUGCsi/YE5jSpNHcTHQ7duYLEAXboAEJwUYjyFlk5CQvl3IwrlWK3w/vuwohGR4P/9D7Zvryy8hvMaV44gGgnEicgRESkGlqLnTqrIbOANEckCqDLCqcmJjz8bOgLo2xdiYgj7vtRMddHSSUwEdfadUKZfoZzjx7UwHDnS8GPYY7JHjzaNTQa340pRiASSKvxOPruuIr2AXkqpH5VSm5VSk11ljIi+fnv0OLtCKZg+ncAtWZSkNuKmMLie4mJYvFhXYA0hMREGDNDfjadQjr11f+SIvkEagl0UKnpjhvMadz9r4An0BCYANwFvK6WqjQ1VSt2jlNqmlNqWlpbWoIxOnoT8/AqeAsD06agSG8EbMs3LdpozK1fCXXfB+vUN2z8xEQYO1B3M7hSFJUtg1y735V+VY8f0Z14epKfXf3+brdxDMJ5Ci8GVopACdK7wO+rsuookA5+LSImIHAV+QYtEJURkoYgMF5Hh4eHhDTLGPjtqmacAMHIk1o4hhG+AwsJjDTqu4RxgD28cOlT/fUtLITkZoqMhMtJ94SObDe65B156yT35O6JiP0BDKvUTJ/QzIGA8hRaEK0VhK9BTKRWjlPIGbgQ+r5LmM7SXgFIqDB1Ockksx95ArOQpWCyUTr2UdluhMO2AK7I1NAX2Cuvw4frva4+bd+2qh525y1M4cUKHwZpTi/pYhYZQQ/oV7KEjL6/mVS5Do3CZKIhIKfBbYBVwAPhERPYppZ5SSk09m2wVkKGU2g+sBR4WEZe89WbmTCgo0KOPKnH9TCwloL4+7x7Qbj3YW6G//FL/fe2t4a5d3esp2Mtgr0ibA4mJ0KeP/t4QUbDvc8EFRhRaEC7tUxCRlSLSS0S6i8gzZ9f9RUQ+P/tdROQhEeknIgNFZKkr7fH1PTsctQLeE6ZSHALeX/7oyqwNjcFeoTbEU7DvW9FTaGinamOwV5onTujOreaAXRQiIhruKVgsMH48nDqlW13nK599Brm57raiWeDujma3ozy9yRofiN/auPP7om6piJRXqEeO6D6C+mD3FLp00Z5CURFkZjatjc5QMebeHOLvIjp81KWLdp8bKgpdukCvXvp3cyhXQ4iLg2uvhUWL3G1Js6DViwJA7uXdsBSUwqpV7jbFUJWMDD01RWxs+TS39SExEcLDwc/v7KPsuKdfoWJ4pTHPBTQVWVl61FHXrg0XhSNH9L4xMfr3+SoKu3frz59/dq8dzQQjCkDp2MGUBClYfl5P7dQysVemkybpz/r2KyQm6pFHoD0FcE+/Qtmc7TQPUbB3Mts9haQk3RFeH+xPg9pF4XztV9i7V3/u2eNeO5oJRhQAn4AY0i8Q5PPPdXjB0Hywtz7tolDffoXERN0aBvd7CiNH6mclmoMoVOyA79ZND5k9Vo9h2Tk5+tmG7t2hQwfw8Tl/PQW7GOzf3/AHJFsQRhQAX99o0i4ClZMDa9a42xxDReytzxEj9Mu16+Mp2OPmdlHo2FF/nmtPobRUt8RjYhoeqmlq7ALQtWt5S78+dtnTdu+uO5ujo89fT2HPHvDw0H2KzeG/cTNGFABf365kDQNbcAAsdekAKEN9SUjQL8cJCtIdmvXxFFJT9cNVdlHw8dGz455rTyElRQtDdHTzEYXERD0cLzy8fJx2fSp1+9Ba+77R0eenp1BQoDua7Z6oPZTUijGigBYF8YbCKUP0jJHNZcigQVc09j6Bnj3r5ylUDJHYccezCvbKMiZGt6wbM9dQU5GYqPsTlNJhNW/v+olVpZeToMt2PnoKBw7o0NnMmfq36VcwogDg4xMFWMieEq1HZHz5pbtNMtg5erQ8vNGrlw572KdWqIuKzyjYccdTzXY77J5CQYGejMudVAyrWSz6HNc3fBQaqkN6oMuWkXH+jfW3i8Do0fq/MZ6CEQUAi8UbH59OnB4kutL40KXv+jE4i0h1T8E+3a0zNBdP4ehR3SK3j/QB94eQ7J6CnfqGtewvJ7Fzvg5L3btXhxW7d9eTJhpPwYiCHR+frhSWJMGNN+pZObOy3G2S4dQp7RXYRcH+kJSzIaTERN2SbVth4t1OnfRx6/sQXGNISNBi5O3dPEShsFCfg4pi2RBRqDiRmP0/Ot9CSHv2QL9+4Ompp1c/fNh5T7SFYkThLL6+0fplOzffrF8taJ5ZcD8VY/GgPQVwvrO54nBUO5GR2ts4l+Gbo0fLK82uXbXX4E5RSDr7mpOqnsLp0841hkpKdPipoiicr57Cnj3aQwD9abXCwYPutcnNGFE4i69vVwoLk7DFDtItUhNCckx+PowdCwsWuD6virF40K3+9u3r5ylUFQV3PKuQkFBeafr6amFypyg4CqvVZ1jqsWO68qwYPgoL00+Nn0+eQmamvg7sL2Cyi0Nt/Qq5ufDdd/Dssy12BgRPdxvQXPD17QpYKS45ge/NN8OTT+rYc2TVl8W1cn76CTZu1IuvL9x5p+vyslcwFSuvnj3r5ymMH1953bl+qrmkpPx9DnbcPSy14jMKdiqGtYYNq33/qiOPQHs/MTHnl6dgr/ztYtCzp54G3FG/wmuvwdtv633sI8eCgvS5CAs7N/aeI4yncBYtClBYmAg33aT/+I8/drNVzZCNG/Xn+PEwezZ88onr8kpI0OPoAwLK1/Xq5ZyncPq0furW3Z5CUpIe8mhviYP7RcH+zuqKDZ76eAoVH1yryPn2AJu98rd7Cl5e+t3tVT2F48dhzhy9/S9/ga+/1vfBmTPw1FPn1uZzgBGFs/j6RgNQWHhUVzzDh5sQkiM2btQ3zsqVOow0a5b+7goqxuLt9Oyp+wPqGvroaDgqaJHx9Dx3noK9kqxYju7ddUXjrll5jx0rfzbBTlCQbvE6U6nHx+sRO3aBtWN/VsHdz2A4y969ehBCRXEcMKC6KLz/vhb2pUth3jyYPBnGjNFv0nvzzYa956MZY0ThLL6+3bFY/MnN3apXzJoF27c37BWQNSGiWxfNmTNn4NVXddijKjYbbN6sX6ri5wdffAGDB8P06bBuXdPbUjEWb8c+AqmuEJKjuDnoMfkdO547T6FqZzk07AnipqTqcFQ7znow8fG6PFVfThIdrb2z06ebxMwaWbAA/vSnxh/H3smsVPm6gQO1aGZn698i8J//6AZQzypvCp43D9q0gUceabwtFbFadYP0oou08GzYoO+9c4QRhbNYLJ4EBY0mO/vsy3ZmztQX/TXX6BeuV60kRbRgnDrlfCYLF+oXmrjr7V/O8P778Lvf6Qq/Kr/8ojvnLrhA/w4Ohm++0S3fq6+GLVuazg6brfIMp3acHYFkF4Wq+4Nu4Z5LT8HDA6Kiyte5e1iqow54cF4UjhypHjqCczNb6s6d8OCD8MILurJsKCLaI7CHjuzYf+/bpz9/+kmPRrrjjurHaN8e5s7VL+hpjC0Vbfr0U93QmjVLv5Dpww91qDYmBh59VD+B7WKMKFQgOHgseXm7KS3N1a3Jzz7TbvLtt0OPHrqz6b334Lbb9E3ep48OMzlTwdhs8OKL+onphQtdXpYGs3q1/nQkCvb+BLsogA45/O9/+gaZPLnpHv6xv9O4aqXeo4f+rMtlT0zUrbjw8OrbIiPPracQFaVDVnbcKQo2m+7nqEkUEhNrf4bD/vBgbaLgqs7m0lLdjxUaqu/PRx9teKgqOVl7A/ZOZjv23/br+J13tFd8ww2OjzNnjv5///jHxrXm09L0LLrTp+tyLl1a3uj84APo318L4ZIlDc/DSYwoVCA4eCxgIydns15x9dWwaxd89ZV2tx98EG69VcfQL7wQ5s/XF9aVV2q3uTZWr9at23bttCjUd+76c4HNpofbgS5z1Yt840Ztvz2EY6djR10+Pz+47LKGvTazKo7CLqDziIpyzlOwz+1TlXPtKVQtQ3i4+6bQPnlSe72OwkcxMbpCSk6uef+0NN2wqfayc1z/ANtrr+mQ7quvwl//qq9HZ6ak2bABJk6sfM3YK/2qotClCwQGai+ioEBXztOn63WO8PODv/8dtm7Vjb6lS/Xvu+6CX/0K3npLt+7rEq8//UnXNf/5j87bHqnw99fPTq1cqa/Z3/++7vI2FhE5r5Zhw4aJqygpyZa1ay1y5MhfHSfYvl1k504Rq7V83apVIh4eIpddJlJcXPPBr7lGJDxc5NNPRUDko4+a1PYyfv97kTlzGrbv9u3atiuv1J+bN1fe3revyJQpNe9/4IBIWJhI584iS5aIPPWUyK23ilxwgci8efWz5b33tA0HDlTfdsklIqNG1b7/8OEikyY53vaPf+hj5+XVz6aqpKfXnaZTJ5Hbb6++fuBAkauvrrxuxQqRt99uuD2lpSIbNujPmti0SZf9yy+rb1uzRm9bs6bu/b/4wvH24GCR3/62/HdBgciHH4qcOeNcGWri6FERPz99/dls+l7r0UNkwIDay3vggEjbttrmPn1ETp/W6599Vq/LzKy+z5gxIuPHi3zwgU7z3Xe122a1igwdqtPal4gIkY4dy3+3b6+vA0fX3A8/6DSPPOLs2WgQwDZxoo51aQUOTAYOAXHA3FrSTQcEGF7XMV0pCiIiW7fGys6dl9Zvp8WL9am8/XZ9wVYlMVHEYhF57DF9AXXrJnLhhU1jsKN8LBb9vb4895wux759Wugef7x8W0aG3vbMM7UfY8cOXTHYb4bISC0SbdqI5OQ4b8vTT+v98/Orb7v3XpF27Wred9cukYAAkXvucbx9yRJ97F9+cd6eithsIk88oY+xeHHN6QoLdZonn6y+7ZprRPr3L/+dmKjPEYh8/HHDbJo9W+9/880iJSWO0y1dqtP8/HP1bUeP6m21CdP77+s0+/c73j54cHnDISdH5OKLdfrLLtMC0RBsNpHJk/V/WvG6tpflvfcc75eaqu+18HCRd94R8fTUxyktFZk1SyQqyvF+s2eLhIaKTJwoEh1duRFYE8nJWij37i2v+G02kcOHRRYtErnlFn1fTp1aWcRKSkQGDdL3SGMbKXXgdlEAPIB4oBvgDewG+jlIFwhsADY3B1E4dOh+Wb/eX6zWGm6qmvjrX/Xp/Mtfqm979NHKFfX8+Trtzp2NtrcSjzxSLgoNaXVcdll5RXXRRfoGt/PVV861mkT0zbhnT3mFvmGD3veDD5y35a67dGvLES++qI/nqKX+zjsivr66he6o4hMRWb1a779unfP22LHZ9P8JuuLw9dUi5IhDh3S6JUuqb3voIS0C9kbEjBn6WMOGifj76/NXH+w2jR+vP2+80bEw2IU/O7v6tpISXXH+4Q/aS5w/X2TaNO2VXXKJ9mwGD9b711TBT5umr6G0NO2teXiUi9XVV9fuTTvCZhNZuFDv/89/Vt5mtYrExuqKu6io8raCAu2h+vpq70ZE5F//0sf5wx90OSZPdpznq6+WN2rq6+HWxmuv6WP+7nfl6/75T71u2bKmy6cGmoMojAFWVfj9KPCog3SvAFOAdc1BFE6e/EjWrkVycrbXb0ebTeTOO/Upffnl8vWFhbqlcs015esyMnSFcPfdTWO0iHbP27UTmT5d5Lrr9Pf6uOwFBfoGsl+wL7ygy2IXsscf1zd4bm79bbNatccwdarz+1xyicjo0Y63ff65tu2NN0SOHNHHLyzUHgSITJggcvJkzcfev7/+IiWi/+M//Unve889IidOaPHp0aM8LFGRVat02g0bqm97/XW97cSJcpF66imRlBQthj17imRlOWeXvZFx773axuef179vuKF6JXz//TqcUhPdu5dXiKDLdtllImPH6oq0Rw99jdXEnDn62u7bV19P9jDTG2+U21RbuMdOerrISy+J9Oun9xszxvF+X3+tt7/4og4FZWbq83bjjXr9//1f5fS//a1er5TIww87zvu778rLf+RI3bbWhzlzygXu+HGRoCCRyy93HGFoYpqDKFwPLKrw+1fA61XSDAWWn/3eLEShoOCYrF2LJCX9s+7EVSkp0TcM6NaNSLm7/e23ldPedZe+eRzFNBuCvTW1fr1uAdcVBqiK/Uaw38QHDujfCxbo35dcouOmDeWhh0S8vJwvb7duIjfd5HhbUpKIj0/5jdumja5I7XHZmkIndrKzddoXXnDefptNtzBB5Ne/Lg8pfP+9Fstrr61+Y7/1lk5/7Fj1461cqbetXasr0G7dylvfP/ygW+xXX1136MIeuqxa2dqF4vrrK4fgrrpKhytq4t13dcW1bJkWrPpib/kGBlb3xOw23XabFuYDB7Q3dfCgFsY339TXyZVXinh767SjRunruKbQis1W7h1VXZ59tnr6khIdFgJdVkekpurtF19c//LXRWmp9qaU0p6Ut3fDw5j1pNmLAnrk0zogWuoQBeAeYBuwrUuXLi47aXY2buwse/fe0LCdi4pErrhC/+kffKBbOD17Vr+5d+wob+E0FptNd7gNHqy/22z6xh840PkWyGOP6crNHlaw2XSr8Ior9I3k71+5A7G+/PST1BmDt1NaqivFRx+tOU1Wlq48Fy7UnevXXivy2WfO2WKz6fI42yFfXKy9OtDnoOo5tYez5s+vvH7uXC2Ejlq4Bw/qfYYPryzGduyexOOPO/4PbTYt2BaL7lCvGj4R0S1t0J3/jz6qxWnQoOod3E3J7t3aw9teg6f91FOOK3D74uurr+UHHtDHcobUVB2aeeUV7aW//LL2EGq69jMz9fmorYEyd67Ijz86l399OXNGZMQIXd4nnnBNHg5oDqJQa/gICAbSgYSzSyFwvC5vwdWegojIvn03yY8/dhJbQ126/HwdwrBYpFo4qSIXXCASE6Mv4OXLdaW2erVz7nVF7K38f/+7fN2iReUtUWcYOVLbU5E5c3SL/Pvv9bE+/LB+dlXEZtNlvfzyutMmJur8/vWvhudXF7166dZ1XWRlaS/JfgPXVEFfd50W1UWLytPMnKnDMY4oKNANB9Ctd0fHvP12vf2SS3SHZUWbrr9eb5s8ufaQ3vr1WjAtFm2fh4cOIbkLm01fk0uX6uvpgw+0N71mjRYtZzp1WwKnTul6wdFAChfRHETBEzgCxFToaO5fS/pmET4SEUlOfl3WrkXy8482/CA5ObrFFBRUc2z4k08ct5YcxYJrY9o03elZ8QLLz9frrr22fJ3NpgXob3+rLDxZWbrSqNpJbo91T5qkPxMSnLfJEY8+qiul1NTa061fLw5Dbk3JJZdoW1pTlewAABgASURBVHr0ELn0Ut0f9OyzOm97X0x8vB7G6OWlO7Br4/Tp8jDGxIl631Gj9LFrIipKi25cnOPtVqsOQQUF6Rb03/+uvaPoaO1JPf+885Xo0aM6ht6pU8NGNxnOe9wuCtoGrgR+OTsK6fGz654CpjpI22xEISdnp6xdi5w8+X7jDlRUpDuTasI+ZG3PHj2CZccOPeQTdMd0YWH1fazWyq3VI0d0i9NRqMU+6unoUe0KjxlTLjwPPlh+nBUrpKw/oqr9QUF6W6dOje8M27VLH+vNNyuvf/ddPYokJkZ3ytv7Cyq2jpuarVt1p/HMmbrytvdJgK5whw/XYZeQEOdHKVmtumyBgXpMva9v7YMJXn65sndXEykp2hOx29e1a/mIGoPBSZqFKLhiOReiYLOVyoYNgXLo0K9dnpdD7PHkyZPLW//79mm3PzBQjx4ZO1aPgLniCt3iTUqqfpxjx/S2mBh9vI4ddSVkHwFh72i9/35diTmKS8+YIWUdlo3FZtMt7wkTytfZR6UMGaLHcv/617pFu2DBORmRUYm0NB3bf/RRbeOFF+rYf305dkyP1a9vZ3ZdfPaZ7ohtqsEJhlaFEYVGsmvXJNmyZeA5ycshixZpD2DsWF1BgR6pMGuWrjjHjdPDTkGvq4lbbtEV/rx55SM4rFYdorIPy+zdW4uLI959V6d76aWmKde8ebpcKSnlHbRXX+3YKzqfsdl05/o5jBkbDLVhRKGRHD36pKxdq6S42Mmx4q7g/fd1S79rVx3vrhqLt9n0eHxHLXw7RUWOOyILCvQDal5eUusoqJwckTvu0E9sNgX2oa6jRpV7ILXZbzAYmgRnRUHptOcPw4cPl23btrk8n6ys79i9+1IGDvya0NDJLs+vRk6d0jOReng0/bGzsmDcOD1N8K5desrec0FsLOzeracHfuedyjOIGgwGl6CU2i4iw+tKZ+7GGggKGoVSnmRmfuNeUejQwXXHDgnRs5v++CMMGuS6fKry4ov63Qt/+pNrxM5gMDQY4ynUwv79N5OR8RVjxiTj6VnD1LkGg8FwHuCsp2Dep1ALUVFzsFpzOHnyP+42xWAwGM4JRhRqIShoJEFBY0hOfhURq7vNMRgMBpdjRKEOoqLmUFgYT0bGV+42xWAwGFyOEYU6CAu7Dh+fziQnv+JuUwwGg8HlGFGoA4vFk8jIBzh9ei25ubvcbY7BYDC4FCMKTtCx491YLH6kpPzT3aYYDAaDSzGi4AReXiFERNzOqVMfUlx8yt3mGAwGg8swouAkUVG/Q6SYlJQ33G2KwWAwuAwjCk7i59eLsLDpJCW9RFHRcXebYzAYDC7BiEI96N79OURKOHr0cXebYjAYDC7BiEI9aNOmO1FRv+PkySXk5m53tzkGg8HQ5BhRqCdduz6Ol1cYcXG/53ybN8pgMBjqwohCPfH0DCYm5mmys78nPf1Td5tjMBgMTYoRhQYQEXEX/v4DiY9/GKu10N3mGAwGQ5PhUlFQSk1WSh1SSsUppeY62P6QUmq/UupnpdQapVRXV9rTVFgsnnTv/hKFhUdJTn7J3eYYDAZDk+EyUVBKeQBvAFcA/YCblFL9qiTbCQwXkUHAMuB5V9nT1LRrN5Hw8Os5evQJTp1a6m5zDAaDoUlwpacwEogTkSMiUgwsBa6pmEBE1opI/tmfm4EoF9rT5PTps4Tg4HEcPPgr0tM/d7c5BoPB0GhcKQqRQFKF38ln19XEXcDXLrSnyfHw8GPgwC8JCBjKvn0zyMxc7W6TDAaDoVE0i45mpdQtwHDghRq236OU2qaU2paWlnZujasDT89ABg36Gj+/Puzdew2nT//gbpMMBoOhwbhSFFKAzhV+R51dVwml1ETgcWCqiBQ5OpCILBSR4SIyPDw83CXGNgYvr3YMHvwtPj6d2bNnCnl5P7vbJIPBYGgQrhSFrUBPpVSMUsobuBGoFHhXSg0B/oUWhFQX2uJyvL07MHjwt3h4BPLzz1dQWJjobpMMBoOh3rhMFESkFPgtsAo4AHwiIvuUUk8ppaaeTfYCEAD8n1Jql1LqvO6t9fXtwqBBX2O1nuHnnydTUpLhbpMMBoOhXqjzbaqG4cOHy7Zt29xtRq2cPr2e3bsvJzBwKIMHr8bDw8/dJhkMhlaOUmq7iAyvK12z6GhuabRtO55+/T4gJ2cz+/bdgNWaX/dOBoPB0AwwouAiwsOn06vXm2RmrmTXrvHmHQwGg+G8wIiCC+nU6V4GDPiMM2cOsH37SHJzd7jbJIPBYKgVIwouJixsKkOH/ohSFnbuHEdamplZ1WAwNF+MKJwDAgIGM3ToFgICBrFv33T277+FoqKT7jbLYDAYqmFE4Rzh4xPB4MFr6dr1z6Sl/R9btvQmOfl1RKzuNs1gMBjKMKJwDvHw8CUm5ilGjNhDUNBI4uIeYPv2kWRmfmve4mYwGJoFRhTcgJ9fLwYN+pZ+/ZZSUpLGzz9fzq5dF5GVtdbdphkMhlaOEQU3oZSiffuZjBp1mJ4936Cg4Ai7d1/Crl2XkJPzk7vNMxgMrRQjCm7GYvEhMvI3jBoVR48er3DmzD527BjNvn0zKSg44m7zDAZDK8PT3QYYNB4ebYiK+h0REXeSlPQCSUkvkp6+gsjI+2nb9hK8vMLw8grFyysMT88QlFLuNtlgMLRAzNxHzZSiouMkJPyVEycWA7ZK27y9OxEcfCHBwWMJDr4Qf/9BWCxG3w0GQ804O/eREYVmTlHRSYr+v707D5KzrvM4/v72PX1MT89kjkwmgQCRsyAIIhBkQQ4DxepaBQIiRam7uCVu6d6yh7u6W+XuH6trlZarsnisCJSuKLKyLNeGjSVnSJAkJIISMsmkJzOZ6Zk+ps/v/vH80nYmk2SISfoJ831VPZV+jjzz6X5m+vs8v+f4lbdTrY5RrY5TrWaZnl5HLreWcvkNAAKBOKnUO+jsvJB0+iLS6UsIh3vanNwY4yfzLQq2e+lz0egA0ejAnPNmZt4gl1vL1NTTTE09zfDwF9i+vYpIiEzmavr6bmbRovcRCqWOcWpjzPHKisJxLBZbRiz2Qfr7PwhAvT5DPr+OsbEfMzp6H6+8ciuBQIyurstJJM4mkTiLROIs4vHTCAZjbU5vjPEjKwpvIcFgjHT6YtLpiznppM8zNfVzstl7yeWeYmLiMVSrAIhESacvJpO5gq6uK0ilzrdzEsYYwM4pLBiNRpVSaSuFwstMTT3LxMTjFAobAAgGO0mnL6Gr63fo6rqMROIs8vmXyOXWksutpVjcyKJF72fp0j8jEulr8zsxxhwOO9FsDqlS2c3k5JNMTDxBLreGYvGV/Zbp6FhBLLaciYnHCARiLFnycZYu/fM5i0Op9GsmJh5jcvJJQEgkznTDWcRiyxGx22KMaRcrCuZNK5d3kcs9RaGwkWTybDo7VzVPcheLW9i27R/JZr9HIBClo+NkgsEUwWAnwWCcfH4DMzPezXaRyGJEIpTL25rrDgZTpFLnk0pdQGfnBSSTbycWW3bEC0W1OsnY2AOMjT1AKJQhk3k3XV2XE4sta87P59cxPf0CqnWSyXNIJs894Ml8Y94qrCiYo6JY3MqOHV+mXN5BvT5FrTZFvT5NR8cKMpkryWSuJB4/DRGhVpuiUNhEofAy+fyLTE8/Sz6/oXluIxCI0dGxgnj8VMLhfmq1PVSru6lWx6jVcogEEQkhEiIQiBGPn+G+xFeSSJxJo1F2l+qOUS7vYGzsx+zZ8zCqFaLRE2g0ClSrYwDEYicjIpRKr875vsLhftLpixkY+DDd3dfsc46lWh0nm72XfP4FuruvoafndwkGO5rzG40audwaJiaeoLPzQrq7VxMIhOf9maoqU1PPsGvXt1CtMDDwEdLpVUfkBkXVxjE9QlNVKpURt8OQPKz3UC7vIBCIEw5njkLChcsXRUFEVgNfAoLAXar6T7PmR4HvAOcB48CNqvr6wdZpReH45l0htZ5C4SWKxa2USlsoFrdQre52d20vcndtd6HaQLWGao16fZpCYSOVyoG7NY1EFtPXdyN9fTeTSr0DUAqFjUxOPsHk5P8CAVKp80ilziOZPA+REIXCS+Tz68nnX2R8/GGq1SyRyCADAx8mmTyH0dH7GB//CapVgsEU9fo0wWCK3t7ryWSuYnJyDWNjP6Ra3d3MEQ7309//IQYGbiMaXUK9XqBeL9BoFFGtuy9p78tyYuIJdu26m2JxM4FAHJEQ9foU8fiZDA5+jEzmCsrlnZTL25iZ2UajMePuR3kXkUjvnJ9Do1FmbOwnZLPfYc+eh0kkznGfyweIxU6Yc/lcbi179jzCxMSj7pLmK8lkriKdXkUgEAVAtU61Og4EiEQWzVpHhdHR+xke/iL5/IuAd0FDOLyIaHQx3d3X0t9/C/H42w64/YrFV9m27bNks/cQCMQZHLydoaE/IRYbai6jWief30CjUSKZPK/tV9E1GmWKxa0Ui5upVvcQCMSaQyTS7y7imP8OwlxUlVzuKXbu/AY9PdfR33/TYa2n7UVBRILAVuAqYBh4DrhZVTe1LPNx4GxV/UMRuQl4v6reeLD1WlFY2CqVUfL5DRSLmwkGE66A9BCJ9NLRcQrer93haTSqjI//FyMjd7Fnz8NAg3C4j/7+WxgYuI1E4iwmJ9eQzX6X3bt/QL0+TSCQoKfnOvr6biCTuZLJyTXs2vVNxscfQrU2r5/b2Xkxixd/hN7eDyASYHT0Pnbu/BrT08/NWjKASAjVCgDx+OmkUu8gGEw0j6hqtUnGxn5ErTZBJDLIokXvY3r6Baann3U/60IikUEajTKNxgyNRol8fj2NRhGRMOn0KlRrTE09jWqNQKCDaHSpO3qbALzvi2h0iGTSK7AAO3d+lUplhHj8dAYGPgKoO4rbTan0Grnc/wFKKnU+fX0309HxNkKhTkKhNCDs2PFlRkbuJhCIsGTJHVQqWbLZ7yESoL//Q3R0vI1c7ilyuZ9Rr08BIBKhs/MC0ul3kUichWod1SqNRgURIRzuJRLpJxzuJxzuQbVGo1FGtUKjUaJS2UW5PEKlspNKZYRKZZRqdZRKxTtaDYd73JHsCjo6VqDaoFLZQbk8TLk8TKn0qns+2b5PHGgVDKbJZK6ku3s1XV2XEQ73EAymDnm1n/ezsmSz9zAy8g1Kpa0Eg2mWL/8Hhob+aF6/V7P5oShcBPy9qr7Hjd8JoKqfb1nmEbfMz0UkBOwCevUgoawomGNhZmY7pdJrbk95/z29er1EPv8iyeRKgsH4fvMrld2MjT1AvV4kGEw0B++gWYEGqko8fhqJxGlzZpieXkehsIlYbCnR6DKi0SFAmZ5+gVzuKSYnnyKfX49qxX0h1hAJ0t19LQMDt5HJXNEskqXSrxgdvb+ZKRCIuj3aKPH4GXR3v4eurssJhZIA1GrTTE6uYWLiUSqVXe4IrpdweBGqZaanvfMypdJWQMlkrmZo6I/p7r56zuaqcnkno6P3kc3eQz6/f1/lImEGBz/GsmV/RTS62G2DbWzf/i+MjNxFo1EiHj+Drq5LSacvJRiMk8utdZ/BunkX4AMJBBKugPQSifQRDvdQqeymVPolMzO/alm/EIn0E40OEYudSDx+enOIRPpdsS3RaMxQKr3GxMQjjI8/TKWyY9b7jRIMJgkEIoiE3RB0R5Vek+xenZ2rGBz8A3p7b5jzd22+/FAUrgdWq+rvu/FbgXeq6idalnnZLTPsxl9zy4wdaL1WFIzxj1ptmlott08Tz6HMzLxBpZJtOSeVp6vr0jmbtsC7OEC1esDmsnq9wMzMGy1fsBGg4fb8s1QqWarVPe7cVJRAIEIgECMc7icaXUwkMnjQu/4bjRrl8jZEwkQii990c5CqUixuYmrqmeY5OG/IN49sVKuo1gkGk4RCnQSD3lFUd/d7SCTOfFM/70DeUo+5EJHbgdsBli1b1uY0xpi9QqHUm36Mincn/vz/jsPhroPODwYTJBKn7zc9Gh18U7kOJBAI0dFx8mH/f5HfXJ59PDialyXsAJa2jA+5aXMu45qP0ngnnPehql9X1fNV9fze3rn3Fowxxvz2jmZReA5YISLLxTueuwl4cNYyDwK3udfXA08c7HyCMcaYo+uoNR+pak1EPgE8gnd27W5V3SginwOeV9UHgX8H/kNEXgX24BUOY4wxbXJUzymo6k+Bn86a9pmW1zPADUczgzHGmPmzh9EYY4xpsqJgjDGmyYqCMcaYJisKxhhjmo67p6SKyG5g2yEXnNsi4IB3S/vI8ZDTMh4ZlvHIsIyHdoKqHvJGr+OuKPw2ROT5+dzm3W7HQ07LeGRYxiPDMh451nxkjDGmyYqCMcaYpoVWFL7e7gDzdDzktIxHhmU8MizjEbKgzikYY4w5uIV2pGCMMeYgFkxREJHVIrJFRF4VkU+3Ow+AiNwtIqOus6G907pF5FER+aX7t629l4vIUhF5UkQ2ichGEfmk33KKSExEnhWRDS7jZ9305SLyjNvm97un9baViARF5EURecjHGV8XkV+IyHoRed5N8832dnm6ROQHIvKKiGwWkYv8lFFETnWf395hSkQ+5aeMB7IgioLrL/orwDXAGcDNInJGe1MB8C1g9axpnwYeV9UVwONuvJ1qwJ+q6hnAhcAd7rPzU84y8G5VPQdYCawWkQuBfwa+qKqnABPAR9uYca9PAptbxv2YEeByVV3Zcgmln7Y3wJeA/1bV04Bz8D5T32RU1S3u81sJnAcUgQf8lPGAVPUtPwAXAY+0jN8J3NnuXC7LicDLLeNbgMXu9WJgS7szzsr7Y+Aqv+YE4sA64J14NwqF5vodaFO2IbwvgncDDwHit4wux+vAolnTfLO98Trj+jXunKgfM87KdTXwMz9nbB0WxJECsATY3jI+7Kb5Ub+qjrjXu4D+doZpJSInAucCz+CznK5ZZj0wCjwKvAZM6m96XPfDNv9X4C+AhhvvwX8ZART4HxF5wXWFC/7a3suB3cA3XVPcXSKSwF8ZW90E3Ote+zVj00IpCscl9XYnfHF5mIgkgf8EPqWqU63z/JBTVevqHaoPARcAp7Uzz2wich0wqqovtDvLPFyiqm/Ha269Q0QubZ3pg+0dAt4OfFVVzwUKzGqG8UFGANw5ovcC3589zy8ZZ1soRWE+/UX7RVZEFgO4f0fbnAcRCeMVhHtU9Ydusu9yAqjqJPAkXlNMl+v7G9q/zVcB7xWR14H78JqQvoS/MgKgqjvcv6N47eAX4K/tPQwMq+ozbvwHeEXCTxn3ugZYp6pZN+7HjPtYKEVhPv1F+0Vrv9W34bXht42ICF63qZtV9Qsts3yTU0R6RaTLve7AO+exGa84XO8Wa2tGVb1TVYdU9US8378nVPUWfJQRQEQSIpLa+xqvPfxlfLS9VXUXsF1ETnWTrgA24aOMLW7mN01H4M+M+2r3SY1jNQDXAlvx2pr/ut15XKZ7gRGgirf381G8dubHgV8CjwHdbc54Cd4h7kvAejdc66ecwNnAiy7jy8Bn3PSTgGeBV/EO36Pt3uYu12XAQ37M6PJscMPGvX8rftreLs9K4Hm3zX8EZHyYMQGMA+mWab7KONdgdzQbY4xpWijNR8YYY+bBioIxxpgmKwrGGGOarCgYY4xpsqJgjDGmyYqCMceQiFy29wmpxviRFQVjjDFNVhSMmYOIfMj10bBeRL7mHriXF5Evuj4bHheRXrfsShF5WkReEpEH9j4jX0ROEZHHXD8P60TkZLf6ZEtfAPe4u8aN8QUrCsbMIiKnAzcCq9R7yF4duAXvDtXnVfVMYA3wd+6/fAf4S1U9G/hFy/R7gK+o18/DxXh3r4P3pNlP4fXtcRLec5GM8YXQoRcxZsG5Aq9jlOfcTnwH3oPLGsD9bpnvAj8UkTTQpapr3PRvA993zw9aoqoPAKjqDIBb37OqOuzG1+P1qbH26L8tYw7NioIx+xPg26p65z4TRf521nKH+4yYcsvrOvZ3aHzEmo+M2d/jwPUi0gfN/olPwPt72ftE0w8Ca1U1B0yIyLvc9FuBNao6DQyLyO+5dURFJH5M34Uxh8H2UIyZRVU3icjf4PU+FsB7iu0deJ25XODmjeKddwDvEcj/5r70fwV82E2/FfiaiHzOreOGY/g2jDks9pRUY+ZJRPKqmmx3DmOOJms+MsYY02RHCsYYY5rsSMEYY0yTFQVjjDFNVhSMMcY0WVEwxhjTZEXBGGNMkxUFY4wxTf8PgQGx3cXDurUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 399us/sample - loss: 0.4188 - acc: 0.8957\n",
      "Loss: 0.41879333938517427 Accuracy: 0.8957425\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6059 - acc: 0.5083\n",
      "Epoch 00001: val_loss improved from inf to 1.03461, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/001-1.0346.hdf5\n",
      "36805/36805 [==============================] - 36s 985us/sample - loss: 1.6058 - acc: 0.5083 - val_loss: 1.0346 - val_acc: 0.6937\n",
      "Epoch 2/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.8128 - acc: 0.7598\n",
      "Epoch 00002: val_loss improved from 1.03461 to 0.61051, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/002-0.6105.hdf5\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.8129 - acc: 0.7598 - val_loss: 0.6105 - val_acc: 0.8332\n",
      "Epoch 3/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.5481 - acc: 0.8389\n",
      "Epoch 00003: val_loss improved from 0.61051 to 0.48234, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/003-0.4823.hdf5\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.5485 - acc: 0.8388 - val_loss: 0.4823 - val_acc: 0.8572\n",
      "Epoch 4/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.4159 - acc: 0.8781\n",
      "Epoch 00004: val_loss improved from 0.48234 to 0.41407, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/004-0.4141.hdf5\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.4158 - acc: 0.8781 - val_loss: 0.4141 - val_acc: 0.8873\n",
      "Epoch 5/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.3373 - acc: 0.9008\n",
      "Epoch 00005: val_loss improved from 0.41407 to 0.35668, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/005-0.3567.hdf5\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.3374 - acc: 0.9008 - val_loss: 0.3567 - val_acc: 0.8984\n",
      "Epoch 6/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2853 - acc: 0.9190\n",
      "Epoch 00006: val_loss improved from 0.35668 to 0.34582, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/006-0.3458.hdf5\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.2852 - acc: 0.9191 - val_loss: 0.3458 - val_acc: 0.8987\n",
      "Epoch 7/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2461 - acc: 0.9285\n",
      "Epoch 00007: val_loss improved from 0.34582 to 0.30369, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/007-0.3037.hdf5\n",
      "36805/36805 [==============================] - 29s 793us/sample - loss: 0.2461 - acc: 0.9285 - val_loss: 0.3037 - val_acc: 0.9115\n",
      "Epoch 8/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9408\n",
      "Epoch 00008: val_loss did not improve from 0.30369\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.2076 - acc: 0.9408 - val_loss: 0.3180 - val_acc: 0.9110\n",
      "Epoch 9/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1871 - acc: 0.9469\n",
      "Epoch 00009: val_loss improved from 0.30369 to 0.28578, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/009-0.2858.hdf5\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.1871 - acc: 0.9469 - val_loss: 0.2858 - val_acc: 0.9224\n",
      "Epoch 10/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1687 - acc: 0.9527\n",
      "Epoch 00010: val_loss improved from 0.28578 to 0.24700, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/010-0.2470.hdf5\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.1686 - acc: 0.9528 - val_loss: 0.2470 - val_acc: 0.9294\n",
      "Epoch 11/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1476 - acc: 0.9593\n",
      "Epoch 00011: val_loss did not improve from 0.24700\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.1478 - acc: 0.9592 - val_loss: 0.2628 - val_acc: 0.9280\n",
      "Epoch 12/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9647\n",
      "Epoch 00012: val_loss did not improve from 0.24700\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.1309 - acc: 0.9647 - val_loss: 0.2513 - val_acc: 0.9250\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9688\n",
      "Epoch 00013: val_loss improved from 0.24700 to 0.23834, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/013-0.2383.hdf5\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.1187 - acc: 0.9688 - val_loss: 0.2383 - val_acc: 0.9311\n",
      "Epoch 14/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9720\n",
      "Epoch 00014: val_loss improved from 0.23834 to 0.22702, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/014-0.2270.hdf5\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.1064 - acc: 0.9720 - val_loss: 0.2270 - val_acc: 0.9350\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0957 - acc: 0.9754\n",
      "Epoch 00015: val_loss did not improve from 0.22702\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.0958 - acc: 0.9753 - val_loss: 0.2315 - val_acc: 0.9369\n",
      "Epoch 16/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0958 - acc: 0.9751\n",
      "Epoch 00016: val_loss did not improve from 0.22702\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.0957 - acc: 0.9751 - val_loss: 0.2506 - val_acc: 0.9271\n",
      "Epoch 17/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9806\n",
      "Epoch 00017: val_loss did not improve from 0.22702\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.0788 - acc: 0.9805 - val_loss: 0.2431 - val_acc: 0.9306\n",
      "Epoch 18/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9795\n",
      "Epoch 00018: val_loss did not improve from 0.22702\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.0806 - acc: 0.9794 - val_loss: 0.2314 - val_acc: 0.9422\n",
      "Epoch 19/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0749 - acc: 0.9810\n",
      "Epoch 00019: val_loss did not improve from 0.22702\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.0749 - acc: 0.9810 - val_loss: 0.3462 - val_acc: 0.9010\n",
      "Epoch 20/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9846\n",
      "Epoch 00020: val_loss improved from 0.22702 to 0.22256, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/020-0.2226.hdf5\n",
      "36805/36805 [==============================] - 29s 792us/sample - loss: 0.0656 - acc: 0.9846 - val_loss: 0.2226 - val_acc: 0.9385\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9870\n",
      "Epoch 00021: val_loss improved from 0.22256 to 0.21109, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/021-0.2111.hdf5\n",
      "36805/36805 [==============================] - 29s 790us/sample - loss: 0.0552 - acc: 0.9870 - val_loss: 0.2111 - val_acc: 0.9415\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9883\n",
      "Epoch 00022: val_loss did not improve from 0.21109\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0516 - acc: 0.9883 - val_loss: 0.2147 - val_acc: 0.9439\n",
      "Epoch 23/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9879\n",
      "Epoch 00023: val_loss did not improve from 0.21109\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0516 - acc: 0.9879 - val_loss: 0.2520 - val_acc: 0.9283\n",
      "Epoch 24/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0442 - acc: 0.9900\n",
      "Epoch 00024: val_loss did not improve from 0.21109\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0443 - acc: 0.9899 - val_loss: 0.2126 - val_acc: 0.9436\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9874\n",
      "Epoch 00025: val_loss did not improve from 0.21109\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0519 - acc: 0.9873 - val_loss: 0.2541 - val_acc: 0.9327\n",
      "Epoch 26/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0516 - acc: 0.9876\n",
      "Epoch 00026: val_loss did not improve from 0.21109\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.0518 - acc: 0.9875 - val_loss: 0.2408 - val_acc: 0.9355\n",
      "Epoch 27/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0473 - acc: 0.9892\n",
      "Epoch 00027: val_loss did not improve from 0.21109\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0475 - acc: 0.9892 - val_loss: 0.2589 - val_acc: 0.9338\n",
      "Epoch 28/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9911\n",
      "Epoch 00028: val_loss did not improve from 0.21109\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0394 - acc: 0.9911 - val_loss: 0.2114 - val_acc: 0.9443\n",
      "Epoch 29/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9921\n",
      "Epoch 00029: val_loss did not improve from 0.21109\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.0338 - acc: 0.9920 - val_loss: 0.2145 - val_acc: 0.9415\n",
      "Epoch 30/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9883\n",
      "Epoch 00030: val_loss did not improve from 0.21109\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.0471 - acc: 0.9884 - val_loss: 0.2255 - val_acc: 0.9387\n",
      "Epoch 31/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9934\n",
      "Epoch 00031: val_loss improved from 0.21109 to 0.20000, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_4_conv_BN_checkpoint/031-0.2000.hdf5\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.0313 - acc: 0.9934 - val_loss: 0.2000 - val_acc: 0.9469\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9943\n",
      "Epoch 00032: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.0272 - acc: 0.9942 - val_loss: 0.2356 - val_acc: 0.9394\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9861\n",
      "Epoch 00033: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0510 - acc: 0.9861 - val_loss: 0.2164 - val_acc: 0.9443\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9944\n",
      "Epoch 00034: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0259 - acc: 0.9943 - val_loss: 0.2238 - val_acc: 0.9432\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0306 - acc: 0.9930\n",
      "Epoch 00035: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.0306 - acc: 0.9930 - val_loss: 0.2347 - val_acc: 0.9425\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9941\n",
      "Epoch 00036: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.0273 - acc: 0.9940 - val_loss: 0.2842 - val_acc: 0.9290\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9912\n",
      "Epoch 00037: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0357 - acc: 0.9912 - val_loss: 0.2200 - val_acc: 0.9462\n",
      "Epoch 38/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0207 - acc: 0.9958\n",
      "Epoch 00038: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 788us/sample - loss: 0.0208 - acc: 0.9958 - val_loss: 0.2208 - val_acc: 0.9450\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0319 - acc: 0.9923\n",
      "Epoch 00039: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 780us/sample - loss: 0.0319 - acc: 0.9923 - val_loss: 0.2093 - val_acc: 0.9462\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0229 - acc: 0.9954\n",
      "Epoch 00040: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0229 - acc: 0.9954 - val_loss: 0.2154 - val_acc: 0.9476\n",
      "Epoch 41/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0196 - acc: 0.9959\n",
      "Epoch 00041: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0195 - acc: 0.9959 - val_loss: 0.2078 - val_acc: 0.9460\n",
      "Epoch 42/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9959\n",
      "Epoch 00042: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0191 - acc: 0.9958 - val_loss: 0.2535 - val_acc: 0.9380\n",
      "Epoch 43/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0355 - acc: 0.9908\n",
      "Epoch 00043: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0355 - acc: 0.9908 - val_loss: 0.2532 - val_acc: 0.9378\n",
      "Epoch 44/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9971\n",
      "Epoch 00044: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.0157 - acc: 0.9971 - val_loss: 0.2167 - val_acc: 0.9450\n",
      "Epoch 45/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9964\n",
      "Epoch 00045: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 781us/sample - loss: 0.0172 - acc: 0.9964 - val_loss: 0.2494 - val_acc: 0.9394\n",
      "Epoch 46/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9969\n",
      "Epoch 00046: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0161 - acc: 0.9968 - val_loss: 0.2817 - val_acc: 0.9350\n",
      "Epoch 47/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0347 - acc: 0.9910\n",
      "Epoch 00047: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0347 - acc: 0.9910 - val_loss: 0.2421 - val_acc: 0.9401\n",
      "Epoch 48/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0143 - acc: 0.9974\n",
      "Epoch 00048: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0144 - acc: 0.9974 - val_loss: 0.2881 - val_acc: 0.9311\n",
      "Epoch 49/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0266 - acc: 0.9933\n",
      "Epoch 00049: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.0266 - acc: 0.9933 - val_loss: 0.2249 - val_acc: 0.9469\n",
      "Epoch 50/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0135 - acc: 0.9976\n",
      "Epoch 00050: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 789us/sample - loss: 0.0135 - acc: 0.9975 - val_loss: 0.2759 - val_acc: 0.9383\n",
      "Epoch 51/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9948\n",
      "Epoch 00051: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0222 - acc: 0.9948 - val_loss: 0.2467 - val_acc: 0.9455\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9957\n",
      "Epoch 00052: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.0191 - acc: 0.9956 - val_loss: 0.2711 - val_acc: 0.9345\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9950\n",
      "Epoch 00053: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.0214 - acc: 0.9949 - val_loss: 0.2702 - val_acc: 0.9352\n",
      "Epoch 54/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0234 - acc: 0.9944\n",
      "Epoch 00054: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.0234 - acc: 0.9944 - val_loss: 0.2336 - val_acc: 0.9427\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0113 - acc: 0.9980\n",
      "Epoch 00055: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0113 - acc: 0.9979 - val_loss: 0.2325 - val_acc: 0.9422\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0174 - acc: 0.9960\n",
      "Epoch 00056: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0174 - acc: 0.9960 - val_loss: 0.2245 - val_acc: 0.9453\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0123 - acc: 0.9974\n",
      "Epoch 00057: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0124 - acc: 0.9973 - val_loss: 0.2454 - val_acc: 0.9411\n",
      "Epoch 58/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0272 - acc: 0.9930\n",
      "Epoch 00058: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0273 - acc: 0.9930 - val_loss: 0.2418 - val_acc: 0.9460\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0152 - acc: 0.9967\n",
      "Epoch 00059: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0153 - acc: 0.9967 - val_loss: 0.2168 - val_acc: 0.9460\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0217 - acc: 0.9947\n",
      "Epoch 00060: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0218 - acc: 0.9947 - val_loss: 0.2277 - val_acc: 0.9450\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0169 - acc: 0.9959\n",
      "Epoch 00061: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 785us/sample - loss: 0.0170 - acc: 0.9958 - val_loss: 0.2450 - val_acc: 0.9453\n",
      "Epoch 62/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0213 - acc: 0.9946\n",
      "Epoch 00062: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 787us/sample - loss: 0.0213 - acc: 0.9946 - val_loss: 0.2186 - val_acc: 0.9492\n",
      "Epoch 63/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9978\n",
      "Epoch 00063: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0103 - acc: 0.9978 - val_loss: 0.2404 - val_acc: 0.9457\n",
      "Epoch 64/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0088 - acc: 0.9984\n",
      "Epoch 00064: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0088 - acc: 0.9984 - val_loss: 0.2254 - val_acc: 0.9483\n",
      "Epoch 65/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9982\n",
      "Epoch 00065: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0089 - acc: 0.9982 - val_loss: 0.2618 - val_acc: 0.9418\n",
      "Epoch 66/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0165 - acc: 0.9959\n",
      "Epoch 00066: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0165 - acc: 0.9959 - val_loss: 0.2428 - val_acc: 0.9432\n",
      "Epoch 67/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9983\n",
      "Epoch 00067: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0089 - acc: 0.9983 - val_loss: 0.2476 - val_acc: 0.9422\n",
      "Epoch 68/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9949\n",
      "Epoch 00068: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0187 - acc: 0.9949 - val_loss: 0.2374 - val_acc: 0.9429\n",
      "Epoch 69/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9979\n",
      "Epoch 00069: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0095 - acc: 0.9979 - val_loss: 0.2509 - val_acc: 0.9469\n",
      "Epoch 70/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0090 - acc: 0.9983\n",
      "Epoch 00070: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0091 - acc: 0.9983 - val_loss: 0.2734 - val_acc: 0.9315\n",
      "Epoch 71/500\n",
      "36736/36805 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9940\n",
      "Epoch 00071: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0220 - acc: 0.9940 - val_loss: 0.2203 - val_acc: 0.9457\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0089 - acc: 0.9983\n",
      "Epoch 00072: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0090 - acc: 0.9983 - val_loss: 0.2642 - val_acc: 0.9366\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9960\n",
      "Epoch 00073: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0170 - acc: 0.9960 - val_loss: 0.2333 - val_acc: 0.9401\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0083 - acc: 0.9984\n",
      "Epoch 00074: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 786us/sample - loss: 0.0083 - acc: 0.9984 - val_loss: 0.2354 - val_acc: 0.9443\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9982\n",
      "Epoch 00075: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0087 - acc: 0.9982 - val_loss: 0.2513 - val_acc: 0.9411\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9941\n",
      "Epoch 00076: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0227 - acc: 0.9941 - val_loss: 0.2295 - val_acc: 0.9467\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9985\n",
      "Epoch 00077: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 782us/sample - loss: 0.0078 - acc: 0.9985 - val_loss: 0.2534 - val_acc: 0.9418\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0175 - acc: 0.9956\n",
      "Epoch 00078: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0175 - acc: 0.9956 - val_loss: 0.2418 - val_acc: 0.9478\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0087 - acc: 0.9983\n",
      "Epoch 00079: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0087 - acc: 0.9983 - val_loss: 0.2376 - val_acc: 0.9467\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0071 - acc: 0.9987\n",
      "Epoch 00080: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 784us/sample - loss: 0.0071 - acc: 0.9987 - val_loss: 0.3143 - val_acc: 0.9387\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0072 - acc: 0.9986\n",
      "Epoch 00081: val_loss did not improve from 0.20000\n",
      "36805/36805 [==============================] - 29s 783us/sample - loss: 0.0072 - acc: 0.9986 - val_loss: 0.2401 - val_acc: 0.9453\n",
      "\n",
      "2D_CNN_only_conv_ch_32_4_conv_BN Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 410us/sample - loss: 0.2785 - acc: 0.9238\n",
      "Loss: 0.27846501246172073 Accuracy: 0.92377985\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_only_conv_ch_32_{}_conv_BN'.format(i)\n",
    "    model = build_2d_cnn_only_conv_ch_32_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_2d_norm, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_2d_norm, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "    \n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2D_CNN_only_conv_ch_32_1_conv_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 195072)            780288    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                3121168   \n",
      "=================================================================\n",
      "Total params: 3,902,416\n",
      "Trainable params: 3,512,208\n",
      "Non-trainable params: 390,208\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 371us/sample - loss: 1.7279 - acc: 0.6534\n",
      "Loss: 1.7279256380235666 Accuracy: 0.65337485\n",
      "\n",
      "2D_CNN_only_conv_ch_32_2_conv_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_32 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 43648)             174592    \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                698384    \n",
      "=================================================================\n",
      "Total params: 899,696\n",
      "Trainable params: 812,272\n",
      "Non-trainable params: 87,424\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 381us/sample - loss: 0.7404 - acc: 0.8237\n",
      "Loss: 0.7404076204988196 Accuracy: 0.823676\n",
      "\n",
      "2D_CNN_only_conv_ch_32_3_conv_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_15 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16704)             66816     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                267280    \n",
      "=================================================================\n",
      "Total params: 412,336\n",
      "Trainable params: 378,672\n",
      "Non-trainable params: 33,664\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 2s 444us/sample - loss: 0.4188 - acc: 0.8957\n",
      "Loss: 0.41879333938517427 Accuracy: 0.8957425\n",
      "\n",
      "2D_CNN_only_conv_ch_32_4_conv_BN Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 25, 5, 64)         102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 25, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 25, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 13, 3, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 2496)              9984      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                39952     \n",
      "=================================================================\n",
      "Total params: 230,896\n",
      "Trainable params: 225,520\n",
      "Non-trainable params: 5,376\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 2s 453us/sample - loss: 0.2785 - acc: 0.9238\n",
      "Loss: 0.27846501246172073 Accuracy: 0.92377985\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_only_conv_ch_32_{}_conv_BN'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_cnn_only_conv_ch_32_DO_BN(conv_num=1):\n",
    "    input_layer = Input(shape=input_shape)\n",
    "    x = input_layer\n",
    "    \n",
    "    for i in range(conv_num):\n",
    "        x = Conv2D(kernel_size=5, filters=32*(2**int((i)/2)), strides=(1,1), padding='valid')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "        x = MaxPooling2D(pool_size=2, strides=(2,2), padding='same')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "  \n",
    "    x = Dropout(0.5)(x)\n",
    "    output_layer = Dense(output_size, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_17 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 195072)            0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                3121168   \n",
      "=================================================================\n",
      "Total params: 3,122,128\n",
      "Trainable params: 3,122,064\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 43648)             0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                698384    \n",
      "=================================================================\n",
      "Total params: 725,104\n",
      "Trainable params: 724,976\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_44 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_45 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 16704)             0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 16)                267280    \n",
      "=================================================================\n",
      "Total params: 345,520\n",
      "Trainable params: 345,264\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_20 (InputLayer)        (None, 257, 99, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_46 (Conv2D)           (None, 253, 95, 32)       832       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 253, 95, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 253, 95, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 127, 48, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 123, 44, 32)       25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 123, 44, 32)       128       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 123, 44, 32)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 62, 22, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_48 (Conv2D)           (None, 58, 18, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 58, 18, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 58, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 29, 9, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 25, 5, 64)         102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 25, 5, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 25, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling (None, 13, 3, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 2496)              0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 16)                39952     \n",
      "=================================================================\n",
      "Total params: 220,912\n",
      "Trainable params: 220,528\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model = build_2d_cnn_only_conv_ch_32_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0427 - acc: 0.4815\n",
      "Epoch 00001: val_loss improved from inf to 1.86061, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_BN_checkpoint/001-1.8606.hdf5\n",
      "36805/36805 [==============================] - 28s 771us/sample - loss: 2.0427 - acc: 0.4815 - val_loss: 1.8606 - val_acc: 0.5094\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4420 - acc: 0.6149\n",
      "Epoch 00002: val_loss improved from 1.86061 to 1.39277, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_BN_checkpoint/002-1.3928.hdf5\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 1.4422 - acc: 0.6149 - val_loss: 1.3928 - val_acc: 0.6320\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1678 - acc: 0.6735\n",
      "Epoch 00003: val_loss did not improve from 1.39277\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 1.1678 - acc: 0.6735 - val_loss: 1.4067 - val_acc: 0.6518\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9897 - acc: 0.7177\n",
      "Epoch 00004: val_loss did not improve from 1.39277\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.9898 - acc: 0.7177 - val_loss: 1.4381 - val_acc: 0.6546\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8287 - acc: 0.7568\n",
      "Epoch 00005: val_loss improved from 1.39277 to 1.31105, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_BN_checkpoint/005-1.3110.hdf5\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.8287 - acc: 0.7568 - val_loss: 1.3110 - val_acc: 0.7030\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7222 - acc: 0.7831\n",
      "Epoch 00006: val_loss did not improve from 1.31105\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.7222 - acc: 0.7831 - val_loss: 1.3397 - val_acc: 0.6965\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6458 - acc: 0.8052\n",
      "Epoch 00007: val_loss did not improve from 1.31105\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.6458 - acc: 0.8052 - val_loss: 1.4419 - val_acc: 0.6827\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5841 - acc: 0.8243\n",
      "Epoch 00008: val_loss did not improve from 1.31105\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 0.5841 - acc: 0.8243 - val_loss: 1.3664 - val_acc: 0.7123\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5485 - acc: 0.8327\n",
      "Epoch 00009: val_loss improved from 1.31105 to 1.30650, saving model to model/checkpoint/2D_CNN_only_conv_ch_32_1_conv_DO_BN_checkpoint/009-1.3065.hdf5\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 0.5485 - acc: 0.8327 - val_loss: 1.3065 - val_acc: 0.7212\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5073 - acc: 0.8456\n",
      "Epoch 00010: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 0.5074 - acc: 0.8456 - val_loss: 1.3599 - val_acc: 0.7170\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4737 - acc: 0.8545\n",
      "Epoch 00011: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 0.4737 - acc: 0.8545 - val_loss: 1.4495 - val_acc: 0.7147\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4377 - acc: 0.8666\n",
      "Epoch 00012: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.4378 - acc: 0.8666 - val_loss: 1.4156 - val_acc: 0.7116\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4138 - acc: 0.8727\n",
      "Epoch 00013: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 599us/sample - loss: 0.4138 - acc: 0.8727 - val_loss: 1.4191 - val_acc: 0.7279\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3954 - acc: 0.8785\n",
      "Epoch 00014: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 0.3954 - acc: 0.8785 - val_loss: 1.4550 - val_acc: 0.7184\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3843 - acc: 0.8826\n",
      "Epoch 00015: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.3843 - acc: 0.8826 - val_loss: 1.4312 - val_acc: 0.7188\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3602 - acc: 0.8906\n",
      "Epoch 00016: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 0.3602 - acc: 0.8906 - val_loss: 1.5049 - val_acc: 0.7310\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3423 - acc: 0.8967\n",
      "Epoch 00017: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.3423 - acc: 0.8967 - val_loss: 1.6068 - val_acc: 0.7130\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3435 - acc: 0.8956\n",
      "Epoch 00018: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 602us/sample - loss: 0.3435 - acc: 0.8956 - val_loss: 1.4993 - val_acc: 0.7382\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.9008\n",
      "Epoch 00019: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.3314 - acc: 0.9008 - val_loss: 1.4634 - val_acc: 0.7431\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3192 - acc: 0.9035\n",
      "Epoch 00020: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 0.3192 - acc: 0.9035 - val_loss: 1.6094 - val_acc: 0.7186\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3056 - acc: 0.9080\n",
      "Epoch 00021: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 0.3059 - acc: 0.9080 - val_loss: 1.5391 - val_acc: 0.7393\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3071 - acc: 0.9065\n",
      "Epoch 00022: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 0.3071 - acc: 0.9065 - val_loss: 1.5856 - val_acc: 0.7230\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2863 - acc: 0.9152\n",
      "Epoch 00023: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.2863 - acc: 0.9151 - val_loss: 1.6530 - val_acc: 0.7116\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2811 - acc: 0.9166\n",
      "Epoch 00024: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 0.2811 - acc: 0.9166 - val_loss: 1.6486 - val_acc: 0.7193\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2706 - acc: 0.9184\n",
      "Epoch 00025: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 0.2706 - acc: 0.9184 - val_loss: 1.6252 - val_acc: 0.7363\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2646 - acc: 0.9216\n",
      "Epoch 00026: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 0.2645 - acc: 0.9216 - val_loss: 1.5713 - val_acc: 0.7452\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2572 - acc: 0.9238\n",
      "Epoch 00027: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 603us/sample - loss: 0.2571 - acc: 0.9238 - val_loss: 1.5918 - val_acc: 0.7393\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2463 - acc: 0.9252\n",
      "Epoch 00028: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 0.2465 - acc: 0.9252 - val_loss: 1.7267 - val_acc: 0.7223\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2575 - acc: 0.9242\n",
      "Epoch 00029: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.2575 - acc: 0.9242 - val_loss: 1.7019 - val_acc: 0.7258\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.9284\n",
      "Epoch 00030: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 601us/sample - loss: 0.2401 - acc: 0.9284 - val_loss: 1.7302 - val_acc: 0.7317\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2326 - acc: 0.9332\n",
      "Epoch 00031: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 0.2327 - acc: 0.9332 - val_loss: 1.7539 - val_acc: 0.7237\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2344 - acc: 0.9309\n",
      "Epoch 00032: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 0.2344 - acc: 0.9309 - val_loss: 1.6868 - val_acc: 0.7419\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2270 - acc: 0.9342\n",
      "Epoch 00033: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 0.2270 - acc: 0.9342 - val_loss: 1.6613 - val_acc: 0.7456\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2246 - acc: 0.9346\n",
      "Epoch 00034: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 0.2246 - acc: 0.9346 - val_loss: 1.7195 - val_acc: 0.7272\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9373\n",
      "Epoch 00035: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 600us/sample - loss: 0.2128 - acc: 0.9372 - val_loss: 1.6667 - val_acc: 0.7396\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2227 - acc: 0.9356\n",
      "Epoch 00036: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 596us/sample - loss: 0.2227 - acc: 0.9356 - val_loss: 1.6906 - val_acc: 0.7349\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9395\n",
      "Epoch 00037: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 0.2105 - acc: 0.9395 - val_loss: 1.7313 - val_acc: 0.7263\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9422\n",
      "Epoch 00038: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 0.1995 - acc: 0.9422 - val_loss: 1.6457 - val_acc: 0.7468\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1965 - acc: 0.9441\n",
      "Epoch 00039: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 598us/sample - loss: 0.1965 - acc: 0.9441 - val_loss: 1.7217 - val_acc: 0.7389\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2164 - acc: 0.9368\n",
      "Epoch 00040: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 597us/sample - loss: 0.2163 - acc: 0.9369 - val_loss: 1.7079 - val_acc: 0.7400\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1986 - acc: 0.9444\n",
      "Epoch 00041: val_loss did not improve from 1.30650\n",
      "36805/36805 [==============================] - 22s 595us/sample - loss: 0.1986 - acc: 0.9444 - val_loss: 1.7048 - val_acc: 0.7379\n",
      "Epoch 42/500\n",
      "31680/36805 [========================>.....] - ETA: 2s - loss: 0.1883 - acc: 0.9455"
     ]
    }
   ],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_only_conv_ch_32_{}_conv_DO_BN'.format(i)\n",
    "    model = build_2d_cnn_only_conv_ch_32_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_2d_norm, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_2d_norm, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "    \n",
    "    del(model)\n",
    "    \n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    model_name = '2D_CNN_only_conv_ch_32_{}_conv_BN'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_2d_norm, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
