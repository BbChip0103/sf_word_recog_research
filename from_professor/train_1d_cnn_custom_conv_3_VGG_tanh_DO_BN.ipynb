{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import os.path as path\n",
    "import itertools\n",
    "from sklearn.preprocessing import maxabs_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.layers import Input,InputLayer, Dense, Activation, BatchNormalization, Flatten, Conv1D\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler, \\\n",
    "                                        EarlyStopping\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = path.join('..', 'data')\n",
    "data_dir = path.join(base_dir, 'data_speech_commands_v0.02')\n",
    " \n",
    "train_txt = path.join(data_dir, 'wav_train_16words.txt')\n",
    "val_txt = path.join(data_dir, 'wav_validation_16words.txt')\n",
    "test_txt = path.join(data_dir, 'wav_test_16words.txt')\n",
    "\n",
    "train_data = np.load(path.join(data_dir, 'wav_train_data.npz'))\n",
    "val_data = np.load(path.join(data_dir, 'wav_validation_data.npz'))\n",
    "test_data = np.load(path.join(data_dir, 'wav_test_data.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((36805, 16000, 1),\n",
       " (36805,),\n",
       " (4293, 16000, 1),\n",
       " (4293,),\n",
       " (4815, 16000, 1),\n",
       " (4815,),\n",
       " (16, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = train_data['x_train']\n",
    "y_train = train_data['y_train']\n",
    "x_val = val_data['x_val']\n",
    "y_val = val_data['y_val']\n",
    "x_test = test_data['x_test']\n",
    "y_test = test_data['y_test']\n",
    "y_table = test_data['table']\n",
    "\n",
    "x_train.shape, y_train.shape, x_val.shape, y_val.shape, x_test.shape, y_test.shape, y_table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = x_test[0].shape\n",
    "output_size = y_table.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train_abs = np.asarray([maxabs_scale(wav) for wav in x_train])\n",
    "y_train_onehot = np.asarray([to_categorical(label, output_size) for label in y_train])\n",
    "del x_train, y_train\n",
    "\n",
    "x_val_abs = np.asarray([maxabs_scale(wav) for wav in x_val])\n",
    "y_val_onehot = np.asarray([to_categorical(label, output_size) for label in y_val])\n",
    "del x_val, y_val\n",
    "\n",
    "x_test_abs = np.asarray([maxabs_scale(wav) for wav in x_test])\n",
    "y_test_onehot = np.asarray([to_categorical(label, output_size) for label in y_test])\n",
    "del x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_1d_cnn_custom_conv_3_VGG_DO_BN(conv_num=1):\n",
    "    model=Sequential()\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same', input_shape=input_shape)) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Conv1D (kernel_size=3, filters=64, strides=1, padding='same')) \n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('tanh'))    \n",
    "#     model.add(MaxPooling1D(pool_size=3, strides=3, padding='same'))\n",
    "    \n",
    "    for i in range(conv_num-1):\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(Conv1D (kernel_size=3, filters=64*(2**int((i+1)/4)), strides=1, padding='same'))\n",
    "        model.add(BatchNormalization())   \n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(MaxPooling1D(pool_size=3, strides=3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(output_size, activation='softmax' ))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_1 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,397,136\n",
      "Trainable params: 16,396,880\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_5 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,499,344\n",
      "Trainable params: 5,498,832\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_6 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_7 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_8 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_9 (Ba (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_10 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_11 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,883,216\n",
      "Trainable params: 1,882,448\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_12 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_12 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_13 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_14 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_15 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_16 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_17 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_18 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_19 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_19 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 694,992\n",
      "Trainable params: 693,968\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_20 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_20 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_21 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_22 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_23 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_24 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_25 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_26 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_26 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_27 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_27 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_28 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_28 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_29 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_29 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 567,248\n",
      "Trainable params: 565,712\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_30 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_30 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_30 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_31 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_31 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_31 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_32 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_32 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_32 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_33 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_33 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_33 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_34 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_34 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_34 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_35 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_35 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_35 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_36 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_36 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_36 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_37 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_37 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_37 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_38 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_38 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_39 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_13 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_40 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_41 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_41 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_14 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 396,496\n",
      "Trainable params: 394,448\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_42 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_42 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_43 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_43 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_44 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_44 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_45 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_45 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_15 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_46 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_46 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_47 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_47 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_48 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_48 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_49 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_49 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_49 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_50 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_50 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_51 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_52 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_52 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_52 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_53 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_53 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_53 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_19 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_54 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_54 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_54 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_55 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_55 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_55 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_20 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 405,968\n",
      "Trainable params: 403,408\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_56 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_56 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_56 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_57 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_57 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_57 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_58 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_58 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_58 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_59 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_59 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_59 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_21 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_60 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_60 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_60 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_61 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_61 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_61 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_22 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_62 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_62 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_62 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_63 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_63 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_63 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_64 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_64 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_64 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_65 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_65 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_65 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_24 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_66 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_66 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_66 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_67 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_67 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_67 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_25 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_68 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_68 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_69 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_69 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_26 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_70 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_70 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_71 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_71 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_27 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 476,880\n",
      "Trainable params: 473,808\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_72 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_72 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_73 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_73 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_73 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_74 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_74 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_74 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_75 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_75 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_75 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_76 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_76 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_76 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_77 (Conv1D)           (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_77 (B (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_77 (Activation)   (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_78 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_78 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_78 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_79 (Conv1D)           (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_79 (B (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_79 (Activation)   (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_80 (Conv1D)           (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_80 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_80 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_81 (Conv1D)           (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_81 (B (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_81 (Activation)   (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_31 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_82 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_82 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_82 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_83 (Conv1D)           (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_83 (B (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_83 (Activation)   (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_32 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_84 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_84 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_84 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_85 (Conv1D)           (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_85 (B (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_85 (Activation)   (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_33 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_86 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_86 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_86 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_87 (Conv1D)           (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_87 (B (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_87 (Activation)   (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_34 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_88 (Conv1D)           (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_88 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_88 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_89 (Conv1D)           (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_89 (B (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_89 (Activation)   (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_35 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 768,208\n",
      "Trainable params: 764,112\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO_BN(conv_num=i)\n",
    "    model.summary()\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 36805 samples, validate on 4293 samples\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 5.2561 - acc: 0.0985\n",
      "Epoch 00001: val_loss improved from inf to 5.15518, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_1_conv_checkpoint/001-5.1552.hdf5\n",
      "36805/36805 [==============================] - 78s 2ms/sample - loss: 5.2559 - acc: 0.0985 - val_loss: 5.1552 - val_acc: 0.1006\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.0044 - acc: 0.3673\n",
      "Epoch 00002: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 3.0044 - acc: 0.3673 - val_loss: 10.2006 - val_acc: 0.0869\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.7335 - acc: 0.5844\n",
      "Epoch 00003: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.7334 - acc: 0.5844 - val_loss: 6.3842 - val_acc: 0.1139\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0220 - acc: 0.7322\n",
      "Epoch 00004: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 1.0220 - acc: 0.7322 - val_loss: 9.0370 - val_acc: 0.0846\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6672 - acc: 0.8183\n",
      "Epoch 00005: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.6672 - acc: 0.8182 - val_loss: 9.2634 - val_acc: 0.1013\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4953 - acc: 0.8622\n",
      "Epoch 00006: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4955 - acc: 0.8621 - val_loss: 10.9451 - val_acc: 0.0925\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4301 - acc: 0.8832\n",
      "Epoch 00007: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4303 - acc: 0.8832 - val_loss: 10.6966 - val_acc: 0.1046\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4341 - acc: 0.8862\n",
      "Epoch 00008: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.4340 - acc: 0.8862 - val_loss: 10.7390 - val_acc: 0.0897\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3830 - acc: 0.9010\n",
      "Epoch 00009: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3829 - acc: 0.9010 - val_loss: 10.1899 - val_acc: 0.1449\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3394 - acc: 0.9144\n",
      "Epoch 00010: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3394 - acc: 0.9144 - val_loss: 10.5548 - val_acc: 0.1321\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3319 - acc: 0.9179\n",
      "Epoch 00011: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3320 - acc: 0.9178 - val_loss: 10.6500 - val_acc: 0.1202\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3254 - acc: 0.9213\n",
      "Epoch 00012: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.3255 - acc: 0.9213 - val_loss: 13.8343 - val_acc: 0.0941\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2985 - acc: 0.9295\n",
      "Epoch 00013: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2986 - acc: 0.9294 - val_loss: 14.5596 - val_acc: 0.0850\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2819 - acc: 0.9343\n",
      "Epoch 00014: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2819 - acc: 0.9343 - val_loss: 13.2886 - val_acc: 0.0999\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2519 - acc: 0.9416\n",
      "Epoch 00015: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2518 - acc: 0.9416 - val_loss: 10.2665 - val_acc: 0.1589\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2554 - acc: 0.9422\n",
      "Epoch 00016: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2554 - acc: 0.9422 - val_loss: 10.7543 - val_acc: 0.1554\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2336 - acc: 0.9484\n",
      "Epoch 00017: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2336 - acc: 0.9484 - val_loss: 12.8370 - val_acc: 0.1160\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2243 - acc: 0.9507\n",
      "Epoch 00018: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2242 - acc: 0.9507 - val_loss: 11.3592 - val_acc: 0.1423\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2295 - acc: 0.9514\n",
      "Epoch 00019: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2295 - acc: 0.9514 - val_loss: 12.3407 - val_acc: 0.1174\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2425 - acc: 0.9510\n",
      "Epoch 00020: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2425 - acc: 0.9510 - val_loss: 11.2693 - val_acc: 0.1624\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2475 - acc: 0.9493\n",
      "Epoch 00021: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2475 - acc: 0.9493 - val_loss: 12.2524 - val_acc: 0.1176\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9565\n",
      "Epoch 00022: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2106 - acc: 0.9566 - val_loss: 12.0268 - val_acc: 0.1421\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1966 - acc: 0.9600\n",
      "Epoch 00023: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1966 - acc: 0.9600 - val_loss: 12.1976 - val_acc: 0.1428\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1875 - acc: 0.9611\n",
      "Epoch 00024: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1875 - acc: 0.9611 - val_loss: 12.2802 - val_acc: 0.1251\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1833 - acc: 0.9629\n",
      "Epoch 00025: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1833 - acc: 0.9629 - val_loss: 12.4814 - val_acc: 0.1335\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1984 - acc: 0.9623\n",
      "Epoch 00026: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1984 - acc: 0.9623 - val_loss: 13.0370 - val_acc: 0.1058\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2051 - acc: 0.9621\n",
      "Epoch 00027: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.2051 - acc: 0.9621 - val_loss: 11.9676 - val_acc: 0.1584\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1769 - acc: 0.9661\n",
      "Epoch 00028: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1771 - acc: 0.9661 - val_loss: 12.8504 - val_acc: 0.1353\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1676 - acc: 0.9686\n",
      "Epoch 00029: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1676 - acc: 0.9686 - val_loss: 11.8323 - val_acc: 0.1659\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1706 - acc: 0.9682\n",
      "Epoch 00030: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1705 - acc: 0.9682 - val_loss: 12.9861 - val_acc: 0.1374\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1717 - acc: 0.9688\n",
      "Epoch 00031: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1717 - acc: 0.9688 - val_loss: 12.3985 - val_acc: 0.1430\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9748\n",
      "Epoch 00032: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1351 - acc: 0.9748 - val_loss: 12.7384 - val_acc: 0.1172\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1787 - acc: 0.9681\n",
      "Epoch 00033: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1786 - acc: 0.9681 - val_loss: 13.0296 - val_acc: 0.1423\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9718\n",
      "Epoch 00034: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1549 - acc: 0.9719 - val_loss: 12.9729 - val_acc: 0.1190\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1539 - acc: 0.9723\n",
      "Epoch 00035: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1539 - acc: 0.9723 - val_loss: 11.4762 - val_acc: 0.1808\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1351 - acc: 0.9748\n",
      "Epoch 00036: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1356 - acc: 0.9747 - val_loss: 12.3345 - val_acc: 0.1456\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1525 - acc: 0.9731\n",
      "Epoch 00037: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1524 - acc: 0.9731 - val_loss: 13.5964 - val_acc: 0.1146\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1709 - acc: 0.9696\n",
      "Epoch 00038: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1708 - acc: 0.9696 - val_loss: 12.2971 - val_acc: 0.1621\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1470 - acc: 0.9744\n",
      "Epoch 00039: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1470 - acc: 0.9744 - val_loss: 13.0165 - val_acc: 0.1055\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9728\n",
      "Epoch 00040: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1577 - acc: 0.9727 - val_loss: 12.4016 - val_acc: 0.1516\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1777 - acc: 0.9699\n",
      "Epoch 00041: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1777 - acc: 0.9699 - val_loss: 12.6913 - val_acc: 0.1337\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1329 - acc: 0.9782\n",
      "Epoch 00042: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1333 - acc: 0.9782 - val_loss: 12.6072 - val_acc: 0.1342\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1379 - acc: 0.9762\n",
      "Epoch 00043: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1379 - acc: 0.9762 - val_loss: 11.7215 - val_acc: 0.1684\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9788\n",
      "Epoch 00044: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1245 - acc: 0.9788 - val_loss: 14.5093 - val_acc: 0.0922\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1645 - acc: 0.9739\n",
      "Epoch 00045: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1644 - acc: 0.9739 - val_loss: 13.8720 - val_acc: 0.1092\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1320 - acc: 0.9777\n",
      "Epoch 00046: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1320 - acc: 0.9777 - val_loss: 12.1786 - val_acc: 0.1512\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1390 - acc: 0.9781\n",
      "Epoch 00047: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1394 - acc: 0.9780 - val_loss: 12.1079 - val_acc: 0.1584\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9765\n",
      "Epoch 00048: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1455 - acc: 0.9765 - val_loss: 12.2992 - val_acc: 0.1416\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9792\n",
      "Epoch 00049: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1263 - acc: 0.9792 - val_loss: 12.0816 - val_acc: 0.1742\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9810\n",
      "Epoch 00050: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1291 - acc: 0.9810 - val_loss: 12.9285 - val_acc: 0.1335\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9798\n",
      "Epoch 00051: val_loss did not improve from 5.15518\n",
      "36805/36805 [==============================] - 74s 2ms/sample - loss: 0.1276 - acc: 0.9798 - val_loss: 12.0429 - val_acc: 0.1654\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_1_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 3s 695us/sample - loss: 5.1162 - acc: 0.1032\n",
      "Loss: 5.116166759898977 Accuracy: 0.10321911\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 3.1669 - acc: 0.2408\n",
      "Epoch 00001: val_loss improved from inf to 2.90470, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_2_conv_checkpoint/001-2.9047.hdf5\n",
      "36805/36805 [==============================] - 136s 4ms/sample - loss: 3.1671 - acc: 0.2408 - val_loss: 2.9047 - val_acc: 0.3005\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6927 - acc: 0.5243\n",
      "Epoch 00002: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 1.6928 - acc: 0.5242 - val_loss: 4.9845 - val_acc: 0.2667\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9511 - acc: 0.7148\n",
      "Epoch 00003: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.9510 - acc: 0.7148 - val_loss: 10.3668 - val_acc: 0.1018\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5530 - acc: 0.8326\n",
      "Epoch 00004: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.5530 - acc: 0.8326 - val_loss: 8.7833 - val_acc: 0.1456\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3891 - acc: 0.8850\n",
      "Epoch 00005: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.3891 - acc: 0.8850 - val_loss: 6.5442 - val_acc: 0.2110\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3079 - acc: 0.9112\n",
      "Epoch 00006: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.3079 - acc: 0.9112 - val_loss: 4.7634 - val_acc: 0.2867\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2775 - acc: 0.9177\n",
      "Epoch 00007: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.2775 - acc: 0.9177 - val_loss: 7.3535 - val_acc: 0.2015\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2354 - acc: 0.9306\n",
      "Epoch 00008: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.2368 - acc: 0.9305 - val_loss: 5.6583 - val_acc: 0.2544\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3556 - acc: 0.9036\n",
      "Epoch 00009: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.3556 - acc: 0.9036 - val_loss: 6.6890 - val_acc: 0.2455\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1908 - acc: 0.9435\n",
      "Epoch 00010: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1908 - acc: 0.9435 - val_loss: 5.9821 - val_acc: 0.3131\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9516\n",
      "Epoch 00011: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1665 - acc: 0.9516 - val_loss: 5.6187 - val_acc: 0.2975\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1702 - acc: 0.9512\n",
      "Epoch 00012: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1702 - acc: 0.9512 - val_loss: 7.2795 - val_acc: 0.2544\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1760 - acc: 0.9487\n",
      "Epoch 00013: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1760 - acc: 0.9487 - val_loss: 9.6122 - val_acc: 0.1868\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9571\n",
      "Epoch 00014: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1519 - acc: 0.9571 - val_loss: 7.4047 - val_acc: 0.2940\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1511 - acc: 0.9562\n",
      "Epoch 00015: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1511 - acc: 0.9562 - val_loss: 7.8548 - val_acc: 0.2742\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9578\n",
      "Epoch 00016: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1501 - acc: 0.9578 - val_loss: 8.4030 - val_acc: 0.2735\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1585 - acc: 0.9554\n",
      "Epoch 00017: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1585 - acc: 0.9554 - val_loss: 9.9833 - val_acc: 0.2159\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9642\n",
      "Epoch 00018: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1302 - acc: 0.9642 - val_loss: 8.3514 - val_acc: 0.2735\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1305 - acc: 0.9625\n",
      "Epoch 00019: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1305 - acc: 0.9625 - val_loss: 8.8028 - val_acc: 0.2583\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1358 - acc: 0.9633\n",
      "Epoch 00020: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1358 - acc: 0.9633 - val_loss: 6.8654 - val_acc: 0.3033\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1303 - acc: 0.9655\n",
      "Epoch 00021: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1303 - acc: 0.9655 - val_loss: 6.6175 - val_acc: 0.3289\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9639\n",
      "Epoch 00022: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1343 - acc: 0.9639 - val_loss: 12.0676 - val_acc: 0.1337\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9711\n",
      "Epoch 00023: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1096 - acc: 0.9711 - val_loss: 6.1705 - val_acc: 0.3501\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1196 - acc: 0.9681\n",
      "Epoch 00024: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1196 - acc: 0.9681 - val_loss: 8.1376 - val_acc: 0.3012\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9704\n",
      "Epoch 00025: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1097 - acc: 0.9704 - val_loss: 7.6538 - val_acc: 0.3077\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0919 - acc: 0.9755\n",
      "Epoch 00026: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0919 - acc: 0.9755 - val_loss: 7.1334 - val_acc: 0.3427\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9727\n",
      "Epoch 00027: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1035 - acc: 0.9726 - val_loss: 8.5136 - val_acc: 0.2639\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0984 - acc: 0.9737\n",
      "Epoch 00028: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0984 - acc: 0.9737 - val_loss: 7.9035 - val_acc: 0.2711\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1021 - acc: 0.9733\n",
      "Epoch 00029: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1021 - acc: 0.9733 - val_loss: 7.1849 - val_acc: 0.3501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9774\n",
      "Epoch 00030: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0899 - acc: 0.9774 - val_loss: 10.3857 - val_acc: 0.1989\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1148 - acc: 0.9721\n",
      "Epoch 00031: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1148 - acc: 0.9721 - val_loss: 8.6010 - val_acc: 0.2751\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1003 - acc: 0.9743\n",
      "Epoch 00032: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.1004 - acc: 0.9743 - val_loss: 7.1624 - val_acc: 0.3287\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9753\n",
      "Epoch 00033: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0963 - acc: 0.9753 - val_loss: 9.1914 - val_acc: 0.2716\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9779\n",
      "Epoch 00034: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0885 - acc: 0.9779 - val_loss: 9.1678 - val_acc: 0.2802\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0863 - acc: 0.9783\n",
      "Epoch 00035: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0863 - acc: 0.9782 - val_loss: 7.3340 - val_acc: 0.3308\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9777\n",
      "Epoch 00036: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0930 - acc: 0.9777 - val_loss: 6.5765 - val_acc: 0.3816\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9811\n",
      "Epoch 00037: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0756 - acc: 0.9811 - val_loss: 7.2273 - val_acc: 0.3485\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0964 - acc: 0.9773\n",
      "Epoch 00038: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0968 - acc: 0.9773 - val_loss: 8.0376 - val_acc: 0.3212\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9788\n",
      "Epoch 00039: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0877 - acc: 0.9788 - val_loss: 10.9496 - val_acc: 0.2031\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9798\n",
      "Epoch 00040: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0855 - acc: 0.9798 - val_loss: 6.9875 - val_acc: 0.3676\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9804\n",
      "Epoch 00041: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0820 - acc: 0.9804 - val_loss: 7.3545 - val_acc: 0.3496\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9812\n",
      "Epoch 00042: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0830 - acc: 0.9812 - val_loss: 8.7002 - val_acc: 0.3000\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9802\n",
      "Epoch 00043: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0865 - acc: 0.9802 - val_loss: 7.8153 - val_acc: 0.3564\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9832\n",
      "Epoch 00044: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0723 - acc: 0.9832 - val_loss: 8.3186 - val_acc: 0.3222\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9820\n",
      "Epoch 00045: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0743 - acc: 0.9819 - val_loss: 6.8893 - val_acc: 0.3769\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9796\n",
      "Epoch 00046: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0916 - acc: 0.9796 - val_loss: 7.8001 - val_acc: 0.3308\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9822\n",
      "Epoch 00047: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0784 - acc: 0.9822 - val_loss: 6.9086 - val_acc: 0.3918\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9831\n",
      "Epoch 00048: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0767 - acc: 0.9831 - val_loss: 6.7928 - val_acc: 0.3925\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9818\n",
      "Epoch 00049: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0781 - acc: 0.9819 - val_loss: 8.7385 - val_acc: 0.3077\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9829\n",
      "Epoch 00050: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0790 - acc: 0.9828 - val_loss: 7.5507 - val_acc: 0.3562\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9847\n",
      "Epoch 00051: val_loss did not improve from 2.90470\n",
      "36805/36805 [==============================] - 132s 4ms/sample - loss: 0.0710 - acc: 0.9846 - val_loss: 6.6042 - val_acc: 0.4100\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_2_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 3.0071 - acc: 0.2721\n",
      "Loss: 3.007104391224783 Accuracy: 0.27206644\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.4392 - acc: 0.3171\n",
      "Epoch 00001: val_loss improved from inf to 5.79774, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_3_conv_checkpoint/001-5.7977.hdf5\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 2.4392 - acc: 0.3171 - val_loss: 5.7977 - val_acc: 0.1789\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5434 - acc: 0.5405\n",
      "Epoch 00002: val_loss improved from 5.79774 to 5.51859, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_3_conv_checkpoint/002-5.5186.hdf5\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 1.5433 - acc: 0.5405 - val_loss: 5.5186 - val_acc: 0.1742\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1420 - acc: 0.6461\n",
      "Epoch 00003: val_loss did not improve from 5.51859\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 1.1420 - acc: 0.6461 - val_loss: 7.4046 - val_acc: 0.1980\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8769 - acc: 0.7255\n",
      "Epoch 00004: val_loss improved from 5.51859 to 5.21138, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_3_conv_checkpoint/004-5.2114.hdf5\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.8770 - acc: 0.7254 - val_loss: 5.2114 - val_acc: 0.2297\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6858 - acc: 0.7849\n",
      "Epoch 00005: val_loss improved from 5.21138 to 3.84565, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_3_conv_checkpoint/005-3.8457.hdf5\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.6858 - acc: 0.7848 - val_loss: 3.8457 - val_acc: 0.3112\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5497 - acc: 0.8256\n",
      "Epoch 00006: val_loss did not improve from 3.84565\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.5498 - acc: 0.8255 - val_loss: 6.2963 - val_acc: 0.2453\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4567 - acc: 0.8553\n",
      "Epoch 00007: val_loss did not improve from 3.84565\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.4569 - acc: 0.8553 - val_loss: 6.7598 - val_acc: 0.2073\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3974 - acc: 0.8758\n",
      "Epoch 00008: val_loss did not improve from 3.84565\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.3974 - acc: 0.8758 - val_loss: 6.4471 - val_acc: 0.2532\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3283 - acc: 0.9000\n",
      "Epoch 00009: val_loss did not improve from 3.84565\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.3283 - acc: 0.9000 - val_loss: 4.5845 - val_acc: 0.3033\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2804 - acc: 0.9138\n",
      "Epoch 00010: val_loss improved from 3.84565 to 3.03593, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_3_conv_checkpoint/010-3.0359.hdf5\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.2804 - acc: 0.9138 - val_loss: 3.0359 - val_acc: 0.4249\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2496 - acc: 0.9210\n",
      "Epoch 00011: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.2497 - acc: 0.9210 - val_loss: 7.2056 - val_acc: 0.2143\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2237 - acc: 0.9318\n",
      "Epoch 00012: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.2238 - acc: 0.9317 - val_loss: 7.2308 - val_acc: 0.2280\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2104 - acc: 0.9346\n",
      "Epoch 00013: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.2105 - acc: 0.9346 - val_loss: 9.2825 - val_acc: 0.1740\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1933 - acc: 0.9392\n",
      "Epoch 00014: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1932 - acc: 0.9392 - val_loss: 5.6170 - val_acc: 0.3569\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9448\n",
      "Epoch 00015: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1811 - acc: 0.9448 - val_loss: 6.1499 - val_acc: 0.3063\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1664 - acc: 0.9479\n",
      "Epoch 00016: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1665 - acc: 0.9478 - val_loss: 5.5326 - val_acc: 0.3631\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9525\n",
      "Epoch 00017: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1579 - acc: 0.9525 - val_loss: 7.0380 - val_acc: 0.3291\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1718 - acc: 0.9486\n",
      "Epoch 00018: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1719 - acc: 0.9485 - val_loss: 4.6545 - val_acc: 0.3734\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1511 - acc: 0.9530\n",
      "Epoch 00019: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1510 - acc: 0.9530 - val_loss: 6.8222 - val_acc: 0.3093\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9597\n",
      "Epoch 00020: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1317 - acc: 0.9597 - val_loss: 5.5326 - val_acc: 0.3280\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1413 - acc: 0.9560\n",
      "Epoch 00021: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1412 - acc: 0.9560 - val_loss: 5.3967 - val_acc: 0.4004\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9611\n",
      "Epoch 00022: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1302 - acc: 0.9611 - val_loss: 3.8785 - val_acc: 0.4214\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1228 - acc: 0.9618\n",
      "Epoch 00023: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1230 - acc: 0.9618 - val_loss: 4.6987 - val_acc: 0.4011\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9615\n",
      "Epoch 00024: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1202 - acc: 0.9615 - val_loss: 6.1464 - val_acc: 0.3408\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9652\n",
      "Epoch 00025: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1117 - acc: 0.9652 - val_loss: 4.7069 - val_acc: 0.3883\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9667\n",
      "Epoch 00026: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1099 - acc: 0.9667 - val_loss: 7.5251 - val_acc: 0.2562\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1044 - acc: 0.9693\n",
      "Epoch 00027: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1044 - acc: 0.9693 - val_loss: 7.7740 - val_acc: 0.2648\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9664\n",
      "Epoch 00028: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1080 - acc: 0.9664 - val_loss: 4.4387 - val_acc: 0.4195\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1028 - acc: 0.9689\n",
      "Epoch 00029: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1028 - acc: 0.9689 - val_loss: 4.5849 - val_acc: 0.4179\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9678\n",
      "Epoch 00030: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1074 - acc: 0.9678 - val_loss: 6.2614 - val_acc: 0.3764\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1025 - acc: 0.9688\n",
      "Epoch 00031: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.1025 - acc: 0.9688 - val_loss: 3.8436 - val_acc: 0.4726\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0934 - acc: 0.9707\n",
      "Epoch 00032: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0934 - acc: 0.9706 - val_loss: 3.5011 - val_acc: 0.4708\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9722\n",
      "Epoch 00033: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0920 - acc: 0.9722 - val_loss: 5.2639 - val_acc: 0.4051\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9744\n",
      "Epoch 00034: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0868 - acc: 0.9744 - val_loss: 6.3152 - val_acc: 0.3545\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0995 - acc: 0.9707\n",
      "Epoch 00035: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0996 - acc: 0.9707 - val_loss: 4.2252 - val_acc: 0.4382\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9723\n",
      "Epoch 00036: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0932 - acc: 0.9723 - val_loss: 4.3429 - val_acc: 0.4489\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0872 - acc: 0.9740\n",
      "Epoch 00037: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0872 - acc: 0.9740 - val_loss: 6.6153 - val_acc: 0.3520\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9767\n",
      "Epoch 00038: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0780 - acc: 0.9767 - val_loss: 4.6326 - val_acc: 0.4584\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9783\n",
      "Epoch 00039: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0700 - acc: 0.9783 - val_loss: 5.9371 - val_acc: 0.4002\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9757\n",
      "Epoch 00040: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0826 - acc: 0.9757 - val_loss: 6.9860 - val_acc: 0.3669\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9758\n",
      "Epoch 00041: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0791 - acc: 0.9758 - val_loss: 5.3914 - val_acc: 0.4191\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0801 - acc: 0.9758\n",
      "Epoch 00042: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0801 - acc: 0.9758 - val_loss: 5.4666 - val_acc: 0.4041\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9757\n",
      "Epoch 00043: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0790 - acc: 0.9757 - val_loss: 6.8549 - val_acc: 0.3445\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9750\n",
      "Epoch 00044: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0842 - acc: 0.9750 - val_loss: 5.2777 - val_acc: 0.4375\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9761\n",
      "Epoch 00045: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0801 - acc: 0.9760 - val_loss: 5.5435 - val_acc: 0.4011\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0825 - acc: 0.9745\n",
      "Epoch 00046: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0825 - acc: 0.9745 - val_loss: 3.8289 - val_acc: 0.5008\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9781\n",
      "Epoch 00047: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0742 - acc: 0.9781 - val_loss: 4.1314 - val_acc: 0.4957\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9782\n",
      "Epoch 00048: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0740 - acc: 0.9782 - val_loss: 5.7904 - val_acc: 0.3846\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0743 - acc: 0.9773\n",
      "Epoch 00049: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0743 - acc: 0.9773 - val_loss: 4.1292 - val_acc: 0.5034\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9802\n",
      "Epoch 00050: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0751 - acc: 0.9802 - val_loss: 5.2576 - val_acc: 0.4554\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9788\n",
      "Epoch 00051: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0742 - acc: 0.9788 - val_loss: 6.2737 - val_acc: 0.3937\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9773\n",
      "Epoch 00052: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0795 - acc: 0.9773 - val_loss: 3.7559 - val_acc: 0.5236\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0590 - acc: 0.9827\n",
      "Epoch 00053: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0590 - acc: 0.9827 - val_loss: 4.5535 - val_acc: 0.4743\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9809\n",
      "Epoch 00054: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0701 - acc: 0.9809 - val_loss: 4.3322 - val_acc: 0.4808\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0711 - acc: 0.9786\n",
      "Epoch 00055: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0711 - acc: 0.9786 - val_loss: 4.1207 - val_acc: 0.5111\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0695 - acc: 0.9802\n",
      "Epoch 00056: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0695 - acc: 0.9802 - val_loss: 6.2992 - val_acc: 0.3720\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0665 - acc: 0.9810\n",
      "Epoch 00057: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0665 - acc: 0.9810 - val_loss: 6.4491 - val_acc: 0.3727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9819\n",
      "Epoch 00058: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0661 - acc: 0.9819 - val_loss: 3.3177 - val_acc: 0.5504\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0708 - acc: 0.9799\n",
      "Epoch 00059: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0708 - acc: 0.9799 - val_loss: 4.9889 - val_acc: 0.4710\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0651 - acc: 0.9817\n",
      "Epoch 00060: val_loss did not improve from 3.03593\n",
      "36805/36805 [==============================] - 151s 4ms/sample - loss: 0.0651 - acc: 0.9817 - val_loss: 4.4916 - val_acc: 0.4938\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_3_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 3.2692 - acc: 0.3927\n",
      "Loss: 3.2692273603421507 Accuracy: 0.39273104\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2276 - acc: 0.3401\n",
      "Epoch 00001: val_loss improved from inf to 3.76052, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_4_conv_checkpoint/001-3.7605.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 2.2277 - acc: 0.3400 - val_loss: 3.7605 - val_acc: 0.1975\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5040 - acc: 0.5427\n",
      "Epoch 00002: val_loss improved from 3.76052 to 1.76325, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_4_conv_checkpoint/002-1.7632.hdf5\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 1.5040 - acc: 0.5426 - val_loss: 1.7632 - val_acc: 0.5059\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2229 - acc: 0.6239\n",
      "Epoch 00003: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 1.2228 - acc: 0.6239 - val_loss: 1.8998 - val_acc: 0.4927\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0479 - acc: 0.6787\n",
      "Epoch 00004: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 1.0479 - acc: 0.6787 - val_loss: 3.9914 - val_acc: 0.3245\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9181 - acc: 0.7161\n",
      "Epoch 00005: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.9181 - acc: 0.7161 - val_loss: 3.0658 - val_acc: 0.4230\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8173 - acc: 0.7495\n",
      "Epoch 00006: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.8173 - acc: 0.7495 - val_loss: 2.3022 - val_acc: 0.4647\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7299 - acc: 0.7739\n",
      "Epoch 00007: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.7299 - acc: 0.7739 - val_loss: 2.9310 - val_acc: 0.4260\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6591 - acc: 0.7944\n",
      "Epoch 00008: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.6595 - acc: 0.7944 - val_loss: 2.2439 - val_acc: 0.4964\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6007 - acc: 0.8127\n",
      "Epoch 00009: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.6007 - acc: 0.8127 - val_loss: 3.1897 - val_acc: 0.4139\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5477 - acc: 0.8282\n",
      "Epoch 00010: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.5478 - acc: 0.8281 - val_loss: 2.8882 - val_acc: 0.4496\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5009 - acc: 0.8449\n",
      "Epoch 00011: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.5010 - acc: 0.8449 - val_loss: 4.0844 - val_acc: 0.3515\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4669 - acc: 0.8549\n",
      "Epoch 00012: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.4670 - acc: 0.8549 - val_loss: 4.3818 - val_acc: 0.3666\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4368 - acc: 0.8626\n",
      "Epoch 00013: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.4368 - acc: 0.8625 - val_loss: 2.5691 - val_acc: 0.4715\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4021 - acc: 0.8742\n",
      "Epoch 00014: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.4022 - acc: 0.8742 - val_loss: 2.0349 - val_acc: 0.5388\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3674 - acc: 0.8857\n",
      "Epoch 00015: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.3673 - acc: 0.8857 - val_loss: 1.8945 - val_acc: 0.5458\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3463 - acc: 0.8919\n",
      "Epoch 00016: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.3463 - acc: 0.8919 - val_loss: 2.8577 - val_acc: 0.4917\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3255 - acc: 0.8971\n",
      "Epoch 00017: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.3255 - acc: 0.8971 - val_loss: 1.8459 - val_acc: 0.5770\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3037 - acc: 0.9036\n",
      "Epoch 00018: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.3037 - acc: 0.9036 - val_loss: 2.6878 - val_acc: 0.5313\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2892 - acc: 0.9090\n",
      "Epoch 00019: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2892 - acc: 0.9090 - val_loss: 4.4871 - val_acc: 0.3524\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2735 - acc: 0.9139\n",
      "Epoch 00020: val_loss did not improve from 1.76325\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2735 - acc: 0.9139 - val_loss: 3.6420 - val_acc: 0.4708\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2600 - acc: 0.9186\n",
      "Epoch 00021: val_loss improved from 1.76325 to 1.47458, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_4_conv_checkpoint/021-1.4746.hdf5\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2600 - acc: 0.9187 - val_loss: 1.4746 - val_acc: 0.6380\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2444 - acc: 0.9239\n",
      "Epoch 00022: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.2444 - acc: 0.9239 - val_loss: 3.9359 - val_acc: 0.4379\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.9247\n",
      "Epoch 00023: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.2401 - acc: 0.9247 - val_loss: 1.8417 - val_acc: 0.6012\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2286 - acc: 0.9265\n",
      "Epoch 00024: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2287 - acc: 0.9265 - val_loss: 2.2121 - val_acc: 0.5788\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2216 - acc: 0.9292\n",
      "Epoch 00025: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2216 - acc: 0.9292 - val_loss: 2.4080 - val_acc: 0.5507\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2032 - acc: 0.9360\n",
      "Epoch 00026: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2032 - acc: 0.9360 - val_loss: 2.7201 - val_acc: 0.5134\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9348\n",
      "Epoch 00027: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2036 - acc: 0.9348 - val_loss: 2.6327 - val_acc: 0.5413\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1926 - acc: 0.9381\n",
      "Epoch 00028: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1927 - acc: 0.9381 - val_loss: 2.9737 - val_acc: 0.5080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1863 - acc: 0.9402\n",
      "Epoch 00029: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1864 - acc: 0.9402 - val_loss: 2.8196 - val_acc: 0.5523\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2093 - acc: 0.9356\n",
      "Epoch 00030: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.2094 - acc: 0.9356 - val_loss: 2.5997 - val_acc: 0.5225\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1733 - acc: 0.9453\n",
      "Epoch 00031: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1733 - acc: 0.9453 - val_loss: 2.8083 - val_acc: 0.4997\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1702 - acc: 0.9455\n",
      "Epoch 00032: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1702 - acc: 0.9455 - val_loss: 2.7169 - val_acc: 0.5411\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1656 - acc: 0.9468\n",
      "Epoch 00033: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1656 - acc: 0.9468 - val_loss: 2.1042 - val_acc: 0.6073\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1651 - acc: 0.9480\n",
      "Epoch 00034: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1651 - acc: 0.9480 - val_loss: 4.0512 - val_acc: 0.4379\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1525 - acc: 0.9514\n",
      "Epoch 00035: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1527 - acc: 0.9514 - val_loss: 2.2776 - val_acc: 0.5782\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1614 - acc: 0.9485\n",
      "Epoch 00036: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1614 - acc: 0.9484 - val_loss: 2.5237 - val_acc: 0.5420\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1517 - acc: 0.9516\n",
      "Epoch 00037: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1517 - acc: 0.9516 - val_loss: 2.4790 - val_acc: 0.5201\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9531\n",
      "Epoch 00038: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1490 - acc: 0.9530 - val_loss: 2.3836 - val_acc: 0.5935\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9520\n",
      "Epoch 00039: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1468 - acc: 0.9520 - val_loss: 2.3341 - val_acc: 0.5805\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1371 - acc: 0.9568\n",
      "Epoch 00040: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1371 - acc: 0.9569 - val_loss: 3.9132 - val_acc: 0.4382\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1376 - acc: 0.9552\n",
      "Epoch 00041: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1376 - acc: 0.9552 - val_loss: 3.3941 - val_acc: 0.4810\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1335 - acc: 0.9576\n",
      "Epoch 00042: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1335 - acc: 0.9576 - val_loss: 2.2858 - val_acc: 0.5891\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9564\n",
      "Epoch 00043: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1355 - acc: 0.9564 - val_loss: 1.7306 - val_acc: 0.6464\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1293 - acc: 0.9586\n",
      "Epoch 00044: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1294 - acc: 0.9586 - val_loss: 2.1426 - val_acc: 0.6240\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1280 - acc: 0.9601\n",
      "Epoch 00045: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1280 - acc: 0.9600 - val_loss: 2.2602 - val_acc: 0.6010\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1368 - acc: 0.9555\n",
      "Epoch 00046: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1368 - acc: 0.9555 - val_loss: 2.3428 - val_acc: 0.5886\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9623\n",
      "Epoch 00047: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1201 - acc: 0.9623 - val_loss: 2.8871 - val_acc: 0.5549\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9610\n",
      "Epoch 00048: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1234 - acc: 0.9610 - val_loss: 2.3356 - val_acc: 0.6096\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9626\n",
      "Epoch 00049: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1201 - acc: 0.9626 - val_loss: 3.7957 - val_acc: 0.5153\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1169 - acc: 0.9630\n",
      "Epoch 00050: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1169 - acc: 0.9630 - val_loss: 2.4902 - val_acc: 0.6094\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9658\n",
      "Epoch 00051: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1099 - acc: 0.9658 - val_loss: 2.4763 - val_acc: 0.5782\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1161 - acc: 0.9621\n",
      "Epoch 00052: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1161 - acc: 0.9621 - val_loss: 2.7708 - val_acc: 0.5667\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1102 - acc: 0.9661\n",
      "Epoch 00053: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1101 - acc: 0.9661 - val_loss: 2.8507 - val_acc: 0.5404\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9627\n",
      "Epoch 00054: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1162 - acc: 0.9627 - val_loss: 2.9162 - val_acc: 0.5558\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9622\n",
      "Epoch 00055: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1198 - acc: 0.9621 - val_loss: 4.5329 - val_acc: 0.4531\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9634\n",
      "Epoch 00056: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1142 - acc: 0.9634 - val_loss: 2.7185 - val_acc: 0.5672\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1008 - acc: 0.9679\n",
      "Epoch 00057: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1008 - acc: 0.9679 - val_loss: 4.1774 - val_acc: 0.4377\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9685\n",
      "Epoch 00058: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1000 - acc: 0.9685 - val_loss: 3.3303 - val_acc: 0.5306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1011 - acc: 0.9680\n",
      "Epoch 00059: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1011 - acc: 0.9680 - val_loss: 3.0852 - val_acc: 0.5588\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9673\n",
      "Epoch 00060: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.1017 - acc: 0.9673 - val_loss: 3.6497 - val_acc: 0.4889\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9699\n",
      "Epoch 00061: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0950 - acc: 0.9699 - val_loss: 2.0025 - val_acc: 0.6758\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1046 - acc: 0.9659\n",
      "Epoch 00062: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1049 - acc: 0.9658 - val_loss: 2.1762 - val_acc: 0.6089\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9663\n",
      "Epoch 00063: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.1034 - acc: 0.9663 - val_loss: 3.0178 - val_acc: 0.5693\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9689\n",
      "Epoch 00064: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0949 - acc: 0.9688 - val_loss: 2.8255 - val_acc: 0.5823\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9687\n",
      "Epoch 00065: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0978 - acc: 0.9687 - val_loss: 1.8978 - val_acc: 0.6620\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0944 - acc: 0.9692\n",
      "Epoch 00066: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0944 - acc: 0.9692 - val_loss: 3.9509 - val_acc: 0.5036\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0987 - acc: 0.9690\n",
      "Epoch 00067: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0987 - acc: 0.9689 - val_loss: 1.4823 - val_acc: 0.7195\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9716\n",
      "Epoch 00068: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0923 - acc: 0.9716 - val_loss: 3.3305 - val_acc: 0.5518\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9721\n",
      "Epoch 00069: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0889 - acc: 0.9722 - val_loss: 3.4296 - val_acc: 0.5504\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0877 - acc: 0.9726\n",
      "Epoch 00070: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 158s 4ms/sample - loss: 0.0877 - acc: 0.9726 - val_loss: 1.8948 - val_acc: 0.6657\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9710\n",
      "Epoch 00071: val_loss did not improve from 1.47458\n",
      "36805/36805 [==============================] - 157s 4ms/sample - loss: 0.0941 - acc: 0.9710 - val_loss: 2.7901 - val_acc: 0.5931\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_4_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 1.6950 - acc: 0.5952\n",
      "Loss: 1.6949939185585188 Accuracy: 0.59522325\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.1294 - acc: 0.3591\n",
      "Epoch 00001: val_loss improved from inf to 3.83865, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_5_conv_checkpoint/001-3.8386.hdf5\n",
      "36805/36805 [==============================] - 178s 5ms/sample - loss: 2.1294 - acc: 0.3591 - val_loss: 3.8386 - val_acc: 0.1912\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.4692 - acc: 0.5500\n",
      "Epoch 00002: val_loss improved from 3.83865 to 1.50158, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_5_conv_checkpoint/002-1.5016.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 1.4691 - acc: 0.5500 - val_loss: 1.5016 - val_acc: 0.5756\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2241 - acc: 0.6275\n",
      "Epoch 00003: val_loss did not improve from 1.50158\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 1.2240 - acc: 0.6275 - val_loss: 3.9182 - val_acc: 0.3077\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0577 - acc: 0.6748\n",
      "Epoch 00004: val_loss improved from 1.50158 to 1.43025, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_5_conv_checkpoint/004-1.4302.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 1.0576 - acc: 0.6748 - val_loss: 1.4302 - val_acc: 0.5977\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9396 - acc: 0.7121\n",
      "Epoch 00005: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.9395 - acc: 0.7121 - val_loss: 3.2618 - val_acc: 0.3743\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8493 - acc: 0.7406\n",
      "Epoch 00006: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.8492 - acc: 0.7406 - val_loss: 1.9697 - val_acc: 0.5444\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7843 - acc: 0.7599\n",
      "Epoch 00007: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.7843 - acc: 0.7598 - val_loss: 3.3508 - val_acc: 0.4109\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7272 - acc: 0.7757\n",
      "Epoch 00008: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.7272 - acc: 0.7757 - val_loss: 3.0772 - val_acc: 0.4416\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6772 - acc: 0.7917\n",
      "Epoch 00009: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.6772 - acc: 0.7917 - val_loss: 2.5406 - val_acc: 0.4526\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6300 - acc: 0.8045\n",
      "Epoch 00010: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.6299 - acc: 0.8045 - val_loss: 3.5626 - val_acc: 0.4391\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5805 - acc: 0.8220\n",
      "Epoch 00011: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.5804 - acc: 0.8220 - val_loss: 2.5025 - val_acc: 0.5085\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5485 - acc: 0.8299\n",
      "Epoch 00012: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.5486 - acc: 0.8298 - val_loss: 2.1375 - val_acc: 0.5010\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5257 - acc: 0.8370\n",
      "Epoch 00013: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.5257 - acc: 0.8370 - val_loss: 2.4821 - val_acc: 0.5551\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4939 - acc: 0.8470\n",
      "Epoch 00014: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.4938 - acc: 0.8471 - val_loss: 2.4480 - val_acc: 0.5651\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4610 - acc: 0.8550\n",
      "Epoch 00015: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.4611 - acc: 0.8550 - val_loss: 2.2218 - val_acc: 0.5178\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4408 - acc: 0.8615\n",
      "Epoch 00016: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.4408 - acc: 0.8615 - val_loss: 1.9054 - val_acc: 0.5730\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4212 - acc: 0.8687\n",
      "Epoch 00017: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.4212 - acc: 0.8688 - val_loss: 4.3664 - val_acc: 0.4300\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3917 - acc: 0.8778\n",
      "Epoch 00018: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.3917 - acc: 0.8778 - val_loss: 4.6621 - val_acc: 0.4018\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3782 - acc: 0.8808\n",
      "Epoch 00019: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.3782 - acc: 0.8807 - val_loss: 1.6280 - val_acc: 0.6322\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3622 - acc: 0.8862\n",
      "Epoch 00020: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.3622 - acc: 0.8862 - val_loss: 2.8311 - val_acc: 0.5262\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3425 - acc: 0.8930\n",
      "Epoch 00021: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.3426 - acc: 0.8929 - val_loss: 5.0205 - val_acc: 0.3827\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3348 - acc: 0.8938\n",
      "Epoch 00022: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.3349 - acc: 0.8938 - val_loss: 3.7775 - val_acc: 0.4533\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3174 - acc: 0.9005\n",
      "Epoch 00023: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.3174 - acc: 0.9004 - val_loss: 4.3393 - val_acc: 0.3955\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3065 - acc: 0.9011\n",
      "Epoch 00024: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.3064 - acc: 0.9011 - val_loss: 2.0922 - val_acc: 0.5574\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2901 - acc: 0.9076\n",
      "Epoch 00025: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2901 - acc: 0.9076 - val_loss: 2.1377 - val_acc: 0.5695\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2771 - acc: 0.9122\n",
      "Epoch 00026: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2771 - acc: 0.9122 - val_loss: 1.6254 - val_acc: 0.6373\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2814 - acc: 0.9102\n",
      "Epoch 00027: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2816 - acc: 0.9101 - val_loss: 1.9406 - val_acc: 0.6166\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2711 - acc: 0.9127\n",
      "Epoch 00028: val_loss did not improve from 1.43025\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2711 - acc: 0.9127 - val_loss: 5.7095 - val_acc: 0.3748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2448 - acc: 0.9229\n",
      "Epoch 00029: val_loss improved from 1.43025 to 1.34834, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_5_conv_checkpoint/029-1.3483.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2448 - acc: 0.9229 - val_loss: 1.3483 - val_acc: 0.6699\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2461 - acc: 0.9225\n",
      "Epoch 00030: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2461 - acc: 0.9225 - val_loss: 1.6379 - val_acc: 0.6434\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2348 - acc: 0.9232\n",
      "Epoch 00031: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2349 - acc: 0.9232 - val_loss: 4.3900 - val_acc: 0.4563\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2362 - acc: 0.9232\n",
      "Epoch 00032: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2362 - acc: 0.9232 - val_loss: 1.7162 - val_acc: 0.6348\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2284 - acc: 0.9255\n",
      "Epoch 00033: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2284 - acc: 0.9255 - val_loss: 1.6049 - val_acc: 0.6720\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2314 - acc: 0.9251\n",
      "Epoch 00034: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2314 - acc: 0.9251 - val_loss: 3.1597 - val_acc: 0.4920\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2031 - acc: 0.9354\n",
      "Epoch 00035: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2031 - acc: 0.9354 - val_loss: 3.7040 - val_acc: 0.4736\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9342\n",
      "Epoch 00036: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.2036 - acc: 0.9342 - val_loss: 4.1431 - val_acc: 0.4563\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1946 - acc: 0.9376\n",
      "Epoch 00037: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1946 - acc: 0.9376 - val_loss: 4.2928 - val_acc: 0.4608\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1937 - acc: 0.9389\n",
      "Epoch 00038: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1937 - acc: 0.9389 - val_loss: 2.1219 - val_acc: 0.6171\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1847 - acc: 0.9404\n",
      "Epoch 00039: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1846 - acc: 0.9404 - val_loss: 3.0080 - val_acc: 0.5488\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1863 - acc: 0.9402\n",
      "Epoch 00040: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1863 - acc: 0.9403 - val_loss: 4.9230 - val_acc: 0.4218\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1757 - acc: 0.9448\n",
      "Epoch 00041: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1757 - acc: 0.9448 - val_loss: 4.5941 - val_acc: 0.4181\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1816 - acc: 0.9412\n",
      "Epoch 00042: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1817 - acc: 0.9411 - val_loss: 1.8961 - val_acc: 0.6499\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1767 - acc: 0.9438\n",
      "Epoch 00043: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1767 - acc: 0.9438 - val_loss: 3.5718 - val_acc: 0.5078\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1712 - acc: 0.9458\n",
      "Epoch 00044: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1715 - acc: 0.9458 - val_loss: 1.7079 - val_acc: 0.6720\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1734 - acc: 0.9444\n",
      "Epoch 00045: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1734 - acc: 0.9444 - val_loss: 2.3365 - val_acc: 0.5912\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9488\n",
      "Epoch 00046: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1579 - acc: 0.9488 - val_loss: 3.0775 - val_acc: 0.5521\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1614 - acc: 0.9465\n",
      "Epoch 00047: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1615 - acc: 0.9465 - val_loss: 2.2870 - val_acc: 0.6061\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1717 - acc: 0.9431\n",
      "Epoch 00048: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1717 - acc: 0.9431 - val_loss: 4.4271 - val_acc: 0.4510\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1529 - acc: 0.9506\n",
      "Epoch 00049: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1529 - acc: 0.9506 - val_loss: 3.4884 - val_acc: 0.5556\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1530 - acc: 0.9511\n",
      "Epoch 00050: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1530 - acc: 0.9511 - val_loss: 3.4392 - val_acc: 0.4948\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1465 - acc: 0.9529\n",
      "Epoch 00051: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1465 - acc: 0.9529 - val_loss: 1.8873 - val_acc: 0.6611\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9541\n",
      "Epoch 00052: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1446 - acc: 0.9541 - val_loss: 3.0322 - val_acc: 0.5723\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9489\n",
      "Epoch 00053: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1579 - acc: 0.9489 - val_loss: 3.9690 - val_acc: 0.4929\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1315 - acc: 0.9582\n",
      "Epoch 00054: val_loss did not improve from 1.34834\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1315 - acc: 0.9582 - val_loss: 4.6648 - val_acc: 0.4382\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1443 - acc: 0.9535\n",
      "Epoch 00055: val_loss improved from 1.34834 to 1.27846, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_5_conv_checkpoint/055-1.2785.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1444 - acc: 0.9535 - val_loss: 1.2785 - val_acc: 0.7372\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1458 - acc: 0.9522\n",
      "Epoch 00056: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1459 - acc: 0.9522 - val_loss: 2.3139 - val_acc: 0.6017\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1410 - acc: 0.9538\n",
      "Epoch 00057: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1410 - acc: 0.9538 - val_loss: 3.1328 - val_acc: 0.5423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9574\n",
      "Epoch 00058: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1308 - acc: 0.9574 - val_loss: 3.6726 - val_acc: 0.4854\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1327 - acc: 0.9570\n",
      "Epoch 00059: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1327 - acc: 0.9570 - val_loss: 1.7685 - val_acc: 0.6653\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1339 - acc: 0.9591\n",
      "Epoch 00060: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1339 - acc: 0.9591 - val_loss: 1.7674 - val_acc: 0.6683\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1286 - acc: 0.9593\n",
      "Epoch 00061: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1286 - acc: 0.9594 - val_loss: 2.4236 - val_acc: 0.6329\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9584\n",
      "Epoch 00062: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1280 - acc: 0.9584 - val_loss: 2.9552 - val_acc: 0.5875\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1355 - acc: 0.9570\n",
      "Epoch 00063: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1355 - acc: 0.9570 - val_loss: 3.8325 - val_acc: 0.5132\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9597\n",
      "Epoch 00064: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1263 - acc: 0.9597 - val_loss: 2.0166 - val_acc: 0.6571\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9626\n",
      "Epoch 00065: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1208 - acc: 0.9625 - val_loss: 2.8622 - val_acc: 0.5854\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1302 - acc: 0.9590\n",
      "Epoch 00066: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1303 - acc: 0.9590 - val_loss: 2.6165 - val_acc: 0.6154\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9614\n",
      "Epoch 00067: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1239 - acc: 0.9614 - val_loss: 2.9036 - val_acc: 0.6182\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9646\n",
      "Epoch 00068: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1147 - acc: 0.9646 - val_loss: 3.5546 - val_acc: 0.5558\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1179 - acc: 0.9623\n",
      "Epoch 00069: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1179 - acc: 0.9623 - val_loss: 3.7089 - val_acc: 0.5376\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1172 - acc: 0.9622\n",
      "Epoch 00070: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1172 - acc: 0.9622 - val_loss: 2.1658 - val_acc: 0.6469\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1163 - acc: 0.9631\n",
      "Epoch 00071: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1163 - acc: 0.9631 - val_loss: 1.5640 - val_acc: 0.7156\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1107 - acc: 0.9656\n",
      "Epoch 00072: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1106 - acc: 0.9656 - val_loss: 1.7192 - val_acc: 0.6967\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1152 - acc: 0.9625\n",
      "Epoch 00073: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1152 - acc: 0.9625 - val_loss: 2.4519 - val_acc: 0.6252\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1098 - acc: 0.9663\n",
      "Epoch 00074: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1098 - acc: 0.9663 - val_loss: 1.4675 - val_acc: 0.7221\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1114 - acc: 0.9647\n",
      "Epoch 00075: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1114 - acc: 0.9647 - val_loss: 2.6135 - val_acc: 0.5891\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9663\n",
      "Epoch 00076: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1035 - acc: 0.9663 - val_loss: 2.0815 - val_acc: 0.6667\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1150 - acc: 0.9629\n",
      "Epoch 00077: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1150 - acc: 0.9629 - val_loss: 1.9372 - val_acc: 0.6755\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1106 - acc: 0.9653\n",
      "Epoch 00078: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1106 - acc: 0.9653 - val_loss: 1.5072 - val_acc: 0.7121\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9662\n",
      "Epoch 00079: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1069 - acc: 0.9662 - val_loss: 2.1295 - val_acc: 0.6539\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9665\n",
      "Epoch 00080: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1099 - acc: 0.9666 - val_loss: 2.2650 - val_acc: 0.6455\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9675\n",
      "Epoch 00081: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1023 - acc: 0.9675 - val_loss: 1.7835 - val_acc: 0.7032\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1066 - acc: 0.9666\n",
      "Epoch 00082: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1067 - acc: 0.9666 - val_loss: 2.5798 - val_acc: 0.6222\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9662\n",
      "Epoch 00083: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1060 - acc: 0.9662 - val_loss: 2.7570 - val_acc: 0.6045\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9674\n",
      "Epoch 00084: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1032 - acc: 0.9673 - val_loss: 1.9254 - val_acc: 0.6751\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9656\n",
      "Epoch 00085: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1093 - acc: 0.9656 - val_loss: 2.0770 - val_acc: 0.6606\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9708\n",
      "Epoch 00086: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0915 - acc: 0.9707 - val_loss: 2.2177 - val_acc: 0.6606\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1132 - acc: 0.9629\n",
      "Epoch 00087: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1132 - acc: 0.9629 - val_loss: 3.1045 - val_acc: 0.6054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9709\n",
      "Epoch 00088: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0928 - acc: 0.9709 - val_loss: 1.9068 - val_acc: 0.6762\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9693\n",
      "Epoch 00089: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0962 - acc: 0.9693 - val_loss: 1.3974 - val_acc: 0.7349\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9706\n",
      "Epoch 00090: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0974 - acc: 0.9706 - val_loss: 1.4033 - val_acc: 0.7468\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9702\n",
      "Epoch 00091: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0960 - acc: 0.9702 - val_loss: 1.8519 - val_acc: 0.6869\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9701\n",
      "Epoch 00092: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0974 - acc: 0.9701 - val_loss: 3.7022 - val_acc: 0.5565\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9709\n",
      "Epoch 00093: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0912 - acc: 0.9708 - val_loss: 1.6817 - val_acc: 0.7186\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1099 - acc: 0.9657\n",
      "Epoch 00094: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1099 - acc: 0.9657 - val_loss: 3.4915 - val_acc: 0.5448\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9725\n",
      "Epoch 00095: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0888 - acc: 0.9725 - val_loss: 3.5985 - val_acc: 0.5402\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0864 - acc: 0.9730\n",
      "Epoch 00096: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0864 - acc: 0.9730 - val_loss: 2.2477 - val_acc: 0.6564\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0941 - acc: 0.9709\n",
      "Epoch 00097: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0941 - acc: 0.9709 - val_loss: 2.8082 - val_acc: 0.6278\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9721\n",
      "Epoch 00098: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0896 - acc: 0.9721 - val_loss: 1.5328 - val_acc: 0.7105\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0894 - acc: 0.9719\n",
      "Epoch 00099: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0894 - acc: 0.9719 - val_loss: 3.3251 - val_acc: 0.5549\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9732\n",
      "Epoch 00100: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0868 - acc: 0.9732 - val_loss: 1.4902 - val_acc: 0.7410\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0893 - acc: 0.9721\n",
      "Epoch 00101: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0893 - acc: 0.9721 - val_loss: 2.5175 - val_acc: 0.6233\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9729\n",
      "Epoch 00102: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0906 - acc: 0.9729 - val_loss: 2.8796 - val_acc: 0.6049\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0904 - acc: 0.9721\n",
      "Epoch 00103: val_loss did not improve from 1.27846\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0904 - acc: 0.9721 - val_loss: 2.2836 - val_acc: 0.6480\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0859 - acc: 0.9730\n",
      "Epoch 00104: val_loss improved from 1.27846 to 1.25863, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_5_conv_checkpoint/104-1.2586.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0859 - acc: 0.9730 - val_loss: 1.2586 - val_acc: 0.7687\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9734\n",
      "Epoch 00105: val_loss did not improve from 1.25863\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0882 - acc: 0.9734 - val_loss: 2.6775 - val_acc: 0.6117\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9645\n",
      "Epoch 00106: val_loss improved from 1.25863 to 1.14935, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_5_conv_checkpoint/106-1.1494.hdf5\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.1248 - acc: 0.9645 - val_loss: 1.1494 - val_acc: 0.7869\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9740\n",
      "Epoch 00107: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0842 - acc: 0.9740 - val_loss: 2.0196 - val_acc: 0.6790\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9762\n",
      "Epoch 00108: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0789 - acc: 0.9763 - val_loss: 2.3433 - val_acc: 0.6448\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9754\n",
      "Epoch 00109: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0795 - acc: 0.9754 - val_loss: 2.9530 - val_acc: 0.6289\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9734\n",
      "Epoch 00110: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0885 - acc: 0.9734 - val_loss: 3.6867 - val_acc: 0.5623\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9736\n",
      "Epoch 00111: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0848 - acc: 0.9736 - val_loss: 1.4223 - val_acc: 0.7468\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9723\n",
      "Epoch 00112: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0885 - acc: 0.9723 - val_loss: 1.2817 - val_acc: 0.7710\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0854 - acc: 0.9741\n",
      "Epoch 00113: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0855 - acc: 0.9741 - val_loss: 3.2626 - val_acc: 0.5884\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9718\n",
      "Epoch 00114: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0896 - acc: 0.9718 - val_loss: 1.9071 - val_acc: 0.6858\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9761\n",
      "Epoch 00115: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0780 - acc: 0.9761 - val_loss: 2.0966 - val_acc: 0.6732\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0751 - acc: 0.9770\n",
      "Epoch 00116: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0751 - acc: 0.9770 - val_loss: 1.4063 - val_acc: 0.7524\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0820 - acc: 0.9746\n",
      "Epoch 00117: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0820 - acc: 0.9747 - val_loss: 1.3045 - val_acc: 0.7666\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9776\n",
      "Epoch 00118: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0757 - acc: 0.9776 - val_loss: 1.9810 - val_acc: 0.6897\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9766\n",
      "Epoch 00119: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0763 - acc: 0.9766 - val_loss: 3.6130 - val_acc: 0.5842\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9744\n",
      "Epoch 00120: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0798 - acc: 0.9744 - val_loss: 2.8932 - val_acc: 0.6115\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9762\n",
      "Epoch 00121: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0773 - acc: 0.9762 - val_loss: 1.6004 - val_acc: 0.7293\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9756\n",
      "Epoch 00122: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0777 - acc: 0.9756 - val_loss: 2.4521 - val_acc: 0.6408\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0780 - acc: 0.9754\n",
      "Epoch 00123: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0781 - acc: 0.9753 - val_loss: 1.3498 - val_acc: 0.7673\n",
      "Epoch 124/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9759\n",
      "Epoch 00124: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0759 - acc: 0.9759 - val_loss: 3.8662 - val_acc: 0.5406\n",
      "Epoch 125/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9761\n",
      "Epoch 00125: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0803 - acc: 0.9761 - val_loss: 1.8097 - val_acc: 0.7037\n",
      "Epoch 126/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0786 - acc: 0.9762\n",
      "Epoch 00126: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0785 - acc: 0.9762 - val_loss: 3.5737 - val_acc: 0.5786\n",
      "Epoch 127/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9780\n",
      "Epoch 00127: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0698 - acc: 0.9780 - val_loss: 3.5207 - val_acc: 0.5768\n",
      "Epoch 128/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0730 - acc: 0.9778\n",
      "Epoch 00128: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0730 - acc: 0.9778 - val_loss: 3.0888 - val_acc: 0.6017\n",
      "Epoch 129/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0754 - acc: 0.9779\n",
      "Epoch 00129: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0754 - acc: 0.9779 - val_loss: 2.6679 - val_acc: 0.6329\n",
      "Epoch 130/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9792\n",
      "Epoch 00130: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0689 - acc: 0.9792 - val_loss: 2.7965 - val_acc: 0.6198\n",
      "Epoch 131/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0701 - acc: 0.9787\n",
      "Epoch 00131: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0701 - acc: 0.9787 - val_loss: 1.7860 - val_acc: 0.7140\n",
      "Epoch 132/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0724 - acc: 0.9774\n",
      "Epoch 00132: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0725 - acc: 0.9774 - val_loss: 1.5837 - val_acc: 0.7382\n",
      "Epoch 133/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0755 - acc: 0.9769\n",
      "Epoch 00133: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0755 - acc: 0.9769 - val_loss: 1.9072 - val_acc: 0.6972\n",
      "Epoch 134/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9790\n",
      "Epoch 00134: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0721 - acc: 0.9790 - val_loss: 1.7447 - val_acc: 0.7191\n",
      "Epoch 135/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0838 - acc: 0.9742\n",
      "Epoch 00135: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0839 - acc: 0.9742 - val_loss: 1.3360 - val_acc: 0.7638\n",
      "Epoch 136/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0689 - acc: 0.9784\n",
      "Epoch 00136: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0689 - acc: 0.9784 - val_loss: 2.7395 - val_acc: 0.6352\n",
      "Epoch 137/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9779\n",
      "Epoch 00137: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0718 - acc: 0.9779 - val_loss: 2.1838 - val_acc: 0.6716\n",
      "Epoch 138/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9771\n",
      "Epoch 00138: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0763 - acc: 0.9771 - val_loss: 2.1955 - val_acc: 0.6751\n",
      "Epoch 139/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0707 - acc: 0.9786\n",
      "Epoch 00139: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0707 - acc: 0.9786 - val_loss: 1.5429 - val_acc: 0.7265\n",
      "Epoch 140/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0669 - acc: 0.9800\n",
      "Epoch 00140: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0669 - acc: 0.9800 - val_loss: 3.3671 - val_acc: 0.5814\n",
      "Epoch 141/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0758 - acc: 0.9772\n",
      "Epoch 00141: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0758 - acc: 0.9772 - val_loss: 1.6518 - val_acc: 0.7382\n",
      "Epoch 142/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0744 - acc: 0.9778\n",
      "Epoch 00142: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0744 - acc: 0.9778 - val_loss: 2.1899 - val_acc: 0.6706\n",
      "Epoch 143/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9801\n",
      "Epoch 00143: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0639 - acc: 0.9801 - val_loss: 3.4209 - val_acc: 0.5924\n",
      "Epoch 144/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0660 - acc: 0.9800\n",
      "Epoch 00144: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0661 - acc: 0.9800 - val_loss: 1.9217 - val_acc: 0.7060\n",
      "Epoch 145/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9771\n",
      "Epoch 00145: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0773 - acc: 0.9771 - val_loss: 1.6347 - val_acc: 0.7314\n",
      "Epoch 146/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9801\n",
      "Epoch 00146: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0686 - acc: 0.9801 - val_loss: 1.6183 - val_acc: 0.7300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0616 - acc: 0.9816\n",
      "Epoch 00147: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0616 - acc: 0.9816 - val_loss: 1.6837 - val_acc: 0.7216\n",
      "Epoch 148/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9794\n",
      "Epoch 00148: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0682 - acc: 0.9794 - val_loss: 2.2249 - val_acc: 0.6858\n",
      "Epoch 149/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0656 - acc: 0.9806\n",
      "Epoch 00149: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0656 - acc: 0.9806 - val_loss: 1.8105 - val_acc: 0.7219\n",
      "Epoch 150/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0736 - acc: 0.9775\n",
      "Epoch 00150: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0737 - acc: 0.9774 - val_loss: 2.5000 - val_acc: 0.6702\n",
      "Epoch 151/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0761 - acc: 0.9762\n",
      "Epoch 00151: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0761 - acc: 0.9763 - val_loss: 2.3256 - val_acc: 0.6685\n",
      "Epoch 152/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9814\n",
      "Epoch 00152: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0632 - acc: 0.9814 - val_loss: 1.4330 - val_acc: 0.7666\n",
      "Epoch 153/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9780\n",
      "Epoch 00153: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0733 - acc: 0.9779 - val_loss: 2.8562 - val_acc: 0.6282\n",
      "Epoch 154/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0722 - acc: 0.9790\n",
      "Epoch 00154: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0722 - acc: 0.9791 - val_loss: 2.6247 - val_acc: 0.6490\n",
      "Epoch 155/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9801\n",
      "Epoch 00155: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0681 - acc: 0.9801 - val_loss: 1.3911 - val_acc: 0.7666\n",
      "Epoch 156/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0682 - acc: 0.9798\n",
      "Epoch 00156: val_loss did not improve from 1.14935\n",
      "36805/36805 [==============================] - 163s 4ms/sample - loss: 0.0682 - acc: 0.9798 - val_loss: 1.5646 - val_acc: 0.7445\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_5_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 1.3499 - acc: 0.7481\n",
      "Loss: 1.3499332119742657 Accuracy: 0.74807894\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.2138 - acc: 0.3299\n",
      "Epoch 00001: val_loss improved from inf to 1.65098, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_6_conv_checkpoint/001-1.6510.hdf5\n",
      "36805/36805 [==============================] - 188s 5ms/sample - loss: 2.2137 - acc: 0.3300 - val_loss: 1.6510 - val_acc: 0.4617\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.5767 - acc: 0.5095\n",
      "Epoch 00002: val_loss did not improve from 1.65098\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 1.5770 - acc: 0.5095 - val_loss: 2.7413 - val_acc: 0.3375\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3039 - acc: 0.5960\n",
      "Epoch 00003: val_loss did not improve from 1.65098\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 1.3040 - acc: 0.5960 - val_loss: 3.8928 - val_acc: 0.3350\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1401 - acc: 0.6475\n",
      "Epoch 00004: val_loss did not improve from 1.65098\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 1.1402 - acc: 0.6475 - val_loss: 2.9301 - val_acc: 0.4272\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0209 - acc: 0.6849\n",
      "Epoch 00005: val_loss improved from 1.65098 to 1.19748, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_6_conv_checkpoint/005-1.1975.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 1.0210 - acc: 0.6849 - val_loss: 1.1975 - val_acc: 0.6504\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9332 - acc: 0.7161\n",
      "Epoch 00006: val_loss did not improve from 1.19748\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.9332 - acc: 0.7161 - val_loss: 1.5001 - val_acc: 0.6033\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8705 - acc: 0.7371\n",
      "Epoch 00007: val_loss did not improve from 1.19748\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.8704 - acc: 0.7372 - val_loss: 1.2964 - val_acc: 0.6413\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8148 - acc: 0.7533\n",
      "Epoch 00008: val_loss did not improve from 1.19748\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.8147 - acc: 0.7533 - val_loss: 1.3395 - val_acc: 0.6334\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7700 - acc: 0.7682\n",
      "Epoch 00009: val_loss improved from 1.19748 to 0.95354, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_6_conv_checkpoint/009-0.9535.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.7700 - acc: 0.7681 - val_loss: 0.9535 - val_acc: 0.7265\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7320 - acc: 0.7779\n",
      "Epoch 00010: val_loss did not improve from 0.95354\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.7321 - acc: 0.7778 - val_loss: 1.6581 - val_acc: 0.5597\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6939 - acc: 0.7891\n",
      "Epoch 00011: val_loss improved from 0.95354 to 0.92510, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_6_conv_checkpoint/011-0.9251.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.6941 - acc: 0.7891 - val_loss: 0.9251 - val_acc: 0.7452\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6638 - acc: 0.8007\n",
      "Epoch 00012: val_loss did not improve from 0.92510\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.6640 - acc: 0.8006 - val_loss: 1.4153 - val_acc: 0.6380\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6462 - acc: 0.8065\n",
      "Epoch 00013: val_loss did not improve from 0.92510\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.6462 - acc: 0.8065 - val_loss: 2.0040 - val_acc: 0.5285\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6148 - acc: 0.8152\n",
      "Epoch 00014: val_loss did not improve from 0.92510\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.6148 - acc: 0.8152 - val_loss: 1.1518 - val_acc: 0.6962\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5943 - acc: 0.8204\n",
      "Epoch 00015: val_loss did not improve from 0.92510\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.5944 - acc: 0.8204 - val_loss: 2.6835 - val_acc: 0.4386\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5769 - acc: 0.8243\n",
      "Epoch 00016: val_loss did not improve from 0.92510\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.5770 - acc: 0.8242 - val_loss: 2.7568 - val_acc: 0.4729\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5565 - acc: 0.8325\n",
      "Epoch 00017: val_loss did not improve from 0.92510\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.5565 - acc: 0.8325 - val_loss: 2.2855 - val_acc: 0.4880\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5336 - acc: 0.8401\n",
      "Epoch 00018: val_loss did not improve from 0.92510\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.5336 - acc: 0.8400 - val_loss: 0.9915 - val_acc: 0.7149\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5176 - acc: 0.8419\n",
      "Epoch 00019: val_loss did not improve from 0.92510\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.5178 - acc: 0.8418 - val_loss: 1.2210 - val_acc: 0.6674\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4924 - acc: 0.8501\n",
      "Epoch 00020: val_loss did not improve from 0.92510\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.4925 - acc: 0.8500 - val_loss: 1.5316 - val_acc: 0.6136\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4840 - acc: 0.8529\n",
      "Epoch 00021: val_loss improved from 0.92510 to 0.80168, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_6_conv_checkpoint/021-0.8017.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.4840 - acc: 0.8529 - val_loss: 0.8017 - val_acc: 0.7731\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4662 - acc: 0.8595\n",
      "Epoch 00022: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.4662 - acc: 0.8595 - val_loss: 2.3507 - val_acc: 0.5404\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4477 - acc: 0.8630\n",
      "Epoch 00023: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.4477 - acc: 0.8630 - val_loss: 1.5813 - val_acc: 0.6476\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4450 - acc: 0.8611\n",
      "Epoch 00024: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.4451 - acc: 0.8611 - val_loss: 0.8900 - val_acc: 0.7505\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4318 - acc: 0.8673\n",
      "Epoch 00025: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.4319 - acc: 0.8672 - val_loss: 1.5730 - val_acc: 0.6424\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4164 - acc: 0.8734\n",
      "Epoch 00026: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.4164 - acc: 0.8734 - val_loss: 1.2510 - val_acc: 0.6946\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3983 - acc: 0.8780\n",
      "Epoch 00027: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.3983 - acc: 0.8780 - val_loss: 0.8605 - val_acc: 0.7685\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3916 - acc: 0.8805\n",
      "Epoch 00028: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.3916 - acc: 0.8805 - val_loss: 1.0746 - val_acc: 0.7265\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3791 - acc: 0.8817\n",
      "Epoch 00029: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.3790 - acc: 0.8817 - val_loss: 1.8903 - val_acc: 0.6191\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3667 - acc: 0.8880\n",
      "Epoch 00030: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.3667 - acc: 0.8880 - val_loss: 2.1277 - val_acc: 0.5945\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3609 - acc: 0.8885\n",
      "Epoch 00031: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.3610 - acc: 0.8885 - val_loss: 2.0287 - val_acc: 0.5667\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3438 - acc: 0.8940\n",
      "Epoch 00032: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.3441 - acc: 0.8939 - val_loss: 1.8196 - val_acc: 0.5912\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3473 - acc: 0.8920\n",
      "Epoch 00033: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.3473 - acc: 0.8920 - val_loss: 2.2157 - val_acc: 0.5884\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3301 - acc: 0.8986\n",
      "Epoch 00034: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.3301 - acc: 0.8987 - val_loss: 2.5442 - val_acc: 0.4948\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3168 - acc: 0.9018\n",
      "Epoch 00035: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.3168 - acc: 0.9018 - val_loss: 1.0871 - val_acc: 0.7205\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3145 - acc: 0.9020\n",
      "Epoch 00036: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.3147 - acc: 0.9019 - val_loss: 2.0261 - val_acc: 0.5644\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3155 - acc: 0.9028\n",
      "Epoch 00037: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.3155 - acc: 0.9028 - val_loss: 1.5816 - val_acc: 0.6580\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2927 - acc: 0.9080\n",
      "Epoch 00038: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2927 - acc: 0.9080 - val_loss: 0.8299 - val_acc: 0.7764\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2889 - acc: 0.9091\n",
      "Epoch 00039: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2889 - acc: 0.9091 - val_loss: 1.1186 - val_acc: 0.7077\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2891 - acc: 0.9079\n",
      "Epoch 00040: val_loss did not improve from 0.80168\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2892 - acc: 0.9079 - val_loss: 0.9528 - val_acc: 0.7431\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2827 - acc: 0.9100\n",
      "Epoch 00041: val_loss improved from 0.80168 to 0.77185, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_6_conv_checkpoint/041-0.7718.hdf5\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2828 - acc: 0.9100 - val_loss: 0.7718 - val_acc: 0.7934\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2779 - acc: 0.9134\n",
      "Epoch 00042: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2780 - acc: 0.9134 - val_loss: 1.5070 - val_acc: 0.6597\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2681 - acc: 0.9151\n",
      "Epoch 00043: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2685 - acc: 0.9151 - val_loss: 1.2670 - val_acc: 0.6944\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2697 - acc: 0.9156\n",
      "Epoch 00044: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2697 - acc: 0.9156 - val_loss: 0.8746 - val_acc: 0.7696\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2434 - acc: 0.9230\n",
      "Epoch 00045: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2436 - acc: 0.9230 - val_loss: 1.4044 - val_acc: 0.6946\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2526 - acc: 0.9212\n",
      "Epoch 00046: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2526 - acc: 0.9212 - val_loss: 1.4411 - val_acc: 0.6841\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2394 - acc: 0.9248\n",
      "Epoch 00047: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2394 - acc: 0.9248 - val_loss: 1.6869 - val_acc: 0.6548\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2448 - acc: 0.9223\n",
      "Epoch 00048: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2448 - acc: 0.9222 - val_loss: 0.8253 - val_acc: 0.7843\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2245 - acc: 0.9292\n",
      "Epoch 00049: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2245 - acc: 0.9292 - val_loss: 2.3696 - val_acc: 0.5775\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2215 - acc: 0.9302\n",
      "Epoch 00050: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2216 - acc: 0.9302 - val_loss: 1.2832 - val_acc: 0.7105\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2248 - acc: 0.9287\n",
      "Epoch 00051: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2248 - acc: 0.9287 - val_loss: 1.8250 - val_acc: 0.6497\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2150 - acc: 0.9327\n",
      "Epoch 00052: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2150 - acc: 0.9328 - val_loss: 1.1486 - val_acc: 0.7256\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2129 - acc: 0.9325\n",
      "Epoch 00053: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2133 - acc: 0.9325 - val_loss: 1.9864 - val_acc: 0.6285\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2014 - acc: 0.9374\n",
      "Epoch 00054: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2015 - acc: 0.9374 - val_loss: 1.0410 - val_acc: 0.7545\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2134 - acc: 0.9320\n",
      "Epoch 00055: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2133 - acc: 0.9320 - val_loss: 0.8993 - val_acc: 0.7785\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2053 - acc: 0.9348\n",
      "Epoch 00056: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2054 - acc: 0.9348 - val_loss: 0.9943 - val_acc: 0.7673\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2046 - acc: 0.9356\n",
      "Epoch 00057: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.2046 - acc: 0.9356 - val_loss: 0.9850 - val_acc: 0.7696\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1913 - acc: 0.9389\n",
      "Epoch 00058: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1913 - acc: 0.9389 - val_loss: 0.7753 - val_acc: 0.8088\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1858 - acc: 0.9416\n",
      "Epoch 00059: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1858 - acc: 0.9416 - val_loss: 1.3305 - val_acc: 0.7119\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1874 - acc: 0.9395\n",
      "Epoch 00060: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1875 - acc: 0.9394 - val_loss: 1.2789 - val_acc: 0.7188\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1914 - acc: 0.9383\n",
      "Epoch 00061: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1914 - acc: 0.9383 - val_loss: 1.0334 - val_acc: 0.7575\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1750 - acc: 0.9455\n",
      "Epoch 00062: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1750 - acc: 0.9455 - val_loss: 1.4381 - val_acc: 0.6601\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1774 - acc: 0.9434\n",
      "Epoch 00063: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1774 - acc: 0.9434 - val_loss: 1.4565 - val_acc: 0.7200\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1719 - acc: 0.9445\n",
      "Epoch 00064: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1720 - acc: 0.9444 - val_loss: 1.0711 - val_acc: 0.7482\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9425\n",
      "Epoch 00065: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1805 - acc: 0.9425 - val_loss: 2.2310 - val_acc: 0.6068\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1741 - acc: 0.9444\n",
      "Epoch 00066: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1742 - acc: 0.9444 - val_loss: 0.9109 - val_acc: 0.7778\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1703 - acc: 0.9458\n",
      "Epoch 00067: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1704 - acc: 0.9458 - val_loss: 0.8379 - val_acc: 0.7936\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1758 - acc: 0.9429\n",
      "Epoch 00068: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1760 - acc: 0.9429 - val_loss: 0.8172 - val_acc: 0.7978\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1728 - acc: 0.9458\n",
      "Epoch 00069: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1728 - acc: 0.9458 - val_loss: 3.0467 - val_acc: 0.5462\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1521 - acc: 0.9508\n",
      "Epoch 00070: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1521 - acc: 0.9508 - val_loss: 1.4144 - val_acc: 0.7023\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1491 - acc: 0.9532\n",
      "Epoch 00071: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1491 - acc: 0.9531 - val_loss: 1.0435 - val_acc: 0.7682\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9499\n",
      "Epoch 00072: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1535 - acc: 0.9500 - val_loss: 1.5192 - val_acc: 0.6995\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9545\n",
      "Epoch 00073: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1450 - acc: 0.9545 - val_loss: 0.9295 - val_acc: 0.7803\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1500 - acc: 0.9525\n",
      "Epoch 00074: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1500 - acc: 0.9525 - val_loss: 1.1788 - val_acc: 0.7519\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1600 - acc: 0.9496\n",
      "Epoch 00075: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1601 - acc: 0.9495 - val_loss: 1.4477 - val_acc: 0.7058\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9514\n",
      "Epoch 00076: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1468 - acc: 0.9514 - val_loss: 1.6642 - val_acc: 0.6853\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9551\n",
      "Epoch 00077: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1409 - acc: 0.9551 - val_loss: 1.3304 - val_acc: 0.7112\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1364 - acc: 0.9569\n",
      "Epoch 00078: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1364 - acc: 0.9569 - val_loss: 1.5891 - val_acc: 0.6858\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1375 - acc: 0.9558\n",
      "Epoch 00079: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1375 - acc: 0.9558 - val_loss: 1.1906 - val_acc: 0.7561\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9539\n",
      "Epoch 00080: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1446 - acc: 0.9539 - val_loss: 0.9914 - val_acc: 0.7741\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1383 - acc: 0.9554\n",
      "Epoch 00081: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1384 - acc: 0.9553 - val_loss: 0.8450 - val_acc: 0.8008\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9557\n",
      "Epoch 00082: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1372 - acc: 0.9556 - val_loss: 1.0726 - val_acc: 0.7643\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1479 - acc: 0.9525\n",
      "Epoch 00083: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1479 - acc: 0.9525 - val_loss: 0.9017 - val_acc: 0.7885\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1199 - acc: 0.9623\n",
      "Epoch 00084: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1201 - acc: 0.9622 - val_loss: 1.2431 - val_acc: 0.7372\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1387 - acc: 0.9546\n",
      "Epoch 00085: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1387 - acc: 0.9547 - val_loss: 1.0825 - val_acc: 0.7768\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9609\n",
      "Epoch 00086: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1213 - acc: 0.9609 - val_loss: 1.9509 - val_acc: 0.6727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9600\n",
      "Epoch 00087: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1245 - acc: 0.9600 - val_loss: 2.0572 - val_acc: 0.6490\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1259 - acc: 0.9589\n",
      "Epoch 00088: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1259 - acc: 0.9589 - val_loss: 1.4689 - val_acc: 0.7018\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9622\n",
      "Epoch 00089: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1187 - acc: 0.9622 - val_loss: 1.4581 - val_acc: 0.7135\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1201 - acc: 0.9606\n",
      "Epoch 00090: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1201 - acc: 0.9606 - val_loss: 1.3601 - val_acc: 0.7275\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1213 - acc: 0.9604\n",
      "Epoch 00091: val_loss did not improve from 0.77185\n",
      "36805/36805 [==============================] - 166s 5ms/sample - loss: 0.1214 - acc: 0.9604 - val_loss: 1.3896 - val_acc: 0.7156\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_6_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.8908 - acc: 0.7666\n",
      "Loss: 0.8907650150861571 Accuracy: 0.7665628\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3231 - acc: 0.2915\n",
      "Epoch 00001: val_loss improved from inf to 1.89036, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_7_conv_checkpoint/001-1.8904.hdf5\n",
      "36805/36805 [==============================] - 200s 5ms/sample - loss: 2.3230 - acc: 0.2915 - val_loss: 1.8904 - val_acc: 0.4267\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6374 - acc: 0.4858\n",
      "Epoch 00002: val_loss did not improve from 1.89036\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 1.6374 - acc: 0.4858 - val_loss: 1.9912 - val_acc: 0.4344\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.3596 - acc: 0.5729\n",
      "Epoch 00003: val_loss did not improve from 1.89036\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 1.3595 - acc: 0.5729 - val_loss: 2.0932 - val_acc: 0.4368\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.1686 - acc: 0.6410\n",
      "Epoch 00004: val_loss improved from 1.89036 to 1.86354, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_7_conv_checkpoint/004-1.8635.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 1.1686 - acc: 0.6410 - val_loss: 1.8635 - val_acc: 0.4978\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0274 - acc: 0.6851\n",
      "Epoch 00005: val_loss improved from 1.86354 to 0.90181, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_7_conv_checkpoint/005-0.9018.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 1.0274 - acc: 0.6851 - val_loss: 0.9018 - val_acc: 0.7261\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.9345 - acc: 0.7165\n",
      "Epoch 00006: val_loss did not improve from 0.90181\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.9345 - acc: 0.7165 - val_loss: 0.9524 - val_acc: 0.7181\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8601 - acc: 0.7400\n",
      "Epoch 00007: val_loss did not improve from 0.90181\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.8602 - acc: 0.7399 - val_loss: 1.0212 - val_acc: 0.6953\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7980 - acc: 0.7614\n",
      "Epoch 00008: val_loss did not improve from 0.90181\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.7980 - acc: 0.7614 - val_loss: 1.4832 - val_acc: 0.6287\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7385 - acc: 0.7809\n",
      "Epoch 00009: val_loss did not improve from 0.90181\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.7384 - acc: 0.7809 - val_loss: 1.1108 - val_acc: 0.7016\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6897 - acc: 0.7929\n",
      "Epoch 00010: val_loss did not improve from 0.90181\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.6897 - acc: 0.7929 - val_loss: 1.2096 - val_acc: 0.6702\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6522 - acc: 0.8040\n",
      "Epoch 00011: val_loss did not improve from 0.90181\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.6521 - acc: 0.8040 - val_loss: 1.4848 - val_acc: 0.6310\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6127 - acc: 0.8187\n",
      "Epoch 00012: val_loss improved from 0.90181 to 0.76725, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_7_conv_checkpoint/012-0.7672.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.6127 - acc: 0.8187 - val_loss: 0.7672 - val_acc: 0.7866\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5792 - acc: 0.8303\n",
      "Epoch 00013: val_loss did not improve from 0.76725\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.5792 - acc: 0.8303 - val_loss: 0.8068 - val_acc: 0.7673\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5504 - acc: 0.8390\n",
      "Epoch 00014: val_loss did not improve from 0.76725\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.5504 - acc: 0.8390 - val_loss: 1.2574 - val_acc: 0.6797\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5233 - acc: 0.8477\n",
      "Epoch 00015: val_loss did not improve from 0.76725\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.5234 - acc: 0.8477 - val_loss: 0.8200 - val_acc: 0.7759\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4988 - acc: 0.8539\n",
      "Epoch 00016: val_loss did not improve from 0.76725\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.4989 - acc: 0.8538 - val_loss: 1.5441 - val_acc: 0.6543\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4718 - acc: 0.8613\n",
      "Epoch 00017: val_loss did not improve from 0.76725\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.4718 - acc: 0.8613 - val_loss: 0.9144 - val_acc: 0.7461\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4466 - acc: 0.8682\n",
      "Epoch 00018: val_loss did not improve from 0.76725\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.4466 - acc: 0.8682 - val_loss: 1.2728 - val_acc: 0.6683\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4276 - acc: 0.8746\n",
      "Epoch 00019: val_loss did not improve from 0.76725\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.4277 - acc: 0.8746 - val_loss: 0.9920 - val_acc: 0.7447\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4125 - acc: 0.8788\n",
      "Epoch 00020: val_loss did not improve from 0.76725\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.4124 - acc: 0.8788 - val_loss: 1.4510 - val_acc: 0.6252\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3944 - acc: 0.8836\n",
      "Epoch 00021: val_loss did not improve from 0.76725\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.3944 - acc: 0.8837 - val_loss: 2.0029 - val_acc: 0.6233\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3764 - acc: 0.8896\n",
      "Epoch 00022: val_loss improved from 0.76725 to 0.57349, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_7_conv_checkpoint/022-0.5735.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.3765 - acc: 0.8895 - val_loss: 0.5735 - val_acc: 0.8344\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3642 - acc: 0.8929\n",
      "Epoch 00023: val_loss did not improve from 0.57349\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.3641 - acc: 0.8929 - val_loss: 1.0199 - val_acc: 0.7473\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3476 - acc: 0.8964\n",
      "Epoch 00024: val_loss did not improve from 0.57349\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.3477 - acc: 0.8963 - val_loss: 1.3221 - val_acc: 0.6741\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3357 - acc: 0.9008\n",
      "Epoch 00025: val_loss did not improve from 0.57349\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.3358 - acc: 0.9008 - val_loss: 1.0511 - val_acc: 0.7214\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3286 - acc: 0.9032\n",
      "Epoch 00026: val_loss did not improve from 0.57349\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.3286 - acc: 0.9032 - val_loss: 0.9765 - val_acc: 0.7368\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3092 - acc: 0.9091\n",
      "Epoch 00027: val_loss did not improve from 0.57349\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.3092 - acc: 0.9091 - val_loss: 1.7947 - val_acc: 0.6247\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2963 - acc: 0.9110\n",
      "Epoch 00028: val_loss did not improve from 0.57349\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2963 - acc: 0.9110 - val_loss: 0.9123 - val_acc: 0.7803\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2918 - acc: 0.9136\n",
      "Epoch 00029: val_loss did not improve from 0.57349\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2919 - acc: 0.9135 - val_loss: 2.7934 - val_acc: 0.5402\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2828 - acc: 0.9149\n",
      "Epoch 00030: val_loss did not improve from 0.57349\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2828 - acc: 0.9149 - val_loss: 0.6143 - val_acc: 0.8379\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2682 - acc: 0.9200\n",
      "Epoch 00031: val_loss improved from 0.57349 to 0.49098, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_7_conv_checkpoint/031-0.4910.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2683 - acc: 0.9200 - val_loss: 0.4910 - val_acc: 0.8668\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2657 - acc: 0.9207\n",
      "Epoch 00032: val_loss did not improve from 0.49098\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2657 - acc: 0.9206 - val_loss: 2.7489 - val_acc: 0.5132\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2533 - acc: 0.9227\n",
      "Epoch 00033: val_loss improved from 0.49098 to 0.44972, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_7_conv_checkpoint/033-0.4497.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2534 - acc: 0.9226 - val_loss: 0.4497 - val_acc: 0.8714\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2482 - acc: 0.9260\n",
      "Epoch 00034: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2483 - acc: 0.9259 - val_loss: 0.8386 - val_acc: 0.7964\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2376 - acc: 0.9285\n",
      "Epoch 00035: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2375 - acc: 0.9285 - val_loss: 2.3138 - val_acc: 0.5975\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.9304\n",
      "Epoch 00036: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2285 - acc: 0.9303 - val_loss: 0.6321 - val_acc: 0.8372\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2193 - acc: 0.9335\n",
      "Epoch 00037: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2193 - acc: 0.9335 - val_loss: 0.6547 - val_acc: 0.8332\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2124 - acc: 0.9353\n",
      "Epoch 00038: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2125 - acc: 0.9353 - val_loss: 0.4953 - val_acc: 0.8609\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9360\n",
      "Epoch 00039: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2117 - acc: 0.9360 - val_loss: 0.6024 - val_acc: 0.8444\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2064 - acc: 0.9372\n",
      "Epoch 00040: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.2064 - acc: 0.9372 - val_loss: 1.2690 - val_acc: 0.7237\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1979 - acc: 0.9384\n",
      "Epoch 00041: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1979 - acc: 0.9384 - val_loss: 1.1346 - val_acc: 0.7403\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1920 - acc: 0.9415\n",
      "Epoch 00042: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1920 - acc: 0.9416 - val_loss: 1.3624 - val_acc: 0.7230\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1835 - acc: 0.9439\n",
      "Epoch 00043: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1835 - acc: 0.9439 - val_loss: 1.1067 - val_acc: 0.7540\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9444\n",
      "Epoch 00044: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1820 - acc: 0.9444 - val_loss: 1.4888 - val_acc: 0.6709\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1764 - acc: 0.9454\n",
      "Epoch 00045: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1764 - acc: 0.9454 - val_loss: 1.4089 - val_acc: 0.7361\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1683 - acc: 0.9482\n",
      "Epoch 00046: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1683 - acc: 0.9482 - val_loss: 0.6262 - val_acc: 0.8425\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1626 - acc: 0.9505\n",
      "Epoch 00047: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1626 - acc: 0.9506 - val_loss: 0.9129 - val_acc: 0.7803\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1640 - acc: 0.9496\n",
      "Epoch 00048: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1641 - acc: 0.9496 - val_loss: 0.9637 - val_acc: 0.7664\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1557 - acc: 0.9521\n",
      "Epoch 00049: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1556 - acc: 0.9521 - val_loss: 0.4902 - val_acc: 0.8682\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1532 - acc: 0.9520\n",
      "Epoch 00050: val_loss did not improve from 0.44972\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1534 - acc: 0.9520 - val_loss: 1.2272 - val_acc: 0.7223\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1551 - acc: 0.9522\n",
      "Epoch 00051: val_loss improved from 0.44972 to 0.44837, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_7_conv_checkpoint/051-0.4484.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1551 - acc: 0.9522 - val_loss: 0.4484 - val_acc: 0.8810\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1446 - acc: 0.9554\n",
      "Epoch 00052: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1446 - acc: 0.9554 - val_loss: 0.6723 - val_acc: 0.8430\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1430 - acc: 0.9564\n",
      "Epoch 00053: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1429 - acc: 0.9564 - val_loss: 1.0296 - val_acc: 0.7827\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1308 - acc: 0.9596\n",
      "Epoch 00054: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1308 - acc: 0.9595 - val_loss: 0.6865 - val_acc: 0.8316\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9590\n",
      "Epoch 00055: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1363 - acc: 0.9590 - val_loss: 1.3011 - val_acc: 0.7242\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1313 - acc: 0.9598\n",
      "Epoch 00056: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1313 - acc: 0.9598 - val_loss: 0.5951 - val_acc: 0.8507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1276 - acc: 0.9610\n",
      "Epoch 00057: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1278 - acc: 0.9609 - val_loss: 0.6613 - val_acc: 0.8330\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1366 - acc: 0.9564\n",
      "Epoch 00058: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1366 - acc: 0.9564 - val_loss: 0.4810 - val_acc: 0.8798\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1197 - acc: 0.9637\n",
      "Epoch 00059: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1197 - acc: 0.9637 - val_loss: 0.8349 - val_acc: 0.8134\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1194 - acc: 0.9628\n",
      "Epoch 00060: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1194 - acc: 0.9628 - val_loss: 0.6618 - val_acc: 0.8470\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1175 - acc: 0.9639\n",
      "Epoch 00061: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1175 - acc: 0.9639 - val_loss: 2.2470 - val_acc: 0.6534\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1208 - acc: 0.9625\n",
      "Epoch 00062: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1208 - acc: 0.9625 - val_loss: 0.8987 - val_acc: 0.7911\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9653\n",
      "Epoch 00063: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1100 - acc: 0.9653 - val_loss: 1.0054 - val_acc: 0.7747\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1142 - acc: 0.9645\n",
      "Epoch 00064: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1142 - acc: 0.9645 - val_loss: 0.6480 - val_acc: 0.8495\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1073 - acc: 0.9672\n",
      "Epoch 00065: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1073 - acc: 0.9672 - val_loss: 0.4579 - val_acc: 0.8770\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1041 - acc: 0.9685\n",
      "Epoch 00066: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1041 - acc: 0.9685 - val_loss: 0.9130 - val_acc: 0.8095\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9669\n",
      "Epoch 00067: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1043 - acc: 0.9669 - val_loss: 0.6704 - val_acc: 0.8437\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1080 - acc: 0.9671\n",
      "Epoch 00068: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1080 - acc: 0.9671 - val_loss: 0.4770 - val_acc: 0.8894\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1117 - acc: 0.9661\n",
      "Epoch 00069: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1116 - acc: 0.9661 - val_loss: 0.9027 - val_acc: 0.7962\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9712\n",
      "Epoch 00070: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0927 - acc: 0.9712 - val_loss: 1.0501 - val_acc: 0.7817\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9701\n",
      "Epoch 00071: val_loss did not improve from 0.44837\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0981 - acc: 0.9701 - val_loss: 0.6103 - val_acc: 0.8572\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9732\n",
      "Epoch 00072: val_loss improved from 0.44837 to 0.41917, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_7_conv_checkpoint/072-0.4192.hdf5\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0886 - acc: 0.9732 - val_loss: 0.4192 - val_acc: 0.8949\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0905 - acc: 0.9714\n",
      "Epoch 00073: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0905 - acc: 0.9714 - val_loss: 1.4576 - val_acc: 0.7407\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9728\n",
      "Epoch 00074: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0892 - acc: 0.9728 - val_loss: 1.3231 - val_acc: 0.7531\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0819 - acc: 0.9758\n",
      "Epoch 00075: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0822 - acc: 0.9757 - val_loss: 1.0404 - val_acc: 0.7650\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9687\n",
      "Epoch 00076: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.1019 - acc: 0.9686 - val_loss: 1.2235 - val_acc: 0.7494\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0996 - acc: 0.9691\n",
      "Epoch 00077: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0996 - acc: 0.9691 - val_loss: 0.9596 - val_acc: 0.8048\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0866 - acc: 0.9729\n",
      "Epoch 00078: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0866 - acc: 0.9729 - val_loss: 0.7041 - val_acc: 0.8344\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0697 - acc: 0.9796\n",
      "Epoch 00079: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0697 - acc: 0.9796 - val_loss: 0.4935 - val_acc: 0.8784\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9756\n",
      "Epoch 00080: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0805 - acc: 0.9755 - val_loss: 0.7838 - val_acc: 0.8332\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9746\n",
      "Epoch 00081: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0841 - acc: 0.9746 - val_loss: 0.8681 - val_acc: 0.8216\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9747\n",
      "Epoch 00082: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0817 - acc: 0.9747 - val_loss: 0.7261 - val_acc: 0.8486\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0805 - acc: 0.9748\n",
      "Epoch 00083: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0805 - acc: 0.9748 - val_loss: 0.9861 - val_acc: 0.7939\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9758\n",
      "Epoch 00084: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0813 - acc: 0.9758 - val_loss: 0.7294 - val_acc: 0.8379\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0686 - acc: 0.9790\n",
      "Epoch 00085: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0686 - acc: 0.9790 - val_loss: 0.8609 - val_acc: 0.8255\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0767 - acc: 0.9757\n",
      "Epoch 00086: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0767 - acc: 0.9757 - val_loss: 0.5170 - val_acc: 0.8817\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9730\n",
      "Epoch 00087: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0911 - acc: 0.9730 - val_loss: 0.4430 - val_acc: 0.8984\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0766 - acc: 0.9761\n",
      "Epoch 00088: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0766 - acc: 0.9761 - val_loss: 0.4795 - val_acc: 0.8910\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0629 - acc: 0.9812\n",
      "Epoch 00089: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0629 - acc: 0.9812 - val_loss: 1.3245 - val_acc: 0.7573\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0674 - acc: 0.9796\n",
      "Epoch 00090: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0674 - acc: 0.9795 - val_loss: 1.0351 - val_acc: 0.7943\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9749\n",
      "Epoch 00091: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0792 - acc: 0.9749 - val_loss: 0.7650 - val_acc: 0.8272\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0625 - acc: 0.9807\n",
      "Epoch 00092: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0625 - acc: 0.9807 - val_loss: 1.1215 - val_acc: 0.7729\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0630 - acc: 0.9805\n",
      "Epoch 00093: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0630 - acc: 0.9805 - val_loss: 1.1256 - val_acc: 0.7901\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0615 - acc: 0.9812\n",
      "Epoch 00094: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0615 - acc: 0.9812 - val_loss: 1.0622 - val_acc: 0.7745\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9787\n",
      "Epoch 00095: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0704 - acc: 0.9787 - val_loss: 1.5138 - val_acc: 0.7561\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9798\n",
      "Epoch 00096: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0659 - acc: 0.9798 - val_loss: 1.1270 - val_acc: 0.8011\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9763\n",
      "Epoch 00097: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0788 - acc: 0.9763 - val_loss: 0.4413 - val_acc: 0.9005\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0597 - acc: 0.9824\n",
      "Epoch 00098: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0597 - acc: 0.9824 - val_loss: 0.9354 - val_acc: 0.8295\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0591 - acc: 0.9826\n",
      "Epoch 00099: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0592 - acc: 0.9826 - val_loss: 0.6052 - val_acc: 0.8679\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9779\n",
      "Epoch 00100: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0690 - acc: 0.9779 - val_loss: 0.6836 - val_acc: 0.8584\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9845\n",
      "Epoch 00101: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0564 - acc: 0.9845 - val_loss: 1.2380 - val_acc: 0.7636\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9807\n",
      "Epoch 00102: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0612 - acc: 0.9807 - val_loss: 0.7772 - val_acc: 0.8411\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0700 - acc: 0.9783\n",
      "Epoch 00103: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0700 - acc: 0.9783 - val_loss: 0.9052 - val_acc: 0.8150\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9837\n",
      "Epoch 00104: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0538 - acc: 0.9837 - val_loss: 0.5666 - val_acc: 0.8747\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9810\n",
      "Epoch 00105: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0618 - acc: 0.9810 - val_loss: 0.5525 - val_acc: 0.8828\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9822\n",
      "Epoch 00106: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0574 - acc: 0.9822 - val_loss: 0.5966 - val_acc: 0.8721\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0584 - acc: 0.9822\n",
      "Epoch 00107: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0584 - acc: 0.9822 - val_loss: 1.0704 - val_acc: 0.7934\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0526 - acc: 0.9836\n",
      "Epoch 00108: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0526 - acc: 0.9836 - val_loss: 0.7535 - val_acc: 0.8379\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0583 - acc: 0.9818\n",
      "Epoch 00109: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0583 - acc: 0.9819 - val_loss: 0.5879 - val_acc: 0.8691\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9811\n",
      "Epoch 00110: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0641 - acc: 0.9810 - val_loss: 0.7344 - val_acc: 0.8463\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0738 - acc: 0.9780\n",
      "Epoch 00111: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0738 - acc: 0.9780 - val_loss: 0.5350 - val_acc: 0.8859\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0433 - acc: 0.9870\n",
      "Epoch 00112: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0434 - acc: 0.9869 - val_loss: 0.6664 - val_acc: 0.8710\n",
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9774\n",
      "Epoch 00113: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 167s 5ms/sample - loss: 0.0748 - acc: 0.9774 - val_loss: 0.4455 - val_acc: 0.9003\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9871\n",
      "Epoch 00114: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0446 - acc: 0.9871 - val_loss: 0.9514 - val_acc: 0.8290\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0639 - acc: 0.9812\n",
      "Epoch 00115: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0639 - acc: 0.9812 - val_loss: 0.5460 - val_acc: 0.8861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9845\n",
      "Epoch 00116: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0518 - acc: 0.9845 - val_loss: 0.6638 - val_acc: 0.8626\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0511 - acc: 0.9846\n",
      "Epoch 00117: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0511 - acc: 0.9846 - val_loss: 0.8220 - val_acc: 0.8341\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0513 - acc: 0.9852\n",
      "Epoch 00118: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0514 - acc: 0.9852 - val_loss: 0.7925 - val_acc: 0.8425\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0552 - acc: 0.9838\n",
      "Epoch 00119: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0552 - acc: 0.9838 - val_loss: 0.5345 - val_acc: 0.8817\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0522 - acc: 0.9846\n",
      "Epoch 00120: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0522 - acc: 0.9846 - val_loss: 0.5292 - val_acc: 0.8905\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0482 - acc: 0.9853\n",
      "Epoch 00121: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0482 - acc: 0.9853 - val_loss: 1.0546 - val_acc: 0.7976\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0484 - acc: 0.9851\n",
      "Epoch 00122: val_loss did not improve from 0.41917\n",
      "36805/36805 [==============================] - 168s 5ms/sample - loss: 0.0484 - acc: 0.9851 - val_loss: 1.0184 - val_acc: 0.8006\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_7_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.5582 - acc: 0.8681\n",
      "Loss: 0.5582438387479614 Accuracy: 0.86812043\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.3372 - acc: 0.2896\n",
      "Epoch 00001: val_loss improved from inf to 1.80493, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/001-1.8049.hdf5\n",
      "36805/36805 [==============================] - 212s 6ms/sample - loss: 2.3371 - acc: 0.2896 - val_loss: 1.8049 - val_acc: 0.4335\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.6240 - acc: 0.4913\n",
      "Epoch 00002: val_loss improved from 1.80493 to 1.44399, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/002-1.4440.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 1.6240 - acc: 0.4913 - val_loss: 1.4440 - val_acc: 0.5618\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2830 - acc: 0.5999\n",
      "Epoch 00003: val_loss improved from 1.44399 to 1.12617, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/003-1.1262.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 1.2830 - acc: 0.5999 - val_loss: 1.1262 - val_acc: 0.6506\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.0565 - acc: 0.6770\n",
      "Epoch 00004: val_loss improved from 1.12617 to 0.90630, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/004-0.9063.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 1.0563 - acc: 0.6770 - val_loss: 0.9063 - val_acc: 0.7270\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8910 - acc: 0.7292\n",
      "Epoch 00005: val_loss did not improve from 0.90630\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.8910 - acc: 0.7292 - val_loss: 0.9245 - val_acc: 0.7282\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.7684 - acc: 0.7693\n",
      "Epoch 00006: val_loss improved from 0.90630 to 0.77347, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/006-0.7735.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.7685 - acc: 0.7692 - val_loss: 0.7735 - val_acc: 0.7659\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6724 - acc: 0.8020\n",
      "Epoch 00007: val_loss improved from 0.77347 to 0.61674, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/007-0.6167.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.6725 - acc: 0.8020 - val_loss: 0.6167 - val_acc: 0.8251\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6003 - acc: 0.8242\n",
      "Epoch 00008: val_loss improved from 0.61674 to 0.52106, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/008-0.5211.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.6004 - acc: 0.8241 - val_loss: 0.5211 - val_acc: 0.8507\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5489 - acc: 0.8377\n",
      "Epoch 00009: val_loss improved from 0.52106 to 0.47289, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/009-0.4729.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.5489 - acc: 0.8378 - val_loss: 0.4729 - val_acc: 0.8679\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4893 - acc: 0.8580\n",
      "Epoch 00010: val_loss did not improve from 0.47289\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.4893 - acc: 0.8580 - val_loss: 0.4965 - val_acc: 0.8588\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4518 - acc: 0.8677\n",
      "Epoch 00011: val_loss did not improve from 0.47289\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.4518 - acc: 0.8677 - val_loss: 0.4877 - val_acc: 0.8647\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4161 - acc: 0.8798\n",
      "Epoch 00012: val_loss did not improve from 0.47289\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.4164 - acc: 0.8797 - val_loss: 0.6013 - val_acc: 0.8325\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3970 - acc: 0.8851\n",
      "Epoch 00013: val_loss did not improve from 0.47289\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.3970 - acc: 0.8851 - val_loss: 0.5053 - val_acc: 0.8544\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3658 - acc: 0.8921\n",
      "Epoch 00014: val_loss improved from 0.47289 to 0.42450, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/014-0.4245.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.3658 - acc: 0.8921 - val_loss: 0.4245 - val_acc: 0.8719\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3295 - acc: 0.9038\n",
      "Epoch 00015: val_loss did not improve from 0.42450\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.3295 - acc: 0.9038 - val_loss: 0.6235 - val_acc: 0.8246\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3216 - acc: 0.9057\n",
      "Epoch 00016: val_loss improved from 0.42450 to 0.30818, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/016-0.3082.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.3216 - acc: 0.9057 - val_loss: 0.3082 - val_acc: 0.9152\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3006 - acc: 0.9120\n",
      "Epoch 00017: val_loss did not improve from 0.30818\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.3007 - acc: 0.9120 - val_loss: 0.7351 - val_acc: 0.8095\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2917 - acc: 0.9157\n",
      "Epoch 00018: val_loss improved from 0.30818 to 0.28532, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/018-0.2853.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.2917 - acc: 0.9157 - val_loss: 0.2853 - val_acc: 0.9210\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2710 - acc: 0.9200\n",
      "Epoch 00019: val_loss did not improve from 0.28532\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.2710 - acc: 0.9200 - val_loss: 0.4999 - val_acc: 0.8619\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2542 - acc: 0.9249\n",
      "Epoch 00020: val_loss did not improve from 0.28532\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.2542 - acc: 0.9249 - val_loss: 0.6870 - val_acc: 0.8013\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2444 - acc: 0.9282\n",
      "Epoch 00021: val_loss did not improve from 0.28532\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.2445 - acc: 0.9282 - val_loss: 0.5023 - val_acc: 0.8556\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2353 - acc: 0.9299\n",
      "Epoch 00022: val_loss did not improve from 0.28532\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.2352 - acc: 0.9299 - val_loss: 0.8201 - val_acc: 0.7866\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2272 - acc: 0.9328\n",
      "Epoch 00023: val_loss did not improve from 0.28532\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.2273 - acc: 0.9328 - val_loss: 0.5422 - val_acc: 0.8570\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2113 - acc: 0.9381\n",
      "Epoch 00024: val_loss did not improve from 0.28532\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.2113 - acc: 0.9381 - val_loss: 1.0323 - val_acc: 0.7310\n",
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2087 - acc: 0.9383\n",
      "Epoch 00025: val_loss did not improve from 0.28532\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.2087 - acc: 0.9384 - val_loss: 0.4579 - val_acc: 0.8775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1971 - acc: 0.9419\n",
      "Epoch 00026: val_loss did not improve from 0.28532\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1971 - acc: 0.9419 - val_loss: 0.4688 - val_acc: 0.8730\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1878 - acc: 0.9448\n",
      "Epoch 00027: val_loss improved from 0.28532 to 0.27237, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/027-0.2724.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1878 - acc: 0.9448 - val_loss: 0.2724 - val_acc: 0.9229\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1807 - acc: 0.9466\n",
      "Epoch 00028: val_loss did not improve from 0.27237\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1807 - acc: 0.9466 - val_loss: 0.3137 - val_acc: 0.9082\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1683 - acc: 0.9494\n",
      "Epoch 00029: val_loss improved from 0.27237 to 0.25796, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/029-0.2580.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1684 - acc: 0.9494 - val_loss: 0.2580 - val_acc: 0.9227\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9476\n",
      "Epoch 00030: val_loss did not improve from 0.25796\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1739 - acc: 0.9476 - val_loss: 0.3759 - val_acc: 0.8933\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9502\n",
      "Epoch 00031: val_loss did not improve from 0.25796\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1624 - acc: 0.9502 - val_loss: 0.2969 - val_acc: 0.9187\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1632 - acc: 0.9518\n",
      "Epoch 00032: val_loss did not improve from 0.25796\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1633 - acc: 0.9518 - val_loss: 0.4277 - val_acc: 0.8777\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1460 - acc: 0.9551\n",
      "Epoch 00033: val_loss did not improve from 0.25796\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1460 - acc: 0.9551 - val_loss: 0.2972 - val_acc: 0.9157\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1424 - acc: 0.9569\n",
      "Epoch 00034: val_loss did not improve from 0.25796\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1424 - acc: 0.9569 - val_loss: 0.2669 - val_acc: 0.9276\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1343 - acc: 0.9607\n",
      "Epoch 00035: val_loss did not improve from 0.25796\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1344 - acc: 0.9607 - val_loss: 0.6656 - val_acc: 0.8248\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1422 - acc: 0.9562\n",
      "Epoch 00036: val_loss did not improve from 0.25796\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1422 - acc: 0.9562 - val_loss: 0.3550 - val_acc: 0.8982\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1284 - acc: 0.9617\n",
      "Epoch 00037: val_loss improved from 0.25796 to 0.24233, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/037-0.2423.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1284 - acc: 0.9617 - val_loss: 0.2423 - val_acc: 0.9315\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1176 - acc: 0.9648\n",
      "Epoch 00038: val_loss did not improve from 0.24233\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1176 - acc: 0.9648 - val_loss: 0.4997 - val_acc: 0.8614\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1166 - acc: 0.9647\n",
      "Epoch 00039: val_loss did not improve from 0.24233\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1166 - acc: 0.9647 - val_loss: 0.3581 - val_acc: 0.8998\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9667\n",
      "Epoch 00040: val_loss did not improve from 0.24233\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1097 - acc: 0.9667 - val_loss: 0.2697 - val_acc: 0.9224\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1159 - acc: 0.9648\n",
      "Epoch 00041: val_loss did not improve from 0.24233\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1159 - acc: 0.9648 - val_loss: 0.2596 - val_acc: 0.9222\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9711\n",
      "Epoch 00042: val_loss did not improve from 0.24233\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0972 - acc: 0.9711 - val_loss: 0.4985 - val_acc: 0.8654\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1068 - acc: 0.9676\n",
      "Epoch 00043: val_loss did not improve from 0.24233\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1069 - acc: 0.9676 - val_loss: 0.2781 - val_acc: 0.9220\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1043 - acc: 0.9676\n",
      "Epoch 00044: val_loss improved from 0.24233 to 0.23421, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/044-0.2342.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1043 - acc: 0.9676 - val_loss: 0.2342 - val_acc: 0.9385\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9679\n",
      "Epoch 00045: val_loss did not improve from 0.23421\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.1056 - acc: 0.9679 - val_loss: 0.2888 - val_acc: 0.9208\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0913 - acc: 0.9722\n",
      "Epoch 00046: val_loss did not improve from 0.23421\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0914 - acc: 0.9722 - val_loss: 0.3799 - val_acc: 0.9022\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9712\n",
      "Epoch 00047: val_loss did not improve from 0.23421\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0926 - acc: 0.9712 - val_loss: 0.4623 - val_acc: 0.8782\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9739\n",
      "Epoch 00048: val_loss did not improve from 0.23421\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0874 - acc: 0.9739 - val_loss: 0.5310 - val_acc: 0.8586\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9750\n",
      "Epoch 00049: val_loss improved from 0.23421 to 0.22873, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/049-0.2287.hdf5\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0841 - acc: 0.9750 - val_loss: 0.2287 - val_acc: 0.9362\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0770 - acc: 0.9763\n",
      "Epoch 00050: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0770 - acc: 0.9763 - val_loss: 0.2889 - val_acc: 0.9215\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9763\n",
      "Epoch 00051: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0792 - acc: 0.9763 - val_loss: 0.7428 - val_acc: 0.8432\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0790 - acc: 0.9760\n",
      "Epoch 00052: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0793 - acc: 0.9759 - val_loss: 0.2880 - val_acc: 0.9217\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0952 - acc: 0.9712\n",
      "Epoch 00053: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0952 - acc: 0.9713 - val_loss: 0.2949 - val_acc: 0.9243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0632 - acc: 0.9810\n",
      "Epoch 00054: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0632 - acc: 0.9810 - val_loss: 0.3143 - val_acc: 0.9129\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0661 - acc: 0.9799\n",
      "Epoch 00055: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0662 - acc: 0.9799 - val_loss: 0.2521 - val_acc: 0.9350\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0683 - acc: 0.9800\n",
      "Epoch 00056: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0683 - acc: 0.9800 - val_loss: 0.3929 - val_acc: 0.9026\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0638 - acc: 0.9805\n",
      "Epoch 00057: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0638 - acc: 0.9805 - val_loss: 0.3856 - val_acc: 0.8963\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0644 - acc: 0.9807\n",
      "Epoch 00058: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0643 - acc: 0.9807 - val_loss: 0.3738 - val_acc: 0.9092\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0582 - acc: 0.9825\n",
      "Epoch 00059: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0582 - acc: 0.9825 - val_loss: 0.2449 - val_acc: 0.9345\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0614 - acc: 0.9818\n",
      "Epoch 00060: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0614 - acc: 0.9818 - val_loss: 0.2458 - val_acc: 0.9336\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0562 - acc: 0.9832\n",
      "Epoch 00061: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0562 - acc: 0.9832 - val_loss: 0.4899 - val_acc: 0.8873\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0578 - acc: 0.9823\n",
      "Epoch 00062: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0578 - acc: 0.9823 - val_loss: 0.2655 - val_acc: 0.9373\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0648 - acc: 0.9806\n",
      "Epoch 00063: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0648 - acc: 0.9806 - val_loss: 0.3117 - val_acc: 0.9173\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9857\n",
      "Epoch 00064: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0498 - acc: 0.9857 - val_loss: 0.4303 - val_acc: 0.8977\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0723 - acc: 0.9785\n",
      "Epoch 00065: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 170s 5ms/sample - loss: 0.0724 - acc: 0.9785 - val_loss: 0.5620 - val_acc: 0.8602\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0481 - acc: 0.9855\n",
      "Epoch 00066: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0482 - acc: 0.9854 - val_loss: 0.2575 - val_acc: 0.9364\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0728 - acc: 0.9778\n",
      "Epoch 00067: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0728 - acc: 0.9778 - val_loss: 0.2397 - val_acc: 0.9320\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9873\n",
      "Epoch 00068: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0429 - acc: 0.9872 - val_loss: 0.2827 - val_acc: 0.9259\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9830\n",
      "Epoch 00069: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0575 - acc: 0.9830 - val_loss: 0.2935 - val_acc: 0.9241\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0459 - acc: 0.9856\n",
      "Epoch 00070: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0459 - acc: 0.9856 - val_loss: 0.3218 - val_acc: 0.9259\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0520 - acc: 0.9843\n",
      "Epoch 00071: val_loss did not improve from 0.22873\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0522 - acc: 0.9842 - val_loss: 0.3284 - val_acc: 0.9199\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0668 - acc: 0.9794\n",
      "Epoch 00072: val_loss improved from 0.22873 to 0.18500, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv_checkpoint/072-0.1850.hdf5\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0667 - acc: 0.9794 - val_loss: 0.1850 - val_acc: 0.9511\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0429 - acc: 0.9874\n",
      "Epoch 00073: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0429 - acc: 0.9874 - val_loss: 0.2528 - val_acc: 0.9378\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0440 - acc: 0.9871\n",
      "Epoch 00074: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0440 - acc: 0.9871 - val_loss: 0.2603 - val_acc: 0.9355\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0371 - acc: 0.9887\n",
      "Epoch 00075: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0371 - acc: 0.9887 - val_loss: 1.1134 - val_acc: 0.7829\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0421 - acc: 0.9867\n",
      "Epoch 00076: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0421 - acc: 0.9867 - val_loss: 0.5319 - val_acc: 0.8819\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9858\n",
      "Epoch 00077: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0483 - acc: 0.9858 - val_loss: 0.3224 - val_acc: 0.9215\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0476 - acc: 0.9849\n",
      "Epoch 00078: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0476 - acc: 0.9849 - val_loss: 0.2728 - val_acc: 0.9329\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0351 - acc: 0.9887\n",
      "Epoch 00079: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0351 - acc: 0.9887 - val_loss: 0.4117 - val_acc: 0.9031\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0480 - acc: 0.9857\n",
      "Epoch 00080: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0480 - acc: 0.9857 - val_loss: 0.2664 - val_acc: 0.9380\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9895\n",
      "Epoch 00081: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0339 - acc: 0.9895 - val_loss: 0.3865 - val_acc: 0.9152\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0396 - acc: 0.9881\n",
      "Epoch 00082: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0396 - acc: 0.9881 - val_loss: 0.3140 - val_acc: 0.9241\n",
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0372 - acc: 0.9885\n",
      "Epoch 00083: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0372 - acc: 0.9885 - val_loss: 0.3169 - val_acc: 0.9220\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9863\n",
      "Epoch 00084: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0449 - acc: 0.9863 - val_loss: 0.2558 - val_acc: 0.9359\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0322 - acc: 0.9903\n",
      "Epoch 00085: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0323 - acc: 0.9902 - val_loss: 0.2498 - val_acc: 0.9394\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0589 - acc: 0.9813\n",
      "Epoch 00086: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0589 - acc: 0.9813 - val_loss: 0.2182 - val_acc: 0.9457\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9919\n",
      "Epoch 00087: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0258 - acc: 0.9918 - val_loss: 0.2325 - val_acc: 0.9483\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0377 - acc: 0.9885\n",
      "Epoch 00088: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0378 - acc: 0.9885 - val_loss: 0.3985 - val_acc: 0.9087\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9851\n",
      "Epoch 00089: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0502 - acc: 0.9851 - val_loss: 0.3772 - val_acc: 0.9168\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9912\n",
      "Epoch 00090: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0285 - acc: 0.9912 - val_loss: 0.4870 - val_acc: 0.8940\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0254 - acc: 0.9928\n",
      "Epoch 00091: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0254 - acc: 0.9928 - val_loss: 0.3867 - val_acc: 0.9119\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0332 - acc: 0.9904\n",
      "Epoch 00092: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0335 - acc: 0.9904 - val_loss: 0.6447 - val_acc: 0.8623\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0491 - acc: 0.9850\n",
      "Epoch 00093: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0491 - acc: 0.9850 - val_loss: 0.2428 - val_acc: 0.9380\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9913\n",
      "Epoch 00094: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0291 - acc: 0.9913 - val_loss: 0.2816 - val_acc: 0.9320\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0318 - acc: 0.9907\n",
      "Epoch 00095: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0319 - acc: 0.9907 - val_loss: 0.2416 - val_acc: 0.9429\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9873\n",
      "Epoch 00096: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0417 - acc: 0.9873 - val_loss: 0.2547 - val_acc: 0.9434\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0405 - acc: 0.9881\n",
      "Epoch 00097: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0405 - acc: 0.9881 - val_loss: 0.2323 - val_acc: 0.9467\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0228 - acc: 0.9934\n",
      "Epoch 00098: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0228 - acc: 0.9934 - val_loss: 0.2326 - val_acc: 0.9481\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0364 - acc: 0.9890\n",
      "Epoch 00099: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0363 - acc: 0.9890 - val_loss: 0.2501 - val_acc: 0.9411\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0258 - acc: 0.9921\n",
      "Epoch 00100: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0258 - acc: 0.9921 - val_loss: 0.2530 - val_acc: 0.9434\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9897\n",
      "Epoch 00101: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0357 - acc: 0.9897 - val_loss: 0.2512 - val_acc: 0.9415\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0312 - acc: 0.9904\n",
      "Epoch 00102: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0312 - acc: 0.9904 - val_loss: 0.2969 - val_acc: 0.9276\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0250 - acc: 0.9927\n",
      "Epoch 00103: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0250 - acc: 0.9927 - val_loss: 0.3071 - val_acc: 0.9352\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0257 - acc: 0.9922\n",
      "Epoch 00104: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0257 - acc: 0.9922 - val_loss: 0.5676 - val_acc: 0.8835\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0327 - acc: 0.9902\n",
      "Epoch 00105: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0327 - acc: 0.9902 - val_loss: 0.3760 - val_acc: 0.9159\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9892\n",
      "Epoch 00106: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0336 - acc: 0.9892 - val_loss: 0.2657 - val_acc: 0.9387\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0293 - acc: 0.9908\n",
      "Epoch 00107: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0294 - acc: 0.9908 - val_loss: 0.2319 - val_acc: 0.9469\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0369 - acc: 0.9887\n",
      "Epoch 00108: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0369 - acc: 0.9887 - val_loss: 0.2746 - val_acc: 0.9322\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0200 - acc: 0.9942\n",
      "Epoch 00109: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0202 - acc: 0.9941 - val_loss: 0.3629 - val_acc: 0.9229\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0419 - acc: 0.9874\n",
      "Epoch 00110: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0419 - acc: 0.9874 - val_loss: 0.2363 - val_acc: 0.9436\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0227 - acc: 0.9934\n",
      "Epoch 00111: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0227 - acc: 0.9934 - val_loss: 0.3517 - val_acc: 0.9245\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0291 - acc: 0.9907\n",
      "Epoch 00112: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0291 - acc: 0.9907 - val_loss: 0.6397 - val_acc: 0.8619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0222 - acc: 0.9933\n",
      "Epoch 00113: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0222 - acc: 0.9933 - val_loss: 0.3165 - val_acc: 0.9257\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0193 - acc: 0.9946\n",
      "Epoch 00114: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0193 - acc: 0.9946 - val_loss: 0.3633 - val_acc: 0.9206\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0326 - acc: 0.9900\n",
      "Epoch 00115: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0326 - acc: 0.9900 - val_loss: 0.7131 - val_acc: 0.8472\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0232 - acc: 0.9930\n",
      "Epoch 00116: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0232 - acc: 0.9930 - val_loss: 0.2523 - val_acc: 0.9432\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0299 - acc: 0.9903\n",
      "Epoch 00117: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0300 - acc: 0.9902 - val_loss: 0.3834 - val_acc: 0.9180\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0389 - acc: 0.9888\n",
      "Epoch 00118: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0389 - acc: 0.9888 - val_loss: 0.2083 - val_acc: 0.9518\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9942\n",
      "Epoch 00119: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0191 - acc: 0.9942 - val_loss: 0.2588 - val_acc: 0.9411\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0237 - acc: 0.9931\n",
      "Epoch 00120: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0237 - acc: 0.9931 - val_loss: 0.2430 - val_acc: 0.9406\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0190 - acc: 0.9940\n",
      "Epoch 00121: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0191 - acc: 0.9940 - val_loss: 0.3552 - val_acc: 0.9194\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0385 - acc: 0.9886\n",
      "Epoch 00122: val_loss did not improve from 0.18500\n",
      "36805/36805 [==============================] - 169s 5ms/sample - loss: 0.0385 - acc: 0.9886 - val_loss: 0.2373 - val_acc: 0.9474\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2550 - acc: 0.9364\n",
      "Loss: 0.25499458150824034 Accuracy: 0.9364486\n",
      "\n",
      "Train on 36805 samples, validate on 4293 samples\n",
      "Epoch 1/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 2.0621 - acc: 0.3744\n",
      "Epoch 00001: val_loss improved from inf to 1.80081, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/001-1.8008.hdf5\n",
      "36805/36805 [==============================] - 228s 6ms/sample - loss: 2.0623 - acc: 0.3744 - val_loss: 1.8008 - val_acc: 0.4561\n",
      "Epoch 2/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 1.2209 - acc: 0.6198\n",
      "Epoch 00002: val_loss improved from 1.80081 to 1.18811, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/002-1.1881.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 1.2209 - acc: 0.6198 - val_loss: 1.1881 - val_acc: 0.6245\n",
      "Epoch 3/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.8480 - acc: 0.7407\n",
      "Epoch 00003: val_loss improved from 1.18811 to 0.71696, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/003-0.7170.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.8479 - acc: 0.7408 - val_loss: 0.7170 - val_acc: 0.7773\n",
      "Epoch 4/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.6325 - acc: 0.8089\n",
      "Epoch 00004: val_loss did not improve from 0.71696\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.6326 - acc: 0.8089 - val_loss: 0.7340 - val_acc: 0.7789\n",
      "Epoch 5/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.5075 - acc: 0.8473\n",
      "Epoch 00005: val_loss improved from 0.71696 to 0.46997, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/005-0.4700.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.5075 - acc: 0.8473 - val_loss: 0.4700 - val_acc: 0.8523\n",
      "Epoch 6/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.4277 - acc: 0.8706\n",
      "Epoch 00006: val_loss improved from 0.46997 to 0.36687, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/006-0.3669.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.4277 - acc: 0.8706 - val_loss: 0.3669 - val_acc: 0.8880\n",
      "Epoch 7/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3649 - acc: 0.8915\n",
      "Epoch 00007: val_loss did not improve from 0.36687\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.3649 - acc: 0.8914 - val_loss: 0.4403 - val_acc: 0.8768\n",
      "Epoch 8/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.3279 - acc: 0.9000\n",
      "Epoch 00008: val_loss improved from 0.36687 to 0.30981, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/008-0.3098.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.3279 - acc: 0.9000 - val_loss: 0.3098 - val_acc: 0.9099\n",
      "Epoch 9/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2951 - acc: 0.9098\n",
      "Epoch 00009: val_loss did not improve from 0.30981\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2951 - acc: 0.9097 - val_loss: 0.3486 - val_acc: 0.8975\n",
      "Epoch 10/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2612 - acc: 0.9218\n",
      "Epoch 00010: val_loss improved from 0.30981 to 0.26684, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/010-0.2668.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2612 - acc: 0.9217 - val_loss: 0.2668 - val_acc: 0.9231\n",
      "Epoch 11/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2449 - acc: 0.9255\n",
      "Epoch 00011: val_loss improved from 0.26684 to 0.26310, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/011-0.2631.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.2449 - acc: 0.9255 - val_loss: 0.2631 - val_acc: 0.9220\n",
      "Epoch 12/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.2154 - acc: 0.9353\n",
      "Epoch 00012: val_loss improved from 0.26310 to 0.23625, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/012-0.2362.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.2154 - acc: 0.9353 - val_loss: 0.2362 - val_acc: 0.9311\n",
      "Epoch 13/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1946 - acc: 0.9395\n",
      "Epoch 00013: val_loss did not improve from 0.23625\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1947 - acc: 0.9395 - val_loss: 0.3048 - val_acc: 0.9087\n",
      "Epoch 14/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1900 - acc: 0.9417\n",
      "Epoch 00014: val_loss improved from 0.23625 to 0.23396, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/014-0.2340.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.1900 - acc: 0.9417 - val_loss: 0.2340 - val_acc: 0.9306\n",
      "Epoch 15/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1702 - acc: 0.9477\n",
      "Epoch 00015: val_loss improved from 0.23396 to 0.21936, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/015-0.2194.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.1703 - acc: 0.9477 - val_loss: 0.2194 - val_acc: 0.9345\n",
      "Epoch 16/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1614 - acc: 0.9508\n",
      "Epoch 00016: val_loss improved from 0.21936 to 0.20455, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/016-0.2045.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.1614 - acc: 0.9508 - val_loss: 0.2045 - val_acc: 0.9425\n",
      "Epoch 17/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9563\n",
      "Epoch 00017: val_loss improved from 0.20455 to 0.20083, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/017-0.2008.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1417 - acc: 0.9563 - val_loss: 0.2008 - val_acc: 0.9397\n",
      "Epoch 18/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9568\n",
      "Epoch 00018: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1372 - acc: 0.9568 - val_loss: 0.2286 - val_acc: 0.9301\n",
      "Epoch 19/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1249 - acc: 0.9621\n",
      "Epoch 00019: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1249 - acc: 0.9620 - val_loss: 0.8698 - val_acc: 0.7491\n",
      "Epoch 20/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9608\n",
      "Epoch 00020: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1281 - acc: 0.9608 - val_loss: 0.2130 - val_acc: 0.9385\n",
      "Epoch 21/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9683\n",
      "Epoch 00021: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1068 - acc: 0.9683 - val_loss: 0.2139 - val_acc: 0.9383\n",
      "Epoch 22/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.1035 - acc: 0.9667\n",
      "Epoch 00022: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.1035 - acc: 0.9667 - val_loss: 0.2853 - val_acc: 0.9166\n",
      "Epoch 23/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0967 - acc: 0.9708\n",
      "Epoch 00023: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0967 - acc: 0.9708 - val_loss: 0.2454 - val_acc: 0.9259\n",
      "Epoch 24/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0926 - acc: 0.9719\n",
      "Epoch 00024: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0926 - acc: 0.9719 - val_loss: 0.2646 - val_acc: 0.9178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9742\n",
      "Epoch 00025: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0810 - acc: 0.9742 - val_loss: 0.5960 - val_acc: 0.8288\n",
      "Epoch 26/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0804 - acc: 0.9758\n",
      "Epoch 00026: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0804 - acc: 0.9758 - val_loss: 0.2510 - val_acc: 0.9327\n",
      "Epoch 27/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9762\n",
      "Epoch 00027: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0776 - acc: 0.9763 - val_loss: 0.4670 - val_acc: 0.8668\n",
      "Epoch 28/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9767\n",
      "Epoch 00028: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0763 - acc: 0.9767 - val_loss: 0.2283 - val_acc: 0.9324\n",
      "Epoch 29/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9788\n",
      "Epoch 00029: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0691 - acc: 0.9788 - val_loss: 0.2088 - val_acc: 0.9413\n",
      "Epoch 30/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0608 - acc: 0.9815\n",
      "Epoch 00030: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0610 - acc: 0.9814 - val_loss: 0.2918 - val_acc: 0.9222\n",
      "Epoch 31/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9764\n",
      "Epoch 00031: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0759 - acc: 0.9764 - val_loss: 0.3679 - val_acc: 0.8966\n",
      "Epoch 32/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0548 - acc: 0.9835\n",
      "Epoch 00032: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0548 - acc: 0.9835 - val_loss: 0.2104 - val_acc: 0.9420\n",
      "Epoch 33/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9855\n",
      "Epoch 00033: val_loss did not improve from 0.20083\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0511 - acc: 0.9855 - val_loss: 0.2184 - val_acc: 0.9392\n",
      "Epoch 34/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9831\n",
      "Epoch 00034: val_loss improved from 0.20083 to 0.19179, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/034-0.1918.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0559 - acc: 0.9831 - val_loss: 0.1918 - val_acc: 0.9457\n",
      "Epoch 35/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0509 - acc: 0.9837\n",
      "Epoch 00035: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0509 - acc: 0.9837 - val_loss: 0.2241 - val_acc: 0.9383\n",
      "Epoch 36/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0456 - acc: 0.9862\n",
      "Epoch 00036: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0457 - acc: 0.9862 - val_loss: 0.2107 - val_acc: 0.9467\n",
      "Epoch 37/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0618 - acc: 0.9810\n",
      "Epoch 00037: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0618 - acc: 0.9810 - val_loss: 0.4087 - val_acc: 0.8901\n",
      "Epoch 38/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9886\n",
      "Epoch 00038: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0381 - acc: 0.9886 - val_loss: 0.2321 - val_acc: 0.9392\n",
      "Epoch 39/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0415 - acc: 0.9873\n",
      "Epoch 00039: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0415 - acc: 0.9873 - val_loss: 0.2399 - val_acc: 0.9399\n",
      "Epoch 40/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0362 - acc: 0.9888\n",
      "Epoch 00040: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0362 - acc: 0.9888 - val_loss: 0.7758 - val_acc: 0.8102\n",
      "Epoch 41/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0427 - acc: 0.9869\n",
      "Epoch 00041: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0428 - acc: 0.9869 - val_loss: 0.3084 - val_acc: 0.9236\n",
      "Epoch 42/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0477 - acc: 0.9857\n",
      "Epoch 00042: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0477 - acc: 0.9857 - val_loss: 0.2263 - val_acc: 0.9418\n",
      "Epoch 43/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9907\n",
      "Epoch 00043: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0297 - acc: 0.9906 - val_loss: 0.2378 - val_acc: 0.9383\n",
      "Epoch 44/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9850\n",
      "Epoch 00044: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0487 - acc: 0.9850 - val_loss: 0.2396 - val_acc: 0.9348\n",
      "Epoch 45/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0304 - acc: 0.9902\n",
      "Epoch 00045: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0304 - acc: 0.9902 - val_loss: 0.1941 - val_acc: 0.9488\n",
      "Epoch 46/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0328 - acc: 0.9894\n",
      "Epoch 00046: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0328 - acc: 0.9894 - val_loss: 0.2325 - val_acc: 0.9394\n",
      "Epoch 47/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0300 - acc: 0.9907\n",
      "Epoch 00047: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0300 - acc: 0.9907 - val_loss: 0.2347 - val_acc: 0.9369\n",
      "Epoch 48/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0280 - acc: 0.9918\n",
      "Epoch 00048: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0280 - acc: 0.9918 - val_loss: 0.2794 - val_acc: 0.9324\n",
      "Epoch 49/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0307 - acc: 0.9902\n",
      "Epoch 00049: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0307 - acc: 0.9902 - val_loss: 0.2277 - val_acc: 0.9455\n",
      "Epoch 50/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0287 - acc: 0.9907\n",
      "Epoch 00050: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0287 - acc: 0.9907 - val_loss: 0.2467 - val_acc: 0.9336\n",
      "Epoch 51/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0285 - acc: 0.9914\n",
      "Epoch 00051: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0285 - acc: 0.9914 - val_loss: 0.4476 - val_acc: 0.8856\n",
      "Epoch 52/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0336 - acc: 0.9903\n",
      "Epoch 00052: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0336 - acc: 0.9903 - val_loss: 0.2463 - val_acc: 0.9401\n",
      "Epoch 53/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9929\n",
      "Epoch 00053: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0248 - acc: 0.9929 - val_loss: 0.2217 - val_acc: 0.9457\n",
      "Epoch 54/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0236 - acc: 0.9931\n",
      "Epoch 00054: val_loss did not improve from 0.19179\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0237 - acc: 0.9930 - val_loss: 0.6676 - val_acc: 0.8388\n",
      "Epoch 55/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0408 - acc: 0.9877\n",
      "Epoch 00055: val_loss improved from 0.19179 to 0.18519, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/055-0.1852.hdf5\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0408 - acc: 0.9877 - val_loss: 0.1852 - val_acc: 0.9550\n",
      "Epoch 56/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0221 - acc: 0.9935\n",
      "Epoch 00056: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0221 - acc: 0.9935 - val_loss: 0.1867 - val_acc: 0.9536\n",
      "Epoch 57/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0191 - acc: 0.9949\n",
      "Epoch 00057: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0191 - acc: 0.9949 - val_loss: 0.2104 - val_acc: 0.9490\n",
      "Epoch 58/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0264 - acc: 0.9919\n",
      "Epoch 00058: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0264 - acc: 0.9919 - val_loss: 0.2754 - val_acc: 0.9341\n",
      "Epoch 59/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9909\n",
      "Epoch 00059: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0289 - acc: 0.9909 - val_loss: 0.2349 - val_acc: 0.9425\n",
      "Epoch 60/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0247 - acc: 0.9923\n",
      "Epoch 00060: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0247 - acc: 0.9923 - val_loss: 0.3048 - val_acc: 0.9290\n",
      "Epoch 61/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9932\n",
      "Epoch 00061: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0225 - acc: 0.9932 - val_loss: 0.2034 - val_acc: 0.9483\n",
      "Epoch 62/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0381 - acc: 0.9880\n",
      "Epoch 00062: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0381 - acc: 0.9880 - val_loss: 0.1861 - val_acc: 0.9546\n",
      "Epoch 63/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0155 - acc: 0.9957\n",
      "Epoch 00063: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0155 - acc: 0.9957 - val_loss: 0.3194 - val_acc: 0.9217\n",
      "Epoch 64/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0189 - acc: 0.9947\n",
      "Epoch 00064: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0189 - acc: 0.9947 - val_loss: 0.1867 - val_acc: 0.9555\n",
      "Epoch 65/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0235 - acc: 0.9923\n",
      "Epoch 00065: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0236 - acc: 0.9923 - val_loss: 0.2123 - val_acc: 0.9478\n",
      "Epoch 66/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0297 - acc: 0.9907\n",
      "Epoch 00066: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0297 - acc: 0.9907 - val_loss: 0.2206 - val_acc: 0.9469\n",
      "Epoch 67/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0162 - acc: 0.9954\n",
      "Epoch 00067: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0162 - acc: 0.9954 - val_loss: 0.2346 - val_acc: 0.9471\n",
      "Epoch 68/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0216 - acc: 0.9938\n",
      "Epoch 00068: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0216 - acc: 0.9938 - val_loss: 0.2328 - val_acc: 0.9485\n",
      "Epoch 69/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9946\n",
      "Epoch 00069: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0173 - acc: 0.9946 - val_loss: 0.3686 - val_acc: 0.9064\n",
      "Epoch 70/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9955\n",
      "Epoch 00070: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0157 - acc: 0.9955 - val_loss: 0.2230 - val_acc: 0.9485\n",
      "Epoch 71/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0337 - acc: 0.9892\n",
      "Epoch 00071: val_loss did not improve from 0.18519\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0340 - acc: 0.9892 - val_loss: 0.2172 - val_acc: 0.9455\n",
      "Epoch 72/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0356 - acc: 0.9889\n",
      "Epoch 00072: val_loss improved from 0.18519 to 0.17364, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/072-0.1736.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0356 - acc: 0.9889 - val_loss: 0.1736 - val_acc: 0.9590\n",
      "Epoch 73/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0179 - acc: 0.9946\n",
      "Epoch 00073: val_loss improved from 0.17364 to 0.16404, saving model to model/checkpoint/1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv_checkpoint/073-0.1640.hdf5\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0180 - acc: 0.9946 - val_loss: 0.1640 - val_acc: 0.9590\n",
      "Epoch 74/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0225 - acc: 0.9933\n",
      "Epoch 00074: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0225 - acc: 0.9932 - val_loss: 0.1931 - val_acc: 0.9543\n",
      "Epoch 75/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0198 - acc: 0.9939\n",
      "Epoch 00075: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0198 - acc: 0.9939 - val_loss: 0.1826 - val_acc: 0.9574\n",
      "Epoch 76/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9961\n",
      "Epoch 00076: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0134 - acc: 0.9961 - val_loss: 0.2387 - val_acc: 0.9467\n",
      "Epoch 77/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0201 - acc: 0.9933\n",
      "Epoch 00077: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0201 - acc: 0.9933 - val_loss: 0.1864 - val_acc: 0.9581\n",
      "Epoch 78/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0118 - acc: 0.9966\n",
      "Epoch 00078: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0118 - acc: 0.9966 - val_loss: 0.2315 - val_acc: 0.9497\n",
      "Epoch 79/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0296 - acc: 0.9911\n",
      "Epoch 00079: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 172s 5ms/sample - loss: 0.0296 - acc: 0.9911 - val_loss: 0.1879 - val_acc: 0.9578\n",
      "Epoch 80/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0114 - acc: 0.9969\n",
      "Epoch 00080: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0115 - acc: 0.9969 - val_loss: 0.2396 - val_acc: 0.9432\n",
      "Epoch 81/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9923\n",
      "Epoch 00081: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0239 - acc: 0.9923 - val_loss: 0.1769 - val_acc: 0.9592\n",
      "Epoch 82/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0142 - acc: 0.9954\n",
      "Epoch 00082: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0142 - acc: 0.9954 - val_loss: 0.2546 - val_acc: 0.9413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9968\n",
      "Epoch 00083: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0112 - acc: 0.9968 - val_loss: 0.2481 - val_acc: 0.9467\n",
      "Epoch 84/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0242 - acc: 0.9921\n",
      "Epoch 00084: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0242 - acc: 0.9920 - val_loss: 0.1875 - val_acc: 0.9571\n",
      "Epoch 85/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9916\n",
      "Epoch 00085: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0259 - acc: 0.9916 - val_loss: 0.2155 - val_acc: 0.9504\n",
      "Epoch 86/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0120 - acc: 0.9966\n",
      "Epoch 00086: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0120 - acc: 0.9966 - val_loss: 0.2138 - val_acc: 0.9539\n",
      "Epoch 87/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0130 - acc: 0.9959\n",
      "Epoch 00087: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0131 - acc: 0.9958 - val_loss: 0.2587 - val_acc: 0.9413\n",
      "Epoch 88/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0354 - acc: 0.9894\n",
      "Epoch 00088: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0354 - acc: 0.9894 - val_loss: 0.1764 - val_acc: 0.9562\n",
      "Epoch 89/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9972\n",
      "Epoch 00089: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0095 - acc: 0.9972 - val_loss: 0.1982 - val_acc: 0.9569\n",
      "Epoch 90/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0170 - acc: 0.9947\n",
      "Epoch 00090: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0171 - acc: 0.9947 - val_loss: 0.2056 - val_acc: 0.9560\n",
      "Epoch 91/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0110 - acc: 0.9967\n",
      "Epoch 00091: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0111 - acc: 0.9967 - val_loss: 0.2081 - val_acc: 0.9529\n",
      "Epoch 92/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0131 - acc: 0.9960\n",
      "Epoch 00092: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0131 - acc: 0.9960 - val_loss: 0.2299 - val_acc: 0.9471\n",
      "Epoch 93/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0157 - acc: 0.9950\n",
      "Epoch 00093: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0157 - acc: 0.9950 - val_loss: 0.2561 - val_acc: 0.9446\n",
      "Epoch 94/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0172 - acc: 0.9945\n",
      "Epoch 00094: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0172 - acc: 0.9945 - val_loss: 0.2377 - val_acc: 0.9453\n",
      "Epoch 95/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9960\n",
      "Epoch 00095: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0129 - acc: 0.9960 - val_loss: 0.2193 - val_acc: 0.9509\n",
      "Epoch 96/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0148 - acc: 0.9957\n",
      "Epoch 00096: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0148 - acc: 0.9957 - val_loss: 0.2363 - val_acc: 0.9448\n",
      "Epoch 97/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9950\n",
      "Epoch 00097: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0160 - acc: 0.9950 - val_loss: 0.2342 - val_acc: 0.9469\n",
      "Epoch 98/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9931\n",
      "Epoch 00098: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0232 - acc: 0.9931 - val_loss: 0.1820 - val_acc: 0.9595\n",
      "Epoch 99/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0224 - acc: 0.9933\n",
      "Epoch 00099: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0224 - acc: 0.9933 - val_loss: 0.1689 - val_acc: 0.9618\n",
      "Epoch 100/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9986\n",
      "Epoch 00100: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0055 - acc: 0.9986 - val_loss: 0.1870 - val_acc: 0.9595\n",
      "Epoch 101/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0073 - acc: 0.9981\n",
      "Epoch 00101: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0073 - acc: 0.9981 - val_loss: 0.1967 - val_acc: 0.9541\n",
      "Epoch 102/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0173 - acc: 0.9945\n",
      "Epoch 00102: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0174 - acc: 0.9945 - val_loss: 0.2300 - val_acc: 0.9476\n",
      "Epoch 103/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9947\n",
      "Epoch 00103: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0163 - acc: 0.9947 - val_loss: 0.2065 - val_acc: 0.9534\n",
      "Epoch 104/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0115 - acc: 0.9965\n",
      "Epoch 00104: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0115 - acc: 0.9965 - val_loss: 0.2109 - val_acc: 0.9527\n",
      "Epoch 105/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0219 - acc: 0.9935\n",
      "Epoch 00105: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0220 - acc: 0.9934 - val_loss: 0.2119 - val_acc: 0.9515\n",
      "Epoch 106/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0223 - acc: 0.9933\n",
      "Epoch 00106: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0223 - acc: 0.9933 - val_loss: 0.1960 - val_acc: 0.9581\n",
      "Epoch 107/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9981\n",
      "Epoch 00107: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0076 - acc: 0.9981 - val_loss: 0.2113 - val_acc: 0.9546\n",
      "Epoch 108/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0230 - acc: 0.9925\n",
      "Epoch 00108: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0230 - acc: 0.9925 - val_loss: 0.1943 - val_acc: 0.9585\n",
      "Epoch 109/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9980\n",
      "Epoch 00109: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0066 - acc: 0.9980 - val_loss: 0.1930 - val_acc: 0.9606\n",
      "Epoch 110/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9972\n",
      "Epoch 00110: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0092 - acc: 0.9972 - val_loss: 0.2269 - val_acc: 0.9469\n",
      "Epoch 111/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0188 - acc: 0.9938\n",
      "Epoch 00111: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0188 - acc: 0.9938 - val_loss: 0.2556 - val_acc: 0.9420\n",
      "Epoch 112/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0078 - acc: 0.9979\n",
      "Epoch 00112: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0080 - acc: 0.9979 - val_loss: 0.4533 - val_acc: 0.8954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0249 - acc: 0.9921\n",
      "Epoch 00113: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0249 - acc: 0.9921 - val_loss: 0.2039 - val_acc: 0.9555\n",
      "Epoch 114/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0059 - acc: 0.9986\n",
      "Epoch 00114: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0059 - acc: 0.9986 - val_loss: 0.1816 - val_acc: 0.9588\n",
      "Epoch 115/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0129 - acc: 0.9959\n",
      "Epoch 00115: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0130 - acc: 0.9959 - val_loss: 0.2598 - val_acc: 0.9448\n",
      "Epoch 116/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0283 - acc: 0.9916\n",
      "Epoch 00116: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0283 - acc: 0.9916 - val_loss: 0.1830 - val_acc: 0.9583\n",
      "Epoch 117/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9986\n",
      "Epoch 00117: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0056 - acc: 0.9986 - val_loss: 0.2266 - val_acc: 0.9518\n",
      "Epoch 118/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0160 - acc: 0.9954\n",
      "Epoch 00118: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0162 - acc: 0.9954 - val_loss: 0.2063 - val_acc: 0.9571\n",
      "Epoch 119/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0184 - acc: 0.9941\n",
      "Epoch 00119: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0184 - acc: 0.9941 - val_loss: 0.2268 - val_acc: 0.9553\n",
      "Epoch 120/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0077 - acc: 0.9978\n",
      "Epoch 00120: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0077 - acc: 0.9978 - val_loss: 0.2039 - val_acc: 0.9532\n",
      "Epoch 121/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0056 - acc: 0.9985\n",
      "Epoch 00121: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0056 - acc: 0.9985 - val_loss: 0.2351 - val_acc: 0.9490\n",
      "Epoch 122/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0197 - acc: 0.9939\n",
      "Epoch 00122: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0197 - acc: 0.9939 - val_loss: 0.1919 - val_acc: 0.9574\n",
      "Epoch 123/500\n",
      "36800/36805 [============================>.] - ETA: 0s - loss: 0.0079 - acc: 0.9976\n",
      "Epoch 00123: val_loss did not improve from 0.16404\n",
      "36805/36805 [==============================] - 171s 5ms/sample - loss: 0.0079 - acc: 0.9976 - val_loss: 0.2352 - val_acc: 0.9499\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv Model\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2268 - acc: 0.9439\n",
      "Loss: 0.22682350990889538 Accuracy: 0.94392526\n",
      "\n"
     ]
    }
   ],
   "source": [
    "base = '1D_CNN_custom_conv_3_VGG_tanh_DO_BN'\n",
    "\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    model = build_1d_cnn_custom_conv_3_VGG_DO_BN(conv_num=i)\n",
    "#         model.summary()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=1e-4),\n",
    "          metrics=['accuracy'])\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    os.makedirs(model_path, exist_ok=True)\n",
    "    model_filename = model_path+'{epoch:03d}-{val_loss:.4f}.hdf5'\n",
    "    checkpointer = ModelCheckpoint(filepath = model_filename, monitor = \"val_loss\", \n",
    "                                   verbose=1, save_best_only=True)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50)\n",
    "    hist = model.fit(x_train_abs, y_train_onehot, batch_size=64, epochs=500, \n",
    "                     validation_data=[x_val_abs, y_val_onehot], shuffle=True, \n",
    "                     callbacks = [checkpointer, early_stopping])\n",
    "\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(hist.history['loss'], 'y', label='train loss')\n",
    "    ax.plot(hist.history['val_loss'], 'r', label='val loss')\n",
    "    ax.plot(hist.history['acc'], 'b', label='train acc')\n",
    "    ax.plot(hist.history['val_acc'], 'g', label='val acc')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    ax.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    png_path = 'visualization/learning_curve/'\n",
    "    filename = model_name+'.png'\n",
    "    os.makedirs(png_path, exist_ok=True)\n",
    "    fig.savefig(png_path+filename, transparent=True)\n",
    "\n",
    "    model.save(model_path+'000_last.hdf5')\n",
    "    del(model)\n",
    "\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "    model = load_model(model_filename)\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "    print()\n",
    "\n",
    "    del(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_1_conv Model\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,397,136\n",
      "Trainable params: 16,396,880\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 4s 858us/sample - loss: 5.1162 - acc: 0.1032\n",
      "Loss: 5.116166759898977 Accuracy: 0.10321911\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,499,344\n",
      "Trainable params: 5,498,832\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 3.0071 - acc: 0.2721\n",
      "Loss: 3.007104391224783 Accuracy: 0.27206644\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,883,216\n",
      "Trainable params: 1,882,448\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 3.2692 - acc: 0.3927\n",
      "Loss: 3.2692273603421507 Accuracy: 0.39273104\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 694,992\n",
      "Trainable params: 693,968\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 7s 1ms/sample - loss: 1.6950 - acc: 0.5952\n",
      "Loss: 1.6949939185585188 Accuracy: 0.59522325\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 567,248\n",
      "Trainable params: 565,712\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 7s 2ms/sample - loss: 1.3499 - acc: 0.7481\n",
      "Loss: 1.3499332119742657 Accuracy: 0.74807894\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_120 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_121 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_122 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_123 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_124 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_125 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_126 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_127 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_128 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_129 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_130 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_131 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 396,496\n",
      "Trainable params: 394,448\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.8908 - acc: 0.7666\n",
      "Loss: 0.8907650150861571 Accuracy: 0.7665628\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_132 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_133 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_134 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_135 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_136 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_137 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_138 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_139 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_140 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_141 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_142 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_143 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_144 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_145 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 405,968\n",
      "Trainable params: 403,408\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.5582 - acc: 0.8681\n",
      "Loss: 0.5582438387479614 Accuracy: 0.86812043\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_146 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_147 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_148 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_149 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_150 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_151 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_152 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_153 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_154 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_155 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_156 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_157 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_158 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_159 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_160 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_161 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 476,880\n",
      "Trainable params: 473,808\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 8s 2ms/sample - loss: 0.2550 - acc: 0.9364\n",
      "Loss: 0.25499458150824034 Accuracy: 0.9364486\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_162 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_163 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_164 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_165 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_166 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_167 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_168 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_169 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_170 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_171 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_172 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_173 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_174 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_175 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_176 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_177 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_178 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_179 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_179 (Activation)  (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 768,208\n",
      "Trainable params: 764,112\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 0.2268 - acc: 0.9439\n",
      "Loss: 0.22682350990889538 Accuracy: 0.94392526\n"
     ]
    }
   ],
   "source": [
    "log_dir = 'log'\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "base = '1D_CNN_custom_conv_3_VGG_tanh_DO_BN'\n",
    "\n",
    "with open(path.join(log_dir, base), 'w') as log_file:\n",
    "    for i in range(1, 10):\n",
    "        model_name = base+'_{}_conv'.format(i)\n",
    "        print()\n",
    "        print(model_name, 'Model')\n",
    "        model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "        model_filename = model_path + sorted(os.listdir(model_path))[-1]\n",
    "\n",
    "        model = load_model(model_filename)\n",
    "        model.summary()\n",
    "\n",
    "        [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "        print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "        del(model)\n",
    "\n",
    "        log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_1_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_90 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_90 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_90 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_91 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_91 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_91 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 1024000)           0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                16384016  \n",
      "=================================================================\n",
      "Total params: 16,397,136\n",
      "Trainable params: 16,396,880\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 6s 1ms/sample - loss: 12.1093 - acc: 0.1512\n",
      "Loss: 12.109296804251825 Accuracy: 0.15119419\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_2_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_92 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_92 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_92 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_93 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_93 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_93 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_94 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_94 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_94 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_95 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_95 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_95 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_36 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 341312)            0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                5461008   \n",
      "=================================================================\n",
      "Total params: 5,499,344\n",
      "Trainable params: 5,498,832\n",
      "Non-trainable params: 512\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 9s 2ms/sample - loss: 6.9546 - acc: 0.3780\n",
      "Loss: 6.9545821518665285 Accuracy: 0.37798545\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_3_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_96 (Conv1D)           (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_96 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_96 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_97 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_97 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_97 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_98 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_98 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_98 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_99 (Conv1D)           (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_99 (B (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_99 (Activation)   (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_37 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_100 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_100 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_100 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_101 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_101 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_101 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_38 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 113728)            0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 16)                1819664   \n",
      "=================================================================\n",
      "Total params: 1,883,216\n",
      "Trainable params: 1,882,448\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 4.8717 - acc: 0.4544\n",
      "Loss: 4.8717013095645765 Accuracy: 0.4544133\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_4_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_102 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_102 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_102 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_103 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_103 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_103 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_104 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_104 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_104 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_105 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_105 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_105 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_39 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_106 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_106 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_106 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_107 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_107 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_107 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_40 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_108 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_108 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_108 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_109 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_109 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_109 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_41 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 37888)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 16)                606224    \n",
      "=================================================================\n",
      "Total params: 694,992\n",
      "Trainable params: 693,968\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 3.2771 - acc: 0.5379\n",
      "Loss: 3.2771400493253426 Accuracy: 0.5379024\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_5_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_110 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_110 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_110 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_111 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_111 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_111 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_112 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_112 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_112 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_113 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_113 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_113 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_42 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_114 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_114 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_114 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_115 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_115 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_115 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_43 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_116 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_116 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_116 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_117 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_117 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_117 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_44 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_118 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_118 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_118 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_119 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_119 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_119 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_45 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 25216)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 16)                403472    \n",
      "=================================================================\n",
      "Total params: 567,248\n",
      "Trainable params: 565,712\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 1.8507 - acc: 0.6933\n",
      "Loss: 1.8507457660366071 Accuracy: 0.69325024\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_6_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_120 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_120 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_120 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_121 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_121 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_121 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_122 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_122 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_122 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_123 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_123 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_123 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_46 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_124 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_124 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_124 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_125 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_125 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_125 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_47 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_126 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_126 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_126 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_127 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_127 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_127 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_48 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_128 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_128 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_128 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_129 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_129 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_129 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_49 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_130 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_130 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_130 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_131 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_131 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_131 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_50 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 8320)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 16)                133136    \n",
      "=================================================================\n",
      "Total params: 396,496\n",
      "Trainable params: 394,448\n",
      "Non-trainable params: 2,048\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 10s 2ms/sample - loss: 1.6797 - acc: 0.6746\n",
      "Loss: 1.679700240489726 Accuracy: 0.6745587\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_7_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_132 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_132 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_132 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_133 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_133 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_133 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_134 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_134 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_134 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_135 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_135 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_135 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_51 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_136 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_136 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_136 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_137 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_137 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_137 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_52 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_138 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_138 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_138 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_139 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_139 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_139 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_53 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_140 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_140 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_140 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_141 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_141 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_141 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_54 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_142 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_142 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_142 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_143 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_143 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_143 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_55 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_144 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_144 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_144 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_145 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_145 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_145 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_56 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 2688)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 16)                43024     \n",
      "=================================================================\n",
      "Total params: 405,968\n",
      "Trainable params: 403,408\n",
      "Non-trainable params: 2,560\n",
      "_________________________________________________________________\n",
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 1.1711 - acc: 0.7815\n",
      "Loss: 1.1711453485216554 Accuracy: 0.7815161\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_8_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_146 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_146 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_146 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_147 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_147 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_147 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_148 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_148 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_148 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_149 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_149 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_149 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_57 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_150 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_150 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_150 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_151 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_151 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_151 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_58 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_152 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_152 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_152 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_153 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_153 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_153 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_59 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_154 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_154 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_154 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_155 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_155 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_155 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_60 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_156 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_156 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_156 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_157 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_157 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_157 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_61 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_158 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_158 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_158 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_159 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_159 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_159 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_62 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_160 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_160 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_160 (Activation)  (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_161 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_161 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_161 (Activation)  (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_63 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 896)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 16)                14352     \n",
      "=================================================================\n",
      "Total params: 476,880\n",
      "Trainable params: 473,808\n",
      "Non-trainable params: 3,072\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.2789 - acc: 0.9367\n",
      "Loss: 0.278882783901252 Accuracy: 0.9366563\n",
      "\n",
      "1D_CNN_custom_conv_3_VGG_tanh_DO_BN_9_conv Model\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_162 (Conv1D)          (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_162 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_162 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_163 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_163 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_163 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_164 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_164 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_164 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_165 (Conv1D)          (None, 16000, 64)         12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_165 ( (None, 16000, 64)         256       \n",
      "_________________________________________________________________\n",
      "activation_165 (Activation)  (None, 16000, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_64 (MaxPooling (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_166 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_166 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_166 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_167 (Conv1D)          (None, 5333, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_167 ( (None, 5333, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_167 (Activation)  (None, 5333, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_65 (MaxPooling (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_168 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_168 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_168 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_169 (Conv1D)          (None, 1777, 64)          12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_169 ( (None, 1777, 64)          256       \n",
      "_________________________________________________________________\n",
      "activation_169 (Activation)  (None, 1777, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_66 (MaxPooling (None, 592, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_170 (Conv1D)          (None, 592, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_170 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_170 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_171 (Conv1D)          (None, 592, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_171 ( (None, 592, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_171 (Activation)  (None, 592, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_67 (MaxPooling (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_172 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_172 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_172 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_173 (Conv1D)          (None, 197, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_173 ( (None, 197, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_173 (Activation)  (None, 197, 128)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_68 (MaxPooling (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_174 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_174 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_174 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_175 (Conv1D)          (None, 65, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_175 ( (None, 65, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_175 (Activation)  (None, 65, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_69 (MaxPooling (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_176 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_176 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_176 (Activation)  (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_177 (Conv1D)          (None, 21, 128)           49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_177 ( (None, 21, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_177 (Activation)  (None, 21, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_70 (MaxPooling (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_178 (Conv1D)          (None, 7, 256)            98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_178 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_178 (Activation)  (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_179 (Conv1D)          (None, 7, 256)            196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_179 ( (None, 7, 256)            1024      \n",
      "_________________________________________________________________\n",
      "activation_179 (Activation)  (None, 7, 256)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_71 (MaxPooling (None, 2, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 16)                8208      \n",
      "=================================================================\n",
      "Total params: 768,208\n",
      "Trainable params: 764,112\n",
      "Non-trainable params: 4,096\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4815/4815 [==============================] - 11s 2ms/sample - loss: 0.3472 - acc: 0.9263\n",
      "Loss: 0.3472443039914901 Accuracy: 0.9262721\n"
     ]
    }
   ],
   "source": [
    "# log_dir = 'log'\n",
    "# os.makedirs(log_dir, exist_ok=True)\n",
    "# base = '1D_CNN_custom_DO_BN'\n",
    "\n",
    "# with open(path.join(log_dir, base), 'w') as log_file:\n",
    "for i in range(1, 10):\n",
    "    model_name = base+'_{}_conv'.format(i)\n",
    "    print()\n",
    "    print(model_name, 'Model')\n",
    "    model_path = 'model/checkpoint/'+model_name+'_checkpoint/'\n",
    "    model_filename = model_path + '000_last.hdf5'\n",
    "\n",
    "    model = load_model(model_filename)\n",
    "    model.summary()\n",
    "\n",
    "    [loss, accuracy] = model.evaluate(x_test_abs, y_test_onehot)\n",
    "    print('Loss:', loss, 'Accuracy:', accuracy)\n",
    "\n",
    "    del(model)\n",
    "\n",
    "#         log_file.write('\\t'.join([model_name, str(accuracy), str(loss)])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
